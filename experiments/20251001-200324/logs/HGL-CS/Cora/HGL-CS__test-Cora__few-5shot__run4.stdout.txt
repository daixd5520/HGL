Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> CiteSeer
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=19.1124 cls=2.3078 smmd=4.7265 ct=9.2750 rec=1.4015 | train/val/test=0.241/0.212/0.224 | c=0.998896
[Epoch 0001] loss=18.7735 cls=2.0221 smmd=4.6975 ct=9.2750 rec=1.3895 | train/val/test=0.310/0.188/0.202 | c=0.998896
[Epoch 0002] loss=18.5770 cls=1.8959 smmd=4.6217 ct=9.2720 rec=1.3937 | train/val/test=0.448/0.254/0.249 | c=0.998896
[Epoch 0003] loss=18.4184 cls=1.8691 smmd=4.5059 ct=9.2605 rec=1.3915 | train/val/test=0.655/0.380/0.427 | c=0.998896
[Epoch 0004] loss=17.9745 cls=1.6313 smmd=4.3481 ct=9.2320 rec=1.3815 | train/val/test=0.897/0.386/0.430 | c=0.998896
[Epoch 0005] loss=17.3661 cls=1.3021 smmd=4.1446 ct=9.1779 rec=1.3707 | train/val/test=0.862/0.398/0.425 | c=0.998896
[Epoch 0006] loss=16.8936 cls=1.2607 smmd=3.8889 ct=9.0558 rec=1.3441 | train/val/test=0.793/0.478/0.514 | c=0.998896
[Epoch 0007] loss=16.5105 cls=1.2749 smmd=3.5871 ct=9.0050 rec=1.3217 | train/val/test=0.862/0.516/0.539 | c=0.998896
[Epoch 0008] loss=15.9190 cls=1.0667 smmd=3.2062 ct=9.0121 rec=1.3170 | train/val/test=0.862/0.422/0.418 | c=0.998896
[Epoch 0009] loss=15.1668 cls=0.9406 smmd=2.7643 ct=8.9092 rec=1.2763 | train/val/test=0.931/0.518/0.511 | c=0.998896
[Epoch 0010] loss=14.7412 cls=1.1375 smmd=2.2574 ct=8.8381 rec=1.2541 | train/val/test=0.966/0.570/0.552 | c=0.998896
[Epoch 0011] loss=13.9517 cls=0.9083 smmd=1.7100 ct=8.8401 rec=1.2467 | train/val/test=0.931/0.654/0.655 | c=0.998896
[Epoch 0012] loss=13.1640 cls=0.6517 smmd=1.2048 ct=8.8324 rec=1.2375 | train/val/test=0.966/0.654/0.654 | c=0.998896
[Epoch 0013] loss=13.0398 cls=0.9049 smmd=0.8584 ct=8.8187 rec=1.2289 | train/val/test=0.966/0.634/0.645 | c=0.998896
[Epoch 0014] loss=12.8419 cls=0.8075 smmd=0.8024 ct=8.8026 rec=1.2147 | train/val/test=0.966/0.666/0.659 | c=0.998896
[Epoch 0015] loss=12.7292 cls=0.5884 smmd=0.9695 ct=8.7727 rec=1.1993 | train/val/test=0.966/0.686/0.687 | c=0.998896
[Epoch 0016] loss=13.1978 cls=0.8316 smmd=1.2062 ct=8.7702 rec=1.1949 | train/val/test=0.966/0.688/0.693 | c=0.998896
[Epoch 0017] loss=13.9216 cls=1.3586 smmd=1.3930 ct=8.7820 rec=1.1941 | train/val/test=0.966/0.688/0.690 | c=0.998896
[Epoch 0018] loss=13.7877 cls=1.1378 smmd=1.4954 ct=8.7727 rec=1.1909 | train/val/test=0.966/0.592/0.626 | c=0.998896
[Epoch 0019] loss=13.4970 cls=0.7569 smmd=1.5320 ct=8.8003 rec=1.2039 | train/val/test=0.966/0.544/0.576 | c=0.998896
[Epoch 0020] loss=14.1748 cls=1.4209 smmd=1.4775 ct=8.8317 rec=1.2224 | train/val/test=0.966/0.614/0.632 | c=0.998896
[Epoch 0021] loss=13.7371 cls=1.2041 smmd=1.3190 ct=8.7993 rec=1.2074 | train/val/test=1.000/0.662/0.677 | c=0.998896
[Epoch 0022] loss=13.6635 cls=1.3378 smmd=1.1481 ct=8.7684 rec=1.2046 | train/val/test=1.000/0.688/0.693 | c=0.998896
[Epoch 0023] loss=13.0066 cls=0.8708 smmd=0.9946 ct=8.7545 rec=1.1934 | train/val/test=1.000/0.692/0.685 | c=0.998896
[Epoch 0024] loss=12.8470 cls=0.7856 smmd=0.9002 ct=8.7674 rec=1.1969 | train/val/test=1.000/0.698/0.695 | c=0.998896
[Epoch 0025] loss=12.8775 cls=0.8641 smmd=0.8374 ct=8.7685 rec=1.2037 | train/val/test=1.000/0.692/0.689 | c=0.998896
[Epoch 0026] loss=13.0506 cls=1.0888 smmd=0.7934 ct=8.7524 rec=1.2080 | train/val/test=1.000/0.692/0.686 | c=0.998896
[Epoch 0027] loss=12.9650 cls=1.0326 smmd=0.7713 ct=8.7318 rec=1.2146 | train/val/test=1.000/0.684/0.675 | c=0.998896
[Epoch 0028] loss=12.8336 cls=0.9191 smmd=0.7627 ct=8.7261 rec=1.2129 | train/val/test=1.000/0.676/0.658 | c=0.998896
[Epoch 0029] loss=13.1272 cls=1.2192 smmd=0.7451 ct=8.7228 rec=1.2201 | train/val/test=1.000/0.668/0.650 | c=0.998896
[Epoch 0030] loss=13.3344 cls=1.4486 smmd=0.7219 ct=8.7251 rec=1.2194 | train/val/test=1.000/0.660/0.650 | c=0.998896
[Epoch 0031] loss=13.0406 cls=1.1996 smmd=0.6715 ct=8.7226 rec=1.2234 | train/val/test=1.000/0.660/0.664 | c=0.998896
[Epoch 0032] loss=12.8010 cls=1.0226 smmd=0.6091 ct=8.7239 rec=1.2227 | train/val/test=1.000/0.676/0.669 | c=0.998896
[Epoch 0033] loss=12.4770 cls=0.7585 smmd=0.5563 ct=8.7236 rec=1.2193 | train/val/test=1.000/0.676/0.674 | c=0.998896
[Epoch 0034] loss=12.7299 cls=1.0697 smmd=0.5070 ct=8.7146 rec=1.2193 | train/val/test=1.000/0.674/0.674 | c=0.998896
[Epoch 0035] loss=12.2677 cls=0.6528 smmd=0.4746 ct=8.7113 rec=1.2145 | train/val/test=1.000/0.672/0.677 | c=0.998896
[Epoch 0036] loss=12.7609 cls=1.1664 smmd=0.4550 ct=8.7116 rec=1.2140 | train/val/test=1.000/0.678/0.671 | c=0.998896
[Epoch 0037] loss=12.7335 cls=1.1554 smmd=0.4291 ct=8.7115 rec=1.2188 | train/val/test=1.000/0.672/0.665 | c=0.998896
[Epoch 0038] loss=12.1199 cls=0.5797 smmd=0.4006 ct=8.7140 rec=1.2128 | train/val/test=1.000/0.670/0.664 | c=0.998896
[Epoch 0039] loss=12.8539 cls=1.3489 smmd=0.3674 ct=8.7134 rec=1.2121 | train/val/test=1.000/0.666/0.665 | c=0.998896
[Epoch 0040] loss=12.2716 cls=0.8177 smmd=0.3353 ct=8.7105 rec=1.2040 | train/val/test=1.000/0.670/0.673 | c=0.998896
[Epoch 0041] loss=12.5356 cls=1.1132 smmd=0.3053 ct=8.7093 rec=1.2039 | train/val/test=1.000/0.688/0.691 | c=0.998896
[Epoch 0042] loss=12.1862 cls=0.7775 smmd=0.2823 ct=8.7154 rec=1.2055 | train/val/test=1.000/0.690/0.697 | c=0.998896
[Epoch 0043] loss=12.4578 cls=1.0730 smmd=0.2552 ct=8.7176 rec=1.2060 | train/val/test=1.000/0.686/0.692 | c=0.998896
[Epoch 0044] loss=12.5719 cls=1.2241 smmd=0.2303 ct=8.7155 rec=1.2010 | train/val/test=1.000/0.680/0.681 | c=0.998896
[Epoch 0045] loss=12.4554 cls=1.1443 smmd=0.2106 ct=8.7089 rec=1.1959 | train/val/test=1.000/0.666/0.667 | c=0.998896
[Epoch 0046] loss=12.0222 cls=0.7216 smmd=0.1931 ct=8.7077 rec=1.1999 | train/val/test=1.000/0.662/0.657 | c=0.998896
[Epoch 0047] loss=12.2599 cls=0.9903 smmd=0.1787 ct=8.7060 rec=1.1924 | train/val/test=1.000/0.660/0.670 | c=0.998896
[Epoch 0048] loss=12.1646 cls=0.9185 smmd=0.1592 ct=8.7015 rec=1.1927 | train/val/test=1.000/0.654/0.673 | c=0.998896
[Epoch 0049] loss=12.3465 cls=1.1022 smmd=0.1536 ct=8.7005 rec=1.1951 | train/val/test=1.000/0.656/0.673 | c=0.998896
[Epoch 0050] loss=12.1704 cls=0.9387 smmd=0.1413 ct=8.7018 rec=1.1943 | train/val/test=1.000/0.660/0.676 | c=0.998896
[Epoch 0051] loss=12.0095 cls=0.7844 smmd=0.1296 ct=8.7029 rec=1.1963 | train/val/test=1.000/0.662/0.677 | c=0.998896
[Epoch 0052] loss=12.3984 cls=1.1945 smmd=0.1191 ct=8.7006 rec=1.1920 | train/val/test=1.000/0.656/0.674 | c=0.998896
[Epoch 0053] loss=12.2113 cls=1.0165 smmd=0.1132 ct=8.7036 rec=1.1890 | train/val/test=1.000/0.656/0.671 | c=0.998896
[Epoch 0054] loss=12.2776 cls=1.0858 smmd=0.1095 ct=8.6999 rec=1.1912 | train/val/test=1.000/0.656/0.661 | c=0.998896
[Epoch 0055] loss=12.1909 cls=0.9799 smmd=0.1129 ct=8.7070 rec=1.1956 | train/val/test=1.000/0.658/0.662 | c=0.998896
[Epoch 0056] loss=12.3093 cls=1.1146 smmd=0.1064 ct=8.7052 rec=1.1915 | train/val/test=1.000/0.674/0.665 | c=0.998896
[Epoch 0057] loss=12.2092 cls=1.0066 smmd=0.1029 ct=8.7072 rec=1.1963 | train/val/test=1.000/0.656/0.671 | c=0.998896
[Epoch 0058] loss=11.9029 cls=0.7148 smmd=0.0968 ct=8.7048 rec=1.1933 | train/val/test=1.000/0.664/0.672 | c=0.998896
[Epoch 0059] loss=11.9654 cls=0.7832 smmd=0.0908 ct=8.7020 rec=1.1947 | train/val/test=1.000/0.654/0.662 | c=0.998896
[Epoch 0060] loss=12.6750 cls=1.4912 smmd=0.0877 ct=8.7049 rec=1.1956 | train/val/test=1.000/0.648/0.650 | c=0.998896
[Epoch 0061] loss=12.1185 cls=0.9347 smmd=0.0886 ct=8.7014 rec=1.1969 | train/val/test=1.000/0.652/0.652 | c=0.998896
[Epoch 0062] loss=12.6545 cls=1.4807 smmd=0.0873 ct=8.6982 rec=1.1941 | train/val/test=1.000/0.656/0.654 | c=0.998896
[Epoch 0063] loss=12.5863 cls=1.3906 smmd=0.0882 ct=8.7037 rec=1.2019 | train/val/test=1.000/0.666/0.665 | c=0.998896
[Epoch 0064] loss=12.1750 cls=0.9936 smmd=0.0905 ct=8.7013 rec=1.1949 | train/val/test=1.000/0.664/0.661 | c=0.998896
[Epoch 0065] loss=12.0747 cls=0.8916 smmd=0.0851 ct=8.7031 rec=1.1975 | train/val/test=1.000/0.650/0.654 | c=0.998896
[Epoch 0066] loss=11.9413 cls=0.7625 smmd=0.0767 ct=8.7060 rec=1.1981 | train/val/test=1.000/0.642/0.647 | c=0.998896
[Epoch 0067] loss=12.1391 cls=0.9674 smmd=0.0755 ct=8.7045 rec=1.1958 | train/val/test=1.000/0.634/0.643 | c=0.998896
[Epoch 0068] loss=12.0837 cls=0.9132 smmd=0.0783 ct=8.7028 rec=1.1947 | train/val/test=1.000/0.632/0.640 | c=0.998896
[Epoch 0069] loss=12.4765 cls=1.2970 smmd=0.0822 ct=8.7012 rec=1.1980 | train/val/test=1.000/0.638/0.647 | c=0.998896
[Epoch 0070] loss=12.2871 cls=1.0971 smmd=0.0839 ct=8.7047 rec=1.2007 | train/val/test=1.000/0.640/0.651 | c=0.998896
[Epoch 0071] loss=12.1213 cls=0.9260 smmd=0.0847 ct=8.7055 rec=1.2025 | train/val/test=1.000/0.640/0.657 | c=0.998896
[Epoch 0072] loss=11.9823 cls=0.8062 smmd=0.0845 ct=8.7065 rec=1.1926 | train/val/test=1.000/0.652/0.660 | c=0.998896
[Epoch 0073] loss=12.1497 cls=0.9710 smmd=0.0841 ct=8.7093 rec=1.1926 | train/val/test=1.000/0.654/0.657 | c=0.998896
[Epoch 0074] loss=12.1263 cls=0.9404 smmd=0.0799 ct=8.7099 rec=1.1980 | train/val/test=1.000/0.660/0.660 | c=0.998896
[Epoch 0075] loss=11.9814 cls=0.8103 smmd=0.0775 ct=8.7052 rec=1.1942 | train/val/test=1.000/0.646/0.661 | c=0.998896
[Epoch 0076] loss=12.7183 cls=1.5373 smmd=0.0759 ct=8.7060 rec=1.1995 | train/val/test=1.000/0.642/0.660 | c=0.998896
[Epoch 0077] loss=11.9842 cls=0.8047 smmd=0.0754 ct=8.7070 rec=1.1985 | train/val/test=1.000/0.640/0.659 | c=0.998896
[Epoch 0078] loss=12.4095 cls=1.2497 smmd=0.0741 ct=8.7039 rec=1.1909 | train/val/test=1.000/0.636/0.655 | c=0.998896
[Epoch 0079] loss=12.5320 cls=1.3593 smmd=0.0759 ct=8.7029 rec=1.1970 | train/val/test=1.000/0.638/0.653 | c=0.998896
[Epoch 0080] loss=12.4253 cls=1.2567 smmd=0.0769 ct=8.7009 rec=1.1954 | train/val/test=1.000/0.632/0.651 | c=0.998896
[Epoch 0081] loss=12.2122 cls=1.0468 smmd=0.0766 ct=8.7019 rec=1.1934 | train/val/test=1.000/0.632/0.645 | c=0.998896
[Epoch 0082] loss=12.2460 cls=1.0726 smmd=0.0748 ct=8.7046 rec=1.1970 | train/val/test=1.000/0.634/0.643 | c=0.998896
[Epoch 0083] loss=12.0618 cls=0.9039 smmd=0.0747 ct=8.7046 rec=1.1893 | train/val/test=1.000/0.632/0.639 | c=0.998896
[Epoch 0084] loss=11.9521 cls=0.7892 smmd=0.0757 ct=8.7043 rec=1.1914 | train/val/test=1.000/0.634/0.642 | c=0.998896
[Epoch 0085] loss=12.0930 cls=0.9260 smmd=0.0751 ct=8.7039 rec=1.1940 | train/val/test=1.000/0.634/0.641 | c=0.998896
[Epoch 0086] loss=12.4903 cls=1.3298 smmd=0.0744 ct=8.7047 rec=1.1907 | train/val/test=1.000/0.634/0.645 | c=0.998896
[Epoch 0087] loss=12.1267 cls=0.9583 smmd=0.0758 ct=8.7050 rec=1.1938 | train/val/test=1.000/0.632/0.648 | c=0.998896
[Epoch 0088] loss=12.0841 cls=0.9284 smmd=0.0753 ct=8.7042 rec=1.1881 | train/val/test=1.000/0.634/0.647 | c=0.998896
[Epoch 0089] loss=12.1185 cls=0.9535 smmd=0.0743 ct=8.7050 rec=1.1929 | train/val/test=1.000/0.634/0.650 | c=0.998896
[Epoch 0090] loss=12.3330 cls=1.1705 smmd=0.0740 ct=8.7043 rec=1.1921 | train/val/test=1.000/0.630/0.651 | c=0.998896
[Epoch 0091] loss=12.1136 cls=0.9555 smmd=0.0726 ct=8.7046 rec=1.1904 | train/val/test=1.000/0.632/0.651 | c=0.998896
[Epoch 0092] loss=12.1670 cls=1.0091 smmd=0.0740 ct=8.7036 rec=1.1902 | train/val/test=1.000/0.632/0.652 | c=0.998896
[Epoch 0093] loss=12.1482 cls=0.9901 smmd=0.0739 ct=8.7038 rec=1.1902 | train/val/test=1.000/0.634/0.652 | c=0.998896
[Epoch 0094] loss=11.8466 cls=0.6940 smmd=0.0734 ct=8.7016 rec=1.1888 | train/val/test=1.000/0.632/0.653 | c=0.998896
[Epoch 0095] loss=12.2966 cls=1.1270 smmd=0.0737 ct=8.7029 rec=1.1965 | train/val/test=1.000/0.632/0.653 | c=0.998896
[Epoch 0096] loss=11.9108 cls=0.7552 smmd=0.0731 ct=8.7033 rec=1.1896 | train/val/test=1.000/0.630/0.653 | c=0.998896
[Epoch 0097] loss=12.4231 cls=1.2564 smmd=0.0742 ct=8.7019 rec=1.1953 | train/val/test=1.000/0.630/0.653 | c=0.998896
[Epoch 0098] loss=12.0052 cls=0.8502 smmd=0.0712 ct=8.7048 rec=1.1895 | train/val/test=1.000/0.630/0.653 | c=0.998896
[Epoch 0099] loss=12.4152 cls=1.2586 smmd=0.0732 ct=8.7028 rec=1.1903 | train/val/test=1.000/0.630/0.653 | c=0.998896
=== Best @ epoch 24: val=0.6980, test=0.6950 ===
