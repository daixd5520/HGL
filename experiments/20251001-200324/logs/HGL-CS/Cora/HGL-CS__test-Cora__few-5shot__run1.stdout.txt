Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> CiteSeer
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.8020 cls=2.0052 smmd=4.7344 ct=9.2842 rec=1.3891 | train/val/test=0.172/0.074/0.095 | c=0.998896
[Epoch 0001] loss=18.6652 cls=1.9232 smmd=4.6750 ct=9.2848 rec=1.3911 | train/val/test=0.655/0.238/0.257 | c=0.998896
[Epoch 0002] loss=18.4988 cls=1.8651 smmd=4.5761 ct=9.2804 rec=1.3886 | train/val/test=0.517/0.346/0.357 | c=0.998896
[Epoch 0003] loss=17.9910 cls=1.5163 smmd=4.4295 ct=9.2673 rec=1.3889 | train/val/test=0.931/0.540/0.549 | c=0.998896
[Epoch 0004] loss=17.5529 cls=1.3263 smmd=4.2413 ct=9.2303 rec=1.3775 | train/val/test=0.931/0.472/0.480 | c=0.998896
[Epoch 0005] loss=17.0061 cls=1.1714 smmd=3.9960 ct=9.1405 rec=1.3491 | train/val/test=0.966/0.592/0.562 | c=0.998896
[Epoch 0006] loss=16.2361 cls=0.9046 smmd=3.7136 ct=9.0102 rec=1.3039 | train/val/test=0.897/0.456/0.447 | c=0.998896
[Epoch 0007] loss=16.2711 cls=1.2333 smmd=3.3845 ct=9.0103 rec=1.3215 | train/val/test=0.966/0.646/0.653 | c=0.998896
[Epoch 0008] loss=15.2705 cls=0.7447 smmd=3.0533 ct=8.9587 rec=1.2569 | train/val/test=0.931/0.652/0.652 | c=0.998896
[Epoch 0009] loss=15.1099 cls=1.0145 smmd=2.6533 ct=8.9445 rec=1.2488 | train/val/test=0.966/0.602/0.583 | c=0.998896
[Epoch 0010] loss=14.5953 cls=1.0186 smmd=2.2012 ct=8.9153 rec=1.2301 | train/val/test=0.966/0.550/0.547 | c=0.998896
[Epoch 0011] loss=14.4941 cls=0.8775 smmd=1.7239 ct=9.4417 rec=1.2255 | train/val/test=0.966/0.652/0.624 | c=0.998896
[Epoch 0012] loss=14.3169 cls=1.2808 smmd=1.2891 ct=9.3384 rec=1.2043 | train/val/test=1.000/0.660/0.638 | c=0.998896
[Epoch 0013] loss=13.6705 cls=0.9258 smmd=1.0269 ct=9.2984 rec=1.2097 | train/val/test=0.966/0.660/0.623 | c=0.998896
[Epoch 0014] loss=13.6940 cls=1.0315 smmd=0.9768 ct=9.2563 rec=1.2147 | train/val/test=0.966/0.626/0.623 | c=0.998896
[Epoch 0015] loss=13.4893 cls=0.7302 smmd=1.0929 ct=9.2267 rec=1.2197 | train/val/test=0.966/0.626/0.623 | c=0.998896
[Epoch 0016] loss=14.2305 cls=1.3421 smmd=1.2461 ct=9.2021 rec=1.2201 | train/val/test=0.966/0.634/0.648 | c=0.998896
[Epoch 0017] loss=13.8899 cls=0.8865 smmd=1.3894 ct=9.1873 rec=1.2133 | train/val/test=1.000/0.656/0.669 | c=0.998896
[Epoch 0018] loss=13.6736 cls=0.5908 smmd=1.4815 ct=9.1844 rec=1.2085 | train/val/test=1.000/0.666/0.653 | c=0.998896
[Epoch 0019] loss=13.8495 cls=0.7021 smmd=1.5186 ct=9.2102 rec=1.2093 | train/val/test=1.000/0.676/0.646 | c=0.998896
[Epoch 0020] loss=14.2313 cls=1.0998 smmd=1.4827 ct=9.2335 rec=1.2076 | train/val/test=1.000/0.672/0.652 | c=0.998896
[Epoch 0021] loss=14.1461 cls=1.0936 smmd=1.3934 ct=9.2508 rec=1.2042 | train/val/test=1.000/0.690/0.671 | c=0.998896
[Epoch 0022] loss=13.9114 cls=0.9799 smmd=1.2637 ct=9.2615 rec=1.2031 | train/val/test=1.000/0.698/0.682 | c=0.998896
[Epoch 0023] loss=14.5531 cls=1.7252 smmd=1.1194 ct=9.2771 rec=1.2157 | train/val/test=1.000/0.670/0.673 | c=0.998896
[Epoch 0024] loss=13.8223 cls=1.1651 smmd=0.9928 ct=9.2499 rec=1.2072 | train/val/test=1.000/0.652/0.661 | c=0.998896
[Epoch 0025] loss=13.3704 cls=0.8010 smmd=0.8922 ct=9.2491 rec=1.2140 | train/val/test=1.000/0.662/0.662 | c=0.998896
[Epoch 0026] loss=14.3355 cls=1.8403 smmd=0.8210 ct=9.2417 rec=1.2163 | train/val/test=1.000/0.674/0.672 | c=0.998896
[Epoch 0027] loss=13.3528 cls=0.9015 smmd=0.7730 ct=9.2492 rec=1.2146 | train/val/test=1.000/0.678/0.685 | c=0.998896
[Epoch 0028] loss=13.5505 cls=1.1131 smmd=0.7375 ct=9.2639 rec=1.2180 | train/val/test=1.000/0.670/0.674 | c=0.998896
[Epoch 0029] loss=13.2507 cls=0.8437 smmd=0.7044 ct=9.2817 rec=1.2105 | train/val/test=1.000/0.654/0.656 | c=0.998896
[Epoch 0030] loss=13.4200 cls=1.0357 smmd=0.6684 ct=9.2868 rec=1.2145 | train/val/test=1.000/0.660/0.634 | c=0.998896
[Epoch 0031] loss=13.0935 cls=0.7258 smmd=0.6352 ct=9.3014 rec=1.2155 | train/val/test=1.000/0.648/0.638 | c=0.998896
[Epoch 0032] loss=13.6080 cls=1.2621 smmd=0.6010 ct=9.2993 rec=1.2228 | train/val/test=1.000/0.648/0.648 | c=0.998896
[Epoch 0033] loss=13.7454 cls=1.4472 smmd=0.5661 ct=9.2870 rec=1.2225 | train/val/test=0.966/0.656/0.668 | c=0.998896
[Epoch 0034] loss=13.1164 cls=0.8495 smmd=0.5394 ct=9.2801 rec=1.2237 | train/val/test=0.966/0.662/0.681 | c=0.998896
[Epoch 0035] loss=13.1160 cls=0.8939 smmd=0.5079 ct=9.2681 rec=1.2230 | train/val/test=0.966/0.664/0.685 | c=0.998896
[Epoch 0036] loss=13.0687 cls=0.9052 smmd=0.4644 ct=9.2588 rec=1.2201 | train/val/test=0.966/0.660/0.675 | c=0.998896
[Epoch 0037] loss=12.6556 cls=0.5523 smmd=0.4291 ct=9.2509 rec=1.2117 | train/val/test=0.966/0.648/0.656 | c=0.998896
[Epoch 0038] loss=13.3629 cls=1.2611 smmd=0.3982 ct=9.2615 rec=1.2211 | train/val/test=0.966/0.652/0.647 | c=0.998896
[Epoch 0039] loss=12.9813 cls=0.9292 smmd=0.3726 ct=9.2638 rec=1.2078 | train/val/test=0.966/0.648/0.648 | c=0.998896
[Epoch 0040] loss=12.8049 cls=0.7798 smmd=0.3363 ct=9.2728 rec=1.2081 | train/val/test=0.966/0.656/0.659 | c=0.998896
[Epoch 0041] loss=12.7737 cls=0.8038 smmd=0.3043 ct=9.2650 rec=1.2003 | train/val/test=0.966/0.652/0.674 | c=0.998896
[Epoch 0042] loss=13.0619 cls=1.1019 smmd=0.2821 ct=9.2694 rec=1.2042 | train/val/test=0.966/0.664/0.683 | c=0.998896
[Epoch 0043] loss=12.8324 cls=0.8877 smmd=0.2678 ct=9.2727 rec=1.2021 | train/val/test=0.966/0.656/0.678 | c=0.998896
[Epoch 0044] loss=13.2425 cls=1.3260 smmd=0.2496 ct=9.2618 rec=1.2026 | train/val/test=0.966/0.650/0.663 | c=0.998896
[Epoch 0045] loss=12.8619 cls=0.9858 smmd=0.2333 ct=9.2514 rec=1.1957 | train/val/test=0.966/0.652/0.657 | c=0.998896
[Epoch 0046] loss=12.7384 cls=0.8860 smmd=0.2236 ct=9.2437 rec=1.1925 | train/val/test=0.966/0.642/0.651 | c=0.998896
[Epoch 0047] loss=13.0747 cls=1.2311 smmd=0.2155 ct=9.2416 rec=1.1933 | train/val/test=0.966/0.652/0.662 | c=0.998896
[Epoch 0048] loss=12.7247 cls=0.8857 smmd=0.2010 ct=9.2463 rec=1.1958 | train/val/test=0.966/0.652/0.665 | c=0.998896
[Epoch 0049] loss=13.4240 cls=1.5901 smmd=0.1857 ct=9.2489 rec=1.1996 | train/val/test=0.966/0.650/0.675 | c=0.998896
[Epoch 0050] loss=12.6216 cls=0.8050 smmd=0.1750 ct=9.2608 rec=1.1904 | train/val/test=0.966/0.642/0.664 | c=0.998896
[Epoch 0051] loss=12.4867 cls=0.6549 smmd=0.1700 ct=9.2698 rec=1.1960 | train/val/test=0.966/0.642/0.653 | c=0.998896
[Epoch 0052] loss=12.8631 cls=1.0517 smmd=0.1703 ct=9.2583 rec=1.1914 | train/val/test=0.966/0.640/0.644 | c=0.998896
[Epoch 0053] loss=12.7353 cls=0.9513 smmd=0.1639 ct=9.2398 rec=1.1901 | train/val/test=0.966/0.640/0.647 | c=0.998896
[Epoch 0054] loss=12.9267 cls=1.1491 smmd=0.1641 ct=9.2257 rec=1.1939 | train/val/test=1.000/0.650/0.657 | c=0.998896
[Epoch 0055] loss=13.3142 cls=1.5101 smmd=0.1611 ct=9.2337 rec=1.2047 | train/val/test=1.000/0.652/0.654 | c=0.998896
[Epoch 0056] loss=12.7002 cls=0.9086 smmd=0.1525 ct=9.2372 rec=1.2010 | train/val/test=1.000/0.650/0.649 | c=0.998896
[Epoch 0057] loss=12.2271 cls=0.4687 smmd=0.1408 ct=9.2347 rec=1.1914 | train/val/test=1.000/0.648/0.657 | c=0.998896
[Epoch 0058] loss=13.0256 cls=1.2584 smmd=0.1361 ct=9.2352 rec=1.1980 | train/val/test=1.000/0.652/0.661 | c=0.998896
[Epoch 0059] loss=12.8462 cls=1.0697 smmd=0.1384 ct=9.2351 rec=1.2015 | train/val/test=1.000/0.650/0.662 | c=0.998896
[Epoch 0060] loss=13.1170 cls=1.3529 smmd=0.1428 ct=9.2221 rec=1.1996 | train/val/test=1.000/0.652/0.656 | c=0.998896
[Epoch 0061] loss=12.4230 cls=0.6711 smmd=0.1402 ct=9.2185 rec=1.1966 | train/val/test=1.000/0.648/0.653 | c=0.998896
[Epoch 0062] loss=12.6226 cls=0.8586 smmd=0.1436 ct=9.2149 rec=1.2027 | train/val/test=1.000/0.644/0.653 | c=0.998896
[Epoch 0063] loss=12.5435 cls=0.7831 smmd=0.1413 ct=9.2156 rec=1.2017 | train/val/test=1.000/0.636/0.639 | c=0.998896
[Epoch 0064] loss=12.8022 cls=1.0440 smmd=0.1386 ct=9.2164 rec=1.2016 | train/val/test=1.000/0.640/0.636 | c=0.998896
[Epoch 0065] loss=12.8368 cls=1.0770 smmd=0.1327 ct=9.2306 rec=1.1983 | train/val/test=1.000/0.646/0.641 | c=0.998896
[Epoch 0066] loss=12.7324 cls=0.9846 smmd=0.1257 ct=9.2291 rec=1.1965 | train/val/test=1.000/0.652/0.666 | c=0.998896
[Epoch 0067] loss=12.8262 cls=1.0729 smmd=0.1247 ct=9.2300 rec=1.1993 | train/val/test=1.000/0.666/0.674 | c=0.998896
[Epoch 0068] loss=12.7349 cls=0.9766 smmd=0.1281 ct=9.2331 rec=1.1986 | train/val/test=1.000/0.672/0.672 | c=0.998896
[Epoch 0069] loss=12.3364 cls=0.5734 smmd=0.1382 ct=9.2248 rec=1.2000 | train/val/test=1.000/0.668/0.664 | c=0.998896
[Epoch 0070] loss=13.0144 cls=1.2519 smmd=0.1419 ct=9.2172 rec=1.2017 | train/val/test=1.000/0.660/0.660 | c=0.998896
[Epoch 0071] loss=12.4581 cls=0.7093 smmd=0.1355 ct=9.2122 rec=1.2005 | train/val/test=1.000/0.646/0.655 | c=0.998896
[Epoch 0072] loss=12.5581 cls=0.8211 smmd=0.1284 ct=9.2098 rec=1.1994 | train/val/test=1.000/0.646/0.648 | c=0.998896
[Epoch 0073] loss=12.5309 cls=0.7947 smmd=0.1245 ct=9.2183 rec=1.1967 | train/val/test=1.000/0.644/0.646 | c=0.998896
[Epoch 0074] loss=13.0291 cls=1.2696 smmd=0.1218 ct=9.2403 rec=1.1987 | train/val/test=1.000/0.648/0.650 | c=0.998896
[Epoch 0075] loss=12.6333 cls=0.8625 smmd=0.1191 ct=9.2566 rec=1.1976 | train/val/test=1.000/0.648/0.659 | c=0.998896
[Epoch 0076] loss=12.6594 cls=0.9069 smmd=0.1149 ct=9.2456 rec=1.1960 | train/val/test=1.000/0.652/0.663 | c=0.998896
[Epoch 0077] loss=12.8806 cls=1.1407 smmd=0.1145 ct=9.2379 rec=1.1938 | train/val/test=1.000/0.656/0.672 | c=0.998896
[Epoch 0078] loss=13.1235 cls=1.3694 smmd=0.1189 ct=9.2319 rec=1.2016 | train/val/test=1.000/0.656/0.671 | c=0.998896
[Epoch 0079] loss=12.4740 cls=0.7220 smmd=0.1228 ct=9.2247 rec=1.2023 | train/val/test=1.000/0.656/0.677 | c=0.998896
[Epoch 0080] loss=12.5449 cls=0.7945 smmd=0.1258 ct=9.2204 rec=1.2021 | train/val/test=1.000/0.656/0.674 | c=0.998896
[Epoch 0081] loss=12.8242 cls=1.0762 smmd=0.1290 ct=9.2143 rec=1.2023 | train/val/test=1.000/0.658/0.671 | c=0.998896
[Epoch 0082] loss=12.5510 cls=0.8140 smmd=0.1303 ct=9.2103 rec=1.1982 | train/val/test=1.000/0.650/0.664 | c=0.998896
[Epoch 0083] loss=12.5208 cls=0.7850 smmd=0.1291 ct=9.2114 rec=1.1976 | train/val/test=1.000/0.646/0.657 | c=0.998896
[Epoch 0084] loss=12.6762 cls=0.9499 smmd=0.1295 ct=9.2075 rec=1.1946 | train/val/test=1.000/0.648/0.653 | c=0.998896
[Epoch 0085] loss=12.5129 cls=0.7658 smmd=0.1305 ct=9.2184 rec=1.1991 | train/val/test=1.000/0.650/0.653 | c=0.998896
[Epoch 0086] loss=12.7830 cls=1.0512 smmd=0.1284 ct=9.2154 rec=1.1940 | train/val/test=1.000/0.652/0.653 | c=0.998896
[Epoch 0087] loss=12.5888 cls=0.8491 smmd=0.1279 ct=9.2219 rec=1.1950 | train/val/test=1.000/0.650/0.652 | c=0.998896
[Epoch 0088] loss=12.6109 cls=0.8748 smmd=0.1271 ct=9.2187 rec=1.1952 | train/val/test=1.000/0.652/0.655 | c=0.998896
[Epoch 0089] loss=12.9508 cls=1.2180 smmd=0.1258 ct=9.2154 rec=1.1959 | train/val/test=1.000/0.650/0.660 | c=0.998896
[Epoch 0090] loss=12.8858 cls=1.1616 smmd=0.1225 ct=9.2192 rec=1.1912 | train/val/test=1.000/0.650/0.661 | c=0.998896
[Epoch 0091] loss=12.6583 cls=0.9416 smmd=0.1214 ct=9.2175 rec=1.1889 | train/val/test=1.000/0.650/0.660 | c=0.998896
[Epoch 0092] loss=12.6162 cls=0.8938 smmd=0.1197 ct=9.2170 rec=1.1929 | train/val/test=1.000/0.654/0.661 | c=0.998896
[Epoch 0093] loss=12.4090 cls=0.6963 smmd=0.1183 ct=9.2161 rec=1.1892 | train/val/test=1.000/0.656/0.661 | c=0.998896
[Epoch 0094] loss=12.3742 cls=0.6519 smmd=0.1201 ct=9.2154 rec=1.1934 | train/val/test=1.000/0.656/0.663 | c=0.998896
[Epoch 0095] loss=12.5203 cls=0.7831 smmd=0.1188 ct=9.2177 rec=1.2003 | train/val/test=1.000/0.656/0.666 | c=0.998896
[Epoch 0096] loss=12.8221 cls=1.0885 smmd=0.1177 ct=9.2208 rec=1.1976 | train/val/test=1.000/0.656/0.666 | c=0.998896
[Epoch 0097] loss=12.7316 cls=1.0022 smmd=0.1180 ct=9.2127 rec=1.1994 | train/val/test=1.000/0.656/0.666 | c=0.998896
[Epoch 0098] loss=12.8811 cls=1.1588 smmd=0.1185 ct=9.2179 rec=1.1930 | train/val/test=1.000/0.656/0.666 | c=0.998896
[Epoch 0099] loss=12.8909 cls=1.1650 smmd=0.1184 ct=9.2252 rec=1.1911 | train/val/test=1.000/0.656/0.666 | c=0.998896
=== Best @ epoch 22: val=0.6980, test=0.6820 ===
