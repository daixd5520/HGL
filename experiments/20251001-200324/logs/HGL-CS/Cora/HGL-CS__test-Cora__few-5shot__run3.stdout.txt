Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> CiteSeer
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.8168 cls=2.1108 smmd=4.6476 ct=9.2777 rec=1.3904 | train/val/test=0.241/0.074/0.097 | c=0.998896
[Epoch 0001] loss=18.4920 cls=1.8315 smmd=4.6000 ct=9.2760 rec=1.3923 | train/val/test=0.172/0.168/0.151 | c=0.998896
[Epoch 0002] loss=18.3644 cls=1.8070 smmd=4.5037 ct=9.2657 rec=1.3940 | train/val/test=0.655/0.418/0.394 | c=0.998896
[Epoch 0003] loss=18.0354 cls=1.6441 smmd=4.3781 ct=9.2386 rec=1.3873 | train/val/test=0.724/0.256/0.278 | c=0.998896
[Epoch 0004] loss=17.5828 cls=1.4318 smmd=4.2093 ct=9.1807 rec=1.3805 | train/val/test=0.862/0.442/0.468 | c=0.998896
[Epoch 0005] loss=17.2577 cls=1.4798 smmd=4.0010 ct=9.0823 rec=1.3473 | train/val/test=0.931/0.592/0.573 | c=0.998896
[Epoch 0006] loss=16.4881 cls=1.0330 smmd=3.7562 ct=9.0380 rec=1.3305 | train/val/test=0.966/0.554/0.565 | c=0.998896
[Epoch 0007] loss=16.1901 cls=1.1467 smmd=3.4531 ct=8.9760 rec=1.3072 | train/val/test=1.000/0.552/0.579 | c=0.998896
[Epoch 0008] loss=15.2253 cls=0.7485 smmd=3.0878 ct=8.8702 rec=1.2594 | train/val/test=0.966/0.550/0.570 | c=0.998896
[Epoch 0009] loss=14.8408 cls=0.8106 smmd=2.6702 ct=8.8603 rec=1.2499 | train/val/test=0.966/0.624/0.631 | c=0.998896
[Epoch 0010] loss=14.3228 cls=0.8598 smmd=2.1969 ct=8.8246 rec=1.2208 | train/val/test=0.966/0.638/0.653 | c=0.998896
[Epoch 0011] loss=14.9287 cls=1.2734 smmd=1.6882 ct=9.5358 rec=1.2156 | train/val/test=0.966/0.608/0.626 | c=0.998896
[Epoch 0012] loss=14.0830 cls=0.9408 smmd=1.2379 ct=9.4601 rec=1.2221 | train/val/test=0.966/0.658/0.670 | c=0.998896
[Epoch 0013] loss=13.4349 cls=0.7781 smmd=0.9334 ct=9.3082 rec=1.2076 | train/val/test=0.966/0.648/0.668 | c=0.998896
[Epoch 0014] loss=13.3820 cls=0.8814 smmd=0.8659 ct=9.2191 rec=1.2078 | train/val/test=0.966/0.624/0.655 | c=0.998896
[Epoch 0015] loss=13.5724 cls=0.9317 smmd=1.0135 ct=9.1935 rec=1.2169 | train/val/test=0.966/0.660/0.662 | c=0.998896
[Epoch 0016] loss=13.7462 cls=0.9303 smmd=1.2324 ct=9.1643 rec=1.2096 | train/val/test=0.966/0.658/0.683 | c=0.998896
[Epoch 0017] loss=14.4546 cls=1.4941 smmd=1.4340 ct=9.1255 rec=1.2005 | train/val/test=1.000/0.620/0.656 | c=0.998896
[Epoch 0018] loss=13.9943 cls=0.8119 smmd=1.5945 ct=9.1533 rec=1.2173 | train/val/test=1.000/0.614/0.658 | c=0.998896
[Epoch 0019] loss=14.1434 cls=0.8772 smmd=1.6592 ct=9.1752 rec=1.2158 | train/val/test=1.000/0.624/0.660 | c=0.998896
[Epoch 0020] loss=13.9444 cls=0.7346 smmd=1.6252 ct=9.1677 rec=1.2084 | train/val/test=0.966/0.634/0.668 | c=0.998896
[Epoch 0021] loss=14.2471 cls=1.1297 smmd=1.5223 ct=9.1780 rec=1.2086 | train/val/test=0.966/0.664/0.674 | c=0.998896
[Epoch 0022] loss=13.6032 cls=0.6358 smmd=1.3762 ct=9.1909 rec=1.2001 | train/val/test=0.966/0.658/0.693 | c=0.998896
[Epoch 0023] loss=13.8812 cls=1.0465 smmd=1.2026 ct=9.2250 rec=1.2036 | train/val/test=0.966/0.660/0.697 | c=0.998896
[Epoch 0024] loss=13.4722 cls=0.7902 smmd=1.0322 ct=9.2478 rec=1.2010 | train/val/test=0.966/0.656/0.703 | c=0.998896
[Epoch 0025] loss=13.9542 cls=1.3850 smmd=0.8829 ct=9.2776 rec=1.2043 | train/val/test=0.966/0.666/0.699 | c=0.998896
[Epoch 0026] loss=13.2380 cls=0.7696 smmd=0.7801 ct=9.2969 rec=1.1957 | train/val/test=0.966/0.658/0.690 | c=0.998896
[Epoch 0027] loss=13.6056 cls=1.1521 smmd=0.7315 ct=9.3267 rec=1.1977 | train/val/test=0.966/0.670/0.701 | c=0.998896
[Epoch 0028] loss=13.6092 cls=1.1574 smmd=0.7102 ct=9.3397 rec=1.2010 | train/val/test=0.966/0.674/0.699 | c=0.998896
[Epoch 0029] loss=13.2351 cls=0.7996 smmd=0.7076 ct=9.3370 rec=1.1955 | train/val/test=0.966/0.672/0.692 | c=0.998896
[Epoch 0030] loss=13.1956 cls=0.7569 smmd=0.7098 ct=9.3341 rec=1.1974 | train/val/test=0.966/0.678/0.694 | c=0.998896
[Epoch 0031] loss=13.2645 cls=0.8481 smmd=0.6983 ct=9.3170 rec=1.2006 | train/val/test=0.966/0.682/0.703 | c=0.998896
[Epoch 0032] loss=13.4399 cls=1.0840 smmd=0.6676 ct=9.2965 rec=1.1959 | train/val/test=0.966/0.694/0.707 | c=0.998896
[Epoch 0033] loss=12.9707 cls=0.6720 smmd=0.6232 ct=9.2816 rec=1.1970 | train/val/test=1.000/0.700/0.708 | c=0.998896
[Epoch 0034] loss=13.2894 cls=1.0428 smmd=0.5693 ct=9.2785 rec=1.1994 | train/val/test=1.000/0.700/0.712 | c=0.998896
[Epoch 0035] loss=12.9888 cls=0.7953 smmd=0.5212 ct=9.2769 rec=1.1977 | train/val/test=1.000/0.690/0.714 | c=0.998896
[Epoch 0036] loss=12.9083 cls=0.7585 smmd=0.4759 ct=9.2802 rec=1.1968 | train/val/test=1.000/0.690/0.711 | c=0.998896
[Epoch 0037] loss=12.7434 cls=0.6171 smmd=0.4346 ct=9.2974 rec=1.1972 | train/val/test=1.000/0.690/0.708 | c=0.998896
[Epoch 0038] loss=13.0147 cls=0.9365 smmd=0.4095 ct=9.2812 rec=1.1938 | train/val/test=1.000/0.690/0.703 | c=0.998896
[Epoch 0039] loss=12.9087 cls=0.8419 smmd=0.3937 ct=9.2840 rec=1.1946 | train/val/test=1.000/0.698/0.705 | c=0.998896
[Epoch 0040] loss=13.0643 cls=1.0094 smmd=0.3752 ct=9.2833 rec=1.1982 | train/val/test=1.000/0.698/0.708 | c=0.998896
[Epoch 0041] loss=13.1839 cls=1.1605 smmd=0.3592 ct=9.2805 rec=1.1919 | train/val/test=1.000/0.694/0.706 | c=0.998896
[Epoch 0042] loss=13.3843 cls=1.3714 smmd=0.3366 ct=9.2887 rec=1.1938 | train/val/test=1.000/0.694/0.707 | c=0.998896
[Epoch 0043] loss=13.1557 cls=1.1951 smmd=0.2980 ct=9.2757 rec=1.1934 | train/val/test=1.000/0.686/0.710 | c=0.998896
[Epoch 0044] loss=13.2171 cls=1.2675 smmd=0.2669 ct=9.2819 rec=1.2004 | train/val/test=1.000/0.676/0.702 | c=0.998896
[Epoch 0045] loss=12.9020 cls=0.9829 smmd=0.2407 ct=9.2936 rec=1.1924 | train/val/test=1.000/0.680/0.688 | c=0.998896
[Epoch 0046] loss=13.3064 cls=1.3649 smmd=0.2232 ct=9.3000 rec=1.2091 | train/val/test=1.000/0.676/0.693 | c=0.998896
[Epoch 0047] loss=13.1250 cls=1.2254 smmd=0.2130 ct=9.2903 rec=1.1982 | train/val/test=1.000/0.684/0.704 | c=0.998896
[Epoch 0048] loss=12.8560 cls=0.9708 smmd=0.2168 ct=9.2731 rec=1.1976 | train/val/test=1.000/0.682/0.710 | c=0.998896
[Epoch 0049] loss=13.2001 cls=1.2945 smmd=0.2254 ct=9.2647 rec=1.2077 | train/val/test=1.000/0.686/0.706 | c=0.998896
[Epoch 0050] loss=12.9795 cls=1.0874 smmd=0.2160 ct=9.2593 rec=1.2084 | train/val/test=1.000/0.678/0.706 | c=0.998896
[Epoch 0051] loss=12.7615 cls=0.8864 smmd=0.2037 ct=9.2512 rec=1.2101 | train/val/test=1.000/0.678/0.695 | c=0.998896
[Epoch 0052] loss=12.5842 cls=0.7408 smmd=0.1809 ct=9.2514 rec=1.2056 | train/val/test=1.000/0.674/0.695 | c=0.998896
[Epoch 0053] loss=12.5091 cls=0.6749 smmd=0.1631 ct=9.2642 rec=1.2035 | train/val/test=1.000/0.662/0.688 | c=0.998896
[Epoch 0054] loss=13.2157 cls=1.3554 smmd=0.1530 ct=9.2828 rec=1.2122 | train/val/test=1.000/0.664/0.695 | c=0.998896
[Epoch 0055] loss=12.8657 cls=1.0054 smmd=0.1505 ct=9.2822 rec=1.2138 | train/val/test=1.000/0.674/0.699 | c=0.998896
[Epoch 0056] loss=12.5197 cls=0.6779 smmd=0.1587 ct=9.2603 rec=1.2114 | train/val/test=1.000/0.678/0.704 | c=0.998896
[Epoch 0057] loss=12.6414 cls=0.8015 smmd=0.1730 ct=9.2500 rec=1.2085 | train/val/test=1.000/0.680/0.708 | c=0.998896
[Epoch 0058] loss=13.0041 cls=1.1419 smmd=0.1753 ct=9.2514 rec=1.2178 | train/val/test=1.000/0.678/0.702 | c=0.998896
[Epoch 0059] loss=12.5406 cls=0.7192 smmd=0.1595 ct=9.2464 rec=1.2077 | train/val/test=1.000/0.662/0.691 | c=0.998896
[Epoch 0060] loss=13.0035 cls=1.1758 smmd=0.1467 ct=9.2594 rec=1.2108 | train/val/test=1.000/0.660/0.682 | c=0.998896
[Epoch 0061] loss=12.5671 cls=0.7672 smmd=0.1400 ct=9.2569 rec=1.2015 | train/val/test=1.000/0.660/0.686 | c=0.998896
[Epoch 0062] loss=12.9774 cls=1.1865 smmd=0.1307 ct=9.2538 rec=1.2032 | train/val/test=1.000/0.666/0.696 | c=0.998896
[Epoch 0063] loss=12.6816 cls=0.8984 smmd=0.1317 ct=9.2470 rec=1.2023 | train/val/test=1.000/0.664/0.691 | c=0.998896
[Epoch 0064] loss=12.3386 cls=0.5640 smmd=0.1345 ct=9.2451 rec=1.1975 | train/val/test=1.000/0.666/0.701 | c=0.998896
[Epoch 0065] loss=12.8183 cls=1.0372 smmd=0.1402 ct=9.2407 rec=1.2001 | train/val/test=1.000/0.670/0.699 | c=0.998896
[Epoch 0066] loss=12.7537 cls=0.9848 smmd=0.1441 ct=9.2310 rec=1.1969 | train/val/test=1.000/0.678/0.701 | c=0.998896
[Epoch 0067] loss=12.6166 cls=0.8402 smmd=0.1426 ct=9.2364 rec=1.1987 | train/val/test=1.000/0.668/0.699 | c=0.998896
[Epoch 0068] loss=13.2307 cls=1.4642 smmd=0.1411 ct=9.2307 rec=1.1974 | train/val/test=1.000/0.668/0.695 | c=0.998896
[Epoch 0069] loss=12.8542 cls=1.0847 smmd=0.1361 ct=9.2484 rec=1.1924 | train/val/test=1.000/0.674/0.691 | c=0.998896
[Epoch 0070] loss=12.8822 cls=1.0961 smmd=0.1313 ct=9.2524 rec=1.2012 | train/val/test=1.000/0.674/0.695 | c=0.998896
[Epoch 0071] loss=12.8849 cls=1.1249 smmd=0.1250 ct=9.2423 rec=1.1964 | train/val/test=1.000/0.680/0.700 | c=0.998896
[Epoch 0072] loss=12.6822 cls=0.9381 smmd=0.1236 ct=9.2428 rec=1.1889 | train/val/test=1.000/0.680/0.703 | c=0.998896
[Epoch 0073] loss=12.6090 cls=0.8425 smmd=0.1266 ct=9.2478 rec=1.1960 | train/val/test=1.000/0.684/0.702 | c=0.998896
[Epoch 0074] loss=12.4835 cls=0.7255 smmd=0.1329 ct=9.2365 rec=1.1943 | train/val/test=1.000/0.676/0.700 | c=0.998896
[Epoch 0075] loss=12.6893 cls=0.9356 smmd=0.1332 ct=9.2315 rec=1.1945 | train/val/test=1.000/0.678/0.705 | c=0.998896
[Epoch 0076] loss=12.8712 cls=1.1193 smmd=0.1332 ct=9.2270 rec=1.1958 | train/val/test=1.000/0.682/0.705 | c=0.998896
[Epoch 0077] loss=12.7088 cls=0.9693 smmd=0.1325 ct=9.2246 rec=1.1912 | train/val/test=1.000/0.682/0.706 | c=0.998896
[Epoch 0078] loss=12.8676 cls=1.1121 smmd=0.1334 ct=9.2309 rec=1.1956 | train/val/test=1.000/0.682/0.704 | c=0.998896
[Epoch 0079] loss=12.7201 cls=0.9683 smmd=0.1324 ct=9.2306 rec=1.1944 | train/val/test=1.000/0.684/0.706 | c=0.998896
[Epoch 0080] loss=12.7104 cls=0.9632 smmd=0.1309 ct=9.2329 rec=1.1917 | train/val/test=1.000/0.686/0.708 | c=0.998896
[Epoch 0081] loss=13.0257 cls=1.2459 smmd=0.1285 ct=9.2453 rec=1.2030 | train/val/test=1.000/0.684/0.704 | c=0.998896
[Epoch 0082] loss=12.5706 cls=0.8367 smmd=0.1275 ct=9.2290 rec=1.1887 | train/val/test=1.000/0.678/0.701 | c=0.998896
[Epoch 0083] loss=12.9868 cls=1.2395 smmd=0.1262 ct=9.2291 rec=1.1960 | train/val/test=1.000/0.672/0.696 | c=0.998896
[Epoch 0084] loss=12.8113 cls=1.0364 smmd=0.1260 ct=9.2451 rec=1.2019 | train/val/test=1.000/0.670/0.696 | c=0.998896
[Epoch 0085] loss=12.8584 cls=1.1015 smmd=0.1263 ct=9.2374 rec=1.1966 | train/val/test=1.000/0.670/0.699 | c=0.998896
[Epoch 0086] loss=12.5456 cls=0.8063 smmd=0.1261 ct=9.2359 rec=1.1886 | train/val/test=1.000/0.674/0.701 | c=0.998896
[Epoch 0087] loss=12.8497 cls=1.0988 smmd=0.1257 ct=9.2369 rec=1.1941 | train/val/test=1.000/0.678/0.706 | c=0.998896
[Epoch 0088] loss=12.9571 cls=1.2114 smmd=0.1257 ct=9.2338 rec=1.1931 | train/val/test=1.000/0.680/0.705 | c=0.998896
[Epoch 0089] loss=12.5707 cls=0.8214 smmd=0.1247 ct=9.2403 rec=1.1922 | train/val/test=1.000/0.682/0.706 | c=0.998896
[Epoch 0090] loss=12.8717 cls=1.1376 smmd=0.1250 ct=9.2280 rec=1.1906 | train/val/test=1.000/0.684/0.708 | c=0.998896
[Epoch 0091] loss=12.4563 cls=0.7264 smmd=0.1262 ct=9.2316 rec=1.1860 | train/val/test=1.000/0.684/0.708 | c=0.998896
[Epoch 0092] loss=12.5935 cls=0.8532 smmd=0.1262 ct=9.2338 rec=1.1902 | train/val/test=1.000/0.684/0.710 | c=0.998896
[Epoch 0093] loss=12.7396 cls=0.9837 smmd=0.1265 ct=9.2325 rec=1.1984 | train/val/test=1.000/0.684/0.710 | c=0.998896
[Epoch 0094] loss=12.9619 cls=1.2268 smmd=0.1274 ct=9.2255 rec=1.1911 | train/val/test=1.000/0.684/0.710 | c=0.998896
[Epoch 0095] loss=12.7299 cls=0.9512 smmd=0.1255 ct=9.2428 rec=1.2052 | train/val/test=1.000/0.684/0.710 | c=0.998896
[Epoch 0096] loss=12.6266 cls=0.8925 smmd=0.1266 ct=9.2283 rec=1.1896 | train/val/test=1.000/0.684/0.710 | c=0.998896
[Epoch 0097] loss=12.6675 cls=0.9341 smmd=0.1262 ct=9.2283 rec=1.1894 | train/val/test=1.000/0.684/0.709 | c=0.998896
[Epoch 0098] loss=13.0727 cls=1.3188 smmd=0.1261 ct=9.2336 rec=1.1971 | train/val/test=1.000/0.684/0.709 | c=0.998896
[Epoch 0099] loss=13.1920 cls=1.4281 smmd=0.1265 ct=9.2450 rec=1.1963 | train/val/test=1.000/0.684/0.709 | c=0.998896
=== Best @ epoch 33: val=0.7000, test=0.7080 ===
