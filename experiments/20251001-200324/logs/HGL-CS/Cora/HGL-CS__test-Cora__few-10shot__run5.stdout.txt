Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> CiteSeer
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=19.0891 cls=2.3670 smmd=4.6815 ct=9.2556 rec=1.3926 | train/val/test=0.138/0.156/0.148 | c=0.998896
[Epoch 0001] loss=18.5834 cls=1.9032 smmd=4.6444 ct=9.2533 rec=1.3913 | train/val/test=0.207/0.078/0.105 | c=0.998896
[Epoch 0002] loss=18.4699 cls=1.8720 smmd=4.5591 ct=9.2482 rec=1.3953 | train/val/test=0.517/0.276/0.267 | c=0.998896
[Epoch 0003] loss=18.1387 cls=1.6887 smmd=4.4448 ct=9.2301 rec=1.3876 | train/val/test=0.586/0.292/0.277 | c=0.998896
[Epoch 0004] loss=17.7837 cls=1.5570 smmd=4.2840 ct=9.1849 rec=1.3789 | train/val/test=0.655/0.430/0.437 | c=0.998896
[Epoch 0005] loss=17.4726 cls=1.5674 smmd=4.0819 ct=9.1058 rec=1.3588 | train/val/test=0.879/0.626/0.629 | c=0.998896
[Epoch 0006] loss=16.6971 cls=1.1953 smmd=3.8294 ct=9.0131 rec=1.3296 | train/val/test=0.966/0.582/0.591 | c=0.998896
[Epoch 0007] loss=16.1368 cls=1.1233 smmd=3.5100 ct=8.9276 rec=1.2879 | train/val/test=0.897/0.612/0.623 | c=0.998896
[Epoch 0008] loss=15.4196 cls=0.9347 smmd=3.1194 ct=8.8537 rec=1.2559 | train/val/test=0.931/0.674/0.658 | c=0.998896
[Epoch 0009] loss=14.9426 cls=1.0950 smmd=2.6521 ct=8.7633 rec=1.2161 | train/val/test=0.948/0.642/0.634 | c=0.998896
[Epoch 0010] loss=14.5748 cls=1.2672 smmd=2.1135 ct=8.7617 rec=1.2163 | train/val/test=0.931/0.684/0.694 | c=0.998896
[Epoch 0011] loss=13.8486 cls=1.1320 smmd=1.5430 ct=8.7692 rec=1.2022 | train/val/test=0.948/0.700/0.695 | c=0.998896
[Epoch 0012] loss=13.4818 cls=1.2249 smmd=1.0445 ct=8.7983 rec=1.2071 | train/val/test=0.948/0.708/0.706 | c=0.998896
[Epoch 0013] loss=13.0147 cls=1.0737 smmd=0.7873 ct=8.7616 rec=1.1960 | train/val/test=0.966/0.696/0.671 | c=0.998896
[Epoch 0014] loss=13.3390 cls=1.3823 smmd=0.8483 ct=8.7265 rec=1.1909 | train/val/test=0.948/0.684/0.648 | c=0.998896
[Epoch 0015] loss=13.2768 cls=1.0651 smmd=1.1061 ct=8.7234 rec=1.1911 | train/val/test=0.966/0.690/0.687 | c=0.998896
[Epoch 0016] loss=14.2540 cls=1.0338 smmd=1.3621 ct=9.4643 rec=1.1969 | train/val/test=0.966/0.706/0.712 | c=0.998896
[Epoch 0017] loss=14.1016 cls=0.7856 smmd=1.5216 ct=9.4041 rec=1.1951 | train/val/test=0.948/0.718/0.697 | c=0.998896
[Epoch 0018] loss=14.6162 cls=1.2729 smmd=1.5958 ct=9.3308 rec=1.2083 | train/val/test=0.948/0.698/0.673 | c=0.998896
[Epoch 0019] loss=14.5001 cls=1.1932 smmd=1.5867 ct=9.2810 rec=1.2196 | train/val/test=0.948/0.702/0.676 | c=0.998896
[Epoch 0020] loss=14.2168 cls=1.0219 smmd=1.5064 ct=9.2426 rec=1.2229 | train/val/test=0.966/0.726/0.697 | c=0.998896
[Epoch 0021] loss=14.2660 cls=1.2541 smmd=1.3636 ct=9.2155 rec=1.2164 | train/val/test=0.966/0.726/0.703 | c=0.998896
[Epoch 0022] loss=13.9399 cls=1.1082 smmd=1.2012 ct=9.2038 rec=1.2133 | train/val/test=0.966/0.726/0.702 | c=0.998896
[Epoch 0023] loss=13.7528 cls=1.0719 smmd=1.0429 ct=9.2149 rec=1.2116 | train/val/test=0.966/0.710/0.700 | c=0.998896
[Epoch 0024] loss=13.3919 cls=0.8271 smmd=0.9187 ct=9.2347 rec=1.2057 | train/val/test=0.983/0.708/0.692 | c=0.998896
[Epoch 0025] loss=13.6219 cls=1.1015 smmd=0.8451 ct=9.2687 rec=1.2033 | train/val/test=0.983/0.716/0.691 | c=0.998896
[Epoch 0026] loss=13.4172 cls=0.8863 smmd=0.8168 ct=9.3140 rec=1.2000 | train/val/test=0.983/0.720/0.699 | c=0.998896
[Epoch 0027] loss=13.5792 cls=1.0397 smmd=0.7950 ct=9.3438 rec=1.2003 | train/val/test=0.983/0.728/0.716 | c=0.998896
[Epoch 0028] loss=13.5543 cls=1.0499 smmd=0.7605 ct=9.3514 rec=1.1962 | train/val/test=0.983/0.726/0.721 | c=0.998896
[Epoch 0029] loss=13.4721 cls=1.0178 smmd=0.7162 ct=9.3479 rec=1.1952 | train/val/test=0.983/0.718/0.721 | c=0.998896
[Epoch 0030] loss=13.5926 cls=1.1982 smmd=0.6710 ct=9.3259 rec=1.1987 | train/val/test=0.983/0.708/0.708 | c=0.998896
[Epoch 0031] loss=13.2985 cls=0.9759 smmd=0.6276 ct=9.3061 rec=1.1945 | train/val/test=0.983/0.708/0.687 | c=0.998896
[Epoch 0032] loss=13.0220 cls=0.7573 smmd=0.5871 ct=9.2872 rec=1.1952 | train/val/test=0.983/0.716/0.689 | c=0.998896
[Epoch 0033] loss=13.2817 cls=1.0571 smmd=0.5469 ct=9.2758 rec=1.2010 | train/val/test=1.000/0.718/0.687 | c=0.998896
[Epoch 0034] loss=13.8174 cls=1.6446 smmd=0.5146 ct=9.2686 rec=1.1948 | train/val/test=1.000/0.730/0.710 | c=0.998896
[Epoch 0035] loss=13.3049 cls=1.1474 smmd=0.4876 ct=9.2772 rec=1.1964 | train/val/test=1.000/0.734/0.729 | c=0.998896
[Epoch 0036] loss=13.7400 cls=1.5842 smmd=0.4540 ct=9.2952 rec=1.2033 | train/val/test=1.000/0.738/0.724 | c=0.998896
[Epoch 0037] loss=13.4634 cls=1.3617 smmd=0.4148 ct=9.3009 rec=1.1930 | train/val/test=1.000/0.724/0.705 | c=0.998896
[Epoch 0038] loss=13.1045 cls=1.0288 smmd=0.3799 ct=9.2967 rec=1.1996 | train/val/test=1.000/0.722/0.703 | c=0.998896
[Epoch 0039] loss=13.2258 cls=1.1628 smmd=0.3553 ct=9.2895 rec=1.2091 | train/val/test=1.000/0.716/0.702 | c=0.998896
[Epoch 0040] loss=13.1398 cls=1.1055 smmd=0.3319 ct=9.2791 rec=1.2116 | train/val/test=1.000/0.722/0.708 | c=0.998896
[Epoch 0041] loss=12.8384 cls=0.8569 smmd=0.3045 ct=9.2734 rec=1.2019 | train/val/test=1.000/0.720/0.712 | c=0.998896
[Epoch 0042] loss=13.0850 cls=1.1060 smmd=0.2809 ct=9.2800 rec=1.2091 | train/val/test=1.000/0.724/0.712 | c=0.998896
[Epoch 0043] loss=12.8535 cls=0.8976 smmd=0.2609 ct=9.2898 rec=1.2026 | train/val/test=1.000/0.714/0.708 | c=0.998896
[Epoch 0044] loss=13.0030 cls=1.0475 smmd=0.2460 ct=9.2932 rec=1.2082 | train/val/test=1.000/0.710/0.696 | c=0.998896
[Epoch 0045] loss=13.0758 cls=1.1515 smmd=0.2285 ct=9.2819 rec=1.2069 | train/val/test=1.000/0.702/0.694 | c=0.998896
[Epoch 0046] loss=13.0317 cls=1.1102 smmd=0.2180 ct=9.2730 rec=1.2152 | train/val/test=1.000/0.702/0.692 | c=0.998896
[Epoch 0047] loss=13.0823 cls=1.1729 smmd=0.2167 ct=9.2654 rec=1.2136 | train/val/test=1.000/0.714/0.697 | c=0.998896
[Epoch 0048] loss=12.8857 cls=0.9755 smmd=0.2117 ct=9.2732 rec=1.2126 | train/val/test=1.000/0.710/0.695 | c=0.998896
[Epoch 0049] loss=13.2097 cls=1.3010 smmd=0.2022 ct=9.2860 rec=1.2102 | train/val/test=1.000/0.704/0.688 | c=0.998896
[Epoch 0050] loss=12.8506 cls=0.9807 smmd=0.1912 ct=9.2646 rec=1.2071 | train/val/test=1.000/0.708/0.692 | c=0.998896
[Epoch 0051] loss=13.1442 cls=1.2853 smmd=0.1865 ct=9.2654 rec=1.2035 | train/val/test=1.000/0.702/0.701 | c=0.998896
[Epoch 0052] loss=13.2124 cls=1.3531 smmd=0.1749 ct=9.2693 rec=1.2075 | train/val/test=1.000/0.704/0.701 | c=0.998896
[Epoch 0053] loss=13.0514 cls=1.1902 smmd=0.1673 ct=9.2876 rec=1.2032 | train/val/test=1.000/0.702/0.690 | c=0.998896
[Epoch 0054] loss=13.0930 cls=1.2453 smmd=0.1666 ct=9.2693 rec=1.2059 | train/val/test=1.000/0.710/0.692 | c=0.998896
[Epoch 0055] loss=13.2226 cls=1.3639 smmd=0.1722 ct=9.2602 rec=1.2132 | train/val/test=1.000/0.706/0.698 | c=0.998896
[Epoch 0056] loss=12.9418 cls=1.0922 smmd=0.1724 ct=9.2585 rec=1.2093 | train/val/test=1.000/0.714/0.703 | c=0.998896
[Epoch 0057] loss=13.0486 cls=1.2192 smmd=0.1660 ct=9.2545 rec=1.2045 | train/val/test=1.000/0.718/0.705 | c=0.998896
[Epoch 0058] loss=13.0513 cls=1.2220 smmd=0.1590 ct=9.2687 rec=1.2007 | train/val/test=1.000/0.716/0.705 | c=0.998896
[Epoch 0059] loss=13.2501 cls=1.4137 smmd=0.1511 ct=9.2750 rec=1.2051 | train/val/test=1.000/0.718/0.702 | c=0.998896
[Epoch 0060] loss=13.0697 cls=1.2419 smmd=0.1526 ct=9.2693 rec=1.2029 | train/val/test=1.000/0.724/0.693 | c=0.998896
[Epoch 0061] loss=13.0725 cls=1.2429 smmd=0.1544 ct=9.2578 rec=1.2087 | train/val/test=1.000/0.716/0.686 | c=0.998896
[Epoch 0062] loss=12.9447 cls=1.1177 smmd=0.1644 ct=9.2492 rec=1.2067 | train/val/test=1.000/0.712/0.688 | c=0.998896
[Epoch 0063] loss=12.9944 cls=1.1467 smmd=0.1636 ct=9.2602 rec=1.2119 | train/val/test=1.000/0.720/0.701 | c=0.998896
[Epoch 0064] loss=12.8477 cls=1.0126 smmd=0.1593 ct=9.2601 rec=1.2078 | train/val/test=1.000/0.726/0.705 | c=0.998896
[Epoch 0065] loss=13.0024 cls=1.1821 smmd=0.1558 ct=9.2607 rec=1.2018 | train/val/test=1.000/0.728/0.711 | c=0.998896
[Epoch 0066] loss=13.0552 cls=1.2456 smmd=0.1528 ct=9.2574 rec=1.1997 | train/val/test=1.000/0.732/0.705 | c=0.998896
[Epoch 0067] loss=13.0967 cls=1.2795 smmd=0.1496 ct=9.2598 rec=1.2039 | train/val/test=1.000/0.732/0.697 | c=0.998896
[Epoch 0068] loss=12.9854 cls=1.1750 smmd=0.1440 ct=9.2627 rec=1.2019 | train/val/test=1.000/0.732/0.696 | c=0.998896
[Epoch 0069] loss=12.8205 cls=1.0081 smmd=0.1422 ct=9.2610 rec=1.2046 | train/val/test=1.000/0.726/0.694 | c=0.998896
[Epoch 0070] loss=13.0009 cls=1.1821 smmd=0.1431 ct=9.2661 rec=1.2047 | train/val/test=1.000/0.728/0.693 | c=0.998896
[Epoch 0071] loss=13.0676 cls=1.2583 smmd=0.1427 ct=9.2565 rec=1.2050 | train/val/test=1.000/0.730/0.694 | c=0.998896
[Epoch 0072] loss=12.8935 cls=1.0812 smmd=0.1459 ct=9.2633 rec=1.2015 | train/val/test=1.000/0.738/0.704 | c=0.998896
[Epoch 0073] loss=12.9134 cls=1.1063 smmd=0.1467 ct=9.2539 rec=1.2032 | train/val/test=1.000/0.746/0.715 | c=0.998896
[Epoch 0074] loss=12.9038 cls=1.0802 smmd=0.1485 ct=9.2616 rec=1.2067 | train/val/test=1.000/0.748/0.708 | c=0.998896
[Epoch 0075] loss=12.8903 cls=1.0888 smmd=0.1485 ct=9.2524 rec=1.2003 | train/val/test=1.000/0.748/0.705 | c=0.998896
[Epoch 0076] loss=12.6321 cls=0.8400 smmd=0.1455 ct=9.2490 rec=1.1988 | train/val/test=0.983/0.742/0.699 | c=0.998896
[Epoch 0077] loss=12.9718 cls=1.1818 smmd=0.1418 ct=9.2475 rec=1.2003 | train/val/test=0.983/0.746/0.695 | c=0.998896
[Epoch 0078] loss=12.7358 cls=0.9459 smmd=0.1400 ct=9.2550 rec=1.1974 | train/val/test=0.983/0.748/0.690 | c=0.998896
[Epoch 0079] loss=12.6457 cls=0.8384 smmd=0.1396 ct=9.2627 rec=1.2025 | train/val/test=0.983/0.748/0.690 | c=0.998896
[Epoch 0080] loss=12.9541 cls=1.1501 smmd=0.1390 ct=9.2630 rec=1.2010 | train/val/test=0.983/0.746/0.696 | c=0.998896
[Epoch 0081] loss=12.7557 cls=0.9536 smmd=0.1388 ct=9.2665 rec=1.1984 | train/val/test=0.983/0.750/0.704 | c=0.998896
[Epoch 0082] loss=12.9199 cls=1.1306 smmd=0.1392 ct=9.2598 rec=1.1951 | train/val/test=0.983/0.746/0.705 | c=0.998896
[Epoch 0083] loss=12.9293 cls=1.1558 smmd=0.1400 ct=9.2471 rec=1.1932 | train/val/test=0.983/0.748/0.705 | c=0.998896
[Epoch 0084] loss=12.9215 cls=1.1162 smmd=0.1425 ct=9.2590 rec=1.2019 | train/val/test=0.983/0.742/0.707 | c=0.998896
[Epoch 0085] loss=12.8120 cls=1.0300 smmd=0.1435 ct=9.2521 rec=1.1932 | train/val/test=0.983/0.742/0.709 | c=0.998896
[Epoch 0086] loss=13.0718 cls=1.2855 smmd=0.1449 ct=9.2574 rec=1.1920 | train/val/test=0.983/0.746/0.711 | c=0.998896
[Epoch 0087] loss=12.9950 cls=1.1998 smmd=0.1441 ct=9.2507 rec=1.2002 | train/val/test=0.983/0.750/0.710 | c=0.998896
[Epoch 0088] loss=13.0376 cls=1.2592 smmd=0.1435 ct=9.2437 rec=1.1956 | train/val/test=0.983/0.748/0.708 | c=0.998896
[Epoch 0089] loss=12.9951 cls=1.2109 smmd=0.1440 ct=9.2504 rec=1.1949 | train/val/test=0.983/0.748/0.707 | c=0.998896
[Epoch 0090] loss=12.7018 cls=0.9201 smmd=0.1426 ct=9.2507 rec=1.1942 | train/val/test=0.983/0.748/0.708 | c=0.998896
[Epoch 0091] loss=12.7064 cls=0.9207 smmd=0.1421 ct=9.2526 rec=1.1955 | train/val/test=0.983/0.746/0.707 | c=0.998896
[Epoch 0092] loss=13.2565 cls=1.4681 smmd=0.1418 ct=9.2527 rec=1.1970 | train/val/test=0.983/0.748/0.707 | c=0.998896
[Epoch 0093] loss=12.6322 cls=0.8548 smmd=0.1409 ct=9.2518 rec=1.1923 | train/val/test=0.983/0.752/0.706 | c=0.998896
[Epoch 0094] loss=12.9802 cls=1.1943 smmd=0.1417 ct=9.2513 rec=1.1964 | train/val/test=0.983/0.752/0.706 | c=0.998896
[Epoch 0095] loss=12.8160 cls=1.0431 smmd=0.1405 ct=9.2507 rec=1.1909 | train/val/test=0.983/0.750/0.707 | c=0.998896
[Epoch 0096] loss=13.2028 cls=1.4014 smmd=0.1422 ct=9.2566 rec=1.2013 | train/val/test=0.983/0.750/0.707 | c=0.998896
[Epoch 0097] loss=13.0891 cls=1.3026 smmd=0.1422 ct=9.2548 rec=1.1948 | train/val/test=0.983/0.750/0.706 | c=0.998896
[Epoch 0098] loss=12.6743 cls=0.8932 smmd=0.1420 ct=9.2508 rec=1.1941 | train/val/test=0.983/0.750/0.706 | c=0.998896
[Epoch 0099] loss=12.7903 cls=1.0062 smmd=0.1413 ct=9.2472 rec=1.1978 | train/val/test=0.983/0.750/0.706 | c=0.998896
=== Best @ epoch 93: val=0.7520, test=0.7060 ===
