Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> CiteSeer
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.7945 cls=2.0642 smmd=4.6867 ct=9.2565 rec=1.3936 | train/val/test=0.241/0.098/0.115 | c=0.998896
[Epoch 0001] loss=18.5757 cls=1.9045 smmd=4.6395 ct=9.2532 rec=1.3893 | train/val/test=0.466/0.272/0.277 | c=0.998896
[Epoch 0002] loss=18.3972 cls=1.8378 smmd=4.5380 ct=9.2451 rec=1.3882 | train/val/test=0.586/0.250/0.258 | c=0.998896
[Epoch 0003] loss=18.0781 cls=1.6938 smmd=4.3984 ct=9.2177 rec=1.3841 | train/val/test=0.793/0.332/0.336 | c=0.998896
[Epoch 0004] loss=17.5931 cls=1.4846 smmd=4.2141 ct=9.1577 rec=1.3684 | train/val/test=0.845/0.480/0.464 | c=0.998896
[Epoch 0005] loss=17.0787 cls=1.3747 smmd=3.9821 ct=9.0410 rec=1.3405 | train/val/test=0.897/0.602/0.596 | c=0.998896
[Epoch 0006] loss=16.6624 cls=1.3278 smmd=3.6985 ct=9.0018 rec=1.3171 | train/val/test=0.931/0.650/0.648 | c=0.998896
[Epoch 0007] loss=16.1316 cls=1.2725 smmd=3.3520 ct=8.9424 rec=1.2823 | train/val/test=0.914/0.698/0.683 | c=0.998896
[Epoch 0008] loss=15.2411 cls=1.0664 smmd=2.9322 ct=8.7802 rec=1.2311 | train/val/test=0.897/0.662/0.651 | c=0.998896
[Epoch 0009] loss=14.5818 cls=0.9431 smmd=2.4356 ct=8.7748 rec=1.2141 | train/val/test=0.914/0.684/0.675 | c=0.998896
[Epoch 0010] loss=13.9420 cls=0.8715 smmd=1.8707 ct=8.7890 rec=1.2054 | train/val/test=0.931/0.708/0.701 | c=0.998896
[Epoch 0011] loss=13.4431 cls=0.9931 smmd=1.2974 ct=8.7648 rec=1.1939 | train/val/test=0.966/0.726/0.718 | c=0.998896
[Epoch 0012] loss=13.1507 cls=1.1591 smmd=0.8709 ct=8.7452 rec=1.1878 | train/val/test=0.983/0.706/0.706 | c=0.998896
[Epoch 0013] loss=12.6954 cls=0.8635 smmd=0.7542 ct=8.7207 rec=1.1785 | train/val/test=0.966/0.688/0.706 | c=0.998896
[Epoch 0014] loss=12.9528 cls=0.9471 smmd=0.9255 ct=8.7195 rec=1.1804 | train/val/test=1.000/0.690/0.704 | c=0.998896
[Epoch 0015] loss=13.4975 cls=1.2312 smmd=1.1912 ct=8.7165 rec=1.1793 | train/val/test=1.000/0.710/0.725 | c=0.998896
[Epoch 0016] loss=13.5569 cls=1.0770 smmd=1.4079 ct=8.7095 rec=1.1812 | train/val/test=1.000/0.722/0.746 | c=0.998896
[Epoch 0017] loss=14.2888 cls=0.9523 smmd=1.5281 ct=9.4312 rec=1.1886 | train/val/test=1.000/0.732/0.737 | c=0.998896
[Epoch 0018] loss=14.3999 cls=1.1078 smmd=1.5319 ct=9.3758 rec=1.1922 | train/val/test=1.000/0.710/0.719 | c=0.998896
[Epoch 0019] loss=14.0127 cls=0.8762 smmd=1.4465 ct=9.2953 rec=1.1973 | train/val/test=0.983/0.708/0.700 | c=0.998896
[Epoch 0020] loss=14.2843 cls=1.3277 smmd=1.3140 ct=9.2208 rec=1.2109 | train/val/test=1.000/0.704/0.706 | c=0.998896
[Epoch 0021] loss=13.9300 cls=1.1411 smmd=1.1709 ct=9.1890 rec=1.2145 | train/val/test=1.000/0.724/0.721 | c=0.998896
[Epoch 0022] loss=14.0317 cls=1.3770 smmd=1.0523 ct=9.1758 rec=1.2133 | train/val/test=1.000/0.742/0.732 | c=0.998896
[Epoch 0023] loss=13.7745 cls=1.1966 smmd=0.9755 ct=9.1892 rec=1.2066 | train/val/test=0.983/0.744/0.733 | c=0.998896
[Epoch 0024] loss=13.7006 cls=1.1409 smmd=0.9291 ct=9.2045 rec=1.2131 | train/val/test=0.983/0.734/0.726 | c=0.998896
[Epoch 0025] loss=14.1177 cls=1.5572 smmd=0.9007 ct=9.2192 rec=1.2203 | train/val/test=0.983/0.724/0.719 | c=0.998896
[Epoch 0026] loss=13.4496 cls=0.8941 smmd=0.8762 ct=9.2541 rec=1.2126 | train/val/test=0.983/0.718/0.712 | c=0.998896
[Epoch 0027] loss=13.6295 cls=1.0911 smmd=0.8352 ct=9.2730 rec=1.2151 | train/val/test=0.983/0.716/0.711 | c=0.998896
[Epoch 0028] loss=13.6808 cls=1.1783 smmd=0.7711 ct=9.2955 rec=1.2179 | train/val/test=0.983/0.712/0.713 | c=0.998896
[Epoch 0029] loss=13.6499 cls=1.2141 smmd=0.7001 ct=9.3005 rec=1.2176 | train/val/test=0.983/0.724/0.719 | c=0.998896
[Epoch 0030] loss=13.5031 cls=1.1550 smmd=0.6250 ct=9.3062 rec=1.2085 | train/val/test=0.983/0.730/0.726 | c=0.998896
[Epoch 0031] loss=13.3883 cls=1.1084 smmd=0.5671 ct=9.2960 rec=1.2084 | train/val/test=0.983/0.732/0.727 | c=0.998896
[Epoch 0032] loss=13.3401 cls=1.1115 smmd=0.5294 ct=9.2850 rec=1.2071 | train/val/test=0.983/0.728/0.721 | c=0.998896
[Epoch 0033] loss=13.4756 cls=1.2897 smmd=0.5053 ct=9.2662 rec=1.2072 | train/val/test=0.983/0.726/0.720 | c=0.998896
[Epoch 0034] loss=13.0794 cls=0.9282 smmd=0.4854 ct=9.2616 rec=1.2021 | train/val/test=0.983/0.724/0.717 | c=0.998896
[Epoch 0035] loss=13.2717 cls=1.1505 smmd=0.4613 ct=9.2508 rec=1.2045 | train/val/test=0.983/0.722/0.708 | c=0.998896
[Epoch 0036] loss=13.2739 cls=1.1926 smmd=0.4318 ct=9.2507 rec=1.1994 | train/val/test=0.983/0.718/0.706 | c=0.998896
[Epoch 0037] loss=13.5211 cls=1.4710 smmd=0.3937 ct=9.2512 rec=1.2026 | train/val/test=0.983/0.722/0.713 | c=0.998896
[Epoch 0038] loss=13.2000 cls=1.1991 smmd=0.3592 ct=9.2518 rec=1.1950 | train/val/test=0.983/0.732/0.707 | c=0.998896
[Epoch 0039] loss=13.3118 cls=1.3125 smmd=0.3338 ct=9.2491 rec=1.2082 | train/val/test=0.966/0.728/0.703 | c=0.998896
[Epoch 0040] loss=13.2556 cls=1.2919 smmd=0.3112 ct=9.2567 rec=1.1979 | train/val/test=0.983/0.732/0.709 | c=0.998896
[Epoch 0041] loss=12.7840 cls=0.8470 smmd=0.2908 ct=9.2452 rec=1.2005 | train/val/test=0.966/0.722/0.709 | c=0.998896
[Epoch 0042] loss=13.4875 cls=1.5752 smmd=0.2667 ct=9.2443 rec=1.2006 | train/val/test=0.983/0.720/0.712 | c=0.998896
[Epoch 0043] loss=13.0691 cls=1.1768 smmd=0.2507 ct=9.2429 rec=1.1993 | train/val/test=0.983/0.726/0.718 | c=0.998896
[Epoch 0044] loss=12.8985 cls=1.0181 smmd=0.2418 ct=9.2436 rec=1.1975 | train/val/test=0.983/0.716/0.714 | c=0.998896
[Epoch 0045] loss=13.1289 cls=1.2491 smmd=0.2372 ct=9.2331 rec=1.2048 | train/val/test=0.983/0.720/0.704 | c=0.998896
[Epoch 0046] loss=13.2341 cls=1.3482 smmd=0.2344 ct=9.2398 rec=1.2059 | train/val/test=0.966/0.716/0.700 | c=0.998896
[Epoch 0047] loss=13.3598 cls=1.4957 smmd=0.2156 ct=9.2311 rec=1.2087 | train/val/test=0.983/0.690/0.685 | c=0.998896
[Epoch 0048] loss=13.1683 cls=1.3145 smmd=0.2069 ct=9.2304 rec=1.2082 | train/val/test=1.000/0.708/0.701 | c=0.998896
[Epoch 0049] loss=12.9502 cls=1.0942 smmd=0.1964 ct=9.2387 rec=1.2104 | train/val/test=1.000/0.716/0.705 | c=0.998896
[Epoch 0050] loss=12.9415 cls=1.1090 smmd=0.1861 ct=9.2340 rec=1.2062 | train/val/test=0.983/0.724/0.713 | c=0.998896
[Epoch 0051] loss=13.0035 cls=1.1725 smmd=0.1814 ct=9.2265 rec=1.2115 | train/val/test=0.983/0.714/0.703 | c=0.998896
[Epoch 0052] loss=12.9821 cls=1.1399 smmd=0.1811 ct=9.2317 rec=1.2147 | train/val/test=0.983/0.696/0.688 | c=0.998896
[Epoch 0053] loss=13.2959 cls=1.4440 smmd=0.1803 ct=9.2259 rec=1.2229 | train/val/test=1.000/0.706/0.693 | c=0.998896
[Epoch 0054] loss=13.0383 cls=1.2252 smmd=0.1747 ct=9.2209 rec=1.2087 | train/val/test=1.000/0.712/0.702 | c=0.998896
[Epoch 0055] loss=12.9935 cls=1.1658 smmd=0.1704 ct=9.2212 rec=1.2180 | train/val/test=1.000/0.720/0.712 | c=0.998896
[Epoch 0056] loss=13.0623 cls=1.2272 smmd=0.1653 ct=9.2186 rec=1.2256 | train/val/test=1.000/0.716/0.713 | c=0.998896
[Epoch 0057] loss=13.0359 cls=1.2251 smmd=0.1611 ct=9.2234 rec=1.2132 | train/val/test=0.983/0.718/0.705 | c=0.998896
[Epoch 0058] loss=13.1981 cls=1.3870 smmd=0.1590 ct=9.2259 rec=1.2131 | train/val/test=0.983/0.712/0.707 | c=0.998896
[Epoch 0059] loss=13.0356 cls=1.2258 smmd=0.1542 ct=9.2265 rec=1.2146 | train/val/test=1.000/0.698/0.702 | c=0.998896
[Epoch 0060] loss=13.1142 cls=1.3044 smmd=0.1553 ct=9.2206 rec=1.2169 | train/val/test=1.000/0.698/0.700 | c=0.998896
[Epoch 0061] loss=13.1723 cls=1.3501 smmd=0.1571 ct=9.2231 rec=1.2210 | train/val/test=1.000/0.712/0.706 | c=0.998896
[Epoch 0062] loss=13.0236 cls=1.2152 smmd=0.1553 ct=9.2225 rec=1.2153 | train/val/test=1.000/0.700/0.712 | c=0.998896
[Epoch 0063] loss=12.9944 cls=1.2071 smmd=0.1524 ct=9.2221 rec=1.2064 | train/val/test=1.000/0.698/0.714 | c=0.998896
[Epoch 0064] loss=12.8126 cls=1.0249 smmd=0.1502 ct=9.2291 rec=1.2043 | train/val/test=1.000/0.702/0.710 | c=0.998896
[Epoch 0065] loss=12.7388 cls=0.9619 smmd=0.1478 ct=9.2179 rec=1.2056 | train/val/test=1.000/0.704/0.717 | c=0.998896
[Epoch 0066] loss=12.9416 cls=1.1719 smmd=0.1440 ct=9.2190 rec=1.2033 | train/val/test=1.000/0.710/0.722 | c=0.998896
[Epoch 0067] loss=13.0214 cls=1.2279 smmd=0.1422 ct=9.2163 rec=1.2174 | train/val/test=1.000/0.722/0.720 | c=0.998896
[Epoch 0068] loss=12.9044 cls=1.1238 smmd=0.1439 ct=9.2250 rec=1.2058 | train/val/test=1.000/0.720/0.714 | c=0.998896
[Epoch 0069] loss=12.6694 cls=0.9156 smmd=0.1462 ct=9.2143 rec=1.1967 | train/val/test=1.000/0.716/0.705 | c=0.998896
[Epoch 0070] loss=12.8445 cls=1.0874 smmd=0.1475 ct=9.2133 rec=1.1981 | train/val/test=1.000/0.716/0.705 | c=0.998896
[Epoch 0071] loss=13.0373 cls=1.2670 smmd=0.1475 ct=9.2138 rec=1.2045 | train/val/test=1.000/0.714/0.706 | c=0.998896
[Epoch 0072] loss=12.9921 cls=1.2073 smmd=0.1464 ct=9.2106 rec=1.2139 | train/val/test=1.000/0.716/0.710 | c=0.998896
[Epoch 0073] loss=12.9352 cls=1.1769 smmd=0.1426 ct=9.2128 rec=1.2014 | train/val/test=1.000/0.724/0.712 | c=0.998896
[Epoch 0074] loss=12.9524 cls=1.1780 smmd=0.1380 ct=9.2238 rec=1.2063 | train/val/test=1.000/0.726/0.714 | c=0.998896
[Epoch 0075] loss=13.0402 cls=1.3031 smmd=0.1345 ct=9.2132 rec=1.1948 | train/val/test=1.000/0.730/0.715 | c=0.998896
[Epoch 0076] loss=12.9768 cls=1.2402 smmd=0.1347 ct=9.2167 rec=1.1926 | train/val/test=1.000/0.736/0.718 | c=0.998896
[Epoch 0077] loss=12.7032 cls=0.9579 smmd=0.1371 ct=9.2224 rec=1.1929 | train/val/test=1.000/0.740/0.717 | c=0.998896
[Epoch 0078] loss=12.6811 cls=0.9210 smmd=0.1411 ct=9.2269 rec=1.1961 | train/val/test=1.000/0.736/0.715 | c=0.998896
[Epoch 0079] loss=12.7634 cls=1.0266 smmd=0.1431 ct=9.2090 rec=1.1923 | train/val/test=1.000/0.738/0.712 | c=0.998896
[Epoch 0080] loss=12.7317 cls=0.9854 smmd=0.1461 ct=9.2017 rec=1.1993 | train/val/test=1.000/0.736/0.710 | c=0.998896
[Epoch 0081] loss=12.6637 cls=0.9103 smmd=0.1453 ct=9.2075 rec=1.2003 | train/val/test=1.000/0.738/0.712 | c=0.998896
[Epoch 0082] loss=12.6902 cls=0.9594 smmd=0.1464 ct=9.2070 rec=1.1887 | train/val/test=1.000/0.740/0.713 | c=0.998896
[Epoch 0083] loss=12.7884 cls=1.0506 smmd=0.1476 ct=9.2065 rec=1.1919 | train/val/test=1.000/0.734/0.712 | c=0.998896
[Epoch 0084] loss=12.9277 cls=1.1924 smmd=0.1470 ct=9.2003 rec=1.1940 | train/val/test=1.000/0.736/0.710 | c=0.998896
[Epoch 0085] loss=12.8538 cls=1.0928 smmd=0.1471 ct=9.1975 rec=1.2082 | train/val/test=1.000/0.736/0.713 | c=0.998896
[Epoch 0086] loss=12.8046 cls=1.0656 smmd=0.1461 ct=9.2049 rec=1.1940 | train/val/test=1.000/0.738/0.714 | c=0.998896
[Epoch 0087] loss=12.6556 cls=0.9313 smmd=0.1439 ct=9.1959 rec=1.1922 | train/val/test=1.000/0.738/0.713 | c=0.998896
[Epoch 0088] loss=13.3357 cls=1.5848 smmd=0.1430 ct=9.2076 rec=1.2001 | train/val/test=1.000/0.730/0.718 | c=0.998896
[Epoch 0089] loss=12.8438 cls=1.1158 smmd=0.1400 ct=9.2056 rec=1.1912 | train/val/test=1.000/0.730/0.719 | c=0.998896
[Epoch 0090] loss=12.7875 cls=1.0577 smmd=0.1380 ct=9.2117 rec=1.1900 | train/val/test=1.000/0.732/0.716 | c=0.998896
[Epoch 0091] loss=13.0268 cls=1.2995 smmd=0.1374 ct=9.2082 rec=1.1909 | train/val/test=0.983/0.732/0.713 | c=0.998896
[Epoch 0092] loss=13.2812 cls=1.5331 smmd=0.1370 ct=9.2084 rec=1.2013 | train/val/test=0.983/0.732/0.713 | c=0.998896
[Epoch 0093] loss=12.8539 cls=1.1236 smmd=0.1371 ct=9.2058 rec=1.1937 | train/val/test=0.983/0.730/0.713 | c=0.998896
[Epoch 0094] loss=12.9842 cls=1.2567 smmd=0.1347 ct=9.2062 rec=1.1933 | train/val/test=0.983/0.730/0.714 | c=0.998896
[Epoch 0095] loss=13.2122 cls=1.4846 smmd=0.1359 ct=9.2123 rec=1.1897 | train/val/test=0.983/0.730/0.714 | c=0.998896
[Epoch 0096] loss=12.7819 cls=1.0580 smmd=0.1359 ct=9.2105 rec=1.1887 | train/val/test=0.983/0.730/0.715 | c=0.998896
[Epoch 0097] loss=12.8606 cls=1.1308 smmd=0.1359 ct=9.2140 rec=1.1900 | train/val/test=0.983/0.730/0.715 | c=0.998896
[Epoch 0098] loss=12.9041 cls=1.1659 smmd=0.1368 ct=9.2079 rec=1.1967 | train/val/test=0.983/0.730/0.715 | c=0.998896
[Epoch 0099] loss=12.6763 cls=0.9491 smmd=0.1356 ct=9.2112 rec=1.1902 | train/val/test=0.983/0.730/0.715 | c=0.998896
=== Best @ epoch 23: val=0.7440, test=0.7330 ===
