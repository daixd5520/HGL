Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.0308 cls=2.0746 smmd=3.9339 ct=9.2427 rec=1.3898 | train/val/test=0.190/0.152/0.133 | c=0.998347
[Epoch 0001] loss=17.8672 cls=1.9951 smmd=3.8551 ct=9.2405 rec=1.3882 | train/val/test=0.172/0.138/0.139 | c=0.998347
[Epoch 0002] loss=17.6781 cls=1.9575 smmd=3.7059 ct=9.2350 rec=1.3899 | train/val/test=0.345/0.174/0.193 | c=0.998347
[Epoch 0003] loss=17.3936 cls=1.8720 smmd=3.5193 ct=9.2253 rec=1.3885 | train/val/test=0.500/0.270/0.267 | c=0.998347
[Epoch 0004] loss=16.9956 cls=1.7555 smmd=3.2655 ct=9.2051 rec=1.3847 | train/val/test=0.552/0.274/0.273 | c=0.998347
[Epoch 0005] loss=16.6548 cls=1.7626 smmd=2.9611 ct=9.1720 rec=1.3796 | train/val/test=0.621/0.356/0.346 | c=0.998347
[Epoch 0006] loss=16.0463 cls=1.6333 smmd=2.5629 ct=9.1176 rec=1.3663 | train/val/test=0.810/0.490/0.472 | c=0.998347
[Epoch 0007] loss=15.3088 cls=1.3770 smmd=2.1618 ct=9.0587 rec=1.3557 | train/val/test=0.776/0.458/0.430 | c=0.998347
[Epoch 0008] loss=14.6771 cls=1.2790 smmd=1.7225 ct=9.0053 rec=1.3352 | train/val/test=0.879/0.540/0.504 | c=0.998347
[Epoch 0009] loss=14.2541 cls=1.3521 smmd=1.3653 ct=8.9310 rec=1.3029 | train/val/test=0.897/0.596/0.582 | c=0.998347
[Epoch 0010] loss=13.9794 cls=1.3096 smmd=1.2250 ct=8.8810 rec=1.2819 | train/val/test=0.914/0.636/0.616 | c=0.998347
[Epoch 0011] loss=13.8849 cls=1.1886 smmd=1.3101 ct=8.8579 rec=1.2642 | train/val/test=0.931/0.656/0.663 | c=0.998347
[Epoch 0012] loss=13.9662 cls=1.1493 smmd=1.4952 ct=8.8412 rec=1.2403 | train/val/test=0.897/0.616/0.584 | c=0.998347
[Epoch 0013] loss=14.2097 cls=1.1988 smmd=1.6822 ct=8.8427 rec=1.2430 | train/val/test=0.897/0.654/0.632 | c=0.998347
[Epoch 0014] loss=14.3836 cls=1.3452 smmd=1.7819 ct=8.8124 rec=1.2221 | train/val/test=0.914/0.694/0.687 | c=0.998347
[Epoch 0015] loss=14.4122 cls=1.3539 smmd=1.8245 ct=8.8051 rec=1.2144 | train/val/test=0.914/0.704/0.693 | c=0.998347
[Epoch 0016] loss=14.8688 cls=1.8144 smmd=1.7854 ct=8.8154 rec=1.2268 | train/val/test=0.931/0.722/0.699 | c=0.998347
[Epoch 0017] loss=14.2433 cls=1.2982 smmd=1.6858 ct=8.8100 rec=1.2246 | train/val/test=0.948/0.720/0.701 | c=0.998347
[Epoch 0018] loss=13.6852 cls=0.9590 smmd=1.4951 ct=8.7809 rec=1.2251 | train/val/test=0.931/0.702/0.679 | c=0.998347
[Epoch 0019] loss=14.0400 cls=1.4190 smmd=1.3389 ct=8.7925 rec=1.2448 | train/val/test=0.948/0.702/0.674 | c=0.998347
[Epoch 0020] loss=13.8360 cls=1.3209 smmd=1.2247 ct=8.7968 rec=1.2468 | train/val/test=0.948/0.718/0.696 | c=0.998347
[Epoch 0021] loss=13.5616 cls=1.1097 smmd=1.1681 ct=8.7922 rec=1.2458 | train/val/test=0.983/0.736/0.714 | c=0.998347
[Epoch 0022] loss=13.7865 cls=1.3332 smmd=1.1851 ct=8.7799 rec=1.2442 | train/val/test=0.966/0.730/0.720 | c=0.998347
[Epoch 0023] loss=13.6206 cls=1.1383 smmd=1.2320 ct=8.7694 rec=1.2405 | train/val/test=0.966/0.718/0.729 | c=0.998347
[Epoch 0024] loss=13.6651 cls=1.1137 smmd=1.3132 ct=8.7655 rec=1.2364 | train/val/test=0.948/0.714/0.727 | c=0.998347
[Epoch 0025] loss=13.7980 cls=1.2861 smmd=1.2835 ct=8.7637 rec=1.2324 | train/val/test=0.948/0.718/0.725 | c=0.998347
[Epoch 0026] loss=13.7980 cls=1.3328 smmd=1.2527 ct=8.7547 rec=1.2289 | train/val/test=0.966/0.722/0.727 | c=0.998347
[Epoch 0027] loss=13.4918 cls=1.1247 smmd=1.1623 ct=8.7541 rec=1.2253 | train/val/test=0.983/0.718/0.726 | c=0.998347
[Epoch 0028] loss=13.5448 cls=1.2189 smmd=1.1325 ct=8.7551 rec=1.2191 | train/val/test=0.983/0.720/0.726 | c=0.998347
[Epoch 0029] loss=13.6457 cls=1.3526 smmd=1.0768 ct=8.7599 rec=1.2282 | train/val/test=0.983/0.718/0.723 | c=0.998347
[Epoch 0030] loss=13.2493 cls=1.0299 smmd=1.0339 ct=8.7524 rec=1.2165 | train/val/test=0.983/0.710/0.719 | c=0.998347
[Epoch 0031] loss=13.5903 cls=1.4164 smmd=0.9978 ct=8.7482 rec=1.2140 | train/val/test=0.983/0.714/0.724 | c=0.998347
[Epoch 0032] loss=13.2678 cls=1.0710 smmd=1.0108 ct=8.7473 rec=1.2194 | train/val/test=0.983/0.728/0.725 | c=0.998347
[Epoch 0033] loss=13.4222 cls=1.2493 smmd=1.0084 ct=8.7449 rec=1.2098 | train/val/test=0.983/0.738/0.721 | c=0.998347
[Epoch 0034] loss=13.4150 cls=1.2602 smmd=0.9802 ct=8.7499 rec=1.2123 | train/val/test=0.983/0.730/0.718 | c=0.998347
[Epoch 0035] loss=13.0240 cls=0.9167 smmd=0.9332 ct=8.7489 rec=1.2126 | train/val/test=0.966/0.724/0.714 | c=0.998347
[Epoch 0036] loss=13.1376 cls=1.0605 smmd=0.9110 ct=8.7490 rec=1.2086 | train/val/test=0.983/0.728/0.712 | c=0.998347
[Epoch 0037] loss=13.3337 cls=1.2195 smmd=0.8954 ct=8.7562 rec=1.2313 | train/val/test=0.983/0.728/0.728 | c=0.998347
[Epoch 0038] loss=12.8190 cls=0.7872 smmd=0.8693 ct=8.7483 rec=1.2072 | train/val/test=0.983/0.722/0.731 | c=0.998347
[Epoch 0039] loss=12.7526 cls=0.7646 smmd=0.8390 ct=8.7494 rec=1.1998 | train/val/test=0.983/0.726/0.735 | c=0.998347
[Epoch 0040] loss=13.0548 cls=1.1217 smmd=0.7887 ct=8.7484 rec=1.1980 | train/val/test=0.983/0.732/0.733 | c=0.998347
[Epoch 0041] loss=13.6393 cls=1.7023 smmd=0.7850 ct=8.7450 rec=1.2035 | train/val/test=0.983/0.718/0.713 | c=0.998347
[Epoch 0042] loss=13.6010 cls=1.6667 smmd=0.7716 ct=8.7522 rec=1.2052 | train/val/test=0.983/0.722/0.688 | c=0.998347
[Epoch 0043] loss=12.9975 cls=1.0843 smmd=0.7343 ct=8.7554 rec=1.2117 | train/val/test=0.983/0.724/0.691 | c=0.998347
[Epoch 0044] loss=13.0485 cls=1.1679 smmd=0.6991 ct=8.7541 rec=1.2137 | train/val/test=0.983/0.722/0.702 | c=0.998347
[Epoch 0045] loss=13.0250 cls=1.1474 smmd=0.6904 ct=8.7586 rec=1.2143 | train/val/test=0.966/0.716/0.715 | c=0.998347
[Epoch 0046] loss=12.9015 cls=1.0455 smmd=0.6626 ct=8.7536 rec=1.2199 | train/val/test=0.966/0.730/0.724 | c=0.998347
[Epoch 0047] loss=12.9157 cls=1.0754 smmd=0.6454 ct=8.7561 rec=1.2194 | train/val/test=0.966/0.732/0.726 | c=0.998347
[Epoch 0048] loss=12.9658 cls=1.1330 smmd=0.6261 ct=8.7538 rec=1.2264 | train/val/test=0.966/0.732/0.721 | c=0.998347
[Epoch 0049] loss=13.1421 cls=1.3388 smmd=0.6034 ct=8.7547 rec=1.2226 | train/val/test=0.966/0.730/0.716 | c=0.998347
[Epoch 0050] loss=12.8864 cls=1.1211 smmd=0.5772 ct=8.7532 rec=1.2175 | train/val/test=0.966/0.734/0.713 | c=0.998347
[Epoch 0051] loss=12.9068 cls=1.1769 smmd=0.5542 ct=8.7569 rec=1.2094 | train/val/test=0.966/0.730/0.704 | c=0.998347
[Epoch 0052] loss=13.0336 cls=1.2461 smmd=0.5495 ct=8.7619 rec=1.2380 | train/val/test=0.966/0.734/0.702 | c=0.998347
[Epoch 0053] loss=13.0760 cls=1.3601 smmd=0.5286 ct=8.7567 rec=1.2153 | train/val/test=0.983/0.722/0.707 | c=0.998347
[Epoch 0054] loss=12.7449 cls=1.0403 smmd=0.5126 ct=8.7558 rec=1.2181 | train/val/test=0.983/0.722/0.729 | c=0.998347
[Epoch 0055] loss=12.8052 cls=1.1117 smmd=0.5099 ct=8.7608 rec=1.2114 | train/val/test=0.983/0.718/0.735 | c=0.998347
[Epoch 0056] loss=12.6523 cls=0.9825 smmd=0.4664 ct=8.7587 rec=1.2224 | train/val/test=0.983/0.726/0.735 | c=0.998347
[Epoch 0057] loss=12.9469 cls=1.2852 smmd=0.4705 ct=8.7636 rec=1.2138 | train/val/test=0.983/0.722/0.723 | c=0.998347
[Epoch 0058] loss=12.8501 cls=1.2175 smmd=0.4490 ct=8.7693 rec=1.2072 | train/val/test=0.983/0.724/0.714 | c=0.998347
[Epoch 0059] loss=12.8323 cls=1.2316 smmd=0.4245 ct=8.7688 rec=1.2037 | train/val/test=0.983/0.718/0.708 | c=0.998347
[Epoch 0060] loss=12.9170 cls=1.2799 smmd=0.4214 ct=8.7712 rec=1.2222 | train/val/test=0.983/0.720/0.704 | c=0.998347
[Epoch 0061] loss=12.6549 cls=1.0365 smmd=0.4306 ct=8.7665 rec=1.2106 | train/val/test=0.983/0.720/0.716 | c=0.998347
[Epoch 0062] loss=13.0620 cls=1.4928 smmd=0.3904 ct=8.7709 rec=1.2039 | train/val/test=0.983/0.720/0.722 | c=0.998347
[Epoch 0063] loss=12.5966 cls=1.0070 smmd=0.3962 ct=8.7791 rec=1.2072 | train/val/test=0.983/0.728/0.725 | c=0.998347
[Epoch 0064] loss=12.6770 cls=1.1117 smmd=0.3757 ct=8.7804 rec=1.2046 | train/val/test=0.983/0.726/0.715 | c=0.998347
[Epoch 0065] loss=12.6014 cls=1.0336 smmd=0.3766 ct=8.7853 rec=1.2030 | train/val/test=0.983/0.708/0.710 | c=0.998347
[Epoch 0066] loss=12.8143 cls=1.2672 smmd=0.3456 ct=8.7878 rec=1.2069 | train/val/test=0.983/0.710/0.701 | c=0.998347
[Epoch 0067] loss=12.7556 cls=1.2102 smmd=0.3578 ct=8.7835 rec=1.2021 | train/val/test=0.983/0.716/0.704 | c=0.998347
[Epoch 0068] loss=12.8357 cls=1.3184 smmd=0.3462 ct=8.7748 rec=1.1981 | train/val/test=0.983/0.724/0.705 | c=0.998347
[Epoch 0069] loss=12.5356 cls=1.0245 smmd=0.3366 ct=8.7734 rec=1.2006 | train/val/test=0.983/0.724/0.714 | c=0.998347
[Epoch 0070] loss=12.6850 cls=1.1497 smmd=0.3538 ct=8.7803 rec=1.2006 | train/val/test=0.983/0.728/0.722 | c=0.998347
[Epoch 0071] loss=12.7281 cls=1.1760 smmd=0.3440 ct=8.7780 rec=1.2151 | train/val/test=0.983/0.730/0.718 | c=0.998347
[Epoch 0072] loss=12.6429 cls=1.1174 smmd=0.3291 ct=8.7905 rec=1.2030 | train/val/test=0.983/0.728/0.707 | c=0.998347
[Epoch 0073] loss=12.6440 cls=1.1209 smmd=0.3292 ct=8.7902 rec=1.2018 | train/val/test=0.983/0.718/0.707 | c=0.998347
[Epoch 0074] loss=12.7990 cls=1.2929 smmd=0.3103 ct=8.7919 rec=1.2020 | train/val/test=0.983/0.720/0.706 | c=0.998347
[Epoch 0075] loss=12.6292 cls=1.1116 smmd=0.3185 ct=8.7924 rec=1.2033 | train/val/test=0.983/0.728/0.707 | c=0.998347
[Epoch 0076] loss=12.3511 cls=0.8546 smmd=0.3147 ct=8.7876 rec=1.1971 | train/val/test=0.983/0.730/0.708 | c=0.998347
[Epoch 0077] loss=12.7353 cls=1.2441 smmd=0.3031 ct=8.7870 rec=1.2006 | train/val/test=0.983/0.728/0.713 | c=0.998347
[Epoch 0078] loss=12.7969 cls=1.2989 smmd=0.3032 ct=8.7851 rec=1.2049 | train/val/test=0.983/0.732/0.716 | c=0.998347
[Epoch 0079] loss=12.7826 cls=1.2908 smmd=0.3076 ct=8.7843 rec=1.1999 | train/val/test=0.983/0.734/0.719 | c=0.998347
[Epoch 0080] loss=12.4496 cls=0.9675 smmd=0.3053 ct=8.7814 rec=1.1977 | train/val/test=0.983/0.730/0.721 | c=0.998347
[Epoch 0081] loss=12.6190 cls=1.1442 smmd=0.2892 ct=8.7781 rec=1.2038 | train/val/test=0.983/0.730/0.720 | c=0.998347
[Epoch 0082] loss=12.7287 cls=1.2412 smmd=0.2907 ct=8.7806 rec=1.2081 | train/val/test=0.983/0.728/0.718 | c=0.998347
[Epoch 0083] loss=12.6403 cls=1.1646 smmd=0.2864 ct=8.7872 rec=1.2011 | train/val/test=0.983/0.728/0.718 | c=0.998347
[Epoch 0084] loss=12.5519 cls=1.0704 smmd=0.2815 ct=8.7885 rec=1.2057 | train/val/test=0.966/0.730/0.721 | c=0.998347
[Epoch 0085] loss=12.6923 cls=1.1932 smmd=0.2917 ct=8.7899 rec=1.2088 | train/val/test=0.966/0.728/0.721 | c=0.998347
[Epoch 0086] loss=12.4087 cls=0.9179 smmd=0.2895 ct=8.7876 rec=1.2068 | train/val/test=0.966/0.730/0.722 | c=0.998347
[Epoch 0087] loss=12.5962 cls=1.1280 smmd=0.2777 ct=8.7895 rec=1.2006 | train/val/test=0.966/0.730/0.723 | c=0.998347
[Epoch 0088] loss=12.5463 cls=1.0469 smmd=0.2738 ct=8.7855 rec=1.2200 | train/val/test=0.966/0.732/0.721 | c=0.998347
[Epoch 0089] loss=12.8343 cls=1.3523 smmd=0.2878 ct=8.7869 rec=1.2037 | train/val/test=0.983/0.728/0.721 | c=0.998347
[Epoch 0090] loss=12.5502 cls=1.0888 smmd=0.2602 ct=8.7864 rec=1.2074 | train/val/test=0.983/0.728/0.722 | c=0.998347
[Epoch 0091] loss=12.8203 cls=1.3410 smmd=0.2726 ct=8.7895 rec=1.2086 | train/val/test=0.983/0.732/0.721 | c=0.998347
[Epoch 0092] loss=12.9726 cls=1.4931 smmd=0.2742 ct=8.7834 rec=1.2110 | train/val/test=0.983/0.734/0.721 | c=0.998347
[Epoch 0093] loss=12.4586 cls=0.9659 smmd=0.2686 ct=8.7889 rec=1.2176 | train/val/test=0.983/0.734/0.720 | c=0.998347
[Epoch 0094] loss=12.4910 cls=1.0343 smmd=0.2615 ct=8.7842 rec=1.2055 | train/val/test=0.983/0.736/0.720 | c=0.998347
[Epoch 0095] loss=12.4743 cls=1.0274 smmd=0.2618 ct=8.7861 rec=1.1995 | train/val/test=0.983/0.736/0.719 | c=0.998347
[Epoch 0096] loss=12.5433 cls=1.0905 smmd=0.2622 ct=8.7900 rec=1.2003 | train/val/test=0.983/0.736/0.719 | c=0.998347
[Epoch 0097] loss=12.8051 cls=1.3444 smmd=0.2697 ct=8.7885 rec=1.2013 | train/val/test=0.983/0.736/0.719 | c=0.998347
[Epoch 0098] loss=12.6039 cls=1.1396 smmd=0.2726 ct=8.7842 rec=1.2037 | train/val/test=0.983/0.736/0.719 | c=0.998347
[Epoch 0099] loss=12.6884 cls=1.2274 smmd=0.2722 ct=8.7861 rec=1.2014 | train/val/test=0.983/0.736/0.719 | c=0.998347
=== Best @ epoch 33: val=0.7380, test=0.7210 ===
