Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.0753 cls=2.0623 smmd=4.0092 ct=9.2269 rec=1.3885 | train/val/test=0.310/0.218/0.211 | c=0.998347
[Epoch 0001] loss=17.8661 cls=1.9630 smmd=3.9053 ct=9.2219 rec=1.3880 | train/val/test=0.310/0.266/0.247 | c=0.998347
[Epoch 0002] loss=17.6732 cls=1.9008 smmd=3.7748 ct=9.2189 rec=1.3893 | train/val/test=0.448/0.234/0.246 | c=0.998347
[Epoch 0003] loss=17.2994 cls=1.7343 smmd=3.5866 ct=9.2034 rec=1.3875 | train/val/test=0.552/0.186/0.215 | c=0.998347
[Epoch 0004] loss=17.1485 cls=1.8518 smmd=3.3418 ct=9.1860 rec=1.3844 | train/val/test=0.741/0.324/0.386 | c=0.998347
[Epoch 0005] loss=16.7254 cls=1.7821 smmd=3.0210 ct=9.1613 rec=1.3805 | train/val/test=0.897/0.476/0.494 | c=0.998347
[Epoch 0006] loss=16.1978 cls=1.6570 smmd=2.6640 ct=9.1300 rec=1.3734 | train/val/test=0.879/0.496/0.508 | c=0.998347
[Epoch 0007] loss=15.4517 cls=1.4505 smmd=2.2099 ct=9.0742 rec=1.3585 | train/val/test=0.879/0.532/0.549 | c=0.998347
[Epoch 0008] loss=14.8815 cls=1.4568 smmd=1.7621 ct=9.0007 rec=1.3310 | train/val/test=0.862/0.612/0.611 | c=0.998347
[Epoch 0009] loss=14.6546 cls=1.6656 smmd=1.4562 ct=8.9285 rec=1.3021 | train/val/test=0.879/0.620/0.615 | c=0.998347
[Epoch 0010] loss=14.1568 cls=1.4648 smmd=1.2945 ct=8.8507 rec=1.2734 | train/val/test=0.914/0.634/0.628 | c=0.998347
[Epoch 0011] loss=13.9567 cls=1.2118 smmd=1.3712 ct=8.8391 rec=1.2673 | train/val/test=0.914/0.658/0.663 | c=0.998347
[Epoch 0012] loss=14.3743 cls=1.5265 smmd=1.5430 ct=8.7944 rec=1.2552 | train/val/test=0.897/0.646/0.638 | c=0.998347
[Epoch 0013] loss=14.3086 cls=1.3415 smmd=1.7101 ct=8.7768 rec=1.2401 | train/val/test=0.897/0.684/0.663 | c=0.998347
[Epoch 0014] loss=14.4352 cls=1.3239 smmd=1.8662 ct=8.7718 rec=1.2366 | train/val/test=0.931/0.696/0.674 | c=0.998347
[Epoch 0015] loss=14.2037 cls=1.0917 smmd=1.9010 ct=8.7636 rec=1.2237 | train/val/test=0.966/0.708/0.699 | c=0.998347
[Epoch 0016] loss=14.2516 cls=1.1696 smmd=1.8951 ct=8.7567 rec=1.2151 | train/val/test=0.983/0.730/0.724 | c=0.998347
[Epoch 0017] loss=14.0560 cls=1.0812 smmd=1.7736 ct=8.7604 rec=1.2204 | train/val/test=0.983/0.746/0.732 | c=0.998347
[Epoch 0018] loss=13.9387 cls=1.1415 smmd=1.6242 ct=8.7600 rec=1.2065 | train/val/test=0.983/0.750/0.731 | c=0.998347
[Epoch 0019] loss=13.7209 cls=1.1208 smmd=1.4464 ct=8.7572 rec=1.1982 | train/val/test=0.966/0.732/0.712 | c=0.998347
[Epoch 0020] loss=13.2128 cls=0.7982 smmd=1.2674 ct=8.7569 rec=1.1952 | train/val/test=0.966/0.726/0.706 | c=0.998347
[Epoch 0021] loss=14.3154 cls=1.3224 smmd=1.1742 ct=9.4219 rec=1.1984 | train/val/test=0.966/0.730/0.707 | c=0.998347
[Epoch 0022] loss=14.1286 cls=1.1489 smmd=1.2188 ct=9.3793 rec=1.1908 | train/val/test=0.931/0.728/0.717 | c=0.998347
[Epoch 0023] loss=14.2699 cls=1.2612 smmd=1.3006 ct=9.3316 rec=1.1883 | train/val/test=0.931/0.730/0.727 | c=0.998347
[Epoch 0024] loss=14.2637 cls=1.2195 smmd=1.3681 ct=9.2837 rec=1.1963 | train/val/test=0.948/0.732/0.725 | c=0.998347
[Epoch 0025] loss=14.4211 cls=1.3237 smmd=1.4410 ct=9.2466 rec=1.2049 | train/val/test=0.966/0.730/0.719 | c=0.998347
[Epoch 0026] loss=14.0441 cls=0.9520 smmd=1.4437 ct=9.2284 rec=1.2101 | train/val/test=0.966/0.720/0.696 | c=0.998347
[Epoch 0027] loss=14.1767 cls=1.1345 smmd=1.3643 ct=9.2337 rec=1.2221 | train/val/test=0.966/0.726/0.713 | c=0.998347
[Epoch 0028] loss=14.0223 cls=1.0353 smmd=1.2974 ct=9.2491 rec=1.2203 | train/val/test=0.983/0.730/0.717 | c=0.998347
[Epoch 0029] loss=14.0385 cls=1.1378 smmd=1.1906 ct=9.2705 rec=1.2198 | train/val/test=0.983/0.732/0.722 | c=0.998347
[Epoch 0030] loss=14.0188 cls=1.1795 smmd=1.1255 ct=9.2954 rec=1.2092 | train/val/test=0.966/0.736/0.723 | c=0.998347
[Epoch 0031] loss=13.6075 cls=0.8325 smmd=1.0501 ct=9.3272 rec=1.1988 | train/val/test=0.966/0.742/0.725 | c=0.998347
[Epoch 0032] loss=13.7931 cls=1.0231 smmd=1.0472 ct=9.3289 rec=1.1969 | train/val/test=0.966/0.738/0.727 | c=0.998347
[Epoch 0033] loss=13.8702 cls=1.1343 smmd=1.0418 ct=9.3236 rec=1.1853 | train/val/test=0.966/0.738/0.731 | c=0.998347
[Epoch 0034] loss=13.7020 cls=0.9922 smmd=1.0136 ct=9.3125 rec=1.1918 | train/val/test=0.983/0.730/0.733 | c=0.998347
[Epoch 0035] loss=14.2316 cls=1.5337 smmd=1.0209 ct=9.3047 rec=1.1861 | train/val/test=0.983/0.722/0.721 | c=0.998347
[Epoch 0036] loss=13.7819 cls=1.1433 smmd=0.9958 ct=9.2854 rec=1.1787 | train/val/test=0.983/0.718/0.708 | c=0.998347
[Epoch 0037] loss=13.9808 cls=1.3192 smmd=0.9738 ct=9.2844 rec=1.2017 | train/val/test=0.983/0.712/0.701 | c=0.998347
[Epoch 0038] loss=13.7045 cls=1.0635 smmd=0.9602 ct=9.2731 rec=1.2038 | train/val/test=0.983/0.716/0.705 | c=0.998347
[Epoch 0039] loss=13.4611 cls=0.8642 smmd=0.9213 ct=9.2805 rec=1.1976 | train/val/test=0.983/0.716/0.714 | c=0.998347
[Epoch 0040] loss=13.6931 cls=1.1196 smmd=0.8869 ct=9.2881 rec=1.1992 | train/val/test=0.983/0.714/0.715 | c=0.998347
[Epoch 0041] loss=13.5444 cls=1.0163 smmd=0.8449 ct=9.2862 rec=1.1986 | train/val/test=0.983/0.706/0.704 | c=0.998347
[Epoch 0042] loss=13.7789 cls=1.2239 smmd=0.8241 ct=9.3145 rec=1.2082 | train/val/test=0.983/0.716/0.710 | c=0.998347
[Epoch 0043] loss=13.6451 cls=1.1462 smmd=0.7999 ct=9.2870 rec=1.2060 | train/val/test=0.983/0.724/0.713 | c=0.998347
[Epoch 0044] loss=13.7694 cls=1.2895 smmd=0.7801 ct=9.2775 rec=1.2112 | train/val/test=0.983/0.718/0.702 | c=0.998347
[Epoch 0045] loss=13.7191 cls=1.2513 smmd=0.7718 ct=9.2749 rec=1.2105 | train/val/test=0.983/0.718/0.705 | c=0.998347
[Epoch 0046] loss=13.5853 cls=1.1512 smmd=0.7364 ct=9.2714 rec=1.2132 | train/val/test=0.983/0.722/0.706 | c=0.998347
[Epoch 0047] loss=13.4027 cls=1.0136 smmd=0.7083 ct=9.2706 rec=1.2051 | train/val/test=0.983/0.724/0.709 | c=0.998347
[Epoch 0048] loss=13.6448 cls=1.2439 smmd=0.7043 ct=9.2726 rec=1.2120 | train/val/test=0.983/0.730/0.710 | c=0.998347
[Epoch 0049] loss=13.7454 cls=1.3823 smmd=0.6688 ct=9.2692 rec=1.2126 | train/val/test=0.983/0.726/0.704 | c=0.998347
[Epoch 0050] loss=13.3277 cls=0.9826 smmd=0.6658 ct=9.2695 rec=1.2049 | train/val/test=1.000/0.722/0.700 | c=0.998347
[Epoch 0051] loss=13.3038 cls=0.9775 smmd=0.6357 ct=9.2803 rec=1.2052 | train/val/test=1.000/0.718/0.698 | c=0.998347
[Epoch 0052] loss=13.3977 cls=1.0942 smmd=0.6164 ct=9.2748 rec=1.2062 | train/val/test=1.000/0.724/0.702 | c=0.998347
[Epoch 0053] loss=13.2201 cls=0.9182 smmd=0.6156 ct=9.2676 rec=1.2093 | train/val/test=1.000/0.724/0.703 | c=0.998347
[Epoch 0054] loss=13.4062 cls=1.1489 smmd=0.5928 ct=9.2672 rec=1.1986 | train/val/test=1.000/0.712/0.692 | c=0.998347
[Epoch 0055] loss=13.5954 cls=1.3484 smmd=0.5680 ct=9.2790 rec=1.2000 | train/val/test=1.000/0.714/0.691 | c=0.998347
[Epoch 0056] loss=13.3302 cls=1.1026 smmd=0.5603 ct=9.2828 rec=1.1923 | train/val/test=1.000/0.708/0.685 | c=0.998347
[Epoch 0057] loss=13.6891 cls=1.4535 smmd=0.5572 ct=9.2883 rec=1.1950 | train/val/test=1.000/0.708/0.687 | c=0.998347
[Epoch 0058] loss=13.5520 cls=1.3460 smmd=0.5412 ct=9.2730 rec=1.1959 | train/val/test=1.000/0.714/0.693 | c=0.998347
[Epoch 0059] loss=13.0764 cls=0.8779 smmd=0.5243 ct=9.2690 rec=1.2026 | train/val/test=1.000/0.714/0.697 | c=0.998347
[Epoch 0060] loss=13.7541 cls=1.5730 smmd=0.4941 ct=9.2696 rec=1.2087 | train/val/test=1.000/0.720/0.697 | c=0.998347
[Epoch 0061] loss=13.6343 cls=1.4467 smmd=0.4854 ct=9.2878 rec=1.2072 | train/val/test=1.000/0.724/0.697 | c=0.998347
[Epoch 0062] loss=13.3206 cls=1.1335 smmd=0.4770 ct=9.2808 rec=1.2146 | train/val/test=1.000/0.718/0.697 | c=0.998347
[Epoch 0063] loss=13.6745 cls=1.4630 smmd=0.4748 ct=9.2895 rec=1.2236 | train/val/test=1.000/0.724/0.688 | c=0.998347
[Epoch 0064] loss=13.3074 cls=1.1144 smmd=0.4604 ct=9.2893 rec=1.2216 | train/val/test=0.983/0.712/0.688 | c=0.998347
[Epoch 0065] loss=13.4097 cls=1.2264 smmd=0.4585 ct=9.2890 rec=1.2179 | train/val/test=0.983/0.716/0.684 | c=0.998347
[Epoch 0066] loss=13.2252 cls=1.0663 smmd=0.4489 ct=9.2763 rec=1.2169 | train/val/test=0.983/0.714/0.692 | c=0.998347
[Epoch 0067] loss=13.4632 cls=1.3002 smmd=0.4360 ct=9.2897 rec=1.2186 | train/val/test=0.983/0.728/0.701 | c=0.998347
[Epoch 0068] loss=13.2941 cls=1.1846 smmd=0.4308 ct=9.2723 rec=1.2032 | train/val/test=0.983/0.732/0.705 | c=0.998347
[Epoch 0069] loss=13.4187 cls=1.3146 smmd=0.4113 ct=9.2765 rec=1.2082 | train/val/test=0.983/0.738/0.707 | c=0.998347
[Epoch 0070] loss=13.5399 cls=1.3873 smmd=0.4288 ct=9.2807 rec=1.2216 | train/val/test=0.983/0.732/0.706 | c=0.998347
[Epoch 0071] loss=13.4039 cls=1.3035 smmd=0.3978 ct=9.2818 rec=1.2104 | train/val/test=0.983/0.734/0.704 | c=0.998347
[Epoch 0072] loss=13.0305 cls=0.9422 smmd=0.3862 ct=9.2848 rec=1.2087 | train/val/test=0.983/0.728/0.707 | c=0.998347
[Epoch 0073] loss=13.2251 cls=1.1653 smmd=0.3751 ct=9.2744 rec=1.2051 | train/val/test=0.983/0.728/0.706 | c=0.998347
[Epoch 0074] loss=13.2417 cls=1.1616 smmd=0.3939 ct=9.2730 rec=1.2066 | train/val/test=0.983/0.728/0.708 | c=0.998347
[Epoch 0075] loss=13.2751 cls=1.1725 smmd=0.4097 ct=9.2737 rec=1.2096 | train/val/test=0.983/0.734/0.705 | c=0.998347
[Epoch 0076] loss=13.1042 cls=1.0283 smmd=0.3991 ct=9.2709 rec=1.2030 | train/val/test=0.983/0.732/0.703 | c=0.998347
[Epoch 0077] loss=12.9586 cls=0.8954 smmd=0.3914 ct=9.2690 rec=1.2014 | train/val/test=0.983/0.732/0.704 | c=0.998347
[Epoch 0078] loss=13.1835 cls=1.1061 smmd=0.3863 ct=9.2827 rec=1.2042 | train/val/test=0.983/0.732/0.708 | c=0.998347
[Epoch 0079] loss=12.9385 cls=0.8988 smmd=0.3559 ct=9.2827 rec=1.2006 | train/val/test=0.983/0.730/0.708 | c=0.998347
[Epoch 0080] loss=13.1909 cls=1.1437 smmd=0.3613 ct=9.2788 rec=1.2036 | train/val/test=0.983/0.732/0.710 | c=0.998347
[Epoch 0081] loss=13.2346 cls=1.1984 smmd=0.3631 ct=9.2803 rec=1.1964 | train/val/test=0.983/0.734/0.708 | c=0.998347
[Epoch 0082] loss=13.1542 cls=1.0940 smmd=0.3738 ct=9.2822 rec=1.2021 | train/val/test=0.983/0.734/0.708 | c=0.998347
[Epoch 0083] loss=13.3885 cls=1.3071 smmd=0.3651 ct=9.2927 rec=1.2118 | train/val/test=0.983/0.732/0.709 | c=0.998347
[Epoch 0084] loss=13.1745 cls=1.1262 smmd=0.3723 ct=9.2758 rec=1.2002 | train/val/test=0.983/0.726/0.710 | c=0.998347
[Epoch 0085] loss=12.9559 cls=0.9233 smmd=0.3718 ct=9.2729 rec=1.1939 | train/val/test=0.983/0.728/0.709 | c=0.998347
[Epoch 0086] loss=12.9662 cls=0.9355 smmd=0.3559 ct=9.2748 rec=1.2000 | train/val/test=0.983/0.726/0.710 | c=0.998347
[Epoch 0087] loss=13.1802 cls=1.1460 smmd=0.3645 ct=9.2794 rec=1.1951 | train/val/test=0.983/0.726/0.709 | c=0.998347
[Epoch 0088] loss=13.1112 cls=1.0784 smmd=0.3612 ct=9.2745 rec=1.1986 | train/val/test=0.983/0.726/0.709 | c=0.998347
[Epoch 0089] loss=13.1337 cls=1.1178 smmd=0.3558 ct=9.2755 rec=1.1923 | train/val/test=0.983/0.726/0.710 | c=0.998347
[Epoch 0090] loss=13.2137 cls=1.1632 smmd=0.3563 ct=9.2819 rec=1.2062 | train/val/test=0.983/0.728/0.711 | c=0.998347
[Epoch 0091] loss=13.1468 cls=1.1300 smmd=0.3537 ct=9.2703 rec=1.1964 | train/val/test=0.983/0.728/0.710 | c=0.998347
[Epoch 0092] loss=13.4116 cls=1.3872 smmd=0.3510 ct=9.2786 rec=1.1974 | train/val/test=0.983/0.728/0.709 | c=0.998347
[Epoch 0093] loss=13.2879 cls=1.2520 smmd=0.3450 ct=9.2846 rec=1.2031 | train/val/test=0.983/0.728/0.708 | c=0.998347
[Epoch 0094] loss=12.9146 cls=0.8981 smmd=0.3522 ct=9.2775 rec=1.1934 | train/val/test=0.983/0.728/0.707 | c=0.998347
[Epoch 0095] loss=13.0242 cls=0.9909 smmd=0.3539 ct=9.2748 rec=1.2023 | train/val/test=0.983/0.730/0.707 | c=0.998347
[Epoch 0096] loss=13.1684 cls=1.1374 smmd=0.3412 ct=9.2780 rec=1.2059 | train/val/test=0.983/0.730/0.708 | c=0.998347
[Epoch 0097] loss=12.9274 cls=0.9174 smmd=0.3506 ct=9.2681 rec=1.1956 | train/val/test=0.983/0.730/0.708 | c=0.998347
[Epoch 0098] loss=13.0968 cls=1.0721 smmd=0.3451 ct=9.2802 rec=1.1997 | train/val/test=0.983/0.730/0.709 | c=0.998347
[Epoch 0099] loss=13.2467 cls=1.2317 smmd=0.3346 ct=9.2767 rec=1.2018 | train/val/test=0.983/0.730/0.709 | c=0.998347
=== Best @ epoch 18: val=0.7500, test=0.7310 ===
