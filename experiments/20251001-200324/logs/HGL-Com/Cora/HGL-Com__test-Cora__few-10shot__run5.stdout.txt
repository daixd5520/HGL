Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.1373 cls=2.1279 smmd=4.0048 ct=9.2253 rec=1.3897 | train/val/test=0.224/0.122/0.135 | c=0.998347
[Epoch 0001] loss=17.9718 cls=2.0723 smmd=3.9019 ct=9.2217 rec=1.3879 | train/val/test=0.155/0.164/0.152 | c=0.998347
[Epoch 0002] loss=17.6989 cls=1.9559 smmd=3.7465 ct=9.2169 rec=1.3898 | train/val/test=0.276/0.204/0.196 | c=0.998347
[Epoch 0003] loss=17.4909 cls=1.9341 smmd=3.5746 ct=9.2070 rec=1.3876 | train/val/test=0.638/0.330/0.318 | c=0.998347
[Epoch 0004] loss=17.1038 cls=1.8221 smmd=3.3205 ct=9.1894 rec=1.3859 | train/val/test=0.621/0.338/0.334 | c=0.998347
[Epoch 0005] loss=16.6618 cls=1.7256 smmd=3.0006 ct=9.1652 rec=1.3852 | train/val/test=0.724/0.328/0.337 | c=0.998347
[Epoch 0006] loss=16.1925 cls=1.6969 smmd=2.6225 ct=9.1203 rec=1.3764 | train/val/test=0.862/0.456/0.478 | c=0.998347
[Epoch 0007] loss=15.8301 cls=1.8416 smmd=2.1967 ct=9.0611 rec=1.3654 | train/val/test=0.914/0.546/0.558 | c=0.998347
[Epoch 0008] loss=14.8653 cls=1.4296 smmd=1.7642 ct=8.9823 rec=1.3446 | train/val/test=0.897/0.582/0.551 | c=0.998347
[Epoch 0009] loss=14.3195 cls=1.3444 smmd=1.4417 ct=8.8991 rec=1.3171 | train/val/test=0.897/0.590/0.563 | c=0.998347
[Epoch 0010] loss=14.0058 cls=1.2801 smmd=1.3004 ct=8.8411 rec=1.2921 | train/val/test=0.879/0.574/0.559 | c=0.998347
[Epoch 0011] loss=14.7086 cls=1.2849 smmd=1.3429 ct=9.5400 rec=1.2704 | train/val/test=0.897/0.562/0.557 | c=0.998347
[Epoch 0012] loss=15.0284 cls=1.4921 smmd=1.5453 ct=9.4563 rec=1.2674 | train/val/test=0.897/0.534/0.530 | c=0.998347
[Epoch 0013] loss=14.7155 cls=1.0675 smmd=1.7558 ct=9.3606 rec=1.2658 | train/val/test=0.897/0.606/0.589 | c=0.998347
[Epoch 0014] loss=14.8236 cls=1.1373 smmd=1.9172 ct=9.2601 rec=1.2545 | train/val/test=0.948/0.702/0.672 | c=0.998347
[Epoch 0015] loss=14.9175 cls=1.1680 smmd=2.0316 ct=9.2304 rec=1.2438 | train/val/test=0.948/0.684/0.686 | c=0.998347
[Epoch 0016] loss=15.1470 cls=1.4101 smmd=2.0266 ct=9.2217 rec=1.2442 | train/val/test=0.948/0.710/0.701 | c=0.998347
[Epoch 0017] loss=14.7289 cls=1.1251 smmd=1.9745 ct=9.1723 rec=1.2285 | train/val/test=0.966/0.726/0.712 | c=0.998347
[Epoch 0018] loss=14.6166 cls=1.1374 smmd=1.8527 ct=9.1779 rec=1.2243 | train/val/test=0.966/0.726/0.680 | c=0.998347
[Epoch 0019] loss=14.5032 cls=1.2000 smmd=1.6776 ct=9.1913 rec=1.2171 | train/val/test=0.948/0.682/0.653 | c=0.998347
[Epoch 0020] loss=14.0400 cls=0.8905 smmd=1.4988 ct=9.2286 rec=1.2110 | train/val/test=0.931/0.646/0.613 | c=0.998347
[Epoch 0021] loss=14.1817 cls=1.1397 smmd=1.3471 ct=9.2733 rec=1.2108 | train/val/test=0.897/0.656/0.627 | c=0.998347
[Epoch 0022] loss=14.2207 cls=1.2049 smmd=1.2897 ct=9.3185 rec=1.2038 | train/val/test=0.966/0.702/0.672 | c=0.998347
[Epoch 0023] loss=14.3162 cls=1.2702 smmd=1.2883 ct=9.3556 rec=1.2011 | train/val/test=1.000/0.730/0.690 | c=0.998347
[Epoch 0024] loss=14.2644 cls=1.1870 smmd=1.2953 ct=9.3803 rec=1.2010 | train/val/test=1.000/0.712/0.679 | c=0.998347
[Epoch 0025] loss=14.2963 cls=1.1890 smmd=1.3107 ct=9.3827 rec=1.2069 | train/val/test=0.966/0.700/0.679 | c=0.998347
[Epoch 0026] loss=14.1961 cls=1.1138 smmd=1.2876 ct=9.3672 rec=1.2138 | train/val/test=0.966/0.702/0.692 | c=0.998347
[Epoch 0027] loss=14.0697 cls=1.0397 smmd=1.2359 ct=9.3579 rec=1.2181 | train/val/test=0.983/0.720/0.701 | c=0.998347
[Epoch 0028] loss=14.1514 cls=1.1874 smmd=1.1910 ct=9.3430 rec=1.2150 | train/val/test=0.983/0.718/0.704 | c=0.998347
[Epoch 0029] loss=14.0890 cls=1.2248 smmd=1.1059 ct=9.3305 rec=1.2139 | train/val/test=0.983/0.720/0.709 | c=0.998347
[Epoch 0030] loss=14.0224 cls=1.1916 smmd=1.0789 ct=9.3262 rec=1.2129 | train/val/test=0.983/0.722/0.708 | c=0.998347
[Epoch 0031] loss=13.9895 cls=1.1773 smmd=1.0576 ct=9.3305 rec=1.2121 | train/val/test=1.000/0.722/0.712 | c=0.998347
[Epoch 0032] loss=13.8833 cls=1.0943 smmd=1.0508 ct=9.3208 rec=1.2087 | train/val/test=1.000/0.736/0.717 | c=0.998347
[Epoch 0033] loss=13.8781 cls=1.0907 smmd=1.0503 ct=9.3173 rec=1.2099 | train/val/test=1.000/0.702/0.718 | c=0.998347
[Epoch 0034] loss=14.0532 cls=1.2907 smmd=1.0283 ct=9.3182 rec=1.2080 | train/val/test=1.000/0.704/0.715 | c=0.998347
[Epoch 0035] loss=13.7857 cls=1.0423 smmd=0.9997 ct=9.3275 rec=1.2081 | train/val/test=1.000/0.700/0.698 | c=0.998347
[Epoch 0036] loss=13.7623 cls=1.0960 smmd=0.9450 ct=9.3221 rec=1.1996 | train/val/test=1.000/0.688/0.698 | c=0.998347
[Epoch 0037] loss=13.6280 cls=0.9915 smmd=0.9130 ct=9.3212 rec=1.2011 | train/val/test=1.000/0.702/0.698 | c=0.998347
[Epoch 0038] loss=14.2636 cls=1.6098 smmd=0.8941 ct=9.3288 rec=1.2155 | train/val/test=1.000/0.704/0.707 | c=0.998347
[Epoch 0039] loss=13.9906 cls=1.4016 smmd=0.8484 ct=9.3328 rec=1.2039 | train/val/test=1.000/0.710/0.721 | c=0.998347
[Epoch 0040] loss=13.7570 cls=1.1973 smmd=0.8134 ct=9.3328 rec=1.2068 | train/val/test=1.000/0.710/0.716 | c=0.998347
[Epoch 0041] loss=13.8274 cls=1.2571 smmd=0.8052 ct=9.3299 rec=1.2175 | train/val/test=0.983/0.702/0.711 | c=0.998347
[Epoch 0042] loss=13.7243 cls=1.1513 smmd=0.7878 ct=9.3370 rec=1.2241 | train/val/test=0.966/0.690/0.698 | c=0.998347
[Epoch 0043] loss=13.8066 cls=1.2710 smmd=0.7513 ct=9.3380 rec=1.2232 | train/val/test=0.966/0.692/0.695 | c=0.998347
[Epoch 0044] loss=13.6706 cls=1.1492 smmd=0.7460 ct=9.3376 rec=1.2189 | train/val/test=0.966/0.698/0.693 | c=0.998347
[Epoch 0045] loss=13.5929 cls=1.0865 smmd=0.7166 ct=9.3359 rec=1.2269 | train/val/test=0.966/0.718/0.697 | c=0.998347
[Epoch 0046] loss=13.8338 cls=1.3792 smmd=0.6876 ct=9.3204 rec=1.2233 | train/val/test=0.983/0.708/0.710 | c=0.998347
[Epoch 0047] loss=13.7212 cls=1.2796 smmd=0.6801 ct=9.3173 rec=1.2221 | train/val/test=0.983/0.700/0.712 | c=0.998347
[Epoch 0048] loss=13.5959 cls=1.1832 smmd=0.6345 ct=9.3227 rec=1.2277 | train/val/test=0.983/0.704/0.712 | c=0.998347
[Epoch 0049] loss=13.7020 cls=1.2933 smmd=0.6515 ct=9.3185 rec=1.2193 | train/val/test=0.983/0.706/0.694 | c=0.998347
[Epoch 0050] loss=13.5020 cls=1.1145 smmd=0.6336 ct=9.3192 rec=1.2174 | train/val/test=0.966/0.694/0.680 | c=0.998347
[Epoch 0051] loss=13.5814 cls=1.1965 smmd=0.6202 ct=9.3168 rec=1.2239 | train/val/test=0.966/0.688/0.685 | c=0.998347
[Epoch 0052] loss=13.7050 cls=1.3522 smmd=0.5813 ct=9.3147 rec=1.2284 | train/val/test=0.966/0.702/0.712 | c=0.998347
[Epoch 0053] loss=13.7454 cls=1.4400 smmd=0.5599 ct=9.3161 rec=1.2147 | train/val/test=0.966/0.708/0.733 | c=0.998347
[Epoch 0054] loss=13.3364 cls=1.0339 smmd=0.5383 ct=9.3222 rec=1.2210 | train/val/test=0.966/0.706/0.722 | c=0.998347
[Epoch 0055] loss=13.2923 cls=1.0531 smmd=0.5114 ct=9.3244 rec=1.2017 | train/val/test=0.966/0.702/0.723 | c=0.998347
[Epoch 0056] loss=13.5714 cls=1.3087 smmd=0.4993 ct=9.3353 rec=1.2140 | train/val/test=0.983/0.700/0.714 | c=0.998347
[Epoch 0057] loss=13.4884 cls=1.2606 smmd=0.4938 ct=9.3190 rec=1.2075 | train/val/test=0.966/0.702/0.713 | c=0.998347
[Epoch 0058] loss=13.3140 cls=1.0591 smmd=0.4771 ct=9.3255 rec=1.2261 | train/val/test=0.966/0.706/0.718 | c=0.998347
[Epoch 0059] loss=13.7816 cls=1.5684 smmd=0.4766 ct=9.3256 rec=1.2055 | train/val/test=0.966/0.714/0.720 | c=0.998347
[Epoch 0060] loss=13.4044 cls=1.1500 smmd=0.4641 ct=9.3321 rec=1.2291 | train/val/test=0.983/0.714/0.724 | c=0.998347
[Epoch 0061] loss=13.5506 cls=1.3637 smmd=0.4401 ct=9.3266 rec=1.2101 | train/val/test=0.983/0.716/0.721 | c=0.998347
[Epoch 0062] loss=13.7193 cls=1.5398 smmd=0.4379 ct=9.3214 rec=1.2102 | train/val/test=0.983/0.712/0.725 | c=0.998347
[Epoch 0063] loss=13.3963 cls=1.2502 smmd=0.4163 ct=9.3189 rec=1.2055 | train/val/test=0.966/0.712/0.726 | c=0.998347
[Epoch 0064] loss=13.4233 cls=1.2605 smmd=0.4139 ct=9.3279 rec=1.2106 | train/val/test=0.966/0.714/0.720 | c=0.998347
[Epoch 0065] loss=13.1585 cls=1.0062 smmd=0.4278 ct=9.3201 rec=1.2022 | train/val/test=0.966/0.710/0.715 | c=0.998347
[Epoch 0066] loss=13.4882 cls=1.3370 smmd=0.4050 ct=9.3316 rec=1.2074 | train/val/test=0.966/0.708/0.724 | c=0.998347
[Epoch 0067] loss=13.2633 cls=1.1274 smmd=0.3956 ct=9.3196 rec=1.2104 | train/val/test=0.966/0.716/0.735 | c=0.998347
[Epoch 0068] loss=13.2097 cls=1.0818 smmd=0.3854 ct=9.3246 rec=1.2090 | train/val/test=0.966/0.720/0.736 | c=0.998347
[Epoch 0069] loss=13.4479 cls=1.3138 smmd=0.3865 ct=9.3307 rec=1.2085 | train/val/test=0.966/0.726/0.739 | c=0.998347
[Epoch 0070] loss=13.1345 cls=1.0139 smmd=0.3670 ct=9.3262 rec=1.2137 | train/val/test=0.966/0.726/0.738 | c=0.998347
[Epoch 0071] loss=13.1599 cls=1.0475 smmd=0.3819 ct=9.3205 rec=1.2050 | train/val/test=0.966/0.724/0.732 | c=0.998347
[Epoch 0072] loss=13.3107 cls=1.2367 smmd=0.3471 ct=9.3209 rec=1.2030 | train/val/test=0.966/0.724/0.731 | c=0.998347
[Epoch 0073] loss=13.1011 cls=1.0175 smmd=0.3561 ct=9.3142 rec=1.2066 | train/val/test=0.966/0.724/0.731 | c=0.998347
[Epoch 0074] loss=13.2782 cls=1.1985 smmd=0.3478 ct=9.3240 rec=1.2040 | train/val/test=0.966/0.722/0.732 | c=0.998347
[Epoch 0075] loss=13.1545 cls=1.0849 smmd=0.3472 ct=9.3276 rec=1.1974 | train/val/test=0.966/0.718/0.734 | c=0.998347
[Epoch 0076] loss=13.1157 cls=1.0477 smmd=0.3410 ct=9.3213 rec=1.2029 | train/val/test=0.966/0.718/0.736 | c=0.998347
[Epoch 0077] loss=13.3140 cls=1.2538 smmd=0.3457 ct=9.3232 rec=1.1956 | train/val/test=0.966/0.724/0.733 | c=0.998347
[Epoch 0078] loss=13.2001 cls=1.1416 smmd=0.3366 ct=9.3146 rec=1.2037 | train/val/test=0.966/0.724/0.732 | c=0.998347
[Epoch 0079] loss=13.2278 cls=1.1706 smmd=0.3318 ct=9.3196 rec=1.2029 | train/val/test=0.966/0.724/0.731 | c=0.998347
[Epoch 0080] loss=13.5148 cls=1.4461 smmd=0.3412 ct=9.3227 rec=1.2025 | train/val/test=0.983/0.720/0.730 | c=0.998347
[Epoch 0081] loss=13.1223 cls=1.0408 smmd=0.3549 ct=9.3174 rec=1.2046 | train/val/test=0.983/0.720/0.729 | c=0.998347
[Epoch 0082] loss=13.3090 cls=1.2418 smmd=0.3397 ct=9.3254 rec=1.2011 | train/val/test=0.983/0.718/0.730 | c=0.998347
[Epoch 0083] loss=13.0941 cls=1.0434 smmd=0.3327 ct=9.3188 rec=1.1996 | train/val/test=0.983/0.718/0.730 | c=0.998347
[Epoch 0084] loss=12.9225 cls=0.8918 smmd=0.3136 ct=9.3243 rec=1.1964 | train/val/test=0.983/0.722/0.731 | c=0.998347
[Epoch 0085] loss=13.1335 cls=1.1004 smmd=0.3284 ct=9.3171 rec=1.1938 | train/val/test=0.983/0.720/0.731 | c=0.998347
[Epoch 0086] loss=13.1098 cls=1.0721 smmd=0.3176 ct=9.3204 rec=1.1999 | train/val/test=0.983/0.720/0.733 | c=0.998347
[Epoch 0087] loss=12.9275 cls=0.8913 smmd=0.3291 ct=9.3261 rec=1.1905 | train/val/test=0.983/0.720/0.732 | c=0.998347
[Epoch 0088] loss=12.9759 cls=0.9327 smmd=0.3328 ct=9.3286 rec=1.1909 | train/val/test=0.983/0.720/0.732 | c=0.998347
[Epoch 0089] loss=13.0296 cls=0.9901 smmd=0.3161 ct=9.3247 rec=1.1994 | train/val/test=0.983/0.720/0.732 | c=0.998347
[Epoch 0090] loss=12.9328 cls=0.8879 smmd=0.3157 ct=9.3283 rec=1.2005 | train/val/test=0.983/0.726/0.734 | c=0.998347
[Epoch 0091] loss=13.4941 cls=1.4524 smmd=0.3181 ct=9.3196 rec=1.2020 | train/val/test=0.983/0.726/0.736 | c=0.998347
[Epoch 0092] loss=13.2164 cls=1.1736 smmd=0.3263 ct=9.3256 rec=1.1954 | train/val/test=0.983/0.726/0.735 | c=0.998347
[Epoch 0093] loss=13.2081 cls=1.1703 smmd=0.3224 ct=9.3240 rec=1.1957 | train/val/test=0.983/0.726/0.734 | c=0.998347
[Epoch 0094] loss=13.2204 cls=1.1781 smmd=0.3224 ct=9.3264 rec=1.1968 | train/val/test=0.983/0.726/0.734 | c=0.998347
[Epoch 0095] loss=12.8349 cls=0.8091 smmd=0.3203 ct=9.3194 rec=1.1931 | train/val/test=0.983/0.726/0.733 | c=0.998347
[Epoch 0096] loss=13.0505 cls=1.0249 smmd=0.3108 ct=9.3212 rec=1.1968 | train/val/test=0.983/0.726/0.733 | c=0.998347
[Epoch 0097] loss=13.0899 cls=1.0520 smmd=0.3216 ct=9.3170 rec=1.1996 | train/val/test=0.983/0.726/0.733 | c=0.998347
[Epoch 0098] loss=13.2503 cls=1.1960 smmd=0.3360 ct=9.3245 rec=1.1970 | train/val/test=0.983/0.726/0.733 | c=0.998347
[Epoch 0099] loss=13.3953 cls=1.3616 smmd=0.3192 ct=9.3198 rec=1.1973 | train/val/test=0.983/0.726/0.733 | c=0.998347
=== Best @ epoch 32: val=0.7360, test=0.7170 ===
