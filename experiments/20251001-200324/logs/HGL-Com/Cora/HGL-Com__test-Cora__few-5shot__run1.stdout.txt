Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.3831 cls=2.2927 smmd=4.0130 ct=9.2563 rec=1.4105 | train/val/test=0.172/0.114/0.138 | c=0.998347
[Epoch 0001] loss=18.0475 cls=2.0586 smmd=3.9588 ct=9.2522 rec=1.3889 | train/val/test=0.310/0.224/0.241 | c=0.998347
[Epoch 0002] loss=17.8005 cls=1.9267 smmd=3.8416 ct=9.2481 rec=1.3920 | train/val/test=0.345/0.208/0.268 | c=0.998347
[Epoch 0003] loss=17.6667 cls=1.9645 smmd=3.6779 ct=9.2419 rec=1.3912 | train/val/test=0.483/0.172/0.177 | c=0.998347
[Epoch 0004] loss=17.5604 cls=2.0874 smmd=3.4658 ct=9.2286 rec=1.3893 | train/val/test=0.690/0.268/0.297 | c=0.998347
[Epoch 0005] loss=17.1140 cls=1.9261 smmd=3.2119 ct=9.2065 rec=1.3848 | train/val/test=0.655/0.232/0.255 | c=0.998347
[Epoch 0006] loss=16.4127 cls=1.6039 smmd=2.8653 ct=9.1774 rec=1.3830 | train/val/test=0.862/0.394/0.433 | c=0.998347
[Epoch 0007] loss=16.0871 cls=1.6685 smmd=2.5018 ct=9.1636 rec=1.3766 | train/val/test=0.552/0.228/0.229 | c=0.998347
[Epoch 0008] loss=15.4918 cls=1.5346 smmd=2.0289 ct=9.1515 rec=1.3884 | train/val/test=0.897/0.388/0.425 | c=0.998347
[Epoch 0009] loss=14.6193 cls=1.2197 smmd=1.6185 ct=9.0716 rec=1.3548 | train/val/test=0.897/0.418/0.452 | c=0.998347
[Epoch 0010] loss=14.3094 cls=1.4082 smmd=1.2733 ct=8.9712 rec=1.3284 | train/val/test=0.862/0.420/0.441 | c=0.998347
[Epoch 0011] loss=14.3170 cls=1.4547 smmd=1.2048 ct=9.0023 rec=1.3275 | train/val/test=0.897/0.512/0.516 | c=0.998347
[Epoch 0012] loss=14.0390 cls=1.1736 smmd=1.3019 ct=8.9430 rec=1.3103 | train/val/test=0.966/0.594/0.593 | c=0.998347
[Epoch 0013] loss=14.1171 cls=1.1494 smmd=1.4852 ct=8.8824 rec=1.3000 | train/val/test=0.966/0.566/0.574 | c=0.998347
[Epoch 0014] loss=14.2577 cls=1.0619 smmd=1.7022 ct=8.9064 rec=1.2935 | train/val/test=0.966/0.554/0.580 | c=0.998347
[Epoch 0015] loss=14.0586 cls=0.7549 smmd=1.8195 ct=8.9122 rec=1.2860 | train/val/test=0.966/0.560/0.586 | c=0.998347
[Epoch 0016] loss=14.2158 cls=0.9958 smmd=1.8413 ct=8.8440 rec=1.2673 | train/val/test=0.966/0.574/0.595 | c=0.998347
[Epoch 0017] loss=13.9066 cls=0.8359 smmd=1.7639 ct=8.8091 rec=1.2488 | train/val/test=0.966/0.584/0.612 | c=0.998347
[Epoch 0018] loss=13.9401 cls=0.9546 smmd=1.6578 ct=8.8386 rec=1.2445 | train/val/test=0.931/0.588/0.621 | c=0.998347
[Epoch 0019] loss=14.1924 cls=1.3607 smmd=1.5170 ct=8.8344 rec=1.2401 | train/val/test=0.931/0.590/0.623 | c=0.998347
[Epoch 0020] loss=13.5300 cls=0.9014 smmd=1.3651 ct=8.8056 rec=1.2290 | train/val/test=0.966/0.586/0.610 | c=0.998347
[Epoch 0021] loss=13.7363 cls=1.2317 smmd=1.2414 ct=8.7969 rec=1.2331 | train/val/test=0.931/0.578/0.608 | c=0.998347
[Epoch 0022] loss=13.3749 cls=0.9236 smmd=1.1755 ct=8.8154 rec=1.2302 | train/val/test=0.966/0.584/0.604 | c=0.998347
[Epoch 0023] loss=13.6854 cls=1.1561 smmd=1.2212 ct=8.8515 rec=1.2284 | train/val/test=0.966/0.588/0.605 | c=0.998347
[Epoch 0024] loss=13.5182 cls=1.0306 smmd=1.2187 ct=8.8272 rec=1.2208 | train/val/test=1.000/0.606/0.629 | c=0.998347
[Epoch 0025] loss=14.2043 cls=1.7511 smmd=1.2246 ct=8.8009 rec=1.2138 | train/val/test=1.000/0.632/0.639 | c=0.998347
[Epoch 0026] loss=13.2550 cls=0.8050 smmd=1.1994 ct=8.8062 rec=1.2222 | train/val/test=1.000/0.646/0.658 | c=0.998347
[Epoch 0027] loss=13.3199 cls=0.8543 smmd=1.2135 ct=8.8097 rec=1.2212 | train/val/test=1.000/0.642/0.644 | c=0.998347
[Epoch 0028] loss=14.0851 cls=1.6668 smmd=1.1487 ct=8.8118 rec=1.2289 | train/val/test=1.000/0.628/0.630 | c=0.998347
[Epoch 0029] loss=13.4978 cls=1.1196 smmd=1.1186 ct=8.7981 rec=1.2308 | train/val/test=1.000/0.616/0.613 | c=0.998347
[Epoch 0030] loss=13.3004 cls=0.9965 smmd=1.0642 ct=8.7796 rec=1.2300 | train/val/test=1.000/0.588/0.587 | c=0.998347
[Epoch 0031] loss=13.3475 cls=1.0920 smmd=1.0080 ct=8.7716 rec=1.2380 | train/val/test=0.966/0.562/0.573 | c=0.998347
[Epoch 0032] loss=13.3502 cls=1.0789 smmd=1.0180 ct=8.7815 rec=1.2359 | train/val/test=0.966/0.570/0.579 | c=0.998347
[Epoch 0033] loss=13.3234 cls=1.0540 smmd=1.0056 ct=8.7783 rec=1.2428 | train/val/test=0.966/0.580/0.587 | c=0.998347
[Epoch 0034] loss=13.5755 cls=1.3049 smmd=1.0028 ct=8.7770 rec=1.2454 | train/val/test=1.000/0.600/0.612 | c=0.998347
[Epoch 0035] loss=13.0883 cls=0.8557 smmd=0.9842 ct=8.7758 rec=1.2363 | train/val/test=1.000/0.626/0.637 | c=0.998347
[Epoch 0036] loss=13.4900 cls=1.2360 smmd=0.9801 ct=8.7737 rec=1.2501 | train/val/test=1.000/0.626/0.641 | c=0.998347
[Epoch 0037] loss=13.2639 cls=1.0570 smmd=0.9389 ct=8.7734 rec=1.2473 | train/val/test=1.000/0.624/0.632 | c=0.998347
[Epoch 0038] loss=13.2917 cls=1.1045 smmd=0.9138 ct=8.7800 rec=1.2467 | train/val/test=1.000/0.618/0.623 | c=0.998347
[Epoch 0039] loss=12.9452 cls=0.8369 smmd=0.8600 ct=8.7771 rec=1.2356 | train/val/test=1.000/0.610/0.617 | c=0.998347
[Epoch 0040] loss=13.2250 cls=1.0707 smmd=0.8600 ct=8.7833 rec=1.2555 | train/val/test=1.000/0.614/0.612 | c=0.998347
[Epoch 0041] loss=12.8911 cls=0.8109 smmd=0.8374 ct=8.7698 rec=1.2365 | train/val/test=1.000/0.618/0.619 | c=0.998347
[Epoch 0042] loss=12.7738 cls=0.7039 smmd=0.8193 ct=8.7710 rec=1.2398 | train/val/test=1.000/0.628/0.632 | c=0.998347
[Epoch 0043] loss=13.5213 cls=0.7982 smmd=0.8002 ct=9.4781 rec=1.2224 | train/val/test=1.000/0.632/0.647 | c=0.998347
[Epoch 0044] loss=13.7013 cls=1.0156 smmd=0.7802 ct=9.4563 rec=1.2246 | train/val/test=1.000/0.644/0.654 | c=0.998347
[Epoch 0045] loss=13.5817 cls=0.9525 smmd=0.7739 ct=9.4077 rec=1.2238 | train/val/test=0.966/0.648/0.660 | c=0.998347
[Epoch 0046] loss=13.9162 cls=1.3259 smmd=0.7861 ct=9.3680 rec=1.2181 | train/val/test=0.966/0.640/0.659 | c=0.998347
[Epoch 0047] loss=13.1875 cls=0.5893 smmd=0.8264 ct=9.3421 rec=1.2148 | train/val/test=0.966/0.642/0.650 | c=0.998347
[Epoch 0048] loss=13.7614 cls=1.2169 smmd=0.8025 ct=9.3232 rec=1.2094 | train/val/test=0.966/0.632/0.638 | c=0.998347
[Epoch 0049] loss=13.5028 cls=0.9654 smmd=0.7732 ct=9.3192 rec=1.2225 | train/val/test=0.966/0.634/0.632 | c=0.998347
[Epoch 0050] loss=14.0704 cls=1.5596 smmd=0.7597 ct=9.3204 rec=1.2154 | train/val/test=0.966/0.648/0.632 | c=0.998347
[Epoch 0051] loss=13.4006 cls=0.9360 smmd=0.7118 ct=9.3380 rec=1.2074 | train/val/test=0.966/0.644/0.640 | c=0.998347
[Epoch 0052] loss=13.6790 cls=1.2235 smmd=0.6797 ct=9.3616 rec=1.2071 | train/val/test=0.966/0.646/0.645 | c=0.998347
[Epoch 0053] loss=13.4575 cls=1.0181 smmd=0.6304 ct=9.3909 rec=1.2090 | train/val/test=0.966/0.652/0.656 | c=0.998347
[Epoch 0054] loss=13.4164 cls=0.9720 smmd=0.6161 ct=9.4167 rec=1.2058 | train/val/test=0.966/0.656/0.656 | c=0.998347
[Epoch 0055] loss=13.5518 cls=1.0915 smmd=0.6116 ct=9.4257 rec=1.2115 | train/val/test=0.966/0.662/0.659 | c=0.998347
[Epoch 0056] loss=13.0584 cls=0.6369 smmd=0.5887 ct=9.4117 rec=1.2105 | train/val/test=0.966/0.672/0.666 | c=0.998347
[Epoch 0057] loss=13.3357 cls=0.9546 smmd=0.5852 ct=9.3888 rec=1.2035 | train/val/test=0.966/0.670/0.666 | c=0.998347
[Epoch 0058] loss=13.7226 cls=1.3476 smmd=0.5782 ct=9.3724 rec=1.2122 | train/val/test=1.000/0.658/0.649 | c=0.998347
[Epoch 0059] loss=13.1979 cls=0.8371 smmd=0.5992 ct=9.3518 rec=1.2049 | train/val/test=1.000/0.660/0.646 | c=0.998347
[Epoch 0060] loss=12.9583 cls=0.6232 smmd=0.5831 ct=9.3415 rec=1.2053 | train/val/test=1.000/0.654/0.646 | c=0.998347
[Epoch 0061] loss=12.9918 cls=0.6724 smmd=0.5735 ct=9.3400 rec=1.2030 | train/val/test=1.000/0.652/0.645 | c=0.998347
[Epoch 0062] loss=13.3445 cls=1.0335 smmd=0.5626 ct=9.3437 rec=1.2024 | train/val/test=1.000/0.648/0.647 | c=0.998347
[Epoch 0063] loss=13.3256 cls=1.0062 smmd=0.5419 ct=9.3620 rec=1.2077 | train/val/test=1.000/0.652/0.650 | c=0.998347
[Epoch 0064] loss=13.1281 cls=0.8295 smmd=0.5156 ct=9.3535 rec=1.2148 | train/val/test=1.000/0.654/0.655 | c=0.998347
[Epoch 0065] loss=13.3807 cls=1.0793 smmd=0.5306 ct=9.3527 rec=1.2090 | train/val/test=1.000/0.650/0.651 | c=0.998347
[Epoch 0066] loss=12.9198 cls=0.6630 smmd=0.5015 ct=9.3556 rec=1.1999 | train/val/test=1.000/0.650/0.648 | c=0.998347
[Epoch 0067] loss=13.4233 cls=1.1415 smmd=0.5065 ct=9.3635 rec=1.2059 | train/val/test=1.000/0.654/0.638 | c=0.998347
[Epoch 0068] loss=13.5750 cls=1.2843 smmd=0.4775 ct=9.3636 rec=1.2248 | train/val/test=1.000/0.660/0.639 | c=0.998347
[Epoch 0069] loss=13.1925 cls=0.9152 smmd=0.4807 ct=9.3692 rec=1.2137 | train/val/test=1.000/0.656/0.643 | c=0.998347
[Epoch 0070] loss=13.1268 cls=0.9022 smmd=0.4589 ct=9.3637 rec=1.2010 | train/val/test=1.000/0.656/0.653 | c=0.998347
[Epoch 0071] loss=13.1376 cls=0.8957 smmd=0.4726 ct=9.3622 rec=1.2035 | train/val/test=1.000/0.656/0.657 | c=0.998347
[Epoch 0072] loss=12.8456 cls=0.5945 smmd=0.4581 ct=9.3654 rec=1.2138 | train/val/test=1.000/0.660/0.655 | c=0.998347
[Epoch 0073] loss=12.9208 cls=0.7122 smmd=0.4590 ct=9.3588 rec=1.1954 | train/val/test=1.000/0.658/0.651 | c=0.998347
[Epoch 0074] loss=13.2734 cls=1.0452 smmd=0.4616 ct=9.3633 rec=1.2016 | train/val/test=1.000/0.658/0.654 | c=0.998347
[Epoch 0075] loss=13.1323 cls=0.9374 smmd=0.4442 ct=9.3597 rec=1.1955 | train/val/test=1.000/0.658/0.654 | c=0.998347
[Epoch 0076] loss=13.5270 cls=1.3065 smmd=0.4233 ct=9.3655 rec=1.2158 | train/val/test=1.000/0.656/0.655 | c=0.998347
[Epoch 0077] loss=13.3773 cls=1.1435 smmd=0.4480 ct=9.3673 rec=1.2092 | train/val/test=1.000/0.654/0.654 | c=0.998347
[Epoch 0078] loss=13.0633 cls=0.8832 smmd=0.4279 ct=9.3558 rec=1.1982 | train/val/test=1.000/0.650/0.652 | c=0.998347
[Epoch 0079] loss=12.9291 cls=0.7573 smmd=0.4253 ct=9.3628 rec=1.1918 | train/val/test=1.000/0.650/0.654 | c=0.998347
[Epoch 0080] loss=12.7769 cls=0.5889 smmd=0.4245 ct=9.3608 rec=1.2013 | train/val/test=1.000/0.644/0.654 | c=0.998347
[Epoch 0081] loss=13.3366 cls=1.1496 smmd=0.4278 ct=9.3560 rec=1.2016 | train/val/test=1.000/0.642/0.654 | c=0.998347
[Epoch 0082] loss=13.0211 cls=0.8659 smmd=0.4132 ct=9.3557 rec=1.1932 | train/val/test=1.000/0.644/0.651 | c=0.998347
[Epoch 0083] loss=13.0417 cls=0.8783 smmd=0.4185 ct=9.3555 rec=1.1947 | train/val/test=1.000/0.644/0.650 | c=0.998347
[Epoch 0084] loss=13.1964 cls=1.0493 smmd=0.4098 ct=9.3574 rec=1.1899 | train/val/test=1.000/0.644/0.649 | c=0.998347
[Epoch 0085] loss=12.8419 cls=0.6787 smmd=0.4185 ct=9.3628 rec=1.1909 | train/val/test=1.000/0.642/0.648 | c=0.998347
[Epoch 0086] loss=12.7783 cls=0.6136 smmd=0.4239 ct=9.3594 rec=1.1908 | train/val/test=1.000/0.640/0.649 | c=0.998347
[Epoch 0087] loss=13.5624 cls=1.3848 smmd=0.4066 ct=9.3667 rec=1.2021 | train/val/test=1.000/0.640/0.651 | c=0.998347
[Epoch 0088] loss=12.8830 cls=0.7218 smmd=0.4084 ct=9.3591 rec=1.1969 | train/val/test=1.000/0.638/0.650 | c=0.998347
[Epoch 0089] loss=12.9765 cls=0.8222 smmd=0.3971 ct=9.3590 rec=1.1991 | train/val/test=1.000/0.638/0.651 | c=0.998347
[Epoch 0090] loss=13.4067 cls=1.2392 smmd=0.4100 ct=9.3603 rec=1.1986 | train/val/test=1.000/0.638/0.653 | c=0.998347
[Epoch 0091] loss=13.0683 cls=0.9287 smmd=0.3972 ct=9.3548 rec=1.1938 | train/val/test=1.000/0.638/0.654 | c=0.998347
[Epoch 0092] loss=13.1285 cls=0.9652 smmd=0.3996 ct=9.3596 rec=1.2021 | train/val/test=1.000/0.638/0.655 | c=0.998347
[Epoch 0093] loss=12.9209 cls=0.7639 smmd=0.4203 ct=9.3525 rec=1.1921 | train/val/test=1.000/0.638/0.655 | c=0.998347
[Epoch 0094] loss=13.0478 cls=0.9003 smmd=0.4083 ct=9.3525 rec=1.1933 | train/val/test=1.000/0.638/0.654 | c=0.998347
[Epoch 0095] loss=13.1387 cls=1.0060 smmd=0.3952 ct=9.3532 rec=1.1922 | train/val/test=1.000/0.638/0.653 | c=0.998347
[Epoch 0096] loss=12.7499 cls=0.6105 smmd=0.3922 ct=9.3567 rec=1.1953 | train/val/test=1.000/0.638/0.653 | c=0.998347
[Epoch 0097] loss=13.0729 cls=0.9269 smmd=0.4043 ct=9.3542 rec=1.1938 | train/val/test=1.000/0.638/0.652 | c=0.998347
[Epoch 0098] loss=12.9927 cls=0.8661 smmd=0.3907 ct=9.3512 rec=1.1924 | train/val/test=1.000/0.638/0.652 | c=0.998347
[Epoch 0099] loss=13.0897 cls=0.9355 smmd=0.4180 ct=9.3544 rec=1.1909 | train/val/test=1.000/0.638/0.652 | c=0.998347
=== Best @ epoch 56: val=0.6720, test=0.6660 ===
