Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.1888 cls=2.1803 smmd=4.0007 ct=9.2228 rec=1.3925 | train/val/test=0.259/0.196/0.171 | c=0.998347
[Epoch 0001] loss=17.9349 cls=2.0051 smmd=3.9384 ct=9.2148 rec=1.3883 | train/val/test=0.276/0.214/0.195 | c=0.998347
[Epoch 0002] loss=17.6639 cls=1.8791 smmd=3.8004 ct=9.2083 rec=1.3881 | train/val/test=0.293/0.374/0.377 | c=0.998347
[Epoch 0003] loss=17.5045 cls=1.9268 smmd=3.6111 ct=9.1921 rec=1.3872 | train/val/test=0.569/0.320/0.315 | c=0.998347
[Epoch 0004] loss=17.1374 cls=1.8219 smmd=3.3787 ct=9.1697 rec=1.3836 | train/val/test=0.741/0.368/0.383 | c=0.998347
[Epoch 0005] loss=16.8703 cls=1.9019 smmd=3.0810 ct=9.1318 rec=1.3778 | train/val/test=0.793/0.444/0.463 | c=0.998347
[Epoch 0006] loss=16.0738 cls=1.5422 smmd=2.7172 ct=9.0824 rec=1.3660 | train/val/test=0.741/0.402/0.424 | c=0.998347
[Epoch 0007] loss=15.5903 cls=1.5492 smmd=2.3149 ct=9.0198 rec=1.3532 | train/val/test=0.845/0.462/0.459 | c=0.998347
[Epoch 0008] loss=15.0035 cls=1.5542 smmd=1.8390 ct=8.9453 rec=1.3326 | train/val/test=0.879/0.508/0.487 | c=0.998347
[Epoch 0009] loss=14.1483 cls=1.1831 smmd=1.4605 ct=8.8756 rec=1.3146 | train/val/test=0.897/0.604/0.577 | c=0.998347
[Epoch 0010] loss=14.2764 cls=1.5847 smmd=1.2762 ct=8.8430 rec=1.2862 | train/val/test=0.914/0.638/0.654 | c=0.998347
[Epoch 0011] loss=14.1371 cls=1.3983 smmd=1.3530 ct=8.8373 rec=1.2743 | train/val/test=0.914/0.652/0.645 | c=0.998347
[Epoch 0012] loss=14.0220 cls=1.1396 smmd=1.5335 ct=8.8234 rec=1.2628 | train/val/test=0.879/0.634/0.633 | c=0.998347
[Epoch 0013] loss=14.8218 cls=1.1095 smmd=1.6982 ct=9.5017 rec=1.2562 | train/val/test=0.897/0.674/0.655 | c=0.998347
[Epoch 0014] loss=15.0554 cls=1.3347 smmd=1.8234 ct=9.4008 rec=1.2483 | train/val/test=0.897/0.672/0.665 | c=0.998347
[Epoch 0015] loss=15.0127 cls=1.2783 smmd=1.9343 ct=9.3084 rec=1.2459 | train/val/test=0.914/0.670/0.672 | c=0.998347
[Epoch 0016] loss=14.8748 cls=1.2475 smmd=1.9419 ct=9.2195 rec=1.2329 | train/val/test=0.897/0.692/0.683 | c=0.998347
[Epoch 0017] loss=14.6266 cls=1.1036 smmd=1.9049 ct=9.1668 rec=1.2256 | train/val/test=0.914/0.696/0.688 | c=0.998347
[Epoch 0018] loss=14.6382 cls=1.2637 smmd=1.7621 ct=9.1616 rec=1.2254 | train/val/test=0.931/0.710/0.705 | c=0.998347
[Epoch 0019] loss=14.2488 cls=1.0204 smmd=1.6505 ct=9.1501 rec=1.2139 | train/val/test=0.948/0.732/0.706 | c=0.998347
[Epoch 0020] loss=14.5623 cls=1.5065 smmd=1.4811 ct=9.1574 rec=1.2087 | train/val/test=0.966/0.728/0.729 | c=0.998347
[Epoch 0021] loss=14.0683 cls=1.0921 smmd=1.3877 ct=9.1762 rec=1.2062 | train/val/test=0.948/0.724/0.716 | c=0.998347
[Epoch 0022] loss=14.1281 cls=1.1378 smmd=1.3474 ct=9.2273 rec=1.2078 | train/val/test=0.983/0.734/0.721 | c=0.998347
[Epoch 0023] loss=14.1094 cls=1.0982 smmd=1.3411 ct=9.2629 rec=1.2035 | train/val/test=1.000/0.728/0.725 | c=0.998347
[Epoch 0024] loss=14.2663 cls=1.2176 smmd=1.3565 ct=9.2829 rec=1.2047 | train/val/test=1.000/0.730/0.740 | c=0.998347
[Epoch 0025] loss=14.2382 cls=1.1817 smmd=1.3423 ct=9.2994 rec=1.2074 | train/val/test=1.000/0.734/0.737 | c=0.998347
[Epoch 0026] loss=14.2351 cls=1.2189 smmd=1.3055 ct=9.3033 rec=1.2037 | train/val/test=0.983/0.730/0.722 | c=0.998347
[Epoch 0027] loss=14.4644 cls=1.4991 smmd=1.2497 ct=9.3037 rec=1.2059 | train/val/test=0.966/0.702/0.708 | c=0.998347
[Epoch 0028] loss=13.9199 cls=1.0000 smmd=1.2149 ct=9.2856 rec=1.2096 | train/val/test=0.966/0.706/0.705 | c=0.998347
[Epoch 0029] loss=14.0527 cls=1.1975 smmd=1.1774 ct=9.2561 rec=1.2108 | train/val/test=0.948/0.714/0.708 | c=0.998347
[Epoch 0030] loss=14.2294 cls=1.3938 smmd=1.1571 ct=9.2468 rec=1.2159 | train/val/test=0.948/0.710/0.712 | c=0.998347
[Epoch 0031] loss=13.9964 cls=1.2140 smmd=1.1145 ct=9.2347 rec=1.2166 | train/val/test=0.948/0.710/0.712 | c=0.998347
[Epoch 0032] loss=13.9274 cls=1.1396 smmd=1.0946 ct=9.2575 rec=1.2179 | train/val/test=0.966/0.712/0.715 | c=0.998347
[Epoch 0033] loss=13.8447 cls=1.0611 smmd=1.0749 ct=9.2805 rec=1.2141 | train/val/test=0.966/0.712/0.723 | c=0.998347
[Epoch 0034] loss=13.9645 cls=1.2162 smmd=1.0535 ct=9.2789 rec=1.2080 | train/val/test=0.948/0.718/0.724 | c=0.998347
[Epoch 0035] loss=13.9452 cls=1.2208 smmd=1.0329 ct=9.2791 rec=1.2062 | train/val/test=0.966/0.722/0.721 | c=0.998347
[Epoch 0036] loss=13.6713 cls=0.9845 smmd=0.9928 ct=9.2779 rec=1.2080 | train/val/test=0.983/0.720/0.717 | c=0.998347
[Epoch 0037] loss=13.8321 cls=1.1501 smmd=0.9577 ct=9.2822 rec=1.2211 | train/val/test=0.983/0.726/0.715 | c=0.998347
[Epoch 0038] loss=13.8161 cls=1.2229 smmd=0.9330 ct=9.2484 rec=1.2059 | train/val/test=0.983/0.732/0.718 | c=0.998347
[Epoch 0039] loss=13.8964 cls=1.2991 smmd=0.9074 ct=9.2617 rec=1.2141 | train/val/test=0.983/0.734/0.711 | c=0.998347
[Epoch 0040] loss=13.8490 cls=1.2768 smmd=0.8994 ct=9.2594 rec=1.2067 | train/val/test=0.983/0.722/0.711 | c=0.998347
[Epoch 0041] loss=13.7567 cls=1.2120 smmd=0.8608 ct=9.2685 rec=1.2077 | train/val/test=0.983/0.722/0.709 | c=0.998347
[Epoch 0042] loss=13.7010 cls=1.1690 smmd=0.8316 ct=9.2847 rec=1.2078 | train/val/test=0.966/0.726/0.710 | c=0.998347
[Epoch 0043] loss=13.8013 cls=1.2686 smmd=0.8139 ct=9.3022 rec=1.2083 | train/val/test=1.000/0.728/0.712 | c=0.998347
[Epoch 0044] loss=13.5424 cls=1.0637 smmd=0.7418 ct=9.2994 rec=1.2188 | train/val/test=1.000/0.740/0.727 | c=0.998347
[Epoch 0045] loss=13.7420 cls=1.3088 smmd=0.7363 ct=9.2898 rec=1.2036 | train/val/test=1.000/0.744/0.731 | c=0.998347
[Epoch 0046] loss=13.4555 cls=1.0311 smmd=0.7326 ct=9.2749 rec=1.2085 | train/val/test=1.000/0.742/0.731 | c=0.998347
[Epoch 0047] loss=13.3749 cls=0.9879 smmd=0.7126 ct=9.2715 rec=1.2014 | train/val/test=1.000/0.738/0.727 | c=0.998347
[Epoch 0048] loss=13.4112 cls=1.0387 smmd=0.6853 ct=9.2615 rec=1.2129 | train/val/test=1.000/0.732/0.714 | c=0.998347
[Epoch 0049] loss=13.7999 cls=1.4849 smmd=0.6556 ct=9.2540 rec=1.2027 | train/val/test=1.000/0.726/0.708 | c=0.998347
[Epoch 0050] loss=13.8011 cls=1.4606 smmd=0.6268 ct=9.2911 rec=1.2113 | train/val/test=1.000/0.720/0.709 | c=0.998347
[Epoch 0051] loss=13.3214 cls=1.0324 smmd=0.5948 ct=9.2941 rec=1.2000 | train/val/test=1.000/0.722/0.717 | c=0.998347
[Epoch 0052] loss=13.7047 cls=1.4097 smmd=0.5868 ct=9.2840 rec=1.2121 | train/val/test=1.000/0.730/0.724 | c=0.998347
[Epoch 0053] loss=13.5264 cls=1.2452 smmd=0.5929 ct=9.2720 rec=1.2082 | train/val/test=1.000/0.730/0.727 | c=0.998347
[Epoch 0054] loss=13.3788 cls=1.1343 smmd=0.5592 ct=9.2708 rec=1.2073 | train/val/test=1.000/0.732/0.729 | c=0.998347
[Epoch 0055] loss=13.3290 cls=1.0821 smmd=0.5504 ct=9.2705 rec=1.2130 | train/val/test=0.983/0.732/0.720 | c=0.998347
[Epoch 0056] loss=13.4080 cls=1.1341 smmd=0.5445 ct=9.2961 rec=1.2167 | train/val/test=0.983/0.722/0.721 | c=0.998347
[Epoch 0057] loss=13.6379 cls=1.3470 smmd=0.5220 ct=9.3162 rec=1.2263 | train/val/test=0.983/0.728/0.727 | c=0.998347
[Epoch 0058] loss=13.4676 cls=1.2889 smmd=0.4697 ct=9.2885 rec=1.2103 | train/val/test=0.983/0.730/0.729 | c=0.998347
[Epoch 0059] loss=13.5223 cls=1.3186 smmd=0.4857 ct=9.2861 rec=1.2159 | train/val/test=1.000/0.732/0.723 | c=0.998347
[Epoch 0060] loss=13.4099 cls=1.2185 smmd=0.4758 ct=9.2826 rec=1.2165 | train/val/test=1.000/0.732/0.726 | c=0.998347
[Epoch 0061] loss=13.5238 cls=1.3547 smmd=0.4497 ct=9.2864 rec=1.2165 | train/val/test=1.000/0.730/0.727 | c=0.998347
[Epoch 0062] loss=13.3053 cls=1.1169 smmd=0.4573 ct=9.3041 rec=1.2135 | train/val/test=1.000/0.736/0.729 | c=0.998347
[Epoch 0063] loss=13.2604 cls=1.0926 smmd=0.4321 ct=9.3047 rec=1.2155 | train/val/test=1.000/0.730/0.728 | c=0.998347
[Epoch 0064] loss=13.3863 cls=1.2527 smmd=0.4216 ct=9.2910 rec=1.2105 | train/val/test=1.000/0.726/0.727 | c=0.998347
[Epoch 0065] loss=13.4496 cls=1.3281 smmd=0.4130 ct=9.2874 rec=1.2105 | train/val/test=1.000/0.728/0.729 | c=0.998347
[Epoch 0066] loss=13.4157 cls=1.2931 smmd=0.4226 ct=9.2824 rec=1.2088 | train/val/test=1.000/0.730/0.727 | c=0.998347
[Epoch 0067] loss=13.4117 cls=1.3127 smmd=0.3944 ct=9.2847 rec=1.2099 | train/val/test=1.000/0.734/0.728 | c=0.998347
[Epoch 0068] loss=13.0487 cls=0.9610 smmd=0.3900 ct=9.2931 rec=1.2023 | train/val/test=1.000/0.738/0.733 | c=0.998347
[Epoch 0069] loss=13.3344 cls=1.2530 smmd=0.3797 ct=9.2893 rec=1.2062 | train/val/test=1.000/0.732/0.744 | c=0.998347
[Epoch 0070] loss=13.2744 cls=1.1872 smmd=0.3878 ct=9.2881 rec=1.2057 | train/val/test=0.983/0.734/0.742 | c=0.998347
[Epoch 0071] loss=13.1378 cls=1.0602 smmd=0.3894 ct=9.2708 rec=1.2087 | train/val/test=0.983/0.730/0.741 | c=0.998347
[Epoch 0072] loss=13.3039 cls=1.2007 smmd=0.3883 ct=9.2961 rec=1.2094 | train/val/test=0.983/0.734/0.740 | c=0.998347
[Epoch 0073] loss=13.3256 cls=1.2324 smmd=0.3740 ct=9.3050 rec=1.2071 | train/val/test=0.983/0.732/0.738 | c=0.998347
[Epoch 0074] loss=13.3393 cls=1.2668 smmd=0.3598 ct=9.3004 rec=1.2061 | train/val/test=1.000/0.740/0.733 | c=0.998347
[Epoch 0075] loss=12.9145 cls=0.8904 smmd=0.3404 ct=9.2850 rec=1.1993 | train/val/test=1.000/0.738/0.733 | c=0.998347
[Epoch 0076] loss=13.1181 cls=1.0702 smmd=0.3503 ct=9.2923 rec=1.2026 | train/val/test=1.000/0.738/0.730 | c=0.998347
[Epoch 0077] loss=13.0436 cls=1.0105 smmd=0.3428 ct=9.2896 rec=1.2003 | train/val/test=1.000/0.736/0.730 | c=0.998347
[Epoch 0078] loss=13.2693 cls=1.2076 smmd=0.3451 ct=9.3033 rec=1.2066 | train/val/test=1.000/0.740/0.735 | c=0.998347
[Epoch 0079] loss=13.4317 cls=1.3892 smmd=0.3421 ct=9.2870 rec=1.2067 | train/val/test=1.000/0.740/0.739 | c=0.998347
[Epoch 0080] loss=13.2808 cls=1.2619 smmd=0.3189 ct=9.2824 rec=1.2088 | train/val/test=1.000/0.740/0.742 | c=0.998347
[Epoch 0081] loss=13.1578 cls=1.1251 smmd=0.3520 ct=9.2813 rec=1.1997 | train/val/test=1.000/0.738/0.741 | c=0.998347
[Epoch 0082] loss=13.0383 cls=1.0162 smmd=0.3399 ct=9.2841 rec=1.1990 | train/val/test=1.000/0.740/0.742 | c=0.998347
[Epoch 0083] loss=13.1287 cls=1.0902 smmd=0.3423 ct=9.2942 rec=1.2010 | train/val/test=1.000/0.740/0.743 | c=0.998347
[Epoch 0084] loss=13.1722 cls=1.1589 smmd=0.3312 ct=9.2858 rec=1.1982 | train/val/test=1.000/0.740/0.742 | c=0.998347
[Epoch 0085] loss=13.1257 cls=1.1249 smmd=0.3307 ct=9.2795 rec=1.1953 | train/val/test=1.000/0.740/0.739 | c=0.998347
[Epoch 0086] loss=13.0153 cls=1.0074 smmd=0.3247 ct=9.2916 rec=1.1957 | train/val/test=1.000/0.742/0.736 | c=0.998347
[Epoch 0087] loss=13.2589 cls=1.2244 smmd=0.3412 ct=9.2973 rec=1.1980 | train/val/test=1.000/0.740/0.736 | c=0.998347
[Epoch 0088] loss=13.3156 cls=1.2804 smmd=0.3234 ct=9.3036 rec=1.2041 | train/val/test=1.000/0.740/0.735 | c=0.998347
[Epoch 0089] loss=13.2349 cls=1.2286 smmd=0.3112 ct=9.2890 rec=1.2031 | train/val/test=1.000/0.740/0.734 | c=0.998347
[Epoch 0090] loss=13.1251 cls=1.1080 smmd=0.3137 ct=9.2981 rec=1.2026 | train/val/test=1.000/0.742/0.736 | c=0.998347
[Epoch 0091] loss=13.0356 cls=1.0310 smmd=0.3141 ct=9.2922 rec=1.1991 | train/val/test=1.000/0.742/0.734 | c=0.998347
[Epoch 0092] loss=13.1559 cls=1.1619 smmd=0.3164 ct=9.2938 rec=1.1919 | train/val/test=1.000/0.742/0.734 | c=0.998347
[Epoch 0093] loss=12.9261 cls=0.9106 smmd=0.3178 ct=9.2927 rec=1.2025 | train/val/test=1.000/0.742/0.734 | c=0.998347
[Epoch 0094] loss=13.3038 cls=1.2949 smmd=0.3199 ct=9.2922 rec=1.1983 | train/val/test=1.000/0.742/0.733 | c=0.998347
[Epoch 0095] loss=13.1269 cls=1.1397 smmd=0.3067 ct=9.2843 rec=1.1981 | train/val/test=1.000/0.740/0.734 | c=0.998347
[Epoch 0096] loss=12.9903 cls=1.0011 smmd=0.3087 ct=9.2834 rec=1.1986 | train/val/test=1.000/0.740/0.734 | c=0.998347
[Epoch 0097] loss=12.9887 cls=1.0022 smmd=0.3045 ct=9.2901 rec=1.1960 | train/val/test=1.000/0.740/0.734 | c=0.998347
[Epoch 0098] loss=13.1498 cls=1.1358 smmd=0.3180 ct=9.2890 rec=1.2035 | train/val/test=1.000/0.740/0.734 | c=0.998347
[Epoch 0099] loss=13.3342 cls=1.3179 smmd=0.3281 ct=9.2907 rec=1.1988 | train/val/test=1.000/0.740/0.734 | c=0.998347
=== Best @ epoch 45: val=0.7440, test=0.7310 ===
