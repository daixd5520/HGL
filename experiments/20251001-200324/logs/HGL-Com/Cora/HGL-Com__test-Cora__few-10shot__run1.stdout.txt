Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.1787 cls=2.1586 smmd=4.0119 ct=9.2296 rec=1.3893 | train/val/test=0.362/0.210/0.207 | c=0.998347
[Epoch 0001] loss=17.8734 cls=1.9554 smmd=3.9144 ct=9.2257 rec=1.3890 | train/val/test=0.397/0.190/0.204 | c=0.998347
[Epoch 0002] loss=17.6265 cls=1.8510 smmd=3.7779 ct=9.2196 rec=1.3890 | train/val/test=0.345/0.152/0.176 | c=0.998347
[Epoch 0003] loss=17.3647 cls=1.8034 smmd=3.5804 ct=9.2063 rec=1.3873 | train/val/test=0.690/0.358/0.359 | c=0.998347
[Epoch 0004] loss=17.1073 cls=1.7818 smmd=3.3737 ct=9.1840 rec=1.3839 | train/val/test=0.759/0.338/0.380 | c=0.998347
[Epoch 0005] loss=16.7613 cls=1.7876 smmd=3.0614 ct=9.1559 rec=1.3782 | train/val/test=0.810/0.366/0.385 | c=0.998347
[Epoch 0006] loss=16.1423 cls=1.6010 smmd=2.6915 ct=9.1100 rec=1.3699 | train/val/test=0.845/0.490/0.505 | c=0.998347
[Epoch 0007] loss=15.4997 cls=1.4871 smmd=2.2513 ct=9.0498 rec=1.3557 | train/val/test=0.914/0.518/0.510 | c=0.998347
[Epoch 0008] loss=14.8344 cls=1.3964 smmd=1.8026 ct=8.9686 rec=1.3334 | train/val/test=0.914/0.542/0.535 | c=0.998347
[Epoch 0009] loss=14.4179 cls=1.4342 smmd=1.4620 ct=8.9058 rec=1.3079 | train/val/test=0.931/0.584/0.570 | c=0.998347
[Epoch 0010] loss=13.8579 cls=1.1504 smmd=1.2767 ct=8.8651 rec=1.2829 | train/val/test=0.931/0.644/0.614 | c=0.998347
[Epoch 0011] loss=13.8767 cls=1.1773 smmd=1.3131 ct=8.8572 rec=1.2645 | train/val/test=0.948/0.668/0.643 | c=0.998347
[Epoch 0012] loss=13.9893 cls=1.1892 smmd=1.4693 ct=8.8310 rec=1.2499 | train/val/test=0.914/0.670/0.655 | c=0.998347
[Epoch 0013] loss=14.3033 cls=1.3554 smmd=1.6512 ct=8.8272 rec=1.2348 | train/val/test=0.931/0.700/0.687 | c=0.998347
[Epoch 0014] loss=14.2160 cls=1.1871 smmd=1.7789 ct=8.8023 rec=1.2239 | train/val/test=0.931/0.710/0.704 | c=0.998347
[Epoch 0015] loss=14.0204 cls=0.9408 smmd=1.8594 ct=8.7953 rec=1.2125 | train/val/test=0.931/0.718/0.684 | c=0.998347
[Epoch 0016] loss=14.2580 cls=1.2128 smmd=1.8328 ct=8.7970 rec=1.2077 | train/val/test=0.948/0.722/0.708 | c=0.998347
[Epoch 0017] loss=14.5357 cls=1.6000 smmd=1.7422 ct=8.7854 rec=1.2041 | train/val/test=0.983/0.708/0.716 | c=0.998347
[Epoch 0018] loss=13.9997 cls=1.2545 smmd=1.5663 ct=8.7756 rec=1.2017 | train/val/test=0.983/0.718/0.724 | c=0.998347
[Epoch 0019] loss=13.6221 cls=1.0380 smmd=1.4079 ct=8.7718 rec=1.2022 | train/val/test=1.000/0.718/0.738 | c=0.998347
[Epoch 0020] loss=13.8519 cls=1.4012 smmd=1.2491 ct=8.7773 rec=1.2121 | train/val/test=0.983/0.742/0.748 | c=0.998347
[Epoch 0021] loss=13.6989 cls=1.2991 smmd=1.1758 ct=8.7836 rec=1.2202 | train/val/test=0.966/0.732/0.708 | c=0.998347
[Epoch 0022] loss=13.3164 cls=0.9355 smmd=1.1667 ct=8.7779 rec=1.2182 | train/val/test=0.948/0.712/0.693 | c=0.998347
[Epoch 0023] loss=13.6960 cls=1.2453 smmd=1.2270 ct=8.7683 rec=1.2276 | train/val/test=0.931/0.718/0.701 | c=0.998347
[Epoch 0024] loss=13.8290 cls=1.3276 smmd=1.2870 ct=8.7622 rec=1.2261 | train/val/test=0.966/0.732/0.732 | c=0.998347
[Epoch 0025] loss=13.7630 cls=1.2357 smmd=1.3006 ct=8.7724 rec=1.2272 | train/val/test=0.966/0.744/0.741 | c=0.998347
[Epoch 0026] loss=13.6903 cls=1.1830 smmd=1.2928 ct=8.7674 rec=1.2235 | train/val/test=0.966/0.744/0.737 | c=0.998347
[Epoch 0027] loss=13.3961 cls=0.9982 smmd=1.2052 ct=8.7581 rec=1.2173 | train/val/test=0.948/0.738/0.727 | c=0.998347
[Epoch 0028] loss=13.6173 cls=1.2610 smmd=1.1475 ct=8.7657 rec=1.2216 | train/val/test=0.948/0.736/0.725 | c=0.998347
[Epoch 0029] loss=13.4612 cls=1.1527 smmd=1.0953 ct=8.7744 rec=1.2194 | train/val/test=0.948/0.738/0.726 | c=0.998347
[Epoch 0030] loss=13.5513 cls=1.2895 smmd=1.0646 ct=8.7700 rec=1.2136 | train/val/test=0.948/0.734/0.727 | c=0.998347
[Epoch 0031] loss=13.1822 cls=1.0345 smmd=0.9855 ct=8.7519 rec=1.2051 | train/val/test=0.948/0.746/0.733 | c=0.998347
[Epoch 0032] loss=13.1222 cls=0.9306 smmd=1.0050 ct=8.7465 rec=1.2201 | train/val/test=0.948/0.748/0.738 | c=0.998347
[Epoch 0033] loss=13.2900 cls=1.1478 smmd=0.9872 ct=8.7476 rec=1.2036 | train/val/test=0.948/0.748/0.736 | c=0.998347
[Epoch 0034] loss=13.4084 cls=1.2695 smmd=0.9961 ct=8.7454 rec=1.1986 | train/val/test=0.983/0.744/0.736 | c=0.998347
[Epoch 0035] loss=13.3403 cls=1.2614 smmd=0.9330 ct=8.7535 rec=1.1962 | train/val/test=0.983/0.744/0.725 | c=0.998347
[Epoch 0036] loss=13.1178 cls=1.0301 smmd=0.9445 ct=8.7596 rec=1.1918 | train/val/test=0.983/0.742/0.734 | c=0.998347
[Epoch 0037] loss=13.2424 cls=1.1975 smmd=0.9135 ct=8.7539 rec=1.1888 | train/val/test=0.983/0.740/0.738 | c=0.998347
[Epoch 0038] loss=14.1181 cls=1.3662 smmd=0.8816 ct=9.4691 rec=1.2006 | train/val/test=0.983/0.744/0.741 | c=0.998347
[Epoch 0039] loss=14.0228 cls=1.3645 smmd=0.8382 ct=9.4278 rec=1.1962 | train/val/test=0.983/0.738/0.749 | c=0.998347
[Epoch 0040] loss=13.7088 cls=1.0856 smmd=0.8481 ct=9.3785 rec=1.1983 | train/val/test=0.983/0.730/0.746 | c=0.998347
[Epoch 0041] loss=13.8436 cls=1.1828 smmd=0.8736 ct=9.3464 rec=1.2204 | train/val/test=0.983/0.726/0.742 | c=0.998347
[Epoch 0042] loss=13.7587 cls=1.1564 smmd=0.8823 ct=9.3094 rec=1.2053 | train/val/test=0.983/0.728/0.746 | c=0.998347
[Epoch 0043] loss=14.1329 cls=1.5260 smmd=0.8640 ct=9.3079 rec=1.2175 | train/val/test=0.983/0.732/0.743 | c=0.998347
[Epoch 0044] loss=13.7606 cls=1.1938 smmd=0.8099 ct=9.3251 rec=1.2159 | train/val/test=0.983/0.732/0.741 | c=0.998347
[Epoch 0045] loss=13.5293 cls=0.9825 smmd=0.7772 ct=9.3535 rec=1.2081 | train/val/test=0.983/0.728/0.729 | c=0.998347
[Epoch 0046] loss=13.6362 cls=1.1300 smmd=0.7026 ct=9.3805 rec=1.2116 | train/val/test=0.983/0.728/0.730 | c=0.998347
[Epoch 0047] loss=13.6647 cls=1.1859 smmd=0.6593 ct=9.3929 rec=1.2133 | train/val/test=0.983/0.724/0.722 | c=0.998347
[Epoch 0048] loss=13.4861 cls=1.0133 smmd=0.6425 ct=9.4073 rec=1.2115 | train/val/test=0.983/0.728/0.726 | c=0.998347
[Epoch 0049] loss=13.7786 cls=1.3316 smmd=0.6161 ct=9.4031 rec=1.2139 | train/val/test=0.983/0.726/0.722 | c=0.998347
[Epoch 0050] loss=13.5493 cls=1.1152 smmd=0.6212 ct=9.3889 rec=1.2120 | train/val/test=0.983/0.724/0.728 | c=0.998347
[Epoch 0051] loss=13.5767 cls=1.1931 smmd=0.5741 ct=9.3778 rec=1.2158 | train/val/test=0.983/0.728/0.725 | c=0.998347
[Epoch 0052] loss=13.6049 cls=1.2100 smmd=0.5897 ct=9.3689 rec=1.2181 | train/val/test=0.983/0.726/0.724 | c=0.998347
[Epoch 0053] loss=13.5177 cls=1.1470 smmd=0.5891 ct=9.3561 rec=1.2128 | train/val/test=0.983/0.730/0.727 | c=0.998347
[Epoch 0054] loss=13.4429 cls=1.0958 smmd=0.5516 ct=9.3697 rec=1.2129 | train/val/test=0.983/0.730/0.722 | c=0.998347
[Epoch 0055] loss=13.6644 cls=1.3201 smmd=0.5234 ct=9.3660 rec=1.2275 | train/val/test=0.983/0.722/0.720 | c=0.998347
[Epoch 0056] loss=13.6711 cls=1.3442 smmd=0.5310 ct=9.3774 rec=1.2093 | train/val/test=0.983/0.724/0.716 | c=0.998347
[Epoch 0057] loss=13.4104 cls=1.0857 smmd=0.4979 ct=9.3886 rec=1.2191 | train/val/test=0.983/0.722/0.718 | c=0.998347
[Epoch 0058] loss=13.6667 cls=1.3892 smmd=0.4850 ct=9.3721 rec=1.2102 | train/val/test=1.000/0.732/0.729 | c=0.998347
[Epoch 0059] loss=13.4726 cls=1.2013 smmd=0.4797 ct=9.3638 rec=1.2139 | train/val/test=1.000/0.734/0.735 | c=0.998347
[Epoch 0060] loss=13.5303 cls=1.2854 smmd=0.4556 ct=9.3618 rec=1.2138 | train/val/test=1.000/0.732/0.726 | c=0.998347
[Epoch 0061] loss=13.7132 cls=1.4757 smmd=0.4582 ct=9.3548 rec=1.2122 | train/val/test=0.983/0.728/0.723 | c=0.998347
[Epoch 0062] loss=13.3759 cls=1.1531 smmd=0.4438 ct=9.3689 rec=1.2051 | train/val/test=0.983/0.718/0.719 | c=0.998347
[Epoch 0063] loss=13.4243 cls=1.1923 smmd=0.4408 ct=9.3741 rec=1.2085 | train/val/test=0.983/0.720/0.721 | c=0.998347
[Epoch 0064] loss=13.2249 cls=0.9938 smmd=0.4134 ct=9.3844 rec=1.2167 | train/val/test=0.983/0.724/0.725 | c=0.998347
[Epoch 0065] loss=13.5162 cls=1.3346 smmd=0.3911 ct=9.3815 rec=1.2045 | train/val/test=1.000/0.728/0.732 | c=0.998347
[Epoch 0066] loss=13.6894 cls=1.4910 smmd=0.4059 ct=9.3670 rec=1.2127 | train/val/test=0.983/0.728/0.734 | c=0.998347
[Epoch 0067] loss=13.5383 cls=1.3493 smmd=0.3850 ct=9.3740 rec=1.2150 | train/val/test=1.000/0.726/0.739 | c=0.998347
[Epoch 0068] loss=13.4128 cls=1.2455 smmd=0.3706 ct=9.3727 rec=1.2120 | train/val/test=0.983/0.726/0.733 | c=0.998347
[Epoch 0069] loss=13.5394 cls=1.3500 smmd=0.3828 ct=9.3706 rec=1.2180 | train/val/test=0.983/0.724/0.731 | c=0.998347
[Epoch 0070] loss=13.4054 cls=1.2443 smmd=0.3634 ct=9.3750 rec=1.2113 | train/val/test=0.983/0.724/0.728 | c=0.998347
[Epoch 0071] loss=13.0495 cls=0.9003 smmd=0.3663 ct=9.3756 rec=1.2036 | train/val/test=0.983/0.724/0.727 | c=0.998347
[Epoch 0072] loss=13.5100 cls=1.3406 smmd=0.3619 ct=9.3771 rec=1.2152 | train/val/test=0.983/0.728/0.728 | c=0.998347
[Epoch 0073] loss=13.5476 cls=1.3754 smmd=0.3660 ct=9.3714 rec=1.2174 | train/val/test=0.983/0.726/0.725 | c=0.998347
[Epoch 0074] loss=13.3872 cls=1.2199 smmd=0.3472 ct=9.3664 rec=1.2269 | train/val/test=0.983/0.728/0.728 | c=0.998347
[Epoch 0075] loss=13.2683 cls=1.1275 smmd=0.3641 ct=9.3619 rec=1.2073 | train/val/test=0.983/0.726/0.727 | c=0.998347
[Epoch 0076] loss=13.5493 cls=1.3680 smmd=0.3502 ct=9.3682 rec=1.2315 | train/val/test=1.000/0.728/0.731 | c=0.998347
[Epoch 0077] loss=13.3676 cls=1.2187 smmd=0.3549 ct=9.3650 rec=1.2145 | train/val/test=1.000/0.730/0.735 | c=0.998347
[Epoch 0078] loss=13.3022 cls=1.1547 smmd=0.3683 ct=9.3677 rec=1.2058 | train/val/test=1.000/0.736/0.734 | c=0.998347
[Epoch 0079] loss=13.3951 cls=1.2579 smmd=0.3457 ct=9.3691 rec=1.2112 | train/val/test=1.000/0.736/0.733 | c=0.998347
[Epoch 0080] loss=13.1861 cls=1.0776 smmd=0.3190 ct=9.3725 rec=1.2085 | train/val/test=1.000/0.736/0.732 | c=0.998347
[Epoch 0081] loss=13.6442 cls=1.5164 smmd=0.3332 ct=9.3786 rec=1.2081 | train/val/test=1.000/0.736/0.737 | c=0.998347
[Epoch 0082] loss=13.1993 cls=1.1070 smmd=0.3124 ct=9.3759 rec=1.2020 | train/val/test=1.000/0.736/0.741 | c=0.998347
[Epoch 0083] loss=13.2464 cls=1.1144 smmd=0.3392 ct=9.3772 rec=1.2078 | train/val/test=1.000/0.734/0.739 | c=0.998347
[Epoch 0084] loss=13.3802 cls=1.2705 smmd=0.3161 ct=9.3729 rec=1.2104 | train/val/test=1.000/0.734/0.738 | c=0.998347
[Epoch 0085] loss=13.2549 cls=1.1348 smmd=0.3198 ct=9.3764 rec=1.2119 | train/val/test=1.000/0.734/0.738 | c=0.998347
[Epoch 0086] loss=13.0965 cls=0.9772 smmd=0.3154 ct=9.3745 rec=1.2147 | train/val/test=1.000/0.732/0.740 | c=0.998347
[Epoch 0087] loss=13.4769 cls=1.3506 smmd=0.3138 ct=9.3768 rec=1.2178 | train/val/test=1.000/0.734/0.739 | c=0.998347
[Epoch 0088] loss=13.3992 cls=1.2569 smmd=0.3227 ct=9.3715 rec=1.2240 | train/val/test=1.000/0.734/0.737 | c=0.998347
[Epoch 0089] loss=13.1676 cls=1.0530 smmd=0.3199 ct=9.3719 rec=1.2114 | train/val/test=1.000/0.732/0.734 | c=0.998347
[Epoch 0090] loss=13.2294 cls=1.1285 smmd=0.3147 ct=9.3701 rec=1.2080 | train/val/test=1.000/0.732/0.734 | c=0.998347
[Epoch 0091] loss=13.2437 cls=1.1485 smmd=0.3073 ct=9.3689 rec=1.2095 | train/val/test=1.000/0.730/0.733 | c=0.998347
[Epoch 0092] loss=13.1540 cls=1.0614 smmd=0.3040 ct=9.3732 rec=1.2078 | train/val/test=1.000/0.730/0.733 | c=0.998347
[Epoch 0093] loss=13.2868 cls=1.1462 smmd=0.3168 ct=9.3788 rec=1.2225 | train/val/test=1.000/0.730/0.733 | c=0.998347
[Epoch 0094] loss=13.1360 cls=1.0116 smmd=0.3303 ct=9.3708 rec=1.2117 | train/val/test=1.000/0.730/0.733 | c=0.998347
[Epoch 0095] loss=13.1937 cls=1.0914 smmd=0.3042 ct=9.3727 rec=1.2127 | train/val/test=1.000/0.730/0.733 | c=0.998347
[Epoch 0096] loss=13.0087 cls=0.9140 smmd=0.3147 ct=9.3711 rec=1.2045 | train/val/test=1.000/0.730/0.733 | c=0.998347
[Epoch 0097] loss=13.1401 cls=1.0560 smmd=0.3118 ct=9.3645 rec=1.2039 | train/val/test=1.000/0.730/0.734 | c=0.998347
[Epoch 0098] loss=13.2561 cls=1.1555 smmd=0.3092 ct=9.3743 rec=1.2085 | train/val/test=1.000/0.730/0.734 | c=0.998347
[Epoch 0099] loss=13.1202 cls=1.0121 smmd=0.3239 ct=9.3751 rec=1.2045 | train/val/test=1.000/0.730/0.734 | c=0.998347
=== Best @ epoch 32: val=0.7480, test=0.7380 ===
