Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.3745 cls=2.3370 smmd=4.0031 ct=9.2534 rec=1.3905 | train/val/test=0.241/0.154/0.173 | c=0.998347
[Epoch 0001] loss=17.9151 cls=1.9537 smmd=3.9314 ct=9.2530 rec=1.3884 | train/val/test=0.172/0.086/0.102 | c=0.998347
[Epoch 0002] loss=17.8685 cls=2.0255 smmd=3.8177 ct=9.2448 rec=1.3902 | train/val/test=0.172/0.072/0.091 | c=0.998347
[Epoch 0003] loss=17.4931 cls=1.8268 smmd=3.6275 ct=9.2403 rec=1.3992 | train/val/test=0.276/0.096/0.118 | c=0.998347
[Epoch 0004] loss=17.1568 cls=1.7388 smmd=3.4130 ct=9.2234 rec=1.3908 | train/val/test=0.621/0.450/0.442 | c=0.998347
[Epoch 0005] loss=17.0039 cls=1.9148 smmd=3.1205 ct=9.2000 rec=1.3843 | train/val/test=0.897/0.452/0.423 | c=0.998347
[Epoch 0006] loss=16.4329 cls=1.7513 smmd=2.7523 ct=9.1706 rec=1.3794 | train/val/test=0.897/0.396/0.384 | c=0.998347
[Epoch 0007] loss=15.7921 cls=1.5761 smmd=2.3463 ct=9.1268 rec=1.3715 | train/val/test=0.897/0.438/0.420 | c=0.998347
[Epoch 0008] loss=15.1587 cls=1.4917 smmd=1.8924 ct=9.0677 rec=1.3534 | train/val/test=0.931/0.480/0.470 | c=0.998347
[Epoch 0009] loss=14.5136 cls=1.3428 smmd=1.4983 ct=9.0044 rec=1.3340 | train/val/test=0.931/0.458/0.483 | c=0.998347
[Epoch 0010] loss=13.9137 cls=1.1032 smmd=1.2238 ct=8.9536 rec=1.3165 | train/val/test=1.000/0.542/0.499 | c=0.998347
[Epoch 0011] loss=13.8750 cls=1.1629 smmd=1.2043 ct=8.9017 rec=1.3031 | train/val/test=0.931/0.524/0.512 | c=0.998347
[Epoch 0012] loss=13.6387 cls=0.7452 smmd=1.4030 ct=8.8986 rec=1.2960 | train/val/test=0.966/0.554/0.546 | c=0.998347
[Epoch 0013] loss=14.0366 cls=0.9918 smmd=1.6335 ct=8.8592 rec=1.2761 | train/val/test=0.931/0.624/0.602 | c=0.998347
[Epoch 0014] loss=14.0639 cls=0.8776 smmd=1.8146 ct=8.8500 rec=1.2609 | train/val/test=0.966/0.622/0.598 | c=0.998347
[Epoch 0015] loss=14.1864 cls=0.9200 smmd=1.8853 ct=8.8653 rec=1.2579 | train/val/test=0.966/0.592/0.573 | c=0.998347
[Epoch 0016] loss=14.2213 cls=0.9935 smmd=1.9022 ct=8.8347 rec=1.2454 | train/val/test=0.966/0.598/0.562 | c=0.998347
[Epoch 0017] loss=14.1006 cls=0.9972 smmd=1.8263 ct=8.8054 rec=1.2358 | train/val/test=0.966/0.600/0.587 | c=0.998347
[Epoch 0018] loss=14.2504 cls=1.2855 smmd=1.6934 ct=8.8152 rec=1.2282 | train/val/test=0.966/0.638/0.633 | c=0.998347
[Epoch 0019] loss=13.6098 cls=0.7690 smmd=1.5362 ct=8.8500 rec=1.2273 | train/val/test=0.966/0.640/0.650 | c=0.998347
[Epoch 0020] loss=13.8970 cls=1.2079 smmd=1.3700 ct=8.8563 rec=1.2314 | train/val/test=0.966/0.648/0.642 | c=0.998347
[Epoch 0021] loss=13.4630 cls=0.9326 smmd=1.2234 ct=8.8323 rec=1.2373 | train/val/test=1.000/0.660/0.642 | c=0.998347
[Epoch 0022] loss=13.7645 cls=0.7022 smmd=1.1377 ct=9.4785 rec=1.2230 | train/val/test=1.000/0.594/0.589 | c=0.998347
[Epoch 0023] loss=13.9464 cls=0.8177 smmd=1.1932 ct=9.4770 rec=1.2292 | train/val/test=0.966/0.546/0.536 | c=0.998347
[Epoch 0024] loss=14.6480 cls=1.5046 smmd=1.2787 ct=9.3957 rec=1.2345 | train/val/test=0.966/0.554/0.541 | c=0.998347
[Epoch 0025] loss=14.2697 cls=1.1236 smmd=1.3367 ct=9.3412 rec=1.2341 | train/val/test=1.000/0.610/0.597 | c=0.998347
[Epoch 0026] loss=13.9466 cls=0.8098 smmd=1.3677 ct=9.3056 rec=1.2317 | train/val/test=1.000/0.646/0.621 | c=0.998347
[Epoch 0027] loss=14.0794 cls=0.9246 smmd=1.3808 ct=9.2969 rec=1.2385 | train/val/test=0.931/0.664/0.635 | c=0.998347
[Epoch 0028] loss=14.2984 cls=1.1734 smmd=1.3604 ct=9.2764 rec=1.2441 | train/val/test=0.966/0.660/0.643 | c=0.998347
[Epoch 0029] loss=13.9029 cls=0.9136 smmd=1.2608 ct=9.2641 rec=1.2322 | train/val/test=0.966/0.636/0.615 | c=0.998347
[Epoch 0030] loss=14.1859 cls=1.2749 smmd=1.2098 ct=9.2556 rec=1.2228 | train/val/test=0.966/0.600/0.614 | c=0.998347
[Epoch 0031] loss=14.2075 cls=1.3565 smmd=1.1396 ct=9.2546 rec=1.2284 | train/val/test=0.966/0.602/0.624 | c=0.998347
[Epoch 0032] loss=13.9424 cls=1.0974 smmd=1.1263 ct=9.2786 rec=1.2201 | train/val/test=0.966/0.640/0.634 | c=0.998347
[Epoch 0033] loss=14.1583 cls=1.3487 smmd=1.0787 ct=9.3022 rec=1.2143 | train/val/test=0.966/0.630/0.641 | c=0.998347
[Epoch 0034] loss=14.0136 cls=1.1223 smmd=1.1017 ct=9.3396 rec=1.2250 | train/val/test=0.966/0.638/0.645 | c=0.998347
[Epoch 0035] loss=13.8034 cls=0.9533 smmd=1.0726 ct=9.3432 rec=1.2171 | train/val/test=0.966/0.656/0.652 | c=0.998347
[Epoch 0036] loss=13.5324 cls=0.7418 smmd=1.0280 ct=9.3324 rec=1.2151 | train/val/test=0.966/0.674/0.649 | c=0.998347
[Epoch 0037] loss=13.7369 cls=0.9603 smmd=1.0226 ct=9.3301 rec=1.2119 | train/val/test=0.966/0.656/0.645 | c=0.998347
[Epoch 0038] loss=13.4402 cls=0.6821 smmd=0.9918 ct=9.3419 rec=1.2122 | train/val/test=0.966/0.650/0.653 | c=0.998347
[Epoch 0039] loss=13.7934 cls=1.0502 smmd=0.9988 ct=9.3205 rec=1.2120 | train/val/test=0.966/0.656/0.657 | c=0.998347
[Epoch 0040] loss=13.3243 cls=0.6323 smmd=0.9685 ct=9.3011 rec=1.2112 | train/val/test=0.966/0.660/0.651 | c=0.998347
[Epoch 0041] loss=13.8707 cls=1.1583 smmd=0.9652 ct=9.2982 rec=1.2245 | train/val/test=0.966/0.652/0.649 | c=0.998347
[Epoch 0042] loss=13.9486 cls=1.2853 smmd=0.9406 ct=9.2893 rec=1.2167 | train/val/test=0.966/0.666/0.661 | c=0.998347
[Epoch 0043] loss=13.7163 cls=1.0825 smmd=0.9183 ct=9.2848 rec=1.2154 | train/val/test=1.000/0.662/0.661 | c=0.998347
[Epoch 0044] loss=13.7143 cls=1.0711 smmd=0.8907 ct=9.3046 rec=1.2240 | train/val/test=1.000/0.666/0.663 | c=0.998347
[Epoch 0045] loss=13.7243 cls=1.1119 smmd=0.8778 ct=9.3061 rec=1.2142 | train/val/test=1.000/0.666/0.658 | c=0.998347
[Epoch 0046] loss=13.4609 cls=0.8650 smmd=0.8462 ct=9.3117 rec=1.2190 | train/val/test=1.000/0.660/0.660 | c=0.998347
[Epoch 0047] loss=14.5034 cls=1.8984 smmd=0.8351 ct=9.3119 rec=1.2290 | train/val/test=1.000/0.658/0.660 | c=0.998347
[Epoch 0048] loss=13.9430 cls=1.3839 smmd=0.8042 ct=9.3089 rec=1.2230 | train/val/test=1.000/0.658/0.657 | c=0.998347
[Epoch 0049] loss=13.4899 cls=0.9250 smmd=0.8033 ct=9.3127 rec=1.2245 | train/val/test=1.000/0.658/0.656 | c=0.998347
[Epoch 0050] loss=13.4971 cls=0.9189 smmd=0.7768 ct=9.3119 rec=1.2448 | train/val/test=1.000/0.662/0.657 | c=0.998347
[Epoch 0051] loss=13.5961 cls=1.0738 smmd=0.7621 ct=9.3083 rec=1.2260 | train/val/test=1.000/0.668/0.662 | c=0.998347
[Epoch 0052] loss=13.6341 cls=1.1313 smmd=0.7411 ct=9.3072 rec=1.2272 | train/val/test=1.000/0.678/0.672 | c=0.998347
[Epoch 0053] loss=13.5006 cls=1.0179 smmd=0.7297 ct=9.3003 rec=1.2263 | train/val/test=1.000/0.684/0.675 | c=0.998347
[Epoch 0054] loss=13.2405 cls=0.7684 smmd=0.7319 ct=9.2969 rec=1.2216 | train/val/test=1.000/0.680/0.672 | c=0.998347
[Epoch 0055] loss=13.5504 cls=1.1124 smmd=0.7019 ct=9.2875 rec=1.2243 | train/val/test=1.000/0.678/0.666 | c=0.998347
[Epoch 0056] loss=13.3897 cls=0.9664 smmd=0.7003 ct=9.2872 rec=1.2179 | train/val/test=1.000/0.678/0.663 | c=0.998347
[Epoch 0057] loss=13.2292 cls=0.8072 smmd=0.6767 ct=9.3020 rec=1.2217 | train/val/test=1.000/0.668/0.664 | c=0.998347
[Epoch 0058] loss=13.2753 cls=0.8840 smmd=0.6739 ct=9.2848 rec=1.2163 | train/val/test=1.000/0.670/0.667 | c=0.998347
[Epoch 0059] loss=13.4365 cls=1.0934 smmd=0.6420 ct=9.2784 rec=1.2113 | train/val/test=1.000/0.670/0.673 | c=0.998347
[Epoch 0060] loss=13.6144 cls=1.2685 smmd=0.6258 ct=9.2979 rec=1.2110 | train/val/test=1.000/0.666/0.670 | c=0.998347
[Epoch 0061] loss=13.3867 cls=1.0455 smmd=0.6150 ct=9.2914 rec=1.2174 | train/val/test=1.000/0.670/0.672 | c=0.998347
[Epoch 0062] loss=13.3435 cls=1.0056 smmd=0.6133 ct=9.3032 rec=1.2107 | train/val/test=1.000/0.674/0.674 | c=0.998347
[Epoch 0063] loss=13.3378 cls=1.0094 smmd=0.6041 ct=9.3022 rec=1.2110 | train/val/test=1.000/0.674/0.676 | c=0.998347
[Epoch 0064] loss=13.3034 cls=0.9850 smmd=0.5868 ct=9.3097 rec=1.2109 | train/val/test=1.000/0.674/0.674 | c=0.998347
[Epoch 0065] loss=13.3544 cls=1.0746 smmd=0.5650 ct=9.3021 rec=1.2063 | train/val/test=1.000/0.670/0.674 | c=0.998347
[Epoch 0066] loss=12.9746 cls=0.7225 smmd=0.5580 ct=9.2920 rec=1.2011 | train/val/test=1.000/0.662/0.671 | c=0.998347
[Epoch 0067] loss=13.0576 cls=0.8246 smmd=0.5572 ct=9.2888 rec=1.1935 | train/val/test=1.000/0.654/0.661 | c=0.998347
[Epoch 0068] loss=12.8648 cls=0.6178 smmd=0.5527 ct=9.2899 rec=1.2022 | train/val/test=1.000/0.654/0.659 | c=0.998347
[Epoch 0069] loss=13.1481 cls=0.8935 smmd=0.5699 ct=9.2885 rec=1.1981 | train/val/test=1.000/0.658/0.660 | c=0.998347
[Epoch 0070] loss=13.4945 cls=1.2446 smmd=0.5433 ct=9.2942 rec=1.2062 | train/val/test=1.000/0.668/0.664 | c=0.998347
[Epoch 0071] loss=13.4241 cls=1.1939 smmd=0.5319 ct=9.2834 rec=1.2075 | train/val/test=1.000/0.672/0.667 | c=0.998347
[Epoch 0072] loss=12.8113 cls=0.6023 smmd=0.5212 ct=9.2983 rec=1.1948 | train/val/test=1.000/0.674/0.672 | c=0.998347
[Epoch 0073] loss=13.1142 cls=0.9062 smmd=0.4967 ct=9.2934 rec=1.2090 | train/val/test=1.000/0.678/0.673 | c=0.998347
[Epoch 0074] loss=13.1324 cls=0.9150 smmd=0.5218 ct=9.3028 rec=1.1964 | train/val/test=1.000/0.678/0.676 | c=0.998347
[Epoch 0075] loss=12.7210 cls=0.5603 smmd=0.4858 ct=9.2956 rec=1.1896 | train/val/test=1.000/0.678/0.679 | c=0.998347
[Epoch 0076] loss=13.2488 cls=1.0649 smmd=0.4882 ct=9.2973 rec=1.1992 | train/val/test=1.000/0.672/0.680 | c=0.998347
[Epoch 0077] loss=13.3914 cls=1.1632 smmd=0.4857 ct=9.2989 rec=1.2218 | train/val/test=1.000/0.670/0.683 | c=0.998347
[Epoch 0078] loss=13.1291 cls=0.9590 smmd=0.4884 ct=9.2969 rec=1.1924 | train/val/test=1.000/0.670/0.682 | c=0.998347
[Epoch 0079] loss=13.1947 cls=1.0383 smmd=0.4781 ct=9.2985 rec=1.1899 | train/val/test=1.000/0.666/0.680 | c=0.998347
[Epoch 0080] loss=13.2955 cls=1.1029 smmd=0.4939 ct=9.2928 rec=1.2030 | train/val/test=1.000/0.670/0.679 | c=0.998347
[Epoch 0081] loss=12.9755 cls=0.7905 smmd=0.4663 ct=9.2937 rec=1.2125 | train/val/test=1.000/0.666/0.683 | c=0.998347
[Epoch 0082] loss=12.7415 cls=0.5896 smmd=0.4810 ct=9.2867 rec=1.1921 | train/val/test=1.000/0.664/0.683 | c=0.998347
[Epoch 0083] loss=12.7755 cls=0.6166 smmd=0.4775 ct=9.2929 rec=1.1943 | train/val/test=1.000/0.660/0.683 | c=0.998347
[Epoch 0084] loss=12.9850 cls=0.8112 smmd=0.4844 ct=9.2934 rec=1.1980 | train/val/test=1.000/0.660/0.682 | c=0.998347
[Epoch 0085] loss=13.1579 cls=0.9937 smmd=0.4831 ct=9.2931 rec=1.1939 | train/val/test=1.000/0.662/0.683 | c=0.998347
[Epoch 0086] loss=13.0045 cls=0.8426 smmd=0.4434 ct=9.2931 rec=1.2127 | train/val/test=1.000/0.662/0.682 | c=0.998347
[Epoch 0087] loss=13.1137 cls=0.9809 smmd=0.4599 ct=9.2925 rec=1.1902 | train/val/test=1.000/0.662/0.680 | c=0.998347
[Epoch 0088] loss=13.0079 cls=0.8799 smmd=0.4468 ct=9.3012 rec=1.1900 | train/val/test=1.000/0.666/0.680 | c=0.998347
[Epoch 0089] loss=13.2857 cls=1.1281 smmd=0.4691 ct=9.2967 rec=1.1959 | train/val/test=1.000/0.666/0.681 | c=0.998347
[Epoch 0090] loss=13.3669 cls=1.2304 smmd=0.4567 ct=9.2976 rec=1.1911 | train/val/test=1.000/0.666/0.682 | c=0.998347
[Epoch 0091] loss=12.8366 cls=0.7187 smmd=0.4461 ct=9.2946 rec=1.1887 | train/val/test=1.000/0.666/0.682 | c=0.998347
[Epoch 0092] loss=13.1866 cls=1.0686 smmd=0.4419 ct=9.2926 rec=1.1917 | train/val/test=1.000/0.666/0.681 | c=0.998347
[Epoch 0093] loss=12.7118 cls=0.6015 smmd=0.4417 ct=9.2932 rec=1.1877 | train/val/test=1.000/0.666/0.681 | c=0.998347
[Epoch 0094] loss=13.3944 cls=1.2571 smmd=0.4638 ct=9.2868 rec=1.1934 | train/val/test=1.000/0.666/0.681 | c=0.998347
[Epoch 0095] loss=12.9706 cls=0.8418 smmd=0.4522 ct=9.2951 rec=1.1908 | train/val/test=1.000/0.668/0.682 | c=0.998347
[Epoch 0096] loss=13.0755 cls=0.9537 smmd=0.4413 ct=9.2915 rec=1.1945 | train/val/test=1.000/0.668/0.682 | c=0.998347
[Epoch 0097] loss=13.4175 cls=1.2733 smmd=0.4571 ct=9.2822 rec=1.2025 | train/val/test=1.000/0.668/0.682 | c=0.998347
[Epoch 0098] loss=13.3892 cls=1.2432 smmd=0.4545 ct=9.2921 rec=1.1997 | train/val/test=1.000/0.668/0.682 | c=0.998347
[Epoch 0099] loss=12.9457 cls=0.8407 smmd=0.4327 ct=9.2898 rec=1.1913 | train/val/test=1.000/0.668/0.682 | c=0.998347
=== Best @ epoch 53: val=0.6840, test=0.6750 ===
