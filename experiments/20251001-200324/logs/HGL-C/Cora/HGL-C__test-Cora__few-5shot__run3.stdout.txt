Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=17.2814 cls=2.1287 smmd=3.0899 ct=9.2735 rec=1.3947 | train/val/test=0.207/0.174/0.182 | c=0.999488
[Epoch 0001] loss=17.0911 cls=2.0268 smmd=3.0154 ct=9.2703 rec=1.3894 | train/val/test=0.345/0.204/0.202 | c=0.999488
[Epoch 0002] loss=16.8865 cls=1.9504 smmd=2.8902 ct=9.2650 rec=1.3904 | train/val/test=0.345/0.168/0.158 | c=0.999488
[Epoch 0003] loss=16.5706 cls=1.8053 smmd=2.7254 ct=9.2569 rec=1.3915 | train/val/test=0.586/0.108/0.137 | c=0.999488
[Epoch 0004] loss=16.3002 cls=1.7710 smmd=2.5105 ct=9.2430 rec=1.3878 | train/val/test=0.759/0.412/0.414 | c=0.999488
[Epoch 0005] loss=15.9048 cls=1.6674 smmd=2.2491 ct=9.2166 rec=1.3859 | train/val/test=0.862/0.558/0.554 | c=0.999488
[Epoch 0006] loss=15.4664 cls=1.6148 smmd=1.9421 ct=9.1634 rec=1.3731 | train/val/test=0.862/0.398/0.408 | c=0.999488
[Epoch 0007] loss=14.7358 cls=1.3715 smmd=1.5990 ct=9.0643 rec=1.3505 | train/val/test=0.931/0.424/0.418 | c=0.999488
[Epoch 0008] loss=14.0312 cls=1.1772 smmd=1.2401 ct=8.9630 rec=1.3255 | train/val/test=1.000/0.502/0.512 | c=0.999488
[Epoch 0009] loss=13.4759 cls=1.0544 smmd=0.8808 ct=8.9248 rec=1.3080 | train/val/test=0.966/0.646/0.631 | c=0.999488
[Epoch 0010] loss=13.1814 cls=1.2376 smmd=0.5626 ct=8.8439 rec=1.2686 | train/val/test=1.000/0.630/0.641 | c=0.999488
[Epoch 0011] loss=12.8582 cls=1.2096 smmd=0.3448 ct=8.8091 rec=1.2474 | train/val/test=1.000/0.632/0.646 | c=0.999488
[Epoch 0012] loss=12.3797 cls=0.8238 smmd=0.2552 ct=8.8234 rec=1.2386 | train/val/test=1.000/0.666/0.660 | c=0.999488
[Epoch 0013] loss=12.4981 cls=0.9213 smmd=0.2914 ct=8.8309 rec=1.2272 | train/val/test=1.000/0.668/0.678 | c=0.999488
[Epoch 0014] loss=12.6761 cls=1.0137 smmd=0.3941 ct=8.8241 rec=1.2221 | train/val/test=0.966/0.702/0.711 | c=0.999488
[Epoch 0015] loss=12.1827 cls=0.4363 smmd=0.5197 ct=8.8023 rec=1.2122 | train/val/test=1.000/0.700/0.722 | c=0.999488
[Epoch 0016] loss=12.9737 cls=1.1922 smmd=0.6216 ct=8.7750 rec=1.1924 | train/val/test=1.000/0.666/0.693 | c=0.999488
[Epoch 0017] loss=12.6528 cls=0.8123 smmd=0.6839 ct=8.7851 rec=1.1858 | train/val/test=1.000/0.678/0.697 | c=0.999488
[Epoch 0018] loss=13.2820 cls=0.7624 smmd=0.6850 ct=9.4639 rec=1.1853 | train/val/test=1.000/0.692/0.710 | c=0.999488
[Epoch 0019] loss=13.1901 cls=0.8328 smmd=0.6381 ct=9.3577 rec=1.1807 | train/val/test=1.000/0.680/0.711 | c=0.999488
[Epoch 0020] loss=13.6419 cls=1.4027 smmd=0.5758 ct=9.2788 rec=1.1923 | train/val/test=1.000/0.670/0.689 | c=0.999488
[Epoch 0021] loss=12.8400 cls=0.6824 smmd=0.5247 ct=9.2386 rec=1.1972 | train/val/test=1.000/0.662/0.672 | c=0.999488
[Epoch 0022] loss=13.2082 cls=1.0927 smmd=0.4868 ct=9.2073 rec=1.2107 | train/val/test=1.000/0.660/0.667 | c=0.999488
[Epoch 0023] loss=12.8297 cls=0.7649 smmd=0.4616 ct=9.1818 rec=1.2107 | train/val/test=1.000/0.676/0.687 | c=0.999488
[Epoch 0024] loss=12.8473 cls=0.8239 smmd=0.4448 ct=9.1596 rec=1.2095 | train/val/test=1.000/0.690/0.698 | c=0.999488
[Epoch 0025] loss=13.2118 cls=1.1956 smmd=0.4430 ct=9.1603 rec=1.2064 | train/val/test=1.000/0.696/0.700 | c=0.999488
[Epoch 0026] loss=12.6302 cls=0.5980 smmd=0.4405 ct=9.1801 rec=1.2058 | train/val/test=1.000/0.706/0.709 | c=0.999488
[Epoch 0027] loss=12.9995 cls=0.9749 smmd=0.4276 ct=9.1957 rec=1.2006 | train/val/test=1.000/0.700/0.704 | c=0.999488
[Epoch 0028] loss=12.6527 cls=0.6315 smmd=0.4096 ct=9.2130 rec=1.1993 | train/val/test=1.000/0.686/0.703 | c=0.999488
[Epoch 0029] loss=12.8679 cls=0.8643 smmd=0.3800 ct=9.2253 rec=1.1991 | train/val/test=1.000/0.690/0.694 | c=0.999488
[Epoch 0030] loss=12.8212 cls=0.8289 smmd=0.3454 ct=9.2429 rec=1.2020 | train/val/test=1.000/0.684/0.680 | c=0.999488
[Epoch 0031] loss=13.0228 cls=1.0390 smmd=0.3142 ct=9.2646 rec=1.2025 | train/val/test=1.000/0.678/0.684 | c=0.999488
[Epoch 0032] loss=12.9751 cls=1.0231 smmd=0.2760 ct=9.2728 rec=1.2016 | train/val/test=1.000/0.682/0.695 | c=0.999488
[Epoch 0033] loss=12.8934 cls=0.9720 smmd=0.2431 ct=9.2810 rec=1.1987 | train/val/test=1.000/0.696/0.700 | c=0.999488
[Epoch 0034] loss=13.2280 cls=1.3236 smmd=0.2142 ct=9.2840 rec=1.2031 | train/val/test=1.000/0.698/0.711 | c=0.999488
[Epoch 0035] loss=12.4220 cls=0.5434 smmd=0.1964 ct=9.2849 rec=1.1987 | train/val/test=1.000/0.708/0.705 | c=0.999488
[Epoch 0036] loss=12.9135 cls=1.0468 smmd=0.1864 ct=9.2844 rec=1.1980 | train/val/test=1.000/0.704/0.704 | c=0.999488
[Epoch 0037] loss=12.7670 cls=0.9131 smmd=0.1799 ct=9.2838 rec=1.1951 | train/val/test=1.000/0.712/0.705 | c=0.999488
[Epoch 0038] loss=13.2228 cls=1.3766 smmd=0.1810 ct=9.2753 rec=1.1949 | train/val/test=1.000/0.710/0.701 | c=0.999488
[Epoch 0039] loss=12.6161 cls=0.7855 smmd=0.1872 ct=9.2585 rec=1.1925 | train/val/test=1.000/0.710/0.706 | c=0.999488
[Epoch 0040] loss=12.8312 cls=0.9967 smmd=0.1963 ct=9.2474 rec=1.1954 | train/val/test=1.000/0.714/0.709 | c=0.999488
[Epoch 0041] loss=12.8183 cls=0.9899 smmd=0.1996 ct=9.2353 rec=1.1967 | train/val/test=1.000/0.714/0.707 | c=0.999488
[Epoch 0042] loss=13.0738 cls=1.2438 smmd=0.1952 ct=9.2349 rec=1.2000 | train/val/test=1.000/0.708/0.716 | c=0.999488
[Epoch 0043] loss=12.8030 cls=0.9746 smmd=0.1920 ct=9.2387 rec=1.1988 | train/val/test=1.000/0.708/0.720 | c=0.999488
[Epoch 0044] loss=12.8555 cls=1.0197 smmd=0.1877 ct=9.2464 rec=1.2008 | train/val/test=1.000/0.716/0.728 | c=0.999488
[Epoch 0045] loss=12.3360 cls=0.5162 smmd=0.1779 ct=9.2441 rec=1.1989 | train/val/test=1.000/0.718/0.728 | c=0.999488
[Epoch 0046] loss=12.5220 cls=0.7070 smmd=0.1639 ct=9.2521 rec=1.1995 | train/val/test=1.000/0.720/0.731 | c=0.999488
[Epoch 0047] loss=13.1293 cls=1.3217 smmd=0.1579 ct=9.2513 rec=1.1992 | train/val/test=1.000/0.720/0.735 | c=0.999488
[Epoch 0048] loss=12.7475 cls=0.9493 smmd=0.1505 ct=9.2506 rec=1.1985 | train/val/test=1.000/0.714/0.730 | c=0.999488
[Epoch 0049] loss=12.9143 cls=1.1243 smmd=0.1432 ct=9.2550 rec=1.1959 | train/val/test=1.000/0.708/0.725 | c=0.999488
[Epoch 0050] loss=12.4826 cls=0.7006 smmd=0.1399 ct=9.2557 rec=1.1932 | train/val/test=1.000/0.708/0.721 | c=0.999488
[Epoch 0051] loss=12.8185 cls=1.0325 smmd=0.1378 ct=9.2594 rec=1.1944 | train/val/test=1.000/0.706/0.715 | c=0.999488
[Epoch 0052] loss=12.5111 cls=0.7354 smmd=0.1383 ct=9.2494 rec=1.1940 | train/val/test=1.000/0.706/0.704 | c=0.999488
[Epoch 0053] loss=12.3815 cls=0.6121 smmd=0.1433 ct=9.2476 rec=1.1893 | train/val/test=1.000/0.704/0.704 | c=0.999488
[Epoch 0054] loss=12.6260 cls=0.8396 smmd=0.1497 ct=9.2509 rec=1.1929 | train/val/test=1.000/0.708/0.710 | c=0.999488
[Epoch 0055] loss=12.4425 cls=0.6833 smmd=0.1498 ct=9.2403 rec=1.1845 | train/val/test=1.000/0.714/0.719 | c=0.999488
[Epoch 0056] loss=12.7160 cls=0.9599 smmd=0.1456 ct=9.2380 rec=1.1862 | train/val/test=1.000/0.720/0.728 | c=0.999488
[Epoch 0057] loss=12.3562 cls=0.6081 smmd=0.1478 ct=9.2345 rec=1.1829 | train/val/test=1.000/0.724/0.725 | c=0.999488
[Epoch 0058] loss=12.2677 cls=0.5292 smmd=0.1496 ct=9.2314 rec=1.1787 | train/val/test=1.000/0.722/0.725 | c=0.999488
[Epoch 0059] loss=12.7086 cls=0.9688 smmd=0.1465 ct=9.2345 rec=1.1793 | train/val/test=1.000/0.714/0.721 | c=0.999488
[Epoch 0060] loss=12.4375 cls=0.6942 smmd=0.1507 ct=9.2292 rec=1.1817 | train/val/test=1.000/0.712/0.717 | c=0.999488
[Epoch 0061] loss=12.7882 cls=1.0563 smmd=0.1480 ct=9.2233 rec=1.1803 | train/val/test=1.000/0.710/0.714 | c=0.999488
[Epoch 0062] loss=12.7514 cls=1.0057 smmd=0.1478 ct=9.2280 rec=1.1849 | train/val/test=1.000/0.710/0.717 | c=0.999488
[Epoch 0063] loss=13.0306 cls=1.2907 smmd=0.1504 ct=9.2287 rec=1.1804 | train/val/test=1.000/0.704/0.711 | c=0.999488
[Epoch 0064] loss=12.3509 cls=0.6020 smmd=0.1469 ct=9.2400 rec=1.1810 | train/val/test=1.000/0.710/0.706 | c=0.999488
[Epoch 0065] loss=12.5133 cls=0.7669 smmd=0.1473 ct=9.2333 rec=1.1829 | train/val/test=1.000/0.708/0.707 | c=0.999488
[Epoch 0066] loss=12.4405 cls=0.6998 smmd=0.1471 ct=9.2297 rec=1.1820 | train/val/test=1.000/0.704/0.706 | c=0.999488
[Epoch 0067] loss=12.3517 cls=0.6137 smmd=0.1482 ct=9.2318 rec=1.1790 | train/val/test=1.000/0.702/0.711 | c=0.999488
[Epoch 0068] loss=12.7113 cls=0.9663 smmd=0.1440 ct=9.2339 rec=1.1835 | train/val/test=1.000/0.702/0.711 | c=0.999488
[Epoch 0069] loss=12.8124 cls=1.0824 smmd=0.1498 ct=9.2275 rec=1.1763 | train/val/test=1.000/0.704/0.711 | c=0.999488
[Epoch 0070] loss=12.6264 cls=0.8926 smmd=0.1500 ct=9.2251 rec=1.1794 | train/val/test=1.000/0.702/0.714 | c=0.999488
[Epoch 0071] loss=12.7249 cls=0.9752 smmd=0.1532 ct=9.2305 rec=1.1830 | train/val/test=1.000/0.704/0.710 | c=0.999488
[Epoch 0072] loss=12.4214 cls=0.6816 smmd=0.1552 ct=9.2257 rec=1.1794 | train/val/test=1.000/0.704/0.713 | c=0.999488
[Epoch 0073] loss=12.6635 cls=0.8934 smmd=0.1573 ct=9.2307 rec=1.1911 | train/val/test=1.000/0.704/0.714 | c=0.999488
[Epoch 0074] loss=12.7103 cls=0.9577 smmd=0.1612 ct=9.2229 rec=1.1843 | train/val/test=1.000/0.712/0.716 | c=0.999488
[Epoch 0075] loss=12.4530 cls=0.7082 smmd=0.1610 ct=9.2209 rec=1.1814 | train/val/test=1.000/0.708/0.722 | c=0.999488
[Epoch 0076] loss=12.5915 cls=0.8423 smmd=0.1631 ct=9.2176 rec=1.1843 | train/val/test=1.000/0.704/0.724 | c=0.999488
[Epoch 0077] loss=12.5958 cls=0.8415 smmd=0.1598 ct=9.2197 rec=1.1874 | train/val/test=1.000/0.706/0.727 | c=0.999488
[Epoch 0078] loss=12.6023 cls=0.8569 smmd=0.1576 ct=9.2176 rec=1.1851 | train/val/test=1.000/0.712/0.726 | c=0.999488
[Epoch 0079] loss=12.5678 cls=0.8225 smmd=0.1622 ct=9.2188 rec=1.1822 | train/val/test=1.000/0.710/0.727 | c=0.999488
[Epoch 0080] loss=12.2935 cls=0.5547 smmd=0.1588 ct=9.2161 rec=1.1819 | train/val/test=1.000/0.710/0.724 | c=0.999488
[Epoch 0081] loss=12.3550 cls=0.6106 smmd=0.1581 ct=9.2204 rec=1.1829 | train/val/test=1.000/0.710/0.724 | c=0.999488
[Epoch 0082] loss=12.6737 cls=0.9377 smmd=0.1539 ct=9.2148 rec=1.1836 | train/val/test=1.000/0.706/0.725 | c=0.999488
[Epoch 0083] loss=12.7251 cls=0.9713 smmd=0.1567 ct=9.2216 rec=1.1877 | train/val/test=1.000/0.708/0.723 | c=0.999488
[Epoch 0084] loss=12.7567 cls=1.0056 smmd=0.1566 ct=9.2202 rec=1.1872 | train/val/test=1.000/0.706/0.720 | c=0.999488
[Epoch 0085] loss=12.7194 cls=0.9555 smmd=0.1565 ct=9.2288 rec=1.1893 | train/val/test=1.000/0.704/0.723 | c=0.999488
[Epoch 0086] loss=12.6925 cls=0.9498 smmd=0.1569 ct=9.2210 rec=1.1825 | train/val/test=1.000/0.706/0.725 | c=0.999488
[Epoch 0087] loss=12.3026 cls=0.5674 smmd=0.1577 ct=9.2169 rec=1.1803 | train/val/test=1.000/0.706/0.724 | c=0.999488
[Epoch 0088] loss=12.7710 cls=1.0277 smmd=0.1582 ct=9.2189 rec=1.1831 | train/val/test=1.000/0.706/0.724 | c=0.999488
[Epoch 0089] loss=12.7502 cls=1.0073 smmd=0.1578 ct=9.2206 rec=1.1823 | train/val/test=1.000/0.704/0.723 | c=0.999488
[Epoch 0090] loss=12.6086 cls=0.8661 smmd=0.1591 ct=9.2173 rec=1.1830 | train/val/test=1.000/0.704/0.723 | c=0.999488
[Epoch 0091] loss=12.4287 cls=0.6929 smmd=0.1569 ct=9.2176 rec=1.1806 | train/val/test=1.000/0.704/0.724 | c=0.999488
[Epoch 0092] loss=12.7126 cls=0.9705 smmd=0.1580 ct=9.2227 rec=1.1807 | train/val/test=1.000/0.706/0.725 | c=0.999488
[Epoch 0093] loss=12.2552 cls=0.5174 smmd=0.1568 ct=9.2201 rec=1.1805 | train/val/test=1.000/0.706/0.725 | c=0.999488
[Epoch 0094] loss=12.2188 cls=0.4735 smmd=0.1592 ct=9.2241 rec=1.1810 | train/val/test=1.000/0.706/0.725 | c=0.999488
[Epoch 0095] loss=12.3186 cls=0.5702 smmd=0.1594 ct=9.2194 rec=1.1848 | train/val/test=1.000/0.706/0.725 | c=0.999488
[Epoch 0096] loss=12.4919 cls=0.7480 smmd=0.1593 ct=9.2215 rec=1.1816 | train/val/test=1.000/0.706/0.725 | c=0.999488
[Epoch 0097] loss=12.8431 cls=1.0982 smmd=0.1613 ct=9.2198 rec=1.1819 | train/val/test=1.000/0.706/0.725 | c=0.999488
[Epoch 0098] loss=12.9118 cls=1.1704 smmd=0.1593 ct=9.2201 rec=1.1810 | train/val/test=1.000/0.706/0.725 | c=0.999488
[Epoch 0099] loss=12.6127 cls=0.8664 smmd=0.1600 ct=9.2190 rec=1.1837 | train/val/test=1.000/0.704/0.725 | c=0.999488
=== Best @ epoch 57: val=0.7240, test=0.7250 ===
