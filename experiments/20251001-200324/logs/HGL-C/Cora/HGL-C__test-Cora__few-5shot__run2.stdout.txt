Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=17.2145 cls=2.0965 smmd=3.0649 ct=9.2730 rec=1.3900 | train/val/test=0.207/0.074/0.094 | c=0.999488
[Epoch 0001] loss=17.0732 cls=2.0332 smmd=2.9902 ct=9.2701 rec=1.3899 | train/val/test=0.172/0.184/0.168 | c=0.999488
[Epoch 0002] loss=16.7473 cls=1.8367 smmd=2.8564 ct=9.2656 rec=1.3943 | train/val/test=0.552/0.308/0.298 | c=0.999488
[Epoch 0003] loss=16.4388 cls=1.7144 smmd=2.6857 ct=9.2591 rec=1.3898 | train/val/test=0.724/0.448/0.453 | c=0.999488
[Epoch 0004] loss=16.1157 cls=1.6369 smmd=2.4617 ct=9.2444 rec=1.3863 | train/val/test=0.793/0.408/0.400 | c=0.999488
[Epoch 0005] loss=15.5642 cls=1.4122 smmd=2.1772 ct=9.2118 rec=1.3815 | train/val/test=0.931/0.410/0.403 | c=0.999488
[Epoch 0006] loss=15.0527 cls=1.3122 smmd=1.8617 ct=9.1495 rec=1.3646 | train/val/test=0.897/0.496/0.496 | c=0.999488
[Epoch 0007] loss=14.6770 cls=1.4183 smmd=1.5176 ct=9.0636 rec=1.3387 | train/val/test=0.897/0.612/0.600 | c=0.999488
[Epoch 0008] loss=14.0466 cls=1.1762 smmd=1.1707 ct=9.0413 rec=1.3292 | train/val/test=1.000/0.622/0.628 | c=0.999488
[Epoch 0009] loss=13.5426 cls=1.1699 smmd=0.8460 ct=8.9640 rec=1.2813 | train/val/test=1.000/0.550/0.552 | c=0.999488
[Epoch 0010] loss=13.1210 cls=1.1492 smmd=0.5583 ct=8.8953 rec=1.2591 | train/val/test=1.000/0.564/0.555 | c=0.999488
[Epoch 0011] loss=13.0722 cls=0.6762 smmd=0.3504 ct=9.5633 rec=1.2412 | train/val/test=1.000/0.622/0.626 | c=0.999488
[Epoch 0012] loss=13.5896 cls=1.4840 smmd=0.2625 ct=9.4048 rec=1.2192 | train/val/test=1.000/0.660/0.669 | c=0.999488
[Epoch 0013] loss=12.8358 cls=0.7577 smmd=0.3051 ct=9.3183 rec=1.2274 | train/val/test=1.000/0.658/0.665 | c=0.999488
[Epoch 0014] loss=12.6631 cls=0.5777 smmd=0.4302 ct=9.2052 rec=1.2250 | train/val/test=1.000/0.628/0.654 | c=0.999488
[Epoch 0015] loss=13.0148 cls=0.8724 smmd=0.5915 ct=9.1225 rec=1.2142 | train/val/test=0.966/0.642/0.652 | c=0.999488
[Epoch 0016] loss=13.1046 cls=0.8713 smmd=0.7327 ct=9.0847 rec=1.2080 | train/val/test=0.966/0.664/0.665 | c=0.999488
[Epoch 0017] loss=13.4377 cls=1.1008 smmd=0.8397 ct=9.0847 rec=1.2062 | train/val/test=0.931/0.662/0.684 | c=0.999488
[Epoch 0018] loss=13.2348 cls=0.8346 smmd=0.8948 ct=9.0828 rec=1.2112 | train/val/test=0.931/0.632/0.659 | c=0.999488
[Epoch 0019] loss=13.5904 cls=1.1586 smmd=0.8967 ct=9.0840 rec=1.2255 | train/val/test=1.000/0.668/0.693 | c=0.999488
[Epoch 0020] loss=13.2537 cls=0.9118 smmd=0.8436 ct=9.0701 rec=1.2141 | train/val/test=1.000/0.670/0.672 | c=0.999488
[Epoch 0021] loss=13.2816 cls=1.0366 smmd=0.7560 ct=9.0740 rec=1.2075 | train/val/test=1.000/0.648/0.655 | c=0.999488
[Epoch 0022] loss=12.7863 cls=0.6114 smmd=0.6509 ct=9.1016 rec=1.2112 | train/val/test=0.966/0.642/0.657 | c=0.999488
[Epoch 0023] loss=12.8137 cls=0.7046 smmd=0.5465 ct=9.1362 rec=1.2132 | train/val/test=0.966/0.652/0.656 | c=0.999488
[Epoch 0024] loss=13.0239 cls=0.9848 smmd=0.4474 ct=9.1632 rec=1.2142 | train/val/test=0.931/0.664/0.664 | c=0.999488
[Epoch 0025] loss=12.7198 cls=0.7573 smmd=0.3651 ct=9.1950 rec=1.2012 | train/val/test=0.966/0.658/0.674 | c=0.999488
[Epoch 0026] loss=12.9219 cls=0.9514 smmd=0.3159 ct=9.2461 rec=1.2042 | train/val/test=0.966/0.664/0.679 | c=0.999488
[Epoch 0027] loss=13.6609 cls=1.7000 smmd=0.2800 ct=9.2712 rec=1.2048 | train/val/test=0.966/0.678/0.687 | c=0.999488
[Epoch 0028] loss=13.1637 cls=1.2035 smmd=0.2586 ct=9.2912 rec=1.2052 | train/val/test=0.966/0.674/0.694 | c=0.999488
[Epoch 0029] loss=12.8393 cls=0.8740 smmd=0.2562 ct=9.2946 rec=1.2073 | train/val/test=1.000/0.680/0.689 | c=0.999488
[Epoch 0030] loss=12.9359 cls=0.9610 smmd=0.2585 ct=9.3015 rec=1.2075 | train/val/test=1.000/0.680/0.688 | c=0.999488
[Epoch 0031] loss=12.8230 cls=0.8683 smmd=0.2544 ct=9.2763 rec=1.2120 | train/val/test=1.000/0.658/0.684 | c=0.999488
[Epoch 0032] loss=12.9567 cls=1.0273 smmd=0.2460 ct=9.2660 rec=1.2087 | train/val/test=1.000/0.662/0.671 | c=0.999488
[Epoch 0033] loss=12.7949 cls=0.8762 smmd=0.2467 ct=9.2439 rec=1.2140 | train/val/test=1.000/0.652/0.666 | c=0.999488
[Epoch 0034] loss=12.6401 cls=0.7412 smmd=0.2444 ct=9.2316 rec=1.2114 | train/val/test=1.000/0.642/0.665 | c=0.999488
[Epoch 0035] loss=12.9153 cls=1.0191 smmd=0.2392 ct=9.2259 rec=1.2156 | train/val/test=1.000/0.644/0.667 | c=0.999488
[Epoch 0036] loss=12.9228 cls=1.0507 smmd=0.2349 ct=9.2142 rec=1.2115 | train/val/test=1.000/0.644/0.671 | c=0.999488
[Epoch 0037] loss=12.8139 cls=0.9450 smmd=0.2251 ct=9.2152 rec=1.2143 | train/val/test=1.000/0.644/0.669 | c=0.999488
[Epoch 0038] loss=13.0061 cls=1.1562 smmd=0.2140 ct=9.2155 rec=1.2102 | train/val/test=1.000/0.658/0.683 | c=0.999488
[Epoch 0039] loss=12.6171 cls=0.7798 smmd=0.2038 ct=9.2146 rec=1.2094 | train/val/test=1.000/0.672/0.689 | c=0.999488
[Epoch 0040] loss=12.5942 cls=0.7697 smmd=0.1952 ct=9.2184 rec=1.2054 | train/val/test=1.000/0.680/0.696 | c=0.999488
[Epoch 0041] loss=12.2654 cls=0.4526 smmd=0.1856 ct=9.2307 rec=1.1982 | train/val/test=1.000/0.688/0.703 | c=0.999488
[Epoch 0042] loss=13.4875 cls=1.6778 smmd=0.1774 ct=9.2349 rec=1.1987 | train/val/test=1.000/0.684/0.703 | c=0.999488
[Epoch 0043] loss=12.7328 cls=0.9358 smmd=0.1677 ct=9.2400 rec=1.1946 | train/val/test=1.000/0.682/0.705 | c=0.999488
[Epoch 0044] loss=12.5191 cls=0.7414 smmd=0.1593 ct=9.2342 rec=1.1921 | train/val/test=1.000/0.680/0.701 | c=0.999488
[Epoch 0045] loss=12.7331 cls=0.9671 smmd=0.1522 ct=9.2350 rec=1.1894 | train/val/test=1.000/0.676/0.694 | c=0.999488
[Epoch 0046] loss=12.2910 cls=0.5235 smmd=0.1497 ct=9.2371 rec=1.1904 | train/val/test=1.000/0.664/0.684 | c=0.999488
[Epoch 0047] loss=12.8891 cls=1.1200 smmd=0.1502 ct=9.2363 rec=1.1913 | train/val/test=1.000/0.662/0.681 | c=0.999488
[Epoch 0048] loss=12.5339 cls=0.7743 smmd=0.1507 ct=9.2281 rec=1.1904 | train/val/test=1.000/0.656/0.685 | c=0.999488
[Epoch 0049] loss=12.3858 cls=0.6369 smmd=0.1431 ct=9.2254 rec=1.1902 | train/val/test=1.000/0.650/0.681 | c=0.999488
[Epoch 0050] loss=12.5386 cls=0.7995 smmd=0.1442 ct=9.2129 rec=1.1910 | train/val/test=1.000/0.648/0.682 | c=0.999488
[Epoch 0051] loss=12.3389 cls=0.5962 smmd=0.1466 ct=9.2114 rec=1.1923 | train/val/test=1.000/0.654/0.683 | c=0.999488
[Epoch 0052] loss=12.6218 cls=0.8800 smmd=0.1500 ct=9.2101 rec=1.1908 | train/val/test=1.000/0.662/0.679 | c=0.999488
[Epoch 0053] loss=12.8270 cls=1.1043 smmd=0.1450 ct=9.2047 rec=1.1865 | train/val/test=1.000/0.664/0.679 | c=0.999488
[Epoch 0054] loss=12.6333 cls=0.9138 smmd=0.1445 ct=9.2083 rec=1.1833 | train/val/test=1.000/0.664/0.679 | c=0.999488
[Epoch 0055] loss=12.4740 cls=0.7546 smmd=0.1449 ct=9.2134 rec=1.1805 | train/val/test=1.000/0.664/0.676 | c=0.999488
[Epoch 0056] loss=12.5679 cls=0.8490 smmd=0.1405 ct=9.2121 rec=1.1832 | train/val/test=1.000/0.662/0.676 | c=0.999488
[Epoch 0057] loss=12.6671 cls=0.9410 smmd=0.1401 ct=9.2122 rec=1.1869 | train/val/test=1.000/0.670/0.681 | c=0.999488
[Epoch 0058] loss=12.8054 cls=1.0740 smmd=0.1377 ct=9.2170 rec=1.1884 | train/val/test=1.000/0.676/0.688 | c=0.999488
[Epoch 0059] loss=12.7659 cls=1.0358 smmd=0.1374 ct=9.2146 rec=1.1891 | train/val/test=1.000/0.668/0.689 | c=0.999488
[Epoch 0060] loss=12.1742 cls=0.4532 smmd=0.1402 ct=9.2096 rec=1.1856 | train/val/test=1.000/0.670/0.690 | c=0.999488
[Epoch 0061] loss=12.9300 cls=1.2015 smmd=0.1443 ct=9.2094 rec=1.1874 | train/val/test=1.000/0.676/0.691 | c=0.999488
[Epoch 0062] loss=12.8876 cls=1.1553 smmd=0.1450 ct=9.2072 rec=1.1901 | train/val/test=1.000/0.674/0.693 | c=0.999488
[Epoch 0063] loss=12.5284 cls=0.8102 smmd=0.1412 ct=9.2029 rec=1.1870 | train/val/test=1.000/0.672/0.687 | c=0.999488
[Epoch 0064] loss=12.6160 cls=0.8975 smmd=0.1424 ct=9.2011 rec=1.1876 | train/val/test=1.000/0.674/0.685 | c=0.999488
[Epoch 0065] loss=12.2798 cls=0.5509 smmd=0.1447 ct=9.2075 rec=1.1883 | train/val/test=1.000/0.674/0.685 | c=0.999488
[Epoch 0066] loss=12.6924 cls=0.9611 smmd=0.1491 ct=9.2068 rec=1.1877 | train/val/test=1.000/0.672/0.685 | c=0.999488
[Epoch 0067] loss=12.8598 cls=1.1388 smmd=0.1469 ct=9.2000 rec=1.1871 | train/val/test=1.000/0.674/0.686 | c=0.999488
[Epoch 0068] loss=12.7019 cls=0.9713 smmd=0.1506 ct=9.1952 rec=1.1924 | train/val/test=1.000/0.666/0.685 | c=0.999488
[Epoch 0069] loss=12.4708 cls=0.7517 smmd=0.1464 ct=9.1893 rec=1.1917 | train/val/test=1.000/0.666/0.684 | c=0.999488
[Epoch 0070] loss=12.6683 cls=0.9249 smmd=0.1532 ct=9.1951 rec=1.1975 | train/val/test=1.000/0.670/0.685 | c=0.999488
[Epoch 0071] loss=13.0610 cls=1.3290 smmd=0.1531 ct=9.1918 rec=1.1935 | train/val/test=1.000/0.668/0.689 | c=0.999488
[Epoch 0072] loss=12.5811 cls=0.8549 smmd=0.1533 ct=9.1888 rec=1.1920 | train/val/test=1.000/0.674/0.698 | c=0.999488
[Epoch 0073] loss=12.8951 cls=1.1612 smmd=0.1540 ct=9.1902 rec=1.1948 | train/val/test=1.000/0.674/0.697 | c=0.999488
[Epoch 0074] loss=12.5519 cls=0.8255 smmd=0.1526 ct=9.1908 rec=1.1915 | train/val/test=1.000/0.674/0.695 | c=0.999488
[Epoch 0075] loss=12.5137 cls=0.7927 smmd=0.1509 ct=9.1897 rec=1.1902 | train/val/test=1.000/0.674/0.698 | c=0.999488
[Epoch 0076] loss=12.7153 cls=0.9883 smmd=0.1518 ct=9.1915 rec=1.1919 | train/val/test=1.000/0.678/0.697 | c=0.999488
[Epoch 0077] loss=12.4957 cls=0.7666 smmd=0.1544 ct=9.1893 rec=1.1927 | train/val/test=1.000/0.674/0.695 | c=0.999488
[Epoch 0078] loss=12.2329 cls=0.5004 smmd=0.1543 ct=9.1914 rec=1.1934 | train/val/test=1.000/0.672/0.691 | c=0.999488
[Epoch 0079] loss=12.6489 cls=0.9087 smmd=0.1516 ct=9.1866 rec=1.2010 | train/val/test=1.000/0.672/0.691 | c=0.999488
[Epoch 0080] loss=12.4913 cls=0.7752 smmd=0.1523 ct=9.1833 rec=1.1903 | train/val/test=1.000/0.672/0.690 | c=0.999488
[Epoch 0081] loss=12.6539 cls=0.9340 smmd=0.1511 ct=9.1875 rec=1.1907 | train/val/test=1.000/0.674/0.693 | c=0.999488
[Epoch 0082] loss=12.2742 cls=0.5553 smmd=0.1525 ct=9.1894 rec=1.1885 | train/val/test=1.000/0.674/0.690 | c=0.999488
[Epoch 0083] loss=12.2450 cls=0.5275 smmd=0.1504 ct=9.1896 rec=1.1887 | train/val/test=1.000/0.676/0.690 | c=0.999488
[Epoch 0084] loss=12.6217 cls=0.9022 smmd=0.1543 ct=9.1862 rec=1.1895 | train/val/test=1.000/0.678/0.691 | c=0.999488
[Epoch 0085] loss=12.6578 cls=0.9359 smmd=0.1513 ct=9.1889 rec=1.1908 | train/val/test=1.000/0.672/0.691 | c=0.999488
[Epoch 0086] loss=12.4741 cls=0.7581 smmd=0.1519 ct=9.1871 rec=1.1885 | train/val/test=1.000/0.674/0.694 | c=0.999488
[Epoch 0087] loss=12.6704 cls=0.9566 smmd=0.1518 ct=9.1882 rec=1.1869 | train/val/test=1.000/0.674/0.694 | c=0.999488
[Epoch 0088] loss=12.4833 cls=0.7695 smmd=0.1513 ct=9.1891 rec=1.1867 | train/val/test=1.000/0.674/0.694 | c=0.999488
[Epoch 0089] loss=12.4954 cls=0.7829 smmd=0.1519 ct=9.1851 rec=1.1877 | train/val/test=1.000/0.674/0.694 | c=0.999488
[Epoch 0090] loss=12.4129 cls=0.6928 smmd=0.1536 ct=9.1881 rec=1.1892 | train/val/test=1.000/0.672/0.694 | c=0.999488
[Epoch 0091] loss=12.8162 cls=1.1052 smmd=0.1518 ct=9.1850 rec=1.1871 | train/val/test=1.000/0.672/0.693 | c=0.999488
[Epoch 0092] loss=12.8265 cls=1.0938 smmd=0.1513 ct=9.1933 rec=1.1940 | train/val/test=1.000/0.672/0.693 | c=0.999488
[Epoch 0093] loss=12.3191 cls=0.6049 smmd=0.1531 ct=9.1868 rec=1.1871 | train/val/test=1.000/0.672/0.693 | c=0.999488
[Epoch 0094] loss=12.1926 cls=0.4845 smmd=0.1561 ct=9.1859 rec=1.1831 | train/val/test=1.000/0.672/0.693 | c=0.999488
[Epoch 0095] loss=12.6548 cls=0.9316 smmd=0.1542 ct=9.1888 rec=1.1901 | train/val/test=1.000/0.672/0.693 | c=0.999488
[Epoch 0096] loss=12.4038 cls=0.6920 smmd=0.1532 ct=9.1867 rec=1.1860 | train/val/test=1.000/0.672/0.693 | c=0.999488
[Epoch 0097] loss=12.3115 cls=0.5947 smmd=0.1553 ct=9.1864 rec=1.1875 | train/val/test=1.000/0.672/0.693 | c=0.999488
[Epoch 0098] loss=12.8039 cls=1.0602 smmd=0.1529 ct=9.1957 rec=1.1975 | train/val/test=1.000/0.672/0.693 | c=0.999488
[Epoch 0099] loss=12.3346 cls=0.6187 smmd=0.1535 ct=9.1866 rec=1.1879 | train/val/test=1.000/0.672/0.693 | c=0.999488
=== Best @ epoch 41: val=0.6880, test=0.7030 ===
