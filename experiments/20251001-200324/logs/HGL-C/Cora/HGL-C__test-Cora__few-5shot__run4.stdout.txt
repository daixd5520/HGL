Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=17.4169 cls=2.2588 smmd=3.1013 ct=9.2691 rec=1.3938 | train/val/test=0.207/0.176/0.188 | c=0.999488
[Epoch 0001] loss=17.1122 cls=2.0330 smmd=3.0348 ct=9.2677 rec=1.3884 | train/val/test=0.310/0.146/0.186 | c=0.999488
[Epoch 0002] loss=16.8635 cls=1.8827 smmd=2.9195 ct=9.2661 rec=1.3976 | train/val/test=0.345/0.156/0.192 | c=0.999488
[Epoch 0003] loss=16.7109 cls=1.9011 smmd=2.7584 ct=9.2597 rec=1.3958 | train/val/test=0.655/0.248/0.255 | c=0.999488
[Epoch 0004] loss=16.4044 cls=1.8321 smmd=2.5532 ct=9.2453 rec=1.3869 | train/val/test=0.828/0.336/0.359 | c=0.999488
[Epoch 0005] loss=15.6970 cls=1.4131 smmd=2.3025 ct=9.2167 rec=1.3824 | train/val/test=0.897/0.448/0.476 | c=0.999488
[Epoch 0006] loss=15.2773 cls=1.3725 smmd=1.9999 ct=9.1658 rec=1.3695 | train/val/test=0.966/0.434/0.452 | c=0.999488
[Epoch 0007] loss=14.6994 cls=1.2540 smmd=1.6507 ct=9.0913 rec=1.3517 | train/val/test=0.966/0.514/0.537 | c=0.999488
[Epoch 0008] loss=13.8867 cls=0.9452 smmd=1.2813 ct=9.0123 rec=1.3239 | train/val/test=0.966/0.556/0.600 | c=0.999488
[Epoch 0009] loss=13.5412 cls=1.0792 smmd=0.9141 ct=8.9472 rec=1.3004 | train/val/test=0.966/0.532/0.556 | c=0.999488
[Epoch 0010] loss=12.8750 cls=0.8339 smmd=0.5968 ct=8.8946 rec=1.2748 | train/val/test=0.966/0.618/0.634 | c=0.999488
[Epoch 0011] loss=12.6794 cls=0.9884 smmd=0.3753 ct=8.8353 rec=1.2402 | train/val/test=0.966/0.558/0.599 | c=0.999488
[Epoch 0012] loss=12.5799 cls=0.9538 smmd=0.2922 ct=8.8494 rec=1.2422 | train/val/test=0.966/0.622/0.640 | c=0.999488
[Epoch 0013] loss=12.5003 cls=0.9069 smmd=0.3052 ct=8.8372 rec=1.2255 | train/val/test=1.000/0.652/0.695 | c=0.999488
[Epoch 0014] loss=12.4521 cls=0.8241 smmd=0.3855 ct=8.8255 rec=1.2085 | train/val/test=1.000/0.602/0.628 | c=0.999488
[Epoch 0015] loss=12.8109 cls=1.0097 smmd=0.4993 ct=8.8573 rec=1.2223 | train/val/test=0.966/0.662/0.695 | c=0.999488
[Epoch 0016] loss=12.5679 cls=0.7180 smmd=0.5987 ct=8.8304 rec=1.2104 | train/val/test=0.966/0.648/0.701 | c=0.999488
[Epoch 0017] loss=13.1693 cls=1.2877 smmd=0.6552 ct=8.8141 rec=1.2061 | train/val/test=0.966/0.662/0.698 | c=0.999488
[Epoch 0018] loss=12.7034 cls=0.8305 smmd=0.6754 ct=8.7985 rec=1.1995 | train/val/test=0.966/0.630/0.653 | c=0.999488
[Epoch 0019] loss=12.9286 cls=1.0772 smmd=0.6532 ct=8.7876 rec=1.2053 | train/val/test=0.966/0.630/0.660 | c=0.999488
[Epoch 0020] loss=12.6363 cls=0.8922 smmd=0.5843 ct=8.7670 rec=1.1964 | train/val/test=0.931/0.652/0.683 | c=0.999488
[Epoch 0021] loss=12.6447 cls=1.0174 smmd=0.4802 ct=8.7647 rec=1.1912 | train/val/test=0.931/0.668/0.695 | c=0.999488
[Epoch 0022] loss=12.4350 cls=0.8630 smmd=0.3912 ct=8.7920 rec=1.1944 | train/val/test=0.931/0.672/0.694 | c=0.999488
[Epoch 0023] loss=12.5878 cls=1.0249 smmd=0.3231 ct=8.8194 rec=1.2102 | train/val/test=0.931/0.674/0.696 | c=0.999488
[Epoch 0024] loss=12.8613 cls=1.3830 smmd=0.2654 ct=8.7994 rec=1.2068 | train/val/test=0.931/0.672/0.712 | c=0.999488
[Epoch 0025] loss=12.1393 cls=0.7280 smmd=0.2293 ct=8.7696 rec=1.2062 | train/val/test=0.931/0.654/0.706 | c=0.999488
[Epoch 0026] loss=12.2170 cls=0.8325 smmd=0.2281 ct=8.7497 rec=1.2034 | train/val/test=0.966/0.652/0.696 | c=0.999488
[Epoch 0027] loss=12.2918 cls=0.8828 smmd=0.2441 ct=8.7471 rec=1.2089 | train/val/test=0.966/0.660/0.688 | c=0.999488
[Epoch 0028] loss=12.2276 cls=0.7967 smmd=0.2640 ct=8.7440 rec=1.2114 | train/val/test=0.966/0.658/0.695 | c=0.999488
[Epoch 0029] loss=12.2238 cls=0.7842 smmd=0.2725 ct=8.7394 rec=1.2138 | train/val/test=0.966/0.664/0.694 | c=0.999488
[Epoch 0030] loss=12.5746 cls=1.1593 smmd=0.2650 ct=8.7247 rec=1.2128 | train/val/test=0.966/0.670/0.702 | c=0.999488
[Epoch 0031] loss=12.4545 cls=1.0376 smmd=0.2486 ct=8.7352 rec=1.2165 | train/val/test=0.966/0.668/0.712 | c=0.999488
[Epoch 0032] loss=12.1866 cls=0.8162 smmd=0.2217 ct=8.7316 rec=1.2086 | train/val/test=1.000/0.666/0.711 | c=0.999488
[Epoch 0033] loss=12.2144 cls=0.8752 smmd=0.1960 ct=8.7343 rec=1.2044 | train/val/test=1.000/0.668/0.711 | c=0.999488
[Epoch 0034] loss=12.2420 cls=0.9196 smmd=0.1742 ct=8.7437 rec=1.2022 | train/val/test=1.000/0.670/0.718 | c=0.999488
[Epoch 0035] loss=12.4970 cls=1.1872 smmd=0.1575 ct=8.7474 rec=1.2025 | train/val/test=1.000/0.668/0.721 | c=0.999488
[Epoch 0036] loss=11.8125 cls=0.5253 smmd=0.1437 ct=8.7421 rec=1.2007 | train/val/test=1.000/0.670/0.721 | c=0.999488
[Epoch 0037] loss=12.4519 cls=1.1914 smmd=0.1323 ct=8.7363 rec=1.1960 | train/val/test=1.000/0.678/0.720 | c=0.999488
[Epoch 0038] loss=12.0706 cls=0.8297 smmd=0.1234 ct=8.7316 rec=1.1929 | train/val/test=1.000/0.672/0.721 | c=0.999488
[Epoch 0039] loss=12.7681 cls=0.8397 smmd=0.1241 ct=9.4204 rec=1.1919 | train/val/test=1.000/0.674/0.718 | c=0.999488
[Epoch 0040] loss=12.7074 cls=0.8033 smmd=0.1237 ct=9.4008 rec=1.1899 | train/val/test=1.000/0.676/0.722 | c=0.999488
[Epoch 0041] loss=13.0630 cls=1.1918 smmd=0.1258 ct=9.3623 rec=1.1916 | train/val/test=1.000/0.676/0.714 | c=0.999488
[Epoch 0042] loss=12.8799 cls=1.0245 smmd=0.1364 ct=9.3305 rec=1.1942 | train/val/test=1.000/0.672/0.710 | c=0.999488
[Epoch 0043] loss=13.2238 cls=1.3954 smmd=0.1506 ct=9.3004 rec=1.1888 | train/val/test=1.000/0.670/0.705 | c=0.999488
[Epoch 0044] loss=12.6063 cls=0.7722 smmd=0.1738 ct=9.2705 rec=1.1949 | train/val/test=1.000/0.676/0.707 | c=0.999488
[Epoch 0045] loss=12.4769 cls=0.6479 smmd=0.1886 ct=9.2541 rec=1.1931 | train/val/test=1.000/0.678/0.716 | c=0.999488
[Epoch 0046] loss=12.3035 cls=0.4857 smmd=0.1984 ct=9.2446 rec=1.1874 | train/val/test=1.000/0.682/0.726 | c=0.999488
[Epoch 0047] loss=12.5439 cls=0.7154 smmd=0.1998 ct=9.2443 rec=1.1922 | train/val/test=1.000/0.682/0.732 | c=0.999488
[Epoch 0048] loss=12.9164 cls=1.0986 smmd=0.1922 ct=9.2483 rec=1.1887 | train/val/test=1.000/0.678/0.734 | c=0.999488
[Epoch 0049] loss=12.6434 cls=0.8291 smmd=0.1807 ct=9.2593 rec=1.1871 | train/val/test=1.000/0.680/0.733 | c=0.999488
[Epoch 0050] loss=12.6629 cls=0.8488 smmd=0.1656 ct=9.2707 rec=1.1889 | train/val/test=1.000/0.676/0.730 | c=0.999488
[Epoch 0051] loss=12.7481 cls=0.9330 smmd=0.1511 ct=9.2873 rec=1.1883 | train/val/test=1.000/0.682/0.729 | c=0.999488
[Epoch 0052] loss=12.7307 cls=0.9304 smmd=0.1358 ct=9.2953 rec=1.1846 | train/val/test=1.000/0.686/0.727 | c=0.999488
[Epoch 0053] loss=12.5435 cls=0.7430 smmd=0.1228 ct=9.3042 rec=1.1868 | train/val/test=1.000/0.682/0.728 | c=0.999488
[Epoch 0054] loss=12.7996 cls=1.0066 smmd=0.1169 ct=9.3043 rec=1.1859 | train/val/test=1.000/0.684/0.719 | c=0.999488
[Epoch 0055] loss=12.6822 cls=0.8815 smmd=0.1178 ct=9.3040 rec=1.1894 | train/val/test=1.000/0.676/0.715 | c=0.999488
[Epoch 0056] loss=12.8166 cls=1.0197 smmd=0.1195 ct=9.2979 rec=1.1897 | train/val/test=1.000/0.682/0.717 | c=0.999488
[Epoch 0057] loss=12.4182 cls=0.6327 smmd=0.1200 ct=9.2939 rec=1.1858 | train/val/test=1.000/0.676/0.717 | c=0.999488
[Epoch 0058] loss=12.9857 cls=1.2041 smmd=0.1196 ct=9.2864 rec=1.1878 | train/val/test=1.000/0.678/0.719 | c=0.999488
[Epoch 0059] loss=12.4614 cls=0.6862 smmd=0.1235 ct=9.2841 rec=1.1838 | train/val/test=1.000/0.678/0.722 | c=0.999488
[Epoch 0060] loss=12.6486 cls=0.8661 smmd=0.1324 ct=9.2782 rec=1.1860 | train/val/test=1.000/0.680/0.722 | c=0.999488
[Epoch 0061] loss=13.0915 cls=1.3020 smmd=0.1340 ct=9.2746 rec=1.1905 | train/val/test=1.000/0.684/0.725 | c=0.999488
[Epoch 0062] loss=12.5942 cls=0.7988 smmd=0.1367 ct=9.2744 rec=1.1922 | train/val/test=1.000/0.688/0.728 | c=0.999488
[Epoch 0063] loss=12.3844 cls=0.6066 smmd=0.1337 ct=9.2670 rec=1.1885 | train/val/test=1.000/0.688/0.723 | c=0.999488
[Epoch 0064] loss=12.4913 cls=0.7058 smmd=0.1293 ct=9.2801 rec=1.1881 | train/val/test=1.000/0.682/0.720 | c=0.999488
[Epoch 0065] loss=12.5007 cls=0.7354 smmd=0.1280 ct=9.2709 rec=1.1832 | train/val/test=1.000/0.680/0.720 | c=0.999488
[Epoch 0066] loss=12.8650 cls=1.0800 smmd=0.1322 ct=9.2730 rec=1.1899 | train/val/test=1.000/0.680/0.716 | c=0.999488
[Epoch 0067] loss=12.5481 cls=0.7742 smmd=0.1358 ct=9.2734 rec=1.1824 | train/val/test=1.000/0.678/0.716 | c=0.999488
[Epoch 0068] loss=12.7566 cls=0.9838 smmd=0.1326 ct=9.2720 rec=1.1841 | train/val/test=1.000/0.674/0.713 | c=0.999488
[Epoch 0069] loss=12.6152 cls=0.8501 smmd=0.1381 ct=9.2623 rec=1.1824 | train/val/test=1.000/0.676/0.714 | c=0.999488
[Epoch 0070] loss=12.3652 cls=0.5989 smmd=0.1416 ct=9.2593 rec=1.1827 | train/val/test=1.000/0.682/0.719 | c=0.999488
[Epoch 0071] loss=12.6752 cls=0.9083 smmd=0.1382 ct=9.2611 rec=1.1838 | train/val/test=1.000/0.686/0.722 | c=0.999488
[Epoch 0072] loss=12.8168 cls=1.0272 smmd=0.1411 ct=9.2649 rec=1.1918 | train/val/test=1.000/0.684/0.722 | c=0.999488
[Epoch 0073] loss=12.9435 cls=1.1747 smmd=0.1389 ct=9.2617 rec=1.1841 | train/val/test=1.000/0.684/0.720 | c=0.999488
[Epoch 0074] loss=12.4284 cls=0.6650 smmd=0.1380 ct=9.2639 rec=1.1807 | train/val/test=1.000/0.682/0.721 | c=0.999488
[Epoch 0075] loss=12.8553 cls=1.0885 smmd=0.1386 ct=9.2640 rec=1.1821 | train/val/test=1.000/0.682/0.720 | c=0.999488
[Epoch 0076] loss=12.4195 cls=0.6503 smmd=0.1382 ct=9.2664 rec=1.1823 | train/val/test=1.000/0.682/0.722 | c=0.999488
[Epoch 0077] loss=12.8031 cls=1.0452 smmd=0.1366 ct=9.2644 rec=1.1784 | train/val/test=1.000/0.680/0.722 | c=0.999488
[Epoch 0078] loss=12.3800 cls=0.6132 smmd=0.1393 ct=9.2658 rec=1.1809 | train/val/test=1.000/0.678/0.721 | c=0.999488
[Epoch 0079] loss=12.7257 cls=0.9602 smmd=0.1340 ct=9.2665 rec=1.1825 | train/val/test=1.000/0.678/0.721 | c=0.999488
[Epoch 0080] loss=12.6039 cls=0.8383 smmd=0.1373 ct=9.2651 rec=1.1816 | train/val/test=1.000/0.678/0.723 | c=0.999488
[Epoch 0081] loss=12.9024 cls=1.1291 smmd=0.1344 ct=9.2645 rec=1.1872 | train/val/test=1.000/0.680/0.722 | c=0.999488
[Epoch 0082] loss=12.7378 cls=0.9675 smmd=0.1355 ct=9.2694 rec=1.1827 | train/val/test=1.000/0.676/0.722 | c=0.999488
[Epoch 0083] loss=12.6609 cls=0.8931 smmd=0.1359 ct=9.2700 rec=1.1809 | train/val/test=1.000/0.676/0.722 | c=0.999488
[Epoch 0084] loss=12.2123 cls=0.4391 smmd=0.1329 ct=9.2708 rec=1.1847 | train/val/test=1.000/0.678/0.720 | c=0.999488
[Epoch 0085] loss=12.8596 cls=1.0881 smmd=0.1363 ct=9.2718 rec=1.1817 | train/val/test=1.000/0.678/0.720 | c=0.999488
[Epoch 0086] loss=12.8405 cls=1.0735 smmd=0.1370 ct=9.2697 rec=1.1801 | train/val/test=1.000/0.676/0.720 | c=0.999488
[Epoch 0087] loss=12.9143 cls=1.1297 smmd=0.1378 ct=9.2717 rec=1.1876 | train/val/test=1.000/0.676/0.720 | c=0.999488
[Epoch 0088] loss=12.8123 cls=1.0212 smmd=0.1391 ct=9.2665 rec=1.1927 | train/val/test=1.000/0.678/0.720 | c=0.999488
[Epoch 0089] loss=12.5922 cls=0.8228 smmd=0.1371 ct=9.2679 rec=1.1822 | train/val/test=1.000/0.678/0.721 | c=0.999488
[Epoch 0090] loss=12.1238 cls=0.3594 smmd=0.1389 ct=9.2705 rec=1.1774 | train/val/test=1.000/0.678/0.720 | c=0.999488
[Epoch 0091] loss=12.4508 cls=0.6841 smmd=0.1409 ct=9.2644 rec=1.1807 | train/val/test=1.000/0.680/0.720 | c=0.999488
[Epoch 0092] loss=12.6876 cls=0.9186 smmd=0.1386 ct=9.2607 rec=1.1848 | train/val/test=1.000/0.680/0.720 | c=0.999488
[Epoch 0093] loss=12.9848 cls=1.2007 smmd=0.1382 ct=9.2690 rec=1.1884 | train/val/test=1.000/0.680/0.720 | c=0.999488
[Epoch 0094] loss=12.5218 cls=0.7541 smmd=0.1393 ct=9.2638 rec=1.1823 | train/val/test=1.000/0.680/0.720 | c=0.999488
[Epoch 0095] loss=12.3686 cls=0.6056 smmd=0.1385 ct=9.2625 rec=1.1810 | train/val/test=1.000/0.680/0.720 | c=0.999488
[Epoch 0096] loss=12.6219 cls=0.8427 smmd=0.1419 ct=9.2695 rec=1.1839 | train/val/test=1.000/0.680/0.720 | c=0.999488
[Epoch 0097] loss=12.7418 cls=0.9769 smmd=0.1399 ct=9.2640 rec=1.1805 | train/val/test=1.000/0.680/0.720 | c=0.999488
[Epoch 0098] loss=12.6818 cls=0.9173 smmd=0.1374 ct=9.2660 rec=1.1806 | train/val/test=1.000/0.680/0.720 | c=0.999488
[Epoch 0099] loss=12.5564 cls=0.7855 smmd=0.1404 ct=9.2671 rec=1.1817 | train/val/test=1.000/0.680/0.720 | c=0.999488
=== Best @ epoch 62: val=0.6880, test=0.7280 ===
