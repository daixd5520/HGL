Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=17.1161 cls=2.0205 smmd=3.0507 ct=9.2656 rec=1.3897 | train/val/test=0.241/0.238/0.260 | c=0.999488
[Epoch 0001] loss=17.0105 cls=2.0103 smmd=2.9571 ct=9.2642 rec=1.3895 | train/val/test=0.379/0.204/0.193 | c=0.999488
[Epoch 0002] loss=16.9296 cls=2.0755 smmd=2.8142 ct=9.2603 rec=1.3898 | train/val/test=0.276/0.102/0.128 | c=0.999488
[Epoch 0003] loss=16.4196 cls=1.7589 smmd=2.6294 ct=9.2533 rec=1.3890 | train/val/test=0.517/0.174/0.190 | c=0.999488
[Epoch 0004] loss=15.9216 cls=1.5270 smmd=2.3874 ct=9.2353 rec=1.3860 | train/val/test=0.897/0.324/0.348 | c=0.999488
[Epoch 0005] loss=15.5551 cls=1.4895 smmd=2.1025 ct=9.2002 rec=1.3815 | train/val/test=0.897/0.452/0.462 | c=0.999488
[Epoch 0006] loss=15.0412 cls=1.3904 smmd=1.7783 ct=9.1299 rec=1.3713 | train/val/test=0.966/0.462/0.487 | c=0.999488
[Epoch 0007] loss=14.3268 cls=1.1643 smmd=1.4299 ct=9.0549 rec=1.3388 | train/val/test=0.966/0.546/0.557 | c=0.999488
[Epoch 0008] loss=13.9291 cls=1.2403 smmd=1.0732 ct=8.9903 rec=1.3126 | train/val/test=0.966/0.610/0.628 | c=0.999488
[Epoch 0009] loss=13.1279 cls=0.9593 smmd=0.7342 ct=8.8904 rec=1.2720 | train/val/test=1.000/0.614/0.613 | c=0.999488
[Epoch 0010] loss=12.4817 cls=0.7476 smmd=0.4585 ct=8.8066 rec=1.2345 | train/val/test=1.000/0.632/0.658 | c=0.999488
[Epoch 0011] loss=12.6484 cls=1.0903 smmd=0.2903 ct=8.8275 rec=1.2202 | train/val/test=1.000/0.628/0.659 | c=0.999488
[Epoch 0012] loss=12.3073 cls=0.7812 smmd=0.2526 ct=8.8581 rec=1.2077 | train/val/test=1.000/0.638/0.682 | c=0.999488
[Epoch 0013] loss=12.5480 cls=0.9641 smmd=0.3166 ct=8.8598 rec=1.2038 | train/val/test=1.000/0.640/0.669 | c=0.999488
[Epoch 0014] loss=12.4831 cls=0.8270 smmd=0.4284 ct=8.8303 rec=1.1987 | train/val/test=0.966/0.680/0.689 | c=0.999488
[Epoch 0015] loss=13.7665 cls=1.3138 smmd=0.5374 ct=9.5336 rec=1.1908 | train/val/test=1.000/0.664/0.660 | c=0.999488
[Epoch 0016] loss=13.0536 cls=0.6284 smmd=0.6250 ct=9.4284 rec=1.1859 | train/val/test=1.000/0.644/0.657 | c=0.999488
[Epoch 0017] loss=13.4800 cls=1.1099 smmd=0.6870 ct=9.3050 rec=1.1891 | train/val/test=1.000/0.674/0.708 | c=0.999488
[Epoch 0018] loss=13.2233 cls=0.9220 smmd=0.7248 ct=9.2132 rec=1.1816 | train/val/test=0.966/0.702/0.718 | c=0.999488
[Epoch 0019] loss=13.3238 cls=0.9818 smmd=0.7458 ct=9.1884 rec=1.2039 | train/val/test=0.966/0.684/0.698 | c=0.999488
[Epoch 0020] loss=13.3658 cls=1.0408 smmd=0.7364 ct=9.1632 rec=1.2127 | train/val/test=0.966/0.676/0.708 | c=0.999488
[Epoch 0021] loss=13.4003 cls=1.1793 smmd=0.6943 ct=9.1090 rec=1.2088 | train/val/test=1.000/0.674/0.710 | c=0.999488
[Epoch 0022] loss=13.0364 cls=0.9086 smmd=0.6306 ct=9.0906 rec=1.2033 | train/val/test=1.000/0.666/0.694 | c=0.999488
[Epoch 0023] loss=13.0072 cls=0.9485 smmd=0.5636 ct=9.0827 rec=1.2062 | train/val/test=1.000/0.644/0.679 | c=0.999488
[Epoch 0024] loss=13.2774 cls=1.2641 smmd=0.4993 ct=9.1014 rec=1.2063 | train/val/test=1.000/0.642/0.677 | c=0.999488
[Epoch 0025] loss=13.0946 cls=1.1060 smmd=0.4376 ct=9.1358 rec=1.2076 | train/val/test=1.000/0.660/0.680 | c=0.999488
[Epoch 0026] loss=12.8990 cls=0.9126 smmd=0.3864 ct=9.1817 rec=1.2092 | train/val/test=1.000/0.684/0.700 | c=0.999488
[Epoch 0027] loss=12.9824 cls=0.9943 smmd=0.3453 ct=9.2195 rec=1.2116 | train/val/test=1.000/0.682/0.700 | c=0.999488
[Epoch 0028] loss=12.6924 cls=0.7043 smmd=0.3148 ct=9.2482 rec=1.2125 | train/val/test=1.000/0.678/0.713 | c=0.999488
[Epoch 0029] loss=12.7365 cls=0.7773 smmd=0.2867 ct=9.2618 rec=1.2054 | train/val/test=1.000/0.680/0.703 | c=0.999488
[Epoch 0030] loss=12.7469 cls=0.7849 smmd=0.2673 ct=9.2813 rec=1.2067 | train/val/test=1.000/0.678/0.701 | c=0.999488
[Epoch 0031] loss=12.9423 cls=0.9935 smmd=0.2535 ct=9.2872 rec=1.2040 | train/val/test=1.000/0.672/0.692 | c=0.999488
[Epoch 0032] loss=12.8310 cls=0.9022 smmd=0.2372 ct=9.2822 rec=1.2046 | train/val/test=1.000/0.666/0.679 | c=0.999488
[Epoch 0033] loss=12.8890 cls=0.9818 smmd=0.2263 ct=9.2770 rec=1.2019 | train/val/test=1.000/0.666/0.673 | c=0.999488
[Epoch 0034] loss=12.9961 cls=1.0957 smmd=0.2205 ct=9.2729 rec=1.2035 | train/val/test=1.000/0.662/0.673 | c=0.999488
[Epoch 0035] loss=12.5892 cls=0.7193 smmd=0.2148 ct=9.2555 rec=1.1998 | train/val/test=1.000/0.666/0.681 | c=0.999488
[Epoch 0036] loss=12.6916 cls=0.8333 smmd=0.2074 ct=9.2460 rec=1.2025 | train/val/test=1.000/0.672/0.690 | c=0.999488
[Epoch 0037] loss=13.0130 cls=1.1814 smmd=0.2057 ct=9.2314 rec=1.1973 | train/val/test=1.000/0.676/0.692 | c=0.999488
[Epoch 0038] loss=12.8003 cls=0.9805 smmd=0.2064 ct=9.2240 rec=1.1947 | train/val/test=1.000/0.672/0.696 | c=0.999488
[Epoch 0039] loss=12.9456 cls=1.1410 smmd=0.2053 ct=9.2172 rec=1.1911 | train/val/test=1.000/0.670/0.694 | c=0.999488
[Epoch 0040] loss=12.4482 cls=0.6444 smmd=0.2046 ct=9.2153 rec=1.1919 | train/val/test=1.000/0.664/0.679 | c=0.999488
[Epoch 0041] loss=13.0920 cls=1.3093 smmd=0.1974 ct=9.2066 rec=1.1894 | train/val/test=1.000/0.654/0.674 | c=0.999488
[Epoch 0042] loss=12.3977 cls=0.6256 smmd=0.1918 ct=9.2049 rec=1.1877 | train/val/test=1.000/0.652/0.671 | c=0.999488
[Epoch 0043] loss=12.6468 cls=0.8668 smmd=0.1892 ct=9.2130 rec=1.1889 | train/val/test=1.000/0.648/0.668 | c=0.999488
[Epoch 0044] loss=12.6206 cls=0.8350 smmd=0.1806 ct=9.2193 rec=1.1929 | train/val/test=1.000/0.656/0.679 | c=0.999488
[Epoch 0045] loss=12.7253 cls=0.9558 smmd=0.1704 ct=9.2205 rec=1.1893 | train/val/test=1.000/0.664/0.689 | c=0.999488
[Epoch 0046] loss=12.5005 cls=0.7409 smmd=0.1613 ct=9.2287 rec=1.1848 | train/val/test=1.000/0.664/0.698 | c=0.999488
[Epoch 0047] loss=12.9119 cls=1.1484 smmd=0.1572 ct=9.2297 rec=1.1882 | train/val/test=1.000/0.672/0.706 | c=0.999488
[Epoch 0048] loss=12.6671 cls=0.9143 smmd=0.1502 ct=9.2322 rec=1.1852 | train/val/test=1.000/0.676/0.705 | c=0.999488
[Epoch 0049] loss=12.4042 cls=0.6391 smmd=0.1488 ct=9.2407 rec=1.1878 | train/val/test=1.000/0.678/0.704 | c=0.999488
[Epoch 0050] loss=12.6024 cls=0.8472 smmd=0.1416 ct=9.2400 rec=1.1868 | train/val/test=1.000/0.670/0.696 | c=0.999488
[Epoch 0051] loss=12.5266 cls=0.7864 smmd=0.1373 ct=9.2288 rec=1.1870 | train/val/test=1.000/0.662/0.677 | c=0.999488
[Epoch 0052] loss=12.5274 cls=0.7895 smmd=0.1412 ct=9.2236 rec=1.1865 | train/val/test=1.000/0.644/0.677 | c=0.999488
[Epoch 0053] loss=12.7518 cls=1.0085 smmd=0.1444 ct=9.2219 rec=1.1885 | train/val/test=1.000/0.646/0.677 | c=0.999488
[Epoch 0054] loss=12.9605 cls=1.2206 smmd=0.1454 ct=9.2193 rec=1.1876 | train/val/test=1.000/0.650/0.678 | c=0.999488
[Epoch 0055] loss=12.7987 cls=1.0557 smmd=0.1489 ct=9.2189 rec=1.1876 | train/val/test=1.000/0.656/0.679 | c=0.999488
[Epoch 0056] loss=12.8469 cls=1.0988 smmd=0.1522 ct=9.2136 rec=1.1912 | train/val/test=1.000/0.660/0.683 | c=0.999488
[Epoch 0057] loss=12.5138 cls=0.7684 smmd=0.1548 ct=9.2064 rec=1.1921 | train/val/test=1.000/0.670/0.690 | c=0.999488
[Epoch 0058] loss=12.5337 cls=0.7962 smmd=0.1597 ct=9.2021 rec=1.1878 | train/val/test=1.000/0.670/0.708 | c=0.999488
[Epoch 0059] loss=12.4343 cls=0.6835 smmd=0.1639 ct=9.2036 rec=1.1916 | train/val/test=1.000/0.668/0.704 | c=0.999488
[Epoch 0060] loss=12.8194 cls=1.0351 smmd=0.1679 ct=9.2134 rec=1.2015 | train/val/test=1.000/0.672/0.699 | c=0.999488
[Epoch 0061] loss=12.2670 cls=0.5143 smmd=0.1614 ct=9.2159 rec=1.1877 | train/val/test=1.000/0.662/0.696 | c=0.999488
[Epoch 0062] loss=12.6538 cls=0.9116 smmd=0.1516 ct=9.2120 rec=1.1893 | train/val/test=1.000/0.660/0.690 | c=0.999488
[Epoch 0063] loss=13.1237 cls=1.3937 smmd=0.1473 ct=9.2086 rec=1.1871 | train/val/test=1.000/0.654/0.684 | c=0.999488
[Epoch 0064] loss=12.7271 cls=0.9785 smmd=0.1430 ct=9.2177 rec=1.1940 | train/val/test=1.000/0.656/0.684 | c=0.999488
[Epoch 0065] loss=12.4289 cls=0.7085 smmd=0.1404 ct=9.2076 rec=1.1862 | train/val/test=1.000/0.664/0.679 | c=0.999488
[Epoch 0066] loss=12.4819 cls=0.7400 smmd=0.1437 ct=9.2164 rec=1.1909 | train/val/test=1.000/0.660/0.680 | c=0.999488
[Epoch 0067] loss=12.2281 cls=0.4944 smmd=0.1482 ct=9.2125 rec=1.1865 | train/val/test=1.000/0.662/0.679 | c=0.999488
[Epoch 0068] loss=12.1389 cls=0.3971 smmd=0.1488 ct=9.2227 rec=1.1852 | train/val/test=1.000/0.662/0.680 | c=0.999488
[Epoch 0069] loss=12.6985 cls=0.9644 smmd=0.1500 ct=9.2114 rec=1.1863 | train/val/test=1.000/0.664/0.680 | c=0.999488
[Epoch 0070] loss=12.8528 cls=1.1270 smmd=0.1527 ct=9.2027 rec=1.1852 | train/val/test=1.000/0.676/0.690 | c=0.999488
[Epoch 0071] loss=12.2050 cls=0.4877 smmd=0.1532 ct=9.1990 rec=1.1825 | train/val/test=1.000/0.680/0.695 | c=0.999488
[Epoch 0072] loss=12.6230 cls=0.8977 smmd=0.1581 ct=9.1998 rec=1.1837 | train/val/test=1.000/0.676/0.700 | c=0.999488
[Epoch 0073] loss=12.4781 cls=0.7554 smmd=0.1586 ct=9.1976 rec=1.1832 | train/val/test=1.000/0.678/0.698 | c=0.999488
[Epoch 0074] loss=12.8450 cls=1.1174 smmd=0.1618 ct=9.1959 rec=1.1849 | train/val/test=1.000/0.678/0.699 | c=0.999488
[Epoch 0075] loss=12.2711 cls=0.5547 smmd=0.1603 ct=9.1927 rec=1.1817 | train/val/test=1.000/0.676/0.700 | c=0.999488
[Epoch 0076] loss=12.8077 cls=1.0744 smmd=0.1642 ct=9.1962 rec=1.1864 | train/val/test=1.000/0.676/0.698 | c=0.999488
[Epoch 0077] loss=12.4485 cls=0.7341 smmd=0.1607 ct=9.1910 rec=1.1813 | train/val/test=1.000/0.672/0.699 | c=0.999488
[Epoch 0078] loss=12.6579 cls=0.9425 smmd=0.1593 ct=9.1948 rec=1.1807 | train/val/test=1.000/0.672/0.699 | c=0.999488
[Epoch 0079] loss=12.4927 cls=0.7745 smmd=0.1599 ct=9.1986 rec=1.1799 | train/val/test=1.000/0.672/0.701 | c=0.999488
[Epoch 0080] loss=12.5347 cls=0.8088 smmd=0.1599 ct=9.1987 rec=1.1836 | train/val/test=1.000/0.678/0.704 | c=0.999488
[Epoch 0081] loss=12.2183 cls=0.4961 smmd=0.1627 ct=9.1986 rec=1.1804 | train/val/test=1.000/0.676/0.703 | c=0.999488
[Epoch 0082] loss=12.4873 cls=0.7616 smmd=0.1612 ct=9.2015 rec=1.1815 | train/val/test=1.000/0.678/0.704 | c=0.999488
[Epoch 0083] loss=12.9410 cls=1.2130 smmd=0.1638 ct=9.1973 rec=1.1835 | train/val/test=1.000/0.676/0.705 | c=0.999488
[Epoch 0084] loss=12.1468 cls=0.4281 smmd=0.1644 ct=9.1959 rec=1.1792 | train/val/test=1.000/0.676/0.705 | c=0.999488
[Epoch 0085] loss=12.3009 cls=0.5546 smmd=0.1649 ct=9.2059 rec=1.1877 | train/val/test=1.000/0.672/0.704 | c=0.999488
[Epoch 0086] loss=12.4876 cls=0.7690 smmd=0.1610 ct=9.1976 rec=1.1800 | train/val/test=1.000/0.672/0.703 | c=0.999488
[Epoch 0087] loss=12.6448 cls=0.9020 smmd=0.1639 ct=9.2014 rec=1.1888 | train/val/test=1.000/0.670/0.702 | c=0.999488
[Epoch 0088] loss=12.9464 cls=1.2218 smmd=0.1653 ct=9.1938 rec=1.1828 | train/val/test=1.000/0.670/0.702 | c=0.999488
[Epoch 0089] loss=12.5780 cls=0.8648 smmd=0.1630 ct=9.1941 rec=1.1781 | train/val/test=1.000/0.670/0.701 | c=0.999488
[Epoch 0090] loss=12.4286 cls=0.7108 smmd=0.1648 ct=9.1920 rec=1.1805 | train/val/test=1.000/0.670/0.700 | c=0.999488
[Epoch 0091] loss=12.2735 cls=0.5576 smmd=0.1654 ct=9.1925 rec=1.1790 | train/val/test=1.000/0.670/0.700 | c=0.999488
[Epoch 0092] loss=12.8504 cls=1.1351 smmd=0.1646 ct=9.1913 rec=1.1797 | train/val/test=1.000/0.670/0.699 | c=0.999488
[Epoch 0093] loss=12.6065 cls=0.8962 smmd=0.1637 ct=9.1919 rec=1.1774 | train/val/test=1.000/0.670/0.698 | c=0.999488
[Epoch 0094] loss=12.5290 cls=0.8124 smmd=0.1653 ct=9.1914 rec=1.1800 | train/val/test=1.000/0.670/0.698 | c=0.999488
[Epoch 0095] loss=12.3259 cls=0.6084 smmd=0.1661 ct=9.1951 rec=1.1781 | train/val/test=1.000/0.670/0.698 | c=0.999488
[Epoch 0096] loss=12.4370 cls=0.7280 smmd=0.1627 ct=9.1911 rec=1.1777 | train/val/test=1.000/0.670/0.698 | c=0.999488
[Epoch 0097] loss=12.4190 cls=0.7050 smmd=0.1646 ct=9.1915 rec=1.1790 | train/val/test=1.000/0.670/0.698 | c=0.999488
[Epoch 0098] loss=12.5380 cls=0.8284 smmd=0.1629 ct=9.1910 rec=1.1779 | train/val/test=1.000/0.670/0.698 | c=0.999488
[Epoch 0099] loss=12.3865 cls=0.6676 smmd=0.1650 ct=9.1968 rec=1.1786 | train/val/test=1.000/0.670/0.698 | c=0.999488
=== Best @ epoch 18: val=0.7020, test=0.7180 ===
