Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=17.2715 cls=2.1620 smmd=3.0486 ct=9.2648 rec=1.3981 | train/val/test=0.414/0.270/0.262 | c=0.999488
[Epoch 0001] loss=16.8984 cls=1.8776 smmd=2.9839 ct=9.2603 rec=1.3883 | train/val/test=0.172/0.072/0.092 | c=0.999488
[Epoch 0002] loss=16.9907 cls=2.0759 smmd=2.8638 ct=9.2539 rec=1.3986 | train/val/test=0.345/0.122/0.147 | c=0.999488
[Epoch 0003] loss=16.5734 cls=1.8466 smmd=2.7041 ct=9.2409 rec=1.3909 | train/val/test=0.724/0.436/0.409 | c=0.999488
[Epoch 0004] loss=16.2580 cls=1.7681 smmd=2.5017 ct=9.2199 rec=1.3841 | train/val/test=0.897/0.514/0.540 | c=0.999488
[Epoch 0005] loss=15.5574 cls=1.3585 smmd=2.2546 ct=9.1874 rec=1.3784 | train/val/test=0.897/0.516/0.524 | c=0.999488
[Epoch 0006] loss=15.2759 cls=1.4508 smmd=1.9595 ct=9.1271 rec=1.3693 | train/val/test=0.966/0.562/0.556 | c=0.999488
[Epoch 0007] loss=14.3223 cls=1.0056 smmd=1.6299 ct=9.0306 rec=1.3281 | train/val/test=0.966/0.470/0.475 | c=0.999488
[Epoch 0008] loss=14.4108 cls=1.5442 smmd=1.2841 ct=8.9672 rec=1.3077 | train/val/test=0.966/0.526/0.511 | c=0.999488
[Epoch 0009] loss=13.4581 cls=1.0765 smmd=0.9258 ct=8.9004 rec=1.2776 | train/val/test=0.966/0.632/0.657 | c=0.999488
[Epoch 0010] loss=13.1237 cls=1.1804 smmd=0.6139 ct=8.8195 rec=1.2549 | train/val/test=0.966/0.640/0.670 | c=0.999488
[Epoch 0011] loss=12.8134 cls=1.1463 smmd=0.3847 ct=8.8071 rec=1.2377 | train/val/test=0.966/0.630/0.682 | c=0.999488
[Epoch 0012] loss=12.4417 cls=0.8828 smmd=0.2723 ct=8.8234 rec=1.2316 | train/val/test=0.966/0.626/0.668 | c=0.999488
[Epoch 0013] loss=12.4093 cls=0.8688 smmd=0.2839 ct=8.8100 rec=1.2233 | train/val/test=1.000/0.638/0.651 | c=0.999488
[Epoch 0014] loss=12.5351 cls=0.9550 smmd=0.3748 ct=8.7805 rec=1.2124 | train/val/test=0.966/0.664/0.690 | c=0.999488
[Epoch 0015] loss=12.9217 cls=1.2262 smmd=0.5056 ct=8.7844 rec=1.2028 | train/val/test=1.000/0.676/0.697 | c=0.999488
[Epoch 0016] loss=12.9516 cls=1.1439 smmd=0.6198 ct=8.7858 rec=1.2011 | train/val/test=1.000/0.672/0.694 | c=0.999488
[Epoch 0017] loss=12.8793 cls=1.0105 smmd=0.6808 ct=8.7797 rec=1.2042 | train/val/test=1.000/0.664/0.674 | c=0.999488
[Epoch 0018] loss=12.4704 cls=0.6165 smmd=0.6866 ct=8.7653 rec=1.2010 | train/val/test=1.000/0.668/0.690 | c=0.999488
[Epoch 0019] loss=12.7441 cls=0.9540 smmd=0.6441 ct=8.7538 rec=1.1961 | train/val/test=0.966/0.678/0.702 | c=0.999488
[Epoch 0020] loss=13.3531 cls=0.9726 smmd=0.5628 ct=9.4408 rec=1.1884 | train/val/test=0.966/0.686/0.724 | c=0.999488
[Epoch 0021] loss=12.9491 cls=0.7333 smmd=0.4633 ct=9.3732 rec=1.1896 | train/val/test=0.966/0.692/0.725 | c=0.999488
[Epoch 0022] loss=13.2486 cls=1.1821 smmd=0.3907 ct=9.2842 rec=1.1958 | train/val/test=0.966/0.700/0.717 | c=0.999488
[Epoch 0023] loss=13.0020 cls=1.0250 smmd=0.3465 ct=9.2341 rec=1.1982 | train/val/test=0.966/0.690/0.712 | c=0.999488
[Epoch 0024] loss=13.3592 cls=1.4107 smmd=0.3416 ct=9.2089 rec=1.1990 | train/val/test=0.966/0.684/0.701 | c=0.999488
[Epoch 0025] loss=13.1922 cls=1.2384 smmd=0.3599 ct=9.1887 rec=1.2026 | train/val/test=0.966/0.698/0.713 | c=0.999488
[Epoch 0026] loss=12.9617 cls=1.0032 smmd=0.3896 ct=9.1701 rec=1.1994 | train/val/test=0.966/0.692/0.707 | c=0.999488
[Epoch 0027] loss=12.9666 cls=0.9687 smmd=0.4132 ct=9.1817 rec=1.2016 | train/val/test=0.966/0.690/0.721 | c=0.999488
[Epoch 0028] loss=13.0282 cls=1.0177 smmd=0.4253 ct=9.1807 rec=1.2023 | train/val/test=1.000/0.708/0.725 | c=0.999488
[Epoch 0029] loss=13.2496 cls=1.2238 smmd=0.4158 ct=9.1921 rec=1.2089 | train/val/test=1.000/0.716/0.728 | c=0.999488
[Epoch 0030] loss=12.8442 cls=0.8451 smmd=0.3911 ct=9.1896 rec=1.2092 | train/val/test=1.000/0.710/0.731 | c=0.999488
[Epoch 0031] loss=12.5389 cls=0.5729 smmd=0.3575 ct=9.1977 rec=1.2054 | train/val/test=1.000/0.722/0.733 | c=0.999488
[Epoch 0032] loss=12.7946 cls=0.8486 smmd=0.3254 ct=9.2058 rec=1.2074 | train/val/test=1.000/0.722/0.731 | c=0.999488
[Epoch 0033] loss=12.6952 cls=0.7613 smmd=0.2963 ct=9.2170 rec=1.2103 | train/val/test=1.000/0.726/0.728 | c=0.999488
[Epoch 0034] loss=12.5338 cls=0.6387 smmd=0.2658 ct=9.2276 rec=1.2009 | train/val/test=1.000/0.728/0.728 | c=0.999488
[Epoch 0035] loss=13.2791 cls=1.3970 smmd=0.2381 ct=9.2414 rec=1.2013 | train/val/test=1.000/0.730/0.729 | c=0.999488
[Epoch 0036] loss=12.4148 cls=0.5676 smmd=0.2136 ct=9.2414 rec=1.1961 | train/val/test=1.000/0.736/0.729 | c=0.999488
[Epoch 0037] loss=12.7795 cls=0.9460 smmd=0.1914 ct=9.2492 rec=1.1964 | train/val/test=1.000/0.740/0.724 | c=0.999488
[Epoch 0038] loss=12.6653 cls=0.8617 smmd=0.1820 ct=9.2559 rec=1.1829 | train/val/test=1.000/0.730/0.718 | c=0.999488
[Epoch 0039] loss=12.9887 cls=1.1663 smmd=0.1784 ct=9.2732 rec=1.1854 | train/val/test=1.000/0.734/0.718 | c=0.999488
[Epoch 0040] loss=13.1437 cls=1.3502 smmd=0.1787 ct=9.2513 rec=1.1818 | train/val/test=1.000/0.734/0.720 | c=0.999488
[Epoch 0041] loss=12.8783 cls=1.0903 smmd=0.1839 ct=9.2396 rec=1.1822 | train/val/test=1.000/0.726/0.723 | c=0.999488
[Epoch 0042] loss=12.5986 cls=0.7948 smmd=0.1846 ct=9.2358 rec=1.1917 | train/val/test=1.000/0.718/0.725 | c=0.999488
[Epoch 0043] loss=12.9767 cls=1.1929 smmd=0.1859 ct=9.2212 rec=1.1884 | train/val/test=1.000/0.718/0.724 | c=0.999488
[Epoch 0044] loss=12.3998 cls=0.6291 smmd=0.1894 ct=9.2085 rec=1.1864 | train/val/test=1.000/0.728/0.727 | c=0.999488
[Epoch 0045] loss=12.7145 cls=0.9401 smmd=0.1888 ct=9.2057 rec=1.1899 | train/val/test=1.000/0.728/0.730 | c=0.999488
[Epoch 0046] loss=12.5584 cls=0.7906 smmd=0.1843 ct=9.1952 rec=1.1942 | train/val/test=1.000/0.720/0.724 | c=0.999488
[Epoch 0047] loss=12.5956 cls=0.8365 smmd=0.1761 ct=9.2009 rec=1.1910 | train/val/test=1.000/0.712/0.722 | c=0.999488
[Epoch 0048] loss=12.7333 cls=0.9831 smmd=0.1601 ct=9.2140 rec=1.1881 | train/val/test=1.000/0.706/0.718 | c=0.999488
[Epoch 0049] loss=12.7575 cls=0.9915 smmd=0.1541 ct=9.2186 rec=1.1967 | train/val/test=1.000/0.708/0.716 | c=0.999488
[Epoch 0050] loss=12.4546 cls=0.6868 smmd=0.1499 ct=9.2286 rec=1.1947 | train/val/test=1.000/0.714/0.720 | c=0.999488
[Epoch 0051] loss=12.3449 cls=0.5979 smmd=0.1440 ct=9.2199 rec=1.1915 | train/val/test=1.000/0.714/0.714 | c=0.999488
[Epoch 0052] loss=12.5422 cls=0.7992 smmd=0.1374 ct=9.2305 rec=1.1875 | train/val/test=1.000/0.714/0.708 | c=0.999488
[Epoch 0053] loss=12.6030 cls=0.8605 smmd=0.1412 ct=9.2260 rec=1.1876 | train/val/test=1.000/0.712/0.712 | c=0.999488
[Epoch 0054] loss=13.0093 cls=1.2579 smmd=0.1502 ct=9.2122 rec=1.1945 | train/val/test=1.000/0.718/0.717 | c=0.999488
[Epoch 0055] loss=12.6027 cls=0.8565 smmd=0.1513 ct=9.2019 rec=1.1965 | train/val/test=1.000/0.718/0.714 | c=0.999488
[Epoch 0056] loss=12.2950 cls=0.5672 smmd=0.1512 ct=9.1932 rec=1.1917 | train/val/test=1.000/0.720/0.716 | c=0.999488
[Epoch 0057] loss=12.9337 cls=1.2011 smmd=0.1522 ct=9.1952 rec=1.1926 | train/val/test=1.000/0.706/0.713 | c=0.999488
[Epoch 0058] loss=12.3075 cls=0.5785 smmd=0.1486 ct=9.2046 rec=1.1879 | train/val/test=1.000/0.690/0.707 | c=0.999488
[Epoch 0059] loss=12.4002 cls=0.6624 smmd=0.1535 ct=9.2072 rec=1.1885 | train/val/test=1.000/0.694/0.706 | c=0.999488
[Epoch 0060] loss=12.7246 cls=0.9923 smmd=0.1499 ct=9.2113 rec=1.1856 | train/val/test=1.000/0.712/0.709 | c=0.999488
[Epoch 0061] loss=11.9966 cls=0.2792 smmd=0.1483 ct=9.2032 rec=1.1830 | train/val/test=1.000/0.718/0.710 | c=0.999488
[Epoch 0062] loss=12.7479 cls=1.0287 smmd=0.1534 ct=9.2009 rec=1.1824 | train/val/test=1.000/0.724/0.721 | c=0.999488
[Epoch 0063] loss=12.7113 cls=0.9842 smmd=0.1594 ct=9.1920 rec=1.1879 | train/val/test=1.000/0.714/0.720 | c=0.999488
[Epoch 0064] loss=12.6489 cls=0.9059 smmd=0.1681 ct=9.1937 rec=1.1905 | train/val/test=1.000/0.720/0.718 | c=0.999488
[Epoch 0065] loss=12.5237 cls=0.7961 smmd=0.1752 ct=9.1806 rec=1.1859 | train/val/test=1.000/0.718/0.715 | c=0.999488
[Epoch 0066] loss=12.8054 cls=1.0706 smmd=0.1755 ct=9.1787 rec=1.1903 | train/val/test=1.000/0.718/0.713 | c=0.999488
[Epoch 0067] loss=12.7803 cls=1.0462 smmd=0.1715 ct=9.1837 rec=1.1894 | train/val/test=1.000/0.710/0.711 | c=0.999488
[Epoch 0068] loss=12.7729 cls=1.0486 smmd=0.1690 ct=9.1784 rec=1.1884 | train/val/test=1.000/0.714/0.710 | c=0.999488
[Epoch 0069] loss=12.5039 cls=0.7839 smmd=0.1653 ct=9.1842 rec=1.1853 | train/val/test=1.000/0.712/0.710 | c=0.999488
[Epoch 0070] loss=12.3793 cls=0.6708 smmd=0.1629 ct=9.1828 rec=1.1814 | train/val/test=1.000/0.712/0.708 | c=0.999488
[Epoch 0071] loss=12.4059 cls=0.6816 smmd=0.1602 ct=9.1882 rec=1.1880 | train/val/test=1.000/0.704/0.713 | c=0.999488
[Epoch 0072] loss=12.4824 cls=0.7548 smmd=0.1614 ct=9.1946 rec=1.1858 | train/val/test=1.000/0.714/0.717 | c=0.999488
[Epoch 0073] loss=12.9581 cls=1.2322 smmd=0.1631 ct=9.1886 rec=1.1871 | train/val/test=1.000/0.716/0.721 | c=0.999488
[Epoch 0074] loss=12.4063 cls=0.6772 smmd=0.1657 ct=9.1912 rec=1.1861 | train/val/test=1.000/0.716/0.724 | c=0.999488
[Epoch 0075] loss=12.6074 cls=0.8679 smmd=0.1695 ct=9.1786 rec=1.1957 | train/val/test=1.000/0.720/0.727 | c=0.999488
[Epoch 0076] loss=12.4941 cls=0.7732 smmd=0.1674 ct=9.1800 rec=1.1868 | train/val/test=1.000/0.716/0.724 | c=0.999488
[Epoch 0077] loss=12.7927 cls=1.0524 smmd=0.1667 ct=9.1940 rec=1.1898 | train/val/test=1.000/0.712/0.723 | c=0.999488
[Epoch 0078] loss=12.5537 cls=0.8361 smmd=0.1678 ct=9.1797 rec=1.1851 | train/val/test=1.000/0.720/0.720 | c=0.999488
[Epoch 0079] loss=12.5450 cls=0.8165 smmd=0.1682 ct=9.1855 rec=1.1874 | train/val/test=1.000/0.718/0.718 | c=0.999488
[Epoch 0080] loss=12.3691 cls=0.6517 smmd=0.1700 ct=9.1765 rec=1.1854 | train/val/test=1.000/0.716/0.717 | c=0.999488
[Epoch 0081] loss=12.6844 cls=0.9509 smmd=0.1692 ct=9.1832 rec=1.1905 | train/val/test=1.000/0.718/0.715 | c=0.999488
[Epoch 0082] loss=12.5190 cls=0.8031 smmd=0.1714 ct=9.1746 rec=1.1849 | train/val/test=1.000/0.716/0.714 | c=0.999488
[Epoch 0083] loss=12.6708 cls=0.9510 smmd=0.1718 ct=9.1754 rec=1.1863 | train/val/test=1.000/0.714/0.717 | c=0.999488
[Epoch 0084] loss=12.3613 cls=0.6460 smmd=0.1737 ct=9.1716 rec=1.1850 | train/val/test=1.000/0.712/0.717 | c=0.999488
[Epoch 0085] loss=12.2578 cls=0.5480 smmd=0.1702 ct=9.1717 rec=1.1839 | train/val/test=1.000/0.712/0.717 | c=0.999488
[Epoch 0086] loss=12.5598 cls=0.8498 smmd=0.1715 ct=9.1703 rec=1.1841 | train/val/test=1.000/0.714/0.716 | c=0.999488
[Epoch 0087] loss=12.6434 cls=0.9228 smmd=0.1709 ct=9.1689 rec=1.1904 | train/val/test=1.000/0.718/0.719 | c=0.999488
[Epoch 0088] loss=12.3850 cls=0.6743 smmd=0.1756 ct=9.1649 rec=1.1851 | train/val/test=1.000/0.714/0.720 | c=0.999488
[Epoch 0089] loss=12.1337 cls=0.4208 smmd=0.1698 ct=9.1771 rec=1.1830 | train/val/test=1.000/0.714/0.723 | c=0.999488
[Epoch 0090] loss=12.7780 cls=1.0507 smmd=0.1732 ct=9.1714 rec=1.1914 | train/val/test=1.000/0.714/0.723 | c=0.999488
[Epoch 0091] loss=12.6868 cls=0.9798 smmd=0.1667 ct=9.1702 rec=1.1851 | train/val/test=1.000/0.714/0.723 | c=0.999488
[Epoch 0092] loss=13.0079 cls=1.2790 smmd=0.1692 ct=9.1757 rec=1.1920 | train/val/test=1.000/0.714/0.724 | c=0.999488
[Epoch 0093] loss=12.4024 cls=0.6938 smmd=0.1704 ct=9.1719 rec=1.1832 | train/val/test=1.000/0.714/0.724 | c=0.999488
[Epoch 0094] loss=12.6244 cls=0.9075 smmd=0.1707 ct=9.1678 rec=1.1892 | train/val/test=1.000/0.714/0.725 | c=0.999488
[Epoch 0095] loss=12.3706 cls=0.6523 smmd=0.1697 ct=9.1709 rec=1.1888 | train/val/test=1.000/0.714/0.725 | c=0.999488
[Epoch 0096] loss=12.3728 cls=0.6610 smmd=0.1688 ct=9.1743 rec=1.1843 | train/val/test=1.000/0.714/0.725 | c=0.999488
[Epoch 0097] loss=12.3556 cls=0.6498 smmd=0.1696 ct=9.1649 rec=1.1856 | train/val/test=1.000/0.714/0.725 | c=0.999488
[Epoch 0098] loss=12.4317 cls=0.7226 smmd=0.1672 ct=9.1722 rec=1.1849 | train/val/test=1.000/0.714/0.725 | c=0.999488
[Epoch 0099] loss=12.1111 cls=0.4085 smmd=0.1686 ct=9.1707 rec=1.1816 | train/val/test=1.000/0.714/0.725 | c=0.999488
=== Best @ epoch 37: val=0.7400, test=0.7240 ===
