Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=17.3196 cls=2.1684 smmd=3.1059 ct=9.2560 rec=1.3946 | train/val/test=0.259/0.200/0.187 | c=0.999488
[Epoch 0001] loss=16.9929 cls=1.9344 smmd=3.0290 ct=9.2515 rec=1.3890 | train/val/test=0.310/0.178/0.181 | c=0.999488
[Epoch 0002] loss=16.9521 cls=2.0227 smmd=2.9016 ct=9.2468 rec=1.3905 | train/val/test=0.259/0.128/0.140 | c=0.999488
[Epoch 0003] loss=16.7200 cls=1.9729 smmd=2.7267 ct=9.2369 rec=1.3917 | train/val/test=0.793/0.340/0.337 | c=0.999488
[Epoch 0004] loss=16.0162 cls=1.5333 smmd=2.4955 ct=9.2184 rec=1.3844 | train/val/test=0.638/0.268/0.282 | c=0.999488
[Epoch 0005] loss=15.7127 cls=1.5575 smmd=2.2195 ct=9.1805 rec=1.3776 | train/val/test=0.741/0.326/0.330 | c=0.999488
[Epoch 0006] loss=15.1295 cls=1.4331 smmd=1.8815 ct=9.1020 rec=1.3565 | train/val/test=0.897/0.620/0.614 | c=0.999488
[Epoch 0007] loss=14.5984 cls=1.4666 smmd=1.5244 ct=8.9762 rec=1.3156 | train/val/test=0.897/0.602/0.595 | c=0.999488
[Epoch 0008] loss=13.7691 cls=1.0808 smmd=1.1630 ct=8.9452 rec=1.2900 | train/val/test=0.948/0.648/0.636 | c=0.999488
[Epoch 0009] loss=13.6638 cls=1.4215 smmd=0.8046 ct=8.8992 rec=1.2693 | train/val/test=0.948/0.644/0.656 | c=0.999488
[Epoch 0010] loss=12.8602 cls=1.0871 smmd=0.4970 ct=8.8084 rec=1.2338 | train/val/test=0.966/0.666/0.668 | c=0.999488
[Epoch 0011] loss=12.4734 cls=0.9378 smmd=0.3073 ct=8.7858 rec=1.2213 | train/val/test=1.000/0.696/0.709 | c=0.999488
[Epoch 0012] loss=12.8280 cls=1.3289 smmd=0.2762 ct=8.7975 rec=1.2127 | train/val/test=0.966/0.688/0.709 | c=0.999488
[Epoch 0013] loss=12.4645 cls=0.8932 smmd=0.3652 ct=8.7944 rec=1.2058 | train/val/test=0.966/0.686/0.666 | c=0.999488
[Epoch 0014] loss=12.9036 cls=1.2334 smmd=0.5024 ct=8.7733 rec=1.1972 | train/val/test=0.948/0.706/0.687 | c=0.999488
[Epoch 0015] loss=12.9388 cls=1.1724 smmd=0.6292 ct=8.7511 rec=1.1930 | train/val/test=0.966/0.696/0.703 | c=0.999488
[Epoch 0016] loss=12.9347 cls=1.0485 smmd=0.7208 ct=8.7666 rec=1.1993 | train/val/test=1.000/0.712/0.716 | c=0.999488
[Epoch 0017] loss=12.9696 cls=1.0464 smmd=0.7491 ct=8.7687 rec=1.2028 | train/val/test=1.000/0.722/0.708 | c=0.999488
[Epoch 0018] loss=12.8580 cls=0.9843 smmd=0.7185 ct=8.7555 rec=1.1998 | train/val/test=0.983/0.700/0.693 | c=0.999488
[Epoch 0019] loss=12.7929 cls=1.0317 smmd=0.6335 ct=8.7287 rec=1.1995 | train/val/test=0.948/0.700/0.677 | c=0.999488
[Epoch 0020] loss=13.3718 cls=1.0672 smmd=0.5222 ct=9.3881 rec=1.1971 | train/val/test=0.948/0.682/0.670 | c=0.999488
[Epoch 0021] loss=13.1388 cls=0.9401 smmd=0.4223 ct=9.3624 rec=1.2070 | train/val/test=0.948/0.698/0.692 | c=0.999488
[Epoch 0022] loss=13.0598 cls=0.9740 smmd=0.3496 ct=9.3248 rec=1.2057 | train/val/test=0.948/0.710/0.705 | c=0.999488
[Epoch 0023] loss=12.9510 cls=0.9394 smmd=0.3253 ct=9.2771 rec=1.2046 | train/val/test=0.966/0.718/0.714 | c=0.999488
[Epoch 0024] loss=12.9764 cls=0.9826 smmd=0.3462 ct=9.2406 rec=1.2035 | train/val/test=0.966/0.718/0.719 | c=0.999488
[Epoch 0025] loss=13.1821 cls=1.1662 smmd=0.3886 ct=9.2183 rec=1.2045 | train/val/test=0.983/0.700/0.719 | c=0.999488
[Epoch 0026] loss=12.9227 cls=0.8756 smmd=0.4295 ct=9.2116 rec=1.2030 | train/val/test=0.983/0.702/0.715 | c=0.999488
[Epoch 0027] loss=12.8653 cls=0.8079 smmd=0.4484 ct=9.2035 rec=1.2028 | train/val/test=0.966/0.694/0.703 | c=0.999488
[Epoch 0028] loss=12.8866 cls=0.8390 smmd=0.4421 ct=9.2064 rec=1.1996 | train/val/test=0.966/0.704/0.698 | c=0.999488
[Epoch 0029] loss=13.0636 cls=1.0575 smmd=0.4095 ct=9.2032 rec=1.1967 | train/val/test=0.983/0.694/0.699 | c=0.999488
[Epoch 0030] loss=13.0810 cls=1.1048 smmd=0.3772 ct=9.2197 rec=1.1897 | train/val/test=0.983/0.714/0.706 | c=0.999488
[Epoch 0031] loss=12.6795 cls=0.7389 smmd=0.3294 ct=9.2344 rec=1.1884 | train/val/test=0.983/0.730/0.715 | c=0.999488
[Epoch 0032] loss=12.9896 cls=1.0831 smmd=0.2857 ct=9.2590 rec=1.1809 | train/val/test=0.983/0.734/0.723 | c=0.999488
[Epoch 0033] loss=12.6801 cls=0.8107 smmd=0.2454 ct=9.2697 rec=1.1771 | train/val/test=0.983/0.732/0.732 | c=0.999488
[Epoch 0034] loss=12.7856 cls=0.9210 smmd=0.2170 ct=9.2814 rec=1.1831 | train/val/test=0.983/0.734/0.730 | c=0.999488
[Epoch 0035] loss=12.8190 cls=0.9671 smmd=0.2043 ct=9.2910 rec=1.1783 | train/val/test=0.983/0.736/0.721 | c=0.999488
[Epoch 0036] loss=12.9171 cls=1.0539 smmd=0.2009 ct=9.2848 rec=1.1887 | train/val/test=0.983/0.728/0.708 | c=0.999488
[Epoch 0037] loss=12.6783 cls=0.8261 smmd=0.1998 ct=9.2870 rec=1.1827 | train/val/test=0.966/0.732/0.704 | c=0.999488
[Epoch 0038] loss=12.7306 cls=0.8683 smmd=0.2012 ct=9.2867 rec=1.1872 | train/val/test=0.983/0.726/0.704 | c=0.999488
[Epoch 0039] loss=13.0679 cls=1.2097 smmd=0.1962 ct=9.2808 rec=1.1907 | train/val/test=0.983/0.732/0.710 | c=0.999488
[Epoch 0040] loss=12.7833 cls=0.9501 smmd=0.1947 ct=9.2669 rec=1.1858 | train/val/test=0.983/0.724/0.707 | c=0.999488
[Epoch 0041] loss=12.7767 cls=0.9434 smmd=0.1953 ct=9.2636 rec=1.1872 | train/val/test=0.983/0.730/0.714 | c=0.999488
[Epoch 0042] loss=12.6716 cls=0.8420 smmd=0.1961 ct=9.2568 rec=1.1883 | train/val/test=0.983/0.738/0.718 | c=0.999488
[Epoch 0043] loss=12.8239 cls=0.9977 smmd=0.1964 ct=9.2481 rec=1.1909 | train/val/test=0.983/0.746/0.729 | c=0.999488
[Epoch 0044] loss=12.7509 cls=0.9331 smmd=0.1944 ct=9.2455 rec=1.1889 | train/val/test=0.983/0.740/0.729 | c=0.999488
[Epoch 0045] loss=12.9421 cls=1.1145 smmd=0.1938 ct=9.2464 rec=1.1937 | train/val/test=0.983/0.736/0.726 | c=0.999488
[Epoch 0046] loss=12.9041 cls=1.0794 smmd=0.1915 ct=9.2425 rec=1.1954 | train/val/test=0.983/0.734/0.721 | c=0.999488
[Epoch 0047] loss=12.7684 cls=0.9453 smmd=0.1902 ct=9.2475 rec=1.1927 | train/val/test=0.983/0.728/0.721 | c=0.999488
[Epoch 0048] loss=12.8498 cls=1.0271 smmd=0.1880 ct=9.2398 rec=1.1974 | train/val/test=0.983/0.730/0.723 | c=0.999488
[Epoch 0049] loss=13.0054 cls=1.1825 smmd=0.1815 ct=9.2435 rec=1.1990 | train/val/test=0.983/0.738/0.724 | c=0.999488
[Epoch 0050] loss=12.9907 cls=1.1663 smmd=0.1764 ct=9.2469 rec=1.2006 | train/val/test=0.983/0.732/0.724 | c=0.999488
[Epoch 0051] loss=12.9651 cls=1.1502 smmd=0.1758 ct=9.2485 rec=1.1953 | train/val/test=0.983/0.730/0.718 | c=0.999488
[Epoch 0052] loss=12.9650 cls=1.1467 smmd=0.1751 ct=9.2422 rec=1.2005 | train/val/test=0.983/0.726/0.718 | c=0.999488
[Epoch 0053] loss=12.6552 cls=0.8337 smmd=0.1698 ct=9.2432 rec=1.2042 | train/val/test=0.983/0.730/0.723 | c=0.999488
[Epoch 0054] loss=12.8017 cls=0.9842 smmd=0.1683 ct=9.2475 rec=1.2009 | train/val/test=0.983/0.728/0.722 | c=0.999488
[Epoch 0055] loss=12.8172 cls=1.0032 smmd=0.1646 ct=9.2389 rec=1.2053 | train/val/test=1.000/0.726/0.709 | c=0.999488
[Epoch 0056] loss=12.8661 cls=1.0540 smmd=0.1623 ct=9.2523 rec=1.1988 | train/val/test=1.000/0.726/0.708 | c=0.999488
[Epoch 0057] loss=13.1349 cls=1.3128 smmd=0.1627 ct=9.2559 rec=1.2017 | train/val/test=1.000/0.728/0.709 | c=0.999488
[Epoch 0058] loss=12.8568 cls=1.0437 smmd=0.1685 ct=9.2472 rec=1.1987 | train/val/test=0.983/0.732/0.711 | c=0.999488
[Epoch 0059] loss=12.5008 cls=0.6955 smmd=0.1715 ct=9.2461 rec=1.1939 | train/val/test=0.983/0.734/0.717 | c=0.999488
[Epoch 0060] loss=12.9572 cls=1.1512 smmd=0.1710 ct=9.2436 rec=1.1957 | train/val/test=0.983/0.732/0.719 | c=0.999488
[Epoch 0061] loss=12.7935 cls=0.9900 smmd=0.1753 ct=9.2398 rec=1.1942 | train/val/test=0.983/0.736/0.725 | c=0.999488
[Epoch 0062] loss=12.6802 cls=0.8731 smmd=0.1749 ct=9.2410 rec=1.1956 | train/val/test=0.983/0.738/0.726 | c=0.999488
[Epoch 0063] loss=12.8138 cls=1.0014 smmd=0.1823 ct=9.2365 rec=1.1968 | train/val/test=0.983/0.740/0.724 | c=0.999488
[Epoch 0064] loss=12.9147 cls=1.1215 smmd=0.1809 ct=9.2277 rec=1.1923 | train/val/test=0.983/0.744/0.720 | c=0.999488
[Epoch 0065] loss=12.8025 cls=1.0183 smmd=0.1850 ct=9.2290 rec=1.1852 | train/val/test=0.983/0.742/0.721 | c=0.999488
[Epoch 0066] loss=12.8555 cls=1.0653 smmd=0.1859 ct=9.2284 rec=1.1880 | train/val/test=0.983/0.740/0.714 | c=0.999488
[Epoch 0067] loss=12.8844 cls=1.0836 smmd=0.1797 ct=9.2297 rec=1.1957 | train/val/test=1.000/0.732/0.710 | c=0.999488
[Epoch 0068] loss=12.9238 cls=1.1362 smmd=0.1780 ct=9.2322 rec=1.1887 | train/val/test=1.000/0.732/0.711 | c=0.999488
[Epoch 0069] loss=12.5907 cls=0.8103 smmd=0.1787 ct=9.2311 rec=1.1853 | train/val/test=1.000/0.734/0.708 | c=0.999488
[Epoch 0070] loss=12.9320 cls=1.1485 smmd=0.1779 ct=9.2347 rec=1.1855 | train/val/test=0.983/0.734/0.707 | c=0.999488
[Epoch 0071] loss=12.7282 cls=0.9541 smmd=0.1770 ct=9.2290 rec=1.1840 | train/val/test=0.983/0.738/0.710 | c=0.999488
[Epoch 0072] loss=13.0366 cls=1.2227 smmd=0.1778 ct=9.2428 rec=1.1967 | train/val/test=0.983/0.740/0.711 | c=0.999488
[Epoch 0073] loss=12.7426 cls=0.9557 smmd=0.1802 ct=9.2386 rec=1.1841 | train/val/test=0.983/0.738/0.713 | c=0.999488
[Epoch 0074] loss=12.6756 cls=0.8822 smmd=0.1803 ct=9.2314 rec=1.1908 | train/val/test=0.983/0.740/0.721 | c=0.999488
[Epoch 0075] loss=12.6997 cls=0.9211 smmd=0.1785 ct=9.2336 rec=1.1832 | train/val/test=0.983/0.738/0.722 | c=0.999488
[Epoch 0076] loss=12.8188 cls=1.0355 smmd=0.1814 ct=9.2301 rec=1.1859 | train/val/test=0.983/0.744/0.725 | c=0.999488
[Epoch 0077] loss=12.5912 cls=0.8169 smmd=0.1838 ct=9.2254 rec=1.1826 | train/val/test=1.000/0.748/0.726 | c=0.999488
[Epoch 0078] loss=13.0268 cls=1.2347 smmd=0.1820 ct=9.2331 rec=1.1885 | train/val/test=1.000/0.746/0.727 | c=0.999488
[Epoch 0079] loss=12.8867 cls=1.1040 smmd=0.1815 ct=9.2244 rec=1.1885 | train/val/test=1.000/0.746/0.727 | c=0.999488
[Epoch 0080] loss=12.7018 cls=0.9287 smmd=0.1797 ct=9.2272 rec=1.1831 | train/val/test=1.000/0.748/0.727 | c=0.999488
[Epoch 0081] loss=12.7517 cls=0.9726 smmd=0.1840 ct=9.2287 rec=1.1832 | train/val/test=1.000/0.748/0.724 | c=0.999488
[Epoch 0082] loss=12.9125 cls=1.1029 smmd=0.1833 ct=9.2317 rec=1.1973 | train/val/test=1.000/0.744/0.722 | c=0.999488
[Epoch 0083] loss=12.7314 cls=0.9427 smmd=0.1828 ct=9.2242 rec=1.1909 | train/val/test=1.000/0.744/0.720 | c=0.999488
[Epoch 0084] loss=12.3046 cls=0.5326 smmd=0.1832 ct=9.2262 rec=1.1813 | train/val/test=1.000/0.744/0.719 | c=0.999488
[Epoch 0085] loss=12.8446 cls=1.0614 smmd=0.1847 ct=9.2263 rec=1.1861 | train/val/test=1.000/0.744/0.718 | c=0.999488
[Epoch 0086] loss=12.7157 cls=0.9355 smmd=0.1866 ct=9.2246 rec=1.1845 | train/val/test=1.000/0.744/0.718 | c=0.999488
[Epoch 0087] loss=12.6739 cls=0.8862 smmd=0.1814 ct=9.2295 rec=1.1884 | train/val/test=1.000/0.744/0.717 | c=0.999488
[Epoch 0088] loss=12.6500 cls=0.8692 smmd=0.1820 ct=9.2240 rec=1.1874 | train/val/test=1.000/0.744/0.719 | c=0.999488
[Epoch 0089] loss=12.6567 cls=0.8741 smmd=0.1826 ct=9.2232 rec=1.1884 | train/val/test=1.000/0.744/0.719 | c=0.999488
[Epoch 0090] loss=12.7566 cls=0.9767 smmd=0.1833 ct=9.2234 rec=1.1866 | train/val/test=1.000/0.744/0.720 | c=0.999488
[Epoch 0091] loss=12.4575 cls=0.6813 smmd=0.1841 ct=9.2231 rec=1.1844 | train/val/test=1.000/0.744/0.720 | c=0.999488
[Epoch 0092] loss=12.7459 cls=0.9645 smmd=0.1825 ct=9.2207 rec=1.1892 | train/val/test=1.000/0.744/0.720 | c=0.999488
[Epoch 0093] loss=12.7422 cls=0.9709 smmd=0.1833 ct=9.2253 rec=1.1813 | train/val/test=1.000/0.748/0.721 | c=0.999488
[Epoch 0094] loss=12.4877 cls=0.7225 smmd=0.1801 ct=9.2249 rec=1.1801 | train/val/test=1.000/0.748/0.721 | c=0.999488
[Epoch 0095] loss=12.7022 cls=0.9363 smmd=0.1826 ct=9.2223 rec=1.1805 | train/val/test=1.000/0.748/0.721 | c=0.999488
[Epoch 0096] loss=12.7789 cls=0.9840 smmd=0.1835 ct=9.2255 rec=1.1929 | train/val/test=1.000/0.746/0.721 | c=0.999488
[Epoch 0097] loss=12.7131 cls=0.9331 smmd=0.1856 ct=9.2270 rec=1.1837 | train/val/test=1.000/0.746/0.721 | c=0.999488
[Epoch 0098] loss=12.7812 cls=0.9902 smmd=0.1849 ct=9.2221 rec=1.1920 | train/val/test=1.000/0.746/0.721 | c=0.999488
[Epoch 0099] loss=12.6360 cls=0.8645 smmd=0.1808 ct=9.2230 rec=1.1838 | train/val/test=1.000/0.746/0.721 | c=0.999488
=== Best @ epoch 77: val=0.7480, test=0.7260 ===
