Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=17.1898 cls=2.0968 smmd=3.0720 ct=9.2401 rec=1.3905 | train/val/test=0.190/0.176/0.187 | c=0.999488
[Epoch 0001] loss=17.0737 cls=2.0692 smmd=2.9886 ct=9.2376 rec=1.3891 | train/val/test=0.328/0.214/0.207 | c=0.999488
[Epoch 0002] loss=16.8769 cls=2.0105 smmd=2.8536 ct=9.2318 rec=1.3905 | train/val/test=0.483/0.216/0.233 | c=0.999488
[Epoch 0003] loss=16.5061 cls=1.8395 smmd=2.6757 ct=9.2150 rec=1.3880 | train/val/test=0.431/0.124/0.154 | c=0.999488
[Epoch 0004] loss=16.2472 cls=1.8396 smmd=2.4456 ct=9.1904 rec=1.3858 | train/val/test=0.741/0.366/0.363 | c=0.999488
[Epoch 0005] loss=15.6339 cls=1.5859 smmd=2.1590 ct=9.1415 rec=1.3738 | train/val/test=0.914/0.648/0.613 | c=0.999488
[Epoch 0006] loss=15.1718 cls=1.5754 smmd=1.8209 ct=9.0655 rec=1.3549 | train/val/test=0.914/0.544/0.524 | c=0.999488
[Epoch 0007] loss=14.4165 cls=1.3466 smmd=1.4392 ct=8.9856 rec=1.3225 | train/val/test=0.879/0.550/0.534 | c=0.999488
[Epoch 0008] loss=13.7022 cls=1.1932 smmd=1.0418 ct=8.8931 rec=1.2871 | train/val/test=0.879/0.580/0.571 | c=0.999488
[Epoch 0009] loss=13.0592 cls=1.0991 smmd=0.6776 ct=8.7868 rec=1.2479 | train/val/test=0.879/0.630/0.621 | c=0.999488
[Epoch 0010] loss=12.5727 cls=0.9470 smmd=0.4098 ct=8.7650 rec=1.2255 | train/val/test=0.897/0.640/0.641 | c=0.999488
[Epoch 0011] loss=12.5691 cls=1.0964 smmd=0.2830 ct=8.7617 rec=1.2140 | train/val/test=0.914/0.640/0.634 | c=0.999488
[Epoch 0012] loss=13.3293 cls=1.1488 smmd=0.3147 ct=9.4570 rec=1.2043 | train/val/test=0.914/0.656/0.653 | c=0.999488
[Epoch 0013] loss=13.0707 cls=0.9271 smmd=0.4505 ct=9.2949 rec=1.1991 | train/val/test=0.983/0.664/0.673 | c=0.999488
[Epoch 0014] loss=13.2839 cls=1.0973 smmd=0.6379 ct=9.1657 rec=1.1915 | train/val/test=0.966/0.666/0.669 | c=0.999488
[Epoch 0015] loss=13.4332 cls=1.1336 smmd=0.8231 ct=9.0929 rec=1.1918 | train/val/test=0.914/0.666/0.641 | c=0.999488
[Epoch 0016] loss=13.5524 cls=1.1374 smmd=0.9588 ct=9.0682 rec=1.1940 | train/val/test=0.966/0.704/0.691 | c=0.999488
[Epoch 0017] loss=13.4381 cls=0.9910 smmd=1.0304 ct=9.0277 rec=1.1945 | train/val/test=0.983/0.714/0.714 | c=0.999488
[Epoch 0018] loss=13.6093 cls=1.1748 smmd=1.0353 ct=9.0115 rec=1.1938 | train/val/test=0.966/0.690/0.710 | c=0.999488
[Epoch 0019] loss=13.4855 cls=1.1206 smmd=0.9743 ct=8.9977 rec=1.1965 | train/val/test=0.966/0.686/0.696 | c=0.999488
[Epoch 0020] loss=13.3191 cls=1.0451 smmd=0.8646 ct=9.0107 rec=1.1993 | train/val/test=0.948/0.690/0.682 | c=0.999488
[Epoch 0021] loss=13.0711 cls=0.9092 smmd=0.7239 ct=9.0385 rec=1.1997 | train/val/test=0.948/0.686/0.678 | c=0.999488
[Epoch 0022] loss=13.2137 cls=1.1592 smmd=0.5848 ct=9.0730 rec=1.1983 | train/val/test=0.948/0.708/0.684 | c=0.999488
[Epoch 0023] loss=13.2090 cls=1.1965 smmd=0.4738 ct=9.1291 rec=1.2048 | train/val/test=0.966/0.710/0.694 | c=0.999488
[Epoch 0024] loss=12.9009 cls=0.8896 smmd=0.4003 ct=9.1863 rec=1.2124 | train/val/test=0.983/0.714/0.692 | c=0.999488
[Epoch 0025] loss=12.9879 cls=0.9762 smmd=0.3577 ct=9.2275 rec=1.2133 | train/val/test=0.983/0.694/0.685 | c=0.999488
[Epoch 0026] loss=13.0315 cls=1.0202 smmd=0.3386 ct=9.2561 rec=1.2083 | train/val/test=0.983/0.696/0.678 | c=0.999488
[Epoch 0027] loss=13.2779 cls=1.2515 smmd=0.3284 ct=9.2756 rec=1.2112 | train/val/test=0.983/0.700/0.685 | c=0.999488
[Epoch 0028] loss=13.2996 cls=1.2760 smmd=0.3218 ct=9.2822 rec=1.2097 | train/val/test=0.966/0.702/0.693 | c=0.999488
[Epoch 0029] loss=12.8592 cls=0.8640 smmd=0.3079 ct=9.2774 rec=1.2050 | train/val/test=0.983/0.708/0.701 | c=0.999488
[Epoch 0030] loss=13.4293 cls=1.4514 smmd=0.2889 ct=9.2675 rec=1.2107 | train/val/test=1.000/0.720/0.707 | c=0.999488
[Epoch 0031] loss=13.0292 cls=1.1019 smmd=0.2682 ct=9.2501 rec=1.2045 | train/val/test=1.000/0.724/0.711 | c=0.999488
[Epoch 0032] loss=13.0373 cls=1.1424 smmd=0.2565 ct=9.2335 rec=1.2025 | train/val/test=1.000/0.728/0.703 | c=0.999488
[Epoch 0033] loss=12.8677 cls=0.9707 smmd=0.2518 ct=9.2212 rec=1.2121 | train/val/test=0.983/0.722/0.698 | c=0.999488
[Epoch 0034] loss=12.9581 cls=1.0797 smmd=0.2481 ct=9.2161 rec=1.2071 | train/val/test=0.983/0.724/0.690 | c=0.999488
[Epoch 0035] loss=12.8846 cls=1.0207 smmd=0.2489 ct=9.2042 rec=1.2054 | train/val/test=0.983/0.722/0.686 | c=0.999488
[Epoch 0036] loss=13.1299 cls=1.2701 smmd=0.2430 ct=9.1961 rec=1.2103 | train/val/test=0.983/0.718/0.689 | c=0.999488
[Epoch 0037] loss=12.7938 cls=0.9686 smmd=0.2346 ct=9.1902 rec=1.2002 | train/val/test=1.000/0.726/0.701 | c=0.999488
[Epoch 0038] loss=13.1901 cls=1.3593 smmd=0.2323 ct=9.1961 rec=1.2012 | train/val/test=1.000/0.742/0.718 | c=0.999488
[Epoch 0039] loss=12.8683 cls=1.0153 smmd=0.2296 ct=9.2025 rec=1.2104 | train/val/test=1.000/0.748/0.735 | c=0.999488
[Epoch 0040] loss=13.1105 cls=1.2750 smmd=0.2231 ct=9.2072 rec=1.2026 | train/val/test=1.000/0.744/0.736 | c=0.999488
[Epoch 0041] loss=13.2366 cls=1.4144 smmd=0.2097 ct=9.2099 rec=1.2013 | train/val/test=1.000/0.740/0.721 | c=0.999488
[Epoch 0042] loss=12.9803 cls=1.1793 smmd=0.1928 ct=9.2072 rec=1.2005 | train/val/test=1.000/0.726/0.700 | c=0.999488
[Epoch 0043] loss=13.0532 cls=1.2598 smmd=0.1811 ct=9.2088 rec=1.2018 | train/val/test=1.000/0.706/0.686 | c=0.999488
[Epoch 0044] loss=12.8757 cls=1.0837 smmd=0.1745 ct=9.2116 rec=1.2030 | train/val/test=1.000/0.704/0.677 | c=0.999488
[Epoch 0045] loss=12.9030 cls=1.1027 smmd=0.1720 ct=9.2167 rec=1.2058 | train/val/test=1.000/0.708/0.679 | c=0.999488
[Epoch 0046] loss=12.8716 cls=1.0649 smmd=0.1694 ct=9.2241 rec=1.2066 | train/val/test=0.983/0.714/0.685 | c=0.999488
[Epoch 0047] loss=12.8110 cls=1.0311 smmd=0.1662 ct=9.2067 rec=1.2035 | train/val/test=0.983/0.728/0.694 | c=0.999488
[Epoch 0048] loss=12.8208 cls=1.0453 smmd=0.1662 ct=9.2096 rec=1.1999 | train/val/test=0.983/0.734/0.700 | c=0.999488
[Epoch 0049] loss=12.5490 cls=0.7772 smmd=0.1712 ct=9.2095 rec=1.1955 | train/val/test=0.983/0.736/0.701 | c=0.999488
[Epoch 0050] loss=12.8031 cls=1.0331 smmd=0.1689 ct=9.2060 rec=1.1976 | train/val/test=0.983/0.730/0.692 | c=0.999488
[Epoch 0051] loss=12.5012 cls=0.7371 smmd=0.1687 ct=9.2032 rec=1.1961 | train/val/test=0.983/0.726/0.695 | c=0.999488
[Epoch 0052] loss=12.5998 cls=0.8390 smmd=0.1673 ct=9.1945 rec=1.1995 | train/val/test=0.983/0.730/0.691 | c=0.999488
[Epoch 0053] loss=12.8950 cls=1.1420 smmd=0.1654 ct=9.2018 rec=1.1929 | train/val/test=0.983/0.724/0.689 | c=0.999488
[Epoch 0054] loss=12.6616 cls=0.9136 smmd=0.1656 ct=9.2033 rec=1.1896 | train/val/test=0.983/0.726/0.697 | c=0.999488
[Epoch 0055] loss=12.6789 cls=0.9329 smmd=0.1685 ct=9.2029 rec=1.1873 | train/val/test=0.983/0.728/0.697 | c=0.999488
[Epoch 0056] loss=12.8230 cls=1.0790 smmd=0.1670 ct=9.1993 rec=1.1888 | train/val/test=0.983/0.732/0.701 | c=0.999488
[Epoch 0057] loss=13.2077 cls=1.4562 smmd=0.1719 ct=9.2002 rec=1.1897 | train/val/test=0.983/0.738/0.699 | c=0.999488
[Epoch 0058] loss=12.8327 cls=1.1034 smmd=0.1710 ct=9.1876 rec=1.1853 | train/val/test=0.983/0.736/0.699 | c=0.999488
[Epoch 0059] loss=12.8454 cls=1.1107 smmd=0.1720 ct=9.1895 rec=1.1866 | train/val/test=0.983/0.722/0.695 | c=0.999488
[Epoch 0060] loss=12.6367 cls=0.8972 smmd=0.1717 ct=9.1879 rec=1.1900 | train/val/test=0.983/0.718/0.691 | c=0.999488
[Epoch 0061] loss=12.6909 cls=0.9429 smmd=0.1733 ct=9.1880 rec=1.1933 | train/val/test=0.983/0.714/0.690 | c=0.999488
[Epoch 0062] loss=13.2355 cls=1.4913 smmd=0.1732 ct=9.1861 rec=1.1925 | train/val/test=0.983/0.718/0.689 | c=0.999488
[Epoch 0063] loss=12.8783 cls=1.1464 smmd=0.1764 ct=9.1871 rec=1.1842 | train/val/test=0.983/0.724/0.692 | c=0.999488
[Epoch 0064] loss=12.6881 cls=0.9477 smmd=0.1745 ct=9.1909 rec=1.1875 | train/val/test=0.983/0.726/0.691 | c=0.999488
[Epoch 0065] loss=12.7453 cls=1.0081 smmd=0.1773 ct=9.1923 rec=1.1838 | train/val/test=0.983/0.726/0.694 | c=0.999488
[Epoch 0066] loss=12.6429 cls=0.8949 smmd=0.1804 ct=9.1927 rec=1.1875 | train/val/test=0.983/0.730/0.697 | c=0.999488
[Epoch 0067] loss=12.6196 cls=0.8711 smmd=0.1797 ct=9.1930 rec=1.1879 | train/val/test=0.983/0.736/0.697 | c=0.999488
[Epoch 0068] loss=12.9697 cls=1.2198 smmd=0.1821 ct=9.1832 rec=1.1923 | train/val/test=0.983/0.738/0.702 | c=0.999488
[Epoch 0069] loss=12.9080 cls=1.1547 smmd=0.1803 ct=9.1823 rec=1.1953 | train/val/test=0.983/0.736/0.697 | c=0.999488
[Epoch 0070] loss=13.0633 cls=1.3177 smmd=0.1798 ct=9.1793 rec=1.1933 | train/val/test=0.983/0.732/0.700 | c=0.999488
[Epoch 0071] loss=12.8086 cls=1.0521 smmd=0.1825 ct=9.1804 rec=1.1968 | train/val/test=0.983/0.734/0.695 | c=0.999488
[Epoch 0072] loss=12.7146 cls=0.9675 smmd=0.1770 ct=9.1788 rec=1.1957 | train/val/test=0.983/0.734/0.693 | c=0.999488
[Epoch 0073] loss=12.6129 cls=0.8716 smmd=0.1770 ct=9.1824 rec=1.1910 | train/val/test=0.983/0.734/0.690 | c=0.999488
[Epoch 0074] loss=12.8324 cls=1.0843 smmd=0.1769 ct=9.1863 rec=1.1925 | train/val/test=1.000/0.732/0.690 | c=0.999488
[Epoch 0075] loss=12.8819 cls=1.1386 smmd=0.1746 ct=9.1878 rec=1.1904 | train/val/test=1.000/0.732/0.692 | c=0.999488
[Epoch 0076] loss=12.6950 cls=0.9555 smmd=0.1724 ct=9.1861 rec=1.1905 | train/val/test=1.000/0.730/0.695 | c=0.999488
[Epoch 0077] loss=12.8283 cls=1.0843 smmd=0.1764 ct=9.1862 rec=1.1907 | train/val/test=1.000/0.734/0.697 | c=0.999488
[Epoch 0078] loss=12.8771 cls=1.1380 smmd=0.1739 ct=9.1839 rec=1.1907 | train/val/test=1.000/0.736/0.703 | c=0.999488
[Epoch 0079] loss=12.9463 cls=1.2002 smmd=0.1757 ct=9.1815 rec=1.1944 | train/val/test=1.000/0.736/0.705 | c=0.999488
[Epoch 0080] loss=12.6622 cls=0.9286 smmd=0.1756 ct=9.1772 rec=1.1903 | train/val/test=1.000/0.736/0.705 | c=0.999488
[Epoch 0081] loss=12.4909 cls=0.7407 smmd=0.1819 ct=9.1815 rec=1.1934 | train/val/test=1.000/0.738/0.706 | c=0.999488
[Epoch 0082] loss=12.6089 cls=0.8672 smmd=0.1798 ct=9.1791 rec=1.1914 | train/val/test=1.000/0.736/0.707 | c=0.999488
[Epoch 0083] loss=12.6332 cls=0.8879 smmd=0.1792 ct=9.1757 rec=1.1952 | train/val/test=1.000/0.734/0.705 | c=0.999488
[Epoch 0084] loss=12.5033 cls=0.7770 smmd=0.1741 ct=9.1752 rec=1.1884 | train/val/test=1.000/0.734/0.704 | c=0.999488
[Epoch 0085] loss=12.9459 cls=1.2046 smmd=0.1788 ct=9.1733 rec=1.1946 | train/val/test=1.000/0.736/0.703 | c=0.999488
[Epoch 0086] loss=12.6761 cls=0.9410 smmd=0.1812 ct=9.1767 rec=1.1886 | train/val/test=1.000/0.736/0.702 | c=0.999488
[Epoch 0087] loss=12.7900 cls=1.0471 smmd=0.1789 ct=9.1780 rec=1.1930 | train/val/test=1.000/0.736/0.701 | c=0.999488
[Epoch 0088] loss=12.5319 cls=0.8053 smmd=0.1795 ct=9.1730 rec=1.1871 | train/val/test=1.000/0.736/0.702 | c=0.999488
[Epoch 0089] loss=12.8881 cls=1.1346 smmd=0.1787 ct=9.1784 rec=1.1982 | train/val/test=1.000/0.734/0.703 | c=0.999488
[Epoch 0090] loss=12.3773 cls=0.6481 smmd=0.1796 ct=9.1740 rec=1.1878 | train/val/test=1.000/0.734/0.702 | c=0.999488
[Epoch 0091] loss=12.8469 cls=1.1124 smmd=0.1797 ct=9.1755 rec=1.1896 | train/val/test=1.000/0.736/0.701 | c=0.999488
[Epoch 0092] loss=12.5709 cls=0.8272 smmd=0.1821 ct=9.1769 rec=1.1923 | train/val/test=1.000/0.734/0.701 | c=0.999488
[Epoch 0093] loss=12.7984 cls=1.0600 smmd=0.1816 ct=9.1776 rec=1.1896 | train/val/test=1.000/0.734/0.701 | c=0.999488
[Epoch 0094] loss=12.5272 cls=0.7902 smmd=0.1812 ct=9.1748 rec=1.1905 | train/val/test=1.000/0.734/0.701 | c=0.999488
[Epoch 0095] loss=12.4831 cls=0.7465 smmd=0.1806 ct=9.1730 rec=1.1915 | train/val/test=1.000/0.734/0.701 | c=0.999488
[Epoch 0096] loss=12.7459 cls=1.0092 smmd=0.1796 ct=9.1742 rec=1.1914 | train/val/test=1.000/0.734/0.701 | c=0.999488
[Epoch 0097] loss=12.9182 cls=1.1632 smmd=0.1799 ct=9.1779 rec=1.1986 | train/val/test=1.000/0.734/0.701 | c=0.999488
[Epoch 0098] loss=12.7019 cls=0.9705 smmd=0.1830 ct=9.1715 rec=1.1885 | train/val/test=1.000/0.734/0.701 | c=0.999488
[Epoch 0099] loss=12.6882 cls=0.9464 smmd=0.1788 ct=9.1703 rec=1.1964 | train/val/test=1.000/0.734/0.701 | c=0.999488
=== Best @ epoch 39: val=0.7480, test=0.7350 ===
