Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=16.9690 cls=1.8999 smmd=3.0341 ct=9.2560 rec=1.3895 | train/val/test=0.190/0.112/0.122 | c=0.999488
[Epoch 0001] loss=16.9293 cls=1.9657 smmd=2.9313 ct=9.2534 rec=1.3894 | train/val/test=0.172/0.158/0.147 | c=0.999488
[Epoch 0002] loss=16.6854 cls=1.8692 smmd=2.7913 ct=9.2467 rec=1.3891 | train/val/test=0.466/0.140/0.186 | c=0.999488
[Epoch 0003] loss=16.2795 cls=1.6691 smmd=2.5988 ct=9.2379 rec=1.3868 | train/val/test=0.552/0.228/0.240 | c=0.999488
[Epoch 0004] loss=16.0229 cls=1.6864 smmd=2.3550 ct=9.2161 rec=1.3827 | train/val/test=0.759/0.344/0.355 | c=0.999488
[Epoch 0005] loss=15.3862 cls=1.4138 smmd=2.0558 ct=9.1794 rec=1.3686 | train/val/test=0.914/0.538/0.514 | c=0.999488
[Epoch 0006] loss=14.8667 cls=1.3593 smmd=1.7132 ct=9.1063 rec=1.3440 | train/val/test=0.914/0.518/0.503 | c=0.999488
[Epoch 0007] loss=14.1797 cls=1.2518 smmd=1.3457 ct=8.9960 rec=1.2931 | train/val/test=0.845/0.520/0.507 | c=0.999488
[Epoch 0008] loss=13.3862 cls=0.9683 smmd=0.9735 ct=8.9249 rec=1.2597 | train/val/test=0.914/0.544/0.534 | c=0.999488
[Epoch 0009] loss=13.4541 cls=1.4962 smmd=0.6389 ct=8.8564 rec=1.2313 | train/val/test=0.966/0.652/0.651 | c=0.999488
[Epoch 0010] loss=12.8261 cls=1.2031 smmd=0.3907 ct=8.8009 rec=1.2157 | train/val/test=0.931/0.702/0.689 | c=0.999488
[Epoch 0011] loss=12.5903 cls=1.0819 smmd=0.2841 ct=8.8013 rec=1.2115 | train/val/test=0.914/0.676/0.661 | c=0.999488
[Epoch 0012] loss=12.6583 cls=1.1148 smmd=0.2960 ct=8.8190 rec=1.2143 | train/val/test=0.931/0.672/0.666 | c=0.999488
[Epoch 0013] loss=12.9897 cls=1.4024 smmd=0.3878 ct=8.7962 rec=1.2016 | train/val/test=0.966/0.704/0.687 | c=0.999488
[Epoch 0014] loss=12.9270 cls=1.2446 smmd=0.5121 ct=8.7769 rec=1.1967 | train/val/test=0.948/0.692/0.685 | c=0.999488
[Epoch 0015] loss=12.9664 cls=1.1654 smmd=0.6215 ct=8.7789 rec=1.2003 | train/val/test=0.948/0.688/0.692 | c=0.999488
[Epoch 0016] loss=13.4194 cls=1.5583 smmd=0.6807 ct=8.7699 rec=1.2053 | train/val/test=0.966/0.698/0.709 | c=0.999488
[Epoch 0017] loss=13.0054 cls=1.1803 smmd=0.6824 ct=8.7399 rec=1.2013 | train/val/test=0.948/0.720/0.704 | c=0.999488
[Epoch 0018] loss=13.1435 cls=1.3583 smmd=0.6427 ct=8.7393 rec=1.2016 | train/val/test=0.948/0.718/0.702 | c=0.999488
[Epoch 0019] loss=12.8054 cls=1.0623 smmd=0.5701 ct=8.7543 rec=1.2093 | train/val/test=0.948/0.704/0.700 | c=0.999488
[Epoch 0020] loss=12.8175 cls=1.1331 smmd=0.4694 ct=8.7639 rec=1.2255 | train/val/test=0.948/0.690/0.685 | c=0.999488
[Epoch 0021] loss=12.6695 cls=1.1103 smmd=0.3617 ct=8.7473 rec=1.2251 | train/val/test=0.948/0.680/0.669 | c=0.999488
[Epoch 0022] loss=12.4357 cls=0.9857 smmd=0.2808 ct=8.7279 rec=1.2206 | train/val/test=0.948/0.666/0.647 | c=0.999488
[Epoch 0023] loss=12.4659 cls=1.0574 smmd=0.2446 ct=8.7224 rec=1.2208 | train/val/test=0.948/0.664/0.645 | c=0.999488
[Epoch 0024] loss=12.3930 cls=0.9906 smmd=0.2378 ct=8.7244 rec=1.2202 | train/val/test=0.948/0.674/0.658 | c=0.999488
[Epoch 0025] loss=12.1224 cls=0.7323 smmd=0.2479 ct=8.7150 rec=1.2136 | train/val/test=0.948/0.686/0.678 | c=0.999488
[Epoch 0026] loss=12.5499 cls=1.1525 smmd=0.2661 ct=8.7107 rec=1.2103 | train/val/test=0.966/0.712/0.719 | c=0.999488
[Epoch 0027] loss=12.3398 cls=0.9307 smmd=0.2810 ct=8.7087 rec=1.2097 | train/val/test=0.966/0.726/0.721 | c=0.999488
[Epoch 0028] loss=12.4538 cls=1.0459 smmd=0.2819 ct=8.7098 rec=1.2081 | train/val/test=0.983/0.722/0.716 | c=0.999488
[Epoch 0029] loss=12.4821 cls=1.0811 smmd=0.2716 ct=8.7093 rec=1.2100 | train/val/test=0.983/0.718/0.709 | c=0.999488
[Epoch 0030] loss=12.5780 cls=1.2263 smmd=0.2462 ct=8.7056 rec=1.2000 | train/val/test=0.983/0.716/0.717 | c=0.999488
[Epoch 0031] loss=12.3515 cls=1.0377 smmd=0.2154 ct=8.7061 rec=1.1961 | train/val/test=0.983/0.710/0.711 | c=0.999488
[Epoch 0032] loss=12.3930 cls=1.1043 smmd=0.1929 ct=8.7034 rec=1.1962 | train/val/test=0.983/0.702/0.702 | c=0.999488
[Epoch 0033] loss=12.1243 cls=0.8620 smmd=0.1760 ct=8.7070 rec=1.1896 | train/val/test=0.966/0.700/0.696 | c=0.999488
[Epoch 0034] loss=12.0964 cls=0.8433 smmd=0.1684 ct=8.7096 rec=1.1876 | train/val/test=0.948/0.706/0.696 | c=0.999488
[Epoch 0035] loss=12.0480 cls=0.8000 smmd=0.1644 ct=8.7112 rec=1.1862 | train/val/test=0.948/0.708/0.700 | c=0.999488
[Epoch 0036] loss=11.9231 cls=0.6904 smmd=0.1612 ct=8.7098 rec=1.1809 | train/val/test=0.948/0.716/0.716 | c=0.999488
[Epoch 0037] loss=11.9019 cls=0.6747 smmd=0.1585 ct=8.7054 rec=1.1816 | train/val/test=0.983/0.726/0.722 | c=0.999488
[Epoch 0038] loss=12.4079 cls=1.1908 smmd=0.1525 ct=8.7049 rec=1.1799 | train/val/test=0.983/0.728/0.731 | c=0.999488
[Epoch 0039] loss=12.3464 cls=1.1451 smmd=0.1453 ct=8.7029 rec=1.1765 | train/val/test=0.983/0.720/0.730 | c=0.999488
[Epoch 0040] loss=12.3630 cls=1.1656 smmd=0.1390 ct=8.7038 rec=1.1773 | train/val/test=0.983/0.714/0.723 | c=0.999488
[Epoch 0041] loss=12.3369 cls=1.1400 smmd=0.1318 ct=8.6995 rec=1.1828 | train/val/test=0.983/0.704/0.723 | c=0.999488
[Epoch 0042] loss=12.5244 cls=1.3331 smmd=0.1264 ct=8.7010 rec=1.1819 | train/val/test=0.966/0.698/0.719 | c=0.999488
[Epoch 0043] loss=12.1976 cls=1.0100 smmd=0.1213 ct=8.6996 rec=1.1834 | train/val/test=0.966/0.704/0.715 | c=0.999488
[Epoch 0044] loss=12.3379 cls=1.1502 smmd=0.1167 ct=8.7005 rec=1.1852 | train/val/test=0.966/0.704/0.711 | c=0.999488
[Epoch 0045] loss=12.1302 cls=0.9630 smmd=0.1132 ct=8.6981 rec=1.1780 | train/val/test=0.983/0.704/0.706 | c=0.999488
[Epoch 0046] loss=12.1169 cls=0.9409 smmd=0.1105 ct=8.6953 rec=1.1851 | train/val/test=0.983/0.702/0.713 | c=0.999488
[Epoch 0047] loss=12.5845 cls=1.4181 smmd=0.1079 ct=8.6944 rec=1.1820 | train/val/test=0.983/0.708/0.720 | c=0.999488
[Epoch 0048] loss=12.3746 cls=1.1870 smmd=0.1129 ct=8.6959 rec=1.1894 | train/val/test=1.000/0.716/0.730 | c=0.999488
[Epoch 0049] loss=12.3682 cls=1.1772 smmd=0.1112 ct=8.6976 rec=1.1911 | train/val/test=1.000/0.710/0.732 | c=0.999488
[Epoch 0050] loss=12.2895 cls=1.0821 smmd=0.1121 ct=8.7044 rec=1.1955 | train/val/test=1.000/0.710/0.735 | c=0.999488
[Epoch 0051] loss=12.1378 cls=0.9303 smmd=0.1082 ct=8.7013 rec=1.1990 | train/val/test=0.983/0.714/0.735 | c=0.999488
[Epoch 0052] loss=12.1218 cls=0.9012 smmd=0.1067 ct=8.7052 rec=1.2044 | train/val/test=0.983/0.714/0.727 | c=0.999488
[Epoch 0053] loss=12.1305 cls=0.9244 smmd=0.1094 ct=8.6997 rec=1.1985 | train/val/test=0.983/0.704/0.720 | c=0.999488
[Epoch 0054] loss=12.2532 cls=1.0362 smmd=0.1106 ct=8.6994 rec=1.2035 | train/val/test=0.983/0.700/0.715 | c=0.999488
[Epoch 0055] loss=12.3495 cls=1.1409 smmd=0.1122 ct=8.6975 rec=1.1994 | train/val/test=0.983/0.708/0.718 | c=0.999488
[Epoch 0056] loss=12.1735 cls=0.9591 smmd=0.1161 ct=8.6892 rec=1.2046 | train/val/test=0.983/0.712/0.723 | c=0.999488
[Epoch 0057] loss=11.8989 cls=0.7070 smmd=0.1107 ct=8.6884 rec=1.1964 | train/val/test=0.983/0.710/0.723 | c=0.999488
[Epoch 0058] loss=12.1571 cls=0.9678 smmd=0.1134 ct=8.6930 rec=1.1915 | train/val/test=1.000/0.720/0.727 | c=0.999488
[Epoch 0059] loss=12.1209 cls=0.9269 smmd=0.1134 ct=8.6966 rec=1.1921 | train/val/test=1.000/0.724/0.723 | c=0.999488
[Epoch 0060] loss=12.2534 cls=1.0453 smmd=0.1149 ct=8.6979 rec=1.1977 | train/val/test=1.000/0.720/0.726 | c=0.999488
[Epoch 0061] loss=12.3672 cls=1.1653 smmd=0.1183 ct=8.6964 rec=1.1936 | train/val/test=1.000/0.716/0.724 | c=0.999488
[Epoch 0062] loss=12.3856 cls=1.1947 smmd=0.1174 ct=8.6972 rec=1.1882 | train/val/test=1.000/0.712/0.724 | c=0.999488
[Epoch 0063] loss=12.2179 cls=1.0203 smmd=0.1171 ct=8.6977 rec=1.1914 | train/val/test=0.983/0.718/0.727 | c=0.999488
[Epoch 0064] loss=12.3079 cls=1.1215 smmd=0.1131 ct=8.6991 rec=1.1871 | train/val/test=0.983/0.714/0.726 | c=0.999488
[Epoch 0065] loss=11.9940 cls=0.8069 smmd=0.1160 ct=8.6981 rec=1.1866 | train/val/test=0.983/0.708/0.721 | c=0.999488
[Epoch 0066] loss=12.3981 cls=1.2077 smmd=0.1166 ct=8.6971 rec=1.1884 | train/val/test=0.983/0.710/0.722 | c=0.999488
[Epoch 0067] loss=12.3631 cls=1.1700 smmd=0.1178 ct=8.6958 rec=1.1897 | train/val/test=0.983/0.712/0.721 | c=0.999488
[Epoch 0068] loss=12.2981 cls=1.1123 smmd=0.1145 ct=8.6933 rec=1.1890 | train/val/test=1.000/0.712/0.716 | c=0.999488
[Epoch 0069] loss=12.1590 cls=0.9809 smmd=0.1188 ct=8.6926 rec=1.1833 | train/val/test=1.000/0.712/0.710 | c=0.999488
[Epoch 0070] loss=12.4298 cls=1.2420 smmd=0.1213 ct=8.6931 rec=1.1867 | train/val/test=1.000/0.714/0.703 | c=0.999488
[Epoch 0071] loss=12.1298 cls=0.9489 smmd=0.1224 ct=8.6948 rec=1.1819 | train/val/test=1.000/0.712/0.701 | c=0.999488
[Epoch 0072] loss=12.3284 cls=1.1459 smmd=0.1214 ct=8.6948 rec=1.1831 | train/val/test=1.000/0.708/0.700 | c=0.999488
[Epoch 0073] loss=12.2141 cls=1.0296 smmd=0.1235 ct=8.6938 rec=1.1836 | train/val/test=1.000/0.706/0.702 | c=0.999488
[Epoch 0074] loss=12.5885 cls=1.3988 smmd=0.1236 ct=8.6957 rec=1.1852 | train/val/test=1.000/0.710/0.701 | c=0.999488
[Epoch 0075] loss=11.8798 cls=0.6948 smmd=0.1245 ct=8.6959 rec=1.1823 | train/val/test=1.000/0.708/0.703 | c=0.999488
[Epoch 0076] loss=12.2162 cls=1.0244 smmd=0.1265 ct=8.6927 rec=1.1862 | train/val/test=1.000/0.710/0.705 | c=0.999488
[Epoch 0077] loss=12.3318 cls=1.1400 smmd=0.1252 ct=8.6944 rec=1.1861 | train/val/test=1.000/0.708/0.705 | c=0.999488
[Epoch 0078] loss=12.4502 cls=1.2538 smmd=0.1246 ct=8.6938 rec=1.1889 | train/val/test=1.000/0.712/0.712 | c=0.999488
[Epoch 0079] loss=12.3063 cls=1.1165 smmd=0.1239 ct=8.6947 rec=1.1856 | train/val/test=1.000/0.714/0.715 | c=0.999488
[Epoch 0080] loss=12.3238 cls=1.1340 smmd=0.1236 ct=8.6948 rec=1.1857 | train/val/test=1.000/0.714/0.718 | c=0.999488
[Epoch 0081] loss=12.2948 cls=1.0986 smmd=0.1275 ct=8.6931 rec=1.1878 | train/val/test=1.000/0.714/0.720 | c=0.999488
[Epoch 0082] loss=12.0872 cls=0.8995 smmd=0.1269 ct=8.6950 rec=1.1829 | train/val/test=1.000/0.714/0.719 | c=0.999488
[Epoch 0083] loss=12.1375 cls=0.9467 smmd=0.1264 ct=8.6947 rec=1.1848 | train/val/test=1.000/0.714/0.718 | c=0.999488
[Epoch 0084] loss=12.3695 cls=1.1740 smmd=0.1260 ct=8.6924 rec=1.1885 | train/val/test=1.000/0.710/0.714 | c=0.999488
[Epoch 0085] loss=12.3407 cls=1.1491 smmd=0.1265 ct=8.6926 rec=1.1862 | train/val/test=1.000/0.708/0.712 | c=0.999488
[Epoch 0086] loss=12.1149 cls=0.9108 smmd=0.1250 ct=8.6929 rec=1.1931 | train/val/test=1.000/0.706/0.710 | c=0.999488
[Epoch 0087] loss=12.3438 cls=1.1535 smmd=0.1264 ct=8.6916 rec=1.1861 | train/val/test=1.000/0.708/0.708 | c=0.999488
[Epoch 0088] loss=12.1524 cls=0.9633 smmd=0.1270 ct=8.6918 rec=1.1852 | train/val/test=1.000/0.710/0.708 | c=0.999488
[Epoch 0089] loss=11.8490 cls=0.6737 smmd=0.1223 ct=8.6944 rec=1.1793 | train/val/test=1.000/0.712/0.711 | c=0.999488
[Epoch 0090] loss=12.0826 cls=0.9010 smmd=0.1253 ct=8.6943 rec=1.1810 | train/val/test=1.000/0.712/0.711 | c=0.999488
[Epoch 0091] loss=11.9548 cls=0.7639 smmd=0.1277 ct=8.6925 rec=1.1854 | train/val/test=1.000/0.712/0.712 | c=0.999488
[Epoch 0092] loss=12.1711 cls=0.9779 smmd=0.1314 ct=8.6924 rec=1.1847 | train/val/test=1.000/0.712/0.712 | c=0.999488
[Epoch 0093] loss=12.2438 cls=1.0585 smmd=0.1251 ct=8.6909 rec=1.1847 | train/val/test=1.000/0.710/0.712 | c=0.999488
[Epoch 0094] loss=12.5750 cls=1.3768 smmd=0.1261 ct=8.6926 rec=1.1897 | train/val/test=1.000/0.710/0.711 | c=0.999488
[Epoch 0095] loss=12.3102 cls=1.1269 smmd=0.1274 ct=8.6911 rec=1.1824 | train/val/test=1.000/0.710/0.711 | c=0.999488
[Epoch 0096] loss=11.9489 cls=0.7661 smmd=0.1253 ct=8.6933 rec=1.1821 | train/val/test=1.000/0.710/0.711 | c=0.999488
[Epoch 0097] loss=12.2008 cls=1.0028 smmd=0.1282 ct=8.6935 rec=1.1881 | train/val/test=1.000/0.710/0.711 | c=0.999488
[Epoch 0098] loss=11.8873 cls=0.7095 smmd=0.1250 ct=8.6922 rec=1.1803 | train/val/test=1.000/0.710/0.711 | c=0.999488
[Epoch 0099] loss=12.1233 cls=0.9423 smmd=0.1275 ct=8.6916 rec=1.1809 | train/val/test=1.000/0.710/0.711 | c=0.999488
=== Best @ epoch 38: val=0.7280, test=0.7310 ===
