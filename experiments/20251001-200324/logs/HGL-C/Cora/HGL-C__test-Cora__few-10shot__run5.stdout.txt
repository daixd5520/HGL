Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=17.1334 cls=2.0529 smmd=3.0806 ct=9.2233 rec=1.3883 | train/val/test=0.362/0.148/0.161 | c=0.999488
[Epoch 0001] loss=16.9493 cls=1.9693 smmd=2.9860 ct=9.2184 rec=1.3878 | train/val/test=0.362/0.224/0.211 | c=0.999488
[Epoch 0002] loss=16.6048 cls=1.7697 smmd=2.8495 ct=9.2103 rec=1.3876 | train/val/test=0.793/0.416/0.420 | c=0.999488
[Epoch 0003] loss=16.2780 cls=1.6560 smmd=2.6650 ct=9.1891 rec=1.3839 | train/val/test=0.845/0.482/0.522 | c=0.999488
[Epoch 0004] loss=15.9622 cls=1.6267 smmd=2.4359 ct=9.1454 rec=1.3771 | train/val/test=0.879/0.512/0.544 | c=0.999488
[Epoch 0005] loss=15.4018 cls=1.4531 smmd=2.1549 ct=9.0787 rec=1.3576 | train/val/test=0.948/0.596/0.607 | c=0.999488
[Epoch 0006] loss=15.0149 cls=1.5516 smmd=1.8336 ct=8.9930 rec=1.3184 | train/val/test=0.931/0.566/0.567 | c=0.999488
[Epoch 0007] loss=14.3369 cls=1.3622 smmd=1.4748 ct=8.9248 rec=1.2876 | train/val/test=0.931/0.598/0.595 | c=0.999488
[Epoch 0008] loss=13.7941 cls=1.3694 smmd=1.1101 ct=8.8157 rec=1.2494 | train/val/test=0.931/0.648/0.650 | c=0.999488
[Epoch 0009] loss=12.9712 cls=0.9719 smmd=0.7697 ct=8.7776 rec=1.2260 | train/val/test=0.948/0.688/0.696 | c=0.999488
[Epoch 0010] loss=13.1261 cls=1.4195 smmd=0.4906 ct=8.7926 rec=1.2117 | train/val/test=0.914/0.676/0.697 | c=0.999488
[Epoch 0011] loss=13.5362 cls=1.2974 smmd=0.3164 ct=9.5164 rec=1.2030 | train/val/test=0.914/0.642/0.643 | c=0.999488
[Epoch 0012] loss=12.8867 cls=0.8471 smmd=0.2799 ct=9.3575 rec=1.2011 | train/val/test=0.914/0.644/0.632 | c=0.999488
[Epoch 0013] loss=12.9750 cls=0.9439 smmd=0.3760 ct=9.2455 rec=1.2048 | train/val/test=0.948/0.638/0.629 | c=0.999488
[Epoch 0014] loss=13.1623 cls=1.0096 smmd=0.5487 ct=9.1721 rec=1.2159 | train/val/test=0.983/0.646/0.640 | c=0.999488
[Epoch 0015] loss=13.3219 cls=1.0413 smmd=0.7233 ct=9.1235 rec=1.2169 | train/val/test=0.983/0.666/0.663 | c=0.999488
[Epoch 0016] loss=13.3649 cls=1.0244 smmd=0.8575 ct=9.0691 rec=1.2069 | train/val/test=0.983/0.672/0.667 | c=0.999488
[Epoch 0017] loss=13.6134 cls=1.2097 smmd=0.9376 ct=9.0632 rec=1.2014 | train/val/test=0.948/0.674/0.673 | c=0.999488
[Epoch 0018] loss=13.3757 cls=0.9400 smmd=0.9516 ct=9.0751 rec=1.2045 | train/val/test=0.948/0.698/0.695 | c=0.999488
[Epoch 0019] loss=13.4425 cls=1.0393 smmd=0.9078 ct=9.0810 rec=1.2072 | train/val/test=0.948/0.716/0.697 | c=0.999488
[Epoch 0020] loss=13.1923 cls=0.9265 smmd=0.8116 ct=9.0615 rec=1.1964 | train/val/test=0.948/0.714/0.691 | c=0.999488
[Epoch 0021] loss=13.2158 cls=1.0723 smmd=0.6875 ct=9.0595 rec=1.1982 | train/val/test=0.983/0.688/0.666 | c=0.999488
[Epoch 0022] loss=13.0303 cls=0.9819 smmd=0.5592 ct=9.0835 rec=1.2028 | train/val/test=0.966/0.682/0.657 | c=0.999488
[Epoch 0023] loss=13.2889 cls=1.3133 smmd=0.4492 ct=9.1165 rec=1.2050 | train/val/test=0.983/0.694/0.666 | c=0.999488
[Epoch 0024] loss=13.0336 cls=1.1141 smmd=0.3649 ct=9.1503 rec=1.2022 | train/val/test=0.983/0.706/0.675 | c=0.999488
[Epoch 0025] loss=12.8770 cls=0.9759 smmd=0.3163 ct=9.1888 rec=1.1980 | train/val/test=0.983/0.730/0.689 | c=0.999488
[Epoch 0026] loss=12.9933 cls=1.0668 smmd=0.3039 ct=9.2137 rec=1.2045 | train/val/test=0.983/0.738/0.702 | c=0.999488
[Epoch 0027] loss=13.0842 cls=1.1406 smmd=0.3083 ct=9.2356 rec=1.1998 | train/val/test=0.983/0.736/0.711 | c=0.999488
[Epoch 0028] loss=13.1576 cls=1.1953 smmd=0.3183 ct=9.2476 rec=1.1982 | train/val/test=0.983/0.740/0.717 | c=0.999488
[Epoch 0029] loss=12.7057 cls=0.7511 smmd=0.3193 ct=9.2368 rec=1.1992 | train/val/test=0.983/0.740/0.715 | c=0.999488
[Epoch 0030] loss=13.0143 cls=1.0758 smmd=0.3111 ct=9.2268 rec=1.2003 | train/val/test=0.983/0.744/0.716 | c=0.999488
[Epoch 0031] loss=13.0301 cls=1.1088 smmd=0.2966 ct=9.2152 rec=1.2047 | train/val/test=0.983/0.746/0.715 | c=0.999488
[Epoch 0032] loss=12.8052 cls=0.9333 smmd=0.2745 ct=9.1984 rec=1.1995 | train/val/test=0.983/0.742/0.711 | c=0.999488
[Epoch 0033] loss=12.8004 cls=0.9580 smmd=0.2562 ct=9.1898 rec=1.1982 | train/val/test=0.983/0.742/0.711 | c=0.999488
[Epoch 0034] loss=12.8280 cls=1.0119 smmd=0.2411 ct=9.1917 rec=1.1916 | train/val/test=0.983/0.742/0.711 | c=0.999488
[Epoch 0035] loss=12.8840 cls=1.0770 smmd=0.2330 ct=9.1879 rec=1.1930 | train/val/test=0.983/0.750/0.715 | c=0.999488
[Epoch 0036] loss=12.6164 cls=0.8281 smmd=0.2280 ct=9.1879 rec=1.1862 | train/val/test=0.983/0.746/0.716 | c=0.999488
[Epoch 0037] loss=12.7911 cls=0.9879 smmd=0.2245 ct=9.1920 rec=1.1933 | train/val/test=0.983/0.748/0.719 | c=0.999488
[Epoch 0038] loss=12.8853 cls=1.1081 smmd=0.2205 ct=9.1892 rec=1.1837 | train/val/test=0.983/0.746/0.714 | c=0.999488
[Epoch 0039] loss=12.8301 cls=1.0531 smmd=0.2186 ct=9.1879 rec=1.1853 | train/val/test=0.983/0.740/0.698 | c=0.999488
[Epoch 0040] loss=12.7382 cls=0.9602 smmd=0.2122 ct=9.1933 rec=1.1863 | train/val/test=0.983/0.730/0.685 | c=0.999488
[Epoch 0041] loss=12.8602 cls=1.0784 smmd=0.2033 ct=9.1979 rec=1.1903 | train/val/test=0.983/0.732/0.679 | c=0.999488
[Epoch 0042] loss=12.9535 cls=1.1792 smmd=0.1958 ct=9.2008 rec=1.1888 | train/val/test=0.983/0.728/0.683 | c=0.999488
[Epoch 0043] loss=12.7775 cls=1.0044 smmd=0.1889 ct=9.1947 rec=1.1947 | train/val/test=0.983/0.738/0.695 | c=0.999488
[Epoch 0044] loss=12.6061 cls=0.8428 smmd=0.1820 ct=9.1976 rec=1.1918 | train/val/test=0.983/0.744/0.704 | c=0.999488
[Epoch 0045] loss=12.7624 cls=0.9866 smmd=0.1801 ct=9.2035 rec=1.1961 | train/val/test=1.000/0.740/0.715 | c=0.999488
[Epoch 0046] loss=12.7191 cls=0.9698 smmd=0.1803 ct=9.1942 rec=1.1874 | train/val/test=0.983/0.742/0.714 | c=0.999488
[Epoch 0047] loss=12.7210 cls=0.9768 smmd=0.1788 ct=9.1905 rec=1.1874 | train/val/test=0.983/0.746/0.711 | c=0.999488
[Epoch 0048] loss=12.5306 cls=0.7878 smmd=0.1746 ct=9.1943 rec=1.1870 | train/val/test=0.983/0.738/0.700 | c=0.999488
[Epoch 0049] loss=12.8552 cls=1.1239 smmd=0.1757 ct=9.1850 rec=1.1853 | train/val/test=0.983/0.728/0.694 | c=0.999488
[Epoch 0050] loss=12.9165 cls=1.1803 smmd=0.1753 ct=9.1814 rec=1.1898 | train/val/test=0.983/0.718/0.692 | c=0.999488
[Epoch 0051] loss=12.5657 cls=0.8334 smmd=0.1790 ct=9.1778 rec=1.1878 | train/val/test=1.000/0.718/0.696 | c=0.999488
[Epoch 0052] loss=12.8955 cls=1.1719 smmd=0.1795 ct=9.1717 rec=1.1862 | train/val/test=1.000/0.718/0.695 | c=0.999488
[Epoch 0053] loss=12.9552 cls=1.2354 smmd=0.1761 ct=9.1665 rec=1.1886 | train/val/test=1.000/0.726/0.700 | c=0.999488
[Epoch 0054] loss=12.7537 cls=1.0175 smmd=0.1782 ct=9.1766 rec=1.1907 | train/val/test=0.983/0.732/0.702 | c=0.999488
[Epoch 0055] loss=12.4632 cls=0.7305 smmd=0.1767 ct=9.1793 rec=1.1884 | train/val/test=0.983/0.736/0.706 | c=0.999488
[Epoch 0056] loss=12.8057 cls=1.0828 smmd=0.1708 ct=9.1767 rec=1.1877 | train/val/test=0.983/0.738/0.714 | c=0.999488
[Epoch 0057] loss=13.0443 cls=1.3125 smmd=0.1755 ct=9.1784 rec=1.1890 | train/val/test=0.983/0.738/0.708 | c=0.999488
[Epoch 0058] loss=12.7742 cls=1.0424 smmd=0.1713 ct=9.1860 rec=1.1872 | train/val/test=0.983/0.740/0.707 | c=0.999488
[Epoch 0059] loss=12.7680 cls=1.0382 smmd=0.1742 ct=9.1785 rec=1.1886 | train/val/test=0.983/0.748/0.700 | c=0.999488
[Epoch 0060] loss=12.5945 cls=0.8488 smmd=0.1764 ct=9.1827 rec=1.1933 | train/val/test=0.983/0.734/0.698 | c=0.999488
[Epoch 0061] loss=12.8932 cls=1.1576 smmd=0.1791 ct=9.1707 rec=1.1929 | train/val/test=0.983/0.730/0.697 | c=0.999488
[Epoch 0062] loss=12.6052 cls=0.8787 smmd=0.1825 ct=9.1656 rec=1.1892 | train/val/test=1.000/0.716/0.695 | c=0.999488
[Epoch 0063] loss=12.6520 cls=0.9154 smmd=0.1875 ct=9.1631 rec=1.1930 | train/val/test=1.000/0.718/0.697 | c=0.999488
[Epoch 0064] loss=12.8335 cls=1.0960 smmd=0.1959 ct=9.1554 rec=1.1931 | train/val/test=1.000/0.720/0.702 | c=0.999488
[Epoch 0065] loss=12.7132 cls=0.9851 smmd=0.1972 ct=9.1539 rec=1.1885 | train/val/test=1.000/0.722/0.704 | c=0.999488
[Epoch 0066] loss=12.5500 cls=0.8295 smmd=0.1964 ct=9.1529 rec=1.1856 | train/val/test=1.000/0.732/0.711 | c=0.999488
[Epoch 0067] loss=12.5203 cls=0.7949 smmd=0.1920 ct=9.1572 rec=1.1881 | train/val/test=1.000/0.738/0.711 | c=0.999488
[Epoch 0068] loss=13.1742 cls=1.4442 smmd=0.1914 ct=9.1604 rec=1.1891 | train/val/test=0.983/0.736/0.706 | c=0.999488
[Epoch 0069] loss=12.6673 cls=0.9354 smmd=0.1885 ct=9.1718 rec=1.1858 | train/val/test=0.983/0.732/0.704 | c=0.999488
[Epoch 0070] loss=12.8359 cls=1.1101 smmd=0.1890 ct=9.1659 rec=1.1854 | train/val/test=0.983/0.734/0.702 | c=0.999488
[Epoch 0071] loss=12.7630 cls=1.0318 smmd=0.1903 ct=9.1599 rec=1.1905 | train/val/test=1.000/0.734/0.708 | c=0.999488
[Epoch 0072] loss=12.4770 cls=0.7606 smmd=0.1921 ct=9.1500 rec=1.1872 | train/val/test=1.000/0.730/0.708 | c=0.999488
[Epoch 0073] loss=12.8233 cls=1.0957 smmd=0.1907 ct=9.1582 rec=1.1894 | train/val/test=1.000/0.728/0.713 | c=0.999488
[Epoch 0074] loss=13.0217 cls=1.2877 smmd=0.1950 ct=9.1553 rec=1.1918 | train/val/test=1.000/0.732/0.713 | c=0.999488
[Epoch 0075] loss=12.7019 cls=0.9838 smmd=0.1977 ct=9.1539 rec=1.1832 | train/val/test=1.000/0.734/0.712 | c=0.999488
[Epoch 0076] loss=12.6956 cls=0.9734 smmd=0.2007 ct=9.1482 rec=1.1867 | train/val/test=1.000/0.730/0.711 | c=0.999488
[Epoch 0077] loss=12.6004 cls=0.8885 smmd=0.1984 ct=9.1481 rec=1.1827 | train/val/test=1.000/0.732/0.704 | c=0.999488
[Epoch 0078] loss=12.4614 cls=0.7509 smmd=0.1959 ct=9.1479 rec=1.1833 | train/val/test=1.000/0.732/0.704 | c=0.999488
[Epoch 0079] loss=12.5648 cls=0.8544 smmd=0.1950 ct=9.1510 rec=1.1822 | train/val/test=1.000/0.732/0.705 | c=0.999488
[Epoch 0080] loss=12.5495 cls=0.8458 smmd=0.1963 ct=9.1502 rec=1.1786 | train/val/test=1.000/0.732/0.707 | c=0.999488
[Epoch 0081] loss=13.0299 cls=1.3107 smmd=0.1948 ct=9.1523 rec=1.1860 | train/val/test=1.000/0.732/0.705 | c=0.999488
[Epoch 0082] loss=12.5402 cls=0.8281 smmd=0.1943 ct=9.1504 rec=1.1837 | train/val/test=1.000/0.736/0.702 | c=0.999488
[Epoch 0083] loss=12.9009 cls=1.1775 smmd=0.1930 ct=9.1548 rec=1.1878 | train/val/test=1.000/0.734/0.705 | c=0.999488
[Epoch 0084] loss=12.5752 cls=0.8654 smmd=0.1940 ct=9.1514 rec=1.1822 | train/val/test=1.000/0.734/0.704 | c=0.999488
[Epoch 0085] loss=12.7397 cls=1.0246 smmd=0.1939 ct=9.1503 rec=1.1854 | train/val/test=1.000/0.734/0.702 | c=0.999488
[Epoch 0086] loss=12.8110 cls=1.0904 smmd=0.1910 ct=9.1512 rec=1.1892 | train/val/test=1.000/0.734/0.703 | c=0.999488
[Epoch 0087] loss=13.0101 cls=1.2969 smmd=0.1953 ct=9.1489 rec=1.1845 | train/val/test=1.000/0.734/0.704 | c=0.999488
[Epoch 0088] loss=12.9633 cls=1.2405 smmd=0.1955 ct=9.1473 rec=1.1900 | train/val/test=1.000/0.732/0.703 | c=0.999488
[Epoch 0089] loss=12.7189 cls=1.0106 smmd=0.1929 ct=9.1462 rec=1.1846 | train/val/test=1.000/0.732/0.704 | c=0.999488
[Epoch 0090] loss=12.7245 cls=1.0083 smmd=0.1971 ct=9.1427 rec=1.1882 | train/val/test=1.000/0.730/0.707 | c=0.999488
[Epoch 0091] loss=12.6307 cls=0.9242 smmd=0.1956 ct=9.1457 rec=1.1826 | train/val/test=1.000/0.730/0.707 | c=0.999488
[Epoch 0092] loss=12.4677 cls=0.7542 smmd=0.1936 ct=9.1443 rec=1.1878 | train/val/test=1.000/0.730/0.707 | c=0.999488
[Epoch 0093] loss=12.6058 cls=0.8978 smmd=0.1954 ct=9.1470 rec=1.1828 | train/val/test=1.000/0.730/0.707 | c=0.999488
[Epoch 0094] loss=12.2382 cls=0.5384 smmd=0.1944 ct=9.1461 rec=1.1796 | train/val/test=1.000/0.730/0.707 | c=0.999488
[Epoch 0095] loss=12.6372 cls=0.9337 smmd=0.1945 ct=9.1451 rec=1.1819 | train/val/test=1.000/0.730/0.706 | c=0.999488
[Epoch 0096] loss=12.5051 cls=0.7929 smmd=0.1971 ct=9.1474 rec=1.1838 | train/val/test=1.000/0.730/0.705 | c=0.999488
[Epoch 0097] loss=12.4117 cls=0.7052 smmd=0.1954 ct=9.1443 rec=1.1834 | train/val/test=1.000/0.730/0.705 | c=0.999488
[Epoch 0098] loss=12.6579 cls=0.9525 smmd=0.1959 ct=9.1463 rec=1.1816 | train/val/test=1.000/0.730/0.705 | c=0.999488
[Epoch 0099] loss=12.7324 cls=1.0061 smmd=0.1953 ct=9.1496 rec=1.1907 | train/val/test=1.000/0.730/0.705 | c=0.999488
=== Best @ epoch 35: val=0.7500, test=0.7150 ===
