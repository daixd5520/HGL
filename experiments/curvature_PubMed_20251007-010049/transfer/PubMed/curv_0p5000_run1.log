Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=56.0789 cls=1.0953 smmd=4.0317 ct=7.2535 rec=1.4137 | train/val/test=0.402/0.405/0.386 | c=0.500000
[Epoch 0001] loss=32.3641 cls=1.0591 smmd=1.6731 ct=7.1979 rec=1.4161 | train/val/test=0.538/0.528/0.535 | c=0.500000
[Epoch 0002] loss=23.0746 cls=1.0646 smmd=0.7557 ct=7.1389 rec=1.4140 | train/val/test=0.614/0.611/0.617 | c=0.500000
[Epoch 0003] loss=26.3242 cls=1.0522 smmd=1.0794 ct=7.1488 rec=1.4138 | train/val/test=0.629/0.620/0.630 | c=0.500000
[Epoch 0004] loss=25.4446 cls=1.0170 smmd=0.9983 ct=7.1225 rec=1.4150 | train/val/test=0.607/0.602/0.612 | c=0.500000
[Epoch 0005] loss=24.3685 cls=0.9895 smmd=0.7950 ct=7.6073 rec=1.4176 | train/val/test=0.578/0.574/0.584 | c=0.500000
[Epoch 0006] loss=21.5800 cls=0.9732 smmd=0.5532 ct=7.4258 rec=1.4195 | train/val/test=0.577/0.571/0.581 | c=0.500000
[Epoch 0007] loss=21.4720 cls=0.9468 smmd=0.5544 ct=7.3730 rec=1.4173 | train/val/test=0.581/0.576/0.587 | c=0.500000
[Epoch 0008] loss=22.9889 cls=0.9055 smmd=0.7046 ct=7.3922 rec=1.4113 | train/val/test=0.583/0.583/0.591 | c=0.500000
[Epoch 0009] loss=23.0952 cls=0.8619 smmd=0.7137 ct=7.4124 rec=1.4039 | train/val/test=0.590/0.590/0.597 | c=0.500000
[Epoch 0010] loss=21.5493 cls=0.8220 smmd=0.5615 ct=7.4126 rec=1.3963 | train/val/test=0.617/0.620/0.621 | c=0.500000
[Epoch 0011] loss=19.9090 cls=0.7860 smmd=0.4017 ct=7.4024 rec=1.3884 | train/val/test=0.674/0.672/0.680 | c=0.500000
[Epoch 0012] loss=19.6501 cls=0.7504 smmd=0.3785 ct=7.4001 rec=1.3800 | train/val/test=0.718/0.717/0.723 | c=0.500000
[Epoch 0013] loss=20.1982 cls=0.7202 smmd=0.4339 ct=7.4066 rec=1.3720 | train/val/test=0.736/0.729/0.740 | c=0.500000
[Epoch 0014] loss=20.3035 cls=0.6987 smmd=0.4453 ct=7.4096 rec=1.3649 | train/val/test=0.747/0.742/0.756 | c=0.500000
[Epoch 0015] loss=19.8160 cls=0.6780 smmd=0.3998 ct=7.4001 rec=1.3573 | train/val/test=0.754/0.747/0.760 | c=0.500000
[Epoch 0016] loss=19.3725 cls=0.6578 smmd=0.3604 ct=7.3822 rec=1.3502 | train/val/test=0.754/0.750/0.758 | c=0.500000
[Epoch 0017] loss=19.3138 cls=0.6391 smmd=0.3590 ct=7.3661 rec=1.3449 | train/val/test=0.760/0.758/0.765 | c=0.500000
[Epoch 0018] loss=19.2866 cls=0.6177 smmd=0.3581 ct=7.3635 rec=1.3403 | train/val/test=0.776/0.771/0.778 | c=0.500000
[Epoch 0019] loss=19.2047 cls=0.5940 smmd=0.3498 ct=7.3707 rec=1.3360 | train/val/test=0.790/0.782/0.788 | c=0.500000
[Epoch 0020] loss=19.1850 cls=0.5711 smmd=0.3499 ct=7.3674 rec=1.3319 | train/val/test=0.798/0.793/0.797 | c=0.500000
[Epoch 0021] loss=18.9954 cls=0.5507 smmd=0.3348 ct=7.3539 rec=1.3275 | train/val/test=0.803/0.799/0.803 | c=0.500000
[Epoch 0022] loss=18.6406 cls=0.5335 smmd=0.3022 ct=7.3455 rec=1.3228 | train/val/test=0.806/0.802/0.806 | c=0.500000
[Epoch 0023] loss=18.4403 cls=0.5201 smmd=0.2824 ct=7.3487 rec=1.3181 | train/val/test=0.808/0.803/0.810 | c=0.500000
[Epoch 0024] loss=18.4107 cls=0.5097 smmd=0.2784 ct=7.3576 rec=1.3140 | train/val/test=0.811/0.805/0.811 | c=0.500000
[Epoch 0025] loss=18.3738 cls=0.4998 smmd=0.2750 ct=7.3593 rec=1.3111 | train/val/test=0.815/0.809/0.813 | c=0.500000
[Epoch 0026] loss=18.2313 cls=0.4889 smmd=0.2635 ct=7.3484 rec=1.3094 | train/val/test=0.818/0.813/0.814 | c=0.500000
[Epoch 0027] loss=18.1093 cls=0.4787 smmd=0.2554 ct=7.3309 rec=1.3090 | train/val/test=0.821/0.815/0.818 | c=0.500000
[Epoch 0028] loss=18.1150 cls=0.4712 smmd=0.2587 ct=7.3190 rec=1.3093 | train/val/test=0.820/0.816/0.820 | c=0.500000
[Epoch 0029] loss=18.1286 cls=0.4663 smmd=0.2611 ct=7.3149 rec=1.3097 | train/val/test=0.822/0.818/0.821 | c=0.500000
[Epoch 0030] loss=18.0752 cls=0.4633 smmd=0.2556 ct=7.3160 rec=1.3105 | train/val/test=0.823/0.820/0.824 | c=0.500000
[Epoch 0031] loss=18.0385 cls=0.4610 smmd=0.2514 ct=7.3191 rec=1.3114 | train/val/test=0.824/0.821/0.826 | c=0.500000
[Epoch 0032] loss=18.0602 cls=0.4599 smmd=0.2530 ct=7.3220 rec=1.3119 | train/val/test=0.824/0.821/0.827 | c=0.500000
[Epoch 0033] loss=18.0669 cls=0.4589 smmd=0.2542 ct=7.3197 rec=1.3119 | train/val/test=0.824/0.822/0.827 | c=0.500000
[Epoch 0034] loss=17.9921 cls=0.4582 smmd=0.2486 ct=7.3107 rec=1.3117 | train/val/test=0.823/0.822/0.828 | c=0.500000
[Epoch 0035] loss=17.9565 cls=0.4577 smmd=0.2464 ct=7.3037 rec=1.3117 | train/val/test=0.822/0.822/0.830 | c=0.500000
[Epoch 0036] loss=17.9479 cls=0.4571 smmd=0.2457 ct=7.3031 rec=1.3118 | train/val/test=0.823/0.819/0.829 | c=0.500000
[Epoch 0037] loss=17.9235 cls=0.4567 smmd=0.2434 ct=7.3027 rec=1.3117 | train/val/test=0.824/0.819/0.829 | c=0.500000
[Epoch 0038] loss=17.8342 cls=0.4566 smmd=0.2352 ct=7.2993 rec=1.3113 | train/val/test=0.825/0.818/0.828 | c=0.500000
[Epoch 0039] loss=17.7924 cls=0.4571 smmd=0.2322 ct=7.2932 rec=1.3111 | train/val/test=0.826/0.819/0.828 | c=0.500000
[Epoch 0040] loss=17.7690 cls=0.4575 smmd=0.2313 ct=7.2857 rec=1.3113 | train/val/test=0.825/0.821/0.830 | c=0.500000
[Epoch 0041] loss=17.7336 cls=0.4575 smmd=0.2290 ct=7.2798 rec=1.3114 | train/val/test=0.827/0.822/0.832 | c=0.500000
[Epoch 0042] loss=17.7111 cls=0.4588 smmd=0.2273 ct=7.2765 rec=1.3114 | train/val/test=0.826/0.821/0.832 | c=0.500000
[Epoch 0043] loss=17.7014 cls=0.4604 smmd=0.2258 ct=7.2786 rec=1.3118 | train/val/test=0.827/0.822/0.828 | c=0.500000
[Epoch 0044] loss=17.6901 cls=0.4619 smmd=0.2241 ct=7.2808 rec=1.3130 | train/val/test=0.827/0.821/0.830 | c=0.500000
[Epoch 0045] loss=17.6978 cls=0.4629 smmd=0.2248 ct=7.2806 rec=1.3145 | train/val/test=0.827/0.821/0.831 | c=0.500000
[Epoch 0046] loss=17.7003 cls=0.4641 smmd=0.2255 ct=7.2777 rec=1.3160 | train/val/test=0.827/0.821/0.830 | c=0.500000
[Epoch 0047] loss=17.6896 cls=0.4655 smmd=0.2255 ct=7.2717 rec=1.3171 | train/val/test=0.826/0.822/0.830 | c=0.500000
[Epoch 0048] loss=17.6910 cls=0.4669 smmd=0.2268 ct=7.2653 rec=1.3177 | train/val/test=0.827/0.823/0.832 | c=0.500000
[Epoch 0049] loss=17.6685 cls=0.4680 smmd=0.2252 ct=7.2616 rec=1.3184 | train/val/test=0.827/0.823/0.831 | c=0.500000
[Epoch 0050] loss=17.6427 cls=0.4685 smmd=0.2231 ct=7.2592 rec=1.3190 | train/val/test=0.826/0.822/0.830 | c=0.500000
[Epoch 0051] loss=17.6474 cls=0.4690 smmd=0.2236 ct=7.2584 rec=1.3191 | train/val/test=0.826/0.822/0.829 | c=0.500000
[Epoch 0052] loss=17.6098 cls=0.4690 smmd=0.2198 ct=7.2589 rec=1.3193 | train/val/test=0.826/0.822/0.828 | c=0.500000
[Epoch 0053] loss=17.5879 cls=0.4691 smmd=0.2177 ct=7.2582 rec=1.3193 | train/val/test=0.826/0.822/0.829 | c=0.500000
[Epoch 0054] loss=17.5727 cls=0.4694 smmd=0.2168 ct=7.2552 rec=1.3194 | train/val/test=0.826/0.822/0.828 | c=0.500000
[Epoch 0055] loss=17.5702 cls=0.4698 smmd=0.2175 ct=7.2504 rec=1.3196 | train/val/test=0.826/0.822/0.829 | c=0.500000
[Epoch 0056] loss=17.5574 cls=0.4701 smmd=0.2170 ct=7.2462 rec=1.3198 | train/val/test=0.825/0.822/0.830 | c=0.500000
[Epoch 0057] loss=17.5569 cls=0.4705 smmd=0.2172 ct=7.2446 rec=1.3200 | train/val/test=0.826/0.822/0.830 | c=0.500000
[Epoch 0058] loss=17.5717 cls=0.4708 smmd=0.2187 ct=7.2445 rec=1.3204 | train/val/test=0.825/0.823/0.831 | c=0.500000
[Epoch 0059] loss=17.5663 cls=0.4711 smmd=0.2185 ct=7.2425 rec=1.3206 | train/val/test=0.825/0.823/0.832 | c=0.500000
[Epoch 0060] loss=17.5904 cls=0.4715 smmd=0.2208 ct=7.2431 rec=1.3208 | train/val/test=0.825/0.824/0.830 | c=0.500000
[Epoch 0061] loss=17.5727 cls=0.4711 smmd=0.2194 ct=7.2414 rec=1.3207 | train/val/test=0.826/0.825/0.830 | c=0.500000
[Epoch 0062] loss=17.5658 cls=0.4706 smmd=0.2194 ct=7.2379 rec=1.3204 | train/val/test=0.825/0.823/0.831 | c=0.500000
[Epoch 0063] loss=17.5515 cls=0.4697 smmd=0.2186 ct=7.2353 rec=1.3203 | train/val/test=0.825/0.824/0.831 | c=0.500000
[Epoch 0064] loss=17.5476 cls=0.4690 smmd=0.2181 ct=7.2363 rec=1.3201 | train/val/test=0.825/0.825/0.830 | c=0.500000
[Epoch 0065] loss=17.5218 cls=0.4682 smmd=0.2158 ct=7.2348 rec=1.3197 | train/val/test=0.826/0.824/0.831 | c=0.500000
[Epoch 0066] loss=17.5191 cls=0.4675 smmd=0.2161 ct=7.2323 rec=1.3196 | train/val/test=0.826/0.824/0.832 | c=0.500000
[Epoch 0067] loss=17.5209 cls=0.4674 smmd=0.2168 ct=7.2298 rec=1.3195 | train/val/test=0.826/0.825/0.831 | c=0.500000
[Epoch 0068] loss=17.5105 cls=0.4668 smmd=0.2161 ct=7.2280 rec=1.3195 | train/val/test=0.825/0.825/0.830 | c=0.500000
[Epoch 0069] loss=17.5092 cls=0.4666 smmd=0.2159 ct=7.2286 rec=1.3196 | train/val/test=0.826/0.826/0.831 | c=0.500000
[Epoch 0070] loss=17.5071 cls=0.4667 smmd=0.2155 ct=7.2296 rec=1.3197 | train/val/test=0.827/0.825/0.832 | c=0.500000
[Epoch 0071] loss=17.5049 cls=0.4667 smmd=0.2156 ct=7.2276 rec=1.3200 | train/val/test=0.827/0.825/0.832 | c=0.500000
[Epoch 0072] loss=17.5126 cls=0.4667 smmd=0.2173 ct=7.2232 rec=1.3204 | train/val/test=0.827/0.824/0.832 | c=0.500000
[Epoch 0073] loss=17.5013 cls=0.4669 smmd=0.2158 ct=7.2248 rec=1.3206 | train/val/test=0.827/0.824/0.832 | c=0.500000
[Epoch 0074] loss=17.5056 cls=0.4671 smmd=0.2162 ct=7.2246 rec=1.3205 | train/val/test=0.826/0.825/0.831 | c=0.500000
[Epoch 0075] loss=17.5097 cls=0.4671 smmd=0.2172 ct=7.2219 rec=1.3205 | train/val/test=0.827/0.825/0.832 | c=0.500000
[Epoch 0076] loss=17.4950 cls=0.4672 smmd=0.2158 ct=7.2216 rec=1.3204 | train/val/test=0.827/0.824/0.833 | c=0.500000
[Epoch 0077] loss=17.4869 cls=0.4673 smmd=0.2152 ct=7.2205 rec=1.3204 | train/val/test=0.827/0.825/0.831 | c=0.500000
[Epoch 0078] loss=17.4859 cls=0.4670 smmd=0.2152 ct=7.2199 rec=1.3205 | train/val/test=0.827/0.825/0.831 | c=0.500000
[Epoch 0079] loss=17.4811 cls=0.4672 smmd=0.2150 ct=7.2188 rec=1.3204 | train/val/test=0.827/0.825/0.832 | c=0.500000
[Epoch 0080] loss=17.4670 cls=0.4673 smmd=0.2139 ct=7.2172 rec=1.3205 | train/val/test=0.827/0.823/0.832 | c=0.500000
[Epoch 0081] loss=17.4631 cls=0.4675 smmd=0.2134 ct=7.2177 rec=1.3207 | train/val/test=0.827/0.825/0.833 | c=0.500000
[Epoch 0082] loss=17.4661 cls=0.4682 smmd=0.2138 ct=7.2167 rec=1.3208 | train/val/test=0.827/0.823/0.832 | c=0.500000
[Epoch 0083] loss=17.4773 cls=0.4683 smmd=0.2152 ct=7.2153 rec=1.3210 | train/val/test=0.827/0.824/0.833 | c=0.500000
[Epoch 0084] loss=17.4705 cls=0.4686 smmd=0.2143 ct=7.2163 rec=1.3213 | train/val/test=0.827/0.824/0.833 | c=0.500000
[Epoch 0085] loss=17.4788 cls=0.4692 smmd=0.2154 ct=7.2148 rec=1.3212 | train/val/test=0.828/0.824/0.833 | c=0.500000
[Epoch 0086] loss=17.4646 cls=0.4691 smmd=0.2142 ct=7.2135 rec=1.3216 | train/val/test=0.828/0.824/0.833 | c=0.500000
[Epoch 0087] loss=17.4842 cls=0.4693 smmd=0.2160 ct=7.2145 rec=1.3218 | train/val/test=0.828/0.823/0.834 | c=0.500000
[Epoch 0088] loss=17.4745 cls=0.4694 smmd=0.2155 ct=7.2119 rec=1.3217 | train/val/test=0.828/0.824/0.833 | c=0.500000
[Epoch 0089] loss=17.4485 cls=0.4697 smmd=0.2131 ct=7.2110 rec=1.3215 | train/val/test=0.829/0.823/0.833 | c=0.500000
[Epoch 0090] loss=17.4489 cls=0.4694 smmd=0.2133 ct=7.2103 rec=1.3218 | train/val/test=0.827/0.824/0.833 | c=0.500000
[Epoch 0091] loss=17.4494 cls=0.4693 smmd=0.2132 ct=7.2107 rec=1.3220 | train/val/test=0.828/0.823/0.833 | c=0.500000
[Epoch 0092] loss=17.4436 cls=0.4698 smmd=0.2124 ct=7.2121 rec=1.3218 | train/val/test=0.828/0.822/0.833 | c=0.500000
[Epoch 0093] loss=17.4425 cls=0.4700 smmd=0.2126 ct=7.2103 rec=1.3221 | train/val/test=0.827/0.824/0.833 | c=0.500000
[Epoch 0094] loss=17.4338 cls=0.4700 smmd=0.2124 ct=7.2069 rec=1.3222 | train/val/test=0.828/0.823/0.833 | c=0.500000
[Epoch 0095] loss=17.4453 cls=0.4705 smmd=0.2135 ct=7.2071 rec=1.3221 | train/val/test=0.828/0.823/0.833 | c=0.500000
[Epoch 0096] loss=17.4698 cls=0.4704 smmd=0.2158 ct=7.2076 rec=1.3223 | train/val/test=0.828/0.823/0.833 | c=0.500000
[Epoch 0097] loss=17.4343 cls=0.4703 smmd=0.2125 ct=7.2067 rec=1.3221 | train/val/test=0.828/0.823/0.832 | c=0.500000
[Epoch 0098] loss=17.4366 cls=0.4704 smmd=0.2124 ct=7.2084 rec=1.3219 | train/val/test=0.827/0.823/0.833 | c=0.500000
[Epoch 0099] loss=17.4493 cls=0.4701 smmd=0.2139 ct=7.2073 rec=1.3220 | train/val/test=0.828/0.823/0.831 | c=0.500000
=== Best @ epoch 69: val=0.8260, test=0.8306 ===
