Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=57.8034 cls=1.0934 smmd=4.2052 ct=7.2488 rec=1.4136 | train/val/test=0.400/0.403/0.407 | c=0.500000
[Epoch 0001] loss=33.6305 cls=1.0588 smmd=1.7999 ct=7.1971 rec=1.4155 | train/val/test=0.566/0.567/0.556 | c=0.500000
[Epoch 0002] loss=23.3482 cls=1.0562 smmd=0.7783 ct=7.1651 rec=1.4143 | train/val/test=0.574/0.571/0.554 | c=0.500000
[Epoch 0003] loss=26.3266 cls=1.0458 smmd=1.0796 ct=7.1505 rec=1.4138 | train/val/test=0.569/0.569/0.560 | c=0.500000
[Epoch 0004] loss=25.9744 cls=1.0154 smmd=1.0541 ct=7.1093 rec=1.4144 | train/val/test=0.557/0.555/0.546 | c=0.500000
[Epoch 0005] loss=23.5107 cls=0.9847 smmd=0.8213 ct=7.0485 rec=1.4160 | train/val/test=0.549/0.549/0.536 | c=0.500000
[Epoch 0006] loss=20.6999 cls=0.9618 smmd=0.5500 ct=7.0054 rec=1.4167 | train/val/test=0.542/0.547/0.526 | c=0.500000
[Epoch 0007] loss=20.6851 cls=0.9369 smmd=0.5490 ct=7.0095 rec=1.4146 | train/val/test=0.544/0.541/0.526 | c=0.500000
[Epoch 0008] loss=22.0050 cls=0.9009 smmd=0.6823 ct=7.0136 rec=1.4096 | train/val/test=0.548/0.549/0.530 | c=0.500000
[Epoch 0009] loss=21.9646 cls=0.8551 smmd=0.6846 ct=6.9950 rec=1.4018 | train/val/test=0.617/0.625/0.601 | c=0.500000
[Epoch 0010] loss=20.4325 cls=0.8068 smmd=0.5414 ct=6.9598 rec=1.3918 | train/val/test=0.670/0.680/0.653 | c=0.500000
[Epoch 0011] loss=19.0624 cls=0.7649 smmd=0.4132 ct=6.9287 rec=1.3809 | train/val/test=0.693/0.701/0.682 | c=0.500000
[Epoch 0012] loss=18.8008 cls=0.7350 smmd=0.3920 ct=6.9137 rec=1.3707 | train/val/test=0.709/0.713/0.698 | c=0.500000
[Epoch 0013] loss=19.0602 cls=0.7159 smmd=0.4209 ct=6.9063 rec=1.3619 | train/val/test=0.715/0.718/0.704 | c=0.500000
[Epoch 0014] loss=19.0330 cls=0.7005 smmd=0.4211 ct=6.8976 rec=1.3543 | train/val/test=0.717/0.719/0.706 | c=0.500000
[Epoch 0015] loss=18.6811 cls=0.6829 smmd=0.3884 ct=6.8911 rec=1.3467 | train/val/test=0.718/0.722/0.709 | c=0.500000
[Epoch 0016] loss=18.4654 cls=0.6653 smmd=0.3681 ct=6.8912 rec=1.3393 | train/val/test=0.723/0.724/0.709 | c=0.500000
[Epoch 0017] loss=18.3626 cls=0.6517 smmd=0.3588 ct=6.8912 rec=1.3336 | train/val/test=0.730/0.733/0.719 | c=0.500000
[Epoch 0018] loss=18.1465 cls=0.6360 smmd=0.3394 ct=6.8851 rec=1.3292 | train/val/test=0.744/0.748/0.731 | c=0.500000
[Epoch 0019] loss=19.3713 cls=0.6139 smmd=0.3318 ct=7.5419 rec=1.3253 | train/val/test=0.760/0.764/0.744 | c=0.500000
[Epoch 0020] loss=19.3825 cls=0.5909 smmd=0.3527 ct=7.4494 rec=1.3227 | train/val/test=0.771/0.774/0.755 | c=0.500000
[Epoch 0021] loss=19.3168 cls=0.5731 smmd=0.3590 ct=7.3902 rec=1.3203 | train/val/test=0.781/0.781/0.764 | c=0.500000
[Epoch 0022] loss=18.9776 cls=0.5586 smmd=0.3251 ct=7.3944 rec=1.3169 | train/val/test=0.786/0.786/0.770 | c=0.500000
[Epoch 0023] loss=18.7192 cls=0.5448 smmd=0.2926 ct=7.4318 rec=1.3137 | train/val/test=0.794/0.792/0.775 | c=0.500000
[Epoch 0024] loss=18.6398 cls=0.5314 smmd=0.2813 ct=7.4527 rec=1.3114 | train/val/test=0.799/0.795/0.781 | c=0.500000
[Epoch 0025] loss=18.6026 cls=0.5192 smmd=0.2789 ct=7.4493 rec=1.3098 | train/val/test=0.800/0.800/0.786 | c=0.500000
[Epoch 0026] loss=18.5185 cls=0.5092 smmd=0.2731 ct=7.4394 rec=1.3085 | train/val/test=0.805/0.805/0.790 | c=0.500000
[Epoch 0027] loss=18.3934 cls=0.5002 smmd=0.2630 ct=7.4299 rec=1.3080 | train/val/test=0.809/0.809/0.794 | c=0.500000
[Epoch 0028] loss=18.3187 cls=0.4910 smmd=0.2583 ct=7.4178 rec=1.3087 | train/val/test=0.813/0.813/0.797 | c=0.500000
[Epoch 0029] loss=18.2413 cls=0.4832 smmd=0.2535 ct=7.4046 rec=1.3101 | train/val/test=0.816/0.817/0.800 | c=0.500000
[Epoch 0030] loss=18.2638 cls=0.4780 smmd=0.2568 ct=7.4008 rec=1.3115 | train/val/test=0.817/0.819/0.805 | c=0.500000
[Epoch 0031] loss=18.3056 cls=0.4747 smmd=0.2590 ct=7.4111 rec=1.3124 | train/val/test=0.820/0.822/0.807 | c=0.500000
[Epoch 0032] loss=18.2618 cls=0.4724 smmd=0.2517 ct=7.4261 rec=1.3131 | train/val/test=0.821/0.824/0.809 | c=0.500000
[Epoch 0033] loss=18.1792 cls=0.4704 smmd=0.2427 ct=7.4301 rec=1.3136 | train/val/test=0.822/0.826/0.812 | c=0.500000
[Epoch 0034] loss=18.1828 cls=0.4687 smmd=0.2452 ct=7.4196 rec=1.3138 | train/val/test=0.823/0.825/0.813 | c=0.500000
[Epoch 0035] loss=18.2568 cls=0.4672 smmd=0.2551 ct=7.4079 rec=1.3134 | train/val/test=0.823/0.827/0.812 | c=0.500000
[Epoch 0036] loss=18.2095 cls=0.4659 smmd=0.2518 ct=7.4014 rec=1.3123 | train/val/test=0.823/0.829/0.810 | c=0.500000
[Epoch 0037] loss=18.1190 cls=0.4646 smmd=0.2432 ct=7.3996 rec=1.3109 | train/val/test=0.823/0.828/0.810 | c=0.500000
[Epoch 0038] loss=18.0731 cls=0.4633 smmd=0.2387 ct=7.4000 rec=1.3097 | train/val/test=0.822/0.828/0.809 | c=0.500000
[Epoch 0039] loss=18.0585 cls=0.4622 smmd=0.2372 ct=7.4005 rec=1.3090 | train/val/test=0.822/0.828/0.809 | c=0.500000
[Epoch 0040] loss=18.0216 cls=0.4616 smmd=0.2342 ct=7.3975 rec=1.3081 | train/val/test=0.822/0.828/0.809 | c=0.500000
[Epoch 0041] loss=17.9670 cls=0.4619 smmd=0.2297 ct=7.3927 rec=1.3069 | train/val/test=0.822/0.827/0.809 | c=0.500000
[Epoch 0042] loss=17.9205 cls=0.4625 smmd=0.2253 ct=7.3914 rec=1.3061 | train/val/test=0.823/0.827/0.808 | c=0.500000
[Epoch 0043] loss=17.9264 cls=0.4626 smmd=0.2257 ct=7.3926 rec=1.3060 | train/val/test=0.822/0.827/0.807 | c=0.500000
[Epoch 0044] loss=17.9143 cls=0.4626 smmd=0.2250 ct=7.3901 rec=1.3064 | train/val/test=0.822/0.828/0.808 | c=0.500000
[Epoch 0045] loss=17.9088 cls=0.4627 smmd=0.2251 ct=7.3864 rec=1.3069 | train/val/test=0.823/0.827/0.807 | c=0.500000
[Epoch 0046] loss=17.9074 cls=0.4632 smmd=0.2252 ct=7.3851 rec=1.3074 | train/val/test=0.823/0.827/0.807 | c=0.500000
[Epoch 0047] loss=17.9118 cls=0.4638 smmd=0.2262 ct=7.3820 rec=1.3080 | train/val/test=0.824/0.828/0.807 | c=0.500000
[Epoch 0048] loss=17.9072 cls=0.4639 smmd=0.2269 ct=7.3757 rec=1.3089 | train/val/test=0.824/0.828/0.808 | c=0.500000
[Epoch 0049] loss=17.9019 cls=0.4634 smmd=0.2270 ct=7.3727 rec=1.3099 | train/val/test=0.825/0.831/0.809 | c=0.500000
[Epoch 0050] loss=17.8784 cls=0.4631 smmd=0.2243 ct=7.3742 rec=1.3106 | train/val/test=0.824/0.831/0.810 | c=0.500000
[Epoch 0051] loss=17.8792 cls=0.4630 smmd=0.2240 ct=7.3763 rec=1.3111 | train/val/test=0.825/0.832/0.810 | c=0.500000
[Epoch 0052] loss=17.8335 cls=0.4628 smmd=0.2198 ct=7.3743 rec=1.3112 | train/val/test=0.825/0.831/0.810 | c=0.500000
[Epoch 0053] loss=17.7981 cls=0.4627 smmd=0.2169 ct=7.3710 rec=1.3111 | train/val/test=0.825/0.832/0.811 | c=0.500000
[Epoch 0054] loss=17.8160 cls=0.4627 smmd=0.2192 ct=7.3684 rec=1.3109 | train/val/test=0.826/0.832/0.812 | c=0.500000
[Epoch 0055] loss=17.7980 cls=0.4625 smmd=0.2184 ct=7.3639 rec=1.3108 | train/val/test=0.826/0.833/0.812 | c=0.500000
[Epoch 0056] loss=17.7968 cls=0.4620 smmd=0.2188 ct=7.3611 rec=1.3107 | train/val/test=0.825/0.832/0.813 | c=0.500000
[Epoch 0057] loss=17.7911 cls=0.4617 smmd=0.2183 ct=7.3611 rec=1.3105 | train/val/test=0.824/0.831/0.813 | c=0.500000
[Epoch 0058] loss=17.7725 cls=0.4616 smmd=0.2168 ct=7.3592 rec=1.3102 | train/val/test=0.825/0.831/0.813 | c=0.500000
[Epoch 0059] loss=17.7821 cls=0.4617 smmd=0.2181 ct=7.3576 rec=1.3097 | train/val/test=0.825/0.831/0.812 | c=0.500000
[Epoch 0060] loss=17.7624 cls=0.4617 smmd=0.2162 ct=7.3576 rec=1.3094 | train/val/test=0.826/0.831/0.812 | c=0.500000
[Epoch 0061] loss=17.7820 cls=0.4616 smmd=0.2184 ct=7.3565 rec=1.3091 | train/val/test=0.826/0.830/0.812 | c=0.500000
[Epoch 0062] loss=17.7778 cls=0.4612 smmd=0.2182 ct=7.3553 rec=1.3090 | train/val/test=0.825/0.831/0.812 | c=0.500000
[Epoch 0063] loss=17.7722 cls=0.4606 smmd=0.2182 ct=7.3530 rec=1.3088 | train/val/test=0.825/0.831/0.812 | c=0.500000
[Epoch 0064] loss=17.7708 cls=0.4601 smmd=0.2188 ct=7.3494 rec=1.3087 | train/val/test=0.825/0.831/0.812 | c=0.500000
[Epoch 0065] loss=17.7511 cls=0.4597 smmd=0.2176 ct=7.3457 rec=1.3086 | train/val/test=0.826/0.831/0.812 | c=0.500000
[Epoch 0066] loss=17.7501 cls=0.4589 smmd=0.2179 ct=7.3436 rec=1.3087 | train/val/test=0.827/0.830/0.813 | c=0.500000
[Epoch 0067] loss=17.7506 cls=0.4586 smmd=0.2185 ct=7.3409 rec=1.3087 | train/val/test=0.826/0.829/0.813 | c=0.500000
[Epoch 0068] loss=17.7263 cls=0.4583 smmd=0.2161 ct=7.3408 rec=1.3087 | train/val/test=0.826/0.831/0.813 | c=0.500000
[Epoch 0069] loss=17.7259 cls=0.4580 smmd=0.2160 ct=7.3413 rec=1.3089 | train/val/test=0.827/0.831/0.814 | c=0.500000
[Epoch 0070] loss=17.7072 cls=0.4575 smmd=0.2147 ct=7.3383 rec=1.3092 | train/val/test=0.828/0.831/0.814 | c=0.500000
[Epoch 0071] loss=17.7157 cls=0.4571 smmd=0.2165 ct=7.3338 rec=1.3098 | train/val/test=0.828/0.830/0.815 | c=0.500000
[Epoch 0072] loss=17.6967 cls=0.4567 smmd=0.2155 ct=7.3292 rec=1.3103 | train/val/test=0.828/0.831/0.816 | c=0.500000
[Epoch 0073] loss=17.7011 cls=0.4568 smmd=0.2165 ct=7.3260 rec=1.3106 | train/val/test=0.828/0.831/0.816 | c=0.500000
[Epoch 0074] loss=17.6938 cls=0.4570 smmd=0.2158 ct=7.3260 rec=1.3107 | train/val/test=0.828/0.831/0.815 | c=0.500000
[Epoch 0075] loss=17.7138 cls=0.4571 smmd=0.2175 ct=7.3272 rec=1.3110 | train/val/test=0.828/0.831/0.816 | c=0.500000
[Epoch 0076] loss=17.6879 cls=0.4570 smmd=0.2153 ct=7.3254 rec=1.3112 | train/val/test=0.828/0.831/0.816 | c=0.500000
[Epoch 0077] loss=17.6692 cls=0.4571 smmd=0.2146 ct=7.3197 rec=1.3113 | train/val/test=0.829/0.832/0.816 | c=0.500000
[Epoch 0078] loss=17.6675 cls=0.4571 smmd=0.2154 ct=7.3148 rec=1.3114 | train/val/test=0.828/0.832/0.816 | c=0.500000
[Epoch 0079] loss=17.6810 cls=0.4573 smmd=0.2170 ct=7.3132 rec=1.3114 | train/val/test=0.828/0.832/0.816 | c=0.500000
[Epoch 0080] loss=17.6551 cls=0.4574 smmd=0.2146 ct=7.3125 rec=1.3115 | train/val/test=0.828/0.831/0.816 | c=0.500000
[Epoch 0081] loss=17.6599 cls=0.4577 smmd=0.2153 ct=7.3113 rec=1.3116 | train/val/test=0.828/0.831/0.815 | c=0.500000
[Epoch 0082] loss=17.6366 cls=0.4578 smmd=0.2134 ct=7.3088 rec=1.3117 | train/val/test=0.828/0.831/0.816 | c=0.500000
[Epoch 0083] loss=17.6453 cls=0.4582 smmd=0.2149 ct=7.3054 rec=1.3118 | train/val/test=0.828/0.830/0.816 | c=0.500000
[Epoch 0084] loss=17.6487 cls=0.4585 smmd=0.2159 ct=7.3022 rec=1.3121 | train/val/test=0.828/0.831/0.817 | c=0.500000
[Epoch 0085] loss=17.6346 cls=0.4590 smmd=0.2147 ct=7.3012 rec=1.3122 | train/val/test=0.828/0.831/0.818 | c=0.500000
[Epoch 0086] loss=17.6315 cls=0.4591 smmd=0.2149 ct=7.2984 rec=1.3126 | train/val/test=0.829/0.831/0.818 | c=0.500000
[Epoch 0087] loss=17.6511 cls=0.4593 smmd=0.2172 ct=7.2965 rec=1.3129 | train/val/test=0.829/0.832/0.818 | c=0.500000
[Epoch 0088] loss=17.6393 cls=0.4596 smmd=0.2163 ct=7.2949 rec=1.3130 | train/val/test=0.829/0.831/0.819 | c=0.500000
[Epoch 0089] loss=17.6171 cls=0.4595 smmd=0.2145 ct=7.2928 rec=1.3133 | train/val/test=0.829/0.831/0.819 | c=0.500000
[Epoch 0090] loss=17.6235 cls=0.4596 smmd=0.2156 ct=7.2905 rec=1.3134 | train/val/test=0.830/0.832/0.819 | c=0.500000
[Epoch 0091] loss=17.6111 cls=0.4597 smmd=0.2148 ct=7.2881 rec=1.3136 | train/val/test=0.829/0.832/0.819 | c=0.500000
[Epoch 0092] loss=17.6010 cls=0.4597 smmd=0.2140 ct=7.2870 rec=1.3139 | train/val/test=0.829/0.831/0.818 | c=0.500000
[Epoch 0093] loss=17.6103 cls=0.4601 smmd=0.2151 ct=7.2862 rec=1.3139 | train/val/test=0.829/0.832/0.819 | c=0.500000
[Epoch 0094] loss=17.5947 cls=0.4603 smmd=0.2142 ct=7.2826 rec=1.3141 | train/val/test=0.829/0.832/0.820 | c=0.500000
[Epoch 0095] loss=17.5999 cls=0.4603 smmd=0.2150 ct=7.2814 rec=1.3145 | train/val/test=0.829/0.833/0.819 | c=0.500000
[Epoch 0096] loss=17.5922 cls=0.4607 smmd=0.2140 ct=7.2820 rec=1.3147 | train/val/test=0.829/0.832/0.818 | c=0.500000
[Epoch 0097] loss=17.6153 cls=0.4614 smmd=0.2169 ct=7.2791 rec=1.3148 | train/val/test=0.829/0.832/0.818 | c=0.500000
[Epoch 0098] loss=17.5889 cls=0.4615 smmd=0.2146 ct=7.2774 rec=1.3150 | train/val/test=0.829/0.832/0.819 | c=0.500000
[Epoch 0099] loss=17.5877 cls=0.4615 smmd=0.2143 ct=7.2780 rec=1.3151 | train/val/test=0.829/0.832/0.818 | c=0.500000
=== Best @ epoch 95: val=0.8329, test=0.8190 ===
