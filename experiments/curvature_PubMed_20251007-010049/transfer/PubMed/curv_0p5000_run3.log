Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=56.4566 cls=1.1164 smmd=4.0688 ct=7.2517 rec=1.4139 | train/val/test=0.396/0.392/0.381 | c=0.500000
[Epoch 0001] loss=32.7009 cls=1.0644 smmd=1.7066 ct=7.1976 rec=1.4150 | train/val/test=0.495/0.492/0.485 | c=0.500000
[Epoch 0002] loss=23.2092 cls=1.0762 smmd=0.7694 ct=7.1349 rec=1.4136 | train/val/test=0.567/0.566/0.570 | c=0.500000
[Epoch 0003] loss=26.1751 cls=1.0701 smmd=1.0611 ct=7.1614 rec=1.4134 | train/val/test=0.554/0.547/0.553 | c=0.500000
[Epoch 0004] loss=25.4660 cls=1.0270 smmd=0.9941 ct=7.1522 rec=1.4140 | train/val/test=0.578/0.566/0.576 | c=0.500000
[Epoch 0005] loss=23.3968 cls=0.9962 smmd=0.7941 ct=7.1244 rec=1.4169 | train/val/test=0.566/0.562/0.565 | c=0.500000
[Epoch 0006] loss=20.9508 cls=0.9817 smmd=0.5596 ct=7.0771 rec=1.4190 | train/val/test=0.562/0.557/0.562 | c=0.500000
[Epoch 0007] loss=20.4683 cls=0.9591 smmd=0.5238 ct=7.0211 rec=1.4177 | train/val/test=0.560/0.554/0.560 | c=0.500000
[Epoch 0008] loss=21.7017 cls=0.9218 smmd=0.6583 ct=6.9758 rec=1.4132 | train/val/test=0.558/0.553/0.558 | c=0.500000
[Epoch 0009] loss=23.1325 cls=0.8793 smmd=0.6825 ct=7.5824 rec=1.4069 | train/val/test=0.571/0.564/0.575 | c=0.500000
[Epoch 0010] loss=21.7641 cls=0.8380 smmd=0.5725 ct=7.4600 rec=1.3997 | train/val/test=0.625/0.619/0.626 | c=0.500000
[Epoch 0011] loss=20.2634 cls=0.8001 smmd=0.4413 ct=7.3769 rec=1.3921 | train/val/test=0.677/0.668/0.680 | c=0.500000
[Epoch 0012] loss=19.7545 cls=0.7675 smmd=0.3939 ct=7.3697 rec=1.3847 | train/val/test=0.696/0.686/0.693 | c=0.500000
[Epoch 0013] loss=20.1166 cls=0.7419 smmd=0.4267 ct=7.3946 rec=1.3784 | train/val/test=0.707/0.699/0.702 | c=0.500000
[Epoch 0014] loss=20.3156 cls=0.7196 smmd=0.4450 ct=7.4099 rec=1.3723 | train/val/test=0.716/0.708/0.710 | c=0.500000
[Epoch 0015] loss=20.0266 cls=0.6983 smmd=0.4166 ct=7.4141 rec=1.3660 | train/val/test=0.724/0.717/0.720 | c=0.500000
[Epoch 0016] loss=19.5976 cls=0.6792 smmd=0.3728 ct=7.4252 rec=1.3600 | train/val/test=0.732/0.726/0.728 | c=0.500000
[Epoch 0017] loss=19.3765 cls=0.6623 smmd=0.3496 ct=7.4361 rec=1.3548 | train/val/test=0.742/0.738/0.738 | c=0.500000
[Epoch 0018] loss=19.3390 cls=0.6456 smmd=0.3488 ct=7.4267 rec=1.3500 | train/val/test=0.751/0.754/0.747 | c=0.500000
[Epoch 0019] loss=19.3195 cls=0.6279 smmd=0.3532 ct=7.4001 rec=1.3457 | train/val/test=0.761/0.765/0.761 | c=0.500000
[Epoch 0020] loss=19.3055 cls=0.6095 smmd=0.3574 ct=7.3778 rec=1.3417 | train/val/test=0.772/0.770/0.768 | c=0.500000
[Epoch 0021] loss=19.1730 cls=0.5910 smmd=0.3462 ct=7.3732 rec=1.3375 | train/val/test=0.779/0.780/0.776 | c=0.500000
[Epoch 0022] loss=18.8838 cls=0.5732 smmd=0.3173 ct=7.3792 rec=1.3325 | train/val/test=0.785/0.785/0.780 | c=0.500000
[Epoch 0023] loss=18.5778 cls=0.5581 smmd=0.2864 ct=7.3857 rec=1.3271 | train/val/test=0.789/0.790/0.783 | c=0.500000
[Epoch 0024] loss=18.4757 cls=0.5456 smmd=0.2764 ct=7.3886 rec=1.3225 | train/val/test=0.795/0.794/0.788 | c=0.500000
[Epoch 0025] loss=18.4496 cls=0.5333 smmd=0.2754 ct=7.3848 rec=1.3190 | train/val/test=0.801/0.799/0.791 | c=0.500000
[Epoch 0026] loss=18.3384 cls=0.5211 smmd=0.2675 ct=7.3722 rec=1.3164 | train/val/test=0.805/0.808/0.795 | c=0.500000
[Epoch 0027] loss=18.2178 cls=0.5099 smmd=0.2589 ct=7.3583 rec=1.3146 | train/val/test=0.809/0.812/0.799 | c=0.500000
[Epoch 0028] loss=18.1524 cls=0.5000 smmd=0.2549 ct=7.3483 rec=1.3137 | train/val/test=0.813/0.815/0.803 | c=0.500000
[Epoch 0029] loss=18.1048 cls=0.4909 smmd=0.2520 ct=7.3410 rec=1.3137 | train/val/test=0.819/0.822/0.809 | c=0.500000
[Epoch 0030] loss=18.0715 cls=0.4831 smmd=0.2492 ct=7.3402 rec=1.3145 | train/val/test=0.820/0.825/0.812 | c=0.500000
[Epoch 0031] loss=18.1114 cls=0.4783 smmd=0.2514 ct=7.3501 rec=1.3160 | train/val/test=0.822/0.825/0.816 | c=0.500000
[Epoch 0032] loss=18.1367 cls=0.4757 smmd=0.2518 ct=7.3613 rec=1.3168 | train/val/test=0.822/0.825/0.817 | c=0.500000
[Epoch 0033] loss=18.0759 cls=0.4732 smmd=0.2463 ct=7.3592 rec=1.3162 | train/val/test=0.822/0.827/0.817 | c=0.500000
[Epoch 0034] loss=18.0107 cls=0.4711 smmd=0.2434 ct=7.3417 rec=1.3155 | train/val/test=0.822/0.827/0.817 | c=0.500000
[Epoch 0035] loss=18.0463 cls=0.4697 smmd=0.2511 ct=7.3211 rec=1.3158 | train/val/test=0.822/0.827/0.816 | c=0.500000
[Epoch 0036] loss=18.0605 cls=0.4679 smmd=0.2541 ct=7.3136 rec=1.3163 | train/val/test=0.822/0.827/0.818 | c=0.500000
[Epoch 0037] loss=17.9889 cls=0.4659 smmd=0.2459 ct=7.3193 rec=1.3162 | train/val/test=0.823/0.828/0.820 | c=0.500000
[Epoch 0038] loss=17.9211 cls=0.4639 smmd=0.2376 ct=7.3277 rec=1.3154 | train/val/test=0.825/0.829/0.823 | c=0.500000
[Epoch 0039] loss=17.8790 cls=0.4624 smmd=0.2330 ct=7.3303 rec=1.3145 | train/val/test=0.825/0.828/0.825 | c=0.500000
[Epoch 0040] loss=17.8625 cls=0.4615 smmd=0.2322 ct=7.3263 rec=1.3136 | train/val/test=0.825/0.828/0.824 | c=0.500000
[Epoch 0041] loss=17.8076 cls=0.4607 smmd=0.2286 ct=7.3175 rec=1.3127 | train/val/test=0.825/0.828/0.822 | c=0.500000
[Epoch 0042] loss=17.7592 cls=0.4607 smmd=0.2260 ct=7.3065 rec=1.3122 | train/val/test=0.825/0.827/0.821 | c=0.500000
[Epoch 0043] loss=17.7375 cls=0.4613 smmd=0.2256 ct=7.2974 rec=1.3122 | train/val/test=0.826/0.829/0.823 | c=0.500000
[Epoch 0044] loss=17.7468 cls=0.4615 smmd=0.2269 ct=7.2951 rec=1.3125 | train/val/test=0.826/0.828/0.823 | c=0.500000
[Epoch 0045] loss=17.7329 cls=0.4624 smmd=0.2247 ct=7.2990 rec=1.3129 | train/val/test=0.826/0.829/0.823 | c=0.500000
[Epoch 0046] loss=17.7309 cls=0.4638 smmd=0.2229 ct=7.3069 rec=1.3132 | train/val/test=0.826/0.828/0.822 | c=0.500000
[Epoch 0047] loss=17.7421 cls=0.4652 smmd=0.2233 ct=7.3095 rec=1.3141 | train/val/test=0.826/0.829/0.824 | c=0.500000
[Epoch 0048] loss=17.7369 cls=0.4660 smmd=0.2243 ct=7.3018 rec=1.3154 | train/val/test=0.826/0.830/0.826 | c=0.500000
[Epoch 0049] loss=17.7613 cls=0.4664 smmd=0.2285 ct=7.2922 rec=1.3166 | train/val/test=0.827/0.831/0.825 | c=0.500000
[Epoch 0050] loss=17.7347 cls=0.4668 smmd=0.2270 ct=7.2866 rec=1.3173 | train/val/test=0.828/0.831/0.826 | c=0.500000
[Epoch 0051] loss=17.7079 cls=0.4671 smmd=0.2243 ct=7.2860 rec=1.3179 | train/val/test=0.828/0.832/0.825 | c=0.500000
[Epoch 0052] loss=17.7132 cls=0.4672 smmd=0.2246 ct=7.2874 rec=1.3182 | train/val/test=0.827/0.832/0.825 | c=0.500000
[Epoch 0053] loss=17.6839 cls=0.4676 smmd=0.2216 ct=7.2873 rec=1.3180 | train/val/test=0.827/0.832/0.825 | c=0.500000
[Epoch 0054] loss=17.6610 cls=0.4677 smmd=0.2198 ct=7.2853 rec=1.3179 | train/val/test=0.828/0.833/0.824 | c=0.500000
[Epoch 0055] loss=17.6460 cls=0.4669 smmd=0.2187 ct=7.2832 rec=1.3184 | train/val/test=0.829/0.833/0.826 | c=0.500000
[Epoch 0056] loss=17.6214 cls=0.4664 smmd=0.2167 ct=7.2808 rec=1.3189 | train/val/test=0.828/0.834/0.825 | c=0.500000
[Epoch 0057] loss=17.6203 cls=0.4667 smmd=0.2171 ct=7.2784 rec=1.3188 | train/val/test=0.828/0.833/0.826 | c=0.500000
[Epoch 0058] loss=17.6137 cls=0.4672 smmd=0.2168 ct=7.2764 rec=1.3188 | train/val/test=0.828/0.834/0.825 | c=0.500000
[Epoch 0059] loss=17.6320 cls=0.4673 smmd=0.2190 ct=7.2745 rec=1.3193 | train/val/test=0.828/0.834/0.825 | c=0.500000
[Epoch 0060] loss=17.6452 cls=0.4677 smmd=0.2207 ct=7.2725 rec=1.3194 | train/val/test=0.829/0.833/0.826 | c=0.500000
[Epoch 0061] loss=17.6328 cls=0.4683 smmd=0.2197 ct=7.2712 rec=1.3193 | train/val/test=0.829/0.834/0.824 | c=0.500000
[Epoch 0062] loss=17.6328 cls=0.4683 smmd=0.2199 ct=7.2697 rec=1.3195 | train/val/test=0.828/0.834/0.825 | c=0.500000
[Epoch 0063] loss=17.6274 cls=0.4680 smmd=0.2197 ct=7.2684 rec=1.3197 | train/val/test=0.829/0.833/0.826 | c=0.500000
[Epoch 0064] loss=17.6230 cls=0.4677 smmd=0.2192 ct=7.2687 rec=1.3199 | train/val/test=0.829/0.833/0.826 | c=0.500000
[Epoch 0065] loss=17.6274 cls=0.4674 smmd=0.2197 ct=7.2682 rec=1.3200 | train/val/test=0.829/0.834/0.826 | c=0.500000
[Epoch 0066] loss=17.5952 cls=0.4671 smmd=0.2170 ct=7.2657 rec=1.3199 | train/val/test=0.828/0.833/0.825 | c=0.500000
[Epoch 0067] loss=17.6076 cls=0.4671 smmd=0.2190 ct=7.2623 rec=1.3198 | train/val/test=0.828/0.834/0.825 | c=0.500000
[Epoch 0068] loss=17.5893 cls=0.4668 smmd=0.2176 ct=7.2600 rec=1.3199 | train/val/test=0.828/0.833/0.827 | c=0.500000
[Epoch 0069] loss=17.5905 cls=0.4663 smmd=0.2180 ct=7.2586 rec=1.3202 | train/val/test=0.829/0.833/0.825 | c=0.500000
[Epoch 0070] loss=17.5744 cls=0.4662 smmd=0.2162 ct=7.2593 rec=1.3204 | train/val/test=0.829/0.833/0.825 | c=0.500000
[Epoch 0071] loss=17.5735 cls=0.4665 smmd=0.2164 ct=7.2583 rec=1.3204 | train/val/test=0.829/0.833/0.825 | c=0.500000
[Epoch 0072] loss=17.5673 cls=0.4666 smmd=0.2162 ct=7.2559 rec=1.3207 | train/val/test=0.828/0.834/0.825 | c=0.500000
[Epoch 0073] loss=17.5893 cls=0.4666 smmd=0.2186 ct=7.2547 rec=1.3212 | train/val/test=0.828/0.834/0.825 | c=0.500000
[Epoch 0074] loss=17.5883 cls=0.4669 smmd=0.2190 ct=7.2523 rec=1.3213 | train/val/test=0.829/0.832/0.825 | c=0.500000
[Epoch 0075] loss=17.5851 cls=0.4670 smmd=0.2186 ct=7.2523 rec=1.3214 | train/val/test=0.829/0.832/0.825 | c=0.500000
[Epoch 0076] loss=17.5590 cls=0.4670 smmd=0.2159 ct=7.2526 rec=1.3216 | train/val/test=0.829/0.832/0.825 | c=0.500000
[Epoch 0077] loss=17.5654 cls=0.4672 smmd=0.2170 ct=7.2507 rec=1.3216 | train/val/test=0.829/0.831/0.824 | c=0.500000
[Epoch 0078] loss=17.5534 cls=0.4673 smmd=0.2164 ct=7.2474 rec=1.3218 | train/val/test=0.829/0.832/0.824 | c=0.500000
[Epoch 0079] loss=17.5620 cls=0.4675 smmd=0.2175 ct=7.2462 rec=1.3219 | train/val/test=0.829/0.832/0.825 | c=0.500000
[Epoch 0080] loss=17.5599 cls=0.4677 smmd=0.2171 ct=7.2468 rec=1.3220 | train/val/test=0.830/0.832/0.824 | c=0.500000
[Epoch 0081] loss=17.5549 cls=0.4678 smmd=0.2168 ct=7.2460 rec=1.3223 | train/val/test=0.830/0.833/0.825 | c=0.500000
[Epoch 0082] loss=17.5350 cls=0.4682 smmd=0.2150 ct=7.2450 rec=1.3223 | train/val/test=0.829/0.832/0.824 | c=0.500000
[Epoch 0083] loss=17.5410 cls=0.4686 smmd=0.2158 ct=7.2438 rec=1.3224 | train/val/test=0.829/0.832/0.824 | c=0.500000
[Epoch 0084] loss=17.5390 cls=0.4687 smmd=0.2157 ct=7.2430 rec=1.3228 | train/val/test=0.829/0.831/0.825 | c=0.500000
[Epoch 0085] loss=17.5441 cls=0.4690 smmd=0.2166 ct=7.2412 rec=1.3231 | train/val/test=0.830/0.833/0.824 | c=0.500000
[Epoch 0086] loss=17.5313 cls=0.4695 smmd=0.2157 ct=7.2388 rec=1.3231 | train/val/test=0.830/0.832/0.824 | c=0.500000
[Epoch 0087] loss=17.5282 cls=0.4699 smmd=0.2155 ct=7.2384 rec=1.3231 | train/val/test=0.830/0.831/0.824 | c=0.500000
[Epoch 0088] loss=17.5377 cls=0.4700 smmd=0.2160 ct=7.2405 rec=1.3234 | train/val/test=0.829/0.832/0.825 | c=0.500000
[Epoch 0089] loss=17.5399 cls=0.4700 smmd=0.2162 ct=7.2403 rec=1.3238 | train/val/test=0.830/0.831/0.825 | c=0.500000
[Epoch 0090] loss=17.5173 cls=0.4705 smmd=0.2149 ct=7.2354 rec=1.3237 | train/val/test=0.830/0.831/0.825 | c=0.500000
[Epoch 0091] loss=17.5465 cls=0.4706 smmd=0.2178 ct=7.2357 rec=1.3238 | train/val/test=0.830/0.831/0.825 | c=0.500000
[Epoch 0092] loss=17.5172 cls=0.4708 smmd=0.2148 ct=7.2357 rec=1.3238 | train/val/test=0.830/0.831/0.825 | c=0.500000
[Epoch 0093] loss=17.5224 cls=0.4709 smmd=0.2157 ct=7.2339 rec=1.3239 | train/val/test=0.830/0.832/0.826 | c=0.500000
[Epoch 0094] loss=17.5387 cls=0.4708 smmd=0.2174 ct=7.2335 rec=1.3241 | train/val/test=0.830/0.831/0.826 | c=0.500000
[Epoch 0095] loss=17.5070 cls=0.4711 smmd=0.2142 ct=7.2339 rec=1.3241 | train/val/test=0.830/0.831/0.826 | c=0.500000
[Epoch 0096] loss=17.5032 cls=0.4712 smmd=0.2141 ct=7.2324 rec=1.3242 | train/val/test=0.830/0.831/0.826 | c=0.500000
[Epoch 0097] loss=17.5285 cls=0.4713 smmd=0.2171 ct=7.2298 rec=1.3244 | train/val/test=0.830/0.831/0.825 | c=0.500000
[Epoch 0098] loss=17.5067 cls=0.4716 smmd=0.2149 ct=7.2300 rec=1.3244 | train/val/test=0.830/0.831/0.826 | c=0.500000
[Epoch 0099] loss=17.4972 cls=0.4716 smmd=0.2138 ct=7.2305 rec=1.3246 | train/val/test=0.830/0.831/0.825 | c=0.500000
=== Best @ epoch 62: val=0.8344, test=0.8251 ===
