Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=56.2278 cls=1.0944 smmd=4.0478 ct=7.2477 rec=1.4137 | train/val/test=0.393/0.394/0.390 | c=0.500000
[Epoch 0001] loss=32.5941 cls=1.0632 smmd=1.6995 ct=7.1798 rec=1.4150 | train/val/test=0.417/0.420/0.418 | c=0.500000
[Epoch 0002] loss=23.2973 cls=1.0607 smmd=0.7812 ct=7.1238 rec=1.4140 | train/val/test=0.473/0.468/0.469 | c=0.500000
[Epoch 0003] loss=26.2758 cls=1.0447 smmd=1.0753 ct=7.1468 rec=1.4138 | train/val/test=0.545/0.547/0.539 | c=0.500000
[Epoch 0004] loss=25.5154 cls=1.0069 smmd=1.0031 ct=7.1366 rec=1.4148 | train/val/test=0.578/0.584/0.574 | c=0.500000
[Epoch 0005] loss=23.4271 cls=0.9734 smmd=0.8044 ct=7.0940 rec=1.4171 | train/val/test=0.564/0.581/0.563 | c=0.500000
[Epoch 0006] loss=20.8164 cls=0.9505 smmd=0.5554 ct=7.0388 rec=1.4185 | train/val/test=0.562/0.573/0.561 | c=0.500000
[Epoch 0007] loss=20.3114 cls=0.9241 smmd=0.5163 ct=6.9890 rec=1.4171 | train/val/test=0.565/0.574/0.565 | c=0.500000
[Epoch 0008] loss=21.7999 cls=0.8840 smmd=0.6753 ct=6.9494 rec=1.4121 | train/val/test=0.608/0.611/0.603 | c=0.500000
[Epoch 0009] loss=21.9755 cls=0.8333 smmd=0.7003 ct=6.9269 rec=1.4035 | train/val/test=0.665/0.663/0.657 | c=0.500000
[Epoch 0010] loss=20.4081 cls=0.7842 smmd=0.5489 ct=6.9154 rec=1.3923 | train/val/test=0.686/0.683/0.680 | c=0.500000
[Epoch 0011] loss=18.8454 cls=0.7466 smmd=0.3962 ct=6.9099 rec=1.3808 | train/val/test=0.695/0.690/0.690 | c=0.500000
[Epoch 0012] loss=19.9734 cls=0.7184 smmd=0.3730 ct=7.5995 rec=1.3705 | train/val/test=0.700/0.694/0.693 | c=0.500000
[Epoch 0013] loss=20.3338 cls=0.6947 smmd=0.4300 ct=7.5025 rec=1.3622 | train/val/test=0.708/0.700/0.701 | c=0.500000
[Epoch 0014] loss=20.4421 cls=0.6742 smmd=0.4585 ct=7.4214 rec=1.3552 | train/val/test=0.718/0.712/0.711 | c=0.500000
[Epoch 0015] loss=19.9344 cls=0.6565 smmd=0.4111 ct=7.4106 rec=1.3484 | train/val/test=0.730/0.725/0.719 | c=0.500000
[Epoch 0016] loss=19.5289 cls=0.6423 smmd=0.3649 ct=7.4439 rec=1.3421 | train/val/test=0.736/0.728/0.724 | c=0.500000
[Epoch 0017] loss=19.5390 cls=0.6317 smmd=0.3627 ct=7.4639 rec=1.3373 | train/val/test=0.741/0.736/0.732 | c=0.500000
[Epoch 0018] loss=19.5236 cls=0.6198 smmd=0.3637 ct=7.4546 rec=1.3340 | train/val/test=0.755/0.746/0.747 | c=0.500000
[Epoch 0019] loss=19.3952 cls=0.6015 smmd=0.3544 ct=7.4424 rec=1.3317 | train/val/test=0.778/0.765/0.774 | c=0.500000
[Epoch 0020] loss=19.3803 cls=0.5819 smmd=0.3539 ct=7.4428 rec=1.3303 | train/val/test=0.796/0.784/0.789 | c=0.500000
[Epoch 0021] loss=19.2573 cls=0.5668 smmd=0.3414 ct=7.4475 rec=1.3292 | train/val/test=0.801/0.795/0.793 | c=0.500000
[Epoch 0022] loss=18.9432 cls=0.5517 smmd=0.3124 ct=7.4400 rec=1.3263 | train/val/test=0.800/0.795/0.794 | c=0.500000
[Epoch 0023] loss=18.7163 cls=0.5374 smmd=0.2945 ct=7.4206 rec=1.3224 | train/val/test=0.799/0.794/0.793 | c=0.500000
[Epoch 0024] loss=18.6635 cls=0.5266 smmd=0.2935 ct=7.4028 rec=1.3192 | train/val/test=0.801/0.797/0.795 | c=0.500000
[Epoch 0025] loss=18.6028 cls=0.5173 smmd=0.2891 ct=7.3977 rec=1.3166 | train/val/test=0.805/0.802/0.799 | c=0.500000
[Epoch 0026] loss=18.4311 cls=0.5084 smmd=0.2717 ct=7.4012 rec=1.3144 | train/val/test=0.808/0.804/0.804 | c=0.500000
[Epoch 0027] loss=18.2745 cls=0.5001 smmd=0.2554 ct=7.4071 rec=1.3129 | train/val/test=0.814/0.807/0.812 | c=0.500000
[Epoch 0028] loss=18.2392 cls=0.4922 smmd=0.2518 ct=7.4096 rec=1.3124 | train/val/test=0.815/0.813/0.815 | c=0.500000
[Epoch 0029] loss=18.2434 cls=0.4847 smmd=0.2537 ct=7.4036 rec=1.3130 | train/val/test=0.816/0.817/0.820 | c=0.500000
[Epoch 0030] loss=18.2048 cls=0.4797 smmd=0.2530 ct=7.3888 rec=1.3141 | train/val/test=0.817/0.817/0.819 | c=0.500000
[Epoch 0031] loss=18.1686 cls=0.4769 smmd=0.2527 ct=7.3729 rec=1.3143 | train/val/test=0.818/0.813/0.818 | c=0.500000
[Epoch 0032] loss=18.1746 cls=0.4754 smmd=0.2554 ct=7.3633 rec=1.3135 | train/val/test=0.818/0.814/0.818 | c=0.500000
[Epoch 0033] loss=18.1485 cls=0.4747 smmd=0.2532 ct=7.3615 rec=1.3127 | train/val/test=0.819/0.816/0.820 | c=0.500000
[Epoch 0034] loss=18.1469 cls=0.4733 smmd=0.2519 ct=7.3673 rec=1.3127 | train/val/test=0.820/0.818/0.822 | c=0.500000
[Epoch 0035] loss=18.1376 cls=0.4721 smmd=0.2495 ct=7.3748 rec=1.3134 | train/val/test=0.821/0.823/0.823 | c=0.500000
[Epoch 0036] loss=18.1152 cls=0.4714 smmd=0.2472 ct=7.3751 rec=1.3139 | train/val/test=0.822/0.824/0.822 | c=0.500000
[Epoch 0037] loss=18.0691 cls=0.4710 smmd=0.2446 ct=7.3652 rec=1.3138 | train/val/test=0.823/0.823/0.824 | c=0.500000
[Epoch 0038] loss=18.0404 cls=0.4707 smmd=0.2446 ct=7.3514 rec=1.3133 | train/val/test=0.822/0.823/0.822 | c=0.500000
[Epoch 0039] loss=17.9853 cls=0.4706 smmd=0.2409 ct=7.3424 rec=1.3125 | train/val/test=0.821/0.824/0.821 | c=0.500000
[Epoch 0040] loss=17.9179 cls=0.4706 smmd=0.2347 ct=7.3399 rec=1.3122 | train/val/test=0.822/0.826/0.821 | c=0.500000
[Epoch 0041] loss=17.8946 cls=0.4705 smmd=0.2325 ct=7.3393 rec=1.3124 | train/val/test=0.823/0.826/0.822 | c=0.500000
[Epoch 0042] loss=17.8500 cls=0.4703 smmd=0.2284 ct=7.3374 rec=1.3131 | train/val/test=0.823/0.827/0.822 | c=0.500000
[Epoch 0043] loss=17.8108 cls=0.4705 smmd=0.2249 ct=7.3346 rec=1.3139 | train/val/test=0.824/0.826/0.823 | c=0.500000
[Epoch 0044] loss=17.7887 cls=0.4715 smmd=0.2232 ct=7.3320 rec=1.3145 | train/val/test=0.824/0.824/0.823 | c=0.500000
[Epoch 0045] loss=17.7958 cls=0.4728 smmd=0.2245 ct=7.3282 rec=1.3154 | train/val/test=0.825/0.825/0.823 | c=0.500000
[Epoch 0046] loss=17.7849 cls=0.4734 smmd=0.2245 ct=7.3222 rec=1.3168 | train/val/test=0.825/0.828/0.822 | c=0.500000
[Epoch 0047] loss=17.7909 cls=0.4739 smmd=0.2259 ct=7.3181 rec=1.3184 | train/val/test=0.826/0.830/0.823 | c=0.500000
[Epoch 0048] loss=17.7698 cls=0.4746 smmd=0.2236 ct=7.3185 rec=1.3198 | train/val/test=0.826/0.829/0.823 | c=0.500000
[Epoch 0049] loss=17.7965 cls=0.4755 smmd=0.2257 ct=7.3207 rec=1.3209 | train/val/test=0.826/0.829/0.823 | c=0.500000
[Epoch 0050] loss=17.7992 cls=0.4760 smmd=0.2262 ct=7.3193 rec=1.3218 | train/val/test=0.825/0.829/0.824 | c=0.500000
[Epoch 0051] loss=17.7768 cls=0.4762 smmd=0.2249 ct=7.3144 rec=1.3221 | train/val/test=0.826/0.829/0.825 | c=0.500000
[Epoch 0052] loss=17.7646 cls=0.4762 smmd=0.2249 ct=7.3081 rec=1.3218 | train/val/test=0.826/0.830/0.824 | c=0.500000
[Epoch 0053] loss=17.7485 cls=0.4761 smmd=0.2243 ct=7.3032 rec=1.3213 | train/val/test=0.826/0.828/0.823 | c=0.500000
[Epoch 0054] loss=17.7156 cls=0.4756 smmd=0.2212 ct=7.3026 rec=1.3207 | train/val/test=0.826/0.830/0.822 | c=0.500000
[Epoch 0055] loss=17.7033 cls=0.4746 smmd=0.2200 ct=7.3031 rec=1.3203 | train/val/test=0.826/0.830/0.823 | c=0.500000
[Epoch 0056] loss=17.6916 cls=0.4736 smmd=0.2192 ct=7.3013 rec=1.3201 | train/val/test=0.825/0.829/0.823 | c=0.500000
[Epoch 0057] loss=17.6523 cls=0.4733 smmd=0.2161 ct=7.2975 rec=1.3195 | train/val/test=0.825/0.826/0.822 | c=0.500000
[Epoch 0058] loss=17.6449 cls=0.4736 smmd=0.2162 ct=7.2931 rec=1.3189 | train/val/test=0.825/0.827/0.821 | c=0.500000
[Epoch 0059] loss=17.6474 cls=0.4736 smmd=0.2170 ct=7.2907 rec=1.3187 | train/val/test=0.825/0.830/0.820 | c=0.500000
[Epoch 0060] loss=17.6573 cls=0.4737 smmd=0.2178 ct=7.2916 rec=1.3189 | train/val/test=0.825/0.829/0.819 | c=0.500000
[Epoch 0061] loss=17.6513 cls=0.4738 smmd=0.2172 ct=7.2914 rec=1.3192 | train/val/test=0.825/0.830/0.820 | c=0.500000
[Epoch 0062] loss=17.6829 cls=0.4739 smmd=0.2207 ct=7.2897 rec=1.3195 | train/val/test=0.825/0.829/0.820 | c=0.500000
[Epoch 0063] loss=17.6764 cls=0.4740 smmd=0.2204 ct=7.2878 rec=1.3196 | train/val/test=0.825/0.829/0.820 | c=0.500000
[Epoch 0064] loss=17.6848 cls=0.4738 smmd=0.2219 ct=7.2845 rec=1.3197 | train/val/test=0.825/0.830/0.820 | c=0.500000
[Epoch 0065] loss=17.6660 cls=0.4732 smmd=0.2206 ct=7.2818 rec=1.3196 | train/val/test=0.825/0.829/0.820 | c=0.500000
[Epoch 0066] loss=17.6566 cls=0.4728 smmd=0.2198 ct=7.2813 rec=1.3194 | train/val/test=0.824/0.829/0.820 | c=0.500000
[Epoch 0067] loss=17.6345 cls=0.4721 smmd=0.2178 ct=7.2807 rec=1.3191 | train/val/test=0.825/0.830/0.820 | c=0.500000
[Epoch 0068] loss=17.6261 cls=0.4713 smmd=0.2170 ct=7.2806 rec=1.3189 | train/val/test=0.825/0.830/0.820 | c=0.500000
[Epoch 0069] loss=17.6190 cls=0.4708 smmd=0.2163 ct=7.2806 rec=1.3190 | train/val/test=0.825/0.831/0.821 | c=0.500000
[Epoch 0070] loss=17.6018 cls=0.4706 smmd=0.2152 ct=7.2776 rec=1.3190 | train/val/test=0.825/0.830/0.821 | c=0.500000
[Epoch 0071] loss=17.6113 cls=0.4708 smmd=0.2169 ct=7.2735 rec=1.3191 | train/val/test=0.826/0.833/0.821 | c=0.500000
[Epoch 0072] loss=17.6289 cls=0.4707 smmd=0.2190 ct=7.2719 rec=1.3195 | train/val/test=0.826/0.832/0.823 | c=0.500000
[Epoch 0073] loss=17.6053 cls=0.4709 smmd=0.2163 ct=7.2733 rec=1.3198 | train/val/test=0.825/0.832/0.820 | c=0.500000
[Epoch 0074] loss=17.6105 cls=0.4711 smmd=0.2167 ct=7.2741 rec=1.3201 | train/val/test=0.826/0.832/0.821 | c=0.500000
[Epoch 0075] loss=17.6241 cls=0.4714 smmd=0.2181 ct=7.2737 rec=1.3204 | train/val/test=0.827/0.832/0.822 | c=0.500000
[Epoch 0076] loss=17.5942 cls=0.4719 smmd=0.2153 ct=7.2724 rec=1.3204 | train/val/test=0.826/0.831/0.821 | c=0.500000
[Epoch 0077] loss=17.6204 cls=0.4722 smmd=0.2182 ct=7.2711 rec=1.3205 | train/val/test=0.826/0.832/0.820 | c=0.500000
[Epoch 0078] loss=17.6210 cls=0.4720 smmd=0.2189 ct=7.2680 rec=1.3208 | train/val/test=0.827/0.832/0.821 | c=0.500000
[Epoch 0079] loss=17.6049 cls=0.4721 smmd=0.2177 ct=7.2660 rec=1.3206 | train/val/test=0.825/0.830/0.821 | c=0.500000
[Epoch 0080] loss=17.5869 cls=0.4724 smmd=0.2155 ct=7.2678 rec=1.3202 | train/val/test=0.826/0.831/0.822 | c=0.500000
[Epoch 0081] loss=17.5978 cls=0.4721 smmd=0.2165 ct=7.2682 rec=1.3203 | train/val/test=0.826/0.830/0.821 | c=0.500000
[Epoch 0082] loss=17.5776 cls=0.4720 smmd=0.2148 ct=7.2665 rec=1.3202 | train/val/test=0.826/0.831/0.822 | c=0.500000
[Epoch 0083] loss=17.5724 cls=0.4720 smmd=0.2144 ct=7.2660 rec=1.3201 | train/val/test=0.826/0.830/0.821 | c=0.500000
[Epoch 0084] loss=17.5781 cls=0.4723 smmd=0.2154 ct=7.2641 rec=1.3202 | train/val/test=0.826/0.831/0.822 | c=0.500000
[Epoch 0085] loss=17.5827 cls=0.4725 smmd=0.2163 ct=7.2615 rec=1.3204 | train/val/test=0.827/0.832/0.823 | c=0.500000
[Epoch 0086] loss=17.5826 cls=0.4726 smmd=0.2162 ct=7.2618 rec=1.3206 | train/val/test=0.827/0.831/0.822 | c=0.500000
[Epoch 0087] loss=17.5780 cls=0.4727 smmd=0.2153 ct=7.2639 rec=1.3208 | train/val/test=0.826/0.831/0.822 | c=0.500000
[Epoch 0088] loss=17.5893 cls=0.4730 smmd=0.2173 ct=7.2599 rec=1.3209 | train/val/test=0.826/0.832/0.821 | c=0.500000
[Epoch 0089] loss=17.5877 cls=0.4729 smmd=0.2173 ct=7.2586 rec=1.3212 | train/val/test=0.826/0.832/0.821 | c=0.500000
[Epoch 0090] loss=17.5713 cls=0.4730 smmd=0.2147 ct=7.2635 rec=1.3212 | train/val/test=0.826/0.832/0.822 | c=0.500000
[Epoch 0091] loss=17.5786 cls=0.4730 smmd=0.2161 ct=7.2601 rec=1.3213 | train/val/test=0.826/0.831/0.821 | c=0.500000
[Epoch 0092] loss=17.5593 cls=0.4730 smmd=0.2149 ct=7.2564 rec=1.3213 | train/val/test=0.826/0.831/0.821 | c=0.500000
[Epoch 0093] loss=17.5633 cls=0.4732 smmd=0.2146 ct=7.2603 rec=1.3212 | train/val/test=0.826/0.831/0.822 | c=0.500000
[Epoch 0094] loss=17.5573 cls=0.4730 smmd=0.2145 ct=7.2578 rec=1.3213 | train/val/test=0.826/0.831/0.822 | c=0.500000
[Epoch 0095] loss=17.5474 cls=0.4730 smmd=0.2139 ct=7.2557 rec=1.3214 | train/val/test=0.826/0.831/0.821 | c=0.500000
[Epoch 0096] loss=17.5584 cls=0.4732 smmd=0.2147 ct=7.2570 rec=1.3213 | train/val/test=0.827/0.831/0.822 | c=0.500000
[Epoch 0097] loss=17.5573 cls=0.4734 smmd=0.2150 ct=7.2552 rec=1.3213 | train/val/test=0.826/0.831/0.822 | c=0.500000
[Epoch 0098] loss=17.5668 cls=0.4734 smmd=0.2157 ct=7.2560 rec=1.3214 | train/val/test=0.826/0.832/0.822 | c=0.500000
[Epoch 0099] loss=17.5662 cls=0.4732 smmd=0.2158 ct=7.2556 rec=1.3215 | train/val/test=0.826/0.831/0.823 | c=0.500000
=== Best @ epoch 71: val=0.8326, test=0.8210 ===
