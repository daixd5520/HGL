Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=56.1834 cls=1.0938 smmd=4.0435 ct=7.2473 rec=1.4138 | train/val/test=0.395/0.405/0.406 | c=0.500000
[Epoch 0001] loss=32.1622 cls=1.0624 smmd=1.6570 ct=7.1767 rec=1.4151 | train/val/test=0.395/0.405/0.406 | c=0.500000
[Epoch 0002] loss=23.5258 cls=1.0662 smmd=0.8003 ct=7.1415 rec=1.4138 | train/val/test=0.395/0.405/0.406 | c=0.500000
[Epoch 0003] loss=26.2008 cls=1.0453 smmd=1.0699 ct=7.1359 rec=1.4139 | train/val/test=0.499/0.505/0.494 | c=0.500000
[Epoch 0004] loss=25.3800 cls=1.0096 smmd=0.9939 ct=7.1143 rec=1.4148 | train/val/test=0.568/0.574/0.560 | c=0.500000
[Epoch 0005] loss=23.4700 cls=0.9803 smmd=0.8115 ct=7.0783 rec=1.4163 | train/val/test=0.568/0.576/0.558 | c=0.500000
[Epoch 0006] loss=20.9117 cls=0.9556 smmd=0.5675 ct=7.0255 rec=1.4163 | train/val/test=0.559/0.563/0.555 | c=0.500000
[Epoch 0007] loss=20.3088 cls=0.9246 smmd=0.5162 ct=6.9892 rec=1.4122 | train/val/test=0.555/0.553/0.547 | c=0.500000
[Epoch 0008] loss=22.9774 cls=0.8829 smmd=0.6549 ct=7.6425 rec=1.4041 | train/val/test=0.584/0.587/0.579 | c=0.500000
[Epoch 0009] loss=23.1655 cls=0.8340 smmd=0.7091 ct=7.4806 rec=1.3931 | train/val/test=0.667/0.657/0.650 | c=0.500000
[Epoch 0010] loss=21.9524 cls=0.7938 smmd=0.6123 ct=7.3711 rec=1.3814 | train/val/test=0.687/0.682/0.674 | c=0.500000
[Epoch 0011] loss=20.2315 cls=0.7620 smmd=0.4443 ct=7.3609 rec=1.3708 | train/val/test=0.692/0.688/0.680 | c=0.500000
[Epoch 0012] loss=19.7251 cls=0.7327 smmd=0.3815 ct=7.4312 rec=1.3623 | train/val/test=0.699/0.696/0.688 | c=0.500000
[Epoch 0013] loss=20.2289 cls=0.7070 smmd=0.4203 ct=7.4973 rec=1.3555 | train/val/test=0.708/0.700/0.696 | c=0.500000
[Epoch 0014] loss=20.4508 cls=0.6844 smmd=0.4434 ct=7.5001 rec=1.3488 | train/val/test=0.716/0.711/0.708 | c=0.500000
[Epoch 0015] loss=20.0378 cls=0.6672 smmd=0.4104 ct=7.4644 rec=1.3426 | train/val/test=0.725/0.723/0.719 | c=0.500000
[Epoch 0016] loss=19.5241 cls=0.6512 smmd=0.3653 ct=7.4381 rec=1.3383 | train/val/test=0.738/0.736/0.733 | c=0.500000
[Epoch 0017] loss=19.4270 cls=0.6293 smmd=0.3577 ct=7.4340 rec=1.3357 | train/val/test=0.758/0.760/0.753 | c=0.500000
[Epoch 0018] loss=19.4814 cls=0.6046 smmd=0.3646 ct=7.4330 rec=1.3340 | train/val/test=0.776/0.779/0.772 | c=0.500000
[Epoch 0019] loss=19.3913 cls=0.5822 smmd=0.3588 ct=7.4231 rec=1.3316 | train/val/test=0.787/0.788/0.780 | c=0.500000
[Epoch 0020] loss=19.2756 cls=0.5645 smmd=0.3509 ct=7.4099 rec=1.3285 | train/val/test=0.793/0.793/0.784 | c=0.500000
[Epoch 0021] loss=19.2096 cls=0.5484 smmd=0.3464 ct=7.4043 rec=1.3253 | train/val/test=0.801/0.801/0.791 | c=0.500000
[Epoch 0022] loss=18.9657 cls=0.5314 smmd=0.3211 ct=7.4138 rec=1.3221 | train/val/test=0.807/0.808/0.797 | c=0.500000
[Epoch 0023] loss=18.6022 cls=0.5166 smmd=0.2823 ct=7.4305 rec=1.3191 | train/val/test=0.810/0.812/0.799 | c=0.500000
[Epoch 0024] loss=18.5109 cls=0.5052 smmd=0.2724 ct=7.4380 rec=1.3161 | train/val/test=0.811/0.816/0.802 | c=0.500000
[Epoch 0025] loss=18.5280 cls=0.4960 smmd=0.2775 ct=7.4241 rec=1.3135 | train/val/test=0.814/0.817/0.806 | c=0.500000
[Epoch 0026] loss=18.4155 cls=0.4873 smmd=0.2728 ct=7.3940 rec=1.3117 | train/val/test=0.816/0.820/0.806 | c=0.500000
[Epoch 0027] loss=18.2402 cls=0.4789 smmd=0.2610 ct=7.3679 rec=1.3110 | train/val/test=0.818/0.821/0.804 | c=0.500000
[Epoch 0028] loss=18.1719 cls=0.4731 smmd=0.2558 ct=7.3607 rec=1.3114 | train/val/test=0.820/0.823/0.806 | c=0.500000
[Epoch 0029] loss=18.1857 cls=0.4699 smmd=0.2552 ct=7.3716 rec=1.3122 | train/val/test=0.821/0.825/0.808 | c=0.500000
[Epoch 0030] loss=18.1975 cls=0.4675 smmd=0.2533 ct=7.3875 rec=1.3123 | train/val/test=0.822/0.825/0.809 | c=0.500000
[Epoch 0031] loss=18.1863 cls=0.4652 smmd=0.2507 ct=7.3953 rec=1.3114 | train/val/test=0.821/0.826/0.810 | c=0.500000
[Epoch 0032] loss=18.1707 cls=0.4647 smmd=0.2503 ct=7.3902 rec=1.3105 | train/val/test=0.819/0.825/0.809 | c=0.500000
[Epoch 0033] loss=18.1407 cls=0.4651 smmd=0.2498 ct=7.3776 rec=1.3103 | train/val/test=0.820/0.826/0.811 | c=0.500000
[Epoch 0034] loss=18.1313 cls=0.4639 smmd=0.2511 ct=7.3666 rec=1.3105 | train/val/test=0.825/0.827/0.813 | c=0.500000
[Epoch 0035] loss=18.1442 cls=0.4618 smmd=0.2533 ct=7.3624 rec=1.3113 | train/val/test=0.826/0.827/0.815 | c=0.500000
[Epoch 0036] loss=18.1301 cls=0.4614 smmd=0.2517 ct=7.3629 rec=1.3124 | train/val/test=0.827/0.828/0.816 | c=0.500000
[Epoch 0037] loss=18.0669 cls=0.4611 smmd=0.2454 ct=7.3630 rec=1.3124 | train/val/test=0.827/0.829/0.817 | c=0.500000
[Epoch 0038] loss=18.0347 cls=0.4606 smmd=0.2428 ct=7.3606 rec=1.3113 | train/val/test=0.826/0.827/0.817 | c=0.500000
[Epoch 0039] loss=17.9965 cls=0.4607 smmd=0.2394 ct=7.3585 rec=1.3102 | train/val/test=0.826/0.827/0.817 | c=0.500000
[Epoch 0040] loss=17.9378 cls=0.4615 smmd=0.2341 ct=7.3558 rec=1.3094 | train/val/test=0.827/0.828/0.816 | c=0.500000
[Epoch 0041] loss=17.9090 cls=0.4626 smmd=0.2325 ct=7.3493 rec=1.3091 | train/val/test=0.827/0.827/0.817 | c=0.500000
[Epoch 0042] loss=17.8760 cls=0.4635 smmd=0.2304 ct=7.3428 rec=1.3093 | train/val/test=0.827/0.827/0.817 | c=0.500000
[Epoch 0043] loss=17.8485 cls=0.4637 smmd=0.2284 ct=7.3386 rec=1.3100 | train/val/test=0.827/0.827/0.818 | c=0.500000
[Epoch 0044] loss=17.8248 cls=0.4640 smmd=0.2262 ct=7.3377 rec=1.3112 | train/val/test=0.828/0.828/0.818 | c=0.500000
[Epoch 0045] loss=17.8245 cls=0.4647 smmd=0.2258 ct=7.3391 rec=1.3126 | train/val/test=0.828/0.827/0.818 | c=0.500000
[Epoch 0046] loss=17.8169 cls=0.4659 smmd=0.2250 ct=7.3385 rec=1.3139 | train/val/test=0.828/0.828/0.818 | c=0.500000
[Epoch 0047] loss=17.8327 cls=0.4671 smmd=0.2273 ct=7.3345 rec=1.3152 | train/val/test=0.828/0.828/0.818 | c=0.500000
[Epoch 0048] loss=17.8120 cls=0.4684 smmd=0.2259 ct=7.3304 rec=1.3160 | train/val/test=0.827/0.827/0.817 | c=0.500000
[Epoch 0049] loss=17.8354 cls=0.4697 smmd=0.2286 ct=7.3281 rec=1.3165 | train/val/test=0.827/0.826/0.816 | c=0.500000
[Epoch 0050] loss=17.8037 cls=0.4706 smmd=0.2260 ct=7.3249 rec=1.3167 | train/val/test=0.826/0.827/0.817 | c=0.500000
[Epoch 0051] loss=17.8170 cls=0.4705 smmd=0.2279 ct=7.3221 rec=1.3170 | train/val/test=0.826/0.826/0.818 | c=0.500000
[Epoch 0052] loss=17.8002 cls=0.4702 smmd=0.2269 ct=7.3186 rec=1.3171 | train/val/test=0.827/0.828/0.816 | c=0.500000
[Epoch 0053] loss=17.7614 cls=0.4695 smmd=0.2230 ct=7.3188 rec=1.3172 | train/val/test=0.827/0.829/0.817 | c=0.500000
[Epoch 0054] loss=17.7315 cls=0.4688 smmd=0.2200 ct=7.3195 rec=1.3170 | train/val/test=0.827/0.829/0.817 | c=0.500000
[Epoch 0055] loss=17.7222 cls=0.4683 smmd=0.2199 ct=7.3155 rec=1.3168 | train/val/test=0.827/0.829/0.816 | c=0.500000
[Epoch 0056] loss=17.7274 cls=0.4680 smmd=0.2212 ct=7.3118 rec=1.3165 | train/val/test=0.827/0.828/0.816 | c=0.500000
[Epoch 0057] loss=17.7018 cls=0.4681 smmd=0.2193 ct=7.3086 rec=1.3160 | train/val/test=0.827/0.829/0.817 | c=0.500000
[Epoch 0058] loss=17.7037 cls=0.4679 smmd=0.2199 ct=7.3066 rec=1.3159 | train/val/test=0.827/0.828/0.818 | c=0.500000
[Epoch 0059] loss=17.6881 cls=0.4678 smmd=0.2185 ct=7.3055 rec=1.3159 | train/val/test=0.828/0.829/0.817 | c=0.500000
[Epoch 0060] loss=17.7052 cls=0.4679 smmd=0.2202 ct=7.3056 rec=1.3161 | train/val/test=0.827/0.829/0.816 | c=0.500000
[Epoch 0061] loss=17.7182 cls=0.4675 smmd=0.2215 ct=7.3057 rec=1.3165 | train/val/test=0.828/0.830/0.816 | c=0.500000
[Epoch 0062] loss=17.7052 cls=0.4672 smmd=0.2206 ct=7.3034 rec=1.3169 | train/val/test=0.828/0.830/0.817 | c=0.500000
[Epoch 0063] loss=17.7015 cls=0.4673 smmd=0.2215 ct=7.2972 rec=1.3167 | train/val/test=0.828/0.829/0.817 | c=0.500000
[Epoch 0064] loss=17.7080 cls=0.4670 smmd=0.2226 ct=7.2950 rec=1.3167 | train/val/test=0.827/0.829/0.817 | c=0.500000
[Epoch 0065] loss=17.7007 cls=0.4664 smmd=0.2215 ct=7.2971 rec=1.3169 | train/val/test=0.827/0.829/0.818 | c=0.500000
[Epoch 0066] loss=17.6891 cls=0.4659 smmd=0.2203 ct=7.2976 rec=1.3168 | train/val/test=0.828/0.829/0.819 | c=0.500000
[Epoch 0067] loss=17.6626 cls=0.4656 smmd=0.2184 ct=7.2937 rec=1.3166 | train/val/test=0.828/0.828/0.819 | c=0.500000
[Epoch 0068] loss=17.6576 cls=0.4650 smmd=0.2188 ct=7.2893 rec=1.3166 | train/val/test=0.828/0.830/0.820 | c=0.500000
[Epoch 0069] loss=17.6565 cls=0.4646 smmd=0.2192 ct=7.2870 rec=1.3167 | train/val/test=0.828/0.831/0.820 | c=0.500000
[Epoch 0070] loss=17.6488 cls=0.4643 smmd=0.2190 ct=7.2843 rec=1.3169 | train/val/test=0.828/0.831/0.820 | c=0.500000
[Epoch 0071] loss=17.6334 cls=0.4640 smmd=0.2175 ct=7.2838 rec=1.3171 | train/val/test=0.829/0.832/0.821 | c=0.500000
[Epoch 0072] loss=17.6314 cls=0.4640 smmd=0.2171 ct=7.2848 rec=1.3174 | train/val/test=0.828/0.832/0.820 | c=0.500000
[Epoch 0073] loss=17.6256 cls=0.4643 smmd=0.2168 ct=7.2832 rec=1.3178 | train/val/test=0.827/0.832/0.820 | c=0.500000
[Epoch 0074] loss=17.6311 cls=0.4648 smmd=0.2178 ct=7.2809 rec=1.3181 | train/val/test=0.828/0.833/0.821 | c=0.500000
[Epoch 0075] loss=17.6395 cls=0.4650 smmd=0.2191 ct=7.2782 rec=1.3183 | train/val/test=0.828/0.833/0.821 | c=0.500000
[Epoch 0076] loss=17.6322 cls=0.4653 smmd=0.2187 ct=7.2768 rec=1.3186 | train/val/test=0.828/0.833/0.820 | c=0.500000
[Epoch 0077] loss=17.6303 cls=0.4658 smmd=0.2183 ct=7.2776 rec=1.3188 | train/val/test=0.828/0.832/0.820 | c=0.500000
[Epoch 0078] loss=17.6420 cls=0.4659 smmd=0.2196 ct=7.2770 rec=1.3188 | train/val/test=0.827/0.833/0.821 | c=0.500000
[Epoch 0079] loss=17.6185 cls=0.4658 smmd=0.2180 ct=7.2731 rec=1.3188 | train/val/test=0.828/0.831/0.820 | c=0.500000
[Epoch 0080] loss=17.6127 cls=0.4660 smmd=0.2177 ct=7.2716 rec=1.3187 | train/val/test=0.828/0.831/0.820 | c=0.500000
[Epoch 0081] loss=17.6124 cls=0.4662 smmd=0.2176 ct=7.2718 rec=1.3185 | train/val/test=0.827/0.831/0.821 | c=0.500000
[Epoch 0082] loss=17.5878 cls=0.4660 smmd=0.2156 ct=7.2696 rec=1.3185 | train/val/test=0.828/0.831/0.821 | c=0.500000
[Epoch 0083] loss=17.6000 cls=0.4663 smmd=0.2168 ct=7.2695 rec=1.3186 | train/val/test=0.828/0.832/0.820 | c=0.500000
[Epoch 0084] loss=17.5984 cls=0.4665 smmd=0.2166 ct=7.2696 rec=1.3189 | train/val/test=0.828/0.832/0.820 | c=0.500000
[Epoch 0085] loss=17.5873 cls=0.4668 smmd=0.2163 ct=7.2656 rec=1.3191 | train/val/test=0.828/0.832/0.820 | c=0.500000
[Epoch 0086] loss=17.5935 cls=0.4669 smmd=0.2170 ct=7.2649 rec=1.3195 | train/val/test=0.828/0.833/0.822 | c=0.500000
[Epoch 0087] loss=17.5834 cls=0.4672 smmd=0.2158 ct=7.2662 rec=1.3197 | train/val/test=0.828/0.832/0.820 | c=0.500000
[Epoch 0088] loss=17.6119 cls=0.4676 smmd=0.2190 ct=7.2642 rec=1.3199 | train/val/test=0.829/0.833/0.820 | c=0.500000
[Epoch 0089] loss=17.5999 cls=0.4678 smmd=0.2179 ct=7.2632 rec=1.3201 | train/val/test=0.829/0.833/0.820 | c=0.500000
[Epoch 0090] loss=17.6028 cls=0.4677 smmd=0.2181 ct=7.2639 rec=1.3202 | train/val/test=0.829/0.833/0.819 | c=0.500000
[Epoch 0091] loss=17.5784 cls=0.4677 smmd=0.2160 ct=7.2623 rec=1.3201 | train/val/test=0.829/0.834/0.819 | c=0.500000
[Epoch 0092] loss=17.5823 cls=0.4675 smmd=0.2170 ct=7.2592 rec=1.3201 | train/val/test=0.829/0.833/0.820 | c=0.500000
[Epoch 0093] loss=17.5776 cls=0.4674 smmd=0.2163 ct=7.2603 rec=1.3201 | train/val/test=0.828/0.834/0.819 | c=0.500000
[Epoch 0094] loss=17.5492 cls=0.4676 smmd=0.2135 ct=7.2604 rec=1.3199 | train/val/test=0.829/0.833/0.820 | c=0.500000
[Epoch 0095] loss=17.5731 cls=0.4676 smmd=0.2163 ct=7.2579 rec=1.3200 | train/val/test=0.828/0.833/0.820 | c=0.500000
[Epoch 0096] loss=17.5813 cls=0.4677 smmd=0.2172 ct=7.2578 rec=1.3201 | train/val/test=0.829/0.833/0.820 | c=0.500000
[Epoch 0097] loss=17.5909 cls=0.4678 smmd=0.2182 ct=7.2573 rec=1.3201 | train/val/test=0.828/0.833/0.820 | c=0.500000
[Epoch 0098] loss=17.5867 cls=0.4678 smmd=0.2180 ct=7.2564 rec=1.3202 | train/val/test=0.829/0.833/0.821 | c=0.500000
[Epoch 0099] loss=17.5630 cls=0.4678 smmd=0.2158 ct=7.2556 rec=1.3201 | train/val/test=0.828/0.833/0.820 | c=0.500000
=== Best @ epoch 91: val=0.8336, test=0.8195 ===
