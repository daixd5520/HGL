Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=16.4102 cls=2.0997 smmd=2.2809 ct=9.2493 rec=1.3901 | train/val/test=0.172/0.084/0.102 | c=0.999014
[Epoch 0001] loss=16.2065 cls=1.9904 smmd=2.1908 ct=9.2477 rec=1.3888 | train/val/test=0.207/0.084/0.113 | c=0.999014
[Epoch 0002] loss=15.9461 cls=1.8698 smmd=2.0511 ct=9.2423 rec=1.3915 | train/val/test=0.448/0.326/0.342 | c=0.999014
[Epoch 0003] loss=15.8433 cls=1.9584 smmd=1.8683 ct=9.2367 rec=1.3899 | train/val/test=0.586/0.324/0.320 | c=0.999014
[Epoch 0004] loss=15.6279 cls=1.9802 smmd=1.6451 ct=9.2263 rec=1.3881 | train/val/test=0.828/0.384/0.389 | c=0.999014
[Epoch 0005] loss=14.8031 cls=1.4422 smmd=1.3797 ct=9.2113 rec=1.3849 | train/val/test=0.931/0.344/0.367 | c=0.999014
[Epoch 0006] loss=14.7433 cls=1.7127 smmd=1.0777 ct=9.1884 rec=1.3823 | train/val/test=0.897/0.318/0.338 | c=0.999014
[Epoch 0007] loss=14.1130 cls=1.4386 smmd=0.7720 ct=9.1533 rec=1.3745 | train/val/test=0.897/0.314/0.361 | c=0.999014
[Epoch 0008] loss=13.7253 cls=1.3902 smmd=0.5044 ct=9.1022 rec=1.3642 | train/val/test=0.931/0.502/0.545 | c=0.999014
[Epoch 0009] loss=13.2159 cls=1.1924 smmd=0.3033 ct=9.0414 rec=1.3394 | train/val/test=0.931/0.562/0.582 | c=0.999014
[Epoch 0010] loss=13.0298 cls=1.1882 smmd=0.2295 ct=8.9845 rec=1.3137 | train/val/test=0.966/0.598/0.591 | c=0.999014
[Epoch 0011] loss=12.9469 cls=1.1683 smmd=0.2608 ct=8.9487 rec=1.2845 | train/val/test=0.966/0.588/0.589 | c=0.999014
[Epoch 0012] loss=13.5035 cls=1.0660 smmd=0.3576 ct=9.5494 rec=1.2652 | train/val/test=0.966/0.592/0.583 | c=0.999014
[Epoch 0013] loss=13.3671 cls=0.9796 smmd=0.4697 ct=9.4282 rec=1.2448 | train/val/test=0.966/0.566/0.564 | c=0.999014
[Epoch 0014] loss=13.4964 cls=1.1541 smmd=0.5809 ct=9.2655 rec=1.2480 | train/val/test=0.966/0.602/0.618 | c=0.999014
[Epoch 0015] loss=12.8876 cls=0.5923 smmd=0.6800 ct=9.1577 rec=1.2288 | train/val/test=0.966/0.614/0.609 | c=0.999014
[Epoch 0016] loss=13.0740 cls=0.7638 smmd=0.7598 ct=9.0782 rec=1.2361 | train/val/test=1.000/0.612/0.603 | c=0.999014
[Epoch 0017] loss=13.6972 cls=1.3776 smmd=0.7994 ct=9.0370 rec=1.2416 | train/val/test=0.966/0.658/0.664 | c=0.999014
[Epoch 0018] loss=13.2689 cls=1.0208 smmd=0.7950 ct=9.0113 rec=1.2209 | train/val/test=0.966/0.654/0.666 | c=0.999014
[Epoch 0019] loss=13.1620 cls=0.9695 smmd=0.7532 ct=9.0059 rec=1.2167 | train/val/test=0.966/0.624/0.638 | c=0.999014
[Epoch 0020] loss=13.0720 cls=0.9082 smmd=0.6932 ct=9.0164 rec=1.2271 | train/val/test=1.000/0.584/0.591 | c=0.999014
[Epoch 0021] loss=12.5815 cls=0.4974 smmd=0.6146 ct=9.0210 rec=1.2243 | train/val/test=1.000/0.562/0.556 | c=0.999014
[Epoch 0022] loss=12.7286 cls=0.6984 smmd=0.5398 ct=9.0390 rec=1.2257 | train/val/test=1.000/0.602/0.596 | c=0.999014
[Epoch 0023] loss=12.9856 cls=1.0448 smmd=0.4595 ct=9.0539 rec=1.2137 | train/val/test=1.000/0.624/0.629 | c=0.999014
[Epoch 0024] loss=12.9512 cls=1.0743 smmd=0.3882 ct=9.0852 rec=1.2018 | train/val/test=1.000/0.632/0.651 | c=0.999014
[Epoch 0025] loss=12.9912 cls=1.1113 smmd=0.3508 ct=9.1196 rec=1.2048 | train/val/test=1.000/0.662/0.681 | c=0.999014
[Epoch 0026] loss=13.4884 cls=1.5675 smmd=0.3267 ct=9.1659 rec=1.2141 | train/val/test=1.000/0.658/0.686 | c=0.999014
[Epoch 0027] loss=12.7801 cls=0.8056 smmd=0.3105 ct=9.2109 rec=1.2266 | train/val/test=1.000/0.660/0.689 | c=0.999014
[Epoch 0028] loss=12.9392 cls=0.9833 smmd=0.2950 ct=9.2056 rec=1.2277 | train/val/test=1.000/0.662/0.696 | c=0.999014
[Epoch 0029] loss=13.3441 cls=1.4245 smmd=0.2811 ct=9.1883 rec=1.2251 | train/val/test=1.000/0.666/0.683 | c=0.999014
[Epoch 0030] loss=12.8503 cls=0.9543 smmd=0.2775 ct=9.1745 rec=1.2220 | train/val/test=1.000/0.644/0.636 | c=0.999014
[Epoch 0031] loss=13.1677 cls=1.2522 smmd=0.2866 ct=9.1713 rec=1.2288 | train/val/test=0.966/0.620/0.619 | c=0.999014
[Epoch 0032] loss=12.4990 cls=0.5797 smmd=0.2839 ct=9.1744 rec=1.2305 | train/val/test=0.966/0.626/0.624 | c=0.999014
[Epoch 0033] loss=12.5659 cls=0.6569 smmd=0.2746 ct=9.1618 rec=1.2363 | train/val/test=0.966/0.638/0.633 | c=0.999014
[Epoch 0034] loss=13.2021 cls=1.3074 smmd=0.2635 ct=9.1548 rec=1.2382 | train/val/test=1.000/0.656/0.653 | c=0.999014
[Epoch 0035] loss=12.6162 cls=0.7647 smmd=0.2421 ct=9.1476 rec=1.2309 | train/val/test=1.000/0.670/0.680 | c=0.999014
[Epoch 0036] loss=12.6570 cls=0.8088 smmd=0.2251 ct=9.1522 rec=1.2354 | train/val/test=1.000/0.674/0.689 | c=0.999014
[Epoch 0037] loss=12.6452 cls=0.8067 smmd=0.2141 ct=9.1588 rec=1.2327 | train/val/test=1.000/0.672/0.698 | c=0.999014
[Epoch 0038] loss=12.9759 cls=1.1364 smmd=0.2165 ct=9.1596 rec=1.2317 | train/val/test=1.000/0.672/0.706 | c=0.999014
[Epoch 0039] loss=12.4934 cls=0.6644 smmd=0.2142 ct=9.1570 rec=1.2289 | train/val/test=1.000/0.676/0.705 | c=0.999014
[Epoch 0040] loss=12.6563 cls=0.8338 smmd=0.2215 ct=9.1513 rec=1.2249 | train/val/test=1.000/0.674/0.703 | c=0.999014
[Epoch 0041] loss=12.9772 cls=1.1590 smmd=0.2231 ct=9.1435 rec=1.2258 | train/val/test=1.000/0.662/0.710 | c=0.999014
[Epoch 0042] loss=13.1216 cls=1.3091 smmd=0.2320 ct=9.1364 rec=1.2221 | train/val/test=1.000/0.674/0.703 | c=0.999014
[Epoch 0043] loss=12.5068 cls=0.7126 smmd=0.2296 ct=9.1395 rec=1.2126 | train/val/test=1.000/0.674/0.698 | c=0.999014
[Epoch 0044] loss=12.4729 cls=0.6927 smmd=0.2247 ct=9.1349 rec=1.2103 | train/val/test=1.000/0.672/0.697 | c=0.999014
[Epoch 0045] loss=12.4880 cls=0.7276 smmd=0.2218 ct=9.1278 rec=1.2054 | train/val/test=1.000/0.670/0.701 | c=0.999014
[Epoch 0046] loss=12.5067 cls=0.7639 smmd=0.2143 ct=9.1248 rec=1.2018 | train/val/test=1.000/0.672/0.697 | c=0.999014
[Epoch 0047] loss=12.5128 cls=0.7856 smmd=0.2067 ct=9.1228 rec=1.1989 | train/val/test=1.000/0.668/0.691 | c=0.999014
[Epoch 0048] loss=12.8666 cls=1.1386 smmd=0.1972 ct=9.1304 rec=1.2002 | train/val/test=1.000/0.678/0.695 | c=0.999014
[Epoch 0049] loss=12.2337 cls=0.5182 smmd=0.1876 ct=9.1316 rec=1.1982 | train/val/test=1.000/0.684/0.698 | c=0.999014
[Epoch 0050] loss=12.2181 cls=0.5129 smmd=0.1779 ct=9.1395 rec=1.1939 | train/val/test=1.000/0.674/0.696 | c=0.999014
[Epoch 0051] loss=12.4076 cls=0.7087 smmd=0.1775 ct=9.1404 rec=1.1905 | train/val/test=1.000/0.686/0.704 | c=0.999014
[Epoch 0052] loss=12.2014 cls=0.5054 smmd=0.1749 ct=9.1397 rec=1.1906 | train/val/test=1.000/0.692/0.708 | c=0.999014
[Epoch 0053] loss=12.1027 cls=0.4174 smmd=0.1751 ct=9.1364 rec=1.1869 | train/val/test=1.000/0.688/0.706 | c=0.999014
[Epoch 0054] loss=12.4672 cls=0.7842 smmd=0.1736 ct=9.1405 rec=1.1845 | train/val/test=1.000/0.686/0.705 | c=0.999014
[Epoch 0055] loss=12.3857 cls=0.7050 smmd=0.1747 ct=9.1352 rec=1.1854 | train/val/test=1.000/0.682/0.706 | c=0.999014
[Epoch 0056] loss=12.2828 cls=0.6069 smmd=0.1775 ct=9.1329 rec=1.1828 | train/val/test=1.000/0.680/0.707 | c=0.999014
[Epoch 0057] loss=12.9115 cls=1.2209 smmd=0.1758 ct=9.1288 rec=1.1930 | train/val/test=1.000/0.682/0.708 | c=0.999014
[Epoch 0058] loss=12.3425 cls=0.6657 smmd=0.1808 ct=9.1289 rec=1.1835 | train/val/test=1.000/0.684/0.705 | c=0.999014
[Epoch 0059] loss=12.6417 cls=0.9716 smmd=0.1762 ct=9.1299 rec=1.1820 | train/val/test=1.000/0.682/0.703 | c=0.999014
[Epoch 0060] loss=12.5441 cls=0.8821 smmd=0.1742 ct=9.1247 rec=1.1816 | train/val/test=1.000/0.680/0.696 | c=0.999014
[Epoch 0061] loss=12.4665 cls=0.8044 smmd=0.1726 ct=9.1247 rec=1.1824 | train/val/test=1.000/0.676/0.693 | c=0.999014
[Epoch 0062] loss=12.2401 cls=0.5717 smmd=0.1755 ct=9.1330 rec=1.1799 | train/val/test=1.000/0.668/0.687 | c=0.999014
[Epoch 0063] loss=12.6902 cls=1.0228 smmd=0.1744 ct=9.1310 rec=1.1810 | train/val/test=1.000/0.666/0.685 | c=0.999014
[Epoch 0064] loss=12.5690 cls=0.8966 smmd=0.1742 ct=9.1352 rec=1.1815 | train/val/test=1.000/0.660/0.684 | c=0.999014
[Epoch 0065] loss=12.3931 cls=0.7203 smmd=0.1706 ct=9.1326 rec=1.1848 | train/val/test=1.000/0.664/0.684 | c=0.999014
[Epoch 0066] loss=12.3022 cls=0.6359 smmd=0.1687 ct=9.1339 rec=1.1819 | train/val/test=1.000/0.670/0.690 | c=0.999014
[Epoch 0067] loss=12.3535 cls=0.6895 smmd=0.1672 ct=9.1320 rec=1.1824 | train/val/test=1.000/0.672/0.695 | c=0.999014
[Epoch 0068] loss=12.6690 cls=1.0094 smmd=0.1651 ct=9.1268 rec=1.1838 | train/val/test=1.000/0.676/0.695 | c=0.999014
[Epoch 0069] loss=12.3445 cls=0.6863 smmd=0.1634 ct=9.1271 rec=1.1839 | train/val/test=1.000/0.674/0.700 | c=0.999014
[Epoch 0070] loss=12.9753 cls=1.3113 smmd=0.1636 ct=9.1271 rec=1.1867 | train/val/test=1.000/0.678/0.704 | c=0.999014
[Epoch 0071] loss=12.2589 cls=0.5975 smmd=0.1627 ct=9.1289 rec=1.1849 | train/val/test=1.000/0.676/0.704 | c=0.999014
[Epoch 0072] loss=12.9332 cls=1.2697 smmd=0.1629 ct=9.1272 rec=1.1867 | train/val/test=1.000/0.674/0.704 | c=0.999014
[Epoch 0073] loss=12.1137 cls=0.4504 smmd=0.1590 ct=9.1377 rec=1.1833 | train/val/test=1.000/0.678/0.706 | c=0.999014
[Epoch 0074] loss=12.7362 cls=1.0707 smmd=0.1572 ct=9.1396 rec=1.1843 | train/val/test=1.000/0.674/0.702 | c=0.999014
[Epoch 0075] loss=12.9311 cls=1.2659 smmd=0.1554 ct=9.1347 rec=1.1876 | train/val/test=1.000/0.668/0.699 | c=0.999014
[Epoch 0076] loss=13.0361 cls=1.3656 smmd=0.1540 ct=9.1411 rec=1.1877 | train/val/test=1.000/0.670/0.695 | c=0.999014
[Epoch 0077] loss=12.4493 cls=0.7794 smmd=0.1561 ct=9.1398 rec=1.1870 | train/val/test=1.000/0.668/0.693 | c=0.999014
[Epoch 0078] loss=12.5831 cls=0.9050 smmd=0.1536 ct=9.1390 rec=1.1927 | train/val/test=1.000/0.668/0.689 | c=0.999014
[Epoch 0079] loss=12.7469 cls=1.0763 smmd=0.1551 ct=9.1347 rec=1.1904 | train/val/test=1.000/0.662/0.692 | c=0.999014
[Epoch 0080] loss=12.3989 cls=0.7351 smmd=0.1551 ct=9.1316 rec=1.1886 | train/val/test=1.000/0.664/0.691 | c=0.999014
[Epoch 0081] loss=12.2656 cls=0.6002 smmd=0.1556 ct=9.1305 rec=1.1897 | train/val/test=1.000/0.662/0.690 | c=0.999014
[Epoch 0082] loss=12.2815 cls=0.6133 smmd=0.1587 ct=9.1255 rec=1.1920 | train/val/test=1.000/0.666/0.687 | c=0.999014
[Epoch 0083] loss=12.1900 cls=0.5253 smmd=0.1597 ct=9.1283 rec=1.1883 | train/val/test=1.000/0.666/0.687 | c=0.999014
[Epoch 0084] loss=12.2638 cls=0.5970 smmd=0.1584 ct=9.1266 rec=1.1909 | train/val/test=1.000/0.666/0.688 | c=0.999014
[Epoch 0085] loss=12.3765 cls=0.7169 smmd=0.1561 ct=9.1220 rec=1.1908 | train/val/test=1.000/0.668/0.689 | c=0.999014
[Epoch 0086] loss=12.3041 cls=0.6434 smmd=0.1581 ct=9.1195 rec=1.1916 | train/val/test=1.000/0.670/0.691 | c=0.999014
[Epoch 0087] loss=12.3368 cls=0.6725 smmd=0.1576 ct=9.1218 rec=1.1924 | train/val/test=1.000/0.674/0.693 | c=0.999014
[Epoch 0088] loss=12.4986 cls=0.8305 smmd=0.1593 ct=9.1302 rec=1.1893 | train/val/test=1.000/0.680/0.693 | c=0.999014
[Epoch 0089] loss=12.2318 cls=0.5628 smmd=0.1591 ct=9.1299 rec=1.1900 | train/val/test=1.000/0.682/0.694 | c=0.999014
[Epoch 0090] loss=12.4533 cls=0.7917 smmd=0.1575 ct=9.1228 rec=1.1907 | train/val/test=1.000/0.682/0.695 | c=0.999014
[Epoch 0091] loss=12.6525 cls=0.9934 smmd=0.1565 ct=9.1222 rec=1.1902 | train/val/test=1.000/0.682/0.695 | c=0.999014
[Epoch 0092] loss=12.4274 cls=0.7738 smmd=0.1546 ct=9.1228 rec=1.1881 | train/val/test=1.000/0.682/0.696 | c=0.999014
[Epoch 0093] loss=12.1058 cls=0.4477 smmd=0.1573 ct=9.1206 rec=1.1901 | train/val/test=1.000/0.682/0.696 | c=0.999014
[Epoch 0094] loss=12.6096 cls=0.9478 smmd=0.1573 ct=9.1225 rec=1.1910 | train/val/test=1.000/0.680/0.697 | c=0.999014
[Epoch 0095] loss=12.6106 cls=0.9515 smmd=0.1589 ct=9.1231 rec=1.1885 | train/val/test=1.000/0.680/0.697 | c=0.999014
[Epoch 0096] loss=12.3024 cls=0.6424 smmd=0.1579 ct=9.1219 rec=1.1901 | train/val/test=1.000/0.680/0.697 | c=0.999014
[Epoch 0097] loss=12.3011 cls=0.6409 smmd=0.1569 ct=9.1246 rec=1.1893 | train/val/test=1.000/0.680/0.697 | c=0.999014
[Epoch 0098] loss=12.3247 cls=0.6675 smmd=0.1570 ct=9.1222 rec=1.1890 | train/val/test=1.000/0.680/0.697 | c=0.999014
[Epoch 0099] loss=12.1223 cls=0.4627 smmd=0.1562 ct=9.1253 rec=1.1890 | train/val/test=1.000/0.680/0.697 | c=0.999014
=== Best @ epoch 52: val=0.6920, test=0.7080 ===
