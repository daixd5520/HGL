Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=16.3578 cls=2.0362 smmd=2.3056 ct=9.2366 rec=1.3897 | train/val/test=0.276/0.164/0.186 | c=0.999014
[Epoch 0001] loss=16.3623 cls=2.1421 smmd=2.2107 ct=9.2327 rec=1.3884 | train/val/test=0.172/0.080/0.099 | c=0.999014
[Epoch 0002] loss=15.8909 cls=1.8325 smmd=2.0495 ct=9.2268 rec=1.3911 | train/val/test=0.241/0.102/0.121 | c=0.999014
[Epoch 0003] loss=15.7975 cls=1.9180 smmd=1.8846 ct=9.2145 rec=1.3902 | train/val/test=0.552/0.278/0.327 | c=0.999014
[Epoch 0004] loss=15.5048 cls=1.8716 smmd=1.6558 ct=9.2023 rec=1.3876 | train/val/test=0.759/0.450/0.448 | c=0.999014
[Epoch 0005] loss=14.9435 cls=1.6161 smmd=1.3852 ct=9.1781 rec=1.3820 | train/val/test=0.862/0.484/0.481 | c=0.999014
[Epoch 0006] loss=14.4809 cls=1.4924 smmd=1.0912 ct=9.1456 rec=1.3759 | train/val/test=0.897/0.500/0.497 | c=0.999014
[Epoch 0007] loss=14.1058 cls=1.4786 smmd=0.7976 ct=9.1037 rec=1.3630 | train/val/test=0.931/0.488/0.485 | c=0.999014
[Epoch 0008] loss=13.8208 cls=1.5521 smmd=0.5345 ct=9.0486 rec=1.3428 | train/val/test=0.931/0.472/0.487 | c=0.999014
[Epoch 0009] loss=13.2927 cls=1.3057 smmd=0.3503 ct=8.9943 rec=1.3212 | train/val/test=0.966/0.560/0.572 | c=0.999014
[Epoch 0010] loss=12.8965 cls=1.0759 smmd=0.2637 ct=8.9601 rec=1.2984 | train/val/test=0.966/0.580/0.571 | c=0.999014
[Epoch 0011] loss=12.7454 cls=0.9998 smmd=0.2754 ct=8.9144 rec=1.2779 | train/val/test=1.000/0.562/0.561 | c=0.999014
[Epoch 0012] loss=12.5261 cls=0.8065 smmd=0.3544 ct=8.8620 rec=1.2516 | train/val/test=0.966/0.590/0.571 | c=0.999014
[Epoch 0013] loss=12.7939 cls=1.0169 smmd=0.4725 ct=8.8359 rec=1.2343 | train/val/test=0.966/0.582/0.578 | c=0.999014
[Epoch 0014] loss=12.8488 cls=0.9979 smmd=0.5769 ct=8.8272 rec=1.2234 | train/val/test=0.966/0.622/0.604 | c=0.999014
[Epoch 0015] loss=12.9596 cls=1.1114 smmd=0.6347 ct=8.8005 rec=1.2065 | train/val/test=0.966/0.660/0.654 | c=0.999014
[Epoch 0016] loss=12.9836 cls=1.1239 smmd=0.6691 ct=8.7962 rec=1.1972 | train/val/test=0.966/0.656/0.673 | c=0.999014
[Epoch 0017] loss=12.6370 cls=0.7098 smmd=0.6719 ct=8.8303 rec=1.2125 | train/val/test=0.966/0.628/0.630 | c=0.999014
[Epoch 0018] loss=12.7810 cls=0.9247 smmd=0.6176 ct=8.8348 rec=1.2020 | train/val/test=1.000/0.618/0.625 | c=0.999014
[Epoch 0019] loss=13.1013 cls=1.3686 smmd=0.5135 ct=8.8199 rec=1.1996 | train/val/test=1.000/0.578/0.583 | c=0.999014
[Epoch 0020] loss=12.4641 cls=0.8257 smmd=0.4109 ct=8.8268 rec=1.2003 | train/val/test=0.966/0.522/0.552 | c=0.999014
[Epoch 0021] loss=12.8898 cls=1.2824 smmd=0.3226 ct=8.8443 rec=1.2202 | train/val/test=0.966/0.590/0.616 | c=0.999014
[Epoch 0022] loss=12.1026 cls=0.6291 smmd=0.2458 ct=8.8293 rec=1.1992 | train/val/test=0.966/0.658/0.659 | c=0.999014
[Epoch 0023] loss=12.6905 cls=1.2859 smmd=0.1946 ct=8.8142 rec=1.1979 | train/val/test=0.966/0.682/0.686 | c=0.999014
[Epoch 0024] loss=12.7774 cls=1.3796 smmd=0.1862 ct=8.8088 rec=1.2014 | train/val/test=0.966/0.686/0.701 | c=0.999014
[Epoch 0025] loss=12.0251 cls=0.6393 smmd=0.1845 ct=8.7998 rec=1.2007 | train/val/test=1.000/0.684/0.696 | c=0.999014
[Epoch 0026] loss=12.4052 cls=1.0152 smmd=0.1984 ct=8.7951 rec=1.1982 | train/val/test=1.000/0.688/0.692 | c=0.999014
[Epoch 0027] loss=13.1255 cls=1.0251 smmd=0.2108 ct=9.4826 rec=1.2035 | train/val/test=1.000/0.666/0.677 | c=0.999014
[Epoch 0028] loss=13.0085 cls=0.9364 smmd=0.2229 ct=9.4375 rec=1.2059 | train/val/test=1.000/0.656/0.666 | c=0.999014
[Epoch 0029] loss=12.7696 cls=0.7314 smmd=0.2434 ct=9.3738 rec=1.2105 | train/val/test=1.000/0.644/0.661 | c=0.999014
[Epoch 0030] loss=12.7927 cls=0.8111 smmd=0.2570 ct=9.3023 rec=1.2112 | train/val/test=1.000/0.648/0.666 | c=0.999014
[Epoch 0031] loss=13.2220 cls=1.2614 smmd=0.2941 ct=9.2336 rec=1.2164 | train/val/test=1.000/0.660/0.674 | c=0.999014
[Epoch 0032] loss=12.9167 cls=0.9658 smmd=0.3195 ct=9.1936 rec=1.2189 | train/val/test=1.000/0.678/0.696 | c=0.999014
[Epoch 0033] loss=12.8354 cls=0.8891 smmd=0.3452 ct=9.1610 rec=1.2201 | train/val/test=1.000/0.688/0.705 | c=0.999014
[Epoch 0034] loss=12.8535 cls=0.9024 smmd=0.3586 ct=9.1518 rec=1.2203 | train/val/test=1.000/0.706/0.703 | c=0.999014
[Epoch 0035] loss=12.6326 cls=0.6918 smmd=0.3619 ct=9.1453 rec=1.2168 | train/val/test=1.000/0.708/0.711 | c=0.999014
[Epoch 0036] loss=12.9362 cls=1.0015 smmd=0.3468 ct=9.1531 rec=1.2174 | train/val/test=1.000/0.700/0.714 | c=0.999014
[Epoch 0037] loss=12.7789 cls=0.8693 smmd=0.3289 ct=9.1587 rec=1.2110 | train/val/test=1.000/0.698/0.712 | c=0.999014
[Epoch 0038] loss=12.4982 cls=0.6106 smmd=0.2970 ct=9.1810 rec=1.2048 | train/val/test=1.000/0.698/0.698 | c=0.999014
[Epoch 0039] loss=12.8268 cls=0.9563 smmd=0.2690 ct=9.1960 rec=1.2028 | train/val/test=1.000/0.682/0.689 | c=0.999014
[Epoch 0040] loss=12.5283 cls=0.6668 smmd=0.2487 ct=9.2191 rec=1.1969 | train/val/test=1.000/0.676/0.683 | c=0.999014
[Epoch 0041] loss=12.8710 cls=0.9925 smmd=0.2311 ct=9.2329 rec=1.2072 | train/val/test=1.000/0.680/0.687 | c=0.999014
[Epoch 0042] loss=12.9189 cls=1.0774 smmd=0.2150 ct=9.2377 rec=1.1944 | train/val/test=1.000/0.684/0.695 | c=0.999014
[Epoch 0043] loss=13.0739 cls=1.2478 smmd=0.1978 ct=9.2463 rec=1.1910 | train/val/test=1.000/0.686/0.698 | c=0.999014
[Epoch 0044] loss=12.9699 cls=1.1442 smmd=0.1877 ct=9.2622 rec=1.1879 | train/val/test=1.000/0.692/0.704 | c=0.999014
[Epoch 0045] loss=12.8387 cls=1.0106 smmd=0.1859 ct=9.2614 rec=1.1904 | train/val/test=1.000/0.692/0.705 | c=0.999014
[Epoch 0046] loss=12.4427 cls=0.6119 smmd=0.1898 ct=9.2631 rec=1.1889 | train/val/test=1.000/0.700/0.716 | c=0.999014
[Epoch 0047] loss=12.6244 cls=0.7922 smmd=0.1901 ct=9.2502 rec=1.1960 | train/val/test=1.000/0.702/0.717 | c=0.999014
[Epoch 0048] loss=12.7109 cls=0.9017 smmd=0.1920 ct=9.2306 rec=1.1933 | train/val/test=1.000/0.704/0.708 | c=0.999014
[Epoch 0049] loss=12.4503 cls=0.6481 smmd=0.1974 ct=9.2289 rec=1.1879 | train/val/test=1.000/0.700/0.712 | c=0.999014
[Epoch 0050] loss=12.6306 cls=0.8379 smmd=0.1999 ct=9.2140 rec=1.1894 | train/val/test=1.000/0.688/0.709 | c=0.999014
[Epoch 0051] loss=12.2119 cls=0.4143 smmd=0.2013 ct=9.2184 rec=1.1889 | train/val/test=1.000/0.686/0.706 | c=0.999014
[Epoch 0052] loss=12.6193 cls=0.8373 smmd=0.1997 ct=9.2084 rec=1.1869 | train/val/test=1.000/0.682/0.699 | c=0.999014
[Epoch 0053] loss=12.8942 cls=1.1178 smmd=0.1923 ct=9.2092 rec=1.1874 | train/val/test=1.000/0.690/0.710 | c=0.999014
[Epoch 0054] loss=12.5151 cls=0.7510 smmd=0.1860 ct=9.2085 rec=1.1848 | train/val/test=1.000/0.690/0.712 | c=0.999014
[Epoch 0055] loss=12.6641 cls=0.9034 smmd=0.1823 ct=9.2135 rec=1.1825 | train/val/test=1.000/0.696/0.712 | c=0.999014
[Epoch 0056] loss=12.3208 cls=0.5630 smmd=0.1834 ct=9.2128 rec=1.1808 | train/val/test=1.000/0.696/0.714 | c=0.999014
[Epoch 0057] loss=12.2946 cls=0.5342 smmd=0.1796 ct=9.2129 rec=1.1839 | train/val/test=1.000/0.704/0.714 | c=0.999014
[Epoch 0058] loss=12.2991 cls=0.5465 smmd=0.1768 ct=9.2127 rec=1.1816 | train/val/test=1.000/0.706/0.720 | c=0.999014
[Epoch 0059] loss=12.8100 cls=1.0635 smmd=0.1792 ct=9.2035 rec=1.1819 | train/val/test=1.000/0.702/0.725 | c=0.999014
[Epoch 0060] loss=12.7611 cls=1.0068 smmd=0.1811 ct=9.2076 rec=1.1828 | train/val/test=1.000/0.702/0.724 | c=0.999014
[Epoch 0061] loss=12.5452 cls=0.7983 smmd=0.1843 ct=9.1999 rec=1.1813 | train/val/test=1.000/0.704/0.722 | c=0.999014
[Epoch 0062] loss=12.6416 cls=0.8986 smmd=0.1836 ct=9.1982 rec=1.1806 | train/val/test=1.000/0.708/0.724 | c=0.999014
[Epoch 0063] loss=12.4148 cls=0.6782 smmd=0.1816 ct=9.1946 rec=1.1802 | train/val/test=1.000/0.706/0.725 | c=0.999014
[Epoch 0064] loss=12.4514 cls=0.7093 smmd=0.1808 ct=9.1999 rec=1.1807 | train/val/test=1.000/0.704/0.721 | c=0.999014
[Epoch 0065] loss=12.4333 cls=0.6903 smmd=0.1808 ct=9.2041 rec=1.1790 | train/val/test=1.000/0.704/0.718 | c=0.999014
[Epoch 0066] loss=12.4765 cls=0.7334 smmd=0.1803 ct=9.2022 rec=1.1803 | train/val/test=1.000/0.706/0.712 | c=0.999014
[Epoch 0067] loss=12.2766 cls=0.5396 smmd=0.1745 ct=9.2035 rec=1.1795 | train/val/test=1.000/0.704/0.712 | c=0.999014
[Epoch 0068] loss=12.5512 cls=0.8241 smmd=0.1723 ct=9.2009 rec=1.1770 | train/val/test=1.000/0.704/0.713 | c=0.999014
[Epoch 0069] loss=12.4740 cls=0.7395 smmd=0.1698 ct=9.2013 rec=1.1817 | train/val/test=1.000/0.702/0.711 | c=0.999014
[Epoch 0070] loss=12.3714 cls=0.6476 smmd=0.1644 ct=9.2028 rec=1.1783 | train/val/test=1.000/0.700/0.714 | c=0.999014
[Epoch 0071] loss=12.3225 cls=0.5949 smmd=0.1627 ct=9.2070 rec=1.1790 | train/val/test=1.000/0.698/0.706 | c=0.999014
[Epoch 0072] loss=12.5770 cls=0.8414 smmd=0.1607 ct=9.2205 rec=1.1772 | train/val/test=1.000/0.698/0.706 | c=0.999014
[Epoch 0073] loss=12.4703 cls=0.7249 smmd=0.1634 ct=9.2172 rec=1.1824 | train/val/test=1.000/0.690/0.705 | c=0.999014
[Epoch 0074] loss=12.8902 cls=1.1481 smmd=0.1591 ct=9.2193 rec=1.1818 | train/val/test=1.000/0.684/0.705 | c=0.999014
[Epoch 0075] loss=12.5597 cls=0.8186 smmd=0.1604 ct=9.2250 rec=1.1779 | train/val/test=1.000/0.682/0.705 | c=0.999014
[Epoch 0076] loss=12.5771 cls=0.8359 smmd=0.1571 ct=9.2236 rec=1.1803 | train/val/test=1.000/0.682/0.705 | c=0.999014
[Epoch 0077] loss=12.8145 cls=1.0539 smmd=0.1589 ct=9.2257 rec=1.1880 | train/val/test=1.000/0.688/0.706 | c=0.999014
[Epoch 0078] loss=12.8215 cls=1.0763 smmd=0.1556 ct=9.2229 rec=1.1833 | train/val/test=1.000/0.696/0.707 | c=0.999014
[Epoch 0079] loss=12.5700 cls=0.8399 smmd=0.1550 ct=9.2159 rec=1.1796 | train/val/test=1.000/0.700/0.707 | c=0.999014
[Epoch 0080] loss=12.2400 cls=0.5119 smmd=0.1552 ct=9.2178 rec=1.1776 | train/val/test=1.000/0.700/0.713 | c=0.999014
[Epoch 0081] loss=12.4046 cls=0.6733 smmd=0.1555 ct=9.2082 rec=1.1838 | train/val/test=1.000/0.700/0.715 | c=0.999014
[Epoch 0082] loss=12.7249 cls=0.9946 smmd=0.1565 ct=9.2130 rec=1.1805 | train/val/test=1.000/0.704/0.716 | c=0.999014
[Epoch 0083] loss=12.6869 cls=0.9611 smmd=0.1570 ct=9.2061 rec=1.1814 | train/val/test=1.000/0.708/0.716 | c=0.999014
[Epoch 0084] loss=12.4897 cls=0.7678 smmd=0.1572 ct=9.2002 rec=1.1823 | train/val/test=1.000/0.708/0.716 | c=0.999014
[Epoch 0085] loss=12.4663 cls=0.7458 smmd=0.1578 ct=9.2023 rec=1.1802 | train/val/test=1.000/0.708/0.716 | c=0.999014
[Epoch 0086] loss=12.2024 cls=0.4869 smmd=0.1584 ct=9.2052 rec=1.1760 | train/val/test=1.000/0.708/0.717 | c=0.999014
[Epoch 0087] loss=12.1532 cls=0.4390 smmd=0.1612 ct=9.1982 rec=1.1774 | train/val/test=1.000/0.706/0.717 | c=0.999014
[Epoch 0088] loss=12.3075 cls=0.5955 smmd=0.1576 ct=9.1985 rec=1.1780 | train/val/test=1.000/0.704/0.716 | c=0.999014
[Epoch 0089] loss=12.3805 cls=0.6635 smmd=0.1635 ct=9.1959 rec=1.1788 | train/val/test=1.000/0.704/0.713 | c=0.999014
[Epoch 0090] loss=12.2891 cls=0.5751 smmd=0.1620 ct=9.1952 rec=1.1784 | train/val/test=1.000/0.704/0.712 | c=0.999014
[Epoch 0091] loss=12.2145 cls=0.5056 smmd=0.1612 ct=9.1945 rec=1.1766 | train/val/test=1.000/0.702/0.712 | c=0.999014
[Epoch 0092] loss=12.4794 cls=0.7592 smmd=0.1629 ct=9.2002 rec=1.1786 | train/val/test=1.000/0.702/0.712 | c=0.999014
[Epoch 0093] loss=12.2338 cls=0.5209 smmd=0.1592 ct=9.1975 rec=1.1780 | train/val/test=1.000/0.702/0.712 | c=0.999014
[Epoch 0094] loss=12.4536 cls=0.7427 smmd=0.1615 ct=9.1967 rec=1.1763 | train/val/test=1.000/0.702/0.712 | c=0.999014
[Epoch 0095] loss=12.3333 cls=0.6010 smmd=0.1636 ct=9.2025 rec=1.1831 | train/val/test=1.000/0.702/0.712 | c=0.999014
[Epoch 0096] loss=12.2969 cls=0.5873 smmd=0.1611 ct=9.1949 rec=1.1769 | train/val/test=1.000/0.702/0.712 | c=0.999014
[Epoch 0097] loss=12.3568 cls=0.6355 smmd=0.1627 ct=9.1979 rec=1.1804 | train/val/test=1.000/0.702/0.712 | c=0.999014
[Epoch 0098] loss=12.3988 cls=0.6803 smmd=0.1614 ct=9.1998 rec=1.1787 | train/val/test=1.000/0.702/0.712 | c=0.999014
[Epoch 0099] loss=12.3986 cls=0.6762 smmd=0.1635 ct=9.2033 rec=1.1779 | train/val/test=1.000/0.702/0.712 | c=0.999014
=== Best @ epoch 35: val=0.7080, test=0.7110 ===
