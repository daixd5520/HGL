Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=16.3882 cls=1.9923 smmd=2.4021 ct=9.2110 rec=1.3914 | train/val/test=0.224/0.178/0.181 | c=0.999014
[Epoch 0001] loss=16.2719 cls=1.9797 smmd=2.3065 ct=9.2109 rec=1.3874 | train/val/test=0.466/0.274/0.286 | c=0.999014
[Epoch 0002] loss=16.1883 cls=2.0478 smmd=2.1633 ct=9.2031 rec=1.3871 | train/val/test=0.621/0.424/0.413 | c=0.999014
[Epoch 0003] loss=15.9645 cls=2.0196 smmd=1.9773 ct=9.1940 rec=1.3868 | train/val/test=0.655/0.342/0.359 | c=0.999014
[Epoch 0004] loss=15.5119 cls=1.8279 smmd=1.7354 ct=9.1779 rec=1.3853 | train/val/test=0.603/0.296/0.293 | c=0.999014
[Epoch 0005] loss=15.1495 cls=1.7779 smmd=1.4471 ct=9.1570 rec=1.3837 | train/val/test=0.534/0.216/0.240 | c=0.999014
[Epoch 0006] loss=14.8366 cls=1.8130 smmd=1.1368 ct=9.1260 rec=1.3804 | train/val/test=0.690/0.330/0.352 | c=0.999014
[Epoch 0007] loss=14.1388 cls=1.5032 smmd=0.8168 ct=9.0787 rec=1.3701 | train/val/test=0.931/0.592/0.556 | c=0.999014
[Epoch 0008] loss=13.8165 cls=1.5562 smmd=0.5333 ct=9.0216 rec=1.3527 | train/val/test=0.966/0.674/0.654 | c=0.999014
[Epoch 0009] loss=13.3308 cls=1.3666 smmd=0.3437 ct=8.9608 rec=1.3298 | train/val/test=0.983/0.702/0.678 | c=0.999014
[Epoch 0010] loss=13.0486 cls=1.2459 smmd=0.2844 ct=8.9108 rec=1.3037 | train/val/test=0.966/0.706/0.691 | c=0.999014
[Epoch 0011] loss=13.1405 cls=1.3711 smmd=0.3267 ct=8.8809 rec=1.2809 | train/val/test=0.966/0.714/0.712 | c=0.999014
[Epoch 0012] loss=13.0546 cls=1.2559 smmd=0.4340 ct=8.8549 rec=1.2549 | train/val/test=0.948/0.708/0.703 | c=0.999014
[Epoch 0013] loss=13.6287 cls=1.0999 smmd=0.5558 ct=9.5073 rec=1.2329 | train/val/test=0.966/0.724/0.724 | c=0.999014
[Epoch 0014] loss=13.5790 cls=1.1190 smmd=0.6646 ct=9.3657 rec=1.2148 | train/val/test=0.966/0.738/0.719 | c=0.999014
[Epoch 0015] loss=13.4729 cls=1.0993 smmd=0.7366 ct=9.2337 rec=1.2016 | train/val/test=0.983/0.742/0.739 | c=0.999014
[Epoch 0016] loss=13.7235 cls=1.3856 smmd=0.7866 ct=9.1475 rec=1.2019 | train/val/test=0.931/0.730/0.720 | c=0.999014
[Epoch 0017] loss=13.3490 cls=1.0516 smmd=0.8117 ct=9.0870 rec=1.1993 | train/val/test=0.931/0.750/0.745 | c=0.999014
[Epoch 0018] loss=13.3370 cls=1.1002 smmd=0.8045 ct=9.0442 rec=1.1941 | train/val/test=0.983/0.752/0.753 | c=0.999014
[Epoch 0019] loss=13.2068 cls=1.0156 smmd=0.7666 ct=9.0376 rec=1.1935 | train/val/test=0.983/0.752/0.756 | c=0.999014
[Epoch 0020] loss=13.2732 cls=1.1498 smmd=0.6973 ct=9.0409 rec=1.1926 | train/val/test=0.966/0.754/0.754 | c=0.999014
[Epoch 0021] loss=13.5812 cls=1.5247 smmd=0.6111 ct=9.0604 rec=1.1924 | train/val/test=0.966/0.760/0.743 | c=0.999014
[Epoch 0022] loss=13.1294 cls=1.1241 smmd=0.5298 ct=9.0873 rec=1.1941 | train/val/test=0.983/0.754/0.733 | c=0.999014
[Epoch 0023] loss=13.3009 cls=1.3206 smmd=0.4661 ct=9.1200 rec=1.1971 | train/val/test=0.966/0.728/0.718 | c=0.999014
[Epoch 0024] loss=13.2097 cls=1.2372 smmd=0.4155 ct=9.1445 rec=1.2063 | train/val/test=0.983/0.738/0.716 | c=0.999014
[Epoch 0025] loss=13.0175 cls=1.0486 smmd=0.3898 ct=9.1658 rec=1.2067 | train/val/test=0.966/0.750/0.718 | c=0.999014
[Epoch 0026] loss=12.9607 cls=0.9926 smmd=0.3667 ct=9.1864 rec=1.2075 | train/val/test=0.966/0.748/0.742 | c=0.999014
[Epoch 0027] loss=13.3668 cls=1.3918 smmd=0.3515 ct=9.2037 rec=1.2099 | train/val/test=0.966/0.766/0.751 | c=0.999014
[Epoch 0028] loss=13.1193 cls=1.1368 smmd=0.3368 ct=9.2201 rec=1.2128 | train/val/test=0.966/0.768/0.749 | c=0.999014
[Epoch 0029] loss=13.1250 cls=1.1476 smmd=0.3177 ct=9.2286 rec=1.2155 | train/val/test=0.966/0.756/0.750 | c=0.999014
[Epoch 0030] loss=12.9907 cls=1.0271 smmd=0.3023 ct=9.2348 rec=1.2133 | train/val/test=0.966/0.748/0.746 | c=0.999014
[Epoch 0031] loss=13.0996 cls=1.1675 smmd=0.2812 ct=9.2277 rec=1.2116 | train/val/test=0.966/0.736/0.726 | c=0.999014
[Epoch 0032] loss=12.9709 cls=1.0418 smmd=0.2746 ct=9.2276 rec=1.2134 | train/val/test=0.966/0.738/0.728 | c=0.999014
[Epoch 0033] loss=12.9134 cls=1.0009 smmd=0.2655 ct=9.2234 rec=1.2118 | train/val/test=0.966/0.740/0.726 | c=0.999014
[Epoch 0034] loss=12.7303 cls=0.8455 smmd=0.2604 ct=9.2098 rec=1.2073 | train/val/test=0.983/0.742/0.730 | c=0.999014
[Epoch 0035] loss=13.2654 cls=1.3912 smmd=0.2613 ct=9.1941 rec=1.2094 | train/val/test=0.966/0.742/0.731 | c=0.999014
[Epoch 0036] loss=12.8443 cls=0.9915 smmd=0.2655 ct=9.1816 rec=1.2029 | train/val/test=0.966/0.750/0.740 | c=0.999014
[Epoch 0037] loss=13.1098 cls=1.2548 smmd=0.2716 ct=9.1758 rec=1.2038 | train/val/test=0.966/0.754/0.748 | c=0.999014
[Epoch 0038] loss=12.6274 cls=0.7780 smmd=0.2634 ct=9.1822 rec=1.2019 | train/val/test=0.966/0.766/0.747 | c=0.999014
[Epoch 0039] loss=12.8746 cls=1.0406 smmd=0.2597 ct=9.1804 rec=1.1969 | train/val/test=0.966/0.768/0.752 | c=0.999014
[Epoch 0040] loss=13.0037 cls=1.1866 smmd=0.2452 ct=9.1905 rec=1.1907 | train/val/test=0.983/0.770/0.752 | c=0.999014
[Epoch 0041] loss=12.9025 cls=1.0879 smmd=0.2379 ct=9.1965 rec=1.1901 | train/val/test=0.983/0.760/0.743 | c=0.999014
[Epoch 0042] loss=12.8461 cls=1.0315 smmd=0.2277 ct=9.2045 rec=1.1913 | train/val/test=0.983/0.762/0.737 | c=0.999014
[Epoch 0043] loss=13.0575 cls=1.2565 smmd=0.2228 ct=9.2047 rec=1.1867 | train/val/test=0.983/0.748/0.729 | c=0.999014
[Epoch 0044] loss=12.7491 cls=0.9632 smmd=0.2217 ct=9.1968 rec=1.1837 | train/val/test=0.983/0.746/0.724 | c=0.999014
[Epoch 0045] loss=12.7312 cls=0.9541 smmd=0.2184 ct=9.1916 rec=1.1835 | train/val/test=0.966/0.746/0.719 | c=0.999014
[Epoch 0046] loss=12.6451 cls=0.8606 smmd=0.2193 ct=9.1924 rec=1.1864 | train/val/test=0.966/0.756/0.722 | c=0.999014
[Epoch 0047] loss=12.8262 cls=1.0435 smmd=0.2186 ct=9.1885 rec=1.1878 | train/val/test=0.983/0.756/0.725 | c=0.999014
[Epoch 0048] loss=12.7591 cls=0.9804 smmd=0.2158 ct=9.1866 rec=1.1882 | train/val/test=1.000/0.756/0.723 | c=0.999014
[Epoch 0049] loss=12.6313 cls=0.8613 smmd=0.2099 ct=9.1881 rec=1.1859 | train/val/test=1.000/0.758/0.724 | c=0.999014
[Epoch 0050] loss=13.1991 cls=1.4320 smmd=0.1983 ct=9.1929 rec=1.1879 | train/val/test=1.000/0.754/0.721 | c=0.999014
[Epoch 0051] loss=12.6856 cls=0.9171 smmd=0.1940 ct=9.2009 rec=1.1867 | train/val/test=1.000/0.752/0.725 | c=0.999014
[Epoch 0052] loss=12.6119 cls=0.8347 smmd=0.1890 ct=9.2063 rec=1.1909 | train/val/test=1.000/0.752/0.726 | c=0.999014
[Epoch 0053] loss=12.6754 cls=0.9184 smmd=0.1850 ct=9.1997 rec=1.1862 | train/val/test=1.000/0.750/0.724 | c=0.999014
[Epoch 0054] loss=12.6736 cls=0.9167 smmd=0.1802 ct=9.2026 rec=1.1871 | train/val/test=0.983/0.752/0.724 | c=0.999014
[Epoch 0055] loss=12.7842 cls=1.0236 smmd=0.1806 ct=9.1972 rec=1.1914 | train/val/test=0.983/0.748/0.726 | c=0.999014
[Epoch 0056] loss=12.7567 cls=0.9944 smmd=0.1830 ct=9.2021 rec=1.1885 | train/val/test=0.983/0.746/0.715 | c=0.999014
[Epoch 0057] loss=12.7596 cls=1.0131 smmd=0.1851 ct=9.1926 rec=1.1844 | train/val/test=0.983/0.746/0.709 | c=0.999014
[Epoch 0058] loss=12.7668 cls=1.0258 smmd=0.1884 ct=9.1857 rec=1.1834 | train/val/test=0.983/0.742/0.710 | c=0.999014
[Epoch 0059] loss=12.3715 cls=0.6296 smmd=0.1852 ct=9.1898 rec=1.1834 | train/val/test=0.983/0.738/0.716 | c=0.999014
[Epoch 0060] loss=12.8338 cls=1.0840 smmd=0.1869 ct=9.1900 rec=1.1865 | train/val/test=1.000/0.742/0.721 | c=0.999014
[Epoch 0061] loss=12.9158 cls=1.1750 smmd=0.1840 ct=9.1862 rec=1.1853 | train/val/test=1.000/0.750/0.721 | c=0.999014
[Epoch 0062] loss=12.9871 cls=1.2156 smmd=0.1823 ct=9.1987 rec=1.1953 | train/val/test=1.000/0.748/0.729 | c=0.999014
[Epoch 0063] loss=12.7828 cls=1.0388 smmd=0.1837 ct=9.1895 rec=1.1854 | train/val/test=1.000/0.748/0.736 | c=0.999014
[Epoch 0064] loss=12.7085 cls=0.9633 smmd=0.1782 ct=9.1928 rec=1.1871 | train/val/test=1.000/0.748/0.735 | c=0.999014
[Epoch 0065] loss=12.9538 cls=1.2059 smmd=0.1781 ct=9.1934 rec=1.1882 | train/val/test=0.983/0.752/0.731 | c=0.999014
[Epoch 0066] loss=12.5114 cls=0.7561 smmd=0.1766 ct=9.1922 rec=1.1932 | train/val/test=0.983/0.748/0.723 | c=0.999014
[Epoch 0067] loss=12.8165 cls=1.0799 smmd=0.1801 ct=9.1796 rec=1.1885 | train/val/test=0.983/0.742/0.721 | c=0.999014
[Epoch 0068] loss=13.0817 cls=1.3318 smmd=0.1792 ct=9.1817 rec=1.1945 | train/val/test=0.983/0.734/0.718 | c=0.999014
[Epoch 0069] loss=12.6828 cls=0.9412 smmd=0.1778 ct=9.1847 rec=1.1896 | train/val/test=0.983/0.734/0.718 | c=0.999014
[Epoch 0070] loss=12.5625 cls=0.8268 smmd=0.1791 ct=9.1804 rec=1.1881 | train/val/test=0.983/0.740/0.719 | c=0.999014
[Epoch 0071] loss=12.6347 cls=0.8953 smmd=0.1779 ct=9.1852 rec=1.1882 | train/val/test=0.983/0.736/0.721 | c=0.999014
[Epoch 0072] loss=12.6780 cls=0.9231 smmd=0.1801 ct=9.1876 rec=1.1935 | train/val/test=0.983/0.736/0.724 | c=0.999014
[Epoch 0073] loss=12.5843 cls=0.8268 smmd=0.1805 ct=9.1878 rec=1.1946 | train/val/test=0.983/0.742/0.725 | c=0.999014
[Epoch 0074] loss=12.7412 cls=1.0014 smmd=0.1798 ct=9.1842 rec=1.1879 | train/val/test=0.983/0.744/0.727 | c=0.999014
[Epoch 0075] loss=12.7372 cls=0.9892 smmd=0.1836 ct=9.1806 rec=1.1919 | train/val/test=0.983/0.744/0.724 | c=0.999014
[Epoch 0076] loss=12.5575 cls=0.8326 smmd=0.1799 ct=9.1748 rec=1.1851 | train/val/test=0.983/0.746/0.726 | c=0.999014
[Epoch 0077] loss=12.3680 cls=0.6430 smmd=0.1812 ct=9.1774 rec=1.1832 | train/val/test=0.983/0.750/0.734 | c=0.999014
[Epoch 0078] loss=12.5861 cls=0.8505 smmd=0.1798 ct=9.1835 rec=1.1862 | train/val/test=0.983/0.750/0.733 | c=0.999014
[Epoch 0079] loss=12.8382 cls=1.0985 smmd=0.1816 ct=9.1819 rec=1.1881 | train/val/test=0.983/0.750/0.732 | c=0.999014
[Epoch 0080] loss=12.8131 cls=1.0914 smmd=0.1795 ct=9.1774 rec=1.1824 | train/val/test=0.983/0.750/0.730 | c=0.999014
[Epoch 0081] loss=12.6196 cls=0.9015 smmd=0.1809 ct=9.1775 rec=1.1799 | train/val/test=0.983/0.748/0.729 | c=0.999014
[Epoch 0082] loss=12.8395 cls=1.1035 smmd=0.1807 ct=9.1811 rec=1.1871 | train/val/test=0.983/0.748/0.729 | c=0.999014
[Epoch 0083] loss=12.9210 cls=1.1843 smmd=0.1798 ct=9.1830 rec=1.1869 | train/val/test=0.983/0.748/0.730 | c=0.999014
[Epoch 0084] loss=12.6838 cls=0.9438 smmd=0.1811 ct=9.1804 rec=1.1893 | train/val/test=0.983/0.748/0.730 | c=0.999014
[Epoch 0085] loss=12.6628 cls=0.9378 smmd=0.1788 ct=9.1810 rec=1.1827 | train/val/test=0.983/0.750/0.732 | c=0.999014
[Epoch 0086] loss=12.6042 cls=0.8836 smmd=0.1801 ct=9.1767 rec=1.1819 | train/val/test=0.983/0.750/0.734 | c=0.999014
[Epoch 0087] loss=12.5550 cls=0.8276 smmd=0.1796 ct=9.1807 rec=1.1836 | train/val/test=0.983/0.750/0.735 | c=0.999014
[Epoch 0088] loss=12.7489 cls=1.0185 smmd=0.1818 ct=9.1761 rec=1.1863 | train/val/test=0.983/0.750/0.739 | c=0.999014
[Epoch 0089] loss=12.8581 cls=1.1334 smmd=0.1801 ct=9.1754 rec=1.1846 | train/val/test=0.983/0.750/0.739 | c=0.999014
[Epoch 0090] loss=12.6128 cls=0.8812 smmd=0.1798 ct=9.1796 rec=1.1861 | train/val/test=0.983/0.750/0.740 | c=0.999014
[Epoch 0091] loss=12.8379 cls=1.1031 smmd=0.1833 ct=9.1749 rec=1.1883 | train/val/test=0.983/0.750/0.740 | c=0.999014
[Epoch 0092] loss=12.5484 cls=0.8231 smmd=0.1813 ct=9.1800 rec=1.1820 | train/val/test=0.983/0.748/0.739 | c=0.999014
[Epoch 0093] loss=12.4652 cls=0.7396 smmd=0.1808 ct=9.1729 rec=1.1859 | train/val/test=0.983/0.748/0.739 | c=0.999014
[Epoch 0094] loss=12.6241 cls=0.8952 smmd=0.1817 ct=9.1763 rec=1.1854 | train/val/test=0.983/0.748/0.739 | c=0.999014
[Epoch 0095] loss=12.5812 cls=0.8541 smmd=0.1821 ct=9.1763 rec=1.1844 | train/val/test=0.983/0.748/0.739 | c=0.999014
[Epoch 0096] loss=12.7664 cls=1.0329 smmd=0.1820 ct=9.1778 rec=1.1868 | train/val/test=0.983/0.748/0.739 | c=0.999014
[Epoch 0097] loss=12.9243 cls=1.1925 smmd=0.1800 ct=9.1764 rec=1.1878 | train/val/test=0.983/0.748/0.739 | c=0.999014
[Epoch 0098] loss=12.4420 cls=0.7194 smmd=0.1790 ct=9.1755 rec=1.1841 | train/val/test=0.983/0.748/0.739 | c=0.999014
[Epoch 0099] loss=12.4613 cls=0.7406 smmd=0.1789 ct=9.1805 rec=1.1806 | train/val/test=0.983/0.748/0.739 | c=0.999014
=== Best @ epoch 40: val=0.7700, test=0.7520 ===
