Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=16.8418 cls=2.4160 smmd=2.3655 ct=9.2653 rec=1.3975 | train/val/test=0.207/0.296/0.290 | c=0.999014
[Epoch 0001] loss=16.2920 cls=1.9578 smmd=2.2947 ct=9.2628 rec=1.3884 | train/val/test=0.172/0.080/0.096 | c=0.999014
[Epoch 0002] loss=16.0774 cls=1.8713 smmd=2.1618 ct=9.2605 rec=1.3919 | train/val/test=0.241/0.100/0.118 | c=0.999014
[Epoch 0003] loss=16.0827 cls=2.0558 smmd=1.9834 ct=9.2564 rec=1.3936 | train/val/test=0.414/0.216/0.237 | c=0.999014
[Epoch 0004] loss=15.6350 cls=1.8383 smmd=1.7661 ct=9.2506 rec=1.3900 | train/val/test=0.655/0.392/0.405 | c=0.999014
[Epoch 0005] loss=15.2025 cls=1.7046 smmd=1.4863 ct=9.2359 rec=1.3878 | train/val/test=0.586/0.364/0.371 | c=0.999014
[Epoch 0006] loss=14.8270 cls=1.6525 smmd=1.1829 ct=9.2179 rec=1.3869 | train/val/test=0.828/0.464/0.484 | c=0.999014
[Epoch 0007] loss=14.3918 cls=1.5767 smmd=0.8638 ct=9.1881 rec=1.3816 | train/val/test=0.931/0.454/0.500 | c=0.999014
[Epoch 0008] loss=13.8161 cls=1.3633 smmd=0.5705 ct=9.1401 rec=1.3712 | train/val/test=0.931/0.420/0.437 | c=0.999014
[Epoch 0009] loss=13.6181 cls=1.4977 smmd=0.3383 ct=9.0730 rec=1.3546 | train/val/test=0.897/0.436/0.434 | c=0.999014
[Epoch 0010] loss=13.3237 cls=1.4301 smmd=0.2344 ct=9.0002 rec=1.3296 | train/val/test=0.966/0.534/0.514 | c=0.999014
[Epoch 0011] loss=13.3753 cls=1.5316 smmd=0.2540 ct=8.9630 rec=1.3133 | train/val/test=0.966/0.626/0.628 | c=0.999014
[Epoch 0012] loss=13.2531 cls=1.3803 smmd=0.3541 ct=8.9370 rec=1.2909 | train/val/test=0.966/0.618/0.657 | c=0.999014
[Epoch 0013] loss=12.9132 cls=0.9792 smmd=0.4958 ct=8.9037 rec=1.2672 | train/val/test=0.966/0.628/0.652 | c=0.999014
[Epoch 0014] loss=13.6486 cls=1.0680 smmd=0.6165 ct=9.4566 rec=1.2538 | train/val/test=1.000/0.616/0.603 | c=0.999014
[Epoch 0015] loss=13.6379 cls=1.1381 smmd=0.7070 ct=9.3055 rec=1.2436 | train/val/test=0.931/0.534/0.528 | c=0.999014
[Epoch 0016] loss=13.1607 cls=0.7198 smmd=0.7642 ct=9.1726 rec=1.2521 | train/val/test=1.000/0.568/0.571 | c=0.999014
[Epoch 0017] loss=13.0001 cls=0.6573 smmd=0.7848 ct=9.0736 rec=1.2422 | train/val/test=1.000/0.646/0.645 | c=0.999014
[Epoch 0018] loss=12.9564 cls=0.7108 smmd=0.7794 ct=9.0246 rec=1.2208 | train/val/test=0.966/0.674/0.687 | c=0.999014
[Epoch 0019] loss=12.9959 cls=0.7899 smmd=0.7564 ct=9.0247 rec=1.2124 | train/val/test=0.966/0.678/0.706 | c=0.999014
[Epoch 0020] loss=13.0360 cls=0.9134 smmd=0.6935 ct=9.0195 rec=1.2048 | train/val/test=0.966/0.670/0.702 | c=0.999014
[Epoch 0021] loss=12.7259 cls=0.6833 smmd=0.6130 ct=9.0236 rec=1.2030 | train/val/test=1.000/0.664/0.700 | c=0.999014
[Epoch 0022] loss=13.3214 cls=1.3602 smmd=0.5361 ct=9.0248 rec=1.2001 | train/val/test=1.000/0.648/0.679 | c=0.999014
[Epoch 0023] loss=12.7634 cls=0.8596 smmd=0.4789 ct=9.0382 rec=1.1934 | train/val/test=1.000/0.626/0.645 | c=0.999014
[Epoch 0024] loss=13.3103 cls=1.4318 smmd=0.4253 ct=9.0604 rec=1.1964 | train/val/test=1.000/0.610/0.634 | c=0.999014
[Epoch 0025] loss=12.8498 cls=0.9684 smmd=0.3953 ct=9.0847 rec=1.2007 | train/val/test=1.000/0.654/0.678 | c=0.999014
[Epoch 0026] loss=12.3681 cls=0.5187 smmd=0.3521 ct=9.1174 rec=1.1900 | train/val/test=1.000/0.676/0.705 | c=0.999014
[Epoch 0027] loss=12.6702 cls=0.8221 smmd=0.3178 ct=9.1513 rec=1.1895 | train/val/test=0.966/0.686/0.716 | c=0.999014
[Epoch 0028] loss=12.3949 cls=0.5148 smmd=0.2938 ct=9.1984 rec=1.1939 | train/val/test=0.966/0.682/0.719 | c=0.999014
[Epoch 0029] loss=12.4833 cls=0.5975 smmd=0.2764 ct=9.2196 rec=1.1949 | train/val/test=0.966/0.678/0.720 | c=0.999014
[Epoch 0030] loss=12.9911 cls=1.1039 smmd=0.2559 ct=9.2289 rec=1.2011 | train/val/test=1.000/0.672/0.712 | c=0.999014
[Epoch 0031] loss=12.6955 cls=0.8528 smmd=0.2382 ct=9.2120 rec=1.1963 | train/val/test=0.966/0.662/0.690 | c=0.999014
[Epoch 0032] loss=12.5823 cls=0.7467 smmd=0.2424 ct=9.1983 rec=1.1975 | train/val/test=0.966/0.662/0.672 | c=0.999014
[Epoch 0033] loss=12.8283 cls=1.0053 smmd=0.2420 ct=9.1798 rec=1.2006 | train/val/test=0.966/0.660/0.684 | c=0.999014
[Epoch 0034] loss=12.8827 cls=1.0638 smmd=0.2497 ct=9.1575 rec=1.2058 | train/val/test=0.966/0.668/0.698 | c=0.999014
[Epoch 0035] loss=12.4207 cls=0.6215 smmd=0.2552 ct=9.1379 rec=1.2031 | train/val/test=0.966/0.672/0.710 | c=0.999014
[Epoch 0036] loss=12.7991 cls=0.9897 smmd=0.2612 ct=9.1263 rec=1.2110 | train/val/test=0.966/0.676/0.711 | c=0.999014
[Epoch 0037] loss=12.9091 cls=1.1163 smmd=0.2618 ct=9.1123 rec=1.2093 | train/val/test=0.966/0.678/0.712 | c=0.999014
[Epoch 0038] loss=12.5727 cls=0.7739 smmd=0.2582 ct=9.1192 rec=1.2107 | train/val/test=0.966/0.674/0.706 | c=0.999014
[Epoch 0039] loss=12.7183 cls=0.9433 smmd=0.2470 ct=9.1196 rec=1.2042 | train/val/test=0.966/0.672/0.708 | c=0.999014
[Epoch 0040] loss=12.9735 cls=1.1970 smmd=0.2357 ct=9.1236 rec=1.2086 | train/val/test=0.966/0.680/0.707 | c=0.999014
[Epoch 0041] loss=12.5806 cls=0.8286 smmd=0.2221 ct=9.1325 rec=1.1987 | train/val/test=0.966/0.678/0.708 | c=0.999014
[Epoch 0042] loss=12.2001 cls=0.4547 smmd=0.2120 ct=9.1446 rec=1.1944 | train/val/test=1.000/0.686/0.711 | c=0.999014
[Epoch 0043] loss=13.0175 cls=1.2696 smmd=0.2061 ct=9.1516 rec=1.1950 | train/val/test=1.000/0.688/0.716 | c=0.999014
[Epoch 0044] loss=12.3425 cls=0.6018 smmd=0.1946 ct=9.1556 rec=1.1952 | train/val/test=1.000/0.686/0.711 | c=0.999014
[Epoch 0045] loss=12.4422 cls=0.7030 smmd=0.1934 ct=9.1657 rec=1.1901 | train/val/test=1.000/0.680/0.706 | c=0.999014
[Epoch 0046] loss=12.7743 cls=1.0494 smmd=0.1890 ct=9.1570 rec=1.1895 | train/val/test=1.000/0.680/0.706 | c=0.999014
[Epoch 0047] loss=12.4979 cls=0.7696 smmd=0.1887 ct=9.1596 rec=1.1900 | train/val/test=1.000/0.684/0.702 | c=0.999014
[Epoch 0048] loss=12.2986 cls=0.5912 smmd=0.1863 ct=9.1463 rec=1.1874 | train/val/test=1.000/0.680/0.699 | c=0.999014
[Epoch 0049] loss=12.2941 cls=0.5909 smmd=0.1818 ct=9.1410 rec=1.1902 | train/val/test=1.000/0.678/0.700 | c=0.999014
[Epoch 0050] loss=12.5095 cls=0.8099 smmd=0.1840 ct=9.1348 rec=1.1904 | train/val/test=1.000/0.682/0.703 | c=0.999014
[Epoch 0051] loss=12.8071 cls=1.1162 smmd=0.1820 ct=9.1329 rec=1.1880 | train/val/test=1.000/0.678/0.701 | c=0.999014
[Epoch 0052] loss=12.7276 cls=1.0352 smmd=0.1836 ct=9.1300 rec=1.1894 | train/val/test=1.000/0.672/0.700 | c=0.999014
[Epoch 0053] loss=12.8240 cls=1.1321 smmd=0.1818 ct=9.1351 rec=1.1875 | train/val/test=1.000/0.670/0.701 | c=0.999014
[Epoch 0054] loss=12.8441 cls=1.1502 smmd=0.1767 ct=9.1339 rec=1.1916 | train/val/test=1.000/0.676/0.705 | c=0.999014
[Epoch 0055] loss=12.2830 cls=0.5901 smmd=0.1718 ct=9.1439 rec=1.1886 | train/val/test=1.000/0.678/0.708 | c=0.999014
[Epoch 0056] loss=12.5458 cls=0.8553 smmd=0.1631 ct=9.1465 rec=1.1904 | train/val/test=1.000/0.682/0.711 | c=0.999014
[Epoch 0057] loss=12.3357 cls=0.6518 smmd=0.1613 ct=9.1518 rec=1.1854 | train/val/test=1.000/0.688/0.712 | c=0.999014
[Epoch 0058] loss=12.7900 cls=1.0785 smmd=0.1581 ct=9.1635 rec=1.1949 | train/val/test=1.000/0.694/0.717 | c=0.999014
[Epoch 0059] loss=12.3425 cls=0.6610 smmd=0.1583 ct=9.1586 rec=1.1823 | train/val/test=1.000/0.698/0.717 | c=0.999014
[Epoch 0060] loss=12.7078 cls=1.0240 smmd=0.1576 ct=9.1548 rec=1.1857 | train/val/test=1.000/0.696/0.714 | c=0.999014
[Epoch 0061] loss=12.1355 cls=0.4600 smmd=0.1600 ct=9.1484 rec=1.1836 | train/val/test=1.000/0.696/0.710 | c=0.999014
[Epoch 0062] loss=12.5508 cls=0.8700 smmd=0.1585 ct=9.1457 rec=1.1883 | train/val/test=1.000/0.686/0.698 | c=0.999014
[Epoch 0063] loss=12.6420 cls=0.9695 smmd=0.1627 ct=9.1402 rec=1.1848 | train/val/test=1.000/0.684/0.699 | c=0.999014
[Epoch 0064] loss=12.6400 cls=0.9632 smmd=0.1635 ct=9.1395 rec=1.1869 | train/val/test=1.000/0.686/0.700 | c=0.999014
[Epoch 0065] loss=12.6290 cls=0.9512 smmd=0.1620 ct=9.1394 rec=1.1882 | train/val/test=1.000/0.686/0.705 | c=0.999014
[Epoch 0066] loss=12.7455 cls=1.0708 smmd=0.1618 ct=9.1364 rec=1.1883 | train/val/test=1.000/0.690/0.706 | c=0.999014
[Epoch 0067] loss=12.5347 cls=0.8534 smmd=0.1630 ct=9.1337 rec=1.1923 | train/val/test=1.000/0.694/0.706 | c=0.999014
[Epoch 0068] loss=12.3678 cls=0.6975 smmd=0.1597 ct=9.1384 rec=1.1861 | train/val/test=1.000/0.692/0.709 | c=0.999014
[Epoch 0069] loss=12.2621 cls=0.6025 smmd=0.1594 ct=9.1326 rec=1.1839 | train/val/test=1.000/0.694/0.714 | c=0.999014
[Epoch 0070] loss=12.8478 cls=1.1813 smmd=0.1585 ct=9.1345 rec=1.1868 | train/val/test=1.000/0.696/0.715 | c=0.999014
[Epoch 0071] loss=12.4495 cls=0.7739 smmd=0.1589 ct=9.1410 rec=1.1878 | train/val/test=1.000/0.694/0.718 | c=0.999014
[Epoch 0072] loss=12.7362 cls=1.0647 smmd=0.1576 ct=9.1404 rec=1.1867 | train/val/test=1.000/0.692/0.719 | c=0.999014
[Epoch 0073] loss=12.2279 cls=0.5552 smmd=0.1571 ct=9.1394 rec=1.1881 | train/val/test=1.000/0.692/0.717 | c=0.999014
[Epoch 0074] loss=12.1762 cls=0.5128 smmd=0.1566 ct=9.1321 rec=1.1874 | train/val/test=1.000/0.692/0.713 | c=0.999014
[Epoch 0075] loss=12.5454 cls=0.8725 smmd=0.1563 ct=9.1402 rec=1.1882 | train/val/test=1.000/0.692/0.715 | c=0.999014
[Epoch 0076] loss=12.2135 cls=0.5481 smmd=0.1563 ct=9.1375 rec=1.1858 | train/val/test=1.000/0.690/0.712 | c=0.999014
[Epoch 0077] loss=12.1810 cls=0.5179 smmd=0.1593 ct=9.1350 rec=1.1844 | train/val/test=1.000/0.690/0.709 | c=0.999014
[Epoch 0078] loss=12.6899 cls=1.0279 smmd=0.1571 ct=9.1333 rec=1.1858 | train/val/test=1.000/0.690/0.706 | c=0.999014
[Epoch 0079] loss=12.4438 cls=0.7790 smmd=0.1556 ct=9.1397 rec=1.1847 | train/val/test=1.000/0.688/0.704 | c=0.999014
[Epoch 0080] loss=12.2976 cls=0.6423 smmd=0.1570 ct=9.1308 rec=1.1838 | train/val/test=1.000/0.688/0.704 | c=0.999014
[Epoch 0081] loss=12.8413 cls=1.1697 smmd=0.1548 ct=9.1348 rec=1.1910 | train/val/test=1.000/0.686/0.706 | c=0.999014
[Epoch 0082] loss=12.2119 cls=0.5518 smmd=0.1564 ct=9.1341 rec=1.1848 | train/val/test=1.000/0.686/0.706 | c=0.999014
[Epoch 0083] loss=12.4765 cls=0.8183 smmd=0.1558 ct=9.1331 rec=1.1847 | train/val/test=1.000/0.688/0.711 | c=0.999014
[Epoch 0084] loss=12.9162 cls=1.2558 smmd=0.1562 ct=9.1307 rec=1.1868 | train/val/test=1.000/0.684/0.712 | c=0.999014
[Epoch 0085] loss=12.5023 cls=0.8397 smmd=0.1564 ct=9.1379 rec=1.1842 | train/val/test=1.000/0.684/0.712 | c=0.999014
[Epoch 0086] loss=12.0329 cls=0.3753 smmd=0.1564 ct=9.1376 rec=1.1818 | train/val/test=1.000/0.684/0.713 | c=0.999014
[Epoch 0087] loss=12.8041 cls=1.1447 smmd=0.1580 ct=9.1281 rec=1.1867 | train/val/test=1.000/0.688/0.713 | c=0.999014
[Epoch 0088] loss=12.0935 cls=0.4379 smmd=0.1588 ct=9.1315 rec=1.1827 | train/val/test=1.000/0.688/0.714 | c=0.999014
[Epoch 0089] loss=12.4847 cls=0.8296 smmd=0.1576 ct=9.1308 rec=1.1834 | train/val/test=1.000/0.688/0.715 | c=0.999014
[Epoch 0090] loss=12.1449 cls=0.4922 smmd=0.1574 ct=9.1310 rec=1.1822 | train/val/test=1.000/0.690/0.714 | c=0.999014
[Epoch 0091] loss=12.1927 cls=0.5365 smmd=0.1572 ct=9.1345 rec=1.1822 | train/val/test=1.000/0.690/0.715 | c=0.999014
[Epoch 0092] loss=12.1669 cls=0.5116 smmd=0.1565 ct=9.1292 rec=1.1848 | train/val/test=1.000/0.690/0.715 | c=0.999014
[Epoch 0093] loss=12.1650 cls=0.5106 smmd=0.1555 ct=9.1289 rec=1.1850 | train/val/test=1.000/0.690/0.715 | c=0.999014
[Epoch 0094] loss=12.4354 cls=0.7802 smmd=0.1588 ct=9.1280 rec=1.1842 | train/val/test=1.000/0.690/0.715 | c=0.999014
[Epoch 0095] loss=12.2729 cls=0.6149 smmd=0.1567 ct=9.1313 rec=1.1850 | train/val/test=1.000/0.690/0.715 | c=0.999014
[Epoch 0096] loss=12.4485 cls=0.7868 smmd=0.1565 ct=9.1348 rec=1.1852 | train/val/test=1.000/0.690/0.715 | c=0.999014
[Epoch 0097] loss=12.4563 cls=0.7889 smmd=0.1568 ct=9.1351 rec=1.1877 | train/val/test=1.000/0.690/0.715 | c=0.999014
[Epoch 0098] loss=12.7381 cls=1.0818 smmd=0.1562 ct=9.1313 rec=1.1844 | train/val/test=1.000/0.690/0.715 | c=0.999014
[Epoch 0099] loss=12.2336 cls=0.5812 smmd=0.1567 ct=9.1330 rec=1.1814 | train/val/test=1.000/0.690/0.715 | c=0.999014
=== Best @ epoch 59: val=0.6980, test=0.7170 ===
