Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=16.5305 cls=2.1270 smmd=2.3722 ct=9.2512 rec=1.3901 | train/val/test=0.172/0.080/0.099 | c=0.999014
[Epoch 0001] loss=16.3434 cls=2.0194 smmd=2.2999 ct=9.2467 rec=1.3887 | train/val/test=0.172/0.082/0.115 | c=0.999014
[Epoch 0002] loss=16.1715 cls=1.9899 smmd=2.1518 ct=9.2424 rec=1.3937 | train/val/test=0.448/0.248/0.256 | c=0.999014
[Epoch 0003] loss=15.9291 cls=1.9306 smmd=1.9734 ct=9.2374 rec=1.3938 | train/val/test=0.414/0.318/0.366 | c=0.999014
[Epoch 0004] loss=15.5865 cls=1.8313 smmd=1.7489 ct=9.2260 rec=1.3901 | train/val/test=0.897/0.376/0.435 | c=0.999014
[Epoch 0005] loss=14.9828 cls=1.5184 smmd=1.4845 ct=9.2097 rec=1.3851 | train/val/test=0.690/0.312/0.344 | c=0.999014
[Epoch 0006] loss=14.6966 cls=1.5697 smmd=1.1801 ct=9.1860 rec=1.3804 | train/val/test=0.759/0.340/0.375 | c=0.999014
[Epoch 0007] loss=14.3961 cls=1.6418 smmd=0.8570 ct=9.1487 rec=1.3743 | train/val/test=0.862/0.380/0.412 | c=0.999014
[Epoch 0008] loss=13.9006 cls=1.5367 smmd=0.5601 ct=9.0910 rec=1.3564 | train/val/test=0.931/0.470/0.497 | c=0.999014
[Epoch 0009] loss=13.4033 cls=1.3603 smmd=0.3505 ct=9.0248 rec=1.3338 | train/val/test=0.966/0.568/0.597 | c=0.999014
[Epoch 0010] loss=13.0682 cls=1.1894 smmd=0.2565 ct=8.9793 rec=1.3215 | train/val/test=1.000/0.596/0.611 | c=0.999014
[Epoch 0011] loss=13.9309 cls=1.4423 smmd=0.2718 ct=9.6144 rec=1.3012 | train/val/test=1.000/0.526/0.547 | c=0.999014
[Epoch 0012] loss=13.6798 cls=1.2634 smmd=0.3732 ct=9.4612 rec=1.2910 | train/val/test=1.000/0.532/0.563 | c=0.999014
[Epoch 0013] loss=13.3424 cls=0.9652 smmd=0.5133 ct=9.3001 rec=1.2819 | train/val/test=1.000/0.582/0.619 | c=0.999014
[Epoch 0014] loss=13.5835 cls=1.1867 smmd=0.6593 ct=9.1866 rec=1.2755 | train/val/test=0.966/0.596/0.627 | c=0.999014
[Epoch 0015] loss=13.6080 cls=1.1857 smmd=0.7796 ct=9.1037 rec=1.2695 | train/val/test=0.966/0.620/0.663 | c=0.999014
[Epoch 0016] loss=13.0563 cls=0.6197 smmd=0.8598 ct=9.0628 rec=1.2570 | train/val/test=1.000/0.630/0.676 | c=0.999014
[Epoch 0017] loss=13.0136 cls=0.5864 smmd=0.8989 ct=9.0445 rec=1.2419 | train/val/test=1.000/0.652/0.684 | c=0.999014
[Epoch 0018] loss=13.1808 cls=0.8291 smmd=0.8690 ct=9.0316 rec=1.2255 | train/val/test=1.000/0.668/0.706 | c=0.999014
[Epoch 0019] loss=12.9262 cls=0.6830 smmd=0.8066 ct=9.0222 rec=1.2072 | train/val/test=1.000/0.658/0.679 | c=0.999014
[Epoch 0020] loss=13.3271 cls=1.1790 smmd=0.7220 ct=9.0335 rec=1.1963 | train/val/test=1.000/0.648/0.661 | c=0.999014
[Epoch 0021] loss=13.4485 cls=1.3797 smmd=0.6121 ct=9.0656 rec=1.1956 | train/val/test=1.000/0.654/0.689 | c=0.999014
[Epoch 0022] loss=13.2314 cls=1.2549 smmd=0.5077 ct=9.0854 rec=1.1918 | train/val/test=1.000/0.668/0.707 | c=0.999014
[Epoch 0023] loss=12.9483 cls=1.0425 smmd=0.4197 ct=9.1080 rec=1.1890 | train/val/test=0.966/0.660/0.709 | c=0.999014
[Epoch 0024] loss=12.6858 cls=0.8122 smmd=0.3592 ct=9.1362 rec=1.1891 | train/val/test=0.931/0.652/0.693 | c=0.999014
[Epoch 0025] loss=12.5763 cls=0.7073 smmd=0.3281 ct=9.1547 rec=1.1931 | train/val/test=0.931/0.664/0.699 | c=0.999014
[Epoch 0026] loss=13.0167 cls=1.1531 smmd=0.3085 ct=9.1672 rec=1.1940 | train/val/test=0.966/0.678/0.706 | c=0.999014
[Epoch 0027] loss=12.7293 cls=0.8507 smmd=0.3081 ct=9.1783 rec=1.1961 | train/val/test=0.966/0.674/0.703 | c=0.999014
[Epoch 0028] loss=13.1667 cls=1.2732 smmd=0.3064 ct=9.1847 rec=1.2012 | train/val/test=1.000/0.676/0.709 | c=0.999014
[Epoch 0029] loss=12.5385 cls=0.6209 smmd=0.3108 ct=9.2026 rec=1.2021 | train/val/test=1.000/0.658/0.712 | c=0.999014
[Epoch 0030] loss=13.0571 cls=1.1146 smmd=0.3053 ct=9.2186 rec=1.2093 | train/val/test=1.000/0.656/0.714 | c=0.999014
[Epoch 0031] loss=12.4627 cls=0.5297 smmd=0.2936 ct=9.2234 rec=1.2080 | train/val/test=1.000/0.668/0.713 | c=0.999014
[Epoch 0032] loss=12.7894 cls=0.8691 smmd=0.2794 ct=9.2271 rec=1.2069 | train/val/test=1.000/0.670/0.709 | c=0.999014
[Epoch 0033] loss=12.8374 cls=0.9559 smmd=0.2539 ct=9.2189 rec=1.2043 | train/val/test=0.966/0.664/0.712 | c=0.999014
[Epoch 0034] loss=12.9361 cls=1.0817 smmd=0.2418 ct=9.2067 rec=1.2029 | train/val/test=0.931/0.650/0.695 | c=0.999014
[Epoch 0035] loss=12.9346 cls=1.0812 smmd=0.2429 ct=9.1982 rec=1.2061 | train/val/test=0.931/0.658/0.699 | c=0.999014
[Epoch 0036] loss=13.1299 cls=1.2817 smmd=0.2420 ct=9.1896 rec=1.2083 | train/val/test=0.966/0.664/0.700 | c=0.999014
[Epoch 0037] loss=12.4036 cls=0.5862 smmd=0.2417 ct=9.1681 rec=1.2038 | train/val/test=0.966/0.676/0.705 | c=0.999014
[Epoch 0038] loss=12.3969 cls=0.5812 smmd=0.2452 ct=9.1656 rec=1.2025 | train/val/test=0.966/0.678/0.713 | c=0.999014
[Epoch 0039] loss=12.6917 cls=0.8763 smmd=0.2513 ct=9.1590 rec=1.2025 | train/val/test=1.000/0.680/0.725 | c=0.999014
[Epoch 0040] loss=12.9526 cls=1.1450 smmd=0.2449 ct=9.1600 rec=1.2014 | train/val/test=1.000/0.686/0.727 | c=0.999014
[Epoch 0041] loss=13.0341 cls=1.2352 smmd=0.2452 ct=9.1540 rec=1.1999 | train/val/test=1.000/0.684/0.726 | c=0.999014
[Epoch 0042] loss=12.4939 cls=0.6950 smmd=0.2416 ct=9.1578 rec=1.1997 | train/val/test=1.000/0.682/0.733 | c=0.999014
[Epoch 0043] loss=12.2643 cls=0.4736 smmd=0.2310 ct=9.1666 rec=1.1965 | train/val/test=1.000/0.686/0.725 | c=0.999014
[Epoch 0044] loss=12.6378 cls=0.8479 smmd=0.2176 ct=9.1834 rec=1.1945 | train/val/test=1.000/0.684/0.719 | c=0.999014
[Epoch 0045] loss=12.5038 cls=0.7270 smmd=0.2094 ct=9.1785 rec=1.1944 | train/val/test=1.000/0.682/0.722 | c=0.999014
[Epoch 0046] loss=12.5564 cls=0.7951 smmd=0.2018 ct=9.1832 rec=1.1881 | train/val/test=1.000/0.688/0.717 | c=0.999014
[Epoch 0047] loss=12.6710 cls=0.9099 smmd=0.1973 ct=9.1829 rec=1.1904 | train/val/test=1.000/0.684/0.710 | c=0.999014
[Epoch 0048] loss=12.5685 cls=0.8119 smmd=0.1954 ct=9.1859 rec=1.1877 | train/val/test=1.000/0.692/0.713 | c=0.999014
[Epoch 0049] loss=12.3806 cls=0.6241 smmd=0.1915 ct=9.1885 rec=1.1883 | train/val/test=1.000/0.700/0.721 | c=0.999014
[Epoch 0050] loss=12.5613 cls=0.8196 smmd=0.1872 ct=9.1859 rec=1.1843 | train/val/test=1.000/0.700/0.733 | c=0.999014
[Epoch 0051] loss=12.2690 cls=0.5333 smmd=0.1845 ct=9.1853 rec=1.1830 | train/val/test=1.000/0.698/0.731 | c=0.999014
[Epoch 0052] loss=12.4463 cls=0.7084 smmd=0.1853 ct=9.1773 rec=1.1877 | train/val/test=1.000/0.694/0.732 | c=0.999014
[Epoch 0053] loss=12.5376 cls=0.7956 smmd=0.1923 ct=9.1742 rec=1.1878 | train/val/test=1.000/0.696/0.732 | c=0.999014
[Epoch 0054] loss=12.2424 cls=0.4928 smmd=0.1927 ct=9.1756 rec=1.1906 | train/val/test=1.000/0.694/0.739 | c=0.999014
[Epoch 0055] loss=12.0046 cls=0.2768 smmd=0.1901 ct=9.1728 rec=1.1825 | train/val/test=1.000/0.696/0.741 | c=0.999014
[Epoch 0056] loss=12.3730 cls=0.6477 smmd=0.1861 ct=9.1724 rec=1.1834 | train/val/test=1.000/0.696/0.728 | c=0.999014
[Epoch 0057] loss=12.5309 cls=0.8154 smmd=0.1844 ct=9.1727 rec=1.1792 | train/val/test=1.000/0.690/0.718 | c=0.999014
[Epoch 0058] loss=12.2184 cls=0.4972 smmd=0.1808 ct=9.1912 rec=1.1746 | train/val/test=1.000/0.690/0.710 | c=0.999014
[Epoch 0059] loss=12.4286 cls=0.7083 smmd=0.1772 ct=9.1984 rec=1.1723 | train/val/test=1.000/0.688/0.707 | c=0.999014
[Epoch 0060] loss=12.6921 cls=0.9680 smmd=0.1818 ct=9.1946 rec=1.1739 | train/val/test=1.000/0.694/0.710 | c=0.999014
[Epoch 0061] loss=12.2558 cls=0.5437 smmd=0.1793 ct=9.1896 rec=1.1716 | train/val/test=1.000/0.688/0.715 | c=0.999014
[Epoch 0062] loss=12.3015 cls=0.5858 smmd=0.1809 ct=9.1837 rec=1.1756 | train/val/test=1.000/0.696/0.723 | c=0.999014
[Epoch 0063] loss=12.3108 cls=0.6091 smmd=0.1805 ct=9.1732 rec=1.1740 | train/val/test=1.000/0.694/0.728 | c=0.999014
[Epoch 0064] loss=12.3910 cls=0.6847 smmd=0.1826 ct=9.1742 rec=1.1748 | train/val/test=1.000/0.700/0.737 | c=0.999014
[Epoch 0065] loss=12.7502 cls=1.0475 smmd=0.1804 ct=9.1687 rec=1.1768 | train/val/test=1.000/0.700/0.738 | c=0.999014
[Epoch 0066] loss=11.9796 cls=0.2814 smmd=0.1849 ct=9.1669 rec=1.1732 | train/val/test=1.000/0.696/0.736 | c=0.999014
[Epoch 0067] loss=12.5740 cls=0.8742 smmd=0.1818 ct=9.1670 rec=1.1755 | train/val/test=1.000/0.692/0.732 | c=0.999014
[Epoch 0068] loss=12.4700 cls=0.7644 smmd=0.1830 ct=9.1761 rec=1.1732 | train/val/test=1.000/0.688/0.732 | c=0.999014
[Epoch 0069] loss=12.5011 cls=0.7921 smmd=0.1819 ct=9.1686 rec=1.1792 | train/val/test=1.000/0.694/0.731 | c=0.999014
[Epoch 0070] loss=12.1534 cls=0.4526 smmd=0.1805 ct=9.1674 rec=1.1764 | train/val/test=1.000/0.692/0.730 | c=0.999014
[Epoch 0071] loss=12.0199 cls=0.3255 smmd=0.1777 ct=9.1712 rec=1.1727 | train/val/test=1.000/0.696/0.729 | c=0.999014
[Epoch 0072] loss=12.7401 cls=1.0429 smmd=0.1732 ct=9.1729 rec=1.1755 | train/val/test=1.000/0.698/0.726 | c=0.999014
[Epoch 0073] loss=12.1899 cls=0.5005 smmd=0.1713 ct=9.1708 rec=1.1736 | train/val/test=1.000/0.698/0.726 | c=0.999014
[Epoch 0074] loss=12.5720 cls=0.8797 smmd=0.1719 ct=9.1710 rec=1.1747 | train/val/test=1.000/0.692/0.722 | c=0.999014
[Epoch 0075] loss=12.3428 cls=0.6563 smmd=0.1679 ct=9.1694 rec=1.1746 | train/val/test=1.000/0.686/0.719 | c=0.999014
[Epoch 0076] loss=12.2408 cls=0.5453 smmd=0.1711 ct=9.1761 rec=1.1742 | train/val/test=1.000/0.690/0.716 | c=0.999014
[Epoch 0077] loss=12.5786 cls=0.8708 smmd=0.1733 ct=9.1821 rec=1.1762 | train/val/test=1.000/0.692/0.714 | c=0.999014
[Epoch 0078] loss=12.1873 cls=0.4912 smmd=0.1743 ct=9.1686 rec=1.1766 | train/val/test=1.000/0.692/0.712 | c=0.999014
[Epoch 0079] loss=12.0429 cls=0.3506 smmd=0.1729 ct=9.1669 rec=1.1763 | train/val/test=1.000/0.690/0.711 | c=0.999014
[Epoch 0080] loss=12.6631 cls=0.9597 smmd=0.1721 ct=9.1757 rec=1.1778 | train/val/test=1.000/0.694/0.712 | c=0.999014
[Epoch 0081] loss=12.3658 cls=0.6653 smmd=0.1713 ct=9.1671 rec=1.1810 | train/val/test=1.000/0.698/0.713 | c=0.999014
[Epoch 0082] loss=12.1492 cls=0.4579 smmd=0.1674 ct=9.1749 rec=1.1745 | train/val/test=1.000/0.700/0.713 | c=0.999014
[Epoch 0083] loss=12.7382 cls=1.0439 smmd=0.1686 ct=9.1761 rec=1.1748 | train/val/test=1.000/0.702/0.715 | c=0.999014
[Epoch 0084] loss=12.7784 cls=1.0752 smmd=0.1660 ct=9.1766 rec=1.1803 | train/val/test=1.000/0.700/0.716 | c=0.999014
[Epoch 0085] loss=12.3418 cls=0.6388 smmd=0.1655 ct=9.1831 rec=1.1772 | train/val/test=1.000/0.702/0.717 | c=0.999014
[Epoch 0086] loss=12.4439 cls=0.7562 smmd=0.1662 ct=9.1728 rec=1.1743 | train/val/test=1.000/0.702/0.719 | c=0.999014
[Epoch 0087] loss=12.6081 cls=0.9195 smmd=0.1655 ct=9.1704 rec=1.1763 | train/val/test=1.000/0.702/0.721 | c=0.999014
[Epoch 0088] loss=12.5833 cls=0.8949 smmd=0.1677 ct=9.1735 rec=1.1736 | train/val/test=1.000/0.704/0.722 | c=0.999014
[Epoch 0089] loss=12.8659 cls=1.1649 smmd=0.1660 ct=9.1805 rec=1.1773 | train/val/test=1.000/0.704/0.726 | c=0.999014
[Epoch 0090] loss=12.1933 cls=0.5067 smmd=0.1661 ct=9.1693 rec=1.1756 | train/val/test=1.000/0.704/0.726 | c=0.999014
[Epoch 0091] loss=12.3242 cls=0.6375 smmd=0.1680 ct=9.1706 rec=1.1740 | train/val/test=1.000/0.706/0.727 | c=0.999014
[Epoch 0092] loss=12.2718 cls=0.5669 smmd=0.1680 ct=9.1787 rec=1.1791 | train/val/test=1.000/0.704/0.729 | c=0.999014
[Epoch 0093] loss=12.6957 cls=0.9979 smmd=0.1647 ct=9.1683 rec=1.1824 | train/val/test=1.000/0.704/0.730 | c=0.999014
[Epoch 0094] loss=12.4727 cls=0.7762 smmd=0.1676 ct=9.1763 rec=1.1763 | train/val/test=1.000/0.702/0.731 | c=0.999014
[Epoch 0095] loss=12.4172 cls=0.7332 smmd=0.1677 ct=9.1669 rec=1.1747 | train/val/test=1.000/0.702/0.731 | c=0.999014
[Epoch 0096] loss=12.1942 cls=0.5040 smmd=0.1685 ct=9.1676 rec=1.1770 | train/val/test=1.000/0.702/0.731 | c=0.999014
[Epoch 0097] loss=12.3849 cls=0.7020 smmd=0.1659 ct=9.1686 rec=1.1741 | train/val/test=1.000/0.702/0.731 | c=0.999014
[Epoch 0098] loss=12.3191 cls=0.6288 smmd=0.1666 ct=9.1737 rec=1.1750 | train/val/test=1.000/0.702/0.731 | c=0.999014
[Epoch 0099] loss=12.5001 cls=0.8121 smmd=0.1690 ct=9.1656 rec=1.1767 | train/val/test=1.000/0.702/0.731 | c=0.999014
=== Best @ epoch 91: val=0.7060, test=0.7270 ===
