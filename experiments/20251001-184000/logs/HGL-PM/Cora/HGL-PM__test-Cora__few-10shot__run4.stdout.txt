Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=16.4747 cls=2.1533 smmd=2.3211 ct=9.2203 rec=1.3900 | train/val/test=0.172/0.110/0.125 | c=0.999014
[Epoch 0001] loss=16.2242 cls=1.9958 smmd=2.2328 ct=9.2195 rec=1.3880 | train/val/test=0.155/0.072/0.091 | c=0.999014
[Epoch 0002] loss=16.1277 cls=2.0556 smmd=2.0801 ct=9.2126 rec=1.3897 | train/val/test=0.224/0.094/0.119 | c=0.999014
[Epoch 0003] loss=15.8682 cls=1.9786 smmd=1.9061 ct=9.2070 rec=1.3882 | train/val/test=0.500/0.244/0.254 | c=0.999014
[Epoch 0004] loss=15.5065 cls=1.8764 smmd=1.6606 ct=9.1957 rec=1.3869 | train/val/test=0.638/0.330/0.329 | c=0.999014
[Epoch 0005] loss=15.0109 cls=1.6862 smmd=1.3745 ct=9.1803 rec=1.3849 | train/val/test=0.793/0.418/0.429 | c=0.999014
[Epoch 0006] loss=14.6670 cls=1.6998 smmd=1.0536 ct=9.1524 rec=1.3806 | train/val/test=0.845/0.484/0.482 | c=0.999014
[Epoch 0007] loss=14.2439 cls=1.6508 smmd=0.7380 ct=9.1138 rec=1.3706 | train/val/test=0.879/0.554/0.548 | c=0.999014
[Epoch 0008] loss=13.8386 cls=1.6304 smmd=0.4591 ct=9.0453 rec=1.3519 | train/val/test=0.931/0.548/0.553 | c=0.999014
[Epoch 0009] loss=13.3782 cls=1.4565 smmd=0.2948 ct=8.9741 rec=1.3264 | train/val/test=0.948/0.614/0.628 | c=0.999014
[Epoch 0010] loss=13.2704 cls=1.4795 smmd=0.2632 ct=8.9238 rec=1.3020 | train/val/test=0.931/0.650/0.658 | c=0.999014
[Epoch 0011] loss=13.7829 cls=1.3414 smmd=0.3343 ct=9.5437 rec=1.2818 | train/val/test=0.914/0.674/0.652 | c=0.999014
[Epoch 0012] loss=13.5369 cls=1.2254 smmd=0.4502 ct=9.3480 rec=1.2566 | train/val/test=0.914/0.624/0.617 | c=0.999014
[Epoch 0013] loss=13.5410 cls=1.2682 smmd=0.5928 ct=9.1709 rec=1.2546 | train/val/test=0.914/0.626/0.611 | c=0.999014
[Epoch 0014] loss=13.4057 cls=1.1093 smmd=0.7278 ct=9.0699 rec=1.2493 | train/val/test=0.914/0.678/0.655 | c=0.999014
[Epoch 0015] loss=13.5716 cls=1.2641 smmd=0.8244 ct=9.0115 rec=1.2358 | train/val/test=0.914/0.684/0.661 | c=0.999014
[Epoch 0016] loss=13.5745 cls=1.2664 smmd=0.8793 ct=8.9800 rec=1.2244 | train/val/test=0.931/0.696/0.683 | c=0.999014
[Epoch 0017] loss=13.4309 cls=1.1551 smmd=0.8762 ct=8.9628 rec=1.2184 | train/val/test=0.931/0.694/0.686 | c=0.999014
[Epoch 0018] loss=13.1912 cls=0.9935 smmd=0.8304 ct=8.9552 rec=1.2061 | train/val/test=0.931/0.710/0.677 | c=0.999014
[Epoch 0019] loss=13.1157 cls=1.0036 smmd=0.7413 ct=8.9654 rec=1.2027 | train/val/test=0.931/0.718/0.682 | c=0.999014
[Epoch 0020] loss=13.4386 cls=1.4275 smmd=0.6263 ct=8.9886 rec=1.1981 | train/val/test=0.948/0.696/0.682 | c=0.999014
[Epoch 0021] loss=12.9827 cls=1.0628 smmd=0.5050 ct=9.0298 rec=1.1926 | train/val/test=0.948/0.706/0.698 | c=0.999014
[Epoch 0022] loss=12.7926 cls=0.9358 smmd=0.4056 ct=9.0681 rec=1.1916 | train/val/test=0.948/0.730/0.708 | c=0.999014
[Epoch 0023] loss=12.9691 cls=1.1351 smmd=0.3436 ct=9.1117 rec=1.1893 | train/val/test=0.931/0.728/0.714 | c=0.999014
[Epoch 0024] loss=13.0390 cls=1.2006 smmd=0.3120 ct=9.1441 rec=1.1911 | train/val/test=0.931/0.732/0.721 | c=0.999014
[Epoch 0025] loss=13.2067 cls=1.3578 smmd=0.3021 ct=9.1665 rec=1.1902 | train/val/test=0.948/0.732/0.728 | c=0.999014
[Epoch 0026] loss=12.8930 cls=1.0265 smmd=0.3014 ct=9.1690 rec=1.1980 | train/val/test=0.948/0.730/0.721 | c=0.999014
[Epoch 0027] loss=13.1324 cls=1.2583 smmd=0.3025 ct=9.1671 rec=1.2023 | train/val/test=0.948/0.728/0.712 | c=0.999014
[Epoch 0028] loss=13.1179 cls=1.2308 smmd=0.3053 ct=9.1634 rec=1.2092 | train/val/test=0.948/0.720/0.708 | c=0.999014
[Epoch 0029] loss=12.9792 cls=1.0798 smmd=0.3120 ct=9.1576 rec=1.2149 | train/val/test=0.948/0.718/0.704 | c=0.999014
[Epoch 0030] loss=13.0836 cls=1.1694 smmd=0.3040 ct=9.1719 rec=1.2191 | train/val/test=0.948/0.720/0.710 | c=0.999014
[Epoch 0031] loss=13.1346 cls=1.2613 smmd=0.2887 ct=9.1442 rec=1.2202 | train/val/test=0.948/0.732/0.717 | c=0.999014
[Epoch 0032] loss=12.8646 cls=1.0314 smmd=0.2702 ct=9.1314 rec=1.2158 | train/val/test=0.966/0.732/0.711 | c=0.999014
[Epoch 0033] loss=13.0227 cls=1.1946 smmd=0.2652 ct=9.1254 rec=1.2187 | train/val/test=0.966/0.730/0.718 | c=0.999014
[Epoch 0034] loss=12.9661 cls=1.1494 smmd=0.2596 ct=9.1226 rec=1.2172 | train/val/test=0.966/0.736/0.723 | c=0.999014
[Epoch 0035] loss=12.6712 cls=0.8663 smmd=0.2614 ct=9.1226 rec=1.2105 | train/val/test=0.983/0.738/0.723 | c=0.999014
[Epoch 0036] loss=12.8887 cls=1.0841 smmd=0.2548 ct=9.1213 rec=1.2142 | train/val/test=0.966/0.740/0.724 | c=0.999014
[Epoch 0037] loss=12.9033 cls=1.1222 smmd=0.2516 ct=9.1172 rec=1.2062 | train/val/test=0.966/0.738/0.718 | c=0.999014
[Epoch 0038] loss=12.8857 cls=1.1098 smmd=0.2477 ct=9.1190 rec=1.2046 | train/val/test=0.966/0.736/0.716 | c=0.999014
[Epoch 0039] loss=12.7767 cls=1.0125 smmd=0.2389 ct=9.1213 rec=1.2020 | train/val/test=0.966/0.738/0.717 | c=0.999014
[Epoch 0040] loss=12.5791 cls=0.8166 smmd=0.2358 ct=9.1357 rec=1.1955 | train/val/test=0.966/0.736/0.721 | c=0.999014
[Epoch 0041] loss=12.5879 cls=0.8376 smmd=0.2310 ct=9.1315 rec=1.1939 | train/val/test=0.966/0.738/0.720 | c=0.999014
[Epoch 0042] loss=12.7578 cls=1.0320 smmd=0.2250 ct=9.1233 rec=1.1888 | train/val/test=0.983/0.738/0.726 | c=0.999014
[Epoch 0043] loss=12.6871 cls=0.9761 smmd=0.2180 ct=9.1168 rec=1.1881 | train/val/test=0.983/0.740/0.731 | c=0.999014
[Epoch 0044] loss=12.7775 cls=1.0682 smmd=0.2115 ct=9.1201 rec=1.1888 | train/val/test=0.983/0.740/0.729 | c=0.999014
[Epoch 0045] loss=12.7497 cls=1.0463 smmd=0.2048 ct=9.1269 rec=1.1859 | train/val/test=0.983/0.736/0.723 | c=0.999014
[Epoch 0046] loss=12.4924 cls=0.7931 smmd=0.1998 ct=9.1274 rec=1.1860 | train/val/test=0.983/0.732/0.717 | c=0.999014
[Epoch 0047] loss=12.5203 cls=0.8159 smmd=0.1985 ct=9.1356 rec=1.1851 | train/val/test=0.966/0.732/0.712 | c=0.999014
[Epoch 0048] loss=12.7589 cls=1.0563 smmd=0.1921 ct=9.1366 rec=1.1870 | train/val/test=0.966/0.722/0.708 | c=0.999014
[Epoch 0049] loss=12.7574 cls=1.0804 smmd=0.1875 ct=9.1291 rec=1.1802 | train/val/test=0.983/0.726/0.708 | c=0.999014
[Epoch 0050] loss=12.5613 cls=0.8827 smmd=0.1844 ct=9.1360 rec=1.1791 | train/val/test=0.983/0.730/0.720 | c=0.999014
[Epoch 0051] loss=12.7715 cls=1.0895 smmd=0.1811 ct=9.1330 rec=1.1840 | train/val/test=0.983/0.742/0.728 | c=0.999014
[Epoch 0052] loss=12.9833 cls=1.3013 smmd=0.1829 ct=9.1296 rec=1.1848 | train/val/test=0.983/0.742/0.732 | c=0.999014
[Epoch 0053] loss=12.6022 cls=0.9202 smmd=0.1819 ct=9.1366 rec=1.1818 | train/val/test=0.983/0.746/0.735 | c=0.999014
[Epoch 0054] loss=12.4828 cls=0.8017 smmd=0.1851 ct=9.1275 rec=1.1843 | train/val/test=0.966/0.738/0.733 | c=0.999014
[Epoch 0055] loss=12.7525 cls=1.0695 smmd=0.1887 ct=9.1248 rec=1.1847 | train/val/test=0.966/0.742/0.730 | c=0.999014
[Epoch 0056] loss=12.8507 cls=1.1586 smmd=0.1868 ct=9.1271 rec=1.1891 | train/val/test=0.966/0.728/0.722 | c=0.999014
[Epoch 0057] loss=12.6390 cls=0.9653 smmd=0.1877 ct=9.1184 rec=1.1838 | train/val/test=0.966/0.722/0.720 | c=0.999014
[Epoch 0058] loss=12.7323 cls=1.0595 smmd=0.1881 ct=9.1160 rec=1.1843 | train/val/test=0.966/0.726/0.718 | c=0.999014
[Epoch 0059] loss=12.6875 cls=1.0019 smmd=0.1852 ct=9.1212 rec=1.1896 | train/val/test=0.966/0.726/0.721 | c=0.999014
[Epoch 0060] loss=12.9661 cls=1.2837 smmd=0.1845 ct=9.1132 rec=1.1924 | train/val/test=0.966/0.728/0.721 | c=0.999014
[Epoch 0061] loss=12.5096 cls=0.8324 smmd=0.1825 ct=9.1193 rec=1.1877 | train/val/test=0.966/0.726/0.725 | c=0.999014
[Epoch 0062] loss=12.7160 cls=1.0449 smmd=0.1788 ct=9.1139 rec=1.1892 | train/val/test=0.966/0.730/0.733 | c=0.999014
[Epoch 0063] loss=12.6941 cls=1.0221 smmd=0.1805 ct=9.1118 rec=1.1898 | train/val/test=0.983/0.736/0.733 | c=0.999014
[Epoch 0064] loss=12.6963 cls=1.0115 smmd=0.1803 ct=9.1240 rec=1.1902 | train/val/test=0.983/0.734/0.732 | c=0.999014
[Epoch 0065] loss=12.6787 cls=1.0032 smmd=0.1795 ct=9.1197 rec=1.1881 | train/val/test=0.983/0.736/0.733 | c=0.999014
[Epoch 0066] loss=12.6710 cls=0.9996 smmd=0.1778 ct=9.1141 rec=1.1897 | train/val/test=0.983/0.736/0.733 | c=0.999014
[Epoch 0067] loss=12.4768 cls=0.8061 smmd=0.1793 ct=9.1164 rec=1.1875 | train/val/test=0.983/0.736/0.732 | c=0.999014
[Epoch 0068] loss=12.7269 cls=1.0501 smmd=0.1770 ct=9.1235 rec=1.1881 | train/val/test=0.983/0.734/0.732 | c=0.999014
[Epoch 0069] loss=12.8260 cls=1.1464 smmd=0.1782 ct=9.1169 rec=1.1922 | train/val/test=0.983/0.730/0.725 | c=0.999014
[Epoch 0070] loss=13.0205 cls=1.3385 smmd=0.1755 ct=9.1252 rec=1.1907 | train/val/test=0.983/0.730/0.724 | c=0.999014
[Epoch 0071] loss=12.3824 cls=0.7137 smmd=0.1775 ct=9.1158 rec=1.1877 | train/val/test=0.983/0.732/0.723 | c=0.999014
[Epoch 0072] loss=12.5142 cls=0.8479 smmd=0.1814 ct=9.1161 rec=1.1844 | train/val/test=0.983/0.730/0.723 | c=0.999014
[Epoch 0073] loss=12.6931 cls=1.0323 smmd=0.1781 ct=9.1103 rec=1.1862 | train/val/test=0.966/0.732/0.724 | c=0.999014
[Epoch 0074] loss=12.7606 cls=1.1058 smmd=0.1813 ct=9.1084 rec=1.1825 | train/val/test=0.983/0.730/0.724 | c=0.999014
[Epoch 0075] loss=12.4416 cls=0.7845 smmd=0.1819 ct=9.1067 rec=1.1842 | train/val/test=0.983/0.728/0.728 | c=0.999014
[Epoch 0076] loss=12.3966 cls=0.7381 smmd=0.1775 ct=9.1146 rec=1.1832 | train/val/test=0.983/0.728/0.729 | c=0.999014
[Epoch 0077] loss=12.6935 cls=1.0216 smmd=0.1828 ct=9.1172 rec=1.1859 | train/val/test=0.983/0.732/0.732 | c=0.999014
[Epoch 0078] loss=12.6326 cls=0.9746 smmd=0.1784 ct=9.1118 rec=1.1839 | train/val/test=0.983/0.730/0.729 | c=0.999014
[Epoch 0079] loss=12.8792 cls=1.2001 smmd=0.1803 ct=9.1201 rec=1.1893 | train/val/test=0.983/0.730/0.730 | c=0.999014
[Epoch 0080] loss=12.5082 cls=0.8473 smmd=0.1788 ct=9.1119 rec=1.1851 | train/val/test=0.983/0.730/0.729 | c=0.999014
[Epoch 0081] loss=12.5376 cls=0.8855 smmd=0.1783 ct=9.1120 rec=1.1809 | train/val/test=0.983/0.730/0.729 | c=0.999014
[Epoch 0082] loss=12.7600 cls=1.0895 smmd=0.1783 ct=9.1195 rec=1.1864 | train/val/test=0.983/0.730/0.729 | c=0.999014
[Epoch 0083] loss=12.4684 cls=0.7908 smmd=0.1782 ct=9.1243 rec=1.1876 | train/val/test=0.983/0.730/0.728 | c=0.999014
[Epoch 0084] loss=12.5020 cls=0.8478 smmd=0.1778 ct=9.1137 rec=1.1813 | train/val/test=0.983/0.730/0.728 | c=0.999014
[Epoch 0085] loss=12.4592 cls=0.7923 smmd=0.1791 ct=9.1191 rec=1.1844 | train/val/test=0.983/0.732/0.727 | c=0.999014
[Epoch 0086] loss=12.7244 cls=1.0771 smmd=0.1770 ct=9.1111 rec=1.1796 | train/val/test=0.983/0.732/0.727 | c=0.999014
[Epoch 0087] loss=12.5331 cls=0.8735 smmd=0.1786 ct=9.1112 rec=1.1848 | train/val/test=0.983/0.732/0.729 | c=0.999014
[Epoch 0088] loss=12.7983 cls=1.1333 smmd=0.1812 ct=9.1199 rec=1.1820 | train/val/test=0.983/0.732/0.729 | c=0.999014
[Epoch 0089] loss=12.4662 cls=0.8086 smmd=0.1790 ct=9.1088 rec=1.1849 | train/val/test=0.983/0.732/0.729 | c=0.999014
[Epoch 0090] loss=12.6666 cls=1.0108 smmd=0.1796 ct=9.1113 rec=1.1824 | train/val/test=0.983/0.732/0.729 | c=0.999014
[Epoch 0091] loss=12.6950 cls=1.0396 smmd=0.1797 ct=9.1088 rec=1.1835 | train/val/test=0.983/0.732/0.726 | c=0.999014
[Epoch 0092] loss=12.6123 cls=0.9599 smmd=0.1805 ct=9.1081 rec=1.1819 | train/val/test=0.983/0.732/0.727 | c=0.999014
[Epoch 0093] loss=12.7890 cls=1.1319 smmd=0.1823 ct=9.1072 rec=1.1838 | train/val/test=0.983/0.732/0.727 | c=0.999014
[Epoch 0094] loss=12.4568 cls=0.8091 smmd=0.1804 ct=9.1118 rec=1.1778 | train/val/test=0.983/0.732/0.727 | c=0.999014
[Epoch 0095] loss=12.4836 cls=0.8298 smmd=0.1788 ct=9.1075 rec=1.1837 | train/val/test=0.983/0.732/0.727 | c=0.999014
[Epoch 0096] loss=12.6100 cls=0.9526 smmd=0.1812 ct=9.1052 rec=1.1855 | train/val/test=0.983/0.732/0.727 | c=0.999014
[Epoch 0097] loss=12.5418 cls=0.8838 smmd=0.1801 ct=9.1062 rec=1.1858 | train/val/test=0.983/0.732/0.727 | c=0.999014
[Epoch 0098] loss=12.6761 cls=1.0194 smmd=0.1791 ct=9.1123 rec=1.1827 | train/val/test=0.983/0.732/0.727 | c=0.999014
[Epoch 0099] loss=12.5200 cls=0.8557 smmd=0.1817 ct=9.1091 rec=1.1868 | train/val/test=0.983/0.732/0.727 | c=0.999014
=== Best @ epoch 53: val=0.7460, test=0.7350 ===
