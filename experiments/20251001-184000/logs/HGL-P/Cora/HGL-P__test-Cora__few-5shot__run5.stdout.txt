Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.1446 cls=2.1259 smmd=3.9692 ct=9.2640 rec=1.3928 | train/val/test=0.345/0.136/0.133 | c=0.998437
[Epoch 0001] loss=17.8806 cls=1.9693 smmd=3.8759 ct=9.2583 rec=1.3886 | train/val/test=0.276/0.092/0.100 | c=0.998437
[Epoch 0002] loss=17.6929 cls=1.9112 smmd=3.7485 ct=9.2502 rec=1.3915 | train/val/test=0.310/0.102/0.116 | c=0.998437
[Epoch 0003] loss=17.4856 cls=1.8796 smmd=3.5791 ct=9.2425 rec=1.3922 | train/val/test=0.586/0.268/0.265 | c=0.998437
[Epoch 0004] loss=17.3285 cls=1.9838 smmd=3.3430 ct=9.2248 rec=1.3885 | train/val/test=0.586/0.404/0.413 | c=0.998437
[Epoch 0005] loss=16.6727 cls=1.6654 smmd=3.0331 ct=9.2024 rec=1.3859 | train/val/test=0.724/0.490/0.464 | c=0.998437
[Epoch 0006] loss=16.0802 cls=1.4781 smmd=2.6806 ct=9.1651 rec=1.3782 | train/val/test=0.828/0.390/0.385 | c=0.998437
[Epoch 0007] loss=15.3362 cls=1.2179 smmd=2.2701 ct=9.1173 rec=1.3654 | train/val/test=0.931/0.378/0.383 | c=0.998437
[Epoch 0008] loss=15.0391 cls=1.4682 smmd=1.8111 ct=9.0633 rec=1.3482 | train/val/test=0.966/0.434/0.424 | c=0.998437
[Epoch 0009] loss=14.5968 cls=1.5083 smmd=1.4410 ct=8.9994 rec=1.3240 | train/val/test=0.966/0.574/0.602 | c=0.998437
[Epoch 0010] loss=13.7550 cls=1.0289 smmd=1.2063 ct=8.9286 rec=1.2956 | train/val/test=0.966/0.588/0.617 | c=0.998437
[Epoch 0011] loss=13.9259 cls=1.2039 smmd=1.2450 ct=8.9146 rec=1.2812 | train/val/test=0.966/0.560/0.593 | c=0.998437
[Epoch 0012] loss=13.8559 cls=1.0268 smmd=1.4058 ct=8.8883 rec=1.2675 | train/val/test=0.966/0.562/0.576 | c=0.998437
[Epoch 0013] loss=14.2678 cls=1.2876 smmd=1.5977 ct=8.8668 rec=1.2578 | train/val/test=0.931/0.584/0.616 | c=0.998437
[Epoch 0014] loss=14.2224 cls=1.1406 smmd=1.7601 ct=8.8367 rec=1.2425 | train/val/test=0.966/0.624/0.653 | c=0.998437
[Epoch 0015] loss=14.0684 cls=0.9009 smmd=1.8328 ct=8.8481 rec=1.2433 | train/val/test=1.000/0.634/0.654 | c=0.998437
[Epoch 0016] loss=14.5734 cls=1.4758 smmd=1.8123 ct=8.8218 rec=1.2317 | train/val/test=0.966/0.594/0.605 | c=0.998437
[Epoch 0017] loss=14.3329 cls=1.3075 smmd=1.7396 ct=8.8234 rec=1.2312 | train/val/test=0.966/0.580/0.603 | c=0.998437
[Epoch 0018] loss=13.9224 cls=1.0290 smmd=1.6125 ct=8.8173 rec=1.2318 | train/val/test=1.000/0.634/0.647 | c=0.998437
[Epoch 0019] loss=14.3641 cls=1.0064 smmd=1.4300 ct=9.4714 rec=1.2281 | train/val/test=0.966/0.640/0.662 | c=0.998437
[Epoch 0020] loss=13.9148 cls=0.7664 smmd=1.2816 ct=9.4137 rec=1.2265 | train/val/test=0.966/0.654/0.659 | c=0.998437
[Epoch 0021] loss=13.7487 cls=0.7327 smmd=1.2158 ct=9.3367 rec=1.2318 | train/val/test=0.966/0.646/0.661 | c=0.998437
[Epoch 0022] loss=14.1963 cls=1.2370 smmd=1.2190 ct=9.2720 rec=1.2342 | train/val/test=0.966/0.646/0.660 | c=0.998437
[Epoch 0023] loss=14.0236 cls=1.0388 smmd=1.3010 ct=9.2257 rec=1.2291 | train/val/test=0.966/0.624/0.665 | c=0.998437
[Epoch 0024] loss=13.8975 cls=0.8618 smmd=1.3914 ct=9.1936 rec=1.2254 | train/val/test=0.966/0.620/0.654 | c=0.998437
[Epoch 0025] loss=13.8522 cls=0.8107 smmd=1.4228 ct=9.1909 rec=1.2138 | train/val/test=1.000/0.604/0.636 | c=0.998437
[Epoch 0026] loss=14.2552 cls=1.2035 smmd=1.4099 ct=9.2126 rec=1.2146 | train/val/test=1.000/0.616/0.643 | c=0.998437
[Epoch 0027] loss=13.5840 cls=0.5707 smmd=1.3719 ct=9.2294 rec=1.2060 | train/val/test=1.000/0.622/0.664 | c=0.998437
[Epoch 0028] loss=13.6479 cls=0.6821 smmd=1.2913 ct=9.2676 rec=1.2034 | train/val/test=1.000/0.636/0.685 | c=0.998437
[Epoch 0029] loss=14.1422 cls=1.2730 smmd=1.1873 ct=9.2839 rec=1.1990 | train/val/test=1.000/0.648/0.697 | c=0.998437
[Epoch 0030] loss=13.5685 cls=0.7304 smmd=1.1213 ct=9.3161 rec=1.2004 | train/val/test=1.000/0.656/0.702 | c=0.998437
[Epoch 0031] loss=13.5415 cls=0.7391 smmd=1.0694 ct=9.3318 rec=1.2006 | train/val/test=1.000/0.652/0.692 | c=0.998437
[Epoch 0032] loss=14.1155 cls=1.3618 smmd=1.0299 ct=9.3350 rec=1.1944 | train/val/test=1.000/0.648/0.683 | c=0.998437
[Epoch 0033] loss=13.4550 cls=0.7064 smmd=1.0210 ct=9.3342 rec=1.1967 | train/val/test=1.000/0.630/0.668 | c=0.998437
[Epoch 0034] loss=14.2785 cls=1.5207 smmd=1.0154 ct=9.3406 rec=1.2009 | train/val/test=1.000/0.626/0.660 | c=0.998437
[Epoch 0035] loss=14.0047 cls=1.2375 smmd=1.0403 ct=9.3252 rec=1.2008 | train/val/test=1.000/0.620/0.659 | c=0.998437
[Epoch 0036] loss=13.5699 cls=0.8387 smmd=1.0157 ct=9.3002 rec=1.2077 | train/val/test=1.000/0.632/0.670 | c=0.998437
[Epoch 0037] loss=13.6323 cls=0.8979 smmd=1.0404 ct=9.2786 rec=1.2077 | train/val/test=1.000/0.628/0.671 | c=0.998437
[Epoch 0038] loss=13.6444 cls=0.9381 smmd=1.0083 ct=9.2788 rec=1.2096 | train/val/test=1.000/0.648/0.675 | c=0.998437
[Epoch 0039] loss=13.3347 cls=0.6442 smmd=0.9843 ct=9.2838 rec=1.2112 | train/val/test=1.000/0.644/0.679 | c=0.998437
[Epoch 0040] loss=13.4483 cls=0.8096 smmd=0.9520 ct=9.2773 rec=1.2047 | train/val/test=1.000/0.638/0.663 | c=0.998437
[Epoch 0041] loss=13.7604 cls=1.1139 smmd=0.9312 ct=9.2964 rec=1.2095 | train/val/test=1.000/0.642/0.658 | c=0.998437
[Epoch 0042] loss=14.0285 cls=1.3861 smmd=0.9095 ct=9.3099 rec=1.2115 | train/val/test=1.000/0.628/0.670 | c=0.998437
[Epoch 0043] loss=13.6001 cls=0.9886 smmd=0.8789 ct=9.3122 rec=1.2102 | train/val/test=1.000/0.638/0.682 | c=0.998437
[Epoch 0044] loss=13.3619 cls=0.7910 smmd=0.8512 ct=9.2955 rec=1.2121 | train/val/test=1.000/0.642/0.679 | c=0.998437
[Epoch 0045] loss=13.6190 cls=1.0515 smmd=0.8260 ct=9.2978 rec=1.2218 | train/val/test=1.000/0.638/0.678 | c=0.998437
[Epoch 0046] loss=13.4456 cls=0.9068 smmd=0.8107 ct=9.3021 rec=1.2131 | train/val/test=1.000/0.636/0.676 | c=0.998437
[Epoch 0047] loss=13.3296 cls=0.8255 smmd=0.7872 ct=9.2964 rec=1.2103 | train/val/test=1.000/0.636/0.677 | c=0.998437
[Epoch 0048] loss=13.3693 cls=0.8840 smmd=0.7672 ct=9.2965 rec=1.2108 | train/val/test=1.000/0.640/0.679 | c=0.998437
[Epoch 0049] loss=13.5746 cls=1.1122 smmd=0.7528 ct=9.2968 rec=1.2064 | train/val/test=1.000/0.636/0.679 | c=0.998437
[Epoch 0050] loss=13.5233 cls=1.0779 smmd=0.7325 ct=9.3073 rec=1.2028 | train/val/test=1.000/0.648/0.681 | c=0.998437
[Epoch 0051] loss=13.1133 cls=0.6916 smmd=0.7246 ct=9.3000 rec=1.1986 | train/val/test=1.000/0.646/0.679 | c=0.998437
[Epoch 0052] loss=13.5960 cls=1.1753 smmd=0.7260 ct=9.2945 rec=1.2001 | train/val/test=1.000/0.650/0.678 | c=0.998437
[Epoch 0053] loss=13.0610 cls=0.6812 smmd=0.7063 ct=9.2841 rec=1.1947 | train/val/test=1.000/0.640/0.665 | c=0.998437
[Epoch 0054] loss=13.6476 cls=1.2769 smmd=0.7024 ct=9.2845 rec=1.1919 | train/val/test=1.000/0.638/0.658 | c=0.998437
[Epoch 0055] loss=13.1426 cls=0.8017 smmd=0.6688 ct=9.2933 rec=1.1894 | train/val/test=1.000/0.636/0.664 | c=0.998437
[Epoch 0056] loss=13.0086 cls=0.6846 smmd=0.6453 ct=9.2953 rec=1.1917 | train/val/test=1.000/0.634/0.666 | c=0.998437
[Epoch 0057] loss=13.1931 cls=0.8676 smmd=0.6562 ct=9.2887 rec=1.1903 | train/val/test=1.000/0.650/0.675 | c=0.998437
[Epoch 0058] loss=13.1883 cls=0.9037 smmd=0.6119 ct=9.2851 rec=1.1938 | train/val/test=1.000/0.646/0.674 | c=0.998437
[Epoch 0059] loss=13.5365 cls=1.2579 smmd=0.6136 ct=9.2852 rec=1.1899 | train/val/test=1.000/0.640/0.664 | c=0.998437
[Epoch 0060] loss=13.3626 cls=1.0909 smmd=0.5965 ct=9.2907 rec=1.1922 | train/val/test=1.000/0.636/0.665 | c=0.998437
[Epoch 0061] loss=13.1020 cls=0.8506 smmd=0.5628 ct=9.2889 rec=1.1998 | train/val/test=1.000/0.636/0.664 | c=0.998437
[Epoch 0062] loss=12.9864 cls=0.7259 smmd=0.5718 ct=9.3013 rec=1.1937 | train/val/test=1.000/0.640/0.667 | c=0.998437
[Epoch 0063] loss=12.9107 cls=0.6826 smmd=0.5426 ct=9.3027 rec=1.1914 | train/val/test=1.000/0.640/0.668 | c=0.998437
[Epoch 0064] loss=13.5263 cls=1.2892 smmd=0.5494 ct=9.2989 rec=1.1945 | train/val/test=1.000/0.648/0.666 | c=0.998437
[Epoch 0065] loss=13.4063 cls=1.1867 smmd=0.5296 ct=9.2924 rec=1.1988 | train/val/test=1.000/0.654/0.667 | c=0.998437
[Epoch 0066] loss=13.0096 cls=0.8157 smmd=0.5142 ct=9.2897 rec=1.1950 | train/val/test=1.000/0.656/0.658 | c=0.998437
[Epoch 0067] loss=13.3688 cls=1.1877 smmd=0.5174 ct=9.2889 rec=1.1874 | train/val/test=1.000/0.660/0.656 | c=0.998437
[Epoch 0068] loss=12.6854 cls=0.4900 smmd=0.5275 ct=9.2908 rec=1.1886 | train/val/test=1.000/0.664/0.655 | c=0.998437
[Epoch 0069] loss=13.1975 cls=0.9855 smmd=0.5225 ct=9.2900 rec=1.1998 | train/val/test=1.000/0.660/0.656 | c=0.998437
[Epoch 0070] loss=13.0167 cls=0.8392 smmd=0.5034 ct=9.2919 rec=1.1911 | train/val/test=1.000/0.660/0.656 | c=0.998437
[Epoch 0071] loss=13.0175 cls=0.8481 smmd=0.4914 ct=9.2918 rec=1.1931 | train/val/test=1.000/0.656/0.662 | c=0.998437
[Epoch 0072] loss=12.8932 cls=0.7310 smmd=0.4951 ct=9.2851 rec=1.1909 | train/val/test=1.000/0.654/0.668 | c=0.998437
[Epoch 0073] loss=13.1501 cls=1.0064 smmd=0.4811 ct=9.2817 rec=1.1904 | train/val/test=1.000/0.656/0.668 | c=0.998437
[Epoch 0074] loss=13.4959 cls=1.3439 smmd=0.4814 ct=9.2812 rec=1.1947 | train/val/test=1.000/0.658/0.667 | c=0.998437
[Epoch 0075] loss=12.6541 cls=0.5285 smmd=0.4657 ct=9.2793 rec=1.1902 | train/val/test=1.000/0.666/0.665 | c=0.998437
[Epoch 0076] loss=12.9280 cls=0.8040 smmd=0.4650 ct=9.2772 rec=1.1909 | train/val/test=1.000/0.660/0.666 | c=0.998437
[Epoch 0077] loss=13.5805 cls=1.4209 smmd=0.4749 ct=9.2807 rec=1.2020 | train/val/test=1.000/0.664/0.666 | c=0.998437
[Epoch 0078] loss=13.0381 cls=0.8857 smmd=0.4728 ct=9.2824 rec=1.1986 | train/val/test=1.000/0.662/0.664 | c=0.998437
[Epoch 0079] loss=13.2143 cls=1.0858 smmd=0.4520 ct=9.2843 rec=1.1961 | train/val/test=1.000/0.660/0.664 | c=0.998437
[Epoch 0080] loss=13.1664 cls=1.0464 smmd=0.4383 ct=9.2846 rec=1.1986 | train/val/test=1.000/0.656/0.664 | c=0.998437
[Epoch 0081] loss=12.8831 cls=0.7670 smmd=0.4530 ct=9.2849 rec=1.1891 | train/val/test=1.000/0.654/0.665 | c=0.998437
[Epoch 0082] loss=13.5324 cls=1.3890 smmd=0.4517 ct=9.2864 rec=1.2026 | train/val/test=1.000/0.656/0.664 | c=0.998437
[Epoch 0083] loss=12.9133 cls=0.8075 smmd=0.4288 ct=9.2899 rec=1.1935 | train/val/test=1.000/0.656/0.662 | c=0.998437
[Epoch 0084] loss=12.8954 cls=0.7951 smmd=0.4264 ct=9.2889 rec=1.1925 | train/val/test=1.000/0.656/0.662 | c=0.998437
[Epoch 0085] loss=13.0173 cls=0.9089 smmd=0.4353 ct=9.2863 rec=1.1934 | train/val/test=1.000/0.658/0.663 | c=0.998437
[Epoch 0086] loss=13.0582 cls=0.9333 smmd=0.4400 ct=9.2881 rec=1.1984 | train/val/test=1.000/0.660/0.662 | c=0.998437
[Epoch 0087] loss=13.1930 cls=1.0739 smmd=0.4358 ct=9.2842 rec=1.1995 | train/val/test=1.000/0.660/0.663 | c=0.998437
[Epoch 0088] loss=12.9663 cls=0.8500 smmd=0.4400 ct=9.2866 rec=1.1948 | train/val/test=1.000/0.662/0.662 | c=0.998437
[Epoch 0089] loss=13.1290 cls=1.0177 smmd=0.4330 ct=9.2855 rec=1.1964 | train/val/test=1.000/0.662/0.662 | c=0.998437
[Epoch 0090] loss=12.9356 cls=0.7980 smmd=0.4357 ct=9.2882 rec=1.2068 | train/val/test=1.000/0.662/0.662 | c=0.998437
[Epoch 0091] loss=12.9866 cls=0.8872 smmd=0.4223 ct=9.2922 rec=1.1924 | train/val/test=1.000/0.660/0.664 | c=0.998437
[Epoch 0092] loss=13.0453 cls=0.9151 smmd=0.4277 ct=9.2919 rec=1.2053 | train/val/test=1.000/0.660/0.665 | c=0.998437
[Epoch 0093] loss=12.9542 cls=0.8493 smmd=0.4219 ct=9.2866 rec=1.1982 | train/val/test=1.000/0.660/0.666 | c=0.998437
[Epoch 0094] loss=12.9917 cls=0.8746 smmd=0.4355 ct=9.2876 rec=1.1970 | train/val/test=1.000/0.660/0.665 | c=0.998437
[Epoch 0095] loss=12.9523 cls=0.8642 smmd=0.4132 ct=9.2811 rec=1.1969 | train/val/test=1.000/0.660/0.666 | c=0.998437
[Epoch 0096] loss=12.9042 cls=0.7762 smmd=0.4388 ct=9.2918 rec=1.1987 | train/val/test=1.000/0.660/0.666 | c=0.998437
[Epoch 0097] loss=12.9857 cls=0.8817 smmd=0.4200 ct=9.2863 rec=1.1988 | train/val/test=1.000/0.660/0.666 | c=0.998437
[Epoch 0098] loss=13.1396 cls=1.0254 smmd=0.4357 ct=9.2852 rec=1.1967 | train/val/test=1.000/0.660/0.666 | c=0.998437
[Epoch 0099] loss=13.1706 cls=1.0651 smmd=0.4233 ct=9.2846 rec=1.1988 | train/val/test=1.000/0.660/0.666 | c=0.998437
=== Best @ epoch 75: val=0.6660, test=0.6650 ===
