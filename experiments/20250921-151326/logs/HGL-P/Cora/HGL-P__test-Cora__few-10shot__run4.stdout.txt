Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.1327 cls=1.9493 smmd=4.1430 ct=9.2627 rec=1.3889 | train/val/test=0.414/0.276/0.276 | c=0.998437
[Epoch 0001] loss=16.5876 cls=1.9081 smmd=2.6925 ct=9.2082 rec=1.3894 | train/val/test=0.310/0.158/0.165 | c=0.998437
[Epoch 0002] loss=15.1813 cls=1.7897 smmd=1.4681 ct=9.1461 rec=1.3887 | train/val/test=0.534/0.360/0.330 | c=0.998437
[Epoch 0003] loss=14.9340 cls=1.5654 smmd=1.4853 ct=9.1085 rec=1.3874 | train/val/test=0.621/0.396/0.405 | c=0.998437
[Epoch 0004] loss=14.6959 cls=1.2979 smmd=1.6808 ct=8.9619 rec=1.3776 | train/val/test=0.897/0.518/0.537 | c=0.998437
[Epoch 0005] loss=14.2083 cls=0.9724 smmd=1.6077 ct=8.8994 rec=1.3644 | train/val/test=0.897/0.560/0.569 | c=0.998437
[Epoch 0006] loss=13.5321 cls=0.6971 smmd=1.3067 ct=8.8504 rec=1.3390 | train/val/test=0.897/0.580/0.572 | c=0.998437
[Epoch 0007] loss=13.6258 cls=0.5141 smmd=1.0323 ct=9.4625 rec=1.3084 | train/val/test=0.966/0.606/0.609 | c=0.998437
[Epoch 0008] loss=13.3087 cls=0.3302 smmd=1.0518 ct=9.3644 rec=1.2811 | train/val/test=1.000/0.660/0.654 | c=0.998437
[Epoch 0009] loss=13.2725 cls=0.2077 smmd=1.2369 ct=9.3141 rec=1.2569 | train/val/test=1.000/0.668/0.671 | c=0.998437
[Epoch 0010] loss=13.1866 cls=0.1315 smmd=1.2870 ct=9.2950 rec=1.2365 | train/val/test=1.000/0.662/0.658 | c=0.998437
[Epoch 0011] loss=12.9346 cls=0.0789 smmd=1.1053 ct=9.3078 rec=1.2213 | train/val/test=1.000/0.664/0.651 | c=0.998437
[Epoch 0012] loss=12.7535 cls=0.0470 smmd=0.9403 ct=9.3455 rec=1.2104 | train/val/test=1.000/0.670/0.661 | c=0.998437
[Epoch 0013] loss=12.6185 cls=0.0302 smmd=0.8046 ct=9.3831 rec=1.2003 | train/val/test=1.000/0.692/0.673 | c=0.998437
[Epoch 0014] loss=12.5614 cls=0.0223 smmd=0.7500 ct=9.4030 rec=1.1931 | train/val/test=1.000/0.694/0.679 | c=0.998437
[Epoch 0015] loss=12.4703 cls=0.0172 smmd=0.6782 ct=9.3964 rec=1.1893 | train/val/test=1.000/0.704/0.679 | c=0.998437
[Epoch 0016] loss=12.3901 cls=0.0133 smmd=0.6348 ct=9.3690 rec=1.1865 | train/val/test=1.000/0.694/0.675 | c=0.998437
[Epoch 0017] loss=12.3465 cls=0.0125 smmd=0.6209 ct=9.3429 rec=1.1851 | train/val/test=1.000/0.696/0.677 | c=0.998437
[Epoch 0018] loss=12.2415 cls=0.0127 smmd=0.5262 ct=9.3323 rec=1.1852 | train/val/test=1.000/0.716/0.678 | c=0.998437
[Epoch 0019] loss=12.2090 cls=0.0135 smmd=0.4832 ct=9.3385 rec=1.1869 | train/val/test=1.000/0.710/0.674 | c=0.998437
[Epoch 0020] loss=12.1337 cls=0.0149 smmd=0.3901 ct=9.3500 rec=1.1894 | train/val/test=1.000/0.712/0.669 | c=0.998437
[Epoch 0021] loss=12.0930 cls=0.0165 smmd=0.3403 ct=9.3541 rec=1.1911 | train/val/test=1.000/0.708/0.672 | c=0.998437
[Epoch 0022] loss=12.0632 cls=0.0190 smmd=0.3065 ct=9.3535 rec=1.1921 | train/val/test=1.000/0.706/0.670 | c=0.998437
[Epoch 0023] loss=12.0279 cls=0.0231 smmd=0.2647 ct=9.3539 rec=1.1931 | train/val/test=1.000/0.708/0.671 | c=0.998437
[Epoch 0024] loss=12.0005 cls=0.0261 smmd=0.2393 ct=9.3528 rec=1.1912 | train/val/test=1.000/0.710/0.670 | c=0.998437
[Epoch 0025] loss=11.9705 cls=0.0290 smmd=0.2065 ct=9.3587 rec=1.1882 | train/val/test=1.000/0.722/0.685 | c=0.998437
[Epoch 0026] loss=11.9404 cls=0.0306 smmd=0.1895 ct=9.3502 rec=1.1851 | train/val/test=1.000/0.708/0.683 | c=0.998437
[Epoch 0027] loss=11.9206 cls=0.0321 smmd=0.1869 ct=9.3416 rec=1.1800 | train/val/test=1.000/0.724/0.690 | c=0.998437
[Epoch 0028] loss=11.8881 cls=0.0324 smmd=0.1631 ct=9.3408 rec=1.1759 | train/val/test=1.000/0.718/0.691 | c=0.998437
[Epoch 0029] loss=11.8654 cls=0.0317 smmd=0.1412 ct=9.3486 rec=1.1720 | train/val/test=1.000/0.712/0.689 | c=0.998437
[Epoch 0030] loss=11.8352 cls=0.0297 smmd=0.1186 ct=9.3499 rec=1.1685 | train/val/test=1.000/0.712/0.693 | c=0.998437
[Epoch 0031] loss=11.8160 cls=0.0266 smmd=0.1152 ct=9.3428 rec=1.1657 | train/val/test=1.000/0.710/0.694 | c=0.998437
[Epoch 0032] loss=11.7836 cls=0.0247 smmd=0.1023 ct=9.3286 rec=1.1640 | train/val/test=1.000/0.714/0.694 | c=0.998437
[Epoch 0033] loss=11.7742 cls=0.0233 smmd=0.1013 ct=9.3230 rec=1.1633 | train/val/test=1.000/0.712/0.693 | c=0.998437
[Epoch 0034] loss=11.7674 cls=0.0217 smmd=0.0908 ct=9.3286 rec=1.1631 | train/val/test=1.000/0.712/0.689 | c=0.998437
[Epoch 0035] loss=11.7488 cls=0.0211 smmd=0.0703 ct=9.3303 rec=1.1636 | train/val/test=1.000/0.716/0.684 | c=0.998437
[Epoch 0036] loss=11.7397 cls=0.0201 smmd=0.0648 ct=9.3263 rec=1.1642 | train/val/test=1.000/0.712/0.685 | c=0.998437
[Epoch 0037] loss=11.7325 cls=0.0196 smmd=0.0629 ct=9.3200 rec=1.1650 | train/val/test=1.000/0.712/0.687 | c=0.998437
[Epoch 0038] loss=11.7144 cls=0.0194 smmd=0.0483 ct=9.3154 rec=1.1657 | train/val/test=1.000/0.710/0.683 | c=0.998437
[Epoch 0039] loss=11.7067 cls=0.0192 smmd=0.0419 ct=9.3140 rec=1.1658 | train/val/test=1.000/0.716/0.689 | c=0.998437
[Epoch 0040] loss=11.7147 cls=0.0196 smmd=0.0517 ct=9.3112 rec=1.1661 | train/val/test=1.000/0.718/0.682 | c=0.998437
[Epoch 0041] loss=11.7075 cls=0.0211 smmd=0.0370 ct=9.3172 rec=1.1661 | train/val/test=1.000/0.726/0.695 | c=0.998437
[Epoch 0042] loss=11.7250 cls=0.0232 smmd=0.0515 ct=9.3111 rec=1.1696 | train/val/test=1.000/0.696/0.671 | c=0.998437
[Epoch 0043] loss=11.7930 cls=0.0349 smmd=0.0685 ct=9.3426 rec=1.1735 | train/val/test=1.000/0.726/0.701 | c=0.998437
[Epoch 0044] loss=11.8878 cls=0.0482 smmd=0.1278 ct=9.3325 rec=1.1896 | train/val/test=1.000/0.684/0.674 | c=0.998437
[Epoch 0045] loss=11.8503 cls=0.0389 smmd=0.1014 ct=9.3600 rec=1.1750 | train/val/test=1.000/0.724/0.687 | c=0.998437
[Epoch 0046] loss=11.6764 cls=0.0146 smmd=0.0452 ct=9.3024 rec=1.1571 | train/val/test=1.000/0.724/0.708 | c=0.998437
[Epoch 0047] loss=11.7811 cls=0.0218 smmd=0.1086 ct=9.3161 rec=1.1673 | train/val/test=1.000/0.706/0.683 | c=0.998437
[Epoch 0048] loss=11.7033 cls=0.0133 smmd=0.0582 ct=9.3190 rec=1.1564 | train/val/test=1.000/0.702/0.678 | c=0.998437
[Epoch 0049] loss=11.7102 cls=0.0147 smmd=0.0529 ct=9.3246 rec=1.1590 | train/val/test=1.000/0.722/0.699 | c=0.998437
[Epoch 0050] loss=11.7103 cls=0.0160 smmd=0.0699 ct=9.3053 rec=1.1596 | train/val/test=1.000/0.726/0.701 | c=0.998437
[Epoch 0051] loss=11.6645 cls=0.0146 smmd=0.0321 ct=9.3003 rec=1.1588 | train/val/test=1.000/0.700/0.679 | c=0.998437
[Epoch 0052] loss=11.7161 cls=0.0176 smmd=0.0489 ct=9.3188 rec=1.1654 | train/val/test=1.000/0.724/0.688 | c=0.998437
[Epoch 0053] loss=11.6584 cls=0.0165 smmd=0.0211 ct=9.2979 rec=1.1615 | train/val/test=1.000/0.724/0.705 | c=0.998437
[Epoch 0054] loss=11.6988 cls=0.0218 smmd=0.0404 ct=9.3021 rec=1.1672 | train/val/test=1.000/0.700/0.675 | c=0.998437
[Epoch 0055] loss=11.7056 cls=0.0235 smmd=0.0257 ct=9.3117 rec=1.1723 | train/val/test=1.000/0.724/0.691 | c=0.998437
[Epoch 0056] loss=11.6587 cls=0.0213 smmd=0.0097 ct=9.2942 rec=1.1668 | train/val/test=1.000/0.720/0.697 | c=0.998437
[Epoch 0057] loss=11.6787 cls=0.0237 smmd=0.0214 ct=9.2957 rec=1.1690 | train/val/test=1.000/0.704/0.675 | c=0.998437
[Epoch 0058] loss=11.6964 cls=0.0286 smmd=0.0174 ct=9.3070 rec=1.1717 | train/val/test=1.000/0.726/0.695 | c=0.998437
[Epoch 0059] loss=11.6556 cls=0.0231 smmd=0.0121 ct=9.2883 rec=1.1660 | train/val/test=1.000/0.724/0.698 | c=0.998437
[Epoch 0060] loss=11.6526 cls=0.0223 smmd=0.0115 ct=9.2892 rec=1.1648 | train/val/test=1.000/0.708/0.676 | c=0.998437
[Epoch 0061] loss=11.6699 cls=0.0261 smmd=0.0109 ct=9.3015 rec=1.1657 | train/val/test=1.000/0.722/0.693 | c=0.998437
[Epoch 0062] loss=11.6433 cls=0.0215 smmd=0.0099 ct=9.2862 rec=1.1628 | train/val/test=1.000/0.724/0.693 | c=0.998437
[Epoch 0063] loss=11.6424 cls=0.0210 smmd=0.0104 ct=9.2848 rec=1.1631 | train/val/test=1.000/0.716/0.676 | c=0.998437
[Epoch 0064] loss=11.6510 cls=0.0221 smmd=0.0073 ct=9.2927 rec=1.1645 | train/val/test=1.000/0.722/0.686 | c=0.998437
[Epoch 0065] loss=11.6302 cls=0.0208 smmd=0.0021 ct=9.2814 rec=1.1629 | train/val/test=1.000/0.722/0.688 | c=0.998437
[Epoch 0066] loss=11.6386 cls=0.0219 smmd=0.0070 ct=9.2808 rec=1.1645 | train/val/test=1.000/0.718/0.679 | c=0.998437
[Epoch 0067] loss=11.6453 cls=0.0223 smmd=0.0029 ct=9.2871 rec=1.1666 | train/val/test=1.000/0.724/0.684 | c=0.998437
[Epoch 0068] loss=11.6297 cls=0.0224 smmd=-0.0039 ct=9.2796 rec=1.1658 | train/val/test=1.000/0.724/0.685 | c=0.998437
[Epoch 0069] loss=11.6297 cls=0.0228 smmd=-0.0037 ct=9.2766 rec=1.1670 | train/val/test=1.000/0.718/0.681 | c=0.998437
[Epoch 0070] loss=11.6422 cls=0.0241 smmd=-0.0025 ct=9.2822 rec=1.1692 | train/val/test=1.000/0.720/0.694 | c=0.998437
[Epoch 0071] loss=11.6346 cls=0.0241 smmd=-0.0020 ct=9.2749 rec=1.1688 | train/val/test=1.000/0.726/0.687 | c=0.998437
[Epoch 0072] loss=11.6202 cls=0.0226 smmd=-0.0106 ct=9.2738 rec=1.1672 | train/val/test=1.000/0.724/0.684 | c=0.998437
[Epoch 0073] loss=11.6243 cls=0.0234 smmd=-0.0106 ct=9.2771 rec=1.1672 | train/val/test=1.000/0.724/0.695 | c=0.998437
[Epoch 0074] loss=11.6279 cls=0.0232 smmd=-0.0018 ct=9.2713 rec=1.1676 | train/val/test=1.000/0.722/0.686 | c=0.998437
[Epoch 0075] loss=11.6163 cls=0.0226 smmd=-0.0095 ct=9.2714 rec=1.1659 | train/val/test=1.000/0.722/0.686 | c=0.998437
[Epoch 0076] loss=11.6160 cls=0.0219 smmd=-0.0062 ct=9.2702 rec=1.1650 | train/val/test=1.000/0.726/0.691 | c=0.998437
[Epoch 0077] loss=11.6136 cls=0.0219 smmd=-0.0074 ct=9.2679 rec=1.1656 | train/val/test=1.000/0.718/0.683 | c=0.998437
[Epoch 0078] loss=11.6136 cls=0.0223 smmd=-0.0094 ct=9.2698 rec=1.1655 | train/val/test=1.000/0.722/0.690 | c=0.998437
[Epoch 0079] loss=11.6089 cls=0.0218 smmd=-0.0090 ct=9.2655 rec=1.1653 | train/val/test=1.000/0.722/0.691 | c=0.998437
[Epoch 0080] loss=11.6086 cls=0.0222 smmd=-0.0106 ct=9.2647 rec=1.1662 | train/val/test=1.000/0.722/0.686 | c=0.998437
[Epoch 0081] loss=11.6049 cls=0.0227 smmd=-0.0162 ct=9.2648 rec=1.1668 | train/val/test=1.000/0.722/0.692 | c=0.998437
[Epoch 0082] loss=11.6064 cls=0.0228 smmd=-0.0129 ct=9.2622 rec=1.1671 | train/val/test=1.000/0.724/0.690 | c=0.998437
[Epoch 0083] loss=11.6025 cls=0.0229 smmd=-0.0179 ct=9.2624 rec=1.1675 | train/val/test=1.000/0.722/0.691 | c=0.998437
[Epoch 0084] loss=11.6035 cls=0.0231 smmd=-0.0176 ct=9.2632 rec=1.1674 | train/val/test=1.000/0.722/0.696 | c=0.998437
[Epoch 0085] loss=11.6033 cls=0.0228 smmd=-0.0146 ct=9.2603 rec=1.1674 | train/val/test=1.000/0.722/0.686 | c=0.998437
[Epoch 0086] loss=11.6009 cls=0.0228 smmd=-0.0136 ct=9.2584 rec=1.1666 | train/val/test=1.000/0.726/0.692 | c=0.998437
[Epoch 0087] loss=11.5942 cls=0.0220 smmd=-0.0191 ct=9.2593 rec=1.1660 | train/val/test=1.000/0.726/0.691 | c=0.998437
[Epoch 0088] loss=11.5966 cls=0.0218 smmd=-0.0152 ct=9.2587 rec=1.1657 | train/val/test=1.000/0.724/0.690 | c=0.998437
[Epoch 0089] loss=11.5918 cls=0.0220 smmd=-0.0191 ct=9.2581 rec=1.1654 | train/val/test=1.000/0.724/0.693 | c=0.998437
[Epoch 0090] loss=11.5942 cls=0.0214 smmd=-0.0149 ct=9.2568 rec=1.1654 | train/val/test=1.000/0.724/0.687 | c=0.998437
[Epoch 0091] loss=11.5918 cls=0.0215 smmd=-0.0142 ct=9.2543 rec=1.1651 | train/val/test=1.000/0.726/0.692 | c=0.998437
[Epoch 0092] loss=11.5876 cls=0.0211 smmd=-0.0199 ct=9.2568 rec=1.1648 | train/val/test=1.000/0.726/0.690 | c=0.998437
[Epoch 0093] loss=11.5886 cls=0.0210 smmd=-0.0168 ct=9.2540 rec=1.1652 | train/val/test=1.000/0.724/0.692 | c=0.998437
[Epoch 0094] loss=11.5845 cls=0.0214 smmd=-0.0206 ct=9.2530 rec=1.1654 | train/val/test=1.000/0.726/0.695 | c=0.998437
[Epoch 0095] loss=11.5853 cls=0.0214 smmd=-0.0191 ct=9.2513 rec=1.1658 | train/val/test=1.000/0.724/0.690 | c=0.998437
[Epoch 0096] loss=11.5856 cls=0.0219 smmd=-0.0191 ct=9.2505 rec=1.1662 | train/val/test=1.000/0.726/0.693 | c=0.998437
[Epoch 0097] loss=11.5875 cls=0.0221 smmd=-0.0209 ct=9.2537 rec=1.1663 | train/val/test=1.000/0.726/0.690 | c=0.998437
[Epoch 0098] loss=11.5863 cls=0.0221 smmd=-0.0183 ct=9.2498 rec=1.1664 | train/val/test=1.000/0.724/0.693 | c=0.998437
[Epoch 0099] loss=11.5837 cls=0.0220 smmd=-0.0208 ct=9.2509 rec=1.1658 | train/val/test=1.000/0.726/0.691 | c=0.998437
=== Best @ epoch 41: val=0.7260, test=0.6950 ===
