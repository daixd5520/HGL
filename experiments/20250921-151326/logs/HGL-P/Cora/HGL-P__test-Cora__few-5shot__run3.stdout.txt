Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.1404 cls=1.9430 smmd=4.1528 ct=9.2669 rec=1.3889 | train/val/test=0.310/0.336/0.337 | c=0.998437
[Epoch 0001] loss=16.6338 cls=1.8967 smmd=2.7525 ct=9.2053 rec=1.3896 | train/val/test=0.690/0.418/0.412 | c=0.998437
[Epoch 0002] loss=15.1232 cls=1.7676 smmd=1.4634 ct=9.1146 rec=1.3887 | train/val/test=0.690/0.370/0.386 | c=0.998437
[Epoch 0003] loss=14.8101 cls=1.5083 smmd=1.4595 ct=9.0676 rec=1.3873 | train/val/test=0.793/0.398/0.402 | c=0.998437
[Epoch 0004] loss=14.5930 cls=1.1837 smmd=1.6997 ct=8.9506 rec=1.3795 | train/val/test=0.966/0.514/0.536 | c=0.998437
[Epoch 0005] loss=14.0664 cls=0.7933 smmd=1.6684 ct=8.8766 rec=1.3640 | train/val/test=0.966/0.458/0.498 | c=0.998437
[Epoch 0006] loss=13.3994 cls=0.4773 smmd=1.3923 ct=8.8505 rec=1.3396 | train/val/test=1.000/0.424/0.461 | c=0.998437
[Epoch 0007] loss=12.8072 cls=0.2691 smmd=1.0862 ct=8.8328 rec=1.3096 | train/val/test=1.000/0.476/0.502 | c=0.998437
[Epoch 0008] loss=12.4922 cls=0.1443 smmd=0.9673 ct=8.8237 rec=1.2784 | train/val/test=1.000/0.524/0.534 | c=0.998437
[Epoch 0009] loss=12.4618 cls=0.0780 smmd=1.0562 ct=8.8203 rec=1.2537 | train/val/test=1.000/0.516/0.540 | c=0.998437
[Epoch 0010] loss=12.4425 cls=0.0410 smmd=1.1172 ct=8.8140 rec=1.2352 | train/val/test=1.000/0.514/0.527 | c=0.998437
[Epoch 0011] loss=12.2970 cls=0.0207 smmd=1.0315 ct=8.8050 rec=1.2199 | train/val/test=1.000/0.496/0.522 | c=0.998437
[Epoch 0012] loss=12.7775 cls=0.0122 smmd=0.8499 ct=9.4982 rec=1.2086 | train/val/test=1.000/0.504/0.525 | c=0.998437
[Epoch 0013] loss=12.5898 cls=0.0069 smmd=0.7384 ct=9.4419 rec=1.2013 | train/val/test=1.000/0.508/0.531 | c=0.998437
[Epoch 0014] loss=12.5618 cls=0.0042 smmd=0.7725 ct=9.3888 rec=1.1982 | train/val/test=1.000/0.510/0.529 | c=0.998437
[Epoch 0015] loss=12.5038 cls=0.0032 smmd=0.7389 ct=9.3698 rec=1.1959 | train/val/test=1.000/0.516/0.522 | c=0.998437
[Epoch 0016] loss=12.4886 cls=0.0030 smmd=0.7149 ct=9.3844 rec=1.1932 | train/val/test=1.000/0.512/0.516 | c=0.998437
[Epoch 0017] loss=12.3721 cls=0.0034 smmd=0.5661 ct=9.4184 rec=1.1921 | train/val/test=1.000/0.512/0.518 | c=0.998437
[Epoch 0018] loss=12.2754 cls=0.0039 smmd=0.4466 ct=9.4400 rec=1.1925 | train/val/test=1.000/0.514/0.516 | c=0.998437
[Epoch 0019] loss=12.2130 cls=0.0047 smmd=0.3817 ct=9.4394 rec=1.1937 | train/val/test=1.000/0.512/0.514 | c=0.998437
[Epoch 0020] loss=12.2101 cls=0.0065 smmd=0.3840 ct=9.4296 rec=1.1950 | train/val/test=1.000/0.508/0.513 | c=0.998437
[Epoch 0021] loss=12.1824 cls=0.0088 smmd=0.3586 ct=9.4236 rec=1.1957 | train/val/test=1.000/0.508/0.511 | c=0.998437
[Epoch 0022] loss=12.1085 cls=0.0115 smmd=0.2774 ct=9.4275 rec=1.1961 | train/val/test=1.000/0.504/0.507 | c=0.998437
[Epoch 0023] loss=12.0725 cls=0.0156 smmd=0.2315 ct=9.4325 rec=1.1964 | train/val/test=1.000/0.510/0.508 | c=0.998437
[Epoch 0024] loss=12.0722 cls=0.0188 smmd=0.2321 ct=9.4275 rec=1.1969 | train/val/test=1.000/0.512/0.512 | c=0.998437
[Epoch 0025] loss=12.0516 cls=0.0235 smmd=0.2177 ct=9.4189 rec=1.1958 | train/val/test=1.000/0.512/0.518 | c=0.998437
[Epoch 0026] loss=12.0275 cls=0.0291 smmd=0.1930 ct=9.4184 rec=1.1935 | train/val/test=1.000/0.512/0.519 | c=0.998437
[Epoch 0027] loss=11.9973 cls=0.0328 smmd=0.1550 ct=9.4269 rec=1.1913 | train/val/test=1.000/0.514/0.520 | c=0.998437
[Epoch 0028] loss=11.9773 cls=0.0345 smmd=0.1388 ct=9.4297 rec=1.1872 | train/val/test=1.000/0.522/0.525 | c=0.998437
[Epoch 0029] loss=11.9460 cls=0.0320 smmd=0.1268 ct=9.4200 rec=1.1836 | train/val/test=1.000/0.516/0.517 | c=0.998437
[Epoch 0030] loss=11.9189 cls=0.0268 smmd=0.1224 ct=9.4110 rec=1.1794 | train/val/test=1.000/0.534/0.530 | c=0.998437
[Epoch 0031] loss=11.8794 cls=0.0229 smmd=0.0993 ct=9.4031 rec=1.1770 | train/val/test=1.000/0.528/0.522 | c=0.998437
[Epoch 0032] loss=11.8689 cls=0.0197 smmd=0.1064 ct=9.3950 rec=1.1739 | train/val/test=1.000/0.540/0.527 | c=0.998437
[Epoch 0033] loss=11.8460 cls=0.0171 smmd=0.0913 ct=9.3920 rec=1.1728 | train/val/test=1.000/0.538/0.525 | c=0.998437
[Epoch 0034] loss=11.8313 cls=0.0151 smmd=0.0788 ct=9.3929 rec=1.1722 | train/val/test=1.000/0.536/0.525 | c=0.998437
[Epoch 0035] loss=11.8165 cls=0.0141 smmd=0.0680 ct=9.3902 rec=1.1721 | train/val/test=1.000/0.538/0.527 | c=0.998437
[Epoch 0036] loss=11.8071 cls=0.0129 smmd=0.0651 ct=9.3839 rec=1.1726 | train/val/test=1.000/0.538/0.528 | c=0.998437
[Epoch 0037] loss=11.7898 cls=0.0122 smmd=0.0493 ct=9.3823 rec=1.1730 | train/val/test=1.000/0.538/0.528 | c=0.998437
[Epoch 0038] loss=11.7840 cls=0.0119 smmd=0.0452 ct=9.3807 rec=1.1731 | train/val/test=1.000/0.536/0.528 | c=0.998437
[Epoch 0039] loss=11.7756 cls=0.0119 smmd=0.0391 ct=9.3779 rec=1.1734 | train/val/test=1.000/0.546/0.534 | c=0.998437
[Epoch 0040] loss=11.7732 cls=0.0123 smmd=0.0398 ct=9.3731 rec=1.1740 | train/val/test=1.000/0.538/0.522 | c=0.998437
[Epoch 0041] loss=11.7675 cls=0.0135 smmd=0.0302 ct=9.3752 rec=1.1743 | train/val/test=1.000/0.550/0.540 | c=0.998437
[Epoch 0042] loss=11.7780 cls=0.0144 smmd=0.0342 ct=9.3774 rec=1.1760 | train/val/test=1.000/0.522/0.519 | c=0.998437
[Epoch 0043] loss=11.7868 cls=0.0175 smmd=0.0389 ct=9.3786 rec=1.1759 | train/val/test=1.000/0.560/0.551 | c=0.998437
[Epoch 0044] loss=11.8054 cls=0.0181 smmd=0.0491 ct=9.3785 rec=1.1799 | train/val/test=1.000/0.522/0.510 | c=0.998437
[Epoch 0045] loss=11.8332 cls=0.0257 smmd=0.0617 ct=9.3882 rec=1.1788 | train/val/test=1.000/0.560/0.557 | c=0.998437
[Epoch 0046] loss=11.8125 cls=0.0201 smmd=0.0545 ct=9.3781 rec=1.1799 | train/val/test=1.000/0.542/0.523 | c=0.998437
[Epoch 0047] loss=11.7602 cls=0.0176 smmd=0.0306 ct=9.3706 rec=1.1707 | train/val/test=1.000/0.548/0.530 | c=0.998437
[Epoch 0048] loss=11.7410 cls=0.0147 smmd=0.0236 ct=9.3639 rec=1.1694 | train/val/test=1.000/0.560/0.554 | c=0.998437
[Epoch 0049] loss=11.7589 cls=0.0161 smmd=0.0319 ct=9.3664 rec=1.1723 | train/val/test=1.000/0.536/0.524 | c=0.998437
[Epoch 0050] loss=11.7417 cls=0.0156 smmd=0.0224 ct=9.3641 rec=1.1698 | train/val/test=1.000/0.548/0.537 | c=0.998437
[Epoch 0051] loss=11.7272 cls=0.0136 smmd=0.0191 ct=9.3549 rec=1.1698 | train/val/test=1.000/0.554/0.543 | c=0.998437
[Epoch 0052] loss=11.7379 cls=0.0148 smmd=0.0190 ct=9.3597 rec=1.1722 | train/val/test=1.000/0.542/0.527 | c=0.998437
[Epoch 0053] loss=11.7377 cls=0.0158 smmd=0.0155 ct=9.3600 rec=1.1731 | train/val/test=1.000/0.550/0.543 | c=0.998437
[Epoch 0054] loss=11.7234 cls=0.0148 smmd=0.0083 ct=9.3533 rec=1.1735 | train/val/test=1.000/0.548/0.535 | c=0.998437
[Epoch 0055] loss=11.7180 cls=0.0153 smmd=0.0020 ct=9.3529 rec=1.1739 | train/val/test=1.000/0.540/0.528 | c=0.998437
[Epoch 0056] loss=11.7289 cls=0.0172 smmd=0.0077 ct=9.3519 rec=1.1760 | train/val/test=1.000/0.556/0.546 | c=0.998437
[Epoch 0057] loss=11.7290 cls=0.0170 smmd=0.0052 ct=9.3523 rec=1.1772 | train/val/test=1.000/0.544/0.529 | c=0.998437
[Epoch 0058] loss=11.7149 cls=0.0179 smmd=0.0005 ct=9.3472 rec=1.1746 | train/val/test=1.000/0.552/0.540 | c=0.998437
[Epoch 0059] loss=11.7023 cls=0.0163 smmd=-0.0057 ct=9.3439 rec=1.1739 | train/val/test=1.000/0.556/0.539 | c=0.998437
[Epoch 0060] loss=11.7108 cls=0.0172 smmd=-0.0021 ct=9.3478 rec=1.1739 | train/val/test=1.000/0.544/0.530 | c=0.998437
[Epoch 0061] loss=11.7085 cls=0.0179 smmd=0.0018 ct=9.3419 rec=1.1735 | train/val/test=1.000/0.558/0.548 | c=0.998437
[Epoch 0062] loss=11.7035 cls=0.0162 smmd=0.0050 ct=9.3366 rec=1.1729 | train/val/test=1.000/0.552/0.533 | c=0.998437
[Epoch 0063] loss=11.6879 cls=0.0167 smmd=-0.0088 ct=9.3366 rec=1.1717 | train/val/test=1.000/0.550/0.538 | c=0.998437
[Epoch 0064] loss=11.6888 cls=0.0163 smmd=-0.0074 ct=9.3339 rec=1.1730 | train/val/test=1.000/0.556/0.543 | c=0.998437
[Epoch 0065] loss=11.6915 cls=0.0164 smmd=-0.0070 ct=9.3359 rec=1.1731 | train/val/test=1.000/0.546/0.534 | c=0.998437
[Epoch 0066] loss=11.6868 cls=0.0168 smmd=-0.0082 ct=9.3312 rec=1.1735 | train/val/test=1.000/0.558/0.547 | c=0.998437
[Epoch 0067] loss=11.6849 cls=0.0166 smmd=-0.0083 ct=9.3269 rec=1.1749 | train/val/test=1.000/0.550/0.537 | c=0.998437
[Epoch 0068] loss=11.6833 cls=0.0176 smmd=-0.0124 ct=9.3289 rec=1.1746 | train/val/test=1.000/0.554/0.547 | c=0.998437
[Epoch 0069] loss=11.6791 cls=0.0168 smmd=-0.0117 ct=9.3229 rec=1.1756 | train/val/test=1.000/0.552/0.540 | c=0.998437
[Epoch 0070] loss=11.6806 cls=0.0174 smmd=-0.0121 ct=9.3256 rec=1.1748 | train/val/test=1.000/0.544/0.538 | c=0.998437
[Epoch 0071] loss=11.6759 cls=0.0171 smmd=-0.0132 ct=9.3224 rec=1.1748 | train/val/test=1.000/0.556/0.548 | c=0.998437
[Epoch 0072] loss=11.6742 cls=0.0169 smmd=-0.0122 ct=9.3199 rec=1.1747 | train/val/test=1.000/0.550/0.538 | c=0.998437
[Epoch 0073] loss=11.6702 cls=0.0177 smmd=-0.0152 ct=9.3192 rec=1.1743 | train/val/test=1.000/0.554/0.549 | c=0.998437
[Epoch 0074] loss=11.6682 cls=0.0169 smmd=-0.0147 ct=9.3159 rec=1.1750 | train/val/test=1.000/0.550/0.541 | c=0.998437
[Epoch 0075] loss=11.6672 cls=0.0181 smmd=-0.0176 ct=9.3178 rec=1.1745 | train/val/test=1.000/0.554/0.550 | c=0.998437
[Epoch 0076] loss=11.6658 cls=0.0169 smmd=-0.0169 ct=9.3157 rec=1.1750 | train/val/test=1.000/0.552/0.537 | c=0.998437
[Epoch 0077] loss=11.6631 cls=0.0180 smmd=-0.0187 ct=9.3144 rec=1.1747 | train/val/test=1.000/0.560/0.554 | c=0.998437
[Epoch 0078] loss=11.6634 cls=0.0168 smmd=-0.0178 ct=9.3143 rec=1.1751 | train/val/test=1.000/0.548/0.538 | c=0.998437
[Epoch 0079] loss=11.6559 cls=0.0178 smmd=-0.0243 ct=9.3136 rec=1.1744 | train/val/test=1.000/0.562/0.558 | c=0.998437
[Epoch 0080] loss=11.6617 cls=0.0165 smmd=-0.0160 ct=9.3112 rec=1.1750 | train/val/test=1.000/0.548/0.536 | c=0.998437
[Epoch 0081] loss=11.6612 cls=0.0176 smmd=-0.0157 ct=9.3116 rec=1.1739 | train/val/test=1.000/0.560/0.557 | c=0.998437
[Epoch 0082] loss=11.6625 cls=0.0165 smmd=-0.0147 ct=9.3112 rec=1.1748 | train/val/test=1.000/0.544/0.535 | c=0.998437
[Epoch 0083] loss=11.6615 cls=0.0174 smmd=-0.0164 ct=9.3136 rec=1.1734 | train/val/test=1.000/0.560/0.556 | c=0.998437
[Epoch 0084] loss=11.6559 cls=0.0160 smmd=-0.0151 ct=9.3074 rec=1.1739 | train/val/test=1.000/0.548/0.538 | c=0.998437
[Epoch 0085] loss=11.6537 cls=0.0167 smmd=-0.0151 ct=9.3064 rec=1.1729 | train/val/test=1.000/0.556/0.553 | c=0.998437
[Epoch 0086] loss=11.6460 cls=0.0157 smmd=-0.0215 ct=9.3051 rec=1.1734 | train/val/test=1.000/0.556/0.540 | c=0.998437
[Epoch 0087] loss=11.6454 cls=0.0162 smmd=-0.0217 ct=9.3046 rec=1.1732 | train/val/test=1.000/0.552/0.548 | c=0.998437
[Epoch 0088] loss=11.6357 cls=0.0160 smmd=-0.0292 ct=9.3016 rec=1.1736 | train/val/test=1.000/0.552/0.546 | c=0.998437
[Epoch 0089] loss=11.6365 cls=0.0164 smmd=-0.0267 ct=9.2988 rec=1.1740 | train/val/test=1.000/0.554/0.545 | c=0.998437
[Epoch 0090] loss=11.6389 cls=0.0170 smmd=-0.0276 ct=9.3006 rec=1.1744 | train/val/test=1.000/0.550/0.545 | c=0.998437
[Epoch 0091] loss=11.6416 cls=0.0169 smmd=-0.0256 ct=9.3001 rec=1.1751 | train/val/test=1.000/0.554/0.542 | c=0.998437
[Epoch 0092] loss=11.6445 cls=0.0185 smmd=-0.0264 ct=9.3016 rec=1.1754 | train/val/test=1.000/0.554/0.554 | c=0.998437
[Epoch 0093] loss=11.6576 cls=0.0178 smmd=-0.0166 ct=9.3025 rec=1.1770 | train/val/test=1.000/0.544/0.534 | c=0.998437
[Epoch 0094] loss=11.6804 cls=0.0226 smmd=-0.0109 ct=9.3127 rec=1.1780 | train/val/test=1.000/0.572/0.566 | c=0.998437
[Epoch 0095] loss=11.7352 cls=0.0238 smmd=0.0133 ct=9.3258 rec=1.1862 | train/val/test=1.000/0.526/0.521 | c=0.998437
[Epoch 0096] loss=11.8318 cls=0.0408 smmd=0.0630 ct=9.3528 rec=1.1876 | train/val/test=1.000/0.576/0.580 | c=0.998437
[Epoch 0097] loss=11.8288 cls=0.0296 smmd=0.0670 ct=9.3468 rec=1.1927 | train/val/test=1.000/0.542/0.533 | c=0.998437
[Epoch 0098] loss=11.7095 cls=0.0117 smmd=0.0312 ct=9.3256 rec=1.1705 | train/val/test=1.000/0.550/0.541 | c=0.998437
[Epoch 0099] loss=11.6771 cls=0.0102 smmd=0.0111 ct=9.3234 rec=1.1662 | train/val/test=1.000/0.576/0.581 | c=0.998437
=== Best @ epoch 96: val=0.5760, test=0.5800 ===
