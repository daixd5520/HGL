Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.1354 cls=1.9469 smmd=4.1459 ct=9.2649 rec=1.3889 | train/val/test=0.207/0.072/0.094 | c=0.998437
[Epoch 0001] loss=16.5859 cls=1.8830 smmd=2.7541 ct=9.1704 rec=1.3892 | train/val/test=0.828/0.404/0.455 | c=0.998437
[Epoch 0002] loss=15.0487 cls=1.7259 smmd=1.4723 ct=9.0732 rec=1.3886 | train/val/test=0.793/0.298/0.341 | c=0.998437
[Epoch 0003] loss=14.7736 cls=1.4231 smmd=1.4771 ct=9.0975 rec=1.3880 | train/val/test=0.931/0.426/0.435 | c=0.998437
[Epoch 0004] loss=15.0882 cls=1.0459 smmd=1.6900 ct=9.5928 rec=1.3797 | train/val/test=0.931/0.404/0.432 | c=0.998437
[Epoch 0005] loss=14.4495 cls=0.7046 smmd=1.7085 ct=9.3082 rec=1.3640 | train/val/test=0.966/0.502/0.512 | c=0.998437
[Epoch 0006] loss=13.9248 cls=0.4261 smmd=1.6322 ct=9.1840 rec=1.3412 | train/val/test=1.000/0.558/0.554 | c=0.998437
[Epoch 0007] loss=13.4525 cls=0.2479 smmd=1.4138 ct=9.1666 rec=1.3121 | train/val/test=1.000/0.540/0.533 | c=0.998437
[Epoch 0008] loss=13.1687 cls=0.1427 smmd=1.2416 ct=9.2191 rec=1.2827 | train/val/test=1.000/0.526/0.517 | c=0.998437
[Epoch 0009] loss=13.1473 cls=0.0832 smmd=1.2312 ct=9.3109 rec=1.2610 | train/val/test=1.000/0.538/0.529 | c=0.998437
[Epoch 0010] loss=13.0800 cls=0.0435 smmd=1.1622 ct=9.3795 rec=1.2474 | train/val/test=1.000/0.558/0.548 | c=0.998437
[Epoch 0011] loss=12.9399 cls=0.0241 smmd=1.0336 ct=9.4061 rec=1.2381 | train/val/test=1.000/0.560/0.546 | c=0.998437
[Epoch 0012] loss=12.7119 cls=0.0139 smmd=0.8603 ct=9.3825 rec=1.2276 | train/val/test=1.000/0.560/0.545 | c=0.998437
[Epoch 0013] loss=12.5583 cls=0.0083 smmd=0.7701 ct=9.3442 rec=1.2179 | train/val/test=1.000/0.554/0.542 | c=0.998437
[Epoch 0014] loss=12.5191 cls=0.0057 smmd=0.7648 ct=9.3240 rec=1.2123 | train/val/test=1.000/0.558/0.549 | c=0.998437
[Epoch 0015] loss=12.4927 cls=0.0045 smmd=0.7558 ct=9.3145 rec=1.2090 | train/val/test=1.000/0.568/0.565 | c=0.998437
[Epoch 0016] loss=12.4177 cls=0.0040 smmd=0.6841 ct=9.3155 rec=1.2071 | train/val/test=1.000/0.580/0.578 | c=0.998437
[Epoch 0017] loss=12.3328 cls=0.0039 smmd=0.5991 ct=9.3186 rec=1.2056 | train/val/test=1.000/0.568/0.576 | c=0.998437
[Epoch 0018] loss=12.2266 cls=0.0044 smmd=0.4885 ct=9.3238 rec=1.2050 | train/val/test=1.000/0.564/0.575 | c=0.998437
[Epoch 0019] loss=12.1929 cls=0.0054 smmd=0.4417 ct=9.3349 rec=1.2055 | train/val/test=1.000/0.590/0.601 | c=0.998437
[Epoch 0020] loss=12.1853 cls=0.0069 smmd=0.4269 ct=9.3388 rec=1.2064 | train/val/test=1.000/0.586/0.606 | c=0.998437
[Epoch 0021] loss=12.1154 cls=0.0083 smmd=0.3585 ct=9.3356 rec=1.2065 | train/val/test=1.000/0.580/0.598 | c=0.998437
[Epoch 0022] loss=12.0694 cls=0.0098 smmd=0.3152 ct=9.3325 rec=1.2060 | train/val/test=1.000/0.592/0.609 | c=0.998437
[Epoch 0023] loss=12.0362 cls=0.0127 smmd=0.2817 ct=9.3327 rec=1.2045 | train/val/test=1.000/0.602/0.619 | c=0.998437
[Epoch 0024] loss=11.9999 cls=0.0168 smmd=0.2384 ct=9.3398 rec=1.2024 | train/val/test=1.000/0.614/0.617 | c=0.998437
[Epoch 0025] loss=11.9806 cls=0.0240 smmd=0.2180 ct=9.3378 rec=1.2004 | train/val/test=1.000/0.622/0.631 | c=0.998437
[Epoch 0026] loss=11.9686 cls=0.0289 smmd=0.2010 ct=9.3441 rec=1.1973 | train/val/test=1.000/0.644/0.632 | c=0.998437
[Epoch 0027] loss=11.9553 cls=0.0352 smmd=0.1974 ct=9.3296 rec=1.1966 | train/val/test=1.000/0.630/0.635 | c=0.998437
[Epoch 0028] loss=11.9804 cls=0.0426 smmd=0.1879 ct=9.3551 rec=1.1974 | train/val/test=1.000/0.638/0.641 | c=0.998437
[Epoch 0029] loss=11.9987 cls=0.0423 smmd=0.2150 ct=9.3397 rec=1.2008 | train/val/test=1.000/0.646/0.657 | c=0.998437
[Epoch 0030] loss=11.8972 cls=0.0234 smmd=0.1503 ct=9.3535 rec=1.1850 | train/val/test=1.000/0.670/0.663 | c=0.998437
[Epoch 0031] loss=11.8135 cls=0.0138 smmd=0.1251 ct=9.3290 rec=1.1728 | train/val/test=1.000/0.672/0.666 | c=0.998437
[Epoch 0032] loss=11.8567 cls=0.0151 smmd=0.1700 ct=9.3216 rec=1.1750 | train/val/test=1.000/0.676/0.673 | c=0.998437
[Epoch 0033] loss=11.7914 cls=0.0091 smmd=0.1331 ct=9.3188 rec=1.1652 | train/val/test=1.000/0.672/0.674 | c=0.998437
[Epoch 0034] loss=11.7984 cls=0.0104 smmd=0.1139 ct=9.3357 rec=1.1692 | train/val/test=1.000/0.680/0.682 | c=0.998437
[Epoch 0035] loss=11.7649 cls=0.0086 smmd=0.1111 ct=9.3158 rec=1.1647 | train/val/test=1.000/0.676/0.677 | c=0.998437
[Epoch 0036] loss=11.7592 cls=0.0090 smmd=0.1070 ct=9.3129 rec=1.1652 | train/val/test=1.000/0.678/0.681 | c=0.998437
[Epoch 0037] loss=11.7674 cls=0.0105 smmd=0.0942 ct=9.3237 rec=1.1695 | train/val/test=1.000/0.686/0.691 | c=0.998437
[Epoch 0038] loss=11.7226 cls=0.0093 smmd=0.0718 ct=9.3064 rec=1.1676 | train/val/test=1.000/0.678/0.686 | c=0.998437
[Epoch 0039] loss=11.7273 cls=0.0111 smmd=0.0724 ct=9.3037 rec=1.1701 | train/val/test=1.000/0.688/0.686 | c=0.998437
[Epoch 0040] loss=11.7361 cls=0.0129 smmd=0.0548 ct=9.3196 rec=1.1744 | train/val/test=1.000/0.684/0.690 | c=0.998437
[Epoch 0041] loss=11.7227 cls=0.0137 smmd=0.0516 ct=9.3114 rec=1.1730 | train/val/test=1.000/0.684/0.688 | c=0.998437
[Epoch 0042] loss=11.7012 cls=0.0137 smmd=0.0428 ct=9.3031 rec=1.1708 | train/val/test=1.000/0.686/0.696 | c=0.998437
[Epoch 0043] loss=11.6961 cls=0.0141 smmd=0.0364 ct=9.3045 rec=1.1706 | train/val/test=1.000/0.688/0.694 | c=0.998437
[Epoch 0044] loss=11.6999 cls=0.0158 smmd=0.0477 ct=9.2979 rec=1.1692 | train/val/test=1.000/0.690/0.691 | c=0.998437
[Epoch 0045] loss=11.6811 cls=0.0153 smmd=0.0325 ct=9.2973 rec=1.1680 | train/val/test=1.000/0.686/0.701 | c=0.998437
[Epoch 0046] loss=11.6731 cls=0.0155 smmd=0.0246 ct=9.2999 rec=1.1665 | train/val/test=1.000/0.692/0.697 | c=0.998437
[Epoch 0047] loss=11.6775 cls=0.0159 smmd=0.0360 ct=9.2933 rec=1.1661 | train/val/test=1.000/0.686/0.693 | c=0.998437
[Epoch 0048] loss=11.6651 cls=0.0157 smmd=0.0247 ct=9.2922 rec=1.1662 | train/val/test=1.000/0.690/0.700 | c=0.998437
[Epoch 0049] loss=11.6550 cls=0.0158 smmd=0.0224 ct=9.2864 rec=1.1652 | train/val/test=1.000/0.690/0.695 | c=0.998437
[Epoch 0050] loss=11.6518 cls=0.0154 smmd=0.0253 ct=9.2799 rec=1.1656 | train/val/test=1.000/0.690/0.700 | c=0.998437
[Epoch 0051] loss=11.6505 cls=0.0154 smmd=0.0182 ct=9.2827 rec=1.1671 | train/val/test=1.000/0.686/0.697 | c=0.998437
[Epoch 0052] loss=11.6479 cls=0.0167 smmd=0.0164 ct=9.2795 rec=1.1676 | train/val/test=1.000/0.686/0.700 | c=0.998437
[Epoch 0053] loss=11.6400 cls=0.0153 smmd=0.0082 ct=9.2802 rec=1.1681 | train/val/test=1.000/0.686/0.701 | c=0.998437
[Epoch 0054] loss=11.6338 cls=0.0152 smmd=0.0097 ct=9.2739 rec=1.1675 | train/val/test=1.000/0.688/0.699 | c=0.998437
[Epoch 0055] loss=11.6267 cls=0.0147 smmd=0.0041 ct=9.2728 rec=1.1676 | train/val/test=1.000/0.682/0.701 | c=0.998437
[Epoch 0056] loss=11.6234 cls=0.0147 smmd=0.0057 ct=9.2676 rec=1.1677 | train/val/test=1.000/0.686/0.699 | c=0.998437
[Epoch 0057] loss=11.6219 cls=0.0145 smmd=0.0031 ct=9.2690 rec=1.1677 | train/val/test=1.000/0.682/0.700 | c=0.998437
[Epoch 0058] loss=11.6203 cls=0.0146 smmd=-0.0021 ct=9.2704 rec=1.1687 | train/val/test=1.000/0.684/0.697 | c=0.998437
[Epoch 0059] loss=11.6257 cls=0.0150 smmd=0.0113 ct=9.2627 rec=1.1684 | train/val/test=1.000/0.680/0.699 | c=0.998437
[Epoch 0060] loss=11.6196 cls=0.0149 smmd=-0.0025 ct=9.2680 rec=1.1696 | train/val/test=1.000/0.682/0.692 | c=0.998437
[Epoch 0061] loss=11.6223 cls=0.0154 smmd=0.0120 ct=9.2570 rec=1.1690 | train/val/test=1.000/0.682/0.699 | c=0.998437
[Epoch 0062] loss=11.6093 cls=0.0150 smmd=-0.0060 ct=9.2623 rec=1.1689 | train/val/test=1.000/0.684/0.697 | c=0.998437
[Epoch 0063] loss=11.6090 cls=0.0153 smmd=-0.0015 ct=9.2585 rec=1.1683 | train/val/test=1.000/0.684/0.698 | c=0.998437
[Epoch 0064] loss=11.6033 cls=0.0155 smmd=-0.0058 ct=9.2566 rec=1.1684 | train/val/test=1.000/0.686/0.701 | c=0.998437
[Epoch 0065] loss=11.5988 cls=0.0158 smmd=-0.0089 ct=9.2553 rec=1.1683 | train/val/test=1.000/0.684/0.699 | c=0.998437
[Epoch 0066] loss=11.5967 cls=0.0158 smmd=-0.0081 ct=9.2525 rec=1.1683 | train/val/test=1.000/0.682/0.701 | c=0.998437
[Epoch 0067] loss=11.5942 cls=0.0160 smmd=-0.0083 ct=9.2503 rec=1.1680 | train/val/test=1.000/0.684/0.700 | c=0.998437
[Epoch 0068] loss=11.5905 cls=0.0159 smmd=-0.0118 ct=9.2499 rec=1.1683 | train/val/test=1.000/0.682/0.700 | c=0.998437
[Epoch 0069] loss=11.5891 cls=0.0160 smmd=-0.0112 ct=9.2476 rec=1.1683 | train/val/test=1.000/0.684/0.700 | c=0.998437
[Epoch 0070] loss=11.5856 cls=0.0160 smmd=-0.0154 ct=9.2481 rec=1.1684 | train/val/test=1.000/0.680/0.701 | c=0.998437
[Epoch 0071] loss=11.5880 cls=0.0159 smmd=-0.0077 ct=9.2426 rec=1.1686 | train/val/test=1.000/0.680/0.701 | c=0.998437
[Epoch 0072] loss=11.5816 cls=0.0159 smmd=-0.0158 ct=9.2443 rec=1.1686 | train/val/test=1.000/0.680/0.699 | c=0.998437
[Epoch 0073] loss=11.5784 cls=0.0158 smmd=-0.0189 ct=9.2434 rec=1.1690 | train/val/test=1.000/0.680/0.702 | c=0.998437
[Epoch 0074] loss=11.5814 cls=0.0162 smmd=-0.0110 ct=9.2378 rec=1.1692 | train/val/test=1.000/0.678/0.699 | c=0.998437
[Epoch 0075] loss=11.5832 cls=0.0162 smmd=-0.0178 ct=9.2441 rec=1.1704 | train/val/test=1.000/0.678/0.697 | c=0.998437
[Epoch 0076] loss=11.5926 cls=0.0183 smmd=-0.0061 ct=9.2364 rec=1.1720 | train/val/test=1.000/0.678/0.704 | c=0.998437
[Epoch 0077] loss=11.6333 cls=0.0204 smmd=-0.0038 ct=9.2588 rec=1.1789 | train/val/test=1.000/0.650/0.679 | c=0.998437
[Epoch 0078] loss=11.7523 cls=0.0371 smmd=0.0633 ct=9.2598 rec=1.1960 | train/val/test=1.000/0.614/0.634 | c=0.998437
[Epoch 0079] loss=11.9875 cls=0.0721 smmd=0.1118 ct=9.3490 rec=1.2273 | train/val/test=1.000/0.628/0.654 | c=0.998437
[Epoch 0080] loss=11.9895 cls=0.0516 smmd=0.2040 ct=9.3066 rec=1.2136 | train/val/test=1.000/0.688/0.704 | c=0.998437
[Epoch 0081] loss=11.5952 cls=0.0058 smmd=0.0197 ct=9.2578 rec=1.1559 | train/val/test=1.000/0.656/0.675 | c=0.998437
[Epoch 0082] loss=11.8440 cls=0.0145 smmd=0.1302 ct=9.3298 rec=1.1848 | train/val/test=1.000/0.684/0.695 | c=0.998437
[Epoch 0083] loss=11.6371 cls=0.0038 smmd=0.0561 ct=9.2680 rec=1.1546 | train/val/test=1.000/0.674/0.695 | c=0.998437
[Epoch 0084] loss=11.7624 cls=0.0052 smmd=0.1475 ct=9.2889 rec=1.1604 | train/val/test=1.000/0.692/0.701 | c=0.998437
[Epoch 0085] loss=11.6878 cls=0.0039 smmd=0.0860 ct=9.2835 rec=1.1572 | train/val/test=1.000/0.684/0.703 | c=0.998437
[Epoch 0086] loss=11.6742 cls=0.0042 smmd=0.0658 ct=9.2800 rec=1.1621 | train/val/test=1.000/0.672/0.687 | c=0.998437
[Epoch 0087] loss=11.6799 cls=0.0055 smmd=0.0547 ct=9.2826 rec=1.1685 | train/val/test=1.000/0.686/0.694 | c=0.998437
[Epoch 0088] loss=11.6531 cls=0.0061 smmd=0.0589 ct=9.2605 rec=1.1638 | train/val/test=1.000/0.678/0.695 | c=0.998437
[Epoch 0089] loss=11.6587 cls=0.0095 smmd=0.0406 ct=9.2631 rec=1.1728 | train/val/test=1.000/0.664/0.687 | c=0.998437
[Epoch 0090] loss=11.6968 cls=0.0126 smmd=0.0431 ct=9.2741 rec=1.1835 | train/val/test=1.000/0.680/0.694 | c=0.998437
[Epoch 0091] loss=11.6248 cls=0.0129 smmd=0.0014 ct=9.2514 rec=1.1796 | train/val/test=1.000/0.666/0.680 | c=0.998437
[Epoch 0092] loss=11.6926 cls=0.0225 smmd=0.0412 ct=9.2519 rec=1.1885 | train/val/test=1.000/0.666/0.686 | c=0.998437
[Epoch 0093] loss=11.6791 cls=0.0216 smmd=0.0144 ct=9.2712 rec=1.1860 | train/val/test=1.000/0.682/0.705 | c=0.998437
[Epoch 0094] loss=11.6319 cls=0.0205 smmd=0.0030 ct=9.2529 rec=1.1777 | train/val/test=1.000/0.674/0.688 | c=0.998437
[Epoch 0095] loss=11.6358 cls=0.0233 smmd=0.0196 ct=9.2452 rec=1.1739 | train/val/test=1.000/0.676/0.695 | c=0.998437
[Epoch 0096] loss=11.6273 cls=0.0183 smmd=0.0061 ct=9.2617 rec=1.1706 | train/val/test=1.000/0.680/0.702 | c=0.998437
[Epoch 0097] loss=11.6025 cls=0.0158 smmd=0.0038 ct=9.2509 rec=1.1660 | train/val/test=1.000/0.682/0.698 | c=0.998437
[Epoch 0098] loss=11.6150 cls=0.0171 smmd=0.0189 ct=9.2478 rec=1.1656 | train/val/test=1.000/0.678/0.694 | c=0.998437
[Epoch 0099] loss=11.5971 cls=0.0136 smmd=0.0079 ct=9.2491 rec=1.1633 | train/val/test=1.000/0.672/0.702 | c=0.998437
=== Best @ epoch 46: val=0.6920, test=0.6970 ===
