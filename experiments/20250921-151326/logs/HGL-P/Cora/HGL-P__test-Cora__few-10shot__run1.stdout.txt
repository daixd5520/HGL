Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.1701 cls=1.9452 smmd=4.1906 ct=9.2565 rec=1.3889 | train/val/test=0.293/0.128/0.144 | c=0.998437
[Epoch 0001] loss=16.6523 cls=1.8964 smmd=2.7826 ct=9.1949 rec=1.3892 | train/val/test=0.655/0.292/0.282 | c=0.998437
[Epoch 0002] loss=15.1097 cls=1.7780 smmd=1.4689 ct=9.0855 rec=1.3886 | train/val/test=0.655/0.448/0.433 | c=0.998437
[Epoch 0003] loss=14.8279 cls=1.5608 smmd=1.4603 ct=9.0329 rec=1.3870 | train/val/test=0.948/0.606/0.592 | c=0.998437
[Epoch 0004] loss=14.5889 cls=1.2349 smmd=1.6875 ct=8.9112 rec=1.3777 | train/val/test=0.983/0.646/0.634 | c=0.998437
[Epoch 0005] loss=14.0953 cls=0.8961 smmd=1.6294 ct=8.8558 rec=1.3570 | train/val/test=0.931/0.622/0.599 | c=0.998437
[Epoch 0006] loss=13.3928 cls=0.6094 smmd=1.3120 ct=8.8166 rec=1.3273 | train/val/test=0.966/0.662/0.638 | c=0.998437
[Epoch 0007] loss=12.7833 cls=0.3876 smmd=0.9994 ct=8.8013 rec=1.2975 | train/val/test=1.000/0.700/0.677 | c=0.998437
[Epoch 0008] loss=12.5509 cls=0.2290 smmd=0.9921 ct=8.7905 rec=1.2696 | train/val/test=1.000/0.694/0.676 | c=0.998437
[Epoch 0009] loss=12.4698 cls=0.1307 smmd=1.0697 ct=8.7826 rec=1.2434 | train/val/test=1.000/0.696/0.676 | c=0.998437
[Epoch 0010] loss=12.3886 cls=0.0744 smmd=1.0986 ct=8.7744 rec=1.2206 | train/val/test=1.000/0.696/0.675 | c=0.998437
[Epoch 0011] loss=12.2173 cls=0.0448 smmd=0.9943 ct=8.7691 rec=1.2045 | train/val/test=1.000/0.704/0.677 | c=0.998437
[Epoch 0012] loss=12.7218 cls=0.0271 smmd=0.8491 ct=9.4592 rec=1.1932 | train/val/test=1.000/0.706/0.681 | c=0.998437
[Epoch 0013] loss=12.5166 cls=0.0166 smmd=0.7226 ct=9.4057 rec=1.1859 | train/val/test=1.000/0.706/0.680 | c=0.998437
[Epoch 0014] loss=12.4940 cls=0.0114 smmd=0.7589 ct=9.3599 rec=1.1819 | train/val/test=1.000/0.704/0.677 | c=0.998437
[Epoch 0015] loss=12.4933 cls=0.0087 smmd=0.7775 ct=9.3487 rec=1.1792 | train/val/test=1.000/0.702/0.672 | c=0.998437
[Epoch 0016] loss=12.4226 cls=0.0077 smmd=0.6908 ct=9.3688 rec=1.1776 | train/val/test=1.000/0.702/0.669 | c=0.998437
[Epoch 0017] loss=12.2991 cls=0.0074 smmd=0.5424 ct=9.3946 rec=1.1773 | train/val/test=1.000/0.710/0.679 | c=0.998437
[Epoch 0018] loss=12.2225 cls=0.0080 smmd=0.4537 ct=9.4042 rec=1.1783 | train/val/test=1.000/0.712/0.682 | c=0.998437
[Epoch 0019] loss=12.1680 cls=0.0093 smmd=0.3994 ct=9.3994 rec=1.1800 | train/val/test=1.000/0.712/0.682 | c=0.998437
[Epoch 0020] loss=12.1736 cls=0.0115 smmd=0.4034 ct=9.3941 rec=1.1823 | train/val/test=1.000/0.712/0.683 | c=0.998437
[Epoch 0021] loss=12.1311 cls=0.0148 smmd=0.3537 ct=9.3927 rec=1.1850 | train/val/test=1.000/0.716/0.683 | c=0.998437
[Epoch 0022] loss=12.0581 cls=0.0190 smmd=0.2738 ct=9.3924 rec=1.1864 | train/val/test=1.000/0.714/0.685 | c=0.998437
[Epoch 0023] loss=12.0318 cls=0.0242 smmd=0.2407 ct=9.3936 rec=1.1866 | train/val/test=1.000/0.716/0.689 | c=0.998437
[Epoch 0024] loss=12.0382 cls=0.0301 smmd=0.2407 ct=9.3962 rec=1.1856 | train/val/test=1.000/0.714/0.697 | c=0.998437
[Epoch 0025] loss=11.9970 cls=0.0347 smmd=0.2014 ct=9.3938 rec=1.1835 | train/val/test=1.000/0.716/0.697 | c=0.998437
[Epoch 0026] loss=11.9598 cls=0.0398 smmd=0.1764 ct=9.3838 rec=1.1799 | train/val/test=1.000/0.720/0.701 | c=0.998437
[Epoch 0027] loss=11.9470 cls=0.0393 smmd=0.1722 ct=9.3825 rec=1.1765 | train/val/test=1.000/0.724/0.694 | c=0.998437
[Epoch 0028] loss=11.9480 cls=0.0436 smmd=0.1774 ct=9.3803 rec=1.1734 | train/val/test=1.000/0.736/0.712 | c=0.998437
[Epoch 0029] loss=11.9248 cls=0.0392 smmd=0.1435 ct=9.3948 rec=1.1737 | train/val/test=1.000/0.716/0.682 | c=0.998437
[Epoch 0030] loss=11.9253 cls=0.0424 smmd=0.1574 ct=9.3834 rec=1.1710 | train/val/test=1.000/0.726/0.721 | c=0.998437
[Epoch 0031] loss=11.8837 cls=0.0291 smmd=0.1354 ct=9.3816 rec=1.1688 | train/val/test=1.000/0.718/0.695 | c=0.998437
[Epoch 0032] loss=11.8319 cls=0.0194 smmd=0.1299 ct=9.3599 rec=1.1614 | train/val/test=1.000/0.718/0.693 | c=0.998437
[Epoch 0033] loss=11.8155 cls=0.0187 smmd=0.1226 ct=9.3511 rec=1.1616 | train/val/test=1.000/0.720/0.705 | c=0.998437
[Epoch 0034] loss=11.8049 cls=0.0171 smmd=0.1104 ct=9.3517 rec=1.1629 | train/val/test=1.000/0.720/0.690 | c=0.998437
[Epoch 0035] loss=11.7782 cls=0.0144 smmd=0.0893 ct=9.3526 rec=1.1609 | train/val/test=1.000/0.720/0.694 | c=0.998437
[Epoch 0036] loss=11.7709 cls=0.0155 smmd=0.0830 ct=9.3487 rec=1.1618 | train/val/test=1.000/0.720/0.701 | c=0.998437
[Epoch 0037] loss=11.7560 cls=0.0150 smmd=0.0667 ct=9.3480 rec=1.1632 | train/val/test=1.000/0.728/0.691 | c=0.998437
[Epoch 0038] loss=11.7578 cls=0.0154 smmd=0.0674 ct=9.3469 rec=1.1641 | train/val/test=1.000/0.720/0.699 | c=0.998437
[Epoch 0039] loss=11.7491 cls=0.0174 smmd=0.0631 ct=9.3393 rec=1.1646 | train/val/test=1.000/0.726/0.699 | c=0.998437
[Epoch 0040] loss=11.7341 cls=0.0172 smmd=0.0534 ct=9.3340 rec=1.1648 | train/val/test=1.000/0.722/0.693 | c=0.998437
[Epoch 0041] loss=11.7350 cls=0.0195 smmd=0.0455 ct=9.3378 rec=1.1661 | train/val/test=1.000/0.730/0.704 | c=0.998437
[Epoch 0042] loss=11.7422 cls=0.0223 smmd=0.0461 ct=9.3393 rec=1.1673 | train/val/test=1.000/0.726/0.700 | c=0.998437
[Epoch 0043] loss=11.7294 cls=0.0231 smmd=0.0393 ct=9.3337 rec=1.1667 | train/val/test=1.000/0.734/0.709 | c=0.998437
[Epoch 0044] loss=11.7236 cls=0.0239 smmd=0.0329 ct=9.3350 rec=1.1659 | train/val/test=1.000/0.726/0.699 | c=0.998437
[Epoch 0045] loss=11.7171 cls=0.0262 smmd=0.0311 ct=9.3287 rec=1.1656 | train/val/test=1.000/0.736/0.708 | c=0.998437
[Epoch 0046] loss=11.7140 cls=0.0248 smmd=0.0307 ct=9.3274 rec=1.1655 | train/val/test=1.000/0.728/0.699 | c=0.998437
[Epoch 0047] loss=11.7077 cls=0.0242 smmd=0.0380 ct=9.3195 rec=1.1630 | train/val/test=1.000/0.730/0.705 | c=0.998437
[Epoch 0048] loss=11.6910 cls=0.0227 smmd=0.0260 ct=9.3170 rec=1.1627 | train/val/test=1.000/0.728/0.702 | c=0.998437
[Epoch 0049] loss=11.6881 cls=0.0219 smmd=0.0187 ct=9.3213 rec=1.1631 | train/val/test=1.000/0.726/0.703 | c=0.998437
[Epoch 0050] loss=11.6872 cls=0.0217 smmd=0.0221 ct=9.3187 rec=1.1624 | train/val/test=1.000/0.728/0.701 | c=0.998437
[Epoch 0051] loss=11.6749 cls=0.0203 smmd=0.0184 ct=9.3109 rec=1.1626 | train/val/test=1.000/0.724/0.706 | c=0.998437
[Epoch 0052] loss=11.6769 cls=0.0201 smmd=0.0226 ct=9.3079 rec=1.1632 | train/val/test=1.000/0.724/0.700 | c=0.998437
[Epoch 0053] loss=11.6739 cls=0.0209 smmd=0.0145 ct=9.3111 rec=1.1637 | train/val/test=1.000/0.726/0.703 | c=0.998437
[Epoch 0054] loss=11.6742 cls=0.0202 smmd=0.0129 ct=9.3121 rec=1.1644 | train/val/test=1.000/0.728/0.701 | c=0.998437
[Epoch 0055] loss=11.6715 cls=0.0212 smmd=0.0134 ct=9.3071 rec=1.1649 | train/val/test=1.000/0.726/0.703 | c=0.998437
[Epoch 0056] loss=11.6774 cls=0.0218 smmd=0.0199 ct=9.3046 rec=1.1655 | train/val/test=1.000/0.730/0.698 | c=0.998437
[Epoch 0057] loss=11.6794 cls=0.0227 smmd=0.0167 ct=9.3060 rec=1.1670 | train/val/test=1.000/0.726/0.707 | c=0.998437
[Epoch 0058] loss=11.6961 cls=0.0249 smmd=0.0190 ct=9.3156 rec=1.1683 | train/val/test=1.000/0.726/0.689 | c=0.998437
[Epoch 0059] loss=11.7112 cls=0.0278 smmd=0.0295 ct=9.3116 rec=1.1711 | train/val/test=1.000/0.734/0.701 | c=0.998437
[Epoch 0060] loss=11.7596 cls=0.0318 smmd=0.0463 ct=9.3282 rec=1.1767 | train/val/test=1.000/0.704/0.671 | c=0.998437
[Epoch 0061] loss=11.8014 cls=0.0386 smmd=0.0761 ct=9.3281 rec=1.1793 | train/val/test=1.000/0.732/0.707 | c=0.998437
[Epoch 0062] loss=11.7397 cls=0.0249 smmd=0.0483 ct=9.3261 rec=1.1702 | train/val/test=1.000/0.722/0.702 | c=0.998437
[Epoch 0063] loss=11.6560 cls=0.0169 smmd=0.0192 ct=9.3024 rec=1.1588 | train/val/test=1.000/0.720/0.686 | c=0.998437
[Epoch 0064] loss=11.7056 cls=0.0193 smmd=0.0466 ct=9.3128 rec=1.1635 | train/val/test=1.000/0.726/0.702 | c=0.998437
[Epoch 0065] loss=11.7054 cls=0.0175 smmd=0.0472 ct=9.3164 rec=1.1621 | train/val/test=1.000/0.724/0.702 | c=0.998437
[Epoch 0066] loss=11.6545 cls=0.0155 smmd=0.0179 ct=9.3023 rec=1.1595 | train/val/test=1.000/0.716/0.681 | c=0.998437
[Epoch 0067] loss=11.6917 cls=0.0183 smmd=0.0372 ct=9.3062 rec=1.1650 | train/val/test=1.000/0.722/0.697 | c=0.998437
[Epoch 0068] loss=11.6828 cls=0.0194 smmd=0.0245 ct=9.3085 rec=1.1652 | train/val/test=1.000/0.720/0.692 | c=0.998437
[Epoch 0069] loss=11.6646 cls=0.0193 smmd=0.0127 ct=9.3006 rec=1.1660 | train/val/test=1.000/0.716/0.680 | c=0.998437
[Epoch 0070] loss=11.6870 cls=0.0232 smmd=0.0237 ct=9.2989 rec=1.1706 | train/val/test=1.000/0.722/0.695 | c=0.998437
[Epoch 0071] loss=11.6867 cls=0.0247 smmd=0.0142 ct=9.3065 rec=1.1706 | train/val/test=1.000/0.708/0.684 | c=0.998437
[Epoch 0072] loss=11.6762 cls=0.0235 smmd=0.0141 ct=9.2994 rec=1.1696 | train/val/test=1.000/0.722/0.692 | c=0.998437
[Epoch 0073] loss=11.6708 cls=0.0252 smmd=0.0158 ct=9.2922 rec=1.1688 | train/val/test=1.000/0.726/0.698 | c=0.998437
[Epoch 0074] loss=11.6678 cls=0.0240 smmd=0.0093 ct=9.2993 rec=1.1676 | train/val/test=1.000/0.710/0.684 | c=0.998437
[Epoch 0075] loss=11.6636 cls=0.0248 smmd=0.0095 ct=9.2950 rec=1.1671 | train/val/test=1.000/0.722/0.698 | c=0.998437
[Epoch 0076] loss=11.6602 cls=0.0236 smmd=0.0126 ct=9.2918 rec=1.1661 | train/val/test=1.000/0.726/0.696 | c=0.998437
[Epoch 0077] loss=11.6549 cls=0.0223 smmd=0.0092 ct=9.2925 rec=1.1654 | train/val/test=1.000/0.714/0.682 | c=0.998437
[Epoch 0078] loss=11.6523 cls=0.0231 smmd=0.0073 ct=9.2901 rec=1.1659 | train/val/test=1.000/0.728/0.700 | c=0.998437
[Epoch 0079] loss=11.6563 cls=0.0224 smmd=0.0123 ct=9.2880 rec=1.1668 | train/val/test=1.000/0.722/0.691 | c=0.998437
[Epoch 0080] loss=11.6466 cls=0.0216 smmd=0.0081 ct=9.2844 rec=1.1662 | train/val/test=1.000/0.720/0.690 | c=0.998437
[Epoch 0081] loss=11.6363 cls=0.0220 smmd=-0.0009 ct=9.2827 rec=1.1663 | train/val/test=1.000/0.726/0.698 | c=0.998437
[Epoch 0082] loss=11.6465 cls=0.0224 smmd=0.0049 ct=9.2832 rec=1.1680 | train/val/test=1.000/0.714/0.683 | c=0.998437
[Epoch 0083] loss=11.6464 cls=0.0227 smmd=0.0029 ct=9.2844 rec=1.1681 | train/val/test=1.000/0.724/0.696 | c=0.998437
[Epoch 0084] loss=11.6464 cls=0.0237 smmd=0.0058 ct=9.2809 rec=1.1680 | train/val/test=1.000/0.726/0.691 | c=0.998437
[Epoch 0085] loss=11.6417 cls=0.0222 smmd=0.0076 ct=9.2763 rec=1.1678 | train/val/test=1.000/0.722/0.693 | c=0.998437
[Epoch 0086] loss=11.6398 cls=0.0242 smmd=0.0008 ct=9.2819 rec=1.1664 | train/val/test=1.000/0.726/0.694 | c=0.998437
[Epoch 0087] loss=11.6271 cls=0.0208 smmd=0.0005 ct=9.2749 rec=1.1654 | train/val/test=1.000/0.726/0.692 | c=0.998437
[Epoch 0088] loss=11.6211 cls=0.0205 smmd=-0.0023 ct=9.2730 rec=1.1649 | train/val/test=1.000/0.724/0.694 | c=0.998437
[Epoch 0089] loss=11.6322 cls=0.0227 smmd=0.0024 ct=9.2756 rec=1.1657 | train/val/test=1.000/0.728/0.693 | c=0.998437
[Epoch 0090] loss=11.6319 cls=0.0219 smmd=0.0062 ct=9.2697 rec=1.1671 | train/val/test=1.000/0.728/0.697 | c=0.998437
[Epoch 0091] loss=11.6251 cls=0.0220 smmd=-0.0032 ct=9.2731 rec=1.1666 | train/val/test=1.000/0.720/0.687 | c=0.998437
[Epoch 0092] loss=11.6283 cls=0.0222 smmd=0.0003 ct=9.2712 rec=1.1673 | train/val/test=1.000/0.730/0.701 | c=0.998437
[Epoch 0093] loss=11.6334 cls=0.0227 smmd=0.0044 ct=9.2685 rec=1.1689 | train/val/test=1.000/0.716/0.686 | c=0.998437
[Epoch 0094] loss=11.6313 cls=0.0234 smmd=0.0018 ct=9.2698 rec=1.1681 | train/val/test=1.000/0.728/0.697 | c=0.998437
[Epoch 0095] loss=11.6210 cls=0.0223 smmd=-0.0076 ct=9.2705 rec=1.1679 | train/val/test=1.000/0.724/0.689 | c=0.998437
[Epoch 0096] loss=11.6251 cls=0.0222 smmd=0.0024 ct=9.2662 rec=1.1671 | train/val/test=1.000/0.730/0.695 | c=0.998437
[Epoch 0097] loss=11.6217 cls=0.0224 smmd=-0.0036 ct=9.2693 rec=1.1668 | train/val/test=1.000/0.726/0.688 | c=0.998437
[Epoch 0098] loss=11.6222 cls=0.0222 smmd=-0.0001 ct=9.2654 rec=1.1674 | train/val/test=1.000/0.730/0.702 | c=0.998437
[Epoch 0099] loss=11.6284 cls=0.0231 smmd=0.0017 ct=9.2688 rec=1.1674 | train/val/test=1.000/0.724/0.686 | c=0.998437
=== Best @ epoch 28: val=0.7360, test=0.7120 ===
