Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.1665 cls=1.9506 smmd=4.1760 ct=9.2621 rec=1.3889 | train/val/test=0.172/0.072/0.091 | c=0.998437
[Epoch 0001] loss=16.6411 cls=1.8875 smmd=2.7838 ct=9.1912 rec=1.3893 | train/val/test=0.724/0.310/0.342 | c=0.998437
[Epoch 0002] loss=15.0927 cls=1.7430 smmd=1.4766 ct=9.0956 rec=1.3887 | train/val/test=0.862/0.256/0.309 | c=0.998437
[Epoch 0003] loss=14.8330 cls=1.4881 smmd=1.4797 ct=9.0917 rec=1.3868 | train/val/test=0.862/0.420/0.451 | c=0.998437
[Epoch 0004] loss=14.6490 cls=1.1296 smmd=1.7259 ct=9.0325 rec=1.3805 | train/val/test=0.931/0.514/0.532 | c=0.998437
[Epoch 0005] loss=14.0584 cls=0.7860 smmd=1.6314 ct=8.9148 rec=1.3631 | train/val/test=1.000/0.416/0.481 | c=0.998437
[Epoch 0006] loss=13.4958 cls=0.5643 smmd=1.3786 ct=8.8677 rec=1.3426 | train/val/test=1.000/0.570/0.579 | c=0.998437
[Epoch 0007] loss=12.9030 cls=0.3374 smmd=1.1008 ct=8.8320 rec=1.3164 | train/val/test=1.000/0.624/0.640 | c=0.998437
[Epoch 0008] loss=12.6448 cls=0.2068 smmd=1.0200 ct=8.8421 rec=1.2879 | train/val/test=1.000/0.622/0.640 | c=0.998437
[Epoch 0009] loss=12.5444 cls=0.1204 smmd=1.0699 ct=8.8302 rec=1.2620 | train/val/test=1.000/0.604/0.628 | c=0.998437
[Epoch 0010] loss=12.4582 cls=0.0678 smmd=1.0921 ct=8.8100 rec=1.2442 | train/val/test=1.000/0.594/0.622 | c=0.998437
[Epoch 0011] loss=12.3219 cls=0.0380 smmd=1.0211 ct=8.7995 rec=1.2316 | train/val/test=1.000/0.608/0.642 | c=0.998437
[Epoch 0012] loss=12.7802 cls=0.0212 smmd=0.8548 ct=9.4692 rec=1.2175 | train/val/test=1.000/0.626/0.646 | c=0.998437
[Epoch 0013] loss=12.6101 cls=0.0123 smmd=0.7721 ct=9.4178 rec=1.2039 | train/val/test=1.000/0.626/0.650 | c=0.998437
[Epoch 0014] loss=12.5235 cls=0.0083 smmd=0.7506 ct=9.3730 rec=1.1958 | train/val/test=1.000/0.626/0.647 | c=0.998437
[Epoch 0015] loss=12.5186 cls=0.0064 smmd=0.7757 ct=9.3545 rec=1.1910 | train/val/test=1.000/0.624/0.641 | c=0.998437
[Epoch 0016] loss=12.4546 cls=0.0052 smmd=0.7084 ct=9.3672 rec=1.1869 | train/val/test=1.000/0.628/0.648 | c=0.998437
[Epoch 0017] loss=12.3744 cls=0.0046 smmd=0.5986 ct=9.4031 rec=1.1841 | train/val/test=1.000/0.640/0.654 | c=0.998437
[Epoch 0018] loss=12.2698 cls=0.0044 smmd=0.4760 ct=9.4263 rec=1.1816 | train/val/test=1.000/0.630/0.649 | c=0.998437
[Epoch 0019] loss=12.1949 cls=0.0052 smmd=0.4045 ct=9.4222 rec=1.1815 | train/val/test=1.000/0.632/0.640 | c=0.998437
[Epoch 0020] loss=12.1852 cls=0.0066 smmd=0.4089 ct=9.4030 rec=1.1833 | train/val/test=1.000/0.632/0.650 | c=0.998437
[Epoch 0021] loss=12.1457 cls=0.0084 smmd=0.3746 ct=9.3923 rec=1.1852 | train/val/test=1.000/0.632/0.648 | c=0.998437
[Epoch 0022] loss=12.0773 cls=0.0122 smmd=0.3007 ct=9.3902 rec=1.1871 | train/val/test=1.000/0.636/0.640 | c=0.998437
[Epoch 0023] loss=12.0303 cls=0.0182 smmd=0.2451 ct=9.3879 rec=1.1895 | train/val/test=1.000/0.634/0.644 | c=0.998437
[Epoch 0024] loss=12.0367 cls=0.0222 smmd=0.2367 ct=9.3971 rec=1.1904 | train/val/test=1.000/0.644/0.653 | c=0.998437
[Epoch 0025] loss=12.0268 cls=0.0285 smmd=0.2158 ct=9.4035 rec=1.1895 | train/val/test=1.000/0.644/0.653 | c=0.998437
[Epoch 0026] loss=11.9816 cls=0.0315 smmd=0.1764 ct=9.3990 rec=1.1874 | train/val/test=1.000/0.648/0.653 | c=0.998437
[Epoch 0027] loss=11.9478 cls=0.0338 smmd=0.1466 ct=9.4011 rec=1.1831 | train/val/test=1.000/0.644/0.652 | c=0.998437
[Epoch 0028] loss=11.9395 cls=0.0353 smmd=0.1559 ct=9.3909 rec=1.1787 | train/val/test=1.000/0.654/0.658 | c=0.998437
[Epoch 0029] loss=11.9152 cls=0.0329 smmd=0.1464 ct=9.3882 rec=1.1738 | train/val/test=1.000/0.648/0.658 | c=0.998437
[Epoch 0030] loss=11.8667 cls=0.0266 smmd=0.1292 ct=9.3727 rec=1.1691 | train/val/test=1.000/0.654/0.662 | c=0.998437
[Epoch 0031] loss=11.8317 cls=0.0213 smmd=0.1092 ct=9.3715 rec=1.1649 | train/val/test=1.000/0.660/0.663 | c=0.998437
[Epoch 0032] loss=11.8302 cls=0.0178 smmd=0.1115 ct=9.3753 rec=1.1628 | train/val/test=1.000/0.654/0.660 | c=0.998437
[Epoch 0033] loss=11.8073 cls=0.0156 smmd=0.0971 ct=9.3715 rec=1.1616 | train/val/test=1.000/0.654/0.664 | c=0.998437
[Epoch 0034] loss=11.7836 cls=0.0135 smmd=0.0790 ct=9.3697 rec=1.1607 | train/val/test=1.000/0.654/0.664 | c=0.998437
[Epoch 0035] loss=11.7760 cls=0.0129 smmd=0.0767 ct=9.3637 rec=1.1614 | train/val/test=1.000/0.654/0.662 | c=0.998437
[Epoch 0036] loss=11.7715 cls=0.0127 smmd=0.0775 ct=9.3568 rec=1.1622 | train/val/test=1.000/0.652/0.662 | c=0.998437
[Epoch 0037] loss=11.7477 cls=0.0129 smmd=0.0486 ct=9.3591 rec=1.1635 | train/val/test=1.000/0.656/0.660 | c=0.998437
[Epoch 0038] loss=11.7518 cls=0.0132 smmd=0.0499 ct=9.3573 rec=1.1657 | train/val/test=1.000/0.654/0.659 | c=0.998437
[Epoch 0039] loss=11.7456 cls=0.0143 smmd=0.0408 ct=9.3563 rec=1.1671 | train/val/test=1.000/0.654/0.660 | c=0.998437
[Epoch 0040] loss=11.7460 cls=0.0145 smmd=0.0362 ct=9.3575 rec=1.1689 | train/val/test=1.000/0.652/0.659 | c=0.998437
[Epoch 0041] loss=11.7357 cls=0.0160 smmd=0.0273 ct=9.3552 rec=1.1686 | train/val/test=1.000/0.652/0.661 | c=0.998437
[Epoch 0042] loss=11.7358 cls=0.0161 smmd=0.0348 ct=9.3467 rec=1.1692 | train/val/test=1.000/0.652/0.661 | c=0.998437
[Epoch 0043] loss=11.7317 cls=0.0176 smmd=0.0280 ct=9.3513 rec=1.1674 | train/val/test=1.000/0.652/0.658 | c=0.998437
[Epoch 0044] loss=11.7353 cls=0.0180 smmd=0.0337 ct=9.3483 rec=1.1676 | train/val/test=1.000/0.654/0.661 | c=0.998437
[Epoch 0045] loss=11.7401 cls=0.0207 smmd=0.0259 ct=9.3603 rec=1.1666 | train/val/test=1.000/0.646/0.656 | c=0.998437
[Epoch 0046] loss=11.7465 cls=0.0211 smmd=0.0442 ct=9.3455 rec=1.1678 | train/val/test=1.000/0.658/0.667 | c=0.998437
[Epoch 0047] loss=11.7497 cls=0.0198 smmd=0.0400 ct=9.3593 rec=1.1653 | train/val/test=1.000/0.650/0.660 | c=0.998437
[Epoch 0048] loss=11.7106 cls=0.0164 smmd=0.0333 ct=9.3365 rec=1.1622 | train/val/test=1.000/0.656/0.661 | c=0.998437
[Epoch 0049] loss=11.6891 cls=0.0134 smmd=0.0174 ct=9.3391 rec=1.1596 | train/val/test=1.000/0.652/0.662 | c=0.998437
[Epoch 0050] loss=11.7025 cls=0.0139 smmd=0.0220 ct=9.3446 rec=1.1610 | train/val/test=1.000/0.652/0.659 | c=0.998437
[Epoch 0051] loss=11.7045 cls=0.0147 smmd=0.0274 ct=9.3354 rec=1.1635 | train/val/test=1.000/0.656/0.665 | c=0.998437
[Epoch 0052] loss=11.6927 cls=0.0140 smmd=0.0061 ct=9.3466 rec=1.1630 | train/val/test=1.000/0.652/0.660 | c=0.998437
[Epoch 0053] loss=11.6867 cls=0.0137 smmd=0.0133 ct=9.3328 rec=1.1634 | train/val/test=1.000/0.656/0.662 | c=0.998437
[Epoch 0054] loss=11.6876 cls=0.0142 smmd=0.0119 ct=9.3297 rec=1.1659 | train/val/test=1.000/0.654/0.659 | c=0.998437
[Epoch 0055] loss=11.7003 cls=0.0175 smmd=0.0080 ct=9.3388 rec=1.1679 | train/val/test=1.000/0.650/0.657 | c=0.998437
[Epoch 0056] loss=11.7140 cls=0.0174 smmd=0.0188 ct=9.3339 rec=1.1719 | train/val/test=1.000/0.656/0.660 | c=0.998437
[Epoch 0057] loss=11.7302 cls=0.0226 smmd=0.0103 ct=9.3526 rec=1.1723 | train/val/test=1.000/0.648/0.656 | c=0.998437
[Epoch 0058] loss=11.7383 cls=0.0203 smmd=0.0324 ct=9.3365 rec=1.1745 | train/val/test=1.000/0.660/0.663 | c=0.998437
[Epoch 0059] loss=11.7287 cls=0.0196 smmd=0.0192 ct=9.3505 rec=1.1697 | train/val/test=1.000/0.652/0.658 | c=0.998437
[Epoch 0060] loss=11.6835 cls=0.0151 smmd=0.0157 ct=9.3246 rec=1.1641 | train/val/test=1.000/0.656/0.664 | c=0.998437
[Epoch 0061] loss=11.6764 cls=0.0141 smmd=0.0096 ct=9.3268 rec=1.1629 | train/val/test=1.000/0.658/0.663 | c=0.998437
[Epoch 0062] loss=11.6904 cls=0.0143 smmd=0.0121 ct=9.3385 rec=1.1628 | train/val/test=1.000/0.652/0.663 | c=0.998437
[Epoch 0063] loss=11.6785 cls=0.0141 smmd=0.0177 ct=9.3223 rec=1.1622 | train/val/test=1.000/0.658/0.664 | c=0.998437
[Epoch 0064] loss=11.6702 cls=0.0137 smmd=0.0043 ct=9.3267 rec=1.1628 | train/val/test=1.000/0.650/0.658 | c=0.998437
[Epoch 0065] loss=11.6809 cls=0.0158 smmd=0.0016 ct=9.3338 rec=1.1649 | train/val/test=1.000/0.650/0.659 | c=0.998437
[Epoch 0066] loss=11.6829 cls=0.0163 smmd=0.0121 ct=9.3195 rec=1.1674 | train/val/test=1.000/0.652/0.663 | c=0.998437
[Epoch 0067] loss=11.6760 cls=0.0167 smmd=-0.0022 ct=9.3264 rec=1.1676 | train/val/test=1.000/0.650/0.658 | c=0.998437
[Epoch 0068] loss=11.6739 cls=0.0181 smmd=-0.0029 ct=9.3201 rec=1.1693 | train/val/test=1.000/0.658/0.660 | c=0.998437
[Epoch 0069] loss=11.6768 cls=0.0178 smmd=-0.0051 ct=9.3219 rec=1.1711 | train/val/test=1.000/0.652/0.657 | c=0.998437
[Epoch 0070] loss=11.6822 cls=0.0206 smmd=-0.0027 ct=9.3216 rec=1.1713 | train/val/test=1.000/0.658/0.661 | c=0.998437
[Epoch 0071] loss=11.6830 cls=0.0186 smmd=-0.0012 ct=9.3199 rec=1.1728 | train/val/test=1.000/0.654/0.659 | c=0.998437
[Epoch 0072] loss=11.6858 cls=0.0205 smmd=-0.0053 ct=9.3293 rec=1.1706 | train/val/test=1.000/0.648/0.660 | c=0.998437
[Epoch 0073] loss=11.6815 cls=0.0175 smmd=0.0126 ct=9.3120 rec=1.1697 | train/val/test=1.000/0.656/0.663 | c=0.998437
[Epoch 0074] loss=11.6682 cls=0.0163 smmd=-0.0032 ct=9.3215 rec=1.1668 | train/val/test=1.000/0.652/0.660 | c=0.998437
[Epoch 0075] loss=11.6584 cls=0.0154 smmd=0.0013 ct=9.3120 rec=1.1649 | train/val/test=1.000/0.658/0.660 | c=0.998437
[Epoch 0076] loss=11.6529 cls=0.0143 smmd=-0.0062 ct=9.3143 rec=1.1652 | train/val/test=1.000/0.648/0.659 | c=0.998437
[Epoch 0077] loss=11.6488 cls=0.0146 smmd=-0.0086 ct=9.3149 rec=1.1640 | train/val/test=1.000/0.650/0.660 | c=0.998437
[Epoch 0078] loss=11.6475 cls=0.0147 smmd=-0.0029 ct=9.3060 rec=1.1648 | train/val/test=1.000/0.658/0.660 | c=0.998437
[Epoch 0079] loss=11.6494 cls=0.0150 smmd=-0.0099 ct=9.3119 rec=1.1662 | train/val/test=1.000/0.648/0.657 | c=0.998437
[Epoch 0080] loss=11.6520 cls=0.0174 smmd=-0.0075 ct=9.3067 rec=1.1677 | train/val/test=1.000/0.652/0.660 | c=0.998437
[Epoch 0081] loss=11.6537 cls=0.0168 smmd=-0.0110 ct=9.3081 rec=1.1699 | train/val/test=1.000/0.648/0.657 | c=0.998437
[Epoch 0082] loss=11.6535 cls=0.0189 smmd=-0.0133 ct=9.3078 rec=1.1700 | train/val/test=1.000/0.646/0.658 | c=0.998437
[Epoch 0083] loss=11.6529 cls=0.0178 smmd=-0.0100 ct=9.3031 rec=1.1710 | train/val/test=1.000/0.658/0.661 | c=0.998437
[Epoch 0084] loss=11.6560 cls=0.0193 smmd=-0.0180 ct=9.3121 rec=1.1713 | train/val/test=1.000/0.646/0.656 | c=0.998437
[Epoch 0085] loss=11.6817 cls=0.0208 smmd=0.0112 ct=9.3027 rec=1.1735 | train/val/test=1.000/0.648/0.664 | c=0.998437
[Epoch 0086] loss=11.7058 cls=0.0241 smmd=0.0021 ct=9.3260 rec=1.1768 | train/val/test=1.000/0.648/0.644 | c=0.998437
[Epoch 0087] loss=11.7326 cls=0.0252 smmd=0.0447 ct=9.3090 rec=1.1769 | train/val/test=1.000/0.658/0.662 | c=0.998437
[Epoch 0088] loss=11.6942 cls=0.0185 smmd=0.0083 ct=9.3282 rec=1.1696 | train/val/test=1.000/0.646/0.660 | c=0.998437
[Epoch 0089] loss=11.6309 cls=0.0111 smmd=-0.0015 ct=9.2983 rec=1.1615 | train/val/test=1.000/0.642/0.656 | c=0.998437
[Epoch 0090] loss=11.6449 cls=0.0123 smmd=0.0105 ct=9.2969 rec=1.1626 | train/val/test=1.000/0.658/0.662 | c=0.998437
[Epoch 0091] loss=11.6592 cls=0.0129 smmd=0.0010 ct=9.3175 rec=1.1639 | train/val/test=1.000/0.646/0.658 | c=0.998437
[Epoch 0092] loss=11.6268 cls=0.0111 smmd=-0.0075 ct=9.2986 rec=1.1623 | train/val/test=1.000/0.644/0.658 | c=0.998437
[Epoch 0093] loss=11.6379 cls=0.0138 smmd=-0.0019 ct=9.2952 rec=1.1654 | train/val/test=1.000/0.654/0.660 | c=0.998437
[Epoch 0094] loss=11.6611 cls=0.0153 smmd=-0.0063 ct=9.3133 rec=1.1694 | train/val/test=1.000/0.642/0.657 | c=0.998437
[Epoch 0095] loss=11.6490 cls=0.0170 smmd=-0.0065 ct=9.2960 rec=1.1712 | train/val/test=1.000/0.646/0.655 | c=0.998437
[Epoch 0096] loss=11.6504 cls=0.0180 smmd=-0.0114 ct=9.3014 rec=1.1712 | train/val/test=1.000/0.656/0.659 | c=0.998437
[Epoch 0097] loss=11.6618 cls=0.0182 smmd=-0.0104 ct=9.3044 rec=1.1748 | train/val/test=1.000/0.646/0.650 | c=0.998437
[Epoch 0098] loss=11.6834 cls=0.0243 smmd=0.0068 ct=9.2995 rec=1.1764 | train/val/test=1.000/0.656/0.663 | c=0.998437
[Epoch 0099] loss=11.6865 cls=0.0205 smmd=0.0063 ct=9.3067 rec=1.1766 | train/val/test=1.000/0.648/0.660 | c=0.998437
=== Best @ epoch 31: val=0.6600, test=0.6630 ===
