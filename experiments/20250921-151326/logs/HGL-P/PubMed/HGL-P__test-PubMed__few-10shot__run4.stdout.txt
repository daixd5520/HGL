Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=40.0925 cls=1.0992 smmd=5.6248 ct=11.2778 rec=1.4136 | train/val/test=0.385/0.390/0.417 | c=0.998437
[Epoch 0001] loss=29.6238 cls=1.0831 smmd=3.5385 ct=11.2484 rec=1.4144 | train/val/test=0.577/0.442/0.473 | c=0.998437
[Epoch 0002] loss=35.8150 cls=1.0630 smmd=4.7755 ct=11.2646 rec=1.4136 | train/val/test=0.615/0.454/0.468 | c=0.998437
[Epoch 0003] loss=35.0951 cls=1.0295 smmd=4.6397 ct=11.2403 rec=1.4136 | train/val/test=0.615/0.490/0.476 | c=0.998437
[Epoch 0004] loss=26.6123 cls=0.9700 smmd=2.8740 ct=11.6162 rec=1.4125 | train/val/test=0.808/0.546/0.510 | c=0.998437
[Epoch 0005] loss=26.5181 cls=0.9092 smmd=2.8862 ct=11.4913 rec=1.4104 | train/val/test=0.885/0.672/0.663 | c=0.998437
[Epoch 0006] loss=28.9342 cls=0.8361 smmd=3.3767 ct=11.4920 rec=1.4070 | train/val/test=0.769/0.694/0.665 | c=0.998437
[Epoch 0007] loss=27.2569 cls=0.7609 smmd=3.0570 ct=11.4511 rec=1.4019 | train/val/test=0.769/0.684/0.672 | c=0.998437
[Epoch 0008] loss=22.9075 cls=0.6991 smmd=2.2156 ct=11.3405 rec=1.3957 | train/val/test=0.769/0.716/0.694 | c=0.998437
[Epoch 0009] loss=22.6524 cls=0.6438 smmd=2.1614 ct=11.3841 rec=1.3922 | train/val/test=0.885/0.708/0.682 | c=0.998437
[Epoch 0010] loss=24.7669 cls=0.6064 smmd=2.5743 ct=11.4529 rec=1.3911 | train/val/test=0.885/0.718/0.697 | c=0.998437
[Epoch 0011] loss=23.4472 cls=0.5691 smmd=2.3147 ct=11.4499 rec=1.3907 | train/val/test=0.846/0.688/0.677 | c=0.998437
[Epoch 0012] loss=20.3913 cls=0.5298 smmd=1.7069 ct=11.4530 rec=1.3900 | train/val/test=1.000/0.736/0.711 | c=0.998437
[Epoch 0013] loss=23.3041 cls=0.4811 smmd=2.2941 ct=11.4543 rec=1.3889 | train/val/test=1.000/0.732/0.707 | c=0.998437
[Epoch 0014] loss=22.4451 cls=0.4142 smmd=2.1444 ct=11.3777 rec=1.3832 | train/val/test=1.000/0.702/0.680 | c=0.998437
[Epoch 0015] loss=19.8635 cls=0.3439 smmd=1.6338 ct=11.3857 rec=1.3694 | train/val/test=1.000/0.734/0.718 | c=0.998437
[Epoch 0016] loss=19.7991 cls=0.2764 smmd=1.6181 ct=11.4339 rec=1.3645 | train/val/test=1.000/0.744/0.709 | c=0.998437
[Epoch 0017] loss=20.2958 cls=0.2261 smmd=1.7182 ct=11.4561 rec=1.3584 | train/val/test=1.000/0.712/0.685 | c=0.998437
[Epoch 0018] loss=18.6893 cls=0.1865 smmd=1.4075 ct=11.4235 rec=1.3503 | train/val/test=1.000/0.724/0.699 | c=0.998437
[Epoch 0019] loss=18.1489 cls=0.1600 smmd=1.3077 ct=11.3960 rec=1.3457 | train/val/test=1.000/0.754/0.727 | c=0.998437
[Epoch 0020] loss=18.3312 cls=0.1417 smmd=1.3511 ct=11.3706 rec=1.3448 | train/val/test=1.000/0.748/0.728 | c=0.998437
[Epoch 0021] loss=18.1459 cls=0.1341 smmd=1.3123 ct=11.3826 rec=1.3466 | train/val/test=1.000/0.748/0.732 | c=0.998437
[Epoch 0022] loss=17.3602 cls=0.1234 smmd=1.1482 ct=11.4235 rec=1.3421 | train/val/test=1.000/0.764/0.741 | c=0.998437
[Epoch 0023] loss=18.0641 cls=0.1252 smmd=1.2888 ct=11.4232 rec=1.3438 | train/val/test=1.000/0.740/0.732 | c=0.998437
[Epoch 0024] loss=17.1708 cls=0.1115 smmd=1.1088 ct=11.4369 rec=1.3396 | train/val/test=1.000/0.762/0.738 | c=0.998437
[Epoch 0025] loss=17.1891 cls=0.1005 smmd=1.1164 ct=11.4236 rec=1.3336 | train/val/test=1.000/0.746/0.731 | c=0.998437
[Epoch 0026] loss=16.6020 cls=0.0867 smmd=1.0122 ct=11.3649 rec=1.3272 | train/val/test=1.000/0.762/0.737 | c=0.998437
[Epoch 0027] loss=16.4429 cls=0.0799 smmd=0.9750 ct=11.3960 rec=1.3213 | train/val/test=1.000/0.770/0.732 | c=0.998437
[Epoch 0028] loss=15.7990 cls=0.0739 smmd=0.8478 ct=11.3912 rec=1.3171 | train/val/test=1.000/0.746/0.734 | c=0.998437
[Epoch 0029] loss=15.9958 cls=0.0763 smmd=0.8876 ct=11.3871 rec=1.3252 | train/val/test=1.000/0.766/0.729 | c=0.998437
[Epoch 0030] loss=15.3799 cls=0.0796 smmd=0.7598 ct=11.4093 rec=1.3205 | train/val/test=1.000/0.748/0.715 | c=0.998437
[Epoch 0031] loss=15.9893 cls=0.0973 smmd=0.8813 ct=11.4015 rec=1.3244 | train/val/test=1.000/0.734/0.727 | c=0.998437
[Epoch 0032] loss=15.8284 cls=0.0963 smmd=0.8548 ct=11.3728 rec=1.3344 | train/val/test=1.000/0.770/0.731 | c=0.998437
[Epoch 0033] loss=15.7422 cls=0.0991 smmd=0.8278 ct=11.4210 rec=1.3280 | train/val/test=1.000/0.732/0.714 | c=0.998437
[Epoch 0034] loss=15.7530 cls=0.0927 smmd=0.8296 ct=11.4255 rec=1.3319 | train/val/test=1.000/0.770/0.737 | c=0.998437
[Epoch 0035] loss=15.1742 cls=0.0874 smmd=0.7239 ct=11.3790 rec=1.3221 | train/val/test=1.000/0.714/0.705 | c=0.998437
[Epoch 0036] loss=15.1580 cls=0.0834 smmd=0.7170 ct=11.3987 rec=1.3268 | train/val/test=1.000/0.772/0.740 | c=0.998437
[Epoch 0037] loss=14.8987 cls=0.0815 smmd=0.6631 ct=11.4107 rec=1.3190 | train/val/test=1.000/0.726/0.706 | c=0.998437
[Epoch 0038] loss=14.7825 cls=0.0818 smmd=0.6517 ct=11.3502 rec=1.3277 | train/val/test=1.000/0.766/0.747 | c=0.998437
[Epoch 0039] loss=14.6484 cls=0.0810 smmd=0.6162 ct=11.3947 rec=1.3205 | train/val/test=1.000/0.762/0.745 | c=0.998437
[Epoch 0040] loss=14.6480 cls=0.0804 smmd=0.6178 ct=11.3864 rec=1.3241 | train/val/test=1.000/0.786/0.752 | c=0.998437
[Epoch 0041] loss=14.7255 cls=0.0872 smmd=0.6366 ct=11.3664 rec=1.3262 | train/val/test=1.000/0.768/0.749 | c=0.998437
[Epoch 0042] loss=15.0334 cls=0.0952 smmd=0.6950 ct=11.3777 rec=1.3330 | train/val/test=1.000/0.780/0.742 | c=0.998437
[Epoch 0043] loss=15.0893 cls=0.0984 smmd=0.6945 ct=11.4345 rec=1.3334 | train/val/test=1.000/0.722/0.681 | c=0.998437
[Epoch 0044] loss=14.8158 cls=0.1072 smmd=0.6491 ct=11.3821 rec=1.3447 | train/val/test=1.000/0.770/0.731 | c=0.998437
[Epoch 0045] loss=14.7400 cls=0.1009 smmd=0.6268 ct=11.4220 rec=1.3339 | train/val/test=1.000/0.730/0.712 | c=0.998437
[Epoch 0046] loss=14.3064 cls=0.0866 smmd=0.5493 ct=11.3836 rec=1.3312 | train/val/test=1.000/0.792/0.748 | c=0.998437
[Epoch 0047] loss=14.2581 cls=0.0794 smmd=0.5457 ct=11.3574 rec=1.3228 | train/val/test=1.000/0.756/0.743 | c=0.998437
[Epoch 0048] loss=13.9794 cls=0.0801 smmd=0.4868 ct=11.3730 rec=1.3256 | train/val/test=1.000/0.788/0.754 | c=0.998437
[Epoch 0049] loss=14.1960 cls=0.0856 smmd=0.5251 ct=11.3953 rec=1.3265 | train/val/test=1.000/0.768/0.751 | c=0.998437
[Epoch 0050] loss=14.2925 cls=0.0949 smmd=0.5539 ct=11.3420 rec=1.3334 | train/val/test=1.000/0.782/0.748 | c=0.998437
[Epoch 0051] loss=14.2333 cls=0.1089 smmd=0.5255 ct=11.4176 rec=1.3382 | train/val/test=1.000/0.752/0.728 | c=0.998437
[Epoch 0052] loss=14.6725 cls=0.1157 smmd=0.6175 ct=11.3927 rec=1.3437 | train/val/test=1.000/0.770/0.740 | c=0.998437
[Epoch 0053] loss=14.7941 cls=0.1241 smmd=0.6390 ct=11.4027 rec=1.3457 | train/val/test=1.000/0.730/0.697 | c=0.998437
[Epoch 0054] loss=14.3850 cls=0.1177 smmd=0.5582 ct=11.4007 rec=1.3445 | train/val/test=1.000/0.776/0.745 | c=0.998437
[Epoch 0055] loss=13.8724 cls=0.1059 smmd=0.4577 ct=11.3974 rec=1.3363 | train/val/test=1.000/0.768/0.733 | c=0.998437
[Epoch 0056] loss=13.9398 cls=0.0947 smmd=0.4863 ct=11.3275 rec=1.3339 | train/val/test=1.000/0.782/0.753 | c=0.998437
[Epoch 0057] loss=13.6217 cls=0.0942 smmd=0.4101 ct=11.3909 rec=1.3313 | train/val/test=1.000/0.772/0.737 | c=0.998437
[Epoch 0058] loss=13.9097 cls=0.0988 smmd=0.4731 ct=11.3613 rec=1.3367 | train/val/test=1.000/0.776/0.756 | c=0.998437
[Epoch 0059] loss=13.9225 cls=0.1075 smmd=0.4726 ct=11.3720 rec=1.3397 | train/val/test=1.000/0.750/0.709 | c=0.998437
[Epoch 0060] loss=14.0598 cls=0.1192 smmd=0.4964 ct=11.3838 rec=1.3458 | train/val/test=1.000/0.746/0.733 | c=0.998437
[Epoch 0061] loss=14.7381 cls=0.1389 smmd=0.6211 ct=11.4275 rec=1.3553 | train/val/test=1.000/0.630/0.602 | c=0.998437
[Epoch 0062] loss=14.4217 cls=0.1545 smmd=0.5630 ct=11.3937 rec=1.3567 | train/val/test=1.000/0.704/0.709 | c=0.998437
[Epoch 0063] loss=14.1871 cls=0.1483 smmd=0.5034 ct=11.4599 rec=1.3629 | train/val/test=1.000/0.652/0.624 | c=0.998437
[Epoch 0064] loss=14.1205 cls=0.1207 smmd=0.5113 ct=11.3690 rec=1.3456 | train/val/test=1.000/0.776/0.744 | c=0.998437
[Epoch 0065] loss=13.6393 cls=0.0843 smmd=0.4161 ct=11.3839 rec=1.3283 | train/val/test=1.000/0.786/0.741 | c=0.998437
[Epoch 0066] loss=13.6361 cls=0.0741 smmd=0.4212 ct=11.3604 rec=1.3257 | train/val/test=1.000/0.798/0.759 | c=0.998437
[Epoch 0067] loss=13.4732 cls=0.0775 smmd=0.3910 ct=11.3467 rec=1.3263 | train/val/test=1.000/0.792/0.758 | c=0.998437
[Epoch 0068] loss=13.6413 cls=0.0855 smmd=0.4168 ct=11.3814 rec=1.3322 | train/val/test=1.000/0.784/0.753 | c=0.998437
[Epoch 0069] loss=14.0392 cls=0.0983 smmd=0.4959 ct=11.3766 rec=1.3394 | train/val/test=1.000/0.784/0.750 | c=0.998437
[Epoch 0070] loss=14.3927 cls=0.1083 smmd=0.5629 ct=11.3895 rec=1.3440 | train/val/test=1.000/0.770/0.739 | c=0.998437
[Epoch 0071] loss=14.7604 cls=0.1146 smmd=0.6334 ct=11.4013 rec=1.3472 | train/val/test=1.000/0.766/0.736 | c=0.998437
[Epoch 0072] loss=14.2510 cls=0.1090 smmd=0.5336 ct=11.3942 rec=1.3426 | train/val/test=1.000/0.750/0.733 | c=0.998437
[Epoch 0073] loss=13.8496 cls=0.1040 smmd=0.4523 ct=11.4018 rec=1.3421 | train/val/test=1.000/0.764/0.734 | c=0.998437
[Epoch 0074] loss=13.5794 cls=0.0997 smmd=0.4029 ct=11.3815 rec=1.3352 | train/val/test=1.000/0.754/0.727 | c=0.998437
[Epoch 0075] loss=13.6310 cls=0.0932 smmd=0.4183 ct=11.3594 rec=1.3346 | train/val/test=1.000/0.790/0.750 | c=0.998437
[Epoch 0076] loss=13.2779 cls=0.0957 smmd=0.3461 ct=11.3664 rec=1.3323 | train/val/test=1.000/0.762/0.734 | c=0.998437
[Epoch 0077] loss=13.4674 cls=0.1059 smmd=0.3859 ct=11.3509 rec=1.3390 | train/val/test=1.000/0.784/0.747 | c=0.998437
[Epoch 0078] loss=13.7393 cls=0.1234 smmd=0.4288 ct=11.3992 rec=1.3436 | train/val/test=1.000/0.740/0.697 | c=0.998437
[Epoch 0079] loss=14.3297 cls=0.1391 smmd=0.5465 ct=11.3919 rec=1.3567 | train/val/test=1.000/0.710/0.700 | c=0.998437
[Epoch 0080] loss=15.1639 cls=0.1750 smmd=0.6958 ct=11.4612 rec=1.3607 | train/val/test=1.000/0.608/0.588 | c=0.998437
[Epoch 0081] loss=14.7562 cls=0.1756 smmd=0.6165 ct=11.4475 rec=1.3869 | train/val/test=1.000/0.698/0.691 | c=0.998437
[Epoch 0082] loss=14.0098 cls=0.1590 smmd=0.4653 ct=11.4688 rec=1.3534 | train/val/test=1.000/0.682/0.661 | c=0.998437
[Epoch 0083] loss=13.8162 cls=0.0897 smmd=0.4528 ct=11.3735 rec=1.3383 | train/val/test=1.000/0.790/0.762 | c=0.998437
[Epoch 0084] loss=13.4751 cls=0.0590 smmd=0.3909 ct=11.3598 rec=1.3114 | train/val/test=1.000/0.792/0.759 | c=0.998437
[Epoch 0085] loss=13.1697 cls=0.0600 smmd=0.3281 ct=11.3677 rec=1.3122 | train/val/test=1.000/0.750/0.716 | c=0.998437
[Epoch 0086] loss=13.3295 cls=0.0686 smmd=0.3591 ct=11.3673 rec=1.3255 | train/val/test=1.000/0.766/0.746 | c=0.998437
[Epoch 0087] loss=13.7888 cls=0.0864 smmd=0.4425 ct=11.4000 rec=1.3337 | train/val/test=1.000/0.740/0.703 | c=0.998437
[Epoch 0088] loss=14.2091 cls=0.1054 smmd=0.5202 ct=11.4207 rec=1.3469 | train/val/test=1.000/0.708/0.696 | c=0.998437
[Epoch 0089] loss=14.9248 cls=0.1402 smmd=0.6450 ct=11.4937 rec=1.3612 | train/val/test=1.000/0.648/0.618 | c=0.998437
[Epoch 0090] loss=15.2762 cls=0.1552 smmd=0.7188 ct=11.4671 rec=1.3770 | train/val/test=1.000/0.696/0.677 | c=0.998437
[Epoch 0091] loss=14.2903 cls=0.1517 smmd=0.5145 ct=11.5065 rec=1.3553 | train/val/test=1.000/0.784/0.749 | c=0.998437
[Epoch 0092] loss=13.6519 cls=0.0870 smmd=0.4196 ct=11.3765 rec=1.3366 | train/val/test=1.000/0.782/0.734 | c=0.998437
[Epoch 0093] loss=13.3346 cls=0.0801 smmd=0.3645 ct=11.3395 rec=1.3261 | train/val/test=1.000/0.764/0.734 | c=0.998437
[Epoch 0094] loss=13.3454 cls=0.0890 smmd=0.3557 ct=11.3899 rec=1.3263 | train/val/test=1.000/0.788/0.747 | c=0.998437
[Epoch 0095] loss=13.1731 cls=0.0834 smmd=0.3264 ct=11.3664 rec=1.3306 | train/val/test=1.000/0.790/0.759 | c=0.998437
[Epoch 0096] loss=13.3239 cls=0.0969 smmd=0.3560 ct=11.3622 rec=1.3328 | train/val/test=1.000/0.788/0.760 | c=0.998437
[Epoch 0097] loss=13.9965 cls=0.1140 smmd=0.4809 ct=11.4011 rec=1.3416 | train/val/test=1.000/0.780/0.741 | c=0.998437
[Epoch 0098] loss=14.5132 cls=0.1317 smmd=0.5828 ct=11.3982 rec=1.3491 | train/val/test=1.000/0.782/0.739 | c=0.998437
[Epoch 0099] loss=15.1076 cls=0.1321 smmd=0.7043 ct=11.3850 rec=1.3492 | train/val/test=1.000/0.792/0.751 | c=0.998437
=== Best @ epoch 66: val=0.7980, test=0.7590 ===
