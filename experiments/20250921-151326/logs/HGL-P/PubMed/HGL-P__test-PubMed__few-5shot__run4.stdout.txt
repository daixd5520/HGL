Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.6597 cls=1.0926 smmd=5.6478 ct=11.2871 rec=1.4137 | train/val/test=0.385/0.388/0.413 | c=0.998437
[Epoch 0001] loss=22.4368 cls=1.0863 smmd=3.9753 ct=11.2486 rec=1.4138 | train/val/test=0.308/0.416/0.407 | c=0.998437
[Epoch 0002] loss=24.6789 cls=1.0844 smmd=4.8625 ct=11.2738 rec=1.4136 | train/val/test=0.692/0.564/0.601 | c=0.998437
[Epoch 0003] loss=23.7499 cls=1.0655 smmd=4.5243 ct=11.1997 rec=1.4135 | train/val/test=0.538/0.490/0.519 | c=0.998437
[Epoch 0004] loss=18.9248 cls=1.0345 smmd=2.4104 ct=11.6747 rec=1.4138 | train/val/test=0.538/0.452/0.483 | c=0.998437
[Epoch 0005] loss=20.4219 cls=1.0045 smmd=3.1627 ct=11.3056 rec=1.4143 | train/val/test=0.538/0.522/0.558 | c=0.998437
[Epoch 0006] loss=21.2127 cls=0.9705 smmd=3.4924 ct=11.2899 rec=1.4131 | train/val/test=0.615/0.554/0.597 | c=0.998437
[Epoch 0007] loss=19.6307 cls=0.9334 smmd=2.8630 ct=11.3005 rec=1.4120 | train/val/test=0.692/0.664/0.670 | c=0.998437
[Epoch 0008] loss=17.2425 cls=0.9015 smmd=1.8786 ct=11.3901 rec=1.4106 | train/val/test=0.923/0.718/0.688 | c=0.998437
[Epoch 0009] loss=18.8127 cls=0.8864 smmd=2.4314 ct=11.5864 rec=1.4091 | train/val/test=0.923/0.696/0.692 | c=0.998437
[Epoch 0010] loss=19.4185 cls=0.8648 smmd=2.6891 ct=11.5588 rec=1.4091 | train/val/test=0.769/0.630/0.654 | c=0.998437
[Epoch 0011] loss=17.0789 cls=0.8346 smmd=1.8251 ct=11.3942 rec=1.4091 | train/val/test=0.923/0.690/0.711 | c=0.998437
[Epoch 0012] loss=18.2335 cls=0.8068 smmd=2.2749 ct=11.4396 rec=1.4067 | train/val/test=0.923/0.694/0.699 | c=0.998437
[Epoch 0013] loss=18.3592 cls=0.7580 smmd=2.3606 ct=11.3757 rec=1.4061 | train/val/test=0.923/0.710/0.702 | c=0.998437
[Epoch 0014] loss=16.7235 cls=0.6917 smmd=1.7234 ct=11.3690 rec=1.4005 | train/val/test=0.923/0.708/0.701 | c=0.998437
[Epoch 0015] loss=16.5382 cls=0.6350 smmd=1.6224 ct=11.4683 rec=1.3927 | train/val/test=0.923/0.712/0.705 | c=0.998437
[Epoch 0016] loss=16.4591 cls=0.5870 smmd=1.5964 ct=11.4809 rec=1.3875 | train/val/test=0.923/0.720/0.708 | c=0.998437
[Epoch 0017] loss=16.0718 cls=0.5489 smmd=1.4664 ct=11.4392 rec=1.3845 | train/val/test=0.923/0.724/0.706 | c=0.998437
[Epoch 0018] loss=15.6934 cls=0.5273 smmd=1.3369 ct=11.3955 rec=1.3839 | train/val/test=1.000/0.724/0.706 | c=0.998437
[Epoch 0019] loss=15.6105 cls=0.5216 smmd=1.3134 ct=11.3738 rec=1.3852 | train/val/test=1.000/0.726/0.722 | c=0.998437
[Epoch 0020] loss=15.6481 cls=0.5217 smmd=1.3160 ct=11.4026 rec=1.3895 | train/val/test=1.000/0.726/0.720 | c=0.998437
[Epoch 0021] loss=15.5076 cls=0.5234 smmd=1.2452 ct=11.4359 rec=1.3942 | train/val/test=1.000/0.746/0.730 | c=0.998437
[Epoch 0022] loss=15.4631 cls=0.5113 smmd=1.2156 ct=11.4727 rec=1.3918 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0023] loss=15.5395 cls=0.4740 smmd=1.2797 ct=11.4087 rec=1.3890 | train/val/test=1.000/0.728/0.731 | c=0.998437
[Epoch 0024] loss=14.8191 cls=0.4250 smmd=1.0135 ct=11.3819 rec=1.3821 | train/val/test=1.000/0.734/0.727 | c=0.998437
[Epoch 0025] loss=14.9483 cls=0.3834 smmd=1.0555 ct=11.4306 rec=1.3745 | train/val/test=1.000/0.728/0.719 | c=0.998437
[Epoch 0026] loss=14.6353 cls=0.3488 smmd=0.9515 ct=11.3976 rec=1.3689 | train/val/test=1.000/0.718/0.722 | c=0.998437
[Epoch 0027] loss=14.4798 cls=0.3266 smmd=0.8997 ct=11.3848 rec=1.3650 | train/val/test=1.000/0.728/0.717 | c=0.998437
[Epoch 0028] loss=14.2665 cls=0.3172 smmd=0.8075 ct=11.4074 rec=1.3637 | train/val/test=1.000/0.726/0.719 | c=0.998437
[Epoch 0029] loss=14.5783 cls=0.3174 smmd=0.9162 ct=11.4461 rec=1.3659 | train/val/test=1.000/0.724/0.725 | c=0.998437
[Epoch 0030] loss=14.1966 cls=0.3163 smmd=0.7824 ct=11.3983 rec=1.3684 | train/val/test=1.000/0.724/0.730 | c=0.998437
[Epoch 0031] loss=14.7825 cls=0.3161 smmd=1.0019 ct=11.4352 rec=1.3689 | train/val/test=1.000/0.722/0.710 | c=0.998437
[Epoch 0032] loss=14.5182 cls=0.3033 smmd=0.9034 ct=11.4238 rec=1.3686 | train/val/test=1.000/0.722/0.724 | c=0.998437
[Epoch 0033] loss=14.4707 cls=0.2729 smmd=0.8860 ct=11.4388 rec=1.3609 | train/val/test=1.000/0.716/0.708 | c=0.998437
[Epoch 0034] loss=14.0470 cls=0.2450 smmd=0.7396 ct=11.3990 rec=1.3532 | train/val/test=1.000/0.716/0.714 | c=0.998437
[Epoch 0035] loss=13.9612 cls=0.2246 smmd=0.6987 ct=11.4283 rec=1.3477 | train/val/test=1.000/0.708/0.704 | c=0.998437
[Epoch 0036] loss=13.9343 cls=0.2172 smmd=0.6987 ct=11.4059 rec=1.3462 | train/val/test=1.000/0.716/0.711 | c=0.998437
[Epoch 0037] loss=13.7312 cls=0.2101 smmd=0.6196 ct=11.4043 rec=1.3460 | train/val/test=1.000/0.688/0.692 | c=0.998437
[Epoch 0038] loss=13.8750 cls=0.2232 smmd=0.6703 ct=11.4116 rec=1.3521 | train/val/test=1.000/0.706/0.713 | c=0.998437
[Epoch 0039] loss=14.0625 cls=0.2322 smmd=0.7184 ct=11.4726 rec=1.3555 | train/val/test=1.000/0.638/0.658 | c=0.998437
[Epoch 0040] loss=14.2316 cls=0.2451 smmd=0.7890 ct=11.4555 rec=1.3621 | train/val/test=1.000/0.694/0.717 | c=0.998437
[Epoch 0041] loss=14.3072 cls=0.2538 smmd=0.7942 ct=11.5136 rec=1.3621 | train/val/test=1.000/0.572/0.570 | c=0.998437
[Epoch 0042] loss=14.1170 cls=0.2364 smmd=0.7348 ct=11.4809 rec=1.3617 | train/val/test=1.000/0.706/0.714 | c=0.998437
[Epoch 0043] loss=14.0376 cls=0.1843 smmd=0.7235 ct=11.4664 rec=1.3405 | train/val/test=1.000/0.702/0.697 | c=0.998437
[Epoch 0044] loss=13.5819 cls=0.1440 smmd=0.5737 ct=11.4110 rec=1.3291 | train/val/test=1.000/0.694/0.691 | c=0.998437
[Epoch 0045] loss=13.5500 cls=0.1423 smmd=0.5600 ct=11.4146 rec=1.3281 | train/val/test=1.000/0.712/0.715 | c=0.998437
[Epoch 0046] loss=13.5647 cls=0.1434 smmd=0.5679 ct=11.4089 rec=1.3287 | train/val/test=1.000/0.700/0.698 | c=0.998437
[Epoch 0047] loss=13.6157 cls=0.1554 smmd=0.5780 ct=11.4238 rec=1.3382 | train/val/test=1.000/0.736/0.719 | c=0.998437
[Epoch 0048] loss=13.8962 cls=0.1741 smmd=0.6696 ct=11.4645 rec=1.3416 | train/val/test=1.000/0.660/0.682 | c=0.998437
[Epoch 0049] loss=14.1710 cls=0.1876 smmd=0.7905 ct=11.4247 rec=1.3528 | train/val/test=1.000/0.708/0.715 | c=0.998437
[Epoch 0050] loss=14.1226 cls=0.1950 smmd=0.7260 ct=11.5369 rec=1.3464 | train/val/test=1.000/0.616/0.608 | c=0.998437
[Epoch 0051] loss=13.9188 cls=0.1846 smmd=0.6864 ct=11.4378 rec=1.3452 | train/val/test=1.000/0.698/0.713 | c=0.998437
[Epoch 0052] loss=13.6088 cls=0.1435 smmd=0.5650 ct=11.4611 rec=1.3271 | train/val/test=1.000/0.702/0.694 | c=0.998437
[Epoch 0053] loss=13.4170 cls=0.1218 smmd=0.5075 ct=11.4286 rec=1.3177 | train/val/test=1.000/0.722/0.707 | c=0.998437
[Epoch 0054] loss=13.3351 cls=0.1163 smmd=0.4941 ct=11.3831 rec=1.3170 | train/val/test=1.000/0.714/0.719 | c=0.998437
[Epoch 0055] loss=13.3354 cls=0.1291 smmd=0.4769 ct=11.4170 rec=1.3229 | train/val/test=1.000/0.694/0.687 | c=0.998437
[Epoch 0056] loss=13.5660 cls=0.1521 smmd=0.5493 ct=11.4485 rec=1.3362 | train/val/test=1.000/0.702/0.725 | c=0.998437
[Epoch 0057] loss=13.8319 cls=0.1854 smmd=0.6456 ct=11.4513 rec=1.3475 | train/val/test=1.000/0.556/0.543 | c=0.998437
[Epoch 0058] loss=14.3570 cls=0.2258 smmd=0.8232 ct=11.4990 rec=1.3740 | train/val/test=0.923/0.674/0.704 | c=0.998437
[Epoch 0059] loss=14.5021 cls=0.2707 smmd=0.8244 ct=11.6255 rec=1.3605 | train/val/test=1.000/0.654/0.649 | c=0.998437
[Epoch 0060] loss=13.5210 cls=0.1234 smmd=0.5464 ct=11.4262 rec=1.3340 | train/val/test=1.000/0.714/0.701 | c=0.998437
[Epoch 0061] loss=13.4119 cls=0.0793 smmd=0.5269 ct=11.4023 rec=1.3057 | train/val/test=1.000/0.716/0.720 | c=0.998437
[Epoch 0062] loss=13.1833 cls=0.0771 smmd=0.4225 ct=11.4372 rec=1.3024 | train/val/test=1.000/0.708/0.700 | c=0.998437
[Epoch 0063] loss=13.1956 cls=0.0756 smmd=0.4414 ct=11.4019 rec=1.3050 | train/val/test=1.000/0.714/0.705 | c=0.998437
[Epoch 0064] loss=13.3443 cls=0.0876 smmd=0.4931 ct=11.4116 rec=1.3123 | train/val/test=1.000/0.722/0.730 | c=0.998437
[Epoch 0065] loss=13.3198 cls=0.1034 smmd=0.4708 ct=11.4300 rec=1.3224 | train/val/test=1.000/0.728/0.720 | c=0.998437
[Epoch 0066] loss=13.8162 cls=0.1354 smmd=0.6483 ct=11.4607 rec=1.3343 | train/val/test=1.000/0.704/0.699 | c=0.998437
[Epoch 0067] loss=14.4754 cls=0.1532 smmd=0.9163 ct=11.4335 rec=1.3489 | train/val/test=1.000/0.714/0.706 | c=0.998437
[Epoch 0068] loss=13.8042 cls=0.1560 smmd=0.6304 ct=11.4818 rec=1.3370 | train/val/test=1.000/0.682/0.703 | c=0.998437
[Epoch 0069] loss=13.7874 cls=0.1601 smmd=0.6439 ct=11.4242 rec=1.3466 | train/val/test=1.000/0.636/0.627 | c=0.998437
[Epoch 0070] loss=13.3830 cls=0.1201 smmd=0.4799 ct=11.4615 rec=1.3235 | train/val/test=1.000/0.700/0.705 | c=0.998437
[Epoch 0071] loss=13.4673 cls=0.1156 smmd=0.5265 ct=11.4354 rec=1.3155 | train/val/test=1.000/0.704/0.693 | c=0.998437
[Epoch 0072] loss=13.1952 cls=0.0772 smmd=0.4506 ct=11.3766 rec=1.3069 | train/val/test=1.000/0.714/0.708 | c=0.998437
[Epoch 0073] loss=13.1419 cls=0.0828 smmd=0.4065 ct=11.4287 rec=1.3111 | train/val/test=1.000/0.706/0.719 | c=0.998437
[Epoch 0074] loss=13.3926 cls=0.1102 smmd=0.4966 ct=11.4325 rec=1.3268 | train/val/test=1.000/0.634/0.617 | c=0.998437
[Epoch 0075] loss=13.8063 cls=0.1651 smmd=0.6287 ct=11.4762 rec=1.3518 | train/val/test=0.923/0.638/0.656 | c=0.998437
[Epoch 0076] loss=14.9062 cls=0.2627 smmd=0.9812 ct=11.6248 rec=1.3939 | train/val/test=1.000/0.508/0.468 | c=0.998437
[Epoch 0077] loss=14.1885 cls=0.2603 smmd=0.7213 ct=11.5657 rec=1.3789 | train/val/test=1.000/0.714/0.724 | c=0.998437
[Epoch 0078] loss=13.6559 cls=0.0721 smmd=0.6083 ct=11.4434 rec=1.3114 | train/val/test=1.000/0.722/0.715 | c=0.998437
[Epoch 0079] loss=13.1846 cls=0.0429 smmd=0.4421 ct=11.4124 rec=1.2908 | train/val/test=1.000/0.674/0.654 | c=0.998437
[Epoch 0080] loss=13.3722 cls=0.0776 smmd=0.4868 ct=11.4604 rec=1.3119 | train/val/test=1.000/0.730/0.717 | c=0.998437
[Epoch 0081] loss=13.2267 cls=0.0396 smmd=0.4650 ct=11.3998 rec=1.2890 | train/val/test=1.000/0.718/0.713 | c=0.998437
[Epoch 0082] loss=13.2168 cls=0.0533 smmd=0.4555 ct=11.4006 rec=1.3015 | train/val/test=1.000/0.730/0.712 | c=0.998437
[Epoch 0083] loss=13.1912 cls=0.0741 smmd=0.4030 ct=11.4898 rec=1.3137 | train/val/test=1.000/0.704/0.708 | c=0.998437
[Epoch 0084] loss=13.9655 cls=0.0970 smmd=0.7342 ct=11.4174 rec=1.3282 | train/val/test=1.000/0.734/0.719 | c=0.998437
[Epoch 0085] loss=14.3333 cls=0.1270 smmd=0.8319 ct=11.5242 rec=1.3316 | train/val/test=1.000/0.656/0.669 | c=0.998437
[Epoch 0086] loss=13.9240 cls=0.1256 smmd=0.6962 ct=11.4534 rec=1.3346 | train/val/test=1.000/0.736/0.718 | c=0.998437
[Epoch 0087] loss=13.7402 cls=0.1686 smmd=0.5932 ct=11.5051 rec=1.3355 | train/val/test=1.000/0.584/0.576 | c=0.998437
[Epoch 0088] loss=13.5242 cls=0.1190 smmd=0.5540 ct=11.4201 rec=1.3195 | train/val/test=1.000/0.702/0.709 | c=0.998437
[Epoch 0089] loss=13.3472 cls=0.1203 smmd=0.4730 ct=11.4450 rec=1.3191 | train/val/test=1.000/0.688/0.685 | c=0.998437
[Epoch 0090] loss=13.2531 cls=0.1003 smmd=0.4423 ct=11.4388 rec=1.3167 | train/val/test=1.000/0.680/0.690 | c=0.998437
[Epoch 0091] loss=13.2268 cls=0.0798 smmd=0.4626 ct=11.3766 rec=1.3075 | train/val/test=1.000/0.742/0.734 | c=0.998437
[Epoch 0092] loss=13.2535 cls=0.0895 smmd=0.4274 ct=11.4820 rec=1.3167 | train/val/test=1.000/0.650/0.621 | c=0.998437
[Epoch 0093] loss=13.5740 cls=0.1556 smmd=0.5317 ct=11.4984 rec=1.3370 | train/val/test=0.923/0.636/0.661 | c=0.998437
[Epoch 0094] loss=14.7093 cls=0.2281 smmd=0.9520 ct=11.5223 rec=1.3858 | train/val/test=1.000/0.538/0.518 | c=0.998437
[Epoch 0095] loss=14.1770 cls=0.2287 smmd=0.7077 ct=11.6084 rec=1.3701 | train/val/test=1.000/0.704/0.717 | c=0.998437
[Epoch 0096] loss=13.6862 cls=0.0766 smmd=0.6113 ct=11.4681 rec=1.3033 | train/val/test=1.000/0.720/0.712 | c=0.998437
[Epoch 0097] loss=13.2400 cls=0.0348 smmd=0.4743 ct=11.3943 rec=1.2854 | train/val/test=1.000/0.678/0.653 | c=0.998437
[Epoch 0098] loss=13.3363 cls=0.0396 smmd=0.4835 ct=11.4593 rec=1.2967 | train/val/test=1.000/0.726/0.728 | c=0.998437
[Epoch 0099] loss=13.2378 cls=0.0298 smmd=0.4525 ct=11.4490 rec=1.2854 | train/val/test=1.000/0.720/0.720 | c=0.998437
=== Best @ epoch 21: val=0.7460, test=0.7300 ===
