Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.6265 cls=1.0994 smmd=5.6364 ct=11.2790 rec=1.4137 | train/val/test=0.385/0.388/0.413 | c=0.998437
[Epoch 0001] loss=22.7339 cls=1.0902 smmd=4.0898 ct=11.2573 rec=1.4137 | train/val/test=0.385/0.388/0.413 | c=0.998437
[Epoch 0002] loss=24.1669 cls=1.0850 smmd=4.6619 ct=11.2628 rec=1.4136 | train/val/test=0.385/0.388/0.414 | c=0.998437
[Epoch 0003] loss=22.7494 cls=1.0698 smmd=4.1199 ct=11.2080 rec=1.4137 | train/val/test=0.538/0.440/0.467 | c=0.998437
[Epoch 0004] loss=18.3153 cls=1.0410 smmd=2.4186 ct=11.0413 rec=1.4137 | train/val/test=0.538/0.514/0.543 | c=0.998437
[Epoch 0005] loss=19.7225 cls=1.0046 smmd=3.0173 ct=10.9702 rec=1.4136 | train/val/test=0.615/0.564/0.593 | c=0.998437
[Epoch 0006] loss=19.6981 cls=0.9634 smmd=3.0395 ct=10.9113 rec=1.4127 | train/val/test=0.769/0.606/0.638 | c=0.998437
[Epoch 0007] loss=17.4754 cls=0.9218 smmd=2.1727 ct=10.8772 rec=1.4111 | train/val/test=0.846/0.674/0.664 | c=0.998437
[Epoch 0008] loss=16.8916 cls=0.8888 smmd=1.9422 ct=10.8872 rec=1.4093 | train/val/test=0.846/0.686/0.670 | c=0.998437
[Epoch 0009] loss=18.0333 cls=0.8640 smmd=2.3962 ct=10.9066 rec=1.4083 | train/val/test=0.846/0.656/0.666 | c=0.998437
[Epoch 0010] loss=16.8525 cls=0.8371 smmd=1.9316 ct=10.9013 rec=1.4075 | train/val/test=0.846/0.628/0.659 | c=0.998437
[Epoch 0011] loss=16.3196 cls=0.8125 smmd=1.7260 ct=10.8951 rec=1.4067 | train/val/test=0.846/0.634/0.651 | c=0.998437
[Epoch 0012] loss=17.0439 cls=0.7893 smmd=2.0217 ct=10.8925 rec=1.4051 | train/val/test=0.923/0.692/0.691 | c=0.998437
[Epoch 0013] loss=15.8912 cls=0.7496 smmd=1.5761 ct=10.8749 rec=1.4026 | train/val/test=0.923/0.702/0.691 | c=0.998437
[Epoch 0014] loss=15.8969 cls=0.7066 smmd=1.5834 ct=10.8862 rec=1.3976 | train/val/test=0.923/0.686/0.694 | c=0.998437
[Epoch 0015] loss=15.4579 cls=0.6512 smmd=1.4265 ct=10.8692 rec=1.3937 | train/val/test=0.923/0.692/0.695 | c=0.998437
[Epoch 0016] loss=15.8906 cls=0.6100 smmd=1.3292 ct=11.5685 rec=1.3884 | train/val/test=0.923/0.704/0.706 | c=0.998437
[Epoch 0017] loss=15.5743 cls=0.6011 smmd=1.2638 ct=11.4217 rec=1.3853 | train/val/test=0.923/0.706/0.719 | c=0.998437
[Epoch 0018] loss=15.3900 cls=0.5808 smmd=1.1744 ct=11.4712 rec=1.3847 | train/val/test=0.923/0.730/0.712 | c=0.998437
[Epoch 0019] loss=15.4483 cls=0.5654 smmd=1.1607 ct=11.5709 rec=1.3861 | train/val/test=0.923/0.712/0.719 | c=0.998437
[Epoch 0020] loss=15.2075 cls=0.5545 smmd=1.1007 ct=11.4843 rec=1.3884 | train/val/test=1.000/0.732/0.722 | c=0.998437
[Epoch 0021] loss=15.2904 cls=0.5511 smmd=1.1242 ct=11.5103 rec=1.3881 | train/val/test=0.923/0.728/0.723 | c=0.998437
[Epoch 0022] loss=15.2395 cls=0.5276 smmd=1.1053 ct=11.5182 rec=1.3882 | train/val/test=1.000/0.738/0.729 | c=0.998437
[Epoch 0023] loss=14.8946 cls=0.4936 smmd=0.9833 ct=11.4972 rec=1.3847 | train/val/test=1.000/0.726/0.728 | c=0.998437
[Epoch 0024] loss=14.7521 cls=0.4584 smmd=0.9390 ct=11.4854 rec=1.3800 | train/val/test=1.000/0.740/0.718 | c=0.998437
[Epoch 0025] loss=14.5879 cls=0.4194 smmd=0.8840 ct=11.4802 rec=1.3762 | train/val/test=1.000/0.732/0.724 | c=0.998437
[Epoch 0026] loss=14.4144 cls=0.3910 smmd=0.8256 ct=11.4691 rec=1.3714 | train/val/test=1.000/0.728/0.714 | c=0.998437
[Epoch 0027] loss=14.2391 cls=0.3736 smmd=0.7505 ct=11.4915 rec=1.3692 | train/val/test=1.000/0.716/0.729 | c=0.998437
[Epoch 0028] loss=14.3598 cls=0.3675 smmd=0.8174 ct=11.4480 rec=1.3688 | train/val/test=1.000/0.738/0.716 | c=0.998437
[Epoch 0029] loss=14.2229 cls=0.3550 smmd=0.7484 ct=11.4895 rec=1.3697 | train/val/test=1.000/0.724/0.714 | c=0.998437
[Epoch 0030] loss=14.4915 cls=0.3522 smmd=0.8520 ct=11.5013 rec=1.3684 | train/val/test=1.000/0.714/0.717 | c=0.998437
[Epoch 0031] loss=14.3263 cls=0.3327 smmd=0.7863 ct=11.5097 rec=1.3690 | train/val/test=1.000/0.702/0.721 | c=0.998437
[Epoch 0032] loss=14.4838 cls=0.3306 smmd=0.8589 ct=11.4891 rec=1.3640 | train/val/test=1.000/0.710/0.705 | c=0.998437
[Epoch 0033] loss=14.2270 cls=0.2887 smmd=0.7465 ct=11.5361 rec=1.3606 | train/val/test=1.000/0.702/0.721 | c=0.998437
[Epoch 0034] loss=14.0273 cls=0.2773 smmd=0.6992 ct=11.4644 rec=1.3524 | train/val/test=1.000/0.714/0.712 | c=0.998437
[Epoch 0035] loss=14.0181 cls=0.2393 smmd=0.6876 ct=11.5070 rec=1.3452 | train/val/test=1.000/0.730/0.715 | c=0.998437
[Epoch 0036] loss=13.7785 cls=0.2340 smmd=0.6127 ct=11.4589 rec=1.3416 | train/val/test=1.000/0.728/0.719 | c=0.998437
[Epoch 0037] loss=13.8059 cls=0.2300 smmd=0.6183 ct=11.4735 rec=1.3433 | train/val/test=1.000/0.734/0.723 | c=0.998437
[Epoch 0038] loss=13.8184 cls=0.2382 smmd=0.6222 ct=11.4703 rec=1.3469 | train/val/test=1.000/0.732/0.729 | c=0.998437
[Epoch 0039] loss=14.1081 cls=0.2469 smmd=0.7196 ct=11.5100 rec=1.3516 | train/val/test=1.000/0.734/0.727 | c=0.998437
[Epoch 0040] loss=14.1685 cls=0.2456 smmd=0.7510 ct=11.4918 rec=1.3528 | train/val/test=1.000/0.730/0.727 | c=0.998437
[Epoch 0041] loss=13.9984 cls=0.2318 smmd=0.6926 ct=11.4765 rec=1.3491 | train/val/test=1.000/0.730/0.727 | c=0.998437
[Epoch 0042] loss=13.8832 cls=0.2123 smmd=0.6426 ct=11.4992 rec=1.3425 | train/val/test=1.000/0.722/0.723 | c=0.998437
[Epoch 0043] loss=13.6200 cls=0.1917 smmd=0.5556 ct=11.4665 rec=1.3371 | train/val/test=1.000/0.730/0.723 | c=0.998437
[Epoch 0044] loss=13.4665 cls=0.1838 smmd=0.4994 ct=11.4593 rec=1.3335 | train/val/test=1.000/0.724/0.720 | c=0.998437
[Epoch 0045] loss=13.5567 cls=0.1773 smmd=0.5221 ct=11.4958 rec=1.3342 | train/val/test=1.000/0.726/0.724 | c=0.998437
[Epoch 0046] loss=13.4711 cls=0.1840 smmd=0.4956 ct=11.4723 rec=1.3359 | train/val/test=1.000/0.726/0.717 | c=0.998437
[Epoch 0047] loss=13.7020 cls=0.1873 smmd=0.5763 ct=11.4973 rec=1.3405 | train/val/test=1.000/0.726/0.721 | c=0.998437
[Epoch 0048] loss=13.9787 cls=0.1942 smmd=0.6827 ct=11.5038 rec=1.3418 | train/val/test=1.000/0.706/0.700 | c=0.998437
[Epoch 0049] loss=13.8470 cls=0.1839 smmd=0.6221 ct=11.5282 rec=1.3431 | train/val/test=1.000/0.732/0.730 | c=0.998437
[Epoch 0050] loss=13.7160 cls=0.1734 smmd=0.5878 ct=11.4923 rec=1.3347 | train/val/test=1.000/0.714/0.704 | c=0.998437
[Epoch 0051] loss=13.6688 cls=0.1512 smmd=0.5691 ct=11.5055 rec=1.3300 | train/val/test=1.000/0.734/0.732 | c=0.998437
[Epoch 0052] loss=13.4756 cls=0.1376 smmd=0.5065 ct=11.4793 rec=1.3222 | train/val/test=1.000/0.724/0.716 | c=0.998437
[Epoch 0053] loss=13.3562 cls=0.1307 smmd=0.4603 ct=11.4792 rec=1.3216 | train/val/test=1.000/0.740/0.731 | c=0.998437
[Epoch 0054] loss=13.4579 cls=0.1352 smmd=0.5034 ct=11.4702 rec=1.3230 | train/val/test=1.000/0.736/0.723 | c=0.998437
[Epoch 0055] loss=13.5525 cls=0.1446 smmd=0.5201 ct=11.5150 rec=1.3299 | train/val/test=1.000/0.742/0.731 | c=0.998437
[Epoch 0056] loss=13.7201 cls=0.1568 smmd=0.5994 ct=11.4770 rec=1.3325 | train/val/test=1.000/0.708/0.705 | c=0.998437
[Epoch 0057] loss=13.8776 cls=0.1652 smmd=0.6280 ct=11.5540 rec=1.3421 | train/val/test=1.000/0.734/0.737 | c=0.998437
[Epoch 0058] loss=13.8176 cls=0.1761 smmd=0.6232 ct=11.5017 rec=1.3398 | train/val/test=1.000/0.698/0.695 | c=0.998437
[Epoch 0059] loss=13.7479 cls=0.1494 smmd=0.5722 ct=11.5744 rec=1.3364 | train/val/test=1.000/0.732/0.737 | c=0.998437
[Epoch 0060] loss=13.3030 cls=0.1184 smmd=0.4473 ct=11.4671 rec=1.3171 | train/val/test=1.000/0.720/0.723 | c=0.998437
[Epoch 0061] loss=13.3381 cls=0.0987 smmd=0.4696 ct=11.4610 rec=1.3075 | train/val/test=1.000/0.724/0.720 | c=0.998437
[Epoch 0062] loss=13.2095 cls=0.0988 smmd=0.4077 ct=11.4868 rec=1.3083 | train/val/test=1.000/0.728/0.727 | c=0.998437
[Epoch 0063] loss=13.1781 cls=0.1093 smmd=0.3899 ct=11.4916 rec=1.3141 | train/val/test=1.000/0.730/0.732 | c=0.998437
[Epoch 0064] loss=13.5319 cls=0.1280 smmd=0.5308 ct=11.4793 rec=1.3232 | train/val/test=1.000/0.726/0.728 | c=0.998437
[Epoch 0065] loss=13.8840 cls=0.1444 smmd=0.6461 ct=11.5293 rec=1.3349 | train/val/test=1.000/0.744/0.725 | c=0.998437
[Epoch 0066] loss=14.1513 cls=0.1480 smmd=0.7632 ct=11.5027 rec=1.3335 | train/val/test=1.000/0.720/0.730 | c=0.998437
[Epoch 0067] loss=13.7345 cls=0.1415 smmd=0.6006 ct=11.4973 rec=1.3302 | train/val/test=1.000/0.706/0.683 | c=0.998437
[Epoch 0068] loss=13.3271 cls=0.1271 smmd=0.4384 ct=11.5051 rec=1.3249 | train/val/test=1.000/0.726/0.729 | c=0.998437
[Epoch 0069] loss=13.4335 cls=0.1097 smmd=0.5049 ct=11.4595 rec=1.3139 | train/val/test=1.000/0.740/0.726 | c=0.998437
[Epoch 0070] loss=13.1469 cls=0.0885 smmd=0.3963 ct=11.4581 rec=1.3076 | train/val/test=1.000/0.732/0.724 | c=0.998437
[Epoch 0071] loss=13.1885 cls=0.0886 smmd=0.4019 ct=11.4848 rec=1.3096 | train/val/test=1.000/0.730/0.734 | c=0.998437
[Epoch 0072] loss=13.3163 cls=0.1003 smmd=0.4566 ct=11.4660 rec=1.3170 | train/val/test=1.000/0.748/0.725 | c=0.998437
[Epoch 0073] loss=13.5245 cls=0.1156 smmd=0.5209 ct=11.5020 rec=1.3248 | train/val/test=1.000/0.718/0.730 | c=0.998437
[Epoch 0074] loss=14.0210 cls=0.1281 smmd=0.6936 ct=11.5560 rec=1.3335 | train/val/test=1.000/0.702/0.687 | c=0.998437
[Epoch 0075] loss=14.1007 cls=0.1363 smmd=0.7561 ct=11.4780 rec=1.3287 | train/val/test=1.000/0.698/0.720 | c=0.998437
[Epoch 0076] loss=13.6334 cls=0.1237 smmd=0.5447 ct=11.5448 rec=1.3298 | train/val/test=1.000/0.690/0.675 | c=0.998437
[Epoch 0077] loss=13.4868 cls=0.1121 smmd=0.5072 ct=11.5049 rec=1.3156 | train/val/test=1.000/0.738/0.730 | c=0.998437
[Epoch 0078] loss=13.3238 cls=0.0726 smmd=0.4762 ct=11.4473 rec=1.2995 | train/val/test=1.000/0.748/0.728 | c=0.998437
[Epoch 0079] loss=13.0992 cls=0.0615 smmd=0.3883 ct=11.4501 rec=1.2951 | train/val/test=1.000/0.742/0.720 | c=0.998437
[Epoch 0080] loss=13.2144 cls=0.0736 smmd=0.4120 ct=11.4958 rec=1.3034 | train/val/test=1.000/0.732/0.732 | c=0.998437
[Epoch 0081] loss=13.3815 cls=0.0993 smmd=0.4803 ct=11.4723 rec=1.3177 | train/val/test=1.000/0.708/0.696 | c=0.998437
[Epoch 0082] loss=13.6968 cls=0.1289 smmd=0.5841 ct=11.5054 rec=1.3335 | train/val/test=1.000/0.688/0.707 | c=0.998437
[Epoch 0083] loss=14.3672 cls=0.1910 smmd=0.7887 ct=11.6195 rec=1.3609 | train/val/test=1.000/0.548/0.510 | c=0.998437
[Epoch 0084] loss=14.3001 cls=0.2076 smmd=0.7902 ct=11.5406 rec=1.3605 | train/val/test=0.923/0.698/0.722 | c=0.998437
[Epoch 0085] loss=13.7306 cls=0.1253 smmd=0.5866 ct=11.5380 rec=1.3267 | train/val/test=1.000/0.744/0.732 | c=0.998437
[Epoch 0086] loss=13.2319 cls=0.0440 smmd=0.4317 ct=11.4865 rec=1.2884 | train/val/test=1.000/0.684/0.651 | c=0.998437
[Epoch 0087] loss=13.3790 cls=0.0785 smmd=0.4917 ct=11.4584 rec=1.3043 | train/val/test=1.000/0.734/0.736 | c=0.998437
[Epoch 0088] loss=13.1761 cls=0.0435 smmd=0.4275 ct=11.4407 rec=1.2900 | train/val/test=1.000/0.734/0.743 | c=0.998437
[Epoch 0089] loss=13.3165 cls=0.0464 smmd=0.4532 ct=11.5141 rec=1.2926 | train/val/test=1.000/0.706/0.693 | c=0.998437
[Epoch 0090] loss=13.2360 cls=0.0776 smmd=0.4125 ct=11.5101 rec=1.3117 | train/val/test=1.000/0.754/0.758 | c=0.998437
[Epoch 0091] loss=13.6948 cls=0.0958 smmd=0.6061 ct=11.4716 rec=1.3200 | train/val/test=1.000/0.730/0.705 | c=0.998437
[Epoch 0092] loss=14.3557 cls=0.1139 smmd=0.8012 ct=11.6292 rec=1.3329 | train/val/test=1.000/0.756/0.744 | c=0.998437
[Epoch 0093] loss=14.0247 cls=0.1168 smmd=0.7229 ct=11.4967 rec=1.3249 | train/val/test=1.000/0.712/0.713 | c=0.998437
[Epoch 0094] loss=13.6871 cls=0.1020 smmd=0.5762 ct=11.5339 rec=1.3234 | train/val/test=1.000/0.698/0.722 | c=0.998437
[Epoch 0095] loss=13.4332 cls=0.1026 smmd=0.4972 ct=11.4790 rec=1.3199 | train/val/test=1.000/0.734/0.729 | c=0.998437
[Epoch 0096] loss=13.2731 cls=0.0717 smmd=0.4377 ct=11.4947 rec=1.2968 | train/val/test=1.000/0.736/0.737 | c=0.998437
[Epoch 0097] loss=13.1561 cls=0.0637 smmd=0.4191 ct=11.4294 rec=1.2940 | train/val/test=1.000/0.732/0.737 | c=0.998437
[Epoch 0098] loss=13.1552 cls=0.0829 smmd=0.4060 ct=11.4435 rec=1.3107 | train/val/test=1.000/0.712/0.719 | c=0.998437
[Epoch 0099] loss=13.4757 cls=0.1004 smmd=0.4740 ct=11.5773 rec=1.3263 | train/val/test=1.000/0.708/0.723 | c=0.998437
=== Best @ epoch 92: val=0.7560, test=0.7440 ===
