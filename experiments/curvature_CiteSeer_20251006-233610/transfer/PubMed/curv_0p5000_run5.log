Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=81.1473 cls=1.0971 smmd=6.5356 ct=7.2680 rec=1.4136 | train/val/test=0.387/0.401/0.401 | c=0.500000
[Epoch 0001] loss=72.3354 cls=1.0584 smmd=5.6573 ct=7.2620 rec=1.4177 | train/val/test=0.401/0.399/0.394 | c=0.500000
[Epoch 0002] loss=41.3780 cls=1.0510 smmd=2.5808 ct=7.1685 rec=1.4142 | train/val/test=0.610/0.591/0.605 | c=0.500000
[Epoch 0003] loss=45.6252 cls=1.0179 smmd=3.0257 ct=7.0769 rec=1.4116 | train/val/test=0.657/0.645/0.651 | c=0.500000
[Epoch 0004] loss=45.3875 cls=0.8755 smmd=3.0448 ct=6.8997 rec=1.4055 | train/val/test=0.670/0.656/0.666 | c=0.500000
[Epoch 0005] loss=35.1410 cls=0.7722 smmd=2.0468 ct=6.7981 rec=1.3805 | train/val/test=0.671/0.656/0.666 | c=0.500000
[Epoch 0006] loss=28.0536 cls=0.7061 smmd=1.3460 ct=6.7823 rec=1.3518 | train/val/test=0.676/0.662/0.669 | c=0.500000
[Epoch 0007] loss=32.2157 cls=0.6811 smmd=1.7622 ct=6.7932 rec=1.3332 | train/val/test=0.689/0.669/0.683 | c=0.500000
[Epoch 0008] loss=34.5901 cls=0.6582 smmd=2.0013 ct=6.7936 rec=1.3222 | train/val/test=0.716/0.704/0.710 | c=0.500000
[Epoch 0009] loss=32.0977 cls=0.6150 smmd=1.7601 ct=6.7656 rec=1.3165 | train/val/test=0.762/0.753/0.761 | c=0.500000
[Epoch 0010] loss=28.9649 cls=0.5728 smmd=1.3113 ct=7.4530 rec=1.3181 | train/val/test=0.788/0.784/0.789 | c=0.500000
[Epoch 0011] loss=25.7830 cls=0.5462 smmd=1.0336 ct=7.2560 rec=1.3238 | train/val/test=0.801/0.801/0.803 | c=0.500000
[Epoch 0012] loss=26.5520 cls=0.5308 smmd=1.1003 ct=7.3105 rec=1.3243 | train/val/test=0.811/0.803/0.805 | c=0.500000
[Epoch 0013] loss=28.6223 cls=0.5262 smmd=1.3013 ct=7.3418 rec=1.3260 | train/val/test=0.788/0.784/0.787 | c=0.500000
[Epoch 0014] loss=26.0689 cls=0.5352 smmd=1.0582 ct=7.2771 rec=1.3307 | train/val/test=0.795/0.791/0.792 | c=0.500000
[Epoch 0015] loss=23.0573 cls=0.5158 smmd=0.7500 ct=7.3197 rec=1.3207 | train/val/test=0.795/0.793/0.796 | c=0.500000
[Epoch 0016] loss=23.8537 cls=0.5050 smmd=0.8304 ct=7.3202 rec=1.3134 | train/val/test=0.812/0.805/0.807 | c=0.500000
[Epoch 0017] loss=24.2173 cls=0.4787 smmd=0.8737 ct=7.2949 rec=1.3012 | train/val/test=0.821/0.817/0.813 | c=0.500000
[Epoch 0018] loss=22.6247 cls=0.4614 smmd=0.7147 ct=7.3009 rec=1.2913 | train/val/test=0.826/0.817/0.819 | c=0.500000
[Epoch 0019] loss=20.9891 cls=0.4489 smmd=0.5474 ct=7.3240 rec=1.2851 | train/val/test=0.830/0.820/0.827 | c=0.500000
[Epoch 0020] loss=20.8827 cls=0.4401 smmd=0.5371 ct=7.3257 rec=1.2813 | train/val/test=0.831/0.823/0.830 | c=0.500000
[Epoch 0021] loss=21.4614 cls=0.4327 smmd=0.5995 ct=7.3047 rec=1.2811 | train/val/test=0.834/0.826/0.832 | c=0.500000
[Epoch 0022] loss=21.1104 cls=0.4257 smmd=0.5685 ct=7.2854 rec=1.2835 | train/val/test=0.834/0.826/0.831 | c=0.500000
[Epoch 0023] loss=20.2545 cls=0.4265 smmd=0.4830 ct=7.2842 rec=1.2863 | train/val/test=0.836/0.824/0.832 | c=0.500000
[Epoch 0024] loss=20.3175 cls=0.4292 smmd=0.4859 ct=7.2993 rec=1.2913 | train/val/test=0.838/0.827/0.834 | c=0.500000
[Epoch 0025] loss=20.8555 cls=0.4315 smmd=0.5377 ct=7.3069 rec=1.2975 | train/val/test=0.839/0.828/0.833 | c=0.500000
[Epoch 0026] loss=20.5382 cls=0.4322 smmd=0.5068 ct=7.3019 rec=1.3014 | train/val/test=0.837/0.828/0.840 | c=0.500000
[Epoch 0027] loss=19.7456 cls=0.4282 smmd=0.4305 ct=7.2879 rec=1.3004 | train/val/test=0.841/0.833/0.840 | c=0.500000
[Epoch 0028] loss=19.4812 cls=0.4221 smmd=0.4053 ct=7.2828 rec=1.3025 | train/val/test=0.839/0.831/0.838 | c=0.500000
[Epoch 0029] loss=19.4203 cls=0.4206 smmd=0.4010 ct=7.2758 rec=1.2975 | train/val/test=0.844/0.830/0.839 | c=0.500000
[Epoch 0030] loss=18.9340 cls=0.4201 smmd=0.3538 ct=7.2676 rec=1.3005 | train/val/test=0.835/0.830/0.831 | c=0.500000
[Epoch 0031] loss=18.5714 cls=0.4225 smmd=0.3166 ct=7.2731 rec=1.2970 | train/val/test=0.836/0.819/0.829 | c=0.500000
[Epoch 0032] loss=18.5890 cls=0.4234 smmd=0.3178 ct=7.2743 rec=1.3015 | train/val/test=0.831/0.828/0.828 | c=0.500000
[Epoch 0033] loss=18.6296 cls=0.4311 smmd=0.3223 ct=7.2703 rec=1.3000 | train/val/test=0.828/0.808/0.817 | c=0.500000
[Epoch 0034] loss=18.6229 cls=0.4407 smmd=0.3207 ct=7.2710 rec=1.3064 | train/val/test=0.814/0.812/0.813 | c=0.500000
[Epoch 0035] loss=18.6260 cls=0.4685 smmd=0.3176 ct=7.2808 rec=1.3092 | train/val/test=0.804/0.784/0.792 | c=0.500000
[Epoch 0036] loss=18.8920 cls=0.4885 smmd=0.3415 ct=7.2863 rec=1.3201 | train/val/test=0.766/0.769/0.767 | c=0.500000
[Epoch 0037] loss=19.0726 cls=0.5810 smmd=0.3534 ct=7.2904 rec=1.3346 | train/val/test=0.764/0.737/0.744 | c=0.500000
[Epoch 0038] loss=19.0223 cls=0.5782 smmd=0.3437 ct=7.3146 rec=1.3332 | train/val/test=0.795/0.796/0.798 | c=0.500000
[Epoch 0039] loss=18.5933 cls=0.5173 smmd=0.3130 ct=7.2745 rec=1.3105 | train/val/test=0.841/0.827/0.834 | c=0.500000
[Epoch 0040] loss=18.1393 cls=0.4044 smmd=0.2768 ct=7.2628 rec=1.2875 | train/val/test=0.838/0.822/0.830 | c=0.500000
[Epoch 0041] loss=18.0315 cls=0.4225 smmd=0.2640 ct=7.2676 rec=1.2891 | train/val/test=0.820/0.815/0.818 | c=0.500000
[Epoch 0042] loss=18.0560 cls=0.4617 smmd=0.2664 ct=7.2555 rec=1.3001 | train/val/test=0.836/0.819/0.828 | c=0.500000
[Epoch 0043] loss=17.9262 cls=0.4319 smmd=0.2555 ct=7.2534 rec=1.2972 | train/val/test=0.839/0.828/0.837 | c=0.500000
[Epoch 0044] loss=17.8747 cls=0.4246 smmd=0.2541 ct=7.2361 rec=1.2984 | train/val/test=0.828/0.822/0.827 | c=0.500000
[Epoch 0045] loss=17.9559 cls=0.4474 smmd=0.2600 ct=7.2375 rec=1.3139 | train/val/test=0.817/0.796/0.802 | c=0.500000
[Epoch 0046] loss=18.1220 cls=0.4886 smmd=0.2741 ct=7.2387 rec=1.3182 | train/val/test=0.795/0.790/0.795 | c=0.500000
[Epoch 0047] loss=18.1902 cls=0.4976 smmd=0.2755 ct=7.2602 rec=1.3324 | train/val/test=0.816/0.794/0.801 | c=0.500000
[Epoch 0048] loss=18.1061 cls=0.4856 smmd=0.2729 ct=7.2368 rec=1.3224 | train/val/test=0.830/0.826/0.829 | c=0.500000
[Epoch 0049] loss=17.9126 cls=0.4535 smmd=0.2566 ct=7.2304 rec=1.3183 | train/val/test=0.841/0.828/0.836 | c=0.500000
[Epoch 0050] loss=17.7308 cls=0.4318 smmd=0.2397 ct=7.2310 rec=1.3123 | train/val/test=0.837/0.829/0.838 | c=0.500000
[Epoch 0051] loss=17.6833 cls=0.4334 smmd=0.2362 ct=7.2258 rec=1.3052 | train/val/test=0.837/0.825/0.833 | c=0.500000
[Epoch 0052] loss=17.6839 cls=0.4338 smmd=0.2351 ct=7.2299 rec=1.3122 | train/val/test=0.833/0.824/0.833 | c=0.500000
[Epoch 0053] loss=17.6649 cls=0.4511 smmd=0.2339 ct=7.2236 rec=1.3054 | train/val/test=0.833/0.821/0.831 | c=0.500000
[Epoch 0054] loss=17.6869 cls=0.4473 smmd=0.2347 ct=7.2284 rec=1.3192 | train/val/test=0.820/0.820/0.823 | c=0.500000
[Epoch 0055] loss=17.7548 cls=0.4789 smmd=0.2424 ct=7.2171 rec=1.3135 | train/val/test=0.781/0.757/0.766 | c=0.500000
[Epoch 0056] loss=17.9722 cls=0.5309 smmd=0.2499 ct=7.2671 rec=1.3469 | train/val/test=0.717/0.717/0.723 | c=0.500000
[Epoch 0057] loss=18.3968 cls=0.6523 smmd=0.2861 ct=7.2696 rec=1.3419 | train/val/test=0.704/0.687/0.688 | c=0.500000
[Epoch 0058] loss=18.4434 cls=0.6415 smmd=0.2797 ct=7.3191 rec=1.3742 | train/val/test=0.779/0.779/0.780 | c=0.500000
[Epoch 0059] loss=18.1019 cls=0.5704 smmd=0.2675 ct=7.2397 rec=1.3248 | train/val/test=0.837/0.822/0.830 | c=0.500000
[Epoch 0060] loss=17.5249 cls=0.4276 smmd=0.2166 ct=7.2482 rec=1.2980 | train/val/test=0.836/0.821/0.827 | c=0.500000
[Epoch 0061] loss=17.5161 cls=0.4248 smmd=0.2173 ct=7.2406 rec=1.2981 | train/val/test=0.804/0.804/0.807 | c=0.500000
[Epoch 0062] loss=17.7636 cls=0.4962 smmd=0.2406 ct=7.2290 rec=1.3020 | train/val/test=0.836/0.824/0.829 | c=0.500000
[Epoch 0063] loss=17.6534 cls=0.4281 smmd=0.2273 ct=7.2573 rec=1.3038 | train/val/test=0.835/0.829/0.833 | c=0.500000
[Epoch 0064] loss=17.5638 cls=0.4258 smmd=0.2284 ct=7.2081 rec=1.3019 | train/val/test=0.823/0.819/0.822 | c=0.500000
[Epoch 0065] loss=17.7446 cls=0.4611 smmd=0.2400 ct=7.2291 rec=1.3111 | train/val/test=0.828/0.815/0.819 | c=0.500000
[Epoch 0066] loss=17.9024 cls=0.4572 smmd=0.2524 ct=7.2441 rec=1.3231 | train/val/test=0.817/0.816/0.813 | c=0.500000
[Epoch 0067] loss=17.8268 cls=0.4847 smmd=0.2473 ct=7.2254 rec=1.3220 | train/val/test=0.839/0.826/0.836 | c=0.500000
[Epoch 0068] loss=17.5779 cls=0.4455 smmd=0.2276 ct=7.2104 rec=1.3163 | train/val/test=0.832/0.825/0.832 | c=0.500000
[Epoch 0069] loss=17.4854 cls=0.4451 smmd=0.2180 ct=7.2124 rec=1.3158 | train/val/test=0.831/0.823/0.831 | c=0.500000
[Epoch 0070] loss=17.5527 cls=0.4567 smmd=0.2247 ct=7.2117 rec=1.3089 | train/val/test=0.825/0.823/0.823 | c=0.500000
[Epoch 0071] loss=17.5956 cls=0.4527 smmd=0.2241 ct=7.2353 rec=1.3150 | train/val/test=0.834/0.822/0.830 | c=0.500000
[Epoch 0072] loss=17.5892 cls=0.4610 smmd=0.2278 ct=7.2134 rec=1.3086 | train/val/test=0.799/0.795/0.799 | c=0.500000
[Epoch 0073] loss=17.6739 cls=0.5029 smmd=0.2277 ct=7.2414 rec=1.3243 | train/val/test=0.791/0.763/0.771 | c=0.500000
[Epoch 0074] loss=17.8924 cls=0.5297 smmd=0.2485 ct=7.2386 rec=1.3309 | train/val/test=0.757/0.758/0.758 | c=0.500000
[Epoch 0075] loss=18.0536 cls=0.5959 smmd=0.2550 ct=7.2661 rec=1.3471 | train/val/test=0.767/0.745/0.748 | c=0.500000
[Epoch 0076] loss=18.0538 cls=0.5539 smmd=0.2569 ct=7.2699 rec=1.3352 | train/val/test=0.802/0.800/0.803 | c=0.500000
[Epoch 0077] loss=17.7414 cls=0.4942 smmd=0.2383 ct=7.2267 rec=1.3159 | train/val/test=0.837/0.824/0.833 | c=0.500000
[Epoch 0078] loss=17.4693 cls=0.4256 smmd=0.2130 ct=7.2387 rec=1.2981 | train/val/test=0.836/0.822/0.829 | c=0.500000
[Epoch 0079] loss=17.4531 cls=0.4266 smmd=0.2181 ct=7.2039 rec=1.3015 | train/val/test=0.822/0.818/0.822 | c=0.500000
[Epoch 0080] loss=17.5937 cls=0.4577 smmd=0.2245 ct=7.2330 rec=1.3076 | train/val/test=0.818/0.800/0.808 | c=0.500000
[Epoch 0081] loss=17.7015 cls=0.4667 smmd=0.2350 ct=7.2307 rec=1.3137 | train/val/test=0.825/0.823/0.826 | c=0.500000
[Epoch 0082] loss=17.6532 cls=0.4522 smmd=0.2325 ct=7.2230 rec=1.3119 | train/val/test=0.834/0.822/0.831 | c=0.500000
[Epoch 0083] loss=17.5577 cls=0.4420 smmd=0.2255 ct=7.2138 rec=1.3086 | train/val/test=0.836/0.822/0.831 | c=0.500000
[Epoch 0084] loss=17.5157 cls=0.4328 smmd=0.2243 ct=7.2007 rec=1.3087 | train/val/test=0.836/0.824/0.833 | c=0.500000
[Epoch 0085] loss=17.5180 cls=0.4333 smmd=0.2204 ct=7.2218 rec=1.3083 | train/val/test=0.835/0.821/0.832 | c=0.500000
[Epoch 0086] loss=17.5544 cls=0.4360 smmd=0.2295 ct=7.1932 rec=1.3095 | train/val/test=0.834/0.823/0.829 | c=0.500000
[Epoch 0087] loss=17.5554 cls=0.4324 smmd=0.2212 ct=7.2364 rec=1.3088 | train/val/test=0.834/0.823/0.831 | c=0.500000
[Epoch 0088] loss=17.5434 cls=0.4357 smmd=0.2270 ct=7.2013 rec=1.3051 | train/val/test=0.827/0.816/0.825 | c=0.500000
[Epoch 0089] loss=17.6071 cls=0.4495 smmd=0.2247 ct=7.2383 rec=1.3166 | train/val/test=0.782/0.786/0.780 | c=0.500000
[Epoch 0090] loss=17.8940 cls=0.5482 smmd=0.2494 ct=7.2327 rec=1.3218 | train/val/test=0.678/0.655/0.654 | c=0.500000
[Epoch 0091] loss=18.4109 cls=0.6940 smmd=0.2693 ct=7.3379 rec=1.3909 | train/val/test=0.664/0.660/0.665 | c=0.500000
[Epoch 0092] loss=19.0077 cls=0.8695 smmd=0.3289 ct=7.3025 rec=1.3568 | train/val/test=0.766/0.737/0.748 | c=0.500000
[Epoch 0093] loss=18.0398 cls=0.5642 smmd=0.2459 ct=7.3131 rec=1.3459 | train/val/test=0.823/0.820/0.827 | c=0.500000
[Epoch 0094] loss=17.3782 cls=0.4438 smmd=0.2109 ct=7.2015 rec=1.2878 | train/val/test=0.815/0.811/0.818 | c=0.500000
[Epoch 0095] loss=17.5537 cls=0.4687 smmd=0.2221 ct=7.2263 rec=1.2917 | train/val/test=0.822/0.805/0.814 | c=0.500000
[Epoch 0096] loss=17.8925 cls=0.4615 smmd=0.2417 ct=7.2944 rec=1.3126 | train/val/test=0.810/0.811/0.811 | c=0.500000
[Epoch 0097] loss=17.7840 cls=0.4804 smmd=0.2477 ct=7.2072 rec=1.3053 | train/val/test=0.835/0.826/0.833 | c=0.500000
[Epoch 0098] loss=17.6865 cls=0.4337 smmd=0.2329 ct=7.2449 rec=1.3025 | train/val/test=0.833/0.826/0.834 | c=0.500000
[Epoch 0099] loss=17.9650 cls=0.4430 smmd=0.2598 ct=7.2444 rec=1.3133 | train/val/test=0.823/0.816/0.824 | c=0.500000
=== Best @ epoch 27: val=0.8331, test=0.8403 ===
