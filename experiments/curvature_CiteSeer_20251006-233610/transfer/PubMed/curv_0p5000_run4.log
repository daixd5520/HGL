Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=81.4469 cls=1.1014 smmd=6.5659 ct=7.2650 rec=1.4136 | train/val/test=0.455/0.451/0.458 | c=0.500000
[Epoch 0001] loss=73.0977 cls=1.0552 smmd=5.7367 ct=7.2476 rec=1.4166 | train/val/test=0.592/0.610/0.603 | c=0.500000
[Epoch 0002] loss=41.9912 cls=1.0628 smmd=2.6520 ct=7.1167 rec=1.4131 | train/val/test=0.532/0.516/0.538 | c=0.500000
[Epoch 0003] loss=46.2226 cls=0.9737 smmd=3.0961 ct=7.0341 rec=1.4123 | train/val/test=0.657/0.659/0.662 | c=0.500000
[Epoch 0004] loss=45.8474 cls=0.8831 smmd=3.0984 ct=6.8617 rec=1.3971 | train/val/test=0.687/0.689/0.694 | c=0.500000
[Epoch 0005] loss=35.8403 cls=0.7784 smmd=2.1151 ct=6.8064 rec=1.3748 | train/val/test=0.682/0.686/0.688 | c=0.500000
[Epoch 0006] loss=28.5345 cls=0.7160 smmd=1.3926 ct=6.7882 rec=1.3484 | train/val/test=0.683/0.691/0.684 | c=0.500000
[Epoch 0007] loss=32.0770 cls=0.6929 smmd=1.7494 ct=6.7856 rec=1.3316 | train/val/test=0.702/0.702/0.707 | c=0.500000
[Epoch 0008] loss=34.5921 cls=0.6649 smmd=2.0035 ct=6.7817 rec=1.3224 | train/val/test=0.746/0.745/0.746 | c=0.500000
[Epoch 0009] loss=32.7495 cls=0.6066 smmd=1.8271 ct=6.7594 rec=1.3133 | train/val/test=0.766/0.763/0.766 | c=0.500000
[Epoch 0010] loss=28.2846 cls=0.5676 smmd=1.3844 ct=6.7499 rec=1.3135 | train/val/test=0.794/0.792/0.798 | c=0.500000
[Epoch 0011] loss=25.6504 cls=0.5413 smmd=0.9827 ct=7.4472 rec=1.3171 | train/val/test=0.781/0.783/0.789 | c=0.500000
[Epoch 0012] loss=26.5862 cls=0.5579 smmd=1.1191 ct=7.2277 rec=1.3219 | train/val/test=0.797/0.801/0.803 | c=0.500000
[Epoch 0013] loss=29.0373 cls=0.5448 smmd=1.3575 ct=7.2641 rec=1.3224 | train/val/test=0.787/0.793/0.792 | c=0.500000
[Epoch 0014] loss=26.5703 cls=0.5490 smmd=1.1044 ct=7.2948 rec=1.3246 | train/val/test=0.775/0.780/0.782 | c=0.500000
[Epoch 0015] loss=23.1773 cls=0.5595 smmd=0.7684 ct=7.2753 rec=1.3262 | train/val/test=0.784/0.789/0.785 | c=0.500000
[Epoch 0016] loss=24.0818 cls=0.5347 smmd=0.8468 ct=7.3440 rec=1.3163 | train/val/test=0.801/0.803/0.803 | c=0.500000
[Epoch 0017] loss=24.3592 cls=0.5131 smmd=0.8854 ct=7.2970 rec=1.3086 | train/val/test=0.816/0.822/0.815 | c=0.500000
[Epoch 0018] loss=22.8640 cls=0.4902 smmd=0.7442 ct=7.2639 rec=1.2981 | train/val/test=0.826/0.831/0.825 | c=0.500000
[Epoch 0019] loss=21.2532 cls=0.4689 smmd=0.5803 ct=7.2854 rec=1.2904 | train/val/test=0.828/0.832/0.824 | c=0.500000
[Epoch 0020] loss=20.9063 cls=0.4488 smmd=0.5451 ct=7.2938 rec=1.2864 | train/val/test=0.830/0.834/0.827 | c=0.500000
[Epoch 0021] loss=21.5356 cls=0.4351 smmd=0.6093 ct=7.2911 rec=1.2855 | train/val/test=0.832/0.832/0.833 | c=0.500000
[Epoch 0022] loss=21.2180 cls=0.4311 smmd=0.5767 ct=7.2959 rec=1.2873 | train/val/test=0.831/0.831/0.833 | c=0.500000
[Epoch 0023] loss=20.3396 cls=0.4345 smmd=0.4898 ct=7.2898 rec=1.2898 | train/val/test=0.830/0.834/0.835 | c=0.500000
[Epoch 0024] loss=20.3506 cls=0.4433 smmd=0.4934 ct=7.2741 rec=1.2936 | train/val/test=0.830/0.829/0.833 | c=0.500000
[Epoch 0025] loss=20.7849 cls=0.4432 smmd=0.5384 ct=7.2651 rec=1.2983 | train/val/test=0.832/0.833/0.835 | c=0.500000
[Epoch 0026] loss=20.6179 cls=0.4448 smmd=0.5224 ct=7.2595 rec=1.3049 | train/val/test=0.833/0.820/0.832 | c=0.500000
[Epoch 0027] loss=19.8916 cls=0.4407 smmd=0.4481 ct=7.2693 rec=1.3043 | train/val/test=0.836/0.843/0.843 | c=0.500000
[Epoch 0028] loss=19.5938 cls=0.4465 smmd=0.4167 ct=7.2737 rec=1.3118 | train/val/test=0.822/0.813/0.816 | c=0.500000
[Epoch 0029] loss=19.5432 cls=0.4537 smmd=0.4134 ct=7.2650 rec=1.3055 | train/val/test=0.778/0.780/0.782 | c=0.500000
[Epoch 0030] loss=19.1984 cls=0.5214 smmd=0.3719 ct=7.2770 rec=1.3301 | train/val/test=0.780/0.771/0.771 | c=0.500000
[Epoch 0031] loss=19.0193 cls=0.5489 smmd=0.3547 ct=7.2677 rec=1.3249 | train/val/test=0.769/0.772/0.776 | c=0.500000
[Epoch 0032] loss=18.8519 cls=0.5321 smmd=0.3351 ct=7.2852 rec=1.3284 | train/val/test=0.822/0.813/0.814 | c=0.500000
[Epoch 0033] loss=18.6387 cls=0.4532 smmd=0.3268 ct=7.2468 rec=1.3015 | train/val/test=0.839/0.840/0.841 | c=0.500000
[Epoch 0034] loss=18.4437 cls=0.4124 smmd=0.3102 ct=7.2442 rec=1.2937 | train/val/test=0.828/0.833/0.833 | c=0.500000
[Epoch 0035] loss=18.4906 cls=0.4393 smmd=0.3095 ct=7.2619 rec=1.3047 | train/val/test=0.814/0.804/0.803 | c=0.500000
[Epoch 0036] loss=18.7472 cls=0.4778 smmd=0.3333 ct=7.2607 rec=1.3072 | train/val/test=0.812/0.816/0.818 | c=0.500000
[Epoch 0037] loss=18.8399 cls=0.4735 smmd=0.3390 ct=7.2771 rec=1.3172 | train/val/test=0.818/0.810/0.809 | c=0.500000
[Epoch 0038] loss=18.7270 cls=0.4650 smmd=0.3342 ct=7.2503 rec=1.3045 | train/val/test=0.834/0.841/0.837 | c=0.500000
[Epoch 0039] loss=18.4768 cls=0.4293 smmd=0.3087 ct=7.2620 rec=1.3024 | train/val/test=0.840/0.836/0.835 | c=0.500000
[Epoch 0040] loss=18.2356 cls=0.4134 smmd=0.2902 ct=7.2399 rec=1.2935 | train/val/test=0.837/0.834/0.834 | c=0.500000
[Epoch 0041] loss=18.0466 cls=0.4197 smmd=0.2731 ct=7.2291 rec=1.2954 | train/val/test=0.834/0.840/0.836 | c=0.500000
[Epoch 0042] loss=17.9576 cls=0.4331 smmd=0.2608 ct=7.2413 rec=1.3017 | train/val/test=0.831/0.827/0.825 | c=0.500000
[Epoch 0043] loss=17.8813 cls=0.4393 smmd=0.2556 ct=7.2268 rec=1.3046 | train/val/test=0.834/0.839/0.834 | c=0.500000
[Epoch 0044] loss=17.8090 cls=0.4429 smmd=0.2477 ct=7.2285 rec=1.3083 | train/val/test=0.837/0.837/0.834 | c=0.500000
[Epoch 0045] loss=17.7860 cls=0.4396 smmd=0.2477 ct=7.2165 rec=1.3116 | train/val/test=0.839/0.843/0.839 | c=0.500000
[Epoch 0046] loss=17.8043 cls=0.4459 smmd=0.2509 ct=7.2080 rec=1.3137 | train/val/test=0.838/0.838/0.839 | c=0.500000
[Epoch 0047] loss=17.8403 cls=0.4481 smmd=0.2542 ct=7.2072 rec=1.3200 | train/val/test=0.840/0.839/0.841 | c=0.500000
[Epoch 0048] loss=17.8594 cls=0.4519 smmd=0.2573 ct=7.2008 rec=1.3179 | train/val/test=0.836/0.839/0.837 | c=0.500000
[Epoch 0049] loss=17.8976 cls=0.4543 smmd=0.2589 ct=7.2097 rec=1.3250 | train/val/test=0.832/0.828/0.831 | c=0.500000
[Epoch 0050] loss=17.9029 cls=0.4664 smmd=0.2612 ct=7.1996 rec=1.3159 | train/val/test=0.818/0.823/0.824 | c=0.500000
[Epoch 0051] loss=17.9422 cls=0.4821 smmd=0.2565 ct=7.2352 rec=1.3324 | train/val/test=0.779/0.788/0.779 | c=0.500000
[Epoch 0052] loss=18.1396 cls=0.5617 smmd=0.2712 ct=7.2440 rec=1.3165 | train/val/test=0.788/0.790/0.793 | c=0.500000
[Epoch 0053] loss=18.2098 cls=0.5394 smmd=0.2708 ct=7.2810 rec=1.3408 | train/val/test=0.800/0.803/0.796 | c=0.500000
[Epoch 0054] loss=17.8783 cls=0.5257 smmd=0.2491 ct=7.2356 rec=1.3064 | train/val/test=0.838/0.840/0.839 | c=0.500000
[Epoch 0055] loss=17.5556 cls=0.4270 smmd=0.2267 ct=7.2111 rec=1.3055 | train/val/test=0.835/0.832/0.832 | c=0.500000
[Epoch 0056] loss=17.6003 cls=0.4313 smmd=0.2273 ct=7.2299 rec=1.3044 | train/val/test=0.826/0.831/0.826 | c=0.500000
[Epoch 0057] loss=17.8622 cls=0.4703 smmd=0.2513 ct=7.2325 rec=1.2984 | train/val/test=0.817/0.813/0.810 | c=0.500000
[Epoch 0058] loss=17.9488 cls=0.4825 smmd=0.2559 ct=7.2437 rec=1.3218 | train/val/test=0.808/0.819/0.815 | c=0.500000
[Epoch 0059] loss=17.9038 cls=0.4914 smmd=0.2517 ct=7.2416 rec=1.3151 | train/val/test=0.705/0.709/0.699 | c=0.500000
[Epoch 0060] loss=18.3013 cls=0.6846 smmd=0.2817 ct=7.2298 rec=1.3646 | train/val/test=0.615/0.628/0.625 | c=0.500000
[Epoch 0061] loss=19.0335 cls=0.8402 smmd=0.3122 ct=7.3964 rec=1.3979 | train/val/test=0.689/0.688/0.675 | c=0.500000
[Epoch 0062] loss=18.8442 cls=0.8587 smmd=0.3215 ct=7.2546 rec=1.3806 | train/val/test=0.830/0.835/0.833 | c=0.500000
[Epoch 0063] loss=17.6463 cls=0.4386 smmd=0.2237 ct=7.2716 rec=1.2932 | train/val/test=0.824/0.831/0.827 | c=0.500000
[Epoch 0064] loss=17.6988 cls=0.4491 smmd=0.2227 ct=7.2986 rec=1.2995 | train/val/test=0.786/0.774/0.777 | c=0.500000
[Epoch 0065] loss=18.0067 cls=0.5754 smmd=0.2617 ct=7.2237 rec=1.3086 | train/val/test=0.832/0.834/0.831 | c=0.500000
[Epoch 0066] loss=17.5565 cls=0.4245 smmd=0.2188 ct=7.2565 rec=1.2861 | train/val/test=0.826/0.829/0.828 | c=0.500000
[Epoch 0067] loss=17.8309 cls=0.4446 smmd=0.2378 ct=7.2891 rec=1.3045 | train/val/test=0.811/0.803/0.806 | c=0.500000
[Epoch 0068] loss=18.0927 cls=0.4842 smmd=0.2765 ct=7.2149 rec=1.3126 | train/val/test=0.823/0.827/0.827 | c=0.500000
[Epoch 0069] loss=17.8765 cls=0.4703 smmd=0.2523 ct=7.2318 rec=1.3097 | train/val/test=0.831/0.839/0.831 | c=0.500000
[Epoch 0070] loss=17.9802 cls=0.4607 smmd=0.2581 ct=7.2540 rec=1.3214 | train/val/test=0.829/0.834/0.830 | c=0.500000
[Epoch 0071] loss=18.0126 cls=0.4793 smmd=0.2688 ct=7.2131 rec=1.3184 | train/val/test=0.822/0.825/0.826 | c=0.500000
[Epoch 0072] loss=17.6679 cls=0.4814 smmd=0.2335 ct=7.2158 rec=1.3213 | train/val/test=0.832/0.836/0.834 | c=0.500000
[Epoch 0073] loss=17.5563 cls=0.4630 smmd=0.2228 ct=7.2172 rec=1.3241 | train/val/test=0.822/0.827/0.822 | c=0.500000
[Epoch 0074] loss=17.6136 cls=0.4865 smmd=0.2299 ct=7.2073 rec=1.3139 | train/val/test=0.834/0.836/0.838 | c=0.500000
[Epoch 0075] loss=17.4811 cls=0.4508 smmd=0.2190 ct=7.2039 rec=1.3156 | train/val/test=0.832/0.834/0.835 | c=0.500000
[Epoch 0076] loss=17.4345 cls=0.4512 smmd=0.2141 ct=7.2054 rec=1.3140 | train/val/test=0.822/0.823/0.819 | c=0.500000
[Epoch 0077] loss=17.6095 cls=0.4680 smmd=0.2325 ct=7.1980 rec=1.3097 | train/val/test=0.824/0.827/0.831 | c=0.500000
[Epoch 0078] loss=17.6658 cls=0.4648 smmd=0.2348 ct=7.2128 rec=1.3205 | train/val/test=0.831/0.825/0.831 | c=0.500000
[Epoch 0079] loss=17.6485 cls=0.4608 smmd=0.2366 ct=7.1981 rec=1.3116 | train/val/test=0.828/0.827/0.829 | c=0.500000
[Epoch 0080] loss=17.6626 cls=0.4601 smmd=0.2393 ct=7.1901 rec=1.3199 | train/val/test=0.836/0.836/0.836 | c=0.500000
[Epoch 0081] loss=17.6885 cls=0.4541 smmd=0.2351 ct=7.2261 rec=1.3158 | train/val/test=0.832/0.835/0.832 | c=0.500000
[Epoch 0082] loss=17.6600 cls=0.4504 smmd=0.2385 ct=7.1951 rec=1.3187 | train/val/test=0.828/0.826/0.824 | c=0.500000
[Epoch 0083] loss=17.5820 cls=0.4608 smmd=0.2237 ct=7.2289 rec=1.3140 | train/val/test=0.817/0.824/0.818 | c=0.500000
[Epoch 0084] loss=17.6190 cls=0.4717 smmd=0.2285 ct=7.2175 rec=1.3251 | train/val/test=0.771/0.760/0.757 | c=0.500000
[Epoch 0085] loss=17.8374 cls=0.5893 smmd=0.2393 ct=7.2408 rec=1.3360 | train/val/test=0.755/0.765/0.757 | c=0.500000
[Epoch 0086] loss=17.9707 cls=0.5661 smmd=0.2466 ct=7.2750 rec=1.3433 | train/val/test=0.765/0.757/0.761 | c=0.500000
[Epoch 0087] loss=17.9052 cls=0.6034 smmd=0.2483 ct=7.2263 rec=1.3353 | train/val/test=0.822/0.827/0.823 | c=0.500000
[Epoch 0088] loss=17.6745 cls=0.4695 smmd=0.2280 ct=7.2549 rec=1.3006 | train/val/test=0.825/0.820/0.819 | c=0.500000
[Epoch 0089] loss=17.5198 cls=0.4446 smmd=0.2241 ct=7.2034 rec=1.2985 | train/val/test=0.822/0.817/0.816 | c=0.500000
[Epoch 0090] loss=17.5781 cls=0.4594 smmd=0.2275 ct=7.2135 rec=1.2934 | train/val/test=0.827/0.832/0.830 | c=0.500000
[Epoch 0091] loss=17.7204 cls=0.4459 smmd=0.2378 ct=7.2330 rec=1.3069 | train/val/test=0.815/0.811/0.806 | c=0.500000
[Epoch 0092] loss=17.8085 cls=0.4811 smmd=0.2463 ct=7.2238 rec=1.3147 | train/val/test=0.819/0.828/0.823 | c=0.500000
[Epoch 0093] loss=17.7664 cls=0.4789 smmd=0.2421 ct=7.2256 rec=1.3096 | train/val/test=0.819/0.816/0.811 | c=0.500000
[Epoch 0094] loss=17.6925 cls=0.4738 smmd=0.2334 ct=7.2305 rec=1.3216 | train/val/test=0.818/0.826/0.816 | c=0.500000
[Epoch 0095] loss=17.5273 cls=0.4931 smmd=0.2237 ct=7.1952 rec=1.3060 | train/val/test=0.826/0.823/0.824 | c=0.500000
[Epoch 0096] loss=17.4850 cls=0.4519 smmd=0.2186 ct=7.2080 rec=1.3134 | train/val/test=0.826/0.828/0.825 | c=0.500000
[Epoch 0097] loss=17.5148 cls=0.4610 smmd=0.2211 ct=7.2112 rec=1.3011 | train/val/test=0.830/0.834/0.834 | c=0.500000
[Epoch 0098] loss=17.5534 cls=0.4372 smmd=0.2269 ct=7.2064 rec=1.3057 | train/val/test=0.833/0.833/0.834 | c=0.500000
[Epoch 0099] loss=17.5839 cls=0.4384 smmd=0.2261 ct=7.2260 rec=1.3045 | train/val/test=0.830/0.824/0.827 | c=0.500000
=== Best @ epoch 27: val=0.8425, test=0.8428 ===
