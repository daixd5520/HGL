Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=81.3065 cls=1.0807 smmd=6.5520 ct=7.2694 rec=1.4142 | train/val/test=0.397/0.408/0.399 | c=0.100000
[Epoch 0001] loss=72.8326 cls=1.0563 smmd=5.7070 ct=7.2625 rec=1.4194 | train/val/test=0.627/0.616/0.621 | c=0.100000
[Epoch 0002] loss=41.5930 cls=1.0622 smmd=2.6002 ct=7.1765 rec=1.4133 | train/val/test=0.558/0.565/0.557 | c=0.100000
[Epoch 0003] loss=45.9237 cls=1.0136 smmd=3.0516 ct=7.0977 rec=1.4104 | train/val/test=0.695/0.689/0.687 | c=0.100000
[Epoch 0004] loss=45.4993 cls=0.8656 smmd=3.0599 ct=6.8852 rec=1.3940 | train/val/test=0.682/0.673/0.675 | c=0.100000
[Epoch 0005] loss=35.4200 cls=0.7684 smmd=2.0738 ct=6.8086 rec=1.3604 | train/val/test=0.670/0.662/0.665 | c=0.100000
[Epoch 0006] loss=28.2839 cls=0.7310 smmd=1.3669 ct=6.7915 rec=1.3336 | train/val/test=0.672/0.669/0.666 | c=0.100000
[Epoch 0007] loss=32.0304 cls=0.7170 smmd=1.7419 ct=6.7973 rec=1.3177 | train/val/test=0.689/0.689/0.686 | c=0.100000
[Epoch 0008] loss=34.4981 cls=0.6764 smmd=1.9926 ct=6.7895 rec=1.3107 | train/val/test=0.731/0.732/0.724 | c=0.100000
[Epoch 0009] loss=32.5517 cls=0.6158 smmd=1.8049 ct=6.7697 rec=1.3108 | train/val/test=0.774/0.779/0.772 | c=0.100000
[Epoch 0010] loss=28.0282 cls=0.5676 smmd=1.3581 ct=6.7526 rec=1.3156 | train/val/test=0.796/0.806/0.795 | c=0.100000
[Epoch 0011] loss=24.1395 cls=0.5403 smmd=0.9724 ct=6.7427 rec=1.3210 | train/val/test=0.817/0.822/0.813 | c=0.100000
[Epoch 0012] loss=25.0702 cls=0.5307 smmd=1.0650 ct=6.7455 rec=1.3285 | train/val/test=0.816/0.818/0.809 | c=0.100000
[Epoch 0013] loss=27.5224 cls=0.5303 smmd=1.3103 ct=6.7443 rec=1.3307 | train/val/test=0.807/0.810/0.806 | c=0.100000
[Epoch 0014] loss=24.7011 cls=0.5274 smmd=1.0298 ct=6.7376 rec=1.3278 | train/val/test=0.798/0.802/0.799 | c=0.100000
[Epoch 0015] loss=21.6482 cls=0.5202 smmd=0.7273 ct=6.7273 rec=1.3200 | train/val/test=0.797/0.798/0.798 | c=0.100000
[Epoch 0016] loss=22.5229 cls=0.5107 smmd=0.8171 ct=6.7204 rec=1.3122 | train/val/test=0.808/0.811/0.807 | c=0.100000
[Epoch 0017] loss=24.0948 cls=0.4894 smmd=0.8452 ct=7.3744 rec=1.2992 | train/val/test=0.814/0.824/0.812 | c=0.100000
[Epoch 0018] loss=22.6995 cls=0.4803 smmd=0.7282 ct=7.2667 rec=1.2871 | train/val/test=0.821/0.829/0.817 | c=0.100000
[Epoch 0019] loss=21.0885 cls=0.4644 smmd=0.5669 ct=7.2738 rec=1.2800 | train/val/test=0.826/0.835/0.818 | c=0.100000
[Epoch 0020] loss=20.8274 cls=0.4509 smmd=0.5294 ct=7.3347 rec=1.2763 | train/val/test=0.828/0.837/0.822 | c=0.100000
[Epoch 0021] loss=21.4901 cls=0.4409 smmd=0.5961 ct=7.3351 rec=1.2758 | train/val/test=0.830/0.834/0.820 | c=0.100000
[Epoch 0022] loss=21.1962 cls=0.4367 smmd=0.5700 ct=7.3191 rec=1.2801 | train/val/test=0.831/0.835/0.823 | c=0.100000
[Epoch 0023] loss=20.3348 cls=0.4373 smmd=0.4858 ct=7.3077 rec=1.2852 | train/val/test=0.830/0.836/0.823 | c=0.100000
[Epoch 0024] loss=20.4627 cls=0.4401 smmd=0.5010 ct=7.2942 rec=1.2886 | train/val/test=0.830/0.839/0.827 | c=0.100000
[Epoch 0025] loss=20.8715 cls=0.4398 smmd=0.5420 ct=7.2916 rec=1.2973 | train/val/test=0.829/0.837/0.825 | c=0.100000
[Epoch 0026] loss=20.5823 cls=0.4380 smmd=0.5144 ct=7.2857 rec=1.2965 | train/val/test=0.837/0.850/0.832 | c=0.100000
[Epoch 0027] loss=19.8534 cls=0.4369 smmd=0.4394 ct=7.2937 rec=1.3066 | train/val/test=0.823/0.829/0.812 | c=0.100000
[Epoch 0028] loss=19.5592 cls=0.4463 smmd=0.4111 ct=7.2873 rec=1.3002 | train/val/test=0.800/0.806/0.794 | c=0.100000
[Epoch 0029] loss=19.5175 cls=0.4879 smmd=0.3997 ct=7.3075 rec=1.3230 | train/val/test=0.790/0.802/0.785 | c=0.100000
[Epoch 0030] loss=19.2573 cls=0.5122 smmd=0.3727 ct=7.3091 rec=1.3111 | train/val/test=0.788/0.798/0.784 | c=0.100000
[Epoch 0031] loss=18.9003 cls=0.5051 smmd=0.3390 ct=7.2994 rec=1.3167 | train/val/test=0.821/0.826/0.816 | c=0.100000
[Epoch 0032] loss=18.6207 cls=0.4457 smmd=0.3191 ct=7.2789 rec=1.2971 | train/val/test=0.837/0.848/0.831 | c=0.100000
[Epoch 0033] loss=18.5954 cls=0.4128 smmd=0.3199 ct=7.2726 rec=1.2891 | train/val/test=0.837/0.844/0.832 | c=0.100000
[Epoch 0034] loss=18.6176 cls=0.4264 smmd=0.3188 ct=7.2834 rec=1.2982 | train/val/test=0.813/0.822/0.809 | c=0.100000
[Epoch 0035] loss=18.6724 cls=0.4647 smmd=0.3218 ct=7.2862 rec=1.3000 | train/val/test=0.828/0.839/0.824 | c=0.100000
[Epoch 0036] loss=18.8333 cls=0.4532 smmd=0.3371 ct=7.2912 rec=1.3066 | train/val/test=0.807/0.814/0.804 | c=0.100000
[Epoch 0037] loss=18.8510 cls=0.4760 smmd=0.3403 ct=7.2785 rec=1.3054 | train/val/test=0.835/0.845/0.832 | c=0.100000
[Epoch 0038] loss=18.6322 cls=0.4336 smmd=0.3213 ct=7.2767 rec=1.2985 | train/val/test=0.829/0.837/0.822 | c=0.100000
[Epoch 0039] loss=18.4323 cls=0.4300 smmd=0.3021 ct=7.2740 rec=1.2965 | train/val/test=0.837/0.842/0.827 | c=0.100000
[Epoch 0040] loss=18.1834 cls=0.4203 smmd=0.2798 ct=7.2654 rec=1.2895 | train/val/test=0.839/0.846/0.834 | c=0.100000
[Epoch 0041] loss=18.0500 cls=0.4131 smmd=0.2661 ct=7.2678 rec=1.2943 | train/val/test=0.830/0.835/0.819 | c=0.100000
[Epoch 0042] loss=17.9294 cls=0.4311 smmd=0.2543 ct=7.2625 rec=1.2918 | train/val/test=0.842/0.849/0.837 | c=0.100000
[Epoch 0043] loss=17.8808 cls=0.4235 smmd=0.2507 ct=7.2562 rec=1.2988 | train/val/test=0.834/0.838/0.824 | c=0.100000
[Epoch 0044] loss=17.8564 cls=0.4263 smmd=0.2475 ct=7.2595 rec=1.2986 | train/val/test=0.843/0.852/0.831 | c=0.100000
[Epoch 0045] loss=17.8710 cls=0.4331 smmd=0.2476 ct=7.2634 rec=1.3035 | train/val/test=0.832/0.838/0.825 | c=0.100000
[Epoch 0046] loss=17.9537 cls=0.4333 smmd=0.2598 ct=7.2427 rec=1.3070 | train/val/test=0.844/0.846/0.830 | c=0.100000
[Epoch 0047] loss=17.9969 cls=0.4470 smmd=0.2619 ct=7.2505 rec=1.3077 | train/val/test=0.822/0.826/0.818 | c=0.100000
[Epoch 0048] loss=18.1060 cls=0.4601 smmd=0.2694 ct=7.2618 rec=1.3175 | train/val/test=0.819/0.825/0.807 | c=0.100000
[Epoch 0049] loss=18.2863 cls=0.5137 smmd=0.2786 ct=7.2925 rec=1.3166 | train/val/test=0.746/0.755/0.751 | c=0.100000
[Epoch 0050] loss=18.6171 cls=0.5950 smmd=0.2974 ct=7.3369 rec=1.3440 | train/val/test=0.744/0.749/0.741 | c=0.100000
[Epoch 0051] loss=18.6600 cls=0.6520 smmd=0.2967 ct=7.3505 rec=1.3328 | train/val/test=0.784/0.794/0.785 | c=0.100000
[Epoch 0052] loss=18.0154 cls=0.5184 smmd=0.2528 ct=7.2856 rec=1.3142 | train/val/test=0.835/0.840/0.829 | c=0.100000
[Epoch 0053] loss=17.6339 cls=0.4323 smmd=0.2210 ct=7.2787 rec=1.3006 | train/val/test=0.818/0.819/0.808 | c=0.100000
[Epoch 0054] loss=17.9296 cls=0.4832 smmd=0.2467 ct=7.2891 rec=1.2863 | train/val/test=0.829/0.833/0.826 | c=0.100000
[Epoch 0055] loss=17.9669 cls=0.4379 smmd=0.2489 ct=7.3042 rec=1.3002 | train/val/test=0.837/0.839/0.830 | c=0.100000
[Epoch 0056] loss=17.6783 cls=0.4128 smmd=0.2301 ct=7.2635 rec=1.2873 | train/val/test=0.837/0.842/0.829 | c=0.100000
[Epoch 0057] loss=17.9058 cls=0.4296 smmd=0.2504 ct=7.2705 rec=1.2921 | train/val/test=0.832/0.833/0.825 | c=0.100000
[Epoch 0058] loss=18.1912 cls=0.4437 smmd=0.2727 ct=7.2939 rec=1.3087 | train/val/test=0.838/0.842/0.829 | c=0.100000
[Epoch 0059] loss=18.0266 cls=0.4312 smmd=0.2634 ct=7.2639 rec=1.2986 | train/val/test=0.810/0.818/0.807 | c=0.100000
[Epoch 0060] loss=17.9032 cls=0.4736 smmd=0.2481 ct=7.2631 rec=1.3175 | train/val/test=0.781/0.790/0.779 | c=0.100000
[Epoch 0061] loss=18.0833 cls=0.5429 smmd=0.2607 ct=7.2687 rec=1.3356 | train/val/test=0.678/0.682/0.677 | c=0.100000
[Epoch 0062] loss=18.3006 cls=0.6857 smmd=0.2626 ct=7.3249 rec=1.3648 | train/val/test=0.744/0.755/0.745 | c=0.100000
[Epoch 0063] loss=18.2554 cls=0.6565 smmd=0.2688 ct=7.2834 rec=1.3447 | train/val/test=0.776/0.781/0.776 | c=0.100000
[Epoch 0064] loss=17.8650 cls=0.5388 smmd=0.2316 ct=7.3055 rec=1.3365 | train/val/test=0.831/0.834/0.820 | c=0.100000
[Epoch 0065] loss=17.5394 cls=0.4385 smmd=0.2160 ct=7.2585 rec=1.2860 | train/val/test=0.826/0.832/0.814 | c=0.100000
[Epoch 0066] loss=17.5040 cls=0.4403 smmd=0.2140 ct=7.2490 rec=1.2908 | train/val/test=0.822/0.824/0.817 | c=0.100000
[Epoch 0067] loss=17.8069 cls=0.4679 smmd=0.2333 ct=7.2914 rec=1.3144 | train/val/test=0.798/0.804/0.791 | c=0.100000
[Epoch 0068] loss=18.0101 cls=0.5131 smmd=0.2569 ct=7.2659 rec=1.3047 | train/val/test=0.836/0.841/0.832 | c=0.100000
[Epoch 0069] loss=17.8846 cls=0.4325 smmd=0.2477 ct=7.2687 rec=1.3070 | train/val/test=0.837/0.838/0.828 | c=0.100000
[Epoch 0070] loss=17.7738 cls=0.4390 smmd=0.2406 ct=7.2478 rec=1.3044 | train/val/test=0.814/0.819/0.805 | c=0.100000
[Epoch 0071] loss=17.8103 cls=0.4855 smmd=0.2450 ct=7.2298 rec=1.3165 | train/val/test=0.828/0.837/0.827 | c=0.100000
[Epoch 0072] loss=17.8167 cls=0.4673 smmd=0.2388 ct=7.2669 rec=1.3233 | train/val/test=0.781/0.786/0.771 | c=0.100000
[Epoch 0073] loss=17.6973 cls=0.5214 smmd=0.2314 ct=7.2303 rec=1.3242 | train/val/test=0.834/0.844/0.828 | c=0.100000
[Epoch 0074] loss=17.4894 cls=0.4650 smmd=0.2147 ct=7.2257 rec=1.3180 | train/val/test=0.828/0.835/0.820 | c=0.100000
[Epoch 0075] loss=17.3978 cls=0.4643 smmd=0.2064 ct=7.2211 rec=1.3195 | train/val/test=0.826/0.830/0.815 | c=0.100000
[Epoch 0076] loss=17.4514 cls=0.4806 smmd=0.2129 ct=7.2125 rec=1.3148 | train/val/test=0.835/0.841/0.834 | c=0.100000
[Epoch 0077] loss=17.5475 cls=0.4593 smmd=0.2196 ct=7.2304 rec=1.3224 | train/val/test=0.827/0.830/0.815 | c=0.100000
[Epoch 0078] loss=17.5977 cls=0.4741 smmd=0.2272 ct=7.2154 rec=1.3162 | train/val/test=0.837/0.843/0.836 | c=0.100000
[Epoch 0079] loss=17.6318 cls=0.4543 smmd=0.2309 ct=7.2181 rec=1.3195 | train/val/test=0.828/0.834/0.820 | c=0.100000
[Epoch 0080] loss=17.6618 cls=0.4620 smmd=0.2339 ct=7.2166 rec=1.3179 | train/val/test=0.831/0.840/0.826 | c=0.100000
[Epoch 0081] loss=17.7011 cls=0.4671 smmd=0.2365 ct=7.2214 rec=1.3189 | train/val/test=0.786/0.797/0.781 | c=0.100000
[Epoch 0082] loss=17.8280 cls=0.5143 smmd=0.2421 ct=7.2422 rec=1.3318 | train/val/test=0.722/0.732/0.725 | c=0.100000
[Epoch 0083] loss=18.1903 cls=0.6344 smmd=0.2603 ct=7.2980 rec=1.3489 | train/val/test=0.672/0.685/0.671 | c=0.100000
[Epoch 0084] loss=18.4387 cls=0.7537 smmd=0.2781 ct=7.2967 rec=1.3753 | train/val/test=0.656/0.663/0.664 | c=0.100000
[Epoch 0085] loss=18.4354 cls=0.7697 smmd=0.2669 ct=7.3493 rec=1.3651 | train/val/test=0.789/0.797/0.787 | c=0.100000
[Epoch 0086] loss=17.7776 cls=0.5379 smmd=0.2346 ct=7.2543 rec=1.3075 | train/val/test=0.834/0.838/0.826 | c=0.100000
[Epoch 0087] loss=17.6447 cls=0.4184 smmd=0.2234 ct=7.2796 rec=1.2846 | train/val/test=0.830/0.830/0.819 | c=0.100000
[Epoch 0088] loss=17.8727 cls=0.4536 smmd=0.2386 ct=7.3065 rec=1.2947 | train/val/test=0.814/0.823/0.807 | c=0.100000
[Epoch 0089] loss=17.7887 cls=0.4727 smmd=0.2425 ct=7.2399 rec=1.2956 | train/val/test=0.833/0.839/0.826 | c=0.100000
[Epoch 0090] loss=17.9128 cls=0.4334 smmd=0.2490 ct=7.2784 rec=1.2994 | train/val/test=0.830/0.836/0.821 | c=0.100000
[Epoch 0091] loss=18.2941 cls=0.4434 smmd=0.2833 ct=7.2952 rec=1.2989 | train/val/test=0.832/0.838/0.824 | c=0.100000
[Epoch 0092] loss=18.1383 cls=0.4475 smmd=0.2712 ct=7.2752 rec=1.3046 | train/val/test=0.824/0.828/0.821 | c=0.100000
[Epoch 0093] loss=17.7954 cls=0.4670 smmd=0.2407 ct=7.2484 rec=1.3153 | train/val/test=0.794/0.803/0.795 | c=0.100000
[Epoch 0094] loss=17.6975 cls=0.5123 smmd=0.2333 ct=7.2255 rec=1.3141 | train/val/test=0.804/0.811/0.804 | c=0.100000
[Epoch 0095] loss=17.7118 cls=0.4988 smmd=0.2312 ct=7.2437 rec=1.3256 | train/val/test=0.803/0.808/0.796 | c=0.100000
[Epoch 0096] loss=17.5555 cls=0.4915 smmd=0.2193 ct=7.2297 rec=1.3150 | train/val/test=0.829/0.836/0.818 | c=0.100000
[Epoch 0097] loss=17.4274 cls=0.4512 smmd=0.2138 ct=7.2059 rec=1.3031 | train/val/test=0.836/0.843/0.829 | c=0.100000
[Epoch 0098] loss=17.5189 cls=0.4357 smmd=0.2192 ct=7.2277 rec=1.3070 | train/val/test=0.833/0.835/0.823 | c=0.100000
[Epoch 0099] loss=17.7049 cls=0.4535 smmd=0.2384 ct=7.2207 rec=1.3048 | train/val/test=0.824/0.832/0.813 | c=0.100000
=== Best @ epoch 44: val=0.8516, test=0.8314 ===
