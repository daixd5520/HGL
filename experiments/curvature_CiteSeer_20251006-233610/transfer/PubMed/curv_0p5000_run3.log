Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=81.4110 cls=1.0995 smmd=6.5615 ct=7.2696 rec=1.4136 | train/val/test=0.392/0.400/0.397 | c=0.500000
[Epoch 0001] loss=73.0785 cls=1.0628 smmd=5.7309 ct=7.2641 rec=1.4207 | train/val/test=0.409/0.404/0.398 | c=0.500000
[Epoch 0002] loss=41.9064 cls=1.0511 smmd=2.6377 ct=7.1480 rec=1.4147 | train/val/test=0.270/0.269/0.274 | c=0.500000
[Epoch 0003] loss=46.4661 cls=1.0852 smmd=3.0988 ct=7.1142 rec=1.4139 | train/val/test=0.639/0.645/0.635 | c=0.500000
[Epoch 0004] loss=46.0176 cls=0.9211 smmd=3.1093 ct=6.8797 rec=1.4084 | train/val/test=0.669/0.674/0.674 | c=0.500000
[Epoch 0005] loss=35.6435 cls=0.8225 smmd=2.0932 ct=6.8021 rec=1.3917 | train/val/test=0.676/0.676/0.682 | c=0.500000
[Epoch 0006] loss=28.3671 cls=0.7514 smmd=1.3774 ct=6.7672 rec=1.3666 | train/val/test=0.679/0.679/0.683 | c=0.500000
[Epoch 0007] loss=32.2797 cls=0.7126 smmd=1.7712 ct=6.7690 rec=1.3462 | train/val/test=0.688/0.687/0.693 | c=0.500000
[Epoch 0008] loss=34.6458 cls=0.6825 smmd=2.0088 ct=6.7753 rec=1.3326 | train/val/test=0.706/0.704/0.710 | c=0.500000
[Epoch 0009] loss=32.7505 cls=0.6505 smmd=1.8228 ct=6.7676 rec=1.3249 | train/val/test=0.734/0.731/0.736 | c=0.500000
[Epoch 0010] loss=29.7912 cls=0.6183 smmd=1.3892 ct=7.4642 rec=1.3232 | train/val/test=0.755/0.753/0.755 | c=0.500000
[Epoch 0011] loss=25.7136 cls=0.5937 smmd=1.0204 ct=7.2753 rec=1.3244 | train/val/test=0.780/0.777/0.778 | c=0.500000
[Epoch 0012] loss=26.5220 cls=0.5763 smmd=1.0983 ct=7.2937 rec=1.3280 | train/val/test=0.794/0.791/0.788 | c=0.500000
[Epoch 0013] loss=29.1086 cls=0.5624 smmd=1.3475 ct=7.3425 rec=1.3350 | train/val/test=0.795/0.794/0.785 | c=0.500000
[Epoch 0014] loss=26.4093 cls=0.5515 smmd=1.0859 ct=7.3036 rec=1.3354 | train/val/test=0.800/0.801/0.794 | c=0.500000
[Epoch 0015] loss=23.2788 cls=0.5316 smmd=0.7694 ct=7.3277 rec=1.3277 | train/val/test=0.798/0.797/0.788 | c=0.500000
[Epoch 0016] loss=24.0387 cls=0.5177 smmd=0.8477 ct=7.3208 rec=1.3225 | train/val/test=0.802/0.800/0.797 | c=0.500000
[Epoch 0017] loss=24.3649 cls=0.4973 smmd=0.8832 ct=7.3136 rec=1.3142 | train/val/test=0.810/0.808/0.807 | c=0.500000
[Epoch 0018] loss=22.8416 cls=0.4792 smmd=0.7317 ct=7.3162 rec=1.3055 | train/val/test=0.817/0.819/0.822 | c=0.500000
[Epoch 0019] loss=21.1321 cls=0.4623 smmd=0.5611 ct=7.3209 rec=1.2967 | train/val/test=0.824/0.825/0.831 | c=0.500000
[Epoch 0020] loss=20.9383 cls=0.4467 smmd=0.5434 ct=7.3179 rec=1.2903 | train/val/test=0.828/0.830/0.835 | c=0.500000
[Epoch 0021] loss=21.5329 cls=0.4339 smmd=0.6053 ct=7.3096 rec=1.2878 | train/val/test=0.829/0.830/0.837 | c=0.500000
[Epoch 0022] loss=21.2047 cls=0.4318 smmd=0.5731 ct=7.3069 rec=1.2881 | train/val/test=0.829/0.829/0.835 | c=0.500000
[Epoch 0023] loss=20.3188 cls=0.4356 smmd=0.4845 ct=7.3055 rec=1.2903 | train/val/test=0.827/0.833/0.830 | c=0.500000
[Epoch 0024] loss=20.3174 cls=0.4409 smmd=0.4844 ct=7.3023 rec=1.2963 | train/val/test=0.827/0.831/0.829 | c=0.500000
[Epoch 0025] loss=20.8624 cls=0.4453 smmd=0.5408 ct=7.2905 rec=1.3025 | train/val/test=0.829/0.831/0.830 | c=0.500000
[Epoch 0026] loss=20.6001 cls=0.4457 smmd=0.5175 ct=7.2743 rec=1.3081 | train/val/test=0.833/0.832/0.840 | c=0.500000
[Epoch 0027] loss=19.8273 cls=0.4420 smmd=0.4402 ct=7.2745 rec=1.3096 | train/val/test=0.836/0.833/0.837 | c=0.500000
[Epoch 0028] loss=19.5336 cls=0.4424 smmd=0.4098 ct=7.2787 rec=1.3137 | train/val/test=0.828/0.827/0.837 | c=0.500000
[Epoch 0029] loss=19.4294 cls=0.4489 smmd=0.4006 ct=7.2718 rec=1.3107 | train/val/test=0.812/0.815/0.812 | c=0.500000
[Epoch 0030] loss=19.1167 cls=0.4700 smmd=0.3755 ct=7.2327 rec=1.3232 | train/val/test=0.779/0.779/0.787 | c=0.500000
[Epoch 0031] loss=18.8895 cls=0.5377 smmd=0.3398 ct=7.2796 rec=1.3261 | train/val/test=0.736/0.740/0.733 | c=0.500000
[Epoch 0032] loss=18.9606 cls=0.5976 smmd=0.3461 ct=7.2628 rec=1.3512 | train/val/test=0.771/0.769/0.772 | c=0.500000
[Epoch 0033] loss=19.0369 cls=0.5883 smmd=0.3480 ct=7.2991 rec=1.3290 | train/val/test=0.829/0.828/0.830 | c=0.500000
[Epoch 0034] loss=18.6325 cls=0.4467 smmd=0.3258 ct=7.2506 rec=1.3002 | train/val/test=0.834/0.836/0.835 | c=0.500000
[Epoch 0035] loss=18.4319 cls=0.4201 smmd=0.3085 ct=7.2452 rec=1.2924 | train/val/test=0.813/0.813/0.814 | c=0.500000
[Epoch 0036] loss=18.6698 cls=0.4743 smmd=0.3248 ct=7.2674 rec=1.2995 | train/val/test=0.806/0.811/0.805 | c=0.500000
[Epoch 0037] loss=18.8652 cls=0.4804 smmd=0.3449 ct=7.2583 rec=1.3181 | train/val/test=0.816/0.815/0.813 | c=0.500000
[Epoch 0038] loss=18.6979 cls=0.4779 smmd=0.3278 ct=7.2625 rec=1.3114 | train/val/test=0.830/0.824/0.838 | c=0.500000
[Epoch 0039] loss=18.4098 cls=0.4391 smmd=0.3081 ct=7.2279 rec=1.3068 | train/val/test=0.835/0.834/0.838 | c=0.500000
[Epoch 0040] loss=18.2478 cls=0.4249 smmd=0.2927 ct=7.2283 rec=1.3045 | train/val/test=0.836/0.835/0.838 | c=0.500000
[Epoch 0041] loss=18.0459 cls=0.4325 smmd=0.2716 ct=7.2314 rec=1.3023 | train/val/test=0.834/0.829/0.840 | c=0.500000
[Epoch 0042] loss=17.9559 cls=0.4333 smmd=0.2662 ct=7.2117 rec=1.3079 | train/val/test=0.831/0.822/0.830 | c=0.500000
[Epoch 0043] loss=17.8648 cls=0.4533 smmd=0.2521 ct=7.2317 rec=1.3065 | train/val/test=0.834/0.831/0.835 | c=0.500000
[Epoch 0044] loss=17.8246 cls=0.4386 smmd=0.2539 ct=7.2065 rec=1.3070 | train/val/test=0.832/0.831/0.833 | c=0.500000
[Epoch 0045] loss=17.7882 cls=0.4383 smmd=0.2515 ct=7.2007 rec=1.3053 | train/val/test=0.836/0.833/0.834 | c=0.500000
[Epoch 0046] loss=17.7891 cls=0.4377 smmd=0.2502 ct=7.2079 rec=1.3058 | train/val/test=0.832/0.833/0.830 | c=0.500000
[Epoch 0047] loss=17.8419 cls=0.4441 smmd=0.2569 ct=7.1973 rec=1.3131 | train/val/test=0.835/0.833/0.836 | c=0.500000
[Epoch 0048] loss=17.9377 cls=0.4600 smmd=0.2614 ct=7.2183 rec=1.3147 | train/val/test=0.817/0.820/0.816 | c=0.500000
[Epoch 0049] loss=18.0847 cls=0.4853 smmd=0.2741 ct=7.2178 rec=1.3303 | train/val/test=0.777/0.775/0.780 | c=0.500000
[Epoch 0050] loss=18.3454 cls=0.5719 smmd=0.2799 ct=7.2984 rec=1.3269 | train/val/test=0.782/0.783/0.781 | c=0.500000
[Epoch 0051] loss=18.6268 cls=0.5769 smmd=0.3060 ct=7.3031 rec=1.3437 | train/val/test=0.812/0.811/0.810 | c=0.500000
[Epoch 0052] loss=18.0172 cls=0.5393 smmd=0.2603 ct=7.2434 rec=1.3162 | train/val/test=0.827/0.826/0.821 | c=0.500000
[Epoch 0053] loss=17.5620 cls=0.4422 smmd=0.2252 ct=7.2180 rec=1.3062 | train/val/test=0.831/0.836/0.827 | c=0.500000
[Epoch 0054] loss=17.6095 cls=0.4320 smmd=0.2305 ct=7.2186 rec=1.3020 | train/val/test=0.828/0.822/0.828 | c=0.500000
[Epoch 0055] loss=17.7990 cls=0.4633 smmd=0.2434 ct=7.2422 rec=1.2969 | train/val/test=0.831/0.833/0.827 | c=0.500000
[Epoch 0056] loss=17.7137 cls=0.4369 smmd=0.2378 ct=7.2325 rec=1.3048 | train/val/test=0.836/0.837/0.838 | c=0.500000
[Epoch 0057] loss=17.6352 cls=0.4268 smmd=0.2383 ct=7.1944 rec=1.3005 | train/val/test=0.835/0.836/0.835 | c=0.500000
[Epoch 0058] loss=17.8602 cls=0.4361 smmd=0.2514 ct=7.2380 rec=1.3054 | train/val/test=0.830/0.827/0.825 | c=0.500000
[Epoch 0059] loss=18.1147 cls=0.4534 smmd=0.2765 ct=7.2322 rec=1.3181 | train/val/test=0.832/0.831/0.830 | c=0.500000
[Epoch 0060] loss=17.9403 cls=0.4522 smmd=0.2558 ct=7.2499 rec=1.3132 | train/val/test=0.828/0.829/0.827 | c=0.500000
[Epoch 0061] loss=17.6904 cls=0.4517 smmd=0.2401 ct=7.2029 rec=1.3160 | train/val/test=0.797/0.799/0.795 | c=0.500000
[Epoch 0062] loss=17.6911 cls=0.5178 smmd=0.2332 ct=7.2174 rec=1.3303 | train/val/test=0.740/0.746/0.748 | c=0.500000
[Epoch 0063] loss=18.0517 cls=0.5935 smmd=0.2524 ct=7.2792 rec=1.3443 | train/val/test=0.723/0.727/0.720 | c=0.500000
[Epoch 0064] loss=18.2285 cls=0.7191 smmd=0.2649 ct=7.2688 rec=1.3654 | train/val/test=0.728/0.735/0.727 | c=0.500000
[Epoch 0065] loss=18.0375 cls=0.6275 smmd=0.2483 ct=7.2814 rec=1.3551 | train/val/test=0.803/0.799/0.802 | c=0.500000
[Epoch 0066] loss=17.6999 cls=0.5263 smmd=0.2319 ct=7.2342 rec=1.2993 | train/val/test=0.819/0.821/0.817 | c=0.500000
[Epoch 0067] loss=17.6160 cls=0.4553 smmd=0.2276 ct=7.2324 rec=1.2944 | train/val/test=0.809/0.812/0.807 | c=0.500000
[Epoch 0068] loss=17.7843 cls=0.4868 smmd=0.2375 ct=7.2559 rec=1.3079 | train/val/test=0.796/0.792/0.797 | c=0.500000
[Epoch 0069] loss=17.9880 cls=0.5434 smmd=0.2575 ct=7.2413 rec=1.3168 | train/val/test=0.793/0.795/0.794 | c=0.500000
[Epoch 0070] loss=18.0463 cls=0.5068 smmd=0.2621 ct=7.2540 rec=1.3282 | train/val/test=0.823/0.817/0.822 | c=0.500000
[Epoch 0071] loss=17.8429 cls=0.4858 smmd=0.2473 ct=7.2368 rec=1.3074 | train/val/test=0.833/0.837/0.833 | c=0.500000
[Epoch 0072] loss=17.6357 cls=0.4368 smmd=0.2327 ct=7.2188 rec=1.3059 | train/val/test=0.827/0.825/0.828 | c=0.500000
[Epoch 0073] loss=17.6294 cls=0.4540 smmd=0.2307 ct=7.2201 rec=1.3112 | train/val/test=0.820/0.811/0.819 | c=0.500000
[Epoch 0074] loss=17.6897 cls=0.4885 smmd=0.2298 ct=7.2459 rec=1.3108 | train/val/test=0.830/0.832/0.830 | c=0.500000
[Epoch 0075] loss=17.5546 cls=0.4498 smmd=0.2257 ct=7.2079 rec=1.3138 | train/val/test=0.831/0.829/0.832 | c=0.500000
[Epoch 0076] loss=17.3852 cls=0.4548 smmd=0.2103 ct=7.2008 rec=1.3072 | train/val/test=0.822/0.820/0.820 | c=0.500000
[Epoch 0077] loss=17.4726 cls=0.4672 smmd=0.2174 ct=7.2045 rec=1.3128 | train/val/test=0.815/0.816/0.813 | c=0.500000
[Epoch 0078] loss=17.6520 cls=0.4809 smmd=0.2329 ct=7.2103 rec=1.3234 | train/val/test=0.813/0.810/0.814 | c=0.500000
[Epoch 0079] loss=17.6995 cls=0.4937 smmd=0.2357 ct=7.2177 rec=1.3196 | train/val/test=0.823/0.825/0.822 | c=0.500000
[Epoch 0080] loss=17.6153 cls=0.4728 smmd=0.2323 ct=7.1977 rec=1.3203 | train/val/test=0.822/0.822/0.819 | c=0.500000
[Epoch 0081] loss=17.5878 cls=0.4717 smmd=0.2258 ct=7.2178 rec=1.3173 | train/val/test=0.830/0.827/0.828 | c=0.500000
[Epoch 0082] loss=17.7186 cls=0.4672 smmd=0.2386 ct=7.2207 rec=1.3145 | train/val/test=0.818/0.820/0.817 | c=0.500000
[Epoch 0083] loss=17.9076 cls=0.4750 smmd=0.2457 ct=7.2763 rec=1.3209 | train/val/test=0.828/0.823/0.825 | c=0.500000
[Epoch 0084] loss=17.8764 cls=0.4782 smmd=0.2438 ct=7.2713 rec=1.3140 | train/val/test=0.811/0.813/0.810 | c=0.500000
[Epoch 0085] loss=17.6466 cls=0.4837 smmd=0.2281 ct=7.2315 rec=1.3205 | train/val/test=0.815/0.821/0.816 | c=0.500000
[Epoch 0086] loss=17.5726 cls=0.4768 smmd=0.2201 ct=7.2378 rec=1.3161 | train/val/test=0.803/0.804/0.803 | c=0.500000
[Epoch 0087] loss=17.6748 cls=0.5051 smmd=0.2313 ct=7.2243 rec=1.3205 | train/val/test=0.814/0.816/0.815 | c=0.500000
[Epoch 0088] loss=17.7662 cls=0.4759 smmd=0.2356 ct=7.2570 rec=1.3161 | train/val/test=0.812/0.811/0.808 | c=0.500000
[Epoch 0089] loss=17.7831 cls=0.4828 smmd=0.2427 ct=7.2291 rec=1.3134 | train/val/test=0.824/0.827/0.822 | c=0.500000
[Epoch 0090] loss=17.8135 cls=0.4607 smmd=0.2406 ct=7.2622 rec=1.3060 | train/val/test=0.819/0.816/0.815 | c=0.500000
[Epoch 0091] loss=17.8386 cls=0.4658 smmd=0.2471 ct=7.2398 rec=1.3104 | train/val/test=0.827/0.823/0.829 | c=0.500000
[Epoch 0092] loss=17.8502 cls=0.4658 smmd=0.2439 ct=7.2635 rec=1.3024 | train/val/test=0.822/0.823/0.821 | c=0.500000
[Epoch 0093] loss=17.7243 cls=0.4520 smmd=0.2371 ct=7.2366 rec=1.3079 | train/val/test=0.830/0.828/0.832 | c=0.500000
[Epoch 0094] loss=17.5249 cls=0.4449 smmd=0.2204 ct=7.2238 rec=1.3007 | train/val/test=0.829/0.828/0.830 | c=0.500000
[Epoch 0095] loss=17.4473 cls=0.4401 smmd=0.2149 ct=7.2134 rec=1.3028 | train/val/test=0.830/0.829/0.831 | c=0.500000
[Epoch 0096] loss=17.5006 cls=0.4405 smmd=0.2203 ct=7.2123 rec=1.3064 | train/val/test=0.826/0.825/0.826 | c=0.500000
[Epoch 0097] loss=17.6241 cls=0.4604 smmd=0.2291 ct=7.2252 rec=1.3055 | train/val/test=0.821/0.826/0.822 | c=0.500000
[Epoch 0098] loss=17.7305 cls=0.4607 smmd=0.2365 ct=7.2387 rec=1.3145 | train/val/test=0.818/0.818/0.817 | c=0.500000
[Epoch 0099] loss=17.7956 cls=0.4766 smmd=0.2441 ct=7.2302 rec=1.3115 | train/val/test=0.799/0.803/0.795 | c=0.500000
=== Best @ epoch 56: val=0.8369, test=0.8377 ===
