Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=80.8618 cls=1.1042 smmd=6.5069 ct=7.2667 rec=1.4140 | train/val/test=0.394/0.393/0.389 | c=0.100000
[Epoch 0001] loss=71.4690 cls=1.0590 smmd=5.5707 ct=7.2612 rec=1.4209 | train/val/test=0.404/0.394/0.392 | c=0.100000
[Epoch 0002] loss=40.2465 cls=1.0528 smmd=2.4704 ct=7.1544 rec=1.4141 | train/val/test=0.393/0.401/0.415 | c=0.100000
[Epoch 0003] loss=46.0128 cls=1.0773 smmd=3.0571 ct=7.0980 rec=1.4136 | train/val/test=0.650/0.635/0.638 | c=0.100000
[Epoch 0004] loss=45.6857 cls=0.8905 smmd=3.0750 ct=6.8942 rec=1.4049 | train/val/test=0.692/0.685/0.692 | c=0.100000
[Epoch 0005] loss=35.5418 cls=0.7903 smmd=2.0835 ct=6.8105 rec=1.3816 | train/val/test=0.683/0.681/0.686 | c=0.100000
[Epoch 0006] loss=27.7964 cls=0.7206 smmd=1.3189 ct=6.7852 rec=1.3536 | train/val/test=0.686/0.683/0.689 | c=0.100000
[Epoch 0007] loss=32.3768 cls=0.6857 smmd=1.7767 ct=6.7982 rec=1.3410 | train/val/test=0.707/0.700/0.709 | c=0.100000
[Epoch 0008] loss=34.9037 cls=0.6468 smmd=2.0326 ct=6.7961 rec=1.3251 | train/val/test=0.735/0.734/0.740 | c=0.100000
[Epoch 0009] loss=32.2502 cls=0.6172 smmd=1.7721 ct=6.7814 rec=1.3158 | train/val/test=0.765/0.767/0.761 | c=0.100000
[Epoch 0010] loss=27.4859 cls=0.5795 smmd=1.3019 ct=6.7595 rec=1.3161 | train/val/test=0.791/0.791/0.780 | c=0.100000
[Epoch 0011] loss=24.6904 cls=0.5456 smmd=1.0251 ct=6.7534 rec=1.3205 | train/val/test=0.801/0.803/0.785 | c=0.100000
[Epoch 0012] loss=25.1679 cls=0.5311 smmd=1.0729 ct=6.7549 rec=1.3269 | train/val/test=0.812/0.813/0.796 | c=0.100000
[Epoch 0013] loss=27.1434 cls=0.5181 smmd=1.2712 ct=6.7539 rec=1.3287 | train/val/test=0.811/0.811/0.800 | c=0.100000
[Epoch 0014] loss=24.8878 cls=0.5060 smmd=1.0510 ct=6.7320 rec=1.3224 | train/val/test=0.809/0.810/0.796 | c=0.100000
[Epoch 0015] loss=21.6245 cls=0.4915 smmd=0.7273 ct=6.7236 rec=1.3168 | train/val/test=0.808/0.813/0.799 | c=0.100000
[Epoch 0016] loss=22.5891 cls=0.4782 smmd=0.8247 ct=6.7243 rec=1.3089 | train/val/test=0.817/0.820/0.809 | c=0.100000
[Epoch 0017] loss=22.7122 cls=0.4583 smmd=0.8397 ct=6.7181 rec=1.2999 | train/val/test=0.826/0.829/0.821 | c=0.100000
[Epoch 0018] loss=21.2007 cls=0.4428 smmd=0.6911 ct=6.7119 rec=1.2897 | train/val/test=0.825/0.823/0.815 | c=0.100000
[Epoch 0019] loss=19.7741 cls=0.4460 smmd=0.5497 ct=6.7064 rec=1.2821 | train/val/test=0.826/0.822/0.817 | c=0.100000
[Epoch 0020] loss=21.0527 cls=0.4452 smmd=0.5363 ct=7.4141 rec=1.2784 | train/val/test=0.833/0.830/0.827 | c=0.100000
[Epoch 0021] loss=21.4223 cls=0.4214 smmd=0.5956 ct=7.3075 rec=1.2815 | train/val/test=0.834/0.830/0.823 | c=0.100000
[Epoch 0022] loss=21.1848 cls=0.4220 smmd=0.5718 ct=7.3065 rec=1.2847 | train/val/test=0.834/0.829/0.826 | c=0.100000
[Epoch 0023] loss=20.5429 cls=0.4235 smmd=0.4993 ct=7.3474 rec=1.2874 | train/val/test=0.835/0.831/0.824 | c=0.100000
[Epoch 0024] loss=20.4645 cls=0.4252 smmd=0.4953 ct=7.3267 rec=1.2915 | train/val/test=0.836/0.835/0.826 | c=0.100000
[Epoch 0025] loss=20.9547 cls=0.4263 smmd=0.5454 ct=7.3197 rec=1.2964 | train/val/test=0.838/0.840/0.827 | c=0.100000
[Epoch 0026] loss=20.6220 cls=0.4276 smmd=0.5145 ct=7.3064 rec=1.3018 | train/val/test=0.839/0.837/0.828 | c=0.100000
[Epoch 0027] loss=19.8563 cls=0.4202 smmd=0.4388 ct=7.3041 rec=1.2993 | train/val/test=0.842/0.839/0.827 | c=0.100000
[Epoch 0028] loss=19.5614 cls=0.4176 smmd=0.4088 ct=7.3066 rec=1.3024 | train/val/test=0.843/0.846/0.835 | c=0.100000
[Epoch 0029] loss=19.3309 cls=0.4098 smmd=0.3864 ct=7.3065 rec=1.2985 | train/val/test=0.841/0.847/0.833 | c=0.100000
[Epoch 0030] loss=18.9881 cls=0.4069 smmd=0.3530 ct=7.3025 rec=1.2985 | train/val/test=0.842/0.847/0.834 | c=0.100000
[Epoch 0031] loss=18.6507 cls=0.4055 smmd=0.3221 ct=7.2892 rec=1.2971 | train/val/test=0.841/0.844/0.834 | c=0.100000
[Epoch 0032] loss=18.5563 cls=0.4042 smmd=0.3134 ct=7.2856 rec=1.2971 | train/val/test=0.843/0.839/0.829 | c=0.100000
[Epoch 0033] loss=18.6031 cls=0.4056 smmd=0.3178 ct=7.2862 rec=1.2993 | train/val/test=0.843/0.843/0.834 | c=0.100000
[Epoch 0034] loss=18.5904 cls=0.4045 smmd=0.3196 ct=7.2710 rec=1.2999 | train/val/test=0.842/0.836/0.828 | c=0.100000
[Epoch 0035] loss=18.6054 cls=0.4090 smmd=0.3212 ct=7.2694 rec=1.3006 | train/val/test=0.842/0.842/0.834 | c=0.100000
[Epoch 0036] loss=18.6723 cls=0.4126 smmd=0.3258 ct=7.2779 rec=1.3042 | train/val/test=0.831/0.829/0.812 | c=0.100000
[Epoch 0037] loss=18.7014 cls=0.4351 smmd=0.3266 ct=7.2823 rec=1.3068 | train/val/test=0.812/0.820/0.801 | c=0.100000
[Epoch 0038] loss=18.7540 cls=0.4793 smmd=0.3294 ct=7.2789 rec=1.3253 | train/val/test=0.723/0.722/0.720 | c=0.100000
[Epoch 0039] loss=19.0870 cls=0.6814 smmd=0.3400 ct=7.3325 rec=1.3617 | train/val/test=0.621/0.624/0.615 | c=0.100000
[Epoch 0040] loss=19.4920 cls=0.8327 smmd=0.3689 ct=7.3470 rec=1.3842 | train/val/test=0.767/0.767/0.758 | c=0.100000
[Epoch 0041] loss=18.7138 cls=0.6072 smmd=0.3116 ct=7.3157 rec=1.3266 | train/val/test=0.836/0.829/0.828 | c=0.100000
[Epoch 0042] loss=17.8897 cls=0.4105 smmd=0.2508 ct=7.2677 rec=1.2822 | train/val/test=0.786/0.794/0.779 | c=0.100000
[Epoch 0043] loss=18.2822 cls=0.5253 smmd=0.2771 ct=7.2958 rec=1.3144 | train/val/test=0.807/0.804/0.801 | c=0.100000
[Epoch 0044] loss=18.2074 cls=0.4892 smmd=0.2746 ct=7.2848 rec=1.2947 | train/val/test=0.835/0.832/0.826 | c=0.100000
[Epoch 0045] loss=17.9609 cls=0.4099 smmd=0.2586 ct=7.2631 rec=1.2872 | train/val/test=0.813/0.810/0.807 | c=0.100000
[Epoch 0046] loss=18.3212 cls=0.4818 smmd=0.2877 ct=7.2743 rec=1.3087 | train/val/test=0.818/0.816/0.802 | c=0.100000
[Epoch 0047] loss=18.4227 cls=0.4656 smmd=0.2986 ct=7.2734 rec=1.3145 | train/val/test=0.839/0.839/0.834 | c=0.100000
[Epoch 0048] loss=18.2302 cls=0.4324 smmd=0.2872 ct=7.2439 rec=1.3078 | train/val/test=0.832/0.829/0.824 | c=0.100000
[Epoch 0049] loss=18.1882 cls=0.4538 smmd=0.2825 ct=7.2386 rec=1.3181 | train/val/test=0.814/0.812/0.808 | c=0.100000
[Epoch 0050] loss=18.1631 cls=0.4756 smmd=0.2745 ct=7.2586 rec=1.3257 | train/val/test=0.825/0.823/0.820 | c=0.100000
[Epoch 0051] loss=17.9233 cls=0.4677 smmd=0.2562 ct=7.2326 rec=1.3241 | train/val/test=0.836/0.837/0.828 | c=0.100000
[Epoch 0052] loss=17.6856 cls=0.4443 smmd=0.2361 ct=7.2224 rec=1.3156 | train/val/test=0.834/0.833/0.823 | c=0.100000
[Epoch 0053] loss=17.6424 cls=0.4453 smmd=0.2302 ct=7.2295 rec=1.3176 | train/val/test=0.833/0.828/0.825 | c=0.100000
[Epoch 0054] loss=17.6454 cls=0.4563 smmd=0.2315 ct=7.2220 rec=1.3167 | train/val/test=0.834/0.832/0.823 | c=0.100000
[Epoch 0055] loss=17.5976 cls=0.4414 smmd=0.2280 ct=7.2200 rec=1.3144 | train/val/test=0.836/0.832/0.827 | c=0.100000
[Epoch 0056] loss=17.6543 cls=0.4457 smmd=0.2333 ct=7.2215 rec=1.3119 | train/val/test=0.831/0.831/0.823 | c=0.100000
[Epoch 0057] loss=17.7729 cls=0.4545 smmd=0.2452 ct=7.2167 rec=1.3215 | train/val/test=0.826/0.824/0.812 | c=0.100000
[Epoch 0058] loss=17.8825 cls=0.4711 smmd=0.2539 ct=7.2244 rec=1.3183 | train/val/test=0.821/0.821/0.811 | c=0.100000
[Epoch 0059] loss=17.9332 cls=0.4755 smmd=0.2568 ct=7.2301 rec=1.3342 | train/val/test=0.776/0.773/0.769 | c=0.100000
[Epoch 0060] loss=18.0555 cls=0.5479 smmd=0.2639 ct=7.2420 rec=1.3167 | train/val/test=0.762/0.756/0.746 | c=0.100000
[Epoch 0061] loss=18.4555 cls=0.5940 smmd=0.2863 ct=7.3094 rec=1.3538 | train/val/test=0.728/0.730/0.726 | c=0.100000
[Epoch 0062] loss=18.4456 cls=0.6937 smmd=0.2818 ct=7.3104 rec=1.3202 | train/val/test=0.811/0.806/0.795 | c=0.100000
[Epoch 0063] loss=18.0564 cls=0.5030 smmd=0.2593 ct=7.2751 rec=1.3237 | train/val/test=0.836/0.833/0.828 | c=0.100000
[Epoch 0064] loss=17.3967 cls=0.4252 smmd=0.2084 ct=7.2275 rec=1.2904 | train/val/test=0.810/0.804/0.802 | c=0.100000
[Epoch 0065] loss=17.7016 cls=0.5090 smmd=0.2297 ct=7.2521 rec=1.2921 | train/val/test=0.821/0.823/0.810 | c=0.100000
[Epoch 0066] loss=18.0075 cls=0.4649 smmd=0.2569 ct=7.2757 rec=1.3101 | train/val/test=0.836/0.835/0.831 | c=0.100000
[Epoch 0067] loss=17.6465 cls=0.4255 smmd=0.2320 ct=7.2343 rec=1.2896 | train/val/test=0.824/0.825/0.814 | c=0.100000
[Epoch 0068] loss=17.8394 cls=0.4610 smmd=0.2483 ct=7.2379 rec=1.3004 | train/val/test=0.818/0.814/0.809 | c=0.100000
[Epoch 0069] loss=18.2171 cls=0.4706 smmd=0.2775 ct=7.2724 rec=1.3237 | train/val/test=0.816/0.817/0.805 | c=0.100000
[Epoch 0070] loss=18.0001 cls=0.4823 smmd=0.2617 ct=7.2430 rec=1.3114 | train/val/test=0.837/0.838/0.828 | c=0.100000
[Epoch 0071] loss=17.7424 cls=0.4281 smmd=0.2424 ct=7.2251 rec=1.3084 | train/val/test=0.810/0.811/0.792 | c=0.100000
[Epoch 0072] loss=17.7675 cls=0.4815 smmd=0.2391 ct=7.2375 rec=1.3207 | train/val/test=0.836/0.832/0.824 | c=0.100000
[Epoch 0073] loss=17.7472 cls=0.4486 smmd=0.2358 ct=7.2563 rec=1.3055 | train/val/test=0.813/0.813/0.797 | c=0.100000
[Epoch 0074] loss=17.5200 cls=0.4743 smmd=0.2196 ct=7.2143 rec=1.3163 | train/val/test=0.833/0.835/0.825 | c=0.100000
[Epoch 0075] loss=17.4422 cls=0.4283 smmd=0.2123 ct=7.2250 rec=1.3096 | train/val/test=0.828/0.827/0.814 | c=0.100000
[Epoch 0076] loss=17.5606 cls=0.4511 smmd=0.2224 ct=7.2287 rec=1.3069 | train/val/test=0.830/0.831/0.820 | c=0.100000
[Epoch 0077] loss=17.5783 cls=0.4353 smmd=0.2275 ct=7.2145 rec=1.3142 | train/val/test=0.837/0.838/0.826 | c=0.100000
[Epoch 0078] loss=17.5491 cls=0.4296 smmd=0.2266 ct=7.2074 rec=1.3079 | train/val/test=0.839/0.841/0.832 | c=0.100000
[Epoch 0079] loss=17.5967 cls=0.4265 smmd=0.2319 ct=7.2048 rec=1.3099 | train/val/test=0.835/0.837/0.824 | c=0.100000
[Epoch 0080] loss=17.6772 cls=0.4325 smmd=0.2366 ct=7.2185 rec=1.3151 | train/val/test=0.842/0.839/0.834 | c=0.100000
[Epoch 0081] loss=17.6953 cls=0.4381 smmd=0.2387 ct=7.2171 rec=1.3108 | train/val/test=0.824/0.821/0.807 | c=0.100000
[Epoch 0082] loss=17.6802 cls=0.4562 smmd=0.2329 ct=7.2313 rec=1.3200 | train/val/test=0.785/0.796/0.779 | c=0.100000
[Epoch 0083] loss=17.7210 cls=0.5122 smmd=0.2315 ct=7.2418 rec=1.3323 | train/val/test=0.755/0.757/0.753 | c=0.100000
[Epoch 0084] loss=17.9515 cls=0.6193 smmd=0.2467 ct=7.2513 rec=1.3452 | train/val/test=0.667/0.672/0.666 | c=0.100000
[Epoch 0085] loss=18.1943 cls=0.7082 smmd=0.2553 ct=7.2977 rec=1.3829 | train/val/test=0.768/0.769/0.764 | c=0.100000
[Epoch 0086] loss=17.9887 cls=0.6190 smmd=0.2514 ct=7.2512 rec=1.3253 | train/val/test=0.827/0.828/0.818 | c=0.100000
[Epoch 0087] loss=17.4950 cls=0.4451 smmd=0.2124 ct=7.2484 rec=1.3043 | train/val/test=0.830/0.829/0.822 | c=0.100000
[Epoch 0088] loss=17.4841 cls=0.4358 smmd=0.2156 ct=7.2316 rec=1.2939 | train/val/test=0.801/0.801/0.795 | c=0.100000
[Epoch 0089] loss=17.8322 cls=0.5053 smmd=0.2453 ct=7.2365 rec=1.3065 | train/val/test=0.802/0.810/0.789 | c=0.100000
[Epoch 0090] loss=17.9222 cls=0.4978 smmd=0.2485 ct=7.2632 rec=1.3237 | train/val/test=0.823/0.820/0.810 | c=0.100000
[Epoch 0091] loss=17.7066 cls=0.4607 smmd=0.2390 ct=7.2156 rec=1.3101 | train/val/test=0.836/0.835/0.830 | c=0.100000
[Epoch 0092] loss=17.5941 cls=0.4338 smmd=0.2279 ct=7.2223 rec=1.3078 | train/val/test=0.835/0.833/0.829 | c=0.100000
[Epoch 0093] loss=17.6860 cls=0.4397 smmd=0.2368 ct=7.2203 rec=1.3147 | train/val/test=0.815/0.816/0.803 | c=0.100000
[Epoch 0094] loss=17.7016 cls=0.4743 smmd=0.2308 ct=7.2492 rec=1.3170 | train/val/test=0.831/0.830/0.823 | c=0.100000
[Epoch 0095] loss=17.5448 cls=0.4559 smmd=0.2252 ct=7.2029 rec=1.3186 | train/val/test=0.831/0.827/0.822 | c=0.100000
[Epoch 0096] loss=17.3944 cls=0.4476 smmd=0.2096 ct=7.2088 rec=1.3144 | train/val/test=0.832/0.829/0.823 | c=0.100000
[Epoch 0097] loss=17.4385 cls=0.4514 smmd=0.2146 ct=7.2059 rec=1.3098 | train/val/test=0.827/0.832/0.823 | c=0.100000
[Epoch 0098] loss=17.5669 cls=0.4488 smmd=0.2255 ct=7.2145 rec=1.3162 | train/val/test=0.827/0.823/0.815 | c=0.100000
[Epoch 0099] loss=17.5846 cls=0.4688 smmd=0.2287 ct=7.2039 rec=1.3113 | train/val/test=0.825/0.826/0.817 | c=0.100000
=== Best @ epoch 30: val=0.8471, test=0.8342 ===
