Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=80.9267 cls=1.1069 smmd=6.5129 ct=7.2689 rec=1.4136 | train/val/test=0.400/0.398/0.400 | c=0.100000
[Epoch 0001] loss=71.7715 cls=1.0551 smmd=5.6011 ct=7.2620 rec=1.4188 | train/val/test=0.494/0.498/0.503 | c=0.100000
[Epoch 0002] loss=41.0446 cls=1.0466 smmd=2.5454 ct=7.1800 rec=1.4140 | train/val/test=0.486/0.482/0.496 | c=0.100000
[Epoch 0003] loss=45.2339 cls=1.0300 smmd=2.9804 ct=7.1051 rec=1.4102 | train/val/test=0.637/0.635/0.649 | c=0.100000
[Epoch 0004] loss=44.9886 cls=0.8836 smmd=3.0061 ct=6.8923 rec=1.4031 | train/val/test=0.667/0.670/0.682 | c=0.100000
[Epoch 0005] loss=34.9130 cls=0.8027 smmd=2.0169 ct=6.8262 rec=1.3805 | train/val/test=0.667/0.671/0.683 | c=0.100000
[Epoch 0006] loss=27.5284 cls=0.7335 smmd=1.2877 ct=6.8036 rec=1.3547 | train/val/test=0.673/0.672/0.686 | c=0.100000
[Epoch 0007] loss=32.3355 cls=0.7004 smmd=1.7696 ct=6.8100 rec=1.3385 | train/val/test=0.688/0.688/0.701 | c=0.100000
[Epoch 0008] loss=34.6313 cls=0.6691 smmd=2.0043 ct=6.7953 rec=1.3266 | train/val/test=0.720/0.720/0.729 | c=0.100000
[Epoch 0009] loss=31.8826 cls=0.6325 smmd=1.7358 ct=6.7745 rec=1.3187 | train/val/test=0.755/0.753/0.761 | c=0.100000
[Epoch 0010] loss=27.1417 cls=0.5947 smmd=1.2650 ct=6.7672 rec=1.3206 | train/val/test=0.787/0.785/0.791 | c=0.100000
[Epoch 0011] loss=24.0062 cls=0.5650 smmd=0.9537 ct=6.7619 rec=1.3256 | train/val/test=0.803/0.803/0.804 | c=0.100000
[Epoch 0012] loss=25.3228 cls=0.5511 smmd=1.0872 ct=6.7558 rec=1.3263 | train/val/test=0.802/0.802/0.803 | c=0.100000
[Epoch 0013] loss=27.2923 cls=0.5438 smmd=1.2839 ct=6.7590 rec=1.3265 | train/val/test=0.792/0.794/0.794 | c=0.100000
[Epoch 0014] loss=23.9891 cls=0.5345 smmd=0.9575 ct=6.7426 rec=1.3229 | train/val/test=0.793/0.794/0.795 | c=0.100000
[Epoch 0015] loss=23.0241 cls=0.5183 smmd=0.7266 ct=7.4209 rec=1.3136 | train/val/test=0.796/0.798/0.799 | c=0.100000
[Epoch 0016] loss=24.1995 cls=0.5058 smmd=0.8731 ct=7.2810 rec=1.3072 | train/val/test=0.808/0.804/0.810 | c=0.100000
[Epoch 0017] loss=23.8909 cls=0.4811 smmd=0.8382 ct=7.3099 rec=1.2964 | train/val/test=0.817/0.810/0.819 | c=0.100000
[Epoch 0018] loss=22.4161 cls=0.4711 smmd=0.6807 ct=7.3647 rec=1.2884 | train/val/test=0.820/0.813/0.820 | c=0.100000
[Epoch 0019] loss=21.0748 cls=0.4700 smmd=0.5496 ct=7.3511 rec=1.2828 | train/val/test=0.826/0.816/0.828 | c=0.100000
[Epoch 0020] loss=20.9846 cls=0.4522 smmd=0.5446 ct=7.3362 rec=1.2810 | train/val/test=0.829/0.824/0.834 | c=0.100000
[Epoch 0021] loss=21.4358 cls=0.4382 smmd=0.5896 ct=7.3391 rec=1.2840 | train/val/test=0.830/0.828/0.838 | c=0.100000
[Epoch 0022] loss=21.0633 cls=0.4369 smmd=0.5528 ct=7.3363 rec=1.2887 | train/val/test=0.829/0.826/0.837 | c=0.100000
[Epoch 0023] loss=20.3668 cls=0.4385 smmd=0.4853 ct=7.3240 rec=1.2935 | train/val/test=0.830/0.830/0.837 | c=0.100000
[Epoch 0024] loss=20.5438 cls=0.4431 smmd=0.5028 ct=7.3229 rec=1.2976 | train/val/test=0.832/0.831/0.838 | c=0.100000
[Epoch 0025] loss=20.8048 cls=0.4435 smmd=0.5306 ct=7.3128 rec=1.3026 | train/val/test=0.831/0.831/0.835 | c=0.100000
[Epoch 0026] loss=20.4000 cls=0.4447 smmd=0.4930 ct=7.2967 rec=1.3077 | train/val/test=0.839/0.833/0.841 | c=0.100000
[Epoch 0027] loss=19.8059 cls=0.4356 smmd=0.4360 ct=7.2872 rec=1.3066 | train/val/test=0.838/0.833/0.842 | c=0.100000
[Epoch 0028] loss=19.3844 cls=0.4314 smmd=0.3937 ct=7.2890 rec=1.3070 | train/val/test=0.842/0.835/0.848 | c=0.100000
[Epoch 0029] loss=19.2360 cls=0.4306 smmd=0.3804 ct=7.2825 rec=1.3027 | train/val/test=0.833/0.829/0.834 | c=0.100000
[Epoch 0030] loss=18.9040 cls=0.4349 smmd=0.3457 ct=7.2880 rec=1.3062 | train/val/test=0.838/0.828/0.835 | c=0.100000
[Epoch 0031] loss=18.6735 cls=0.4331 smmd=0.3236 ct=7.2844 rec=1.3036 | train/val/test=0.817/0.822/0.823 | c=0.100000
[Epoch 0032] loss=18.5783 cls=0.4557 smmd=0.3140 ct=7.2778 rec=1.3098 | train/val/test=0.823/0.809/0.819 | c=0.100000
[Epoch 0033] loss=18.6993 cls=0.4599 smmd=0.3270 ct=7.2713 rec=1.3138 | train/val/test=0.794/0.795/0.801 | c=0.100000
[Epoch 0034] loss=18.8380 cls=0.5087 smmd=0.3378 ct=7.2727 rec=1.3216 | train/val/test=0.786/0.775/0.777 | c=0.100000
[Epoch 0035] loss=18.9670 cls=0.5271 smmd=0.3451 ct=7.2931 rec=1.3326 | train/val/test=0.745/0.745/0.758 | c=0.100000
[Epoch 0036] loss=19.1242 cls=0.6372 smmd=0.3503 ct=7.3138 rec=1.3494 | train/val/test=0.781/0.771/0.776 | c=0.100000
[Epoch 0037] loss=19.0946 cls=0.5455 smmd=0.3514 ct=7.3210 rec=1.3313 | train/val/test=0.809/0.810/0.816 | c=0.100000
[Epoch 0038] loss=18.5918 cls=0.4816 smmd=0.3151 ct=7.2735 rec=1.3067 | train/val/test=0.834/0.831/0.836 | c=0.100000
[Epoch 0039] loss=18.1568 cls=0.4148 smmd=0.2787 ct=7.2593 rec=1.2884 | train/val/test=0.833/0.822/0.834 | c=0.100000
[Epoch 0040] loss=18.1796 cls=0.4337 smmd=0.2757 ct=7.2780 rec=1.3005 | train/val/test=0.817/0.817/0.819 | c=0.100000
[Epoch 0041] loss=18.1497 cls=0.4618 smmd=0.2763 ct=7.2526 rec=1.3021 | train/val/test=0.837/0.824/0.829 | c=0.100000
[Epoch 0042] loss=17.9426 cls=0.4287 smmd=0.2599 ct=7.2396 rec=1.3009 | train/val/test=0.840/0.830/0.841 | c=0.100000
[Epoch 0043] loss=17.8725 cls=0.4228 smmd=0.2531 ct=7.2394 rec=1.3026 | train/val/test=0.827/0.824/0.832 | c=0.100000
[Epoch 0044] loss=17.9704 cls=0.4495 smmd=0.2613 ct=7.2376 rec=1.3148 | train/val/test=0.797/0.784/0.787 | c=0.100000
[Epoch 0045] loss=18.1063 cls=0.5047 smmd=0.2720 ct=7.2347 rec=1.3299 | train/val/test=0.784/0.787/0.787 | c=0.100000
[Epoch 0046] loss=18.1829 cls=0.5028 smmd=0.2730 ct=7.2670 rec=1.3347 | train/val/test=0.787/0.775/0.780 | c=0.100000
[Epoch 0047] loss=18.1471 cls=0.5191 smmd=0.2752 ct=7.2332 rec=1.3393 | train/val/test=0.817/0.815/0.819 | c=0.100000
[Epoch 0048] loss=17.9858 cls=0.4754 smmd=0.2621 ct=7.2326 rec=1.3247 | train/val/test=0.837/0.826/0.840 | c=0.100000
[Epoch 0049] loss=17.8010 cls=0.4465 smmd=0.2459 ct=7.2287 rec=1.3218 | train/val/test=0.832/0.824/0.832 | c=0.100000
[Epoch 0050] loss=17.7320 cls=0.4451 smmd=0.2404 ct=7.2258 rec=1.3079 | train/val/test=0.826/0.824/0.831 | c=0.100000
[Epoch 0051] loss=17.7656 cls=0.4542 smmd=0.2397 ct=7.2408 rec=1.3196 | train/val/test=0.817/0.809/0.817 | c=0.100000
[Epoch 0052] loss=17.8840 cls=0.5043 smmd=0.2503 ct=7.2365 rec=1.3115 | train/val/test=0.803/0.807/0.806 | c=0.100000
[Epoch 0053] loss=18.0386 cls=0.5121 smmd=0.2574 ct=7.2707 rec=1.3348 | train/val/test=0.772/0.770/0.771 | c=0.100000
[Epoch 0054] loss=18.1471 cls=0.5982 smmd=0.2680 ct=7.2543 rec=1.3185 | train/val/test=0.795/0.797/0.800 | c=0.100000
[Epoch 0055] loss=18.2055 cls=0.5363 smmd=0.2669 ct=7.2985 rec=1.3425 | train/val/test=0.802/0.800/0.799 | c=0.100000
[Epoch 0056] loss=17.8880 cls=0.5284 smmd=0.2506 ct=7.2321 rec=1.3074 | train/val/test=0.825/0.814/0.821 | c=0.100000
[Epoch 0057] loss=17.6932 cls=0.4587 smmd=0.2344 ct=7.2314 rec=1.3135 | train/val/test=0.816/0.818/0.823 | c=0.100000
[Epoch 0058] loss=17.7681 cls=0.4720 smmd=0.2375 ct=7.2497 rec=1.3155 | train/val/test=0.812/0.803/0.809 | c=0.100000
[Epoch 0059] loss=17.9099 cls=0.5014 smmd=0.2488 ct=7.2592 rec=1.3051 | train/val/test=0.819/0.821/0.828 | c=0.100000
[Epoch 0060] loss=17.7911 cls=0.4566 smmd=0.2426 ct=7.2410 rec=1.3103 | train/val/test=0.839/0.830/0.843 | c=0.100000
[Epoch 0061] loss=17.5982 cls=0.4177 smmd=0.2268 ct=7.2366 rec=1.2970 | train/val/test=0.837/0.832/0.840 | c=0.100000
[Epoch 0062] loss=17.5753 cls=0.4194 smmd=0.2279 ct=7.2187 rec=1.2992 | train/val/test=0.822/0.829/0.830 | c=0.100000
[Epoch 0063] loss=17.7068 cls=0.4493 smmd=0.2373 ct=7.2254 rec=1.3163 | train/val/test=0.834/0.821/0.830 | c=0.100000
[Epoch 0064] loss=17.7877 cls=0.4542 smmd=0.2427 ct=7.2393 rec=1.3106 | train/val/test=0.813/0.819/0.820 | c=0.100000
[Epoch 0065] loss=17.7440 cls=0.4851 smmd=0.2377 ct=7.2293 rec=1.3317 | train/val/test=0.809/0.796/0.804 | c=0.100000
[Epoch 0066] loss=17.6844 cls=0.4906 smmd=0.2328 ct=7.2229 rec=1.3312 | train/val/test=0.757/0.760/0.762 | c=0.100000
[Epoch 0067] loss=17.8698 cls=0.5768 smmd=0.2412 ct=7.2490 rec=1.3429 | train/val/test=0.646/0.654/0.652 | c=0.100000
[Epoch 0068] loss=18.2578 cls=0.7256 smmd=0.2607 ct=7.2938 rec=1.4000 | train/val/test=0.698/0.696/0.708 | c=0.100000
[Epoch 0069] loss=18.5818 cls=0.7797 smmd=0.2909 ct=7.3026 rec=1.3556 | train/val/test=0.770/0.765/0.767 | c=0.100000
[Epoch 0070] loss=17.9241 cls=0.5513 smmd=0.2416 ct=7.2803 rec=1.3435 | train/val/test=0.830/0.829/0.837 | c=0.100000
[Epoch 0071] loss=17.4431 cls=0.4279 smmd=0.2118 ct=7.2332 rec=1.2894 | train/val/test=0.806/0.808/0.815 | c=0.100000
[Epoch 0072] loss=17.6815 cls=0.4846 smmd=0.2310 ct=7.2413 rec=1.2934 | train/val/test=0.817/0.808/0.819 | c=0.100000
[Epoch 0073] loss=17.8854 cls=0.4695 smmd=0.2433 ct=7.2796 rec=1.3169 | train/val/test=0.822/0.821/0.830 | c=0.100000
[Epoch 0074] loss=17.7292 cls=0.4521 smmd=0.2397 ct=7.2275 rec=1.3013 | train/val/test=0.834/0.829/0.837 | c=0.100000
[Epoch 0075] loss=17.7329 cls=0.4351 smmd=0.2399 ct=7.2320 rec=1.3040 | train/val/test=0.837/0.829/0.840 | c=0.100000
[Epoch 0076] loss=17.9480 cls=0.4453 smmd=0.2563 ct=7.2513 rec=1.3194 | train/val/test=0.814/0.814/0.815 | c=0.100000
[Epoch 0077] loss=17.9391 cls=0.4823 smmd=0.2524 ct=7.2569 rec=1.3208 | train/val/test=0.836/0.824/0.832 | c=0.100000
[Epoch 0078] loss=17.6108 cls=0.4627 smmd=0.2289 ct=7.2148 rec=1.3209 | train/val/test=0.831/0.830/0.839 | c=0.100000
[Epoch 0079] loss=17.5092 cls=0.4558 smmd=0.2169 ct=7.2247 rec=1.3255 | train/val/test=0.803/0.801/0.806 | c=0.100000
[Epoch 0080] loss=17.5950 cls=0.4946 smmd=0.2243 ct=7.2236 rec=1.3139 | train/val/test=0.821/0.823/0.830 | c=0.100000
[Epoch 0081] loss=17.5722 cls=0.4649 smmd=0.2212 ct=7.2323 rec=1.3251 | train/val/test=0.824/0.816/0.826 | c=0.100000
[Epoch 0082] loss=17.5041 cls=0.4753 smmd=0.2205 ct=7.2030 rec=1.3116 | train/val/test=0.813/0.816/0.825 | c=0.100000
[Epoch 0083] loss=17.5804 cls=0.4755 smmd=0.2216 ct=7.2329 rec=1.3217 | train/val/test=0.827/0.818/0.832 | c=0.100000
[Epoch 0084] loss=17.7527 cls=0.4763 smmd=0.2407 ct=7.2250 rec=1.3156 | train/val/test=0.798/0.805/0.815 | c=0.100000
[Epoch 0085] loss=17.8687 cls=0.5000 smmd=0.2448 ct=7.2529 rec=1.3294 | train/val/test=0.810/0.805/0.808 | c=0.100000
[Epoch 0086] loss=17.9122 cls=0.5272 smmd=0.2504 ct=7.2426 rec=1.3194 | train/val/test=0.789/0.795/0.799 | c=0.100000
[Epoch 0087] loss=17.9937 cls=0.5327 smmd=0.2510 ct=7.2740 rec=1.3388 | train/val/test=0.771/0.768/0.772 | c=0.100000
[Epoch 0088] loss=17.9943 cls=0.5818 smmd=0.2520 ct=7.2623 rec=1.3176 | train/val/test=0.808/0.814/0.822 | c=0.100000
[Epoch 0089] loss=17.7967 cls=0.4847 smmd=0.2376 ct=7.2580 rec=1.3244 | train/val/test=0.823/0.814/0.824 | c=0.100000
[Epoch 0090] loss=17.5689 cls=0.4649 smmd=0.2206 ct=7.2382 rec=1.3093 | train/val/test=0.817/0.815/0.819 | c=0.100000
[Epoch 0091] loss=17.5924 cls=0.4681 smmd=0.2257 ct=7.2250 rec=1.3023 | train/val/test=0.792/0.790/0.794 | c=0.100000
[Epoch 0092] loss=17.8690 cls=0.5148 smmd=0.2391 ct=7.2764 rec=1.3355 | train/val/test=0.796/0.794/0.791 | c=0.100000
[Epoch 0093] loss=18.0337 cls=0.5365 smmd=0.2626 ct=7.2435 rec=1.3047 | train/val/test=0.776/0.777/0.776 | c=0.100000
[Epoch 0094] loss=17.9927 cls=0.5496 smmd=0.2458 ct=7.2941 rec=1.3431 | train/val/test=0.813/0.812/0.817 | c=0.100000
[Epoch 0095] loss=17.8086 cls=0.4887 smmd=0.2446 ct=7.2332 rec=1.3034 | train/val/test=0.808/0.802/0.810 | c=0.100000
[Epoch 0096] loss=17.7235 cls=0.4815 smmd=0.2326 ct=7.2506 rec=1.3112 | train/val/test=0.806/0.812/0.815 | c=0.100000
[Epoch 0097] loss=17.7525 cls=0.4847 smmd=0.2332 ct=7.2607 rec=1.3132 | train/val/test=0.824/0.817/0.828 | c=0.100000
[Epoch 0098] loss=17.6662 cls=0.4621 smmd=0.2309 ct=7.2376 rec=1.3012 | train/val/test=0.827/0.831/0.834 | c=0.100000
[Epoch 0099] loss=17.5104 cls=0.4356 smmd=0.2179 ct=7.2304 rec=1.3057 | train/val/test=0.838/0.832/0.839 | c=0.100000
=== Best @ epoch 28: val=0.8349, test=0.8484 ===
