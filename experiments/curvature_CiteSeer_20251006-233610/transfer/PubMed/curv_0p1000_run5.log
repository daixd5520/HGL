Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=81.3086 cls=1.0854 smmd=6.5526 ct=7.2665 rec=1.4137 | train/val/test=0.455/0.450/0.448 | c=0.100000
[Epoch 0001] loss=72.7759 cls=1.0546 smmd=5.7017 ct=7.2608 rec=1.4195 | train/val/test=0.555/0.550/0.556 | c=0.100000
[Epoch 0002] loss=41.7542 cls=1.0473 smmd=2.6190 ct=7.1668 rec=1.4138 | train/val/test=0.332/0.331/0.342 | c=0.100000
[Epoch 0003] loss=45.8857 cls=1.0523 smmd=3.0465 ct=7.0941 rec=1.4127 | train/val/test=0.688/0.681/0.683 | c=0.100000
[Epoch 0004] loss=45.4666 cls=0.8629 smmd=3.0580 ct=6.8775 rec=1.3997 | train/val/test=0.674/0.668/0.674 | c=0.100000
[Epoch 0005] loss=35.2988 cls=0.7581 smmd=2.0619 ct=6.8077 rec=1.3701 | train/val/test=0.677/0.669/0.677 | c=0.100000
[Epoch 0006] loss=28.2289 cls=0.6990 smmd=1.3635 ct=6.7871 rec=1.3395 | train/val/test=0.681/0.673/0.685 | c=0.100000
[Epoch 0007] loss=32.2707 cls=0.6779 smmd=1.7689 ct=6.7913 rec=1.3204 | train/val/test=0.695/0.685/0.695 | c=0.100000
[Epoch 0008] loss=34.5733 cls=0.6538 smmd=1.9999 ct=6.7963 rec=1.3102 | train/val/test=0.729/0.720/0.731 | c=0.100000
[Epoch 0009] loss=32.2621 cls=0.6071 smmd=1.7740 ct=6.7824 rec=1.3085 | train/val/test=0.773/0.772/0.775 | c=0.100000
[Epoch 0010] loss=29.1367 cls=0.5588 smmd=1.3337 ct=7.4318 rec=1.3131 | train/val/test=0.803/0.802/0.803 | c=0.100000
[Epoch 0011] loss=25.6704 cls=0.5308 smmd=1.0232 ct=7.2556 rec=1.3230 | train/val/test=0.809/0.811/0.811 | c=0.100000
[Epoch 0012] loss=26.4979 cls=0.5184 smmd=1.1020 ct=7.2783 rec=1.3234 | train/val/test=0.812/0.811/0.812 | c=0.100000
[Epoch 0013] loss=28.6855 cls=0.5225 smmd=1.3138 ct=7.3108 rec=1.3297 | train/val/test=0.796/0.795/0.792 | c=0.100000
[Epoch 0014] loss=25.9061 cls=0.5338 smmd=1.0451 ct=7.2611 rec=1.3325 | train/val/test=0.781/0.781/0.773 | c=0.100000
[Epoch 0015] loss=23.2633 cls=0.5409 smmd=0.7724 ct=7.3019 rec=1.3306 | train/val/test=0.780/0.779/0.771 | c=0.100000
[Epoch 0016] loss=23.9492 cls=0.5380 smmd=0.8416 ct=7.3004 rec=1.3266 | train/val/test=0.799/0.797/0.795 | c=0.100000
[Epoch 0017] loss=24.0119 cls=0.5030 smmd=0.8520 ct=7.2916 rec=1.3133 | train/val/test=0.812/0.810/0.810 | c=0.100000
[Epoch 0018] loss=22.5998 cls=0.4773 smmd=0.7149 ct=7.2800 rec=1.3050 | train/val/test=0.825/0.825/0.825 | c=0.100000
[Epoch 0019] loss=21.0740 cls=0.4489 smmd=0.5619 ct=7.2915 rec=1.2947 | train/val/test=0.830/0.826/0.828 | c=0.100000
[Epoch 0020] loss=20.8741 cls=0.4397 smmd=0.5402 ct=7.3040 rec=1.2889 | train/val/test=0.832/0.828/0.835 | c=0.100000
[Epoch 0021] loss=21.3785 cls=0.4291 smmd=0.5965 ct=7.2781 rec=1.2852 | train/val/test=0.834/0.828/0.837 | c=0.100000
[Epoch 0022] loss=21.0085 cls=0.4320 smmd=0.5620 ct=7.2649 rec=1.2857 | train/val/test=0.830/0.827/0.834 | c=0.100000
[Epoch 0023] loss=20.2624 cls=0.4407 smmd=0.4830 ct=7.2839 rec=1.2885 | train/val/test=0.829/0.824/0.838 | c=0.100000
[Epoch 0024] loss=20.3237 cls=0.4432 smmd=0.4894 ct=7.2803 rec=1.2953 | train/val/test=0.824/0.821/0.831 | c=0.100000
[Epoch 0025] loss=20.7515 cls=0.4511 smmd=0.5334 ct=7.2704 rec=1.3022 | train/val/test=0.832/0.828/0.839 | c=0.100000
[Epoch 0026] loss=20.4900 cls=0.4532 smmd=0.5124 ct=7.2421 rec=1.3105 | train/val/test=0.802/0.796/0.801 | c=0.100000
[Epoch 0027] loss=19.8563 cls=0.4938 smmd=0.4412 ct=7.2678 rec=1.3227 | train/val/test=0.639/0.645/0.648 | c=0.100000
[Epoch 0028] loss=20.1326 cls=0.7137 smmd=0.4499 ct=7.2952 rec=1.3732 | train/val/test=0.605/0.600/0.600 | c=0.100000
[Epoch 0029] loss=20.7835 cls=1.0021 smmd=0.4738 ct=7.4186 rec=1.4149 | train/val/test=0.678/0.690/0.687 | c=0.100000
[Epoch 0030] loss=19.7242 cls=0.7022 smmd=0.4142 ct=7.2776 rec=1.3519 | train/val/test=0.839/0.834/0.842 | c=0.100000
[Epoch 0031] loss=18.6400 cls=0.4058 smmd=0.3283 ct=7.2552 rec=1.2868 | train/val/test=0.775/0.775/0.782 | c=0.100000
[Epoch 0032] loss=18.9961 cls=0.5932 smmd=0.3445 ct=7.2993 rec=1.3120 | train/val/test=0.834/0.831/0.838 | c=0.100000
[Epoch 0033] loss=18.7225 cls=0.4408 smmd=0.3359 ct=7.2497 rec=1.2877 | train/val/test=0.835/0.832/0.837 | c=0.100000
[Epoch 0034] loss=18.6309 cls=0.4371 smmd=0.3239 ct=7.2641 rec=1.2911 | train/val/test=0.804/0.804/0.810 | c=0.100000
[Epoch 0035] loss=18.7959 cls=0.4932 smmd=0.3346 ct=7.2766 rec=1.2994 | train/val/test=0.836/0.835/0.841 | c=0.100000
[Epoch 0036] loss=18.7026 cls=0.4220 smmd=0.3357 ct=7.2448 rec=1.2911 | train/val/test=0.832/0.830/0.833 | c=0.100000
[Epoch 0037] loss=18.8812 cls=0.4473 smmd=0.3511 ct=7.2473 rec=1.3048 | train/val/test=0.809/0.805/0.811 | c=0.100000
[Epoch 0038] loss=18.9184 cls=0.4882 smmd=0.3513 ct=7.2503 rec=1.3211 | train/val/test=0.833/0.832/0.831 | c=0.100000
[Epoch 0039] loss=18.5653 cls=0.4602 smmd=0.3254 ct=7.2119 rec=1.3153 | train/val/test=0.836/0.833/0.837 | c=0.100000
[Epoch 0040] loss=18.3162 cls=0.4563 smmd=0.2993 ct=7.2188 rec=1.3144 | train/val/test=0.825/0.820/0.826 | c=0.100000
[Epoch 0041] loss=18.1471 cls=0.4669 smmd=0.2809 ct=7.2225 rec=1.3186 | train/val/test=0.831/0.827/0.832 | c=0.100000
[Epoch 0042] loss=17.9099 cls=0.4628 smmd=0.2628 ct=7.1967 rec=1.3149 | train/val/test=0.833/0.826/0.836 | c=0.100000
[Epoch 0043] loss=17.7950 cls=0.4497 smmd=0.2508 ct=7.2031 rec=1.3113 | train/val/test=0.829/0.825/0.832 | c=0.100000
[Epoch 0044] loss=17.7529 cls=0.4533 smmd=0.2464 ct=7.2033 rec=1.3109 | train/val/test=0.828/0.820/0.830 | c=0.100000
[Epoch 0045] loss=17.7864 cls=0.4620 smmd=0.2507 ct=7.1959 rec=1.3130 | train/val/test=0.826/0.822/0.830 | c=0.100000
[Epoch 0046] loss=17.8089 cls=0.4641 smmd=0.2543 ct=7.1881 rec=1.3147 | train/val/test=0.828/0.824/0.831 | c=0.100000
[Epoch 0047] loss=17.8951 cls=0.4675 smmd=0.2639 ct=7.1815 rec=1.3191 | train/val/test=0.831/0.821/0.832 | c=0.100000
[Epoch 0048] loss=17.9609 cls=0.4749 smmd=0.2687 ct=7.1867 rec=1.3254 | train/val/test=0.827/0.825/0.827 | c=0.100000
[Epoch 0049] loss=17.9652 cls=0.4846 smmd=0.2682 ct=7.1872 rec=1.3328 | train/val/test=0.825/0.821/0.827 | c=0.100000
[Epoch 0050] loss=17.9418 cls=0.4921 smmd=0.2658 ct=7.1854 rec=1.3343 | train/val/test=0.813/0.809/0.813 | c=0.100000
[Epoch 0051] loss=17.8817 cls=0.5000 smmd=0.2554 ct=7.2039 rec=1.3393 | train/val/test=0.811/0.809/0.818 | c=0.100000
[Epoch 0052] loss=17.8639 cls=0.5108 smmd=0.2518 ct=7.2125 rec=1.3305 | train/val/test=0.804/0.796/0.806 | c=0.100000
[Epoch 0053] loss=17.8322 cls=0.5059 smmd=0.2470 ct=7.2214 rec=1.3333 | train/val/test=0.821/0.817/0.827 | c=0.100000
[Epoch 0054] loss=17.7718 cls=0.5064 smmd=0.2395 ct=7.2340 rec=1.3116 | train/val/test=0.820/0.811/0.817 | c=0.100000
[Epoch 0055] loss=17.7366 cls=0.4800 smmd=0.2400 ct=7.2200 rec=1.3137 | train/val/test=0.810/0.804/0.817 | c=0.100000
[Epoch 0056] loss=17.7620 cls=0.5153 smmd=0.2401 ct=7.2258 rec=1.3033 | train/val/test=0.794/0.789/0.797 | c=0.100000
[Epoch 0057] loss=17.9494 cls=0.5270 smmd=0.2506 ct=7.2573 rec=1.3304 | train/val/test=0.800/0.801/0.808 | c=0.100000
[Epoch 0058] loss=17.9110 cls=0.5319 smmd=0.2555 ct=7.2170 rec=1.3120 | train/val/test=0.809/0.805/0.816 | c=0.100000
[Epoch 0059] loss=17.8320 cls=0.4884 smmd=0.2491 ct=7.2200 rec=1.3135 | train/val/test=0.820/0.821/0.821 | c=0.100000
[Epoch 0060] loss=17.8145 cls=0.4605 smmd=0.2495 ct=7.2185 rec=1.3050 | train/val/test=0.834/0.832/0.835 | c=0.100000
[Epoch 0061] loss=17.8015 cls=0.4465 smmd=0.2518 ct=7.2056 rec=1.2987 | train/val/test=0.832/0.825/0.833 | c=0.100000
[Epoch 0062] loss=17.7583 cls=0.4315 smmd=0.2421 ct=7.2347 rec=1.3050 | train/val/test=0.836/0.833/0.840 | c=0.100000
[Epoch 0063] loss=17.6547 cls=0.4391 smmd=0.2386 ct=7.1993 rec=1.3011 | train/val/test=0.836/0.830/0.836 | c=0.100000
[Epoch 0064] loss=17.4797 cls=0.4251 smmd=0.2230 ct=7.1919 rec=1.3061 | train/val/test=0.837/0.834/0.841 | c=0.100000
[Epoch 0065] loss=17.4427 cls=0.4295 smmd=0.2204 ct=7.1859 rec=1.3046 | train/val/test=0.837/0.831/0.838 | c=0.100000
[Epoch 0066] loss=17.5202 cls=0.4310 smmd=0.2270 ct=7.1909 rec=1.3061 | train/val/test=0.836/0.828/0.837 | c=0.100000
[Epoch 0067] loss=17.5498 cls=0.4369 smmd=0.2266 ct=7.2059 rec=1.3070 | train/val/test=0.835/0.829/0.836 | c=0.100000
[Epoch 0068] loss=17.5509 cls=0.4428 smmd=0.2318 ct=7.1787 rec=1.3074 | train/val/test=0.834/0.828/0.834 | c=0.100000
[Epoch 0069] loss=17.5377 cls=0.4459 smmd=0.2276 ct=7.1922 rec=1.3088 | train/val/test=0.833/0.828/0.833 | c=0.100000
[Epoch 0070] loss=17.5130 cls=0.4479 smmd=0.2284 ct=7.1748 rec=1.3105 | train/val/test=0.834/0.830/0.837 | c=0.100000
[Epoch 0071] loss=17.5430 cls=0.4481 smmd=0.2297 ct=7.1832 rec=1.3109 | train/val/test=0.830/0.825/0.831 | c=0.100000
[Epoch 0072] loss=17.6029 cls=0.4515 smmd=0.2318 ct=7.2005 rec=1.3161 | train/val/test=0.830/0.827/0.835 | c=0.100000
[Epoch 0073] loss=17.6750 cls=0.4675 smmd=0.2355 ct=7.2147 rec=1.3146 | train/val/test=0.814/0.806/0.810 | c=0.100000
[Epoch 0074] loss=17.7658 cls=0.4848 smmd=0.2407 ct=7.2266 rec=1.3259 | train/val/test=0.782/0.782/0.788 | c=0.100000
[Epoch 0075] loss=17.8256 cls=0.5437 smmd=0.2397 ct=7.2474 rec=1.3247 | train/val/test=0.763/0.762/0.759 | c=0.100000
[Epoch 0076] loss=17.9216 cls=0.5914 smmd=0.2479 ct=7.2370 rec=1.3469 | train/val/test=0.703/0.706/0.705 | c=0.100000
[Epoch 0077] loss=18.1149 cls=0.6637 smmd=0.2569 ct=7.2708 rec=1.3449 | train/val/test=0.758/0.757/0.756 | c=0.100000
[Epoch 0078] loss=18.1166 cls=0.6492 smmd=0.2572 ct=7.2758 rec=1.3379 | train/val/test=0.770/0.768/0.774 | c=0.100000
[Epoch 0079] loss=18.0861 cls=0.5535 smmd=0.2597 ct=7.2736 rec=1.3295 | train/val/test=0.813/0.809/0.819 | c=0.100000
[Epoch 0080] loss=17.7906 cls=0.4972 smmd=0.2355 ct=7.2720 rec=1.2859 | train/val/test=0.825/0.816/0.823 | c=0.100000
[Epoch 0081] loss=17.7568 cls=0.4497 smmd=0.2401 ct=7.2423 rec=1.2918 | train/val/test=0.830/0.827/0.835 | c=0.100000
[Epoch 0082] loss=17.7245 cls=0.4523 smmd=0.2367 ct=7.2437 rec=1.2871 | train/val/test=0.827/0.825/0.829 | c=0.100000
[Epoch 0083] loss=17.6685 cls=0.4437 smmd=0.2347 ct=7.2267 rec=1.2924 | train/val/test=0.834/0.834/0.832 | c=0.100000
[Epoch 0084] loss=17.8145 cls=0.4294 smmd=0.2458 ct=7.2456 rec=1.3014 | train/val/test=0.829/0.825/0.831 | c=0.100000
[Epoch 0085] loss=17.8366 cls=0.4706 smmd=0.2476 ct=7.2363 rec=1.3046 | train/val/test=0.836/0.832/0.831 | c=0.100000
[Epoch 0086] loss=17.7562 cls=0.4437 smmd=0.2416 ct=7.2311 rec=1.3132 | train/val/test=0.829/0.824/0.834 | c=0.100000
[Epoch 0087] loss=17.6608 cls=0.4715 smmd=0.2343 ct=7.2134 rec=1.3101 | train/val/test=0.830/0.825/0.829 | c=0.100000
[Epoch 0088] loss=17.6085 cls=0.4488 smmd=0.2281 ct=7.2236 rec=1.3119 | train/val/test=0.821/0.816/0.824 | c=0.100000
[Epoch 0089] loss=17.6147 cls=0.4676 smmd=0.2300 ct=7.2134 rec=1.3091 | train/val/test=0.826/0.819/0.830 | c=0.100000
[Epoch 0090] loss=17.5221 cls=0.4518 smmd=0.2241 ct=7.2009 rec=1.3077 | train/val/test=0.822/0.818/0.826 | c=0.100000
[Epoch 0091] loss=17.4701 cls=0.4557 smmd=0.2177 ct=7.2063 rec=1.3046 | train/val/test=0.828/0.820/0.832 | c=0.100000
[Epoch 0092] loss=17.5239 cls=0.4503 smmd=0.2281 ct=7.1821 rec=1.3064 | train/val/test=0.830/0.821/0.833 | c=0.100000
[Epoch 0093] loss=17.6075 cls=0.4520 smmd=0.2296 ct=7.2151 rec=1.3108 | train/val/test=0.831/0.827/0.832 | c=0.100000
[Epoch 0094] loss=17.6377 cls=0.4569 smmd=0.2364 ct=7.1938 rec=1.3148 | train/val/test=0.832/0.822/0.834 | c=0.100000
[Epoch 0095] loss=17.5963 cls=0.4568 smmd=0.2304 ct=7.2021 rec=1.3188 | train/val/test=0.834/0.831/0.835 | c=0.100000
[Epoch 0096] loss=17.5604 cls=0.4590 smmd=0.2263 ct=7.2047 rec=1.3178 | train/val/test=0.833/0.824/0.834 | c=0.100000
[Epoch 0097] loss=17.5394 cls=0.4522 smmd=0.2263 ct=7.1957 rec=1.3174 | train/val/test=0.832/0.830/0.833 | c=0.100000
[Epoch 0098] loss=17.5351 cls=0.4530 smmd=0.2239 ct=7.2072 rec=1.3110 | train/val/test=0.830/0.823/0.830 | c=0.100000
[Epoch 0099] loss=17.5158 cls=0.4482 smmd=0.2228 ct=7.2041 rec=1.3112 | train/val/test=0.821/0.819/0.824 | c=0.100000
=== Best @ epoch 35: val=0.8346, test=0.8405 ===
