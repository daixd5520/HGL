Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=81.3313 cls=1.1033 smmd=6.5537 ct=7.2681 rec=1.4137 | train/val/test=0.402/0.405/0.387 | c=0.100000
[Epoch 0001] loss=72.9003 cls=1.0565 smmd=5.7140 ct=7.2614 rec=1.4193 | train/val/test=0.528/0.529/0.534 | c=0.100000
[Epoch 0002] loss=41.9638 cls=1.0503 smmd=2.6466 ct=7.1327 rec=1.4142 | train/val/test=0.362/0.360/0.368 | c=0.100000
[Epoch 0003] loss=45.6714 cls=1.0651 smmd=3.0199 ct=7.1167 rec=1.4121 | train/val/test=0.665/0.664/0.668 | c=0.100000
[Epoch 0004] loss=45.3303 cls=0.8907 smmd=3.0389 ct=6.8974 rec=1.4021 | train/val/test=0.681/0.685/0.685 | c=0.100000
[Epoch 0005] loss=35.3418 cls=0.8055 smmd=2.0604 ct=6.8224 rec=1.3796 | train/val/test=0.680/0.686/0.686 | c=0.100000
[Epoch 0006] loss=28.2184 cls=0.7391 smmd=1.3588 ct=6.7917 rec=1.3547 | train/val/test=0.674/0.682/0.680 | c=0.100000
[Epoch 0007] loss=32.1022 cls=0.7021 smmd=1.7496 ct=6.7933 rec=1.3381 | train/val/test=0.685/0.691/0.690 | c=0.100000
[Epoch 0008] loss=34.5049 cls=0.6693 smmd=1.9936 ct=6.7853 rec=1.3275 | train/val/test=0.720/0.720/0.722 | c=0.100000
[Epoch 0009] loss=32.4660 cls=0.6279 smmd=1.7954 ct=6.7685 rec=1.3220 | train/val/test=0.749/0.749/0.746 | c=0.100000
[Epoch 0010] loss=27.8467 cls=0.5896 smmd=1.3367 ct=6.7613 rec=1.3239 | train/val/test=0.779/0.782/0.776 | c=0.100000
[Epoch 0011] loss=23.7947 cls=0.5615 smmd=0.9358 ct=6.7465 rec=1.3254 | train/val/test=0.800/0.805/0.796 | c=0.100000
[Epoch 0012] loss=25.4171 cls=0.5531 smmd=1.0991 ct=6.7431 rec=1.3273 | train/val/test=0.805/0.804/0.801 | c=0.100000
[Epoch 0013] loss=27.6873 cls=0.5445 smmd=1.3262 ct=6.7443 rec=1.3284 | train/val/test=0.797/0.793/0.794 | c=0.100000
[Epoch 0014] loss=24.2825 cls=0.5333 smmd=0.9887 ct=6.7334 rec=1.3248 | train/val/test=0.794/0.788/0.788 | c=0.100000
[Epoch 0015] loss=23.0205 cls=0.5188 smmd=0.7273 ct=7.4152 rec=1.3163 | train/val/test=0.797/0.799/0.793 | c=0.100000
[Epoch 0016] loss=24.2011 cls=0.5025 smmd=0.8659 ct=7.3194 rec=1.3038 | train/val/test=0.809/0.806/0.804 | c=0.100000
[Epoch 0017] loss=24.1246 cls=0.4834 smmd=0.8571 ct=7.3319 rec=1.2969 | train/val/test=0.817/0.815/0.811 | c=0.100000
[Epoch 0018] loss=22.5702 cls=0.4694 smmd=0.6980 ct=7.3555 rec=1.2883 | train/val/test=0.819/0.817/0.813 | c=0.100000
[Epoch 0019] loss=21.0047 cls=0.4643 smmd=0.5432 ct=7.3495 rec=1.2823 | train/val/test=0.825/0.826/0.820 | c=0.100000
[Epoch 0020] loss=21.0907 cls=0.4445 smmd=0.5527 ct=7.3507 rec=1.2799 | train/val/test=0.829/0.830/0.824 | c=0.100000
[Epoch 0021] loss=21.6342 cls=0.4320 smmd=0.6086 ct=7.3458 rec=1.2807 | train/val/test=0.828/0.830/0.825 | c=0.100000
[Epoch 0022] loss=21.0737 cls=0.4311 smmd=0.5554 ct=7.3313 rec=1.2830 | train/val/test=0.828/0.829/0.825 | c=0.100000
[Epoch 0023] loss=20.4156 cls=0.4334 smmd=0.4890 ct=7.3325 rec=1.2875 | train/val/test=0.829/0.830/0.824 | c=0.100000
[Epoch 0024] loss=20.6393 cls=0.4359 smmd=0.5097 ct=7.3390 rec=1.2923 | train/val/test=0.830/0.830/0.824 | c=0.100000
[Epoch 0025] loss=20.9046 cls=0.4384 smmd=0.5368 ct=7.3342 rec=1.2974 | train/val/test=0.830/0.833/0.825 | c=0.100000
[Epoch 0026] loss=20.5099 cls=0.4351 smmd=0.4996 ct=7.3230 rec=1.2997 | train/val/test=0.832/0.834/0.825 | c=0.100000
[Epoch 0027] loss=19.8643 cls=0.4285 smmd=0.4373 ct=7.3139 rec=1.2984 | train/val/test=0.837/0.843/0.832 | c=0.100000
[Epoch 0028] loss=19.5038 cls=0.4196 smmd=0.4039 ct=7.3034 rec=1.2973 | train/val/test=0.836/0.838/0.835 | c=0.100000
[Epoch 0029] loss=19.3230 cls=0.4153 smmd=0.3843 ct=7.3120 rec=1.2965 | train/val/test=0.839/0.846/0.837 | c=0.100000
[Epoch 0030] loss=18.9661 cls=0.4122 smmd=0.3501 ct=7.3055 rec=1.2968 | train/val/test=0.836/0.841/0.840 | c=0.100000
[Epoch 0031] loss=18.6803 cls=0.4125 smmd=0.3210 ct=7.3077 rec=1.2978 | train/val/test=0.838/0.842/0.835 | c=0.100000
[Epoch 0032] loss=18.6162 cls=0.4144 smmd=0.3165 ct=7.2974 rec=1.2993 | train/val/test=0.836/0.841/0.838 | c=0.100000
[Epoch 0033] loss=18.6325 cls=0.4143 smmd=0.3194 ct=7.2906 rec=1.2992 | train/val/test=0.838/0.837/0.833 | c=0.100000
[Epoch 0034] loss=18.6821 cls=0.4249 smmd=0.3262 ct=7.2774 rec=1.3056 | train/val/test=0.828/0.830/0.831 | c=0.100000
[Epoch 0035] loss=18.7139 cls=0.4354 smmd=0.3264 ct=7.2890 rec=1.3077 | train/val/test=0.821/0.809/0.810 | c=0.100000
[Epoch 0036] loss=18.8450 cls=0.4693 smmd=0.3395 ct=7.2772 rec=1.3216 | train/val/test=0.745/0.747/0.747 | c=0.100000
[Epoch 0037] loss=19.1469 cls=0.6183 smmd=0.3486 ct=7.3384 rec=1.3498 | train/val/test=0.676/0.676/0.668 | c=0.100000
[Epoch 0038] loss=19.5419 cls=0.7262 smmd=0.3821 ct=7.3358 rec=1.3722 | train/val/test=0.736/0.740/0.743 | c=0.100000
[Epoch 0039] loss=19.0855 cls=0.6803 smmd=0.3380 ct=7.3459 rec=1.3465 | train/val/test=0.834/0.827/0.828 | c=0.100000
[Epoch 0040] loss=18.1492 cls=0.4225 smmd=0.2731 ct=7.2804 rec=1.2932 | train/val/test=0.822/0.817/0.813 | c=0.100000
[Epoch 0041] loss=18.1401 cls=0.4597 smmd=0.2707 ct=7.2781 rec=1.2935 | train/val/test=0.801/0.801/0.803 | c=0.100000
[Epoch 0042] loss=18.2480 cls=0.5098 smmd=0.2753 ct=7.2952 rec=1.3003 | train/val/test=0.834/0.834/0.832 | c=0.100000
[Epoch 0043] loss=17.9366 cls=0.4099 smmd=0.2538 ct=7.2750 rec=1.2873 | train/val/test=0.831/0.827/0.823 | c=0.100000
[Epoch 0044] loss=18.0526 cls=0.4368 smmd=0.2645 ct=7.2712 rec=1.2941 | train/val/test=0.817/0.814/0.818 | c=0.100000
[Epoch 0045] loss=18.2951 cls=0.4670 smmd=0.2826 ct=7.2894 rec=1.3139 | train/val/test=0.829/0.823/0.820 | c=0.100000
[Epoch 0046] loss=18.2868 cls=0.4555 smmd=0.2911 ct=7.2467 rec=1.3097 | train/val/test=0.837/0.835/0.834 | c=0.100000
[Epoch 0047] loss=18.1332 cls=0.4397 smmd=0.2765 ct=7.2451 rec=1.3159 | train/val/test=0.827/0.827/0.823 | c=0.100000
[Epoch 0048] loss=18.1506 cls=0.4620 smmd=0.2762 ct=7.2486 rec=1.3200 | train/val/test=0.807/0.798/0.797 | c=0.100000
[Epoch 0049] loss=18.1088 cls=0.4898 smmd=0.2715 ct=7.2411 rec=1.3343 | train/val/test=0.799/0.801/0.796 | c=0.100000
[Epoch 0050] loss=17.9565 cls=0.4972 smmd=0.2543 ct=7.2522 rec=1.3219 | train/val/test=0.823/0.820/0.816 | c=0.100000
[Epoch 0051] loss=17.7828 cls=0.4654 smmd=0.2402 ct=7.2412 rec=1.3312 | train/val/test=0.805/0.799/0.796 | c=0.100000
[Epoch 0052] loss=17.7442 cls=0.4950 smmd=0.2366 ct=7.2380 rec=1.3088 | train/val/test=0.819/0.819/0.815 | c=0.100000
[Epoch 0053] loss=17.7754 cls=0.4737 smmd=0.2343 ct=7.2664 rec=1.3252 | train/val/test=0.822/0.816/0.813 | c=0.100000
[Epoch 0054] loss=17.7546 cls=0.4828 smmd=0.2404 ct=7.2281 rec=1.3071 | train/val/test=0.828/0.831/0.825 | c=0.100000
[Epoch 0055] loss=17.7126 cls=0.4460 smmd=0.2354 ct=7.2395 rec=1.3138 | train/val/test=0.833/0.830/0.829 | c=0.100000
[Epoch 0056] loss=17.7358 cls=0.4419 smmd=0.2418 ct=7.2219 rec=1.3066 | train/val/test=0.837/0.836/0.832 | c=0.100000
[Epoch 0057] loss=17.8074 cls=0.4406 smmd=0.2491 ct=7.2200 rec=1.3122 | train/val/test=0.827/0.827/0.827 | c=0.100000
[Epoch 0058] loss=17.8392 cls=0.4615 smmd=0.2478 ct=7.2342 rec=1.3238 | train/val/test=0.827/0.824/0.821 | c=0.100000
[Epoch 0059] loss=17.8659 cls=0.4700 smmd=0.2542 ct=7.2148 rec=1.3183 | train/val/test=0.811/0.811/0.813 | c=0.100000
[Epoch 0060] loss=17.8362 cls=0.4918 smmd=0.2422 ct=7.2501 rec=1.3359 | train/val/test=0.813/0.803/0.799 | c=0.100000
[Epoch 0061] loss=17.7968 cls=0.4953 smmd=0.2433 ct=7.2290 rec=1.3159 | train/val/test=0.815/0.815/0.816 | c=0.100000
[Epoch 0062] loss=17.6786 cls=0.4799 smmd=0.2290 ct=7.2426 rec=1.3270 | train/val/test=0.831/0.830/0.824 | c=0.100000
[Epoch 0063] loss=17.5216 cls=0.4397 smmd=0.2203 ct=7.2240 rec=1.3020 | train/val/test=0.834/0.837/0.830 | c=0.100000
[Epoch 0064] loss=17.4189 cls=0.4237 smmd=0.2124 ct=7.2150 rec=1.3060 | train/val/test=0.831/0.833/0.831 | c=0.100000
[Epoch 0065] loss=17.4710 cls=0.4325 smmd=0.2171 ct=7.2161 rec=1.3038 | train/val/test=0.827/0.822/0.819 | c=0.100000
[Epoch 0066] loss=17.6410 cls=0.4541 smmd=0.2319 ct=7.2184 rec=1.3168 | train/val/test=0.785/0.779/0.790 | c=0.100000
[Epoch 0067] loss=17.9206 cls=0.5339 smmd=0.2478 ct=7.2530 rec=1.3386 | train/val/test=0.678/0.682/0.670 | c=0.100000
[Epoch 0068] loss=18.3841 cls=0.6864 smmd=0.2811 ct=7.2701 rec=1.3797 | train/val/test=0.667/0.659/0.670 | c=0.100000
[Epoch 0069] loss=18.8594 cls=0.8421 smmd=0.3048 ct=7.3506 rec=1.3785 | train/val/test=0.636/0.642/0.633 | c=0.100000
[Epoch 0070] loss=18.5614 cls=0.7582 smmd=0.2853 ct=7.3135 rec=1.4039 | train/val/test=0.774/0.767/0.768 | c=0.100000
[Epoch 0071] loss=17.8737 cls=0.5713 smmd=0.2407 ct=7.2664 rec=1.2968 | train/val/test=0.814/0.811/0.811 | c=0.100000
[Epoch 0072] loss=17.6626 cls=0.4732 smmd=0.2216 ct=7.2797 rec=1.3009 | train/val/test=0.796/0.786/0.782 | c=0.100000
[Epoch 0073] loss=17.7941 cls=0.5164 smmd=0.2343 ct=7.2691 rec=1.3089 | train/val/test=0.805/0.800/0.802 | c=0.100000
[Epoch 0074] loss=17.6621 cls=0.5007 smmd=0.2279 ct=7.2443 rec=1.2881 | train/val/test=0.814/0.813/0.817 | c=0.100000
[Epoch 0075] loss=17.9325 cls=0.4756 smmd=0.2443 ct=7.2984 rec=1.3093 | train/val/test=0.791/0.774/0.777 | c=0.100000
[Epoch 0076] loss=18.2967 cls=0.5540 smmd=0.2826 ct=7.2685 rec=1.3138 | train/val/test=0.809/0.806/0.808 | c=0.100000
[Epoch 0077] loss=18.0117 cls=0.4827 smmd=0.2573 ct=7.2686 rec=1.3206 | train/val/test=0.834/0.834/0.832 | c=0.100000
[Epoch 0078] loss=17.7191 cls=0.4376 smmd=0.2396 ct=7.2248 rec=1.3103 | train/val/test=0.818/0.804/0.807 | c=0.100000
[Epoch 0079] loss=17.8046 cls=0.4850 smmd=0.2439 ct=7.2335 rec=1.3120 | train/val/test=0.811/0.812/0.810 | c=0.100000
[Epoch 0080] loss=17.8601 cls=0.4900 smmd=0.2396 ct=7.2763 rec=1.3337 | train/val/test=0.815/0.802/0.801 | c=0.100000
[Epoch 0081] loss=17.6151 cls=0.4947 smmd=0.2277 ct=7.2163 rec=1.3161 | train/val/test=0.831/0.835/0.826 | c=0.100000
[Epoch 0082] loss=17.4146 cls=0.4469 smmd=0.2089 ct=7.2219 rec=1.3168 | train/val/test=0.824/0.828/0.824 | c=0.100000
[Epoch 0083] loss=17.5321 cls=0.4583 smmd=0.2169 ct=7.2372 rec=1.3183 | train/val/test=0.828/0.826/0.823 | c=0.100000
[Epoch 0084] loss=17.6270 cls=0.4683 smmd=0.2293 ct=7.2207 rec=1.3160 | train/val/test=0.823/0.824/0.822 | c=0.100000
[Epoch 0085] loss=17.5693 cls=0.4650 smmd=0.2221 ct=7.2279 rec=1.3208 | train/val/test=0.830/0.828/0.824 | c=0.100000
[Epoch 0086] loss=17.6029 cls=0.4611 smmd=0.2295 ct=7.2101 rec=1.3146 | train/val/test=0.826/0.827/0.822 | c=0.100000
[Epoch 0087] loss=17.7690 cls=0.4656 smmd=0.2400 ct=7.2367 rec=1.3260 | train/val/test=0.822/0.825/0.819 | c=0.100000
[Epoch 0088] loss=17.8335 cls=0.4740 smmd=0.2470 ct=7.2332 rec=1.3196 | train/val/test=0.823/0.823/0.817 | c=0.100000
[Epoch 0089] loss=17.7462 cls=0.4679 smmd=0.2366 ct=7.2407 rec=1.3301 | train/val/test=0.815/0.814/0.811 | c=0.100000
[Epoch 0090] loss=17.6276 cls=0.4759 smmd=0.2286 ct=7.2233 rec=1.3136 | train/val/test=0.824/0.827/0.820 | c=0.100000
[Epoch 0091] loss=17.5665 cls=0.4577 smmd=0.2208 ct=7.2335 rec=1.3245 | train/val/test=0.823/0.818/0.816 | c=0.100000
[Epoch 0092] loss=17.5664 cls=0.4667 smmd=0.2244 ct=7.2176 rec=1.3070 | train/val/test=0.824/0.826/0.824 | c=0.100000
[Epoch 0093] loss=17.5426 cls=0.4493 smmd=0.2189 ct=7.2356 rec=1.3166 | train/val/test=0.832/0.830/0.826 | c=0.100000
[Epoch 0094] loss=17.5006 cls=0.4401 smmd=0.2221 ct=7.2042 rec=1.3023 | train/val/test=0.832/0.835/0.828 | c=0.100000
[Epoch 0095] loss=17.4753 cls=0.4339 smmd=0.2180 ct=7.2120 rec=1.3093 | train/val/test=0.830/0.831/0.828 | c=0.100000
[Epoch 0096] loss=17.5147 cls=0.4379 smmd=0.2234 ct=7.2044 rec=1.3062 | train/val/test=0.832/0.830/0.823 | c=0.100000
[Epoch 0097] loss=17.6236 cls=0.4414 smmd=0.2328 ct=7.2091 rec=1.3144 | train/val/test=0.800/0.798/0.801 | c=0.100000
[Epoch 0098] loss=17.8109 cls=0.5103 smmd=0.2410 ct=7.2408 rec=1.3286 | train/val/test=0.739/0.735/0.731 | c=0.100000
[Epoch 0099] loss=18.1700 cls=0.5866 smmd=0.2659 ct=7.2700 rec=1.3561 | train/val/test=0.685/0.680/0.685 | c=0.100000
=== Best @ epoch 29: val=0.8455, test=0.8370 ===
