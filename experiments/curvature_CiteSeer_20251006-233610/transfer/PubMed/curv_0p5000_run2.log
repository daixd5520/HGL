Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=81.1621 cls=1.1057 smmd=6.5370 ct=7.2663 rec=1.4136 | train/val/test=0.393/0.388/0.395 | c=0.500000
[Epoch 0001] loss=72.3352 cls=1.0579 smmd=5.6581 ct=7.2582 rec=1.4176 | train/val/test=0.520/0.509/0.517 | c=0.500000
[Epoch 0002] loss=41.2734 cls=1.0459 smmd=2.5800 ct=7.1216 rec=1.4146 | train/val/test=0.357/0.355/0.365 | c=0.500000
[Epoch 0003] loss=45.8562 cls=1.0551 smmd=3.0429 ct=7.0966 rec=1.4119 | train/val/test=0.642/0.626/0.646 | c=0.500000
[Epoch 0004] loss=45.6183 cls=0.8720 smmd=3.0692 ct=6.8939 rec=1.4049 | train/val/test=0.689/0.684/0.693 | c=0.500000
[Epoch 0005] loss=35.4176 cls=0.7644 smmd=2.0719 ct=6.8129 rec=1.3806 | train/val/test=0.687/0.680/0.681 | c=0.500000
[Epoch 0006] loss=27.9925 cls=0.7053 smmd=1.3409 ct=6.7772 rec=1.3520 | train/val/test=0.695/0.695/0.690 | c=0.500000
[Epoch 0007] loss=32.1586 cls=0.6670 smmd=1.7603 ct=6.7778 rec=1.3334 | train/val/test=0.719/0.717/0.708 | c=0.500000
[Epoch 0008] loss=34.6567 cls=0.6340 smmd=2.0093 ct=6.7924 rec=1.3232 | train/val/test=0.749/0.747/0.746 | c=0.500000
[Epoch 0009] loss=32.4419 cls=0.5961 smmd=1.7910 ct=6.7879 rec=1.3160 | train/val/test=0.774/0.767/0.766 | c=0.500000
[Epoch 0010] loss=27.8645 cls=0.5616 smmd=1.3389 ct=6.7689 rec=1.3139 | train/val/test=0.794/0.793/0.787 | c=0.500000
[Epoch 0011] loss=24.1319 cls=0.5322 smmd=0.9712 ct=6.7478 rec=1.3162 | train/val/test=0.809/0.808/0.794 | c=0.500000
[Epoch 0012] loss=25.0755 cls=0.5218 smmd=1.0676 ct=6.7396 rec=1.3181 | train/val/test=0.807/0.812/0.797 | c=0.500000
[Epoch 0013] loss=28.9996 cls=0.5193 smmd=1.3172 ct=7.4537 rec=1.3220 | train/val/test=0.800/0.807/0.790 | c=0.500000
[Epoch 0014] loss=26.1625 cls=0.5179 smmd=1.0775 ct=7.2338 rec=1.3214 | train/val/test=0.798/0.808/0.787 | c=0.500000
[Epoch 0015] loss=23.1402 cls=0.5132 smmd=0.7669 ct=7.2788 rec=1.3141 | train/val/test=0.785/0.791/0.777 | c=0.500000
[Epoch 0016] loss=24.1643 cls=0.5186 smmd=0.8550 ct=7.3485 rec=1.3155 | train/val/test=0.808/0.811/0.796 | c=0.500000
[Epoch 0017] loss=24.2354 cls=0.4835 smmd=0.8681 ct=7.3314 rec=1.2994 | train/val/test=0.820/0.821/0.809 | c=0.500000
[Epoch 0018] loss=22.6876 cls=0.4670 smmd=0.7172 ct=7.3182 rec=1.2907 | train/val/test=0.826/0.831/0.814 | c=0.500000
[Epoch 0019] loss=21.1001 cls=0.4492 smmd=0.5584 ct=7.3244 rec=1.2849 | train/val/test=0.828/0.831/0.818 | c=0.500000
[Epoch 0020] loss=20.9516 cls=0.4430 smmd=0.5444 ct=7.3229 rec=1.2804 | train/val/test=0.828/0.833/0.823 | c=0.500000
[Epoch 0021] loss=21.5774 cls=0.4372 smmd=0.6099 ct=7.3098 rec=1.2806 | train/val/test=0.829/0.833/0.827 | c=0.500000
[Epoch 0022] loss=21.1372 cls=0.4333 smmd=0.5670 ct=7.3042 rec=1.2836 | train/val/test=0.832/0.834/0.826 | c=0.500000
[Epoch 0023] loss=20.2794 cls=0.4339 smmd=0.4808 ct=7.3052 rec=1.2871 | train/val/test=0.831/0.832/0.825 | c=0.500000
[Epoch 0024] loss=20.4420 cls=0.4368 smmd=0.4970 ct=7.3035 rec=1.2933 | train/val/test=0.834/0.834/0.826 | c=0.500000
[Epoch 0025] loss=20.8319 cls=0.4400 smmd=0.5376 ct=7.2930 rec=1.3005 | train/val/test=0.827/0.828/0.827 | c=0.500000
[Epoch 0026] loss=20.5173 cls=0.4482 smmd=0.5113 ct=7.2629 rec=1.3093 | train/val/test=0.839/0.839/0.831 | c=0.500000
[Epoch 0027] loss=19.8151 cls=0.4407 smmd=0.4419 ct=7.2606 rec=1.3100 | train/val/test=0.823/0.822/0.821 | c=0.500000
[Epoch 0028] loss=19.4915 cls=0.4614 smmd=0.4059 ct=7.2707 rec=1.3210 | train/val/test=0.808/0.808/0.796 | c=0.500000
[Epoch 0029] loss=19.4729 cls=0.4973 smmd=0.3996 ct=7.2832 rec=1.3235 | train/val/test=0.753/0.751/0.748 | c=0.500000
[Epoch 0030] loss=19.3256 cls=0.5628 smmd=0.3795 ct=7.2883 rec=1.3455 | train/val/test=0.720/0.718/0.714 | c=0.500000
[Epoch 0031] loss=19.0939 cls=0.6303 smmd=0.3560 ct=7.2730 rec=1.3462 | train/val/test=0.783/0.779/0.776 | c=0.500000
[Epoch 0032] loss=18.8577 cls=0.5422 smmd=0.3406 ct=7.2583 rec=1.3285 | train/val/test=0.840/0.839/0.833 | c=0.500000
[Epoch 0033] loss=18.5347 cls=0.4177 smmd=0.3193 ct=7.2412 rec=1.3009 | train/val/test=0.841/0.837/0.825 | c=0.500000
[Epoch 0034] loss=18.5193 cls=0.4268 smmd=0.3125 ct=7.2666 rec=1.2954 | train/val/test=0.806/0.801/0.806 | c=0.500000
[Epoch 0035] loss=18.6399 cls=0.4847 smmd=0.3228 ct=7.2573 rec=1.3110 | train/val/test=0.819/0.815/0.806 | c=0.500000
[Epoch 0036] loss=18.7142 cls=0.4666 smmd=0.3338 ct=7.2437 rec=1.3111 | train/val/test=0.830/0.831/0.830 | c=0.500000
[Epoch 0037] loss=18.6745 cls=0.4322 smmd=0.3322 ct=7.2422 rec=1.3040 | train/val/test=0.841/0.837/0.834 | c=0.500000
[Epoch 0038] loss=18.5305 cls=0.4271 smmd=0.3235 ct=7.2138 rec=1.3085 | train/val/test=0.837/0.840/0.827 | c=0.500000
[Epoch 0039] loss=18.3783 cls=0.4507 smmd=0.3048 ct=7.2256 rec=1.3083 | train/val/test=0.824/0.820/0.821 | c=0.500000
[Epoch 0040] loss=18.3487 cls=0.4680 smmd=0.2992 ct=7.2299 rec=1.3261 | train/val/test=0.815/0.812/0.801 | c=0.500000
[Epoch 0041] loss=18.2251 cls=0.5097 smmd=0.2876 ct=7.2185 rec=1.3154 | train/val/test=0.830/0.828/0.833 | c=0.500000
[Epoch 0042] loss=17.9648 cls=0.4522 smmd=0.2625 ct=7.2266 rec=1.3202 | train/val/test=0.836/0.835/0.823 | c=0.500000
[Epoch 0043] loss=17.7374 cls=0.4431 smmd=0.2478 ct=7.1924 rec=1.3052 | train/val/test=0.839/0.840/0.835 | c=0.500000
[Epoch 0044] loss=17.6832 cls=0.4286 smmd=0.2430 ct=7.1938 rec=1.3019 | train/val/test=0.831/0.831/0.833 | c=0.500000
[Epoch 0045] loss=17.7408 cls=0.4373 smmd=0.2471 ct=7.1984 rec=1.3092 | train/val/test=0.835/0.833/0.822 | c=0.500000
[Epoch 0046] loss=17.8744 cls=0.4605 smmd=0.2584 ct=7.2033 rec=1.3077 | train/val/test=0.822/0.823/0.818 | c=0.500000
[Epoch 0047] loss=18.0165 cls=0.4722 smmd=0.2691 ct=7.2135 rec=1.3242 | train/val/test=0.837/0.833/0.821 | c=0.500000
[Epoch 0048] loss=18.0676 cls=0.4780 smmd=0.2730 ct=7.2203 rec=1.3166 | train/val/test=0.821/0.824/0.816 | c=0.500000
[Epoch 0049] loss=18.0913 cls=0.4826 smmd=0.2753 ct=7.2154 rec=1.3322 | train/val/test=0.824/0.828/0.819 | c=0.500000
[Epoch 0050] loss=18.0319 cls=0.4905 smmd=0.2677 ct=7.2255 rec=1.3169 | train/val/test=0.805/0.805/0.793 | c=0.500000
[Epoch 0051] loss=17.9873 cls=0.4988 smmd=0.2625 ct=7.2220 rec=1.3375 | train/val/test=0.768/0.770/0.762 | c=0.500000
[Epoch 0052] loss=18.0210 cls=0.5851 smmd=0.2547 ct=7.2578 rec=1.3323 | train/val/test=0.672/0.672/0.656 | c=0.500000
[Epoch 0053] loss=18.2770 cls=0.6978 smmd=0.2730 ct=7.2545 rec=1.3782 | train/val/test=0.719/0.718/0.720 | c=0.500000
[Epoch 0054] loss=18.3479 cls=0.7281 smmd=0.2712 ct=7.2951 rec=1.3636 | train/val/test=0.799/0.794/0.781 | c=0.500000
[Epoch 0055] loss=17.8837 cls=0.5167 smmd=0.2444 ct=7.2630 rec=1.3111 | train/val/test=0.832/0.836/0.826 | c=0.500000
[Epoch 0056] loss=17.5283 cls=0.4252 smmd=0.2245 ct=7.2127 rec=1.2909 | train/val/test=0.795/0.791/0.792 | c=0.500000
[Epoch 0057] loss=17.8615 cls=0.5292 smmd=0.2464 ct=7.2404 rec=1.3048 | train/val/test=0.820/0.817/0.806 | c=0.500000
[Epoch 0058] loss=18.0156 cls=0.4782 smmd=0.2581 ct=7.2713 rec=1.3061 | train/val/test=0.823/0.825/0.822 | c=0.500000
[Epoch 0059] loss=17.8502 cls=0.4379 smmd=0.2549 ct=7.2154 rec=1.3029 | train/val/test=0.828/0.835/0.821 | c=0.500000
[Epoch 0060] loss=17.8747 cls=0.4463 smmd=0.2525 ct=7.2369 rec=1.3064 | train/val/test=0.823/0.817/0.813 | c=0.500000
[Epoch 0061] loss=17.9893 cls=0.4653 smmd=0.2666 ct=7.2152 rec=1.3203 | train/val/test=0.784/0.786/0.780 | c=0.500000
[Epoch 0062] loss=17.8794 cls=0.5104 smmd=0.2488 ct=7.2346 rec=1.3350 | train/val/test=0.829/0.826/0.814 | c=0.500000
[Epoch 0063] loss=17.6513 cls=0.4849 smmd=0.2356 ct=7.1967 rec=1.3194 | train/val/test=0.830/0.830/0.831 | c=0.500000
[Epoch 0064] loss=17.5378 cls=0.4494 smmd=0.2276 ct=7.1884 rec=1.3200 | train/val/test=0.828/0.834/0.825 | c=0.500000
[Epoch 0065] loss=17.4905 cls=0.4609 smmd=0.2170 ct=7.2172 rec=1.3122 | train/val/test=0.832/0.829/0.821 | c=0.500000
[Epoch 0066] loss=17.4329 cls=0.4519 smmd=0.2196 ct=7.1769 rec=1.3135 | train/val/test=0.820/0.823/0.819 | c=0.500000
[Epoch 0067] loss=17.4245 cls=0.4602 smmd=0.2179 ct=7.1794 rec=1.3136 | train/val/test=0.830/0.832/0.823 | c=0.500000
[Epoch 0068] loss=17.5546 cls=0.4670 smmd=0.2264 ct=7.2006 rec=1.3121 | train/val/test=0.821/0.830/0.820 | c=0.500000
[Epoch 0069] loss=17.7411 cls=0.4702 smmd=0.2455 ct=7.1951 rec=1.3225 | train/val/test=0.829/0.836/0.825 | c=0.500000
[Epoch 0070] loss=17.7775 cls=0.4846 smmd=0.2444 ct=7.2158 rec=1.3188 | train/val/test=0.823/0.827/0.820 | c=0.500000
[Epoch 0071] loss=17.7905 cls=0.4777 smmd=0.2485 ct=7.2009 rec=1.3299 | train/val/test=0.830/0.830/0.821 | c=0.500000
[Epoch 0072] loss=17.6582 cls=0.4896 smmd=0.2344 ct=7.2044 rec=1.3206 | train/val/test=0.828/0.827/0.825 | c=0.500000
[Epoch 0073] loss=17.6034 cls=0.4657 smmd=0.2309 ct=7.1993 rec=1.3264 | train/val/test=0.831/0.835/0.818 | c=0.500000
[Epoch 0074] loss=17.5532 cls=0.4712 smmd=0.2281 ct=7.1895 rec=1.3159 | train/val/test=0.825/0.826/0.827 | c=0.500000
[Epoch 0075] loss=17.4942 cls=0.4577 smmd=0.2193 ct=7.2064 rec=1.3182 | train/val/test=0.824/0.826/0.811 | c=0.500000
[Epoch 0076] loss=17.4720 cls=0.4613 smmd=0.2227 ct=7.1784 rec=1.3150 | train/val/test=0.815/0.817/0.810 | c=0.500000
[Epoch 0077] loss=17.4787 cls=0.4800 smmd=0.2201 ct=7.1894 rec=1.3168 | train/val/test=0.808/0.808/0.793 | c=0.500000
[Epoch 0078] loss=17.6403 cls=0.4875 smmd=0.2321 ct=7.2068 rec=1.3246 | train/val/test=0.790/0.786/0.787 | c=0.500000
[Epoch 0079] loss=17.8395 cls=0.5427 smmd=0.2499 ct=7.2018 rec=1.3305 | train/val/test=0.770/0.773/0.758 | c=0.500000
[Epoch 0080] loss=18.0745 cls=0.5460 smmd=0.2597 ct=7.2674 rec=1.3405 | train/val/test=0.768/0.762/0.769 | c=0.500000
[Epoch 0081] loss=18.0465 cls=0.5938 smmd=0.2645 ct=7.2170 rec=1.3409 | train/val/test=0.803/0.800/0.787 | c=0.500000
[Epoch 0082] loss=17.7846 cls=0.4995 smmd=0.2376 ct=7.2497 rec=1.3189 | train/val/test=0.810/0.808/0.812 | c=0.500000
[Epoch 0083] loss=17.5191 cls=0.4735 smmd=0.2238 ct=7.1950 rec=1.3077 | train/val/test=0.832/0.837/0.826 | c=0.500000
[Epoch 0084] loss=17.5131 cls=0.4368 smmd=0.2232 ct=7.2079 rec=1.2947 | train/val/test=0.831/0.833/0.826 | c=0.500000
[Epoch 0085] loss=17.6236 cls=0.4289 smmd=0.2293 ct=7.2327 rec=1.3021 | train/val/test=0.828/0.833/0.824 | c=0.500000
[Epoch 0086] loss=17.5722 cls=0.4493 smmd=0.2310 ct=7.1930 rec=1.3035 | train/val/test=0.836/0.835/0.823 | c=0.500000
[Epoch 0087] loss=17.5034 cls=0.4397 smmd=0.2249 ct=7.1905 rec=1.3069 | train/val/test=0.836/0.832/0.828 | c=0.500000
[Epoch 0088] loss=17.6195 cls=0.4413 smmd=0.2345 ct=7.1995 rec=1.3101 | train/val/test=0.836/0.836/0.826 | c=0.500000
[Epoch 0089] loss=17.8001 cls=0.4495 smmd=0.2485 ct=7.2178 rec=1.3098 | train/val/test=0.833/0.833/0.828 | c=0.500000
[Epoch 0090] loss=17.8181 cls=0.4426 smmd=0.2506 ct=7.2173 rec=1.3133 | train/val/test=0.833/0.839/0.827 | c=0.500000
[Epoch 0091] loss=17.6385 cls=0.4520 smmd=0.2336 ct=7.2115 rec=1.3076 | train/val/test=0.825/0.827/0.826 | c=0.500000
[Epoch 0092] loss=17.4475 cls=0.4448 smmd=0.2209 ct=7.1802 rec=1.3107 | train/val/test=0.829/0.834/0.817 | c=0.500000
[Epoch 0093] loss=17.4786 cls=0.4636 smmd=0.2187 ct=7.2027 rec=1.3084 | train/val/test=0.811/0.810/0.814 | c=0.500000
[Epoch 0094] loss=17.6598 cls=0.4776 smmd=0.2335 ct=7.2134 rec=1.3183 | train/val/test=0.809/0.810/0.792 | c=0.500000
[Epoch 0095] loss=17.8252 cls=0.5174 smmd=0.2430 ct=7.2384 rec=1.3192 | train/val/test=0.784/0.781/0.779 | c=0.500000
[Epoch 0096] loss=17.8564 cls=0.5426 smmd=0.2425 ct=7.2454 rec=1.3381 | train/val/test=0.762/0.766/0.748 | c=0.500000
[Epoch 0097] loss=17.9919 cls=0.5944 smmd=0.2550 ct=7.2395 rec=1.3317 | train/val/test=0.754/0.745/0.749 | c=0.500000
[Epoch 0098] loss=18.1530 cls=0.6059 smmd=0.2612 ct=7.2809 rec=1.3530 | train/val/test=0.774/0.778/0.757 | c=0.500000
[Epoch 0099] loss=18.0221 cls=0.5536 smmd=0.2568 ct=7.2574 rec=1.3259 | train/val/test=0.807/0.811/0.806 | c=0.500000
=== Best @ epoch 43: val=0.8402, test=0.8349 ===
