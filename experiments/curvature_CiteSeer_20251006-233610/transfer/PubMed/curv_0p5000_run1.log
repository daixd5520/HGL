Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=81.0684 cls=1.0982 smmd=6.5278 ct=7.2673 rec=1.4136 | train/val/test=0.392/0.385/0.403 | c=0.500000
[Epoch 0001] loss=72.1470 cls=1.0557 smmd=5.6389 ct=7.2604 rec=1.4192 | train/val/test=0.407/0.400/0.392 | c=0.500000
[Epoch 0002] loss=40.7805 cls=1.0537 smmd=2.5194 ct=7.1765 rec=1.4142 | train/val/test=0.534/0.530/0.543 | c=0.500000
[Epoch 0003] loss=45.6809 cls=1.0330 smmd=3.0314 ct=7.0724 rec=1.4118 | train/val/test=0.627/0.613/0.629 | c=0.500000
[Epoch 0004] loss=45.4122 cls=0.9203 smmd=3.0470 ct=6.8893 rec=1.4061 | train/val/test=0.673/0.661/0.681 | c=0.500000
[Epoch 0005] loss=35.2842 cls=0.8286 smmd=2.0549 ct=6.8129 rec=1.3901 | train/val/test=0.694/0.686/0.698 | c=0.500000
[Epoch 0006] loss=27.8803 cls=0.7633 smmd=1.3223 ct=6.7951 rec=1.3706 | train/val/test=0.689/0.683/0.691 | c=0.500000
[Epoch 0007] loss=32.2692 cls=0.7142 smmd=1.7610 ct=6.8121 rec=1.3569 | train/val/test=0.711/0.710/0.717 | c=0.500000
[Epoch 0008] loss=34.5610 cls=0.6642 smmd=1.9940 ct=6.8087 rec=1.3429 | train/val/test=0.730/0.725/0.733 | c=0.500000
[Epoch 0009] loss=32.1357 cls=0.6224 smmd=1.7593 ct=6.7825 rec=1.3334 | train/val/test=0.759/0.753/0.761 | c=0.500000
[Epoch 0010] loss=27.5780 cls=0.5816 smmd=1.3095 ct=6.7635 rec=1.3300 | train/val/test=0.794/0.793/0.795 | c=0.500000
[Epoch 0011] loss=24.3184 cls=0.5488 smmd=0.9886 ct=6.7473 rec=1.3266 | train/val/test=0.803/0.805/0.804 | c=0.500000
[Epoch 0012] loss=25.0283 cls=0.5397 smmd=1.0606 ct=6.7462 rec=1.3209 | train/val/test=0.809/0.814/0.806 | c=0.500000
[Epoch 0013] loss=27.1555 cls=0.5320 smmd=1.2742 ct=6.7439 rec=1.3189 | train/val/test=0.804/0.808/0.801 | c=0.500000
[Epoch 0014] loss=24.6276 cls=0.5177 smmd=1.0228 ct=6.7412 rec=1.3157 | train/val/test=0.804/0.806/0.802 | c=0.500000
[Epoch 0015] loss=21.5496 cls=0.5042 smmd=0.7178 ct=6.7334 rec=1.3059 | train/val/test=0.806/0.809/0.802 | c=0.500000
[Epoch 0016] loss=22.4095 cls=0.4944 smmd=0.8048 ct=6.7319 rec=1.3005 | train/val/test=0.817/0.818/0.812 | c=0.500000
[Epoch 0017] loss=22.6307 cls=0.4735 smmd=0.8319 ct=6.7156 rec=1.2886 | train/val/test=0.821/0.830/0.818 | c=0.500000
[Epoch 0018] loss=21.2655 cls=0.4626 smmd=0.6967 ct=6.7129 rec=1.2820 | train/val/test=0.827/0.832/0.821 | c=0.500000
[Epoch 0019] loss=19.7207 cls=0.4579 smmd=0.5430 ct=6.7112 rec=1.2778 | train/val/test=0.827/0.828/0.819 | c=0.500000
[Epoch 0020] loss=19.5023 cls=0.4522 smmd=0.5220 ct=6.7093 rec=1.2756 | train/val/test=0.831/0.829/0.824 | c=0.500000
[Epoch 0021] loss=20.1475 cls=0.4350 smmd=0.5875 ct=6.7080 rec=1.2780 | train/val/test=0.833/0.832/0.827 | c=0.500000
[Epoch 0022] loss=19.8439 cls=0.4265 smmd=0.5578 ct=6.7060 rec=1.2818 | train/val/test=0.833/0.832/0.829 | c=0.500000
[Epoch 0023] loss=19.0619 cls=0.4239 smmd=0.4791 ct=6.7080 rec=1.2863 | train/val/test=0.833/0.832/0.830 | c=0.500000
[Epoch 0024] loss=19.1636 cls=0.4231 smmd=0.4878 ct=6.7138 rec=1.2923 | train/val/test=0.834/0.836/0.831 | c=0.500000
[Epoch 0025] loss=19.5706 cls=0.4224 smmd=0.5287 ct=6.7127 rec=1.2940 | train/val/test=0.833/0.828/0.831 | c=0.500000
[Epoch 0026] loss=19.2128 cls=0.4226 smmd=0.4939 ct=6.7070 rec=1.2966 | train/val/test=0.838/0.838/0.835 | c=0.500000
[Epoch 0027] loss=18.4337 cls=0.4162 smmd=0.4177 ct=6.7002 rec=1.2965 | train/val/test=0.838/0.837/0.835 | c=0.500000
[Epoch 0028] loss=18.0885 cls=0.4118 smmd=0.3838 ct=6.6993 rec=1.2926 | train/val/test=0.842/0.840/0.837 | c=0.500000
[Epoch 0029] loss=18.0315 cls=0.4144 smmd=0.3796 ct=6.6915 rec=1.2912 | train/val/test=0.838/0.839/0.836 | c=0.500000
[Epoch 0030] loss=17.6641 cls=0.4101 smmd=0.3436 ct=6.6895 rec=1.2874 | train/val/test=0.841/0.839/0.837 | c=0.500000
[Epoch 0031] loss=18.7358 cls=0.4091 smmd=0.3084 ct=7.4015 rec=1.2889 | train/val/test=0.831/0.830/0.827 | c=0.500000
[Epoch 0032] loss=18.7565 cls=0.4284 smmd=0.3338 ct=7.2806 rec=1.2859 | train/val/test=0.840/0.841/0.836 | c=0.500000
[Epoch 0033] loss=18.8335 cls=0.4051 smmd=0.3326 ct=7.3298 rec=1.2905 | train/val/test=0.838/0.836/0.831 | c=0.500000
[Epoch 0034] loss=18.7661 cls=0.4078 smmd=0.3251 ct=7.3325 rec=1.2915 | train/val/test=0.838/0.838/0.836 | c=0.500000
[Epoch 0035] loss=18.7518 cls=0.4101 smmd=0.3272 ct=7.3135 rec=1.2965 | train/val/test=0.834/0.832/0.829 | c=0.500000
[Epoch 0036] loss=18.8353 cls=0.4166 smmd=0.3294 ct=7.3418 rec=1.2984 | train/val/test=0.839/0.839/0.835 | c=0.500000
[Epoch 0037] loss=18.8201 cls=0.4132 smmd=0.3359 ct=7.3025 rec=1.2985 | train/val/test=0.829/0.828/0.828 | c=0.500000
[Epoch 0038] loss=18.6080 cls=0.4288 smmd=0.3109 ct=7.3169 rec=1.3020 | train/val/test=0.833/0.836/0.834 | c=0.500000
[Epoch 0039] loss=18.4143 cls=0.4303 smmd=0.2928 ct=7.3095 rec=1.3043 | train/val/test=0.816/0.813/0.810 | c=0.500000
[Epoch 0040] loss=18.3647 cls=0.4621 smmd=0.2871 ct=7.3047 rec=1.3059 | train/val/test=0.820/0.825/0.816 | c=0.500000
[Epoch 0041] loss=18.2664 cls=0.4596 smmd=0.2762 ct=7.3092 rec=1.3122 | train/val/test=0.807/0.802/0.801 | c=0.500000
[Epoch 0042] loss=18.1545 cls=0.4870 smmd=0.2647 ct=7.3043 rec=1.3099 | train/val/test=0.827/0.827/0.824 | c=0.500000
[Epoch 0043] loss=18.0665 cls=0.4447 smmd=0.2586 ct=7.3015 rec=1.3096 | train/val/test=0.832/0.834/0.824 | c=0.500000
[Epoch 0044] loss=17.9794 cls=0.4283 smmd=0.2552 ct=7.2820 rec=1.2987 | train/val/test=0.842/0.843/0.837 | c=0.500000
[Epoch 0045] loss=17.9733 cls=0.4129 smmd=0.2554 ct=7.2809 rec=1.3013 | train/val/test=0.844/0.842/0.839 | c=0.500000
[Epoch 0046] loss=17.9944 cls=0.4189 smmd=0.2591 ct=7.2714 rec=1.3032 | train/val/test=0.833/0.836/0.826 | c=0.500000
[Epoch 0047] loss=18.0921 cls=0.4354 smmd=0.2668 ct=7.2758 rec=1.3103 | train/val/test=0.821/0.819/0.812 | c=0.500000
[Epoch 0048] loss=18.1703 cls=0.4658 smmd=0.2736 ct=7.2708 rec=1.3195 | train/val/test=0.790/0.785/0.792 | c=0.500000
[Epoch 0049] loss=18.2614 cls=0.5190 smmd=0.2767 ct=7.2832 rec=1.3360 | train/val/test=0.729/0.729/0.715 | c=0.500000
[Epoch 0050] loss=18.4251 cls=0.6085 smmd=0.2831 ct=7.3076 rec=1.3485 | train/val/test=0.745/0.734/0.752 | c=0.500000
[Epoch 0051] loss=18.4293 cls=0.6278 smmd=0.2819 ct=7.3091 rec=1.3568 | train/val/test=0.797/0.804/0.786 | c=0.500000
[Epoch 0052] loss=17.9503 cls=0.5083 smmd=0.2477 ct=7.2795 rec=1.3206 | train/val/test=0.835/0.840/0.831 | c=0.500000
[Epoch 0053] loss=17.5337 cls=0.4182 smmd=0.2165 ct=7.2562 rec=1.2945 | train/val/test=0.819/0.819/0.813 | c=0.500000
[Epoch 0054] loss=17.6800 cls=0.4551 smmd=0.2297 ct=7.2518 rec=1.3028 | train/val/test=0.808/0.816/0.797 | c=0.500000
[Epoch 0055] loss=17.9317 cls=0.4899 smmd=0.2476 ct=7.2766 rec=1.3156 | train/val/test=0.823/0.827/0.818 | c=0.500000
[Epoch 0056] loss=17.8662 cls=0.4528 smmd=0.2482 ct=7.2515 rec=1.3092 | train/val/test=0.837/0.839/0.835 | c=0.500000
[Epoch 0057] loss=17.7945 cls=0.4354 smmd=0.2462 ct=7.2305 rec=1.3084 | train/val/test=0.833/0.838/0.830 | c=0.500000
[Epoch 0058] loss=17.8866 cls=0.4555 smmd=0.2523 ct=7.2390 rec=1.3160 | train/val/test=0.816/0.823/0.813 | c=0.500000
[Epoch 0059] loss=18.0154 cls=0.4792 smmd=0.2601 ct=7.2555 rec=1.3281 | train/val/test=0.791/0.798/0.778 | c=0.500000
[Epoch 0060] loss=18.0684 cls=0.5262 smmd=0.2662 ct=7.2386 rec=1.3324 | train/val/test=0.804/0.808/0.803 | c=0.500000
[Epoch 0061] loss=17.8919 cls=0.4954 smmd=0.2447 ct=7.2652 rec=1.3338 | train/val/test=0.820/0.824/0.817 | c=0.500000
[Epoch 0062] loss=17.6349 cls=0.4800 smmd=0.2302 ct=7.2174 rec=1.3168 | train/val/test=0.836/0.836/0.831 | c=0.500000
[Epoch 0063] loss=17.4832 cls=0.4311 smmd=0.2160 ct=7.2261 rec=1.3103 | train/val/test=0.828/0.829/0.824 | c=0.500000
[Epoch 0064] loss=17.5309 cls=0.4477 smmd=0.2209 ct=7.2228 rec=1.3045 | train/val/test=0.825/0.826/0.815 | c=0.500000
[Epoch 0065] loss=17.6583 cls=0.4581 smmd=0.2295 ct=7.2375 rec=1.3193 | train/val/test=0.815/0.810/0.810 | c=0.500000
[Epoch 0066] loss=17.7291 cls=0.4790 smmd=0.2411 ct=7.2108 rec=1.3132 | train/val/test=0.815/0.817/0.805 | c=0.500000
[Epoch 0067] loss=17.8385 cls=0.4819 smmd=0.2425 ct=7.2538 rec=1.3305 | train/val/test=0.801/0.800/0.801 | c=0.500000
[Epoch 0068] loss=18.0890 cls=0.5236 smmd=0.2724 ct=7.2213 rec=1.3212 | train/val/test=0.763/0.757/0.742 | c=0.500000
[Epoch 0069] loss=18.4570 cls=0.5693 smmd=0.2806 ct=7.3432 rec=1.3597 | train/val/test=0.754/0.758/0.769 | c=0.500000
[Epoch 0070] loss=18.6173 cls=0.6285 smmd=0.3091 ct=7.2747 rec=1.3253 | train/val/test=0.815/0.810/0.805 | c=0.500000
[Epoch 0071] loss=17.9405 cls=0.4841 smmd=0.2469 ct=7.2833 rec=1.3266 | train/val/test=0.832/0.832/0.826 | c=0.500000
[Epoch 0072] loss=17.4340 cls=0.4381 smmd=0.2147 ct=7.2106 rec=1.2932 | train/val/test=0.827/0.826/0.820 | c=0.500000
[Epoch 0073] loss=17.5623 cls=0.4479 smmd=0.2259 ct=7.2158 rec=1.2962 | train/val/test=0.830/0.828/0.824 | c=0.500000
[Epoch 0074] loss=17.7446 cls=0.4360 smmd=0.2338 ct=7.2674 rec=1.3071 | train/val/test=0.827/0.826/0.819 | c=0.500000
[Epoch 0075] loss=17.6638 cls=0.4483 smmd=0.2362 ct=7.2137 rec=1.3007 | train/val/test=0.834/0.829/0.829 | c=0.500000
[Epoch 0076] loss=17.6359 cls=0.4289 smmd=0.2354 ct=7.2072 rec=1.3055 | train/val/test=0.834/0.832/0.828 | c=0.500000
[Epoch 0077] loss=17.8873 cls=0.4326 smmd=0.2521 ct=7.2473 rec=1.3099 | train/val/test=0.828/0.830/0.825 | c=0.500000
[Epoch 0078] loss=18.0640 cls=0.4456 smmd=0.2722 ct=7.2312 rec=1.3134 | train/val/test=0.834/0.831/0.830 | c=0.500000
[Epoch 0079] loss=17.8547 cls=0.4341 smmd=0.2518 ct=7.2323 rec=1.3106 | train/val/test=0.829/0.824/0.823 | c=0.500000
[Epoch 0080] loss=17.6000 cls=0.4389 smmd=0.2289 ct=7.2177 rec=1.3126 | train/val/test=0.831/0.830/0.825 | c=0.500000
[Epoch 0081] loss=17.5298 cls=0.4486 smmd=0.2263 ct=7.1951 rec=1.3054 | train/val/test=0.825/0.823/0.811 | c=0.500000
[Epoch 0082] loss=17.5647 cls=0.4453 smmd=0.2217 ct=7.2339 rec=1.3142 | train/val/test=0.831/0.831/0.824 | c=0.500000
[Epoch 0083] loss=17.4777 cls=0.4514 smmd=0.2223 ct=7.1886 rec=1.3041 | train/val/test=0.833/0.828/0.823 | c=0.500000
[Epoch 0084] loss=17.3999 cls=0.4315 smmd=0.2124 ct=7.2027 rec=1.3092 | train/val/test=0.837/0.836/0.830 | c=0.500000
[Epoch 0085] loss=17.4807 cls=0.4311 smmd=0.2225 ct=7.1934 rec=1.3060 | train/val/test=0.835/0.833/0.831 | c=0.500000
[Epoch 0086] loss=17.6688 cls=0.4308 smmd=0.2381 ct=7.2087 rec=1.3092 | train/val/test=0.838/0.833/0.830 | c=0.500000
[Epoch 0087] loss=17.8654 cls=0.4287 smmd=0.2519 ct=7.2386 rec=1.3095 | train/val/test=0.838/0.834/0.830 | c=0.500000
[Epoch 0088] loss=17.9168 cls=0.4246 smmd=0.2559 ct=7.2458 rec=1.3079 | train/val/test=0.831/0.832/0.827 | c=0.500000
[Epoch 0089] loss=17.9769 cls=0.4401 smmd=0.2605 ct=7.2485 rec=1.3088 | train/val/test=0.803/0.801/0.788 | c=0.500000
[Epoch 0090] loss=18.0086 cls=0.4843 smmd=0.2487 ct=7.3085 rec=1.3244 | train/val/test=0.732/0.720/0.736 | c=0.500000
[Epoch 0091] loss=18.3012 cls=0.6834 smmd=0.2748 ct=7.2651 rec=1.3620 | train/val/test=0.611/0.615/0.592 | c=0.500000
[Epoch 0092] loss=18.7029 cls=0.8937 smmd=0.2848 ct=7.3595 rec=1.3788 | train/val/test=0.684/0.672/0.691 | c=0.500000
[Epoch 0093] loss=18.6735 cls=0.8501 smmd=0.2910 ct=7.3236 rec=1.3831 | train/val/test=0.795/0.802/0.785 | c=0.500000
[Epoch 0094] loss=18.1174 cls=0.5664 smmd=0.2608 ct=7.2870 rec=1.3043 | train/val/test=0.829/0.828/0.823 | c=0.500000
[Epoch 0095] loss=17.5595 cls=0.4294 smmd=0.2135 ct=7.2827 rec=1.2892 | train/val/test=0.784/0.783/0.785 | c=0.500000
[Epoch 0096] loss=17.9985 cls=0.5588 smmd=0.2565 ct=7.2507 rec=1.3053 | train/val/test=0.811/0.821/0.801 | c=0.500000
[Epoch 0097] loss=18.2373 cls=0.5117 smmd=0.2720 ct=7.3051 rec=1.3020 | train/val/test=0.831/0.826/0.824 | c=0.500000
[Epoch 0098] loss=18.0283 cls=0.4277 smmd=0.2606 ct=7.2793 rec=1.2991 | train/val/test=0.814/0.819/0.803 | c=0.500000
[Epoch 0099] loss=18.1388 cls=0.4794 smmd=0.2758 ct=7.2446 rec=1.3042 | train/val/test=0.786/0.793/0.774 | c=0.500000
=== Best @ epoch 44: val=0.8425, test=0.8370 ===
