Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=81.2083 cls=1.1213 smmd=6.5410 ct=7.2653 rec=1.4139 | train/val/test=0.403/0.403/0.383 | c=1.498601
[Epoch 0001] loss=72.5165 cls=1.0634 smmd=5.6767 ct=7.2552 rec=1.4154 | train/val/test=0.461/0.468/0.448 | c=1.498601
[Epoch 0002] loss=41.1024 cls=1.0656 smmd=2.5591 ct=7.1358 rec=1.4140 | train/val/test=0.447/0.452/0.447 | c=1.498601
[Epoch 0003] loss=46.4314 cls=1.0649 smmd=3.0929 ct=7.1319 rec=1.4123 | train/val/test=0.634/0.640/0.629 | c=1.498601
[Epoch 0004] loss=45.9638 cls=0.9448 smmd=3.1042 ct=6.8724 rec=1.4086 | train/val/test=0.671/0.671/0.663 | c=1.498601
[Epoch 0005] loss=36.0575 cls=0.8459 smmd=2.1289 ct=6.8234 rec=1.3977 | train/val/test=0.675/0.682/0.668 | c=1.498601
[Epoch 0006] loss=28.4068 cls=0.7688 smmd=1.3747 ct=6.7928 rec=1.3799 | train/val/test=0.677/0.681/0.672 | c=1.498601
[Epoch 0007] loss=32.2177 cls=0.7260 smmd=1.7594 ct=6.7900 rec=1.3615 | train/val/test=0.683/0.685/0.681 | c=1.498601
[Epoch 0008] loss=34.8305 cls=0.6887 smmd=2.0243 ct=6.7854 rec=1.3447 | train/val/test=0.696/0.698/0.694 | c=1.498601
[Epoch 0009] loss=32.8255 cls=0.6614 smmd=1.8272 ct=6.7782 rec=1.3338 | train/val/test=0.714/0.717/0.708 | c=1.498601
[Epoch 0010] loss=28.3190 cls=0.6364 smmd=1.3808 ct=6.7643 rec=1.3283 | train/val/test=0.734/0.736/0.733 | c=1.498601
[Epoch 0011] loss=24.6385 cls=0.6093 smmd=1.0170 ct=6.7507 rec=1.3250 | train/val/test=0.761/0.764/0.760 | c=1.498601
[Epoch 0012] loss=25.1101 cls=0.5933 smmd=1.0644 ct=6.7526 rec=1.3275 | train/val/test=0.792/0.787/0.793 | c=1.498601
[Epoch 0013] loss=27.4725 cls=0.5708 smmd=1.3025 ct=6.7483 rec=1.3310 | train/val/test=0.799/0.796/0.809 | c=1.498601
[Epoch 0014] loss=25.2275 cls=0.5478 smmd=1.0827 ct=6.7324 rec=1.3246 | train/val/test=0.804/0.800/0.811 | c=1.498601
[Epoch 0015] loss=21.8008 cls=0.5250 smmd=0.7441 ct=6.7193 rec=1.3173 | train/val/test=0.805/0.801/0.809 | c=1.498601
[Epoch 0016] loss=22.5440 cls=0.5077 smmd=0.8202 ct=6.7161 rec=1.3118 | train/val/test=0.810/0.808/0.813 | c=1.498601
[Epoch 0017] loss=24.2092 cls=0.4870 smmd=0.8526 ct=7.3939 rec=1.3042 | train/val/test=0.819/0.818/0.819 | c=1.498601
[Epoch 0018] loss=22.8718 cls=0.4681 smmd=0.7461 ct=7.2649 rec=1.2939 | train/val/test=0.821/0.821/0.824 | c=1.498601
[Epoch 0019] loss=21.3072 cls=0.4636 smmd=0.5875 ct=7.2780 rec=1.2885 | train/val/test=0.823/0.823/0.824 | c=1.498601
[Epoch 0020] loss=20.9485 cls=0.4534 smmd=0.5395 ct=7.3418 rec=1.2862 | train/val/test=0.826/0.826/0.833 | c=1.498601
[Epoch 0021] loss=21.3846 cls=0.4399 smmd=0.5854 ct=7.3338 rec=1.2863 | train/val/test=0.831/0.832/0.832 | c=1.498601
[Epoch 0022] loss=21.2927 cls=0.4284 smmd=0.5809 ct=7.3124 rec=1.2887 | train/val/test=0.833/0.831/0.830 | c=1.498601
[Epoch 0023] loss=20.5460 cls=0.4255 smmd=0.5075 ct=7.3060 rec=1.2929 | train/val/test=0.831/0.830/0.828 | c=1.498601
[Epoch 0024] loss=20.3483 cls=0.4316 smmd=0.4892 ct=7.2962 rec=1.2962 | train/val/test=0.833/0.834/0.828 | c=1.498601
[Epoch 0025] loss=20.9123 cls=0.4339 smmd=0.5461 ct=7.2924 rec=1.2996 | train/val/test=0.834/0.828/0.825 | c=1.498601
[Epoch 0026] loss=20.6833 cls=0.4371 smmd=0.5245 ct=7.2841 rec=1.3035 | train/val/test=0.836/0.833/0.829 | c=1.498601
[Epoch 0027] loss=19.8896 cls=0.4362 smmd=0.4458 ct=7.2805 rec=1.3057 | train/val/test=0.830/0.824/0.823 | c=1.498601
[Epoch 0028] loss=19.5492 cls=0.4395 smmd=0.4110 ct=7.2838 rec=1.3046 | train/val/test=0.830/0.832/0.827 | c=1.498601
[Epoch 0029] loss=19.3814 cls=0.4532 smmd=0.3961 ct=7.2689 rec=1.3122 | train/val/test=0.812/0.805/0.810 | c=1.498601
[Epoch 0030] loss=19.2118 cls=0.4731 smmd=0.3725 ct=7.2967 rec=1.3143 | train/val/test=0.783/0.788/0.774 | c=1.498601
[Epoch 0031] loss=18.8957 cls=0.5158 smmd=0.3441 ct=7.2666 rec=1.3278 | train/val/test=0.777/0.772/0.777 | c=1.498601
[Epoch 0032] loss=18.8374 cls=0.5430 smmd=0.3294 ct=7.3026 rec=1.3324 | train/val/test=0.803/0.805/0.797 | c=1.498601
[Epoch 0033] loss=18.8307 cls=0.4836 smmd=0.3392 ct=7.2683 rec=1.3199 | train/val/test=0.828/0.824/0.823 | c=1.498601
[Epoch 0034] loss=18.6289 cls=0.4364 smmd=0.3225 ct=7.2672 rec=1.3017 | train/val/test=0.838/0.836/0.835 | c=1.498601
[Epoch 0035] loss=18.4743 cls=0.4104 smmd=0.3123 ct=7.2481 rec=1.2991 | train/val/test=0.839/0.835/0.838 | c=1.498601
[Epoch 0036] loss=18.6156 cls=0.4244 smmd=0.3248 ct=7.2529 rec=1.2996 | train/val/test=0.815/0.812/0.809 | c=1.498601
[Epoch 0037] loss=18.7897 cls=0.4638 smmd=0.3345 ct=7.2781 rec=1.3131 | train/val/test=0.814/0.815/0.815 | c=1.498601
[Epoch 0038] loss=18.7698 cls=0.4734 smmd=0.3366 ct=7.2551 rec=1.3136 | train/val/test=0.800/0.794/0.793 | c=1.498601
[Epoch 0039] loss=18.6143 cls=0.5010 smmd=0.3149 ct=7.2759 rec=1.3263 | train/val/test=0.808/0.808/0.809 | c=1.498601
[Epoch 0040] loss=18.4531 cls=0.4840 smmd=0.3070 ct=7.2419 rec=1.3155 | train/val/test=0.826/0.820/0.821 | c=1.498601
[Epoch 0041] loss=18.1330 cls=0.4486 smmd=0.2759 ct=7.2473 rec=1.3109 | train/val/test=0.842/0.837/0.841 | c=1.498601
[Epoch 0042] loss=17.8524 cls=0.4195 smmd=0.2537 ct=7.2271 rec=1.3032 | train/val/test=0.839/0.834/0.841 | c=1.498601
[Epoch 0043] loss=17.7686 cls=0.4332 smmd=0.2456 ct=7.2224 rec=1.3022 | train/val/test=0.833/0.825/0.831 | c=1.498601
[Epoch 0044] loss=17.8496 cls=0.4412 smmd=0.2507 ct=7.2322 rec=1.3151 | train/val/test=0.825/0.828/0.826 | c=1.498601
[Epoch 0045] loss=17.9227 cls=0.4744 smmd=0.2608 ct=7.2103 rec=1.3144 | train/val/test=0.815/0.813/0.811 | c=1.498601
[Epoch 0046] loss=17.9655 cls=0.4756 smmd=0.2573 ct=7.2453 rec=1.3280 | train/val/test=0.808/0.809/0.804 | c=1.498601
[Epoch 0047] loss=18.0653 cls=0.4977 smmd=0.2744 ct=7.2050 rec=1.3253 | train/val/test=0.802/0.797/0.798 | c=1.498601
[Epoch 0048] loss=18.1347 cls=0.5024 smmd=0.2709 ct=7.2537 rec=1.3348 | train/val/test=0.775/0.769/0.761 | c=1.498601
[Epoch 0049] loss=18.1768 cls=0.5323 smmd=0.2759 ct=7.2409 rec=1.3403 | train/val/test=0.779/0.769/0.773 | c=1.498601
[Epoch 0050] loss=18.2843 cls=0.5647 smmd=0.2802 ct=7.2660 rec=1.3355 | train/val/test=0.753/0.742/0.742 | c=1.498601
[Epoch 0051] loss=18.3110 cls=0.5701 smmd=0.2753 ct=7.2971 rec=1.3578 | train/val/test=0.784/0.784/0.783 | c=1.498601
[Epoch 0052] loss=18.1780 cls=0.5665 smmd=0.2710 ct=7.2648 rec=1.3106 | train/val/test=0.823/0.817/0.816 | c=1.498601
[Epoch 0053] loss=17.9162 cls=0.4718 smmd=0.2456 ct=7.2839 rec=1.3136 | train/val/test=0.829/0.832/0.831 | c=1.498601
[Epoch 0054] loss=17.6847 cls=0.4541 smmd=0.2334 ct=7.2372 rec=1.2992 | train/val/test=0.817/0.817/0.817 | c=1.498601
[Epoch 0055] loss=17.7183 cls=0.4759 smmd=0.2386 ct=7.2215 rec=1.3021 | train/val/test=0.836/0.828/0.824 | c=1.498601
[Epoch 0056] loss=17.8389 cls=0.4565 smmd=0.2414 ct=7.2693 rec=1.3161 | train/val/test=0.826/0.832/0.831 | c=1.498601
[Epoch 0057] loss=17.8680 cls=0.4847 smmd=0.2532 ct=7.2196 rec=1.3088 | train/val/test=0.808/0.798/0.802 | c=1.498601
[Epoch 0058] loss=17.9198 cls=0.4833 smmd=0.2520 ct=7.2473 rec=1.3279 | train/val/test=0.796/0.798/0.794 | c=1.498601
[Epoch 0059] loss=18.0292 cls=0.5061 smmd=0.2658 ct=7.2268 rec=1.3293 | train/val/test=0.763/0.751/0.762 | c=1.498601
[Epoch 0060] loss=18.0343 cls=0.5391 smmd=0.2606 ct=7.2451 rec=1.3372 | train/val/test=0.814/0.810/0.810 | c=1.498601
[Epoch 0061] loss=17.8263 cls=0.4768 smmd=0.2459 ct=7.2325 rec=1.3285 | train/val/test=0.821/0.818/0.821 | c=1.498601
[Epoch 0062] loss=17.6243 cls=0.4618 smmd=0.2307 ct=7.2149 rec=1.3141 | train/val/test=0.834/0.834/0.833 | c=1.498601
[Epoch 0063] loss=17.5856 cls=0.4314 smmd=0.2265 ct=7.2258 rec=1.3069 | train/val/test=0.835/0.830/0.830 | c=1.498601
[Epoch 0064] loss=17.5735 cls=0.4350 smmd=0.2252 ct=7.2247 rec=1.3085 | train/val/test=0.825/0.824/0.823 | c=1.498601
[Epoch 0065] loss=17.5086 cls=0.4515 smmd=0.2222 ct=7.2031 rec=1.3090 | train/val/test=0.835/0.831/0.831 | c=1.498601
[Epoch 0066] loss=17.4647 cls=0.4458 smmd=0.2186 ct=7.1995 rec=1.3136 | train/val/test=0.831/0.827/0.830 | c=1.498601
[Epoch 0067] loss=17.5574 cls=0.4554 smmd=0.2271 ct=7.2000 rec=1.3183 | train/val/test=0.838/0.834/0.836 | c=1.498601
[Epoch 0068] loss=17.7205 cls=0.4612 smmd=0.2416 ct=7.2062 rec=1.3223 | train/val/test=0.830/0.823/0.826 | c=1.498601
[Epoch 0069] loss=17.8623 cls=0.4702 smmd=0.2474 ct=7.2445 rec=1.3290 | train/val/test=0.825/0.826/0.822 | c=1.498601
[Epoch 0070] loss=17.9444 cls=0.4833 smmd=0.2552 ct=7.2438 rec=1.3269 | train/val/test=0.784/0.772/0.776 | c=1.498601
[Epoch 0071] loss=18.0238 cls=0.5372 smmd=0.2555 ct=7.2638 rec=1.3456 | train/val/test=0.738/0.744/0.734 | c=1.498601
[Epoch 0072] loss=18.0903 cls=0.5982 smmd=0.2561 ct=7.2789 rec=1.3453 | train/val/test=0.760/0.753/0.757 | c=1.498601
[Epoch 0073] loss=17.9174 cls=0.5949 smmd=0.2458 ct=7.2453 rec=1.3434 | train/val/test=0.812/0.812/0.807 | c=1.498601
[Epoch 0074] loss=17.6382 cls=0.4773 smmd=0.2233 ct=7.2552 rec=1.3132 | train/val/test=0.828/0.831/0.830 | c=1.498601
[Epoch 0075] loss=17.5041 cls=0.4318 smmd=0.2155 ct=7.2433 rec=1.2930 | train/val/test=0.815/0.810/0.810 | c=1.498601
[Epoch 0076] loss=17.6317 cls=0.4609 smmd=0.2312 ct=7.2194 rec=1.3006 | train/val/test=0.813/0.812/0.810 | c=1.498601
[Epoch 0077] loss=17.7301 cls=0.4797 smmd=0.2340 ct=7.2474 rec=1.3102 | train/val/test=0.817/0.813/0.813 | c=1.498601
[Epoch 0078] loss=17.7737 cls=0.4672 smmd=0.2435 ct=7.2250 rec=1.3110 | train/val/test=0.822/0.820/0.818 | c=1.498601
[Epoch 0079] loss=17.8839 cls=0.4653 smmd=0.2519 ct=7.2378 rec=1.3133 | train/val/test=0.832/0.826/0.832 | c=1.498601
[Epoch 0080] loss=17.9483 cls=0.4507 smmd=0.2563 ct=7.2514 rec=1.3147 | train/val/test=0.834/0.835/0.832 | c=1.498601
[Epoch 0081] loss=17.8107 cls=0.4540 smmd=0.2429 ct=7.2488 rec=1.3141 | train/val/test=0.837/0.833/0.837 | c=1.498601
[Epoch 0082] loss=17.4850 cls=0.4407 smmd=0.2224 ct=7.1924 rec=1.3125 | train/val/test=0.836/0.834/0.838 | c=1.498601
[Epoch 0083] loss=17.3747 cls=0.4432 smmd=0.2084 ct=7.2075 rec=1.3085 | train/val/test=0.836/0.832/0.832 | c=1.498601
[Epoch 0084] loss=17.4336 cls=0.4328 smmd=0.2158 ct=7.2028 rec=1.3080 | train/val/test=0.834/0.833/0.835 | c=1.498601
[Epoch 0085] loss=17.4966 cls=0.4397 smmd=0.2201 ct=7.2119 rec=1.3043 | train/val/test=0.834/0.829/0.829 | c=1.498601
[Epoch 0086] loss=17.5069 cls=0.4390 smmd=0.2224 ct=7.2051 rec=1.3070 | train/val/test=0.830/0.829/0.829 | c=1.498601
[Epoch 0087] loss=17.5202 cls=0.4449 smmd=0.2257 ct=7.1939 rec=1.3063 | train/val/test=0.833/0.825/0.827 | c=1.498601
[Epoch 0088] loss=17.6172 cls=0.4502 smmd=0.2336 ct=7.1997 rec=1.3125 | train/val/test=0.824/0.820/0.822 | c=1.498601
[Epoch 0089] loss=17.7401 cls=0.4629 smmd=0.2434 ct=7.2080 rec=1.3178 | train/val/test=0.818/0.816/0.811 | c=1.498601
[Epoch 0090] loss=17.8897 cls=0.4814 smmd=0.2514 ct=7.2356 rec=1.3274 | train/val/test=0.790/0.780/0.789 | c=1.498601
[Epoch 0091] loss=18.0217 cls=0.5315 smmd=0.2572 ct=7.2574 rec=1.3376 | train/val/test=0.756/0.756/0.744 | c=1.498601
[Epoch 0092] loss=17.9375 cls=0.5515 smmd=0.2481 ct=7.2531 rec=1.3492 | train/val/test=0.751/0.740/0.747 | c=1.498601
[Epoch 0093] loss=17.9462 cls=0.6281 smmd=0.2443 ct=7.2586 rec=1.3437 | train/val/test=0.762/0.753/0.748 | c=1.498601
[Epoch 0094] loss=17.9605 cls=0.5526 smmd=0.2451 ct=7.2795 rec=1.3482 | train/val/test=0.795/0.792/0.794 | c=1.498601
[Epoch 0095] loss=17.8520 cls=0.5346 smmd=0.2418 ct=7.2553 rec=1.3127 | train/val/test=0.834/0.828/0.828 | c=1.498601
[Epoch 0096] loss=17.5864 cls=0.4322 smmd=0.2243 ct=7.2390 rec=1.2988 | train/val/test=0.832/0.833/0.828 | c=1.498601
[Epoch 0097] loss=17.5481 cls=0.4303 smmd=0.2223 ct=7.2307 rec=1.2963 | train/val/test=0.821/0.823/0.825 | c=1.498601
[Epoch 0098] loss=17.8026 cls=0.4680 smmd=0.2477 ct=7.2213 rec=1.2986 | train/val/test=0.828/0.821/0.817 | c=1.498601
[Epoch 0099] loss=18.0781 cls=0.4592 smmd=0.2626 ct=7.2827 rec=1.3148 | train/val/test=0.821/0.827/0.827 | c=1.498601
=== Best @ epoch 41: val=0.8369, test=0.8408 ===
