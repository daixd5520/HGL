Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=81.0688 cls=1.0961 smmd=6.5281 ct=7.2666 rec=1.4137 | train/val/test=0.402/0.392/0.398 | c=1.498601
[Epoch 0001] loss=72.1261 cls=1.0548 smmd=5.6381 ct=7.2544 rec=1.4170 | train/val/test=0.561/0.553/0.553 | c=1.498601
[Epoch 0002] loss=41.3690 cls=1.0627 smmd=2.5906 ct=7.1125 rec=1.4135 | train/val/test=0.622/0.624/0.613 | c=1.498601
[Epoch 0003] loss=45.4260 cls=1.0013 smmd=3.0053 ct=7.0832 rec=1.4121 | train/val/test=0.642/0.647/0.634 | c=1.498601
[Epoch 0004] loss=45.1332 cls=0.9103 smmd=3.0195 ct=6.8910 rec=1.4027 | train/val/test=0.650/0.655/0.640 | c=1.498601
[Epoch 0005] loss=35.2443 cls=0.8201 smmd=2.0493 ct=6.8251 rec=1.3824 | train/val/test=0.657/0.664/0.650 | c=1.498601
[Epoch 0006] loss=29.5447 cls=0.7708 smmd=1.3497 ct=7.4916 rec=1.3582 | train/val/test=0.663/0.659/0.654 | c=1.498601
[Epoch 0007] loss=33.4963 cls=0.7433 smmd=1.7808 ct=7.3221 rec=1.3442 | train/val/test=0.677/0.667/0.666 | c=1.498601
[Epoch 0008] loss=35.8131 cls=0.7102 smmd=2.0226 ct=7.2819 rec=1.3367 | train/val/test=0.698/0.692/0.687 | c=1.498601
[Epoch 0009] loss=33.5993 cls=0.6512 smmd=1.8047 ct=7.2808 rec=1.3302 | train/val/test=0.734/0.733/0.723 | c=1.498601
[Epoch 0010] loss=29.1304 cls=0.6025 smmd=1.3559 ct=7.3019 rec=1.3327 | train/val/test=0.782/0.777/0.767 | c=1.498601
[Epoch 0011] loss=25.5013 cls=0.5719 smmd=0.9922 ct=7.3128 rec=1.3358 | train/val/test=0.806/0.795/0.801 | c=1.498601
[Epoch 0012] loss=26.3319 cls=0.5751 smmd=1.0698 ct=7.3389 rec=1.3369 | train/val/test=0.805/0.794/0.786 | c=1.498601
[Epoch 0013] loss=28.6710 cls=0.5710 smmd=1.3114 ct=7.2994 rec=1.3452 | train/val/test=0.790/0.779/0.783 | c=1.498601
[Epoch 0014] loss=26.1233 cls=0.5844 smmd=1.0637 ct=7.2628 rec=1.3376 | train/val/test=0.747/0.738/0.738 | c=1.498601
[Epoch 0015] loss=23.0308 cls=0.6122 smmd=0.7483 ct=7.2838 rec=1.3481 | train/val/test=0.767/0.757/0.761 | c=1.498601
[Epoch 0016] loss=24.1427 cls=0.5972 smmd=0.8572 ct=7.3058 rec=1.3205 | train/val/test=0.757/0.745/0.747 | c=1.498601
[Epoch 0017] loss=24.3497 cls=0.5927 smmd=0.8800 ct=7.2931 rec=1.3342 | train/val/test=0.798/0.784/0.790 | c=1.498601
[Epoch 0018] loss=22.5875 cls=0.5133 smmd=0.7099 ct=7.2900 rec=1.3035 | train/val/test=0.817/0.810/0.810 | c=1.498601
[Epoch 0019] loss=21.0851 cls=0.4915 smmd=0.5598 ct=7.2976 rec=1.2929 | train/val/test=0.827/0.817/0.818 | c=1.498601
[Epoch 0020] loss=20.9440 cls=0.4481 smmd=0.5486 ct=7.2937 rec=1.2922 | train/val/test=0.833/0.826/0.827 | c=1.498601
[Epoch 0021] loss=21.3906 cls=0.4402 smmd=0.5950 ct=7.2893 rec=1.2840 | train/val/test=0.830/0.826/0.825 | c=1.498601
[Epoch 0022] loss=21.1344 cls=0.4397 smmd=0.5702 ct=7.2855 rec=1.2829 | train/val/test=0.834/0.826/0.827 | c=1.498601
[Epoch 0023] loss=20.2844 cls=0.4242 smmd=0.4855 ct=7.2859 rec=1.2909 | train/val/test=0.833/0.824/0.828 | c=1.498601
[Epoch 0024] loss=20.3099 cls=0.4368 smmd=0.4889 ct=7.2784 rec=1.2910 | train/val/test=0.836/0.821/0.823 | c=1.498601
[Epoch 0025] loss=20.8130 cls=0.4358 smmd=0.5387 ct=7.2792 rec=1.2999 | train/val/test=0.834/0.830/0.826 | c=1.498601
[Epoch 0026] loss=20.4922 cls=0.4357 smmd=0.5093 ct=7.2657 rec=1.3009 | train/val/test=0.836/0.825/0.820 | c=1.498601
[Epoch 0027] loss=19.8224 cls=0.4504 smmd=0.4432 ct=7.2547 rec=1.3108 | train/val/test=0.817/0.808/0.813 | c=1.498601
[Epoch 0028] loss=19.5728 cls=0.4633 smmd=0.4159 ct=7.2637 rec=1.3099 | train/val/test=0.752/0.742/0.739 | c=1.498601
[Epoch 0029] loss=19.6216 cls=0.5571 smmd=0.4071 ct=7.3007 rec=1.3408 | train/val/test=0.754/0.745/0.741 | c=1.498601
[Epoch 0030] loss=19.5013 cls=0.6080 smmd=0.3937 ct=7.2966 rec=1.3338 | train/val/test=0.739/0.730/0.723 | c=1.498601
[Epoch 0031] loss=18.9173 cls=0.5903 smmd=0.3363 ct=7.2944 rec=1.3415 | train/val/test=0.832/0.820/0.823 | c=1.498601
[Epoch 0032] loss=18.5446 cls=0.4299 smmd=0.3192 ct=7.2459 rec=1.2926 | train/val/test=0.838/0.830/0.830 | c=1.498601
[Epoch 0033] loss=18.4960 cls=0.4142 smmd=0.3174 ct=7.2348 rec=1.2896 | train/val/test=0.804/0.793/0.794 | c=1.498601
[Epoch 0034] loss=18.6102 cls=0.4765 smmd=0.3169 ct=7.2727 rec=1.3145 | train/val/test=0.811/0.797/0.800 | c=1.498601
[Epoch 0035] loss=18.6264 cls=0.4783 smmd=0.3205 ct=7.2646 rec=1.3065 | train/val/test=0.838/0.826/0.825 | c=1.498601
[Epoch 0036] loss=18.6039 cls=0.4262 smmd=0.3228 ct=7.2554 rec=1.3031 | train/val/test=0.844/0.832/0.829 | c=1.498601
[Epoch 0037] loss=18.6109 cls=0.4135 smmd=0.3267 ct=7.2432 rec=1.3011 | train/val/test=0.832/0.820/0.824 | c=1.498601
[Epoch 0038] loss=18.5719 cls=0.4390 smmd=0.3238 ct=7.2297 rec=1.3092 | train/val/test=0.815/0.801/0.803 | c=1.498601
[Epoch 0039] loss=18.5285 cls=0.4718 smmd=0.3124 ct=7.2544 rec=1.3199 | train/val/test=0.773/0.763/0.755 | c=1.498601
[Epoch 0040] loss=18.4238 cls=0.5183 smmd=0.3023 ct=7.2386 rec=1.3287 | train/val/test=0.803/0.794/0.794 | c=1.498601
[Epoch 0041] loss=18.2145 cls=0.4972 smmd=0.2832 ct=7.2367 rec=1.3210 | train/val/test=0.808/0.795/0.800 | c=1.498601
[Epoch 0042] loss=17.9733 cls=0.4742 smmd=0.2594 ct=7.2410 rec=1.3198 | train/val/test=0.837/0.831/0.827 | c=1.498601
[Epoch 0043] loss=17.8104 cls=0.4461 smmd=0.2492 ct=7.2215 rec=1.3037 | train/val/test=0.841/0.832/0.830 | c=1.498601
[Epoch 0044] loss=17.7341 cls=0.4261 smmd=0.2415 ct=7.2267 rec=1.3056 | train/val/test=0.829/0.825/0.825 | c=1.498601
[Epoch 0045] loss=17.7609 cls=0.4466 smmd=0.2450 ct=7.2170 rec=1.3073 | train/val/test=0.837/0.832/0.825 | c=1.498601
[Epoch 0046] loss=17.8120 cls=0.4488 smmd=0.2500 ct=7.2155 rec=1.3129 | train/val/test=0.830/0.813/0.818 | c=1.498601
[Epoch 0047] loss=17.9378 cls=0.4602 smmd=0.2607 ct=7.2202 rec=1.3212 | train/val/test=0.834/0.828/0.823 | c=1.498601
[Epoch 0048] loss=18.0354 cls=0.4690 smmd=0.2690 ct=7.2253 rec=1.3198 | train/val/test=0.817/0.799/0.802 | c=1.498601
[Epoch 0049] loss=18.1308 cls=0.4901 smmd=0.2753 ct=7.2324 rec=1.3355 | train/val/test=0.809/0.799/0.808 | c=1.498601
[Epoch 0050] loss=18.1726 cls=0.5144 smmd=0.2718 ct=7.2675 rec=1.3258 | train/val/test=0.781/0.764/0.766 | c=1.498601
[Epoch 0051] loss=18.1810 cls=0.5375 smmd=0.2754 ct=7.2421 rec=1.3476 | train/val/test=0.793/0.781/0.789 | c=1.498601
[Epoch 0052] loss=17.9572 cls=0.5307 smmd=0.2464 ct=7.2828 rec=1.3240 | train/val/test=0.818/0.801/0.803 | c=1.498601
[Epoch 0053] loss=17.6846 cls=0.4672 smmd=0.2372 ct=7.2099 rec=1.3189 | train/val/test=0.837/0.831/0.825 | c=1.498601
[Epoch 0054] loss=17.5867 cls=0.4280 smmd=0.2237 ct=7.2419 rec=1.3045 | train/val/test=0.835/0.832/0.828 | c=1.498601
[Epoch 0055] loss=17.6253 cls=0.4324 smmd=0.2274 ct=7.2427 rec=1.2989 | train/val/test=0.833/0.827/0.823 | c=1.498601
[Epoch 0056] loss=17.6311 cls=0.4341 smmd=0.2335 ct=7.2128 rec=1.3068 | train/val/test=0.836/0.830/0.826 | c=1.498601
[Epoch 0057] loss=17.6133 cls=0.4433 smmd=0.2288 ct=7.2256 rec=1.3060 | train/val/test=0.830/0.825/0.823 | c=1.498601
[Epoch 0058] loss=17.7672 cls=0.4536 smmd=0.2463 ct=7.2103 rec=1.3143 | train/val/test=0.824/0.813/0.810 | c=1.498601
[Epoch 0059] loss=17.9812 cls=0.4712 smmd=0.2580 ct=7.2522 rec=1.3222 | train/val/test=0.809/0.800/0.799 | c=1.498601
[Epoch 0060] loss=18.0950 cls=0.4840 smmd=0.2692 ct=7.2500 rec=1.3213 | train/val/test=0.790/0.780/0.783 | c=1.498601
[Epoch 0061] loss=17.9872 cls=0.5104 smmd=0.2541 ct=7.2624 rec=1.3331 | train/val/test=0.787/0.775/0.774 | c=1.498601
[Epoch 0062] loss=17.8558 cls=0.5365 smmd=0.2451 ct=7.2358 rec=1.3302 | train/val/test=0.759/0.751/0.747 | c=1.498601
[Epoch 0063] loss=17.8896 cls=0.5519 smmd=0.2400 ct=7.2723 rec=1.3372 | train/val/test=0.805/0.792/0.800 | c=1.498601
[Epoch 0064] loss=17.7869 cls=0.4989 smmd=0.2378 ct=7.2529 rec=1.3067 | train/val/test=0.837/0.827/0.824 | c=1.498601
[Epoch 0065] loss=17.4876 cls=0.4235 smmd=0.2142 ct=7.2429 rec=1.2959 | train/val/test=0.835/0.827/0.823 | c=1.498601
[Epoch 0066] loss=17.4546 cls=0.4383 smmd=0.2128 ct=7.2298 rec=1.2955 | train/val/test=0.812/0.797/0.801 | c=1.498601
[Epoch 0067] loss=17.7023 cls=0.4783 smmd=0.2358 ct=7.2256 rec=1.3086 | train/val/test=0.807/0.797/0.796 | c=1.498601
[Epoch 0068] loss=17.9134 cls=0.4877 smmd=0.2485 ct=7.2626 rec=1.3186 | train/val/test=0.811/0.802/0.803 | c=1.498601
[Epoch 0069] loss=17.8906 cls=0.4896 smmd=0.2527 ct=7.2297 rec=1.3195 | train/val/test=0.827/0.817/0.812 | c=1.498601
[Epoch 0070] loss=17.7739 cls=0.4586 smmd=0.2416 ct=7.2349 rec=1.3176 | train/val/test=0.826/0.824/0.819 | c=1.498601
[Epoch 0071] loss=17.7030 cls=0.4747 smmd=0.2391 ct=7.2093 rec=1.3118 | train/val/test=0.836/0.829/0.823 | c=1.498601
[Epoch 0072] loss=17.6834 cls=0.4426 smmd=0.2313 ct=7.2458 rec=1.3142 | train/val/test=0.832/0.826/0.823 | c=1.498601
[Epoch 0073] loss=17.6234 cls=0.4608 smmd=0.2314 ct=7.2134 rec=1.3050 | train/val/test=0.834/0.827/0.822 | c=1.498601
[Epoch 0074] loss=17.4943 cls=0.4336 smmd=0.2155 ct=7.2346 rec=1.3068 | train/val/test=0.837/0.831/0.829 | c=1.498601
[Epoch 0075] loss=17.4188 cls=0.4338 smmd=0.2137 ct=7.2072 rec=1.3013 | train/val/test=0.835/0.831/0.829 | c=1.498601
[Epoch 0076] loss=17.4542 cls=0.4339 smmd=0.2166 ct=7.2098 rec=1.3033 | train/val/test=0.834/0.825/0.824 | c=1.498601
[Epoch 0077] loss=17.5501 cls=0.4371 smmd=0.2228 ct=7.2243 rec=1.3088 | train/val/test=0.838/0.834/0.829 | c=1.498601
[Epoch 0078] loss=17.6211 cls=0.4462 smmd=0.2334 ct=7.2045 rec=1.3098 | train/val/test=0.830/0.817/0.819 | c=1.498601
[Epoch 0079] loss=17.6481 cls=0.4544 smmd=0.2310 ct=7.2255 rec=1.3190 | train/val/test=0.835/0.825/0.820 | c=1.498601
[Epoch 0080] loss=17.6778 cls=0.4617 smmd=0.2378 ct=7.2052 rec=1.3178 | train/val/test=0.802/0.785/0.789 | c=1.498601
[Epoch 0081] loss=17.7588 cls=0.5019 smmd=0.2374 ct=7.2337 rec=1.3324 | train/val/test=0.761/0.748/0.744 | c=1.498601
[Epoch 0082] loss=17.9779 cls=0.5548 smmd=0.2484 ct=7.2728 rec=1.3406 | train/val/test=0.719/0.710/0.709 | c=1.498601
[Epoch 0083] loss=18.2469 cls=0.6686 smmd=0.2715 ct=7.2577 rec=1.3651 | train/val/test=0.735/0.727/0.718 | c=1.498601
[Epoch 0084] loss=18.1230 cls=0.5996 smmd=0.2475 ct=7.3379 rec=1.3452 | train/val/test=0.807/0.797/0.798 | c=1.498601
[Epoch 0085] loss=17.5863 cls=0.4886 smmd=0.2275 ct=7.2077 rec=1.3034 | train/val/test=0.829/0.823/0.819 | c=1.498601
[Epoch 0086] loss=17.4453 cls=0.4253 smmd=0.2097 ct=7.2454 rec=1.2902 | train/val/test=0.825/0.817/0.813 | c=1.498601
[Epoch 0087] loss=17.7035 cls=0.4579 smmd=0.2275 ct=7.2746 rec=1.3012 | train/val/test=0.814/0.805/0.803 | c=1.498601
[Epoch 0088] loss=17.7462 cls=0.4771 smmd=0.2453 ct=7.2004 rec=1.3080 | train/val/test=0.830/0.819/0.818 | c=1.498601
[Epoch 0089] loss=17.7261 cls=0.4506 smmd=0.2327 ct=7.2605 rec=1.3058 | train/val/test=0.831/0.826/0.824 | c=1.498601
[Epoch 0090] loss=17.9143 cls=0.4525 smmd=0.2585 ct=7.2241 rec=1.3090 | train/val/test=0.832/0.825/0.824 | c=1.498601
[Epoch 0091] loss=18.0047 cls=0.4523 smmd=0.2580 ct=7.2709 rec=1.3130 | train/val/test=0.832/0.824/0.825 | c=1.498601
[Epoch 0092] loss=17.8079 cls=0.4567 smmd=0.2454 ct=7.2349 rec=1.3112 | train/val/test=0.833/0.825/0.826 | c=1.498601
[Epoch 0093] loss=17.5140 cls=0.4462 smmd=0.2195 ct=7.2204 rec=1.3100 | train/val/test=0.829/0.823/0.822 | c=1.498601
[Epoch 0094] loss=17.4483 cls=0.4488 smmd=0.2144 ct=7.2131 rec=1.3076 | train/val/test=0.826/0.818/0.811 | c=1.498601
[Epoch 0095] loss=17.5485 cls=0.4561 smmd=0.2220 ct=7.2223 rec=1.3108 | train/val/test=0.821/0.812/0.809 | c=1.498601
[Epoch 0096] loss=17.5453 cls=0.4605 smmd=0.2225 ct=7.2183 rec=1.3074 | train/val/test=0.832/0.825/0.821 | c=1.498601
[Epoch 0097] loss=17.4797 cls=0.4481 smmd=0.2174 ct=7.2134 rec=1.3089 | train/val/test=0.828/0.820/0.819 | c=1.498601
[Epoch 0098] loss=17.5099 cls=0.4473 smmd=0.2242 ct=7.1954 rec=1.3062 | train/val/test=0.835/0.828/0.825 | c=1.498601
[Epoch 0099] loss=17.6990 cls=0.4446 smmd=0.2387 ct=7.2168 rec=1.3112 | train/val/test=0.834/0.830/0.828 | c=1.498601
=== Best @ epoch 77: val=0.8344, test=0.8289 ===
