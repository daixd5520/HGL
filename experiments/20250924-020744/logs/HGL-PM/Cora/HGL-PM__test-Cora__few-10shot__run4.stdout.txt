Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.7087 cls=1.9477 smmd=2.2675 ct=9.2136 rec=1.3889 | train/val/test=0.155/0.114/0.103 | c=0.999014
[Epoch 0001] loss=18.6097 cls=1.9417 smmd=2.1518 ct=9.2066 rec=1.3889 | train/val/test=0.293/0.166/0.182 | c=0.999014
[Epoch 0002] loss=18.4676 cls=1.9340 smmd=1.9818 ct=9.1978 rec=1.3889 | train/val/test=0.328/0.160/0.178 | c=0.999014
[Epoch 0003] loss=18.2814 cls=1.9359 smmd=1.7385 ct=9.1834 rec=1.3889 | train/val/test=0.328/0.154/0.159 | c=0.999014
[Epoch 0004] loss=18.0645 cls=1.9353 smmd=1.4729 ct=9.1601 rec=1.3889 | train/val/test=0.362/0.226/0.228 | c=0.999014
[Epoch 0005] loss=17.7757 cls=1.9266 smmd=1.1457 ct=9.1241 rec=1.3890 | train/val/test=0.448/0.272/0.293 | c=0.999014
[Epoch 0006] loss=17.4793 cls=1.9163 smmd=0.8386 ct=9.0734 rec=1.3890 | train/val/test=0.431/0.276/0.291 | c=0.999014
[Epoch 0007] loss=17.1847 cls=1.8995 smmd=0.5880 ct=9.0012 rec=1.3890 | train/val/test=0.483/0.284/0.300 | c=0.999014
[Epoch 0008] loss=16.9297 cls=1.8622 smmd=0.4369 ct=8.9295 rec=1.3889 | train/val/test=0.569/0.328/0.351 | c=0.999014
[Epoch 0009] loss=16.8413 cls=1.8660 smmd=0.4061 ct=8.8738 rec=1.3888 | train/val/test=0.724/0.440/0.435 | c=0.999014
[Epoch 0010] loss=16.7011 cls=1.7797 smmd=0.4716 ct=8.8305 rec=1.3886 | train/val/test=0.793/0.474/0.468 | c=0.999014
[Epoch 0011] loss=16.6810 cls=1.7451 smmd=0.5861 ct=8.7939 rec=1.3881 | train/val/test=0.793/0.486/0.474 | c=0.999014
[Epoch 0012] loss=16.6735 cls=1.7183 smmd=0.6961 ct=8.7612 rec=1.3870 | train/val/test=0.810/0.518/0.500 | c=0.999014
[Epoch 0013] loss=16.4233 cls=1.5309 smmd=0.7834 ct=8.7410 rec=1.3845 | train/val/test=0.845/0.564/0.549 | c=0.999014
[Epoch 0014] loss=17.0656 cls=1.3664 smmd=0.8128 ct=9.4153 rec=1.3795 | train/val/test=0.897/0.634/0.599 | c=0.999014
[Epoch 0015] loss=16.7223 cls=1.3714 smmd=0.8089 ct=9.1631 rec=1.3668 | train/val/test=0.879/0.648/0.637 | c=0.999014
[Epoch 0016] loss=16.4181 cls=1.2946 smmd=0.8361 ct=9.0315 rec=1.3438 | train/val/test=0.914/0.690/0.665 | c=0.999014
[Epoch 0017] loss=15.9523 cls=1.0472 smmd=0.8891 ct=8.9709 rec=1.3106 | train/val/test=0.931/0.710/0.731 | c=0.999014
[Epoch 0018] loss=16.5622 cls=1.5037 smmd=0.9331 ct=8.9328 rec=1.2755 | train/val/test=0.931/0.734/0.735 | c=0.999014
[Epoch 0019] loss=17.1050 cls=1.8678 smmd=0.9646 ct=8.9147 rec=1.2743 | train/val/test=0.914/0.714/0.686 | c=0.999014
[Epoch 0020] loss=16.3110 cls=1.3387 smmd=0.9647 ct=8.9113 rec=1.2768 | train/val/test=0.897/0.652/0.641 | c=0.999014
[Epoch 0021] loss=16.5021 cls=1.4438 smmd=0.9444 ct=8.9253 rec=1.2953 | train/val/test=0.914/0.682/0.656 | c=0.999014
[Epoch 0022] loss=16.4922 cls=1.4467 smmd=0.8891 ct=8.9316 rec=1.3054 | train/val/test=0.914/0.696/0.689 | c=0.999014
[Epoch 0023] loss=16.3310 cls=1.3452 smmd=0.8276 ct=8.9489 rec=1.3127 | train/val/test=0.914/0.656/0.649 | c=0.999014
[Epoch 0024] loss=16.2536 cls=1.2894 smmd=0.7522 ct=8.9790 rec=1.3252 | train/val/test=0.931/0.664/0.674 | c=0.999014
[Epoch 0025] loss=16.4029 cls=1.3914 smmd=0.6817 ct=9.0052 rec=1.3324 | train/val/test=0.914/0.718/0.743 | c=0.999014
[Epoch 0026] loss=16.6818 cls=1.5817 smmd=0.6109 ct=9.0316 rec=1.3379 | train/val/test=0.948/0.728/0.754 | c=0.999014
[Epoch 0027] loss=16.3157 cls=1.3478 smmd=0.5464 ct=9.0450 rec=1.3456 | train/val/test=0.931/0.738/0.743 | c=0.999014
[Epoch 0028] loss=16.3733 cls=1.3808 smmd=0.4889 ct=9.0774 rec=1.3496 | train/val/test=0.931/0.722/0.713 | c=0.999014
[Epoch 0029] loss=16.4729 cls=1.4588 smmd=0.4343 ct=9.0895 rec=1.3527 | train/val/test=0.948/0.704/0.686 | c=0.999014
[Epoch 0030] loss=16.4656 cls=1.4544 smmd=0.3899 ct=9.1108 rec=1.3544 | train/val/test=0.931/0.674/0.653 | c=0.999014
[Epoch 0031] loss=16.3654 cls=1.4025 smmd=0.3650 ct=9.1038 rec=1.3570 | train/val/test=0.931/0.644/0.636 | c=0.999014
[Epoch 0032] loss=16.4702 cls=1.4847 smmd=0.3416 ct=9.1002 rec=1.3586 | train/val/test=0.931/0.624/0.614 | c=0.999014
[Epoch 0033] loss=16.4344 cls=1.4704 smmd=0.3387 ct=9.0903 rec=1.3589 | train/val/test=0.931/0.608/0.601 | c=0.999014
[Epoch 0034] loss=16.4607 cls=1.4955 smmd=0.3499 ct=9.0772 rec=1.3577 | train/val/test=0.931/0.592/0.591 | c=0.999014
[Epoch 0035] loss=16.1280 cls=1.2751 smmd=0.3590 ct=9.0754 rec=1.3537 | train/val/test=0.931/0.598/0.583 | c=0.999014
[Epoch 0036] loss=16.1663 cls=1.3085 smmd=0.3739 ct=9.0623 rec=1.3505 | train/val/test=0.931/0.610/0.594 | c=0.999014
[Epoch 0037] loss=15.9529 cls=1.1708 smmd=0.3874 ct=9.0492 rec=1.3510 | train/val/test=0.931/0.614/0.599 | c=0.999014
[Epoch 0038] loss=16.5977 cls=1.5974 smmd=0.3948 ct=9.0516 rec=1.3489 | train/val/test=0.931/0.618/0.607 | c=0.999014
[Epoch 0039] loss=16.0453 cls=1.2376 smmd=0.3939 ct=9.0424 rec=1.3488 | train/val/test=0.931/0.614/0.613 | c=0.999014
[Epoch 0040] loss=15.8318 cls=1.1006 smmd=0.3907 ct=9.0446 rec=1.3435 | train/val/test=0.948/0.616/0.610 | c=0.999014
[Epoch 0041] loss=16.1295 cls=1.3009 smmd=0.3837 ct=9.0465 rec=1.3432 | train/val/test=0.948/0.620/0.613 | c=0.999014
[Epoch 0042] loss=16.3181 cls=1.4320 smmd=0.3702 ct=9.0481 rec=1.3427 | train/val/test=0.948/0.624/0.618 | c=0.999014
[Epoch 0043] loss=15.9760 cls=1.2059 smmd=0.3559 ct=9.0591 rec=1.3383 | train/val/test=0.948/0.630/0.620 | c=0.999014
[Epoch 0044] loss=15.8845 cls=1.1488 smmd=0.3425 ct=9.0626 rec=1.3375 | train/val/test=0.948/0.650/0.639 | c=0.999014
[Epoch 0045] loss=15.9597 cls=1.1977 smmd=0.3383 ct=9.0669 rec=1.3372 | train/val/test=0.966/0.670/0.661 | c=0.999014
[Epoch 0046] loss=15.9817 cls=1.2171 smmd=0.3382 ct=9.0611 rec=1.3374 | train/val/test=0.966/0.688/0.669 | c=0.999014
[Epoch 0047] loss=15.9802 cls=1.2249 smmd=0.3345 ct=9.0587 rec=1.3327 | train/val/test=0.966/0.710/0.675 | c=0.999014
[Epoch 0048] loss=15.5110 cls=0.9080 smmd=0.3400 ct=9.0624 rec=1.3313 | train/val/test=0.966/0.718/0.678 | c=0.999014
[Epoch 0049] loss=16.1122 cls=1.3197 smmd=0.3426 ct=9.0481 rec=1.3314 | train/val/test=0.966/0.726/0.678 | c=0.999014
[Epoch 0050] loss=16.0357 cls=1.2645 smmd=0.3457 ct=9.0526 rec=1.3303 | train/val/test=0.966/0.716/0.684 | c=0.999014
[Epoch 0051] loss=16.0356 cls=1.2701 smmd=0.3440 ct=9.0529 rec=1.3255 | train/val/test=0.966/0.720/0.691 | c=0.999014
[Epoch 0052] loss=15.9525 cls=1.2146 smmd=0.3441 ct=9.0520 rec=1.3263 | train/val/test=0.983/0.724/0.690 | c=0.999014
[Epoch 0053] loss=15.8392 cls=1.1510 smmd=0.3317 ct=9.0460 rec=1.3255 | train/val/test=0.966/0.728/0.698 | c=0.999014
[Epoch 0054] loss=15.7675 cls=1.0999 smmd=0.3312 ct=9.0519 rec=1.3239 | train/val/test=0.966/0.732/0.704 | c=0.999014
[Epoch 0055] loss=15.3438 cls=0.8217 smmd=0.3263 ct=9.0579 rec=1.3173 | train/val/test=0.966/0.742/0.703 | c=0.999014
[Epoch 0056] loss=15.8208 cls=1.1440 smmd=0.3165 ct=9.0595 rec=1.3163 | train/val/test=0.966/0.748/0.710 | c=0.999014
[Epoch 0057] loss=16.0928 cls=1.3230 smmd=0.3075 ct=9.0552 rec=1.3259 | train/val/test=0.966/0.750/0.709 | c=0.999014
[Epoch 0058] loss=15.6286 cls=1.0158 smmd=0.3005 ct=9.0589 rec=1.3238 | train/val/test=0.966/0.740/0.715 | c=0.999014
[Epoch 0059] loss=15.8844 cls=1.1905 smmd=0.3012 ct=9.0590 rec=1.3194 | train/val/test=0.966/0.740/0.717 | c=0.999014
[Epoch 0060] loss=15.5868 cls=0.9956 smmd=0.3005 ct=9.0574 rec=1.3178 | train/val/test=0.966/0.736/0.712 | c=0.999014
[Epoch 0061] loss=16.0018 cls=1.2625 smmd=0.3003 ct=9.0676 rec=1.3187 | train/val/test=0.966/0.726/0.713 | c=0.999014
[Epoch 0062] loss=15.9914 cls=1.2628 smmd=0.2983 ct=9.0622 rec=1.3172 | train/val/test=0.966/0.714/0.703 | c=0.999014
[Epoch 0063] loss=15.9104 cls=1.2083 smmd=0.3037 ct=9.0617 rec=1.3158 | train/val/test=0.966/0.710/0.702 | c=0.999014
[Epoch 0064] loss=15.9220 cls=1.2185 smmd=0.3011 ct=9.0593 rec=1.3165 | train/val/test=0.966/0.720/0.707 | c=0.999014
[Epoch 0065] loss=15.8041 cls=1.1358 smmd=0.3086 ct=9.0633 rec=1.3139 | train/val/test=0.966/0.728/0.711 | c=0.999014
[Epoch 0066] loss=16.0158 cls=1.2885 smmd=0.3050 ct=9.0478 rec=1.3172 | train/val/test=0.966/0.732/0.713 | c=0.999014
[Epoch 0067] loss=15.9902 cls=1.2677 smmd=0.3025 ct=9.0509 rec=1.3192 | train/val/test=0.966/0.740/0.710 | c=0.999014
[Epoch 0068] loss=15.5587 cls=0.9865 smmd=0.3018 ct=9.0464 rec=1.3170 | train/val/test=0.966/0.748/0.710 | c=0.999014
[Epoch 0069] loss=15.5768 cls=1.0012 smmd=0.3021 ct=9.0475 rec=1.3136 | train/val/test=0.966/0.736/0.710 | c=0.999014
[Epoch 0070] loss=15.5540 cls=0.9783 smmd=0.2995 ct=9.0541 rec=1.3167 | train/val/test=0.966/0.740/0.712 | c=0.999014
[Epoch 0071] loss=15.2368 cls=0.7724 smmd=0.2981 ct=9.0514 rec=1.3142 | train/val/test=0.966/0.742/0.714 | c=0.999014
[Epoch 0072] loss=15.4070 cls=0.8857 smmd=0.2938 ct=9.0505 rec=1.3170 | train/val/test=0.966/0.744/0.715 | c=0.999014
[Epoch 0073] loss=15.5187 cls=0.9599 smmd=0.2918 ct=9.0504 rec=1.3182 | train/val/test=0.966/0.744/0.714 | c=0.999014
[Epoch 0074] loss=15.7708 cls=1.1280 smmd=0.2921 ct=9.0532 rec=1.3157 | train/val/test=0.966/0.744/0.714 | c=0.999014
[Epoch 0075] loss=15.2827 cls=0.8058 smmd=0.2933 ct=9.0503 rec=1.3146 | train/val/test=0.966/0.746/0.714 | c=0.999014
[Epoch 0076] loss=15.9277 cls=1.2368 smmd=0.2890 ct=9.0545 rec=1.3122 | train/val/test=0.966/0.742/0.713 | c=0.999014
[Epoch 0077] loss=15.5083 cls=0.9548 smmd=0.2940 ct=9.0503 rec=1.3156 | train/val/test=0.966/0.746/0.711 | c=0.999014
[Epoch 0078] loss=15.6678 cls=1.0581 smmd=0.2933 ct=9.0553 rec=1.3147 | train/val/test=0.966/0.752/0.713 | c=0.999014
[Epoch 0079] loss=15.9985 cls=1.2838 smmd=0.2927 ct=9.0528 rec=1.3120 | train/val/test=0.966/0.748/0.712 | c=0.999014
[Epoch 0080] loss=15.7461 cls=1.1165 smmd=0.2898 ct=9.0504 rec=1.3144 | train/val/test=0.966/0.744/0.713 | c=0.999014
[Epoch 0081] loss=15.7020 cls=1.0865 smmd=0.2947 ct=9.0478 rec=1.3149 | train/val/test=0.966/0.742/0.712 | c=0.999014
[Epoch 0082] loss=16.0474 cls=1.3149 smmd=0.2934 ct=9.0551 rec=1.3112 | train/val/test=0.966/0.742/0.711 | c=0.999014
[Epoch 0083] loss=15.8626 cls=1.1900 smmd=0.2911 ct=9.0548 rec=1.3141 | train/val/test=0.966/0.744/0.713 | c=0.999014
[Epoch 0084] loss=15.3153 cls=0.8243 smmd=0.2919 ct=9.0551 rec=1.3142 | train/val/test=0.966/0.748/0.713 | c=0.999014
[Epoch 0085] loss=15.6710 cls=1.0688 smmd=0.2893 ct=9.0450 rec=1.3167 | train/val/test=0.966/0.748/0.712 | c=0.999014
[Epoch 0086] loss=15.7185 cls=1.0953 smmd=0.2937 ct=9.0547 rec=1.3118 | train/val/test=0.966/0.748/0.714 | c=0.999014
[Epoch 0087] loss=15.7560 cls=1.1261 smmd=0.2913 ct=9.0487 rec=1.3123 | train/val/test=0.966/0.750/0.713 | c=0.999014
[Epoch 0088] loss=15.9543 cls=1.2516 smmd=0.2946 ct=9.0467 rec=1.3188 | train/val/test=0.966/0.750/0.711 | c=0.999014
[Epoch 0089] loss=15.5219 cls=0.9716 smmd=0.2941 ct=9.0451 rec=1.3125 | train/val/test=0.966/0.750/0.710 | c=0.999014
[Epoch 0090] loss=15.8427 cls=1.1791 smmd=0.2941 ct=9.0518 rec=1.3130 | train/val/test=0.966/0.750/0.708 | c=0.999014
[Epoch 0091] loss=15.7735 cls=1.1321 smmd=0.3000 ct=9.0471 rec=1.3151 | train/val/test=0.966/0.748/0.707 | c=0.999014
[Epoch 0092] loss=15.7005 cls=1.0826 smmd=0.2936 ct=9.0515 rec=1.3151 | train/val/test=0.966/0.748/0.707 | c=0.999014
[Epoch 0093] loss=15.9136 cls=1.2292 smmd=0.2912 ct=9.0475 rec=1.3151 | train/val/test=0.966/0.748/0.706 | c=0.999014
[Epoch 0094] loss=16.0388 cls=1.3077 smmd=0.2957 ct=9.0461 rec=1.3189 | train/val/test=0.966/0.748/0.706 | c=0.999014
[Epoch 0095] loss=15.3706 cls=0.8679 smmd=0.2966 ct=9.0465 rec=1.3129 | train/val/test=0.966/0.748/0.706 | c=0.999014
[Epoch 0096] loss=15.4752 cls=0.9444 smmd=0.2925 ct=9.0441 rec=1.3103 | train/val/test=0.966/0.748/0.706 | c=0.999014
[Epoch 0097] loss=15.4965 cls=0.9516 smmd=0.2961 ct=9.0496 rec=1.3109 | train/val/test=0.966/0.748/0.706 | c=0.999014
[Epoch 0098] loss=15.3699 cls=0.8698 smmd=0.2920 ct=9.0428 rec=1.3158 | train/val/test=0.966/0.748/0.706 | c=0.999014
[Epoch 0099] loss=15.6048 cls=1.0261 smmd=0.2933 ct=9.0440 rec=1.3145 | train/val/test=0.966/0.748/0.706 | c=0.999014
=== Best @ epoch 78: val=0.7520, test=0.7130 ===
