Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.8616 cls=1.9446 smmd=2.4116 ct=9.2571 rec=1.3889 | train/val/test=0.276/0.276/0.302 | c=0.999014
[Epoch 0001] loss=18.7528 cls=1.9358 smmd=2.2806 ct=9.2542 rec=1.3889 | train/val/test=0.172/0.078/0.097 | c=0.999014
[Epoch 0002] loss=18.6347 cls=1.9402 smmd=2.1130 ct=9.2485 rec=1.3889 | train/val/test=0.172/0.072/0.092 | c=0.999014
[Epoch 0003] loss=18.4373 cls=1.9290 smmd=1.8725 ct=9.2390 rec=1.3889 | train/val/test=0.172/0.072/0.092 | c=0.999014
[Epoch 0004] loss=18.2281 cls=1.9327 smmd=1.5890 ct=9.2264 rec=1.3890 | train/val/test=0.172/0.072/0.092 | c=0.999014
[Epoch 0005] loss=17.9209 cls=1.8952 smmd=1.2746 ct=9.2026 rec=1.3891 | train/val/test=0.172/0.072/0.094 | c=0.999014
[Epoch 0006] loss=17.6475 cls=1.9050 smmd=0.9323 ct=9.1651 rec=1.3891 | train/val/test=0.276/0.122/0.158 | c=0.999014
[Epoch 0007] loss=17.3319 cls=1.8891 smmd=0.6344 ct=9.1012 rec=1.3891 | train/val/test=0.414/0.332/0.356 | c=0.999014
[Epoch 0008] loss=17.0504 cls=1.8628 smmd=0.4342 ct=9.0228 rec=1.3891 | train/val/test=0.448/0.362/0.378 | c=0.999014
[Epoch 0009] loss=16.7936 cls=1.7802 smmd=0.3633 ct=8.9589 rec=1.3890 | train/val/test=0.552/0.434/0.444 | c=0.999014
[Epoch 0010] loss=16.8094 cls=1.8158 smmd=0.3962 ct=8.9125 rec=1.3889 | train/val/test=0.621/0.486/0.487 | c=0.999014
[Epoch 0011] loss=16.6544 cls=1.7017 smmd=0.4909 ct=8.8743 rec=1.3886 | train/val/test=0.724/0.476/0.508 | c=0.999014
[Epoch 0012] loss=17.2497 cls=1.5386 smmd=0.6041 ct=9.4603 rec=1.3878 | train/val/test=0.862/0.566/0.582 | c=0.999014
[Epoch 0013] loss=16.9670 cls=1.5324 smmd=0.7305 ct=9.1845 rec=1.3857 | train/val/test=0.931/0.646/0.658 | c=0.999014
[Epoch 0014] loss=17.0622 cls=1.6403 smmd=0.8901 ct=9.0531 rec=1.3811 | train/val/test=0.966/0.646/0.682 | c=0.999014
[Epoch 0015] loss=16.4643 cls=1.2398 smmd=1.0244 ct=8.9953 rec=1.3710 | train/val/test=0.966/0.626/0.663 | c=0.999014
[Epoch 0016] loss=16.3849 cls=1.1997 smmd=1.1090 ct=8.9572 rec=1.3530 | train/val/test=1.000/0.646/0.646 | c=0.999014
[Epoch 0017] loss=16.1549 cls=1.0781 smmd=1.1469 ct=8.9321 rec=1.3270 | train/val/test=1.000/0.586/0.627 | c=0.999014
[Epoch 0018] loss=17.1563 cls=1.7630 smmd=1.1291 ct=8.9519 rec=1.3024 | train/val/test=0.966/0.586/0.667 | c=0.999014
[Epoch 0019] loss=15.7237 cls=0.7765 smmd=1.0938 ct=9.0027 rec=1.3060 | train/val/test=0.966/0.590/0.661 | c=0.999014
[Epoch 0020] loss=15.6414 cls=0.7445 smmd=1.0132 ct=9.0215 rec=1.3047 | train/val/test=0.966/0.612/0.683 | c=0.999014
[Epoch 0021] loss=15.9603 cls=1.0363 smmd=0.9094 ct=9.0037 rec=1.2903 | train/val/test=1.000/0.654/0.689 | c=0.999014
[Epoch 0022] loss=15.9705 cls=1.0779 smmd=0.8172 ct=9.0161 rec=1.2879 | train/val/test=0.966/0.618/0.628 | c=0.999014
[Epoch 0023] loss=16.4908 cls=1.4364 smmd=0.7562 ct=9.0430 rec=1.2819 | train/val/test=0.897/0.574/0.562 | c=0.999014
[Epoch 0024] loss=16.1694 cls=1.2357 smmd=0.6813 ct=9.0660 rec=1.2832 | train/val/test=0.897/0.580/0.556 | c=0.999014
[Epoch 0025] loss=16.6384 cls=1.5679 smmd=0.5991 ct=9.0738 rec=1.2944 | train/val/test=0.931/0.598/0.598 | c=0.999014
[Epoch 0026] loss=16.4583 cls=1.4444 smmd=0.5251 ct=9.0922 rec=1.3152 | train/val/test=0.966/0.548/0.604 | c=0.999014
[Epoch 0027] loss=15.9842 cls=1.0880 smmd=0.5071 ct=9.1360 rec=1.3253 | train/val/test=0.966/0.548/0.595 | c=0.999014
[Epoch 0028] loss=16.1520 cls=1.1775 smmd=0.4855 ct=9.1593 rec=1.3367 | train/val/test=0.966/0.562/0.613 | c=0.999014
[Epoch 0029] loss=16.1824 cls=1.2041 smmd=0.4611 ct=9.1603 rec=1.3406 | train/val/test=0.966/0.584/0.621 | c=0.999014
[Epoch 0030] loss=16.6790 cls=1.5552 smmd=0.4384 ct=9.1439 rec=1.3451 | train/val/test=0.966/0.586/0.618 | c=0.999014
[Epoch 0031] loss=15.8494 cls=1.0166 smmd=0.4241 ct=9.1387 rec=1.3421 | train/val/test=1.000/0.588/0.606 | c=0.999014
[Epoch 0032] loss=15.6268 cls=0.8807 smmd=0.4005 ct=9.1366 rec=1.3423 | train/val/test=0.966/0.614/0.609 | c=0.999014
[Epoch 0033] loss=16.1960 cls=1.2650 smmd=0.3949 ct=9.1318 rec=1.3442 | train/val/test=0.966/0.622/0.619 | c=0.999014
[Epoch 0034] loss=15.6811 cls=0.9288 smmd=0.3850 ct=9.1354 rec=1.3389 | train/val/test=0.966/0.638/0.628 | c=0.999014
[Epoch 0035] loss=16.3081 cls=1.3508 smmd=0.3669 ct=9.1394 rec=1.3399 | train/val/test=0.966/0.630/0.637 | c=0.999014
[Epoch 0036] loss=16.0902 cls=1.2199 smmd=0.3537 ct=9.1320 rec=1.3382 | train/val/test=0.966/0.628/0.636 | c=0.999014
[Epoch 0037] loss=15.6539 cls=0.9356 smmd=0.3491 ct=9.1303 rec=1.3354 | train/val/test=0.966/0.628/0.631 | c=0.999014
[Epoch 0038] loss=16.2735 cls=1.3540 smmd=0.3480 ct=9.1227 rec=1.3371 | train/val/test=0.966/0.624/0.631 | c=0.999014
[Epoch 0039] loss=15.8364 cls=1.0681 smmd=0.3431 ct=9.1248 rec=1.3324 | train/val/test=0.966/0.632/0.636 | c=0.999014
[Epoch 0040] loss=15.9710 cls=1.1699 smmd=0.3379 ct=9.1107 rec=1.3349 | train/val/test=0.966/0.636/0.633 | c=0.999014
[Epoch 0041] loss=16.9655 cls=1.8288 smmd=0.3486 ct=9.1063 rec=1.3375 | train/val/test=0.966/0.634/0.627 | c=0.999014
[Epoch 0042] loss=16.3455 cls=1.4206 smmd=0.3505 ct=9.0993 rec=1.3376 | train/val/test=0.966/0.626/0.632 | c=0.999014
[Epoch 0043] loss=15.8768 cls=1.1028 smmd=0.3665 ct=9.1030 rec=1.3326 | train/val/test=1.000/0.618/0.637 | c=0.999014
[Epoch 0044] loss=15.8650 cls=1.0842 smmd=0.3742 ct=9.1076 rec=1.3356 | train/val/test=1.000/0.620/0.641 | c=0.999014
[Epoch 0045] loss=15.6904 cls=0.9699 smmd=0.3758 ct=9.1063 rec=1.3338 | train/val/test=1.000/0.636/0.649 | c=0.999014
[Epoch 0046] loss=15.8562 cls=1.0825 smmd=0.3710 ct=9.1057 rec=1.3345 | train/val/test=1.000/0.648/0.648 | c=0.999014
[Epoch 0047] loss=17.2297 cls=1.9948 smmd=0.3764 ct=9.1006 rec=1.3395 | train/val/test=1.000/0.642/0.644 | c=0.999014
[Epoch 0048] loss=16.8757 cls=1.7704 smmd=0.3686 ct=9.0896 rec=1.3410 | train/val/test=0.966/0.638/0.644 | c=0.999014
[Epoch 0049] loss=16.2008 cls=1.3307 smmd=0.3577 ct=9.0905 rec=1.3354 | train/val/test=1.000/0.640/0.647 | c=0.999014
[Epoch 0050] loss=15.4987 cls=0.8648 smmd=0.3538 ct=9.0921 rec=1.3338 | train/val/test=1.000/0.658/0.648 | c=0.999014
[Epoch 0051] loss=15.9438 cls=1.1582 smmd=0.3503 ct=9.0933 rec=1.3375 | train/val/test=1.000/0.660/0.651 | c=0.999014
[Epoch 0052] loss=15.4741 cls=0.8442 smmd=0.3466 ct=9.1001 rec=1.3344 | train/val/test=1.000/0.666/0.652 | c=0.999014
[Epoch 0053] loss=15.3463 cls=0.7611 smmd=0.3405 ct=9.1040 rec=1.3319 | train/val/test=1.000/0.668/0.654 | c=0.999014
[Epoch 0054] loss=15.3748 cls=0.7858 smmd=0.3315 ct=9.0972 rec=1.3360 | train/val/test=1.000/0.666/0.659 | c=0.999014
[Epoch 0055] loss=15.8000 cls=1.0662 smmd=0.3328 ct=9.1022 rec=1.3343 | train/val/test=1.000/0.668/0.661 | c=0.999014
[Epoch 0056] loss=15.6659 cls=0.9788 smmd=0.3241 ct=9.1036 rec=1.3351 | train/val/test=1.000/0.662/0.664 | c=0.999014
[Epoch 0057] loss=15.9558 cls=1.1712 smmd=0.3225 ct=9.1010 rec=1.3388 | train/val/test=1.000/0.652/0.659 | c=0.999014
[Epoch 0058] loss=15.5555 cls=0.9079 smmd=0.3150 ct=9.1047 rec=1.3357 | train/val/test=1.000/0.642/0.649 | c=0.999014
[Epoch 0059] loss=15.4084 cls=0.8132 smmd=0.3043 ct=9.1090 rec=1.3337 | train/val/test=1.000/0.636/0.640 | c=0.999014
[Epoch 0060] loss=16.4614 cls=1.5125 smmd=0.3115 ct=9.1070 rec=1.3346 | train/val/test=1.000/0.634/0.639 | c=0.999014
[Epoch 0061] loss=15.8825 cls=1.1341 smmd=0.2980 ct=9.1027 rec=1.3370 | train/val/test=1.000/0.626/0.637 | c=0.999014
[Epoch 0062] loss=15.7876 cls=1.0731 smmd=0.2980 ct=9.1038 rec=1.3340 | train/val/test=1.000/0.632/0.637 | c=0.999014
[Epoch 0063] loss=15.2267 cls=0.6960 smmd=0.2954 ct=9.1150 rec=1.3290 | train/val/test=1.000/0.632/0.640 | c=0.999014
[Epoch 0064] loss=15.6809 cls=0.9983 smmd=0.2921 ct=9.1065 rec=1.3378 | train/val/test=1.000/0.634/0.640 | c=0.999014
[Epoch 0065] loss=16.4163 cls=1.4932 smmd=0.2954 ct=9.1023 rec=1.3355 | train/val/test=1.000/0.636/0.643 | c=0.999014
[Epoch 0066] loss=16.3713 cls=1.4655 smmd=0.2947 ct=9.0990 rec=1.3363 | train/val/test=1.000/0.636/0.647 | c=0.999014
[Epoch 0067] loss=15.4151 cls=0.8307 smmd=0.2995 ct=9.1002 rec=1.3307 | train/val/test=1.000/0.634/0.643 | c=0.999014
[Epoch 0068] loss=15.9135 cls=1.1644 smmd=0.2987 ct=9.0992 rec=1.3305 | train/val/test=1.000/0.638/0.648 | c=0.999014
[Epoch 0069] loss=15.9589 cls=1.1947 smmd=0.3011 ct=9.0950 rec=1.3328 | train/val/test=1.000/0.636/0.646 | c=0.999014
[Epoch 0070] loss=15.5103 cls=0.8958 smmd=0.3008 ct=9.0975 rec=1.3309 | train/val/test=1.000/0.640/0.647 | c=0.999014
[Epoch 0071] loss=15.7156 cls=1.0346 smmd=0.3055 ct=9.0915 rec=1.3318 | train/val/test=1.000/0.638/0.647 | c=0.999014
[Epoch 0072] loss=15.3719 cls=0.8112 smmd=0.3035 ct=9.0890 rec=1.3293 | train/val/test=1.000/0.640/0.645 | c=0.999014
[Epoch 0073] loss=15.5080 cls=0.8979 smmd=0.3059 ct=9.0907 rec=1.3307 | train/val/test=1.000/0.644/0.648 | c=0.999014
[Epoch 0074] loss=15.4181 cls=0.8409 smmd=0.3068 ct=9.0929 rec=1.3257 | train/val/test=1.000/0.648/0.650 | c=0.999014
[Epoch 0075] loss=15.3002 cls=0.7647 smmd=0.3049 ct=9.0904 rec=1.3264 | train/val/test=1.000/0.652/0.648 | c=0.999014
[Epoch 0076] loss=15.6562 cls=0.9973 smmd=0.3039 ct=9.0955 rec=1.3271 | train/val/test=1.000/0.656/0.650 | c=0.999014
[Epoch 0077] loss=15.4787 cls=0.8816 smmd=0.3042 ct=9.0940 rec=1.3257 | train/val/test=1.000/0.654/0.650 | c=0.999014
[Epoch 0078] loss=15.4928 cls=0.8962 smmd=0.2975 ct=9.0911 rec=1.3262 | train/val/test=1.000/0.650/0.650 | c=0.999014
[Epoch 0079] loss=15.6579 cls=0.9977 smmd=0.3049 ct=9.0944 rec=1.3282 | train/val/test=1.000/0.650/0.648 | c=0.999014
[Epoch 0080] loss=15.4320 cls=0.8503 smmd=0.3013 ct=9.0937 rec=1.3274 | train/val/test=1.000/0.646/0.649 | c=0.999014
[Epoch 0081] loss=15.3028 cls=0.7706 smmd=0.2920 ct=9.0934 rec=1.3256 | train/val/test=1.000/0.648/0.650 | c=0.999014
[Epoch 0082] loss=15.0827 cls=0.6209 smmd=0.2960 ct=9.0941 rec=1.3262 | train/val/test=1.000/0.650/0.649 | c=0.999014
[Epoch 0083] loss=15.5342 cls=0.9248 smmd=0.2901 ct=9.0900 rec=1.3293 | train/val/test=1.000/0.648/0.648 | c=0.999014
[Epoch 0084] loss=15.1794 cls=0.6877 smmd=0.2931 ct=9.0924 rec=1.3267 | train/val/test=1.000/0.652/0.649 | c=0.999014
[Epoch 0085] loss=15.8322 cls=1.1237 smmd=0.2897 ct=9.0936 rec=1.3264 | train/val/test=1.000/0.648/0.651 | c=0.999014
[Epoch 0086] loss=15.1304 cls=0.6584 smmd=0.2935 ct=9.0905 rec=1.3249 | train/val/test=1.000/0.648/0.651 | c=0.999014
[Epoch 0087] loss=14.9808 cls=0.5557 smmd=0.2944 ct=9.0925 rec=1.3255 | train/val/test=1.000/0.654/0.652 | c=0.999014
[Epoch 0088] loss=15.5052 cls=0.9074 smmd=0.2946 ct=9.0872 rec=1.3279 | train/val/test=1.000/0.654/0.652 | c=0.999014
[Epoch 0089] loss=15.6656 cls=1.0143 smmd=0.2904 ct=9.0888 rec=1.3284 | train/val/test=1.000/0.654/0.649 | c=0.999014
[Epoch 0090] loss=15.5777 cls=0.9531 smmd=0.2944 ct=9.0901 rec=1.3280 | train/val/test=1.000/0.654/0.648 | c=0.999014
[Epoch 0091] loss=15.5573 cls=0.9420 smmd=0.2910 ct=9.0917 rec=1.3259 | train/val/test=1.000/0.650/0.650 | c=0.999014
[Epoch 0092] loss=14.9226 cls=0.5209 smmd=0.2947 ct=9.0923 rec=1.3219 | train/val/test=1.000/0.650/0.651 | c=0.999014
[Epoch 0093] loss=15.4876 cls=0.8967 smmd=0.2955 ct=9.0879 rec=1.3260 | train/val/test=1.000/0.650/0.651 | c=0.999014
[Epoch 0094] loss=15.4253 cls=0.8500 smmd=0.2932 ct=9.0949 rec=1.3260 | train/val/test=1.000/0.650/0.651 | c=0.999014
[Epoch 0095] loss=15.5551 cls=0.9390 smmd=0.2945 ct=9.0947 rec=1.3233 | train/val/test=1.000/0.650/0.652 | c=0.999014
[Epoch 0096] loss=15.4738 cls=0.8879 smmd=0.2963 ct=9.0921 rec=1.3217 | train/val/test=1.000/0.650/0.652 | c=0.999014
[Epoch 0097] loss=15.4669 cls=0.8793 smmd=0.2960 ct=9.0912 rec=1.3263 | train/val/test=1.000/0.650/0.652 | c=0.999014
[Epoch 0098] loss=15.1718 cls=0.6910 smmd=0.2879 ct=9.0916 rec=1.3217 | train/val/test=1.000/0.650/0.652 | c=0.999014
[Epoch 0099] loss=15.6946 cls=1.0319 smmd=0.2937 ct=9.0918 rec=1.3261 | train/val/test=1.000/0.650/0.652 | c=0.999014
=== Best @ epoch 53: val=0.6680, test=0.6540 ===
