Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.7915 cls=1.9468 smmd=2.3823 ct=9.2165 rec=1.3889 | train/val/test=0.155/0.162/0.149 | c=0.999014
[Epoch 0001] loss=18.6956 cls=1.9434 smmd=2.2661 ct=9.2092 rec=1.3889 | train/val/test=0.155/0.162/0.147 | c=0.999014
[Epoch 0002] loss=18.5663 cls=1.9487 smmd=2.0911 ct=9.1979 rec=1.3889 | train/val/test=0.190/0.142/0.150 | c=0.999014
[Epoch 0003] loss=18.3816 cls=1.9378 smmd=1.8712 ct=9.1868 rec=1.3889 | train/val/test=0.224/0.096/0.121 | c=0.999014
[Epoch 0004] loss=18.1289 cls=1.9286 smmd=1.5794 ct=9.1600 rec=1.3889 | train/val/test=0.224/0.078/0.107 | c=0.999014
[Epoch 0005] loss=17.8431 cls=1.9188 smmd=1.2671 ct=9.1197 rec=1.3889 | train/val/test=0.345/0.156/0.191 | c=0.999014
[Epoch 0006] loss=17.5363 cls=1.9149 smmd=0.9467 ct=9.0607 rec=1.3889 | train/val/test=0.379/0.220/0.228 | c=0.999014
[Epoch 0007] loss=17.2298 cls=1.9114 smmd=0.6631 ct=8.9818 rec=1.3889 | train/val/test=0.466/0.262/0.266 | c=0.999014
[Epoch 0008] loss=16.9749 cls=1.8861 smmd=0.4790 ct=8.9140 rec=1.3889 | train/val/test=0.552/0.330/0.337 | c=0.999014
[Epoch 0009] loss=16.8169 cls=1.8569 smmd=0.4048 ct=8.8662 rec=1.3888 | train/val/test=0.707/0.394/0.411 | c=0.999014
[Epoch 0010] loss=16.7444 cls=1.8158 smmd=0.4509 ct=8.8331 rec=1.3887 | train/val/test=0.707/0.450/0.434 | c=0.999014
[Epoch 0011] loss=16.6027 cls=1.6974 smmd=0.5552 ct=8.8051 rec=1.3883 | train/val/test=0.690/0.436/0.418 | c=0.999014
[Epoch 0012] loss=17.4797 cls=1.6377 smmd=0.6800 ct=9.4826 rec=1.3875 | train/val/test=0.741/0.468/0.469 | c=0.999014
[Epoch 0013] loss=17.0903 cls=1.5231 smmd=0.7831 ct=9.2623 rec=1.3854 | train/val/test=0.845/0.526/0.511 | c=0.999014
[Epoch 0014] loss=16.9758 cls=1.5262 smmd=0.8933 ct=9.1158 rec=1.3816 | train/val/test=0.897/0.562/0.550 | c=0.999014
[Epoch 0015] loss=16.8819 cls=1.5024 smmd=0.9832 ct=9.0338 rec=1.3726 | train/val/test=0.897/0.670/0.638 | c=0.999014
[Epoch 0016] loss=16.5819 cls=1.3277 smmd=1.0596 ct=8.9806 rec=1.3587 | train/val/test=0.931/0.700/0.673 | c=0.999014
[Epoch 0017] loss=16.6305 cls=1.3900 smmd=1.0998 ct=8.9529 rec=1.3355 | train/val/test=0.931/0.698/0.701 | c=0.999014
[Epoch 0018] loss=16.7279 cls=1.4947 smmd=1.0971 ct=8.9421 rec=1.3082 | train/val/test=0.948/0.720/0.719 | c=0.999014
[Epoch 0019] loss=16.5839 cls=1.4327 smmd=1.0620 ct=8.9397 rec=1.2937 | train/val/test=0.931/0.694/0.708 | c=0.999014
[Epoch 0020] loss=17.2187 cls=1.8723 smmd=1.0025 ct=8.9461 rec=1.2991 | train/val/test=0.948/0.680/0.664 | c=0.999014
[Epoch 0021] loss=16.5437 cls=1.4378 smmd=0.9149 ct=8.9668 rec=1.3061 | train/val/test=0.948/0.686/0.660 | c=0.999014
[Epoch 0022] loss=16.5206 cls=1.4553 smmd=0.7996 ct=8.9811 rec=1.3141 | train/val/test=0.966/0.680/0.665 | c=0.999014
[Epoch 0023] loss=16.2151 cls=1.2595 smmd=0.6992 ct=9.0155 rec=1.3227 | train/val/test=0.966/0.706/0.695 | c=0.999014
[Epoch 0024] loss=16.2565 cls=1.2901 smmd=0.6075 ct=9.0544 rec=1.3284 | train/val/test=0.948/0.722/0.726 | c=0.999014
[Epoch 0025] loss=16.4564 cls=1.4090 smmd=0.5467 ct=9.0935 rec=1.3367 | train/val/test=0.948/0.724/0.722 | c=0.999014
[Epoch 0026] loss=16.4000 cls=1.3637 smmd=0.4941 ct=9.1258 rec=1.3406 | train/val/test=0.931/0.712/0.702 | c=0.999014
[Epoch 0027] loss=16.5620 cls=1.4656 smmd=0.4638 ct=9.1446 rec=1.3443 | train/val/test=0.914/0.680/0.685 | c=0.999014
[Epoch 0028] loss=16.6192 cls=1.5016 smmd=0.4356 ct=9.1550 rec=1.3503 | train/val/test=0.914/0.654/0.662 | c=0.999014
[Epoch 0029] loss=16.7810 cls=1.6117 smmd=0.4133 ct=9.1646 rec=1.3501 | train/val/test=0.931/0.622/0.614 | c=0.999014
[Epoch 0030] loss=16.0910 cls=1.1494 smmd=0.3961 ct=9.1760 rec=1.3505 | train/val/test=0.931/0.608/0.597 | c=0.999014
[Epoch 0031] loss=16.3502 cls=1.3319 smmd=0.3816 ct=9.1705 rec=1.3523 | train/val/test=0.931/0.598/0.595 | c=0.999014
[Epoch 0032] loss=16.2619 cls=1.2957 smmd=0.3683 ct=9.1529 rec=1.3511 | train/val/test=0.931/0.620/0.600 | c=0.999014
[Epoch 0033] loss=16.4292 cls=1.4282 smmd=0.3552 ct=9.1352 rec=1.3516 | train/val/test=0.931/0.640/0.626 | c=0.999014
[Epoch 0034] loss=16.2606 cls=1.3252 smmd=0.3582 ct=9.1243 rec=1.3502 | train/val/test=0.931/0.654/0.645 | c=0.999014
[Epoch 0035] loss=16.3765 cls=1.4043 smmd=0.3701 ct=9.1158 rec=1.3503 | train/val/test=0.931/0.680/0.672 | c=0.999014
[Epoch 0036] loss=16.4127 cls=1.4180 smmd=0.3890 ct=9.1124 rec=1.3546 | train/val/test=0.931/0.686/0.675 | c=0.999014
[Epoch 0037] loss=16.3716 cls=1.3981 smmd=0.3893 ct=9.1105 rec=1.3489 | train/val/test=0.931/0.692/0.675 | c=0.999014
[Epoch 0038] loss=16.4079 cls=1.4270 smmd=0.3962 ct=9.1026 rec=1.3480 | train/val/test=0.931/0.688/0.672 | c=0.999014
[Epoch 0039] loss=16.3677 cls=1.3995 smmd=0.3940 ct=9.1015 rec=1.3505 | train/val/test=0.931/0.682/0.667 | c=0.999014
[Epoch 0040] loss=16.0139 cls=1.1733 smmd=0.3839 ct=9.0972 rec=1.3492 | train/val/test=0.931/0.680/0.655 | c=0.999014
[Epoch 0041] loss=16.0479 cls=1.2012 smmd=0.3810 ct=9.0980 rec=1.3450 | train/val/test=0.931/0.678/0.658 | c=0.999014
[Epoch 0042] loss=15.6648 cls=0.9458 smmd=0.3749 ct=9.1030 rec=1.3437 | train/val/test=0.931/0.672/0.652 | c=0.999014
[Epoch 0043] loss=16.0249 cls=1.1910 smmd=0.3648 ct=9.1069 rec=1.3400 | train/val/test=0.931/0.674/0.658 | c=0.999014
[Epoch 0044] loss=15.8925 cls=1.1015 smmd=0.3563 ct=9.1119 rec=1.3408 | train/val/test=0.931/0.692/0.667 | c=0.999014
[Epoch 0045] loss=15.8956 cls=1.1245 smmd=0.3380 ct=9.1063 rec=1.3338 | train/val/test=0.948/0.700/0.680 | c=0.999014
[Epoch 0046] loss=16.0743 cls=1.2379 smmd=0.3359 ct=9.1136 rec=1.3342 | train/val/test=0.966/0.712/0.683 | c=0.999014
[Epoch 0047] loss=15.8098 cls=1.0677 smmd=0.3248 ct=9.1140 rec=1.3329 | train/val/test=0.966/0.712/0.692 | c=0.999014
[Epoch 0048] loss=15.8743 cls=1.1151 smmd=0.3199 ct=9.1169 rec=1.3285 | train/val/test=0.948/0.712/0.706 | c=0.999014
[Epoch 0049] loss=16.1519 cls=1.2961 smmd=0.3207 ct=9.1213 rec=1.3285 | train/val/test=0.948/0.712/0.709 | c=0.999014
[Epoch 0050] loss=15.8182 cls=1.0782 smmd=0.3124 ct=9.1224 rec=1.3270 | train/val/test=0.948/0.718/0.719 | c=0.999014
[Epoch 0051] loss=16.0385 cls=1.2250 smmd=0.3135 ct=9.1224 rec=1.3265 | train/val/test=0.966/0.716/0.717 | c=0.999014
[Epoch 0052] loss=15.8356 cls=1.1010 smmd=0.3119 ct=9.1179 rec=1.3203 | train/val/test=1.000/0.724/0.722 | c=0.999014
[Epoch 0053] loss=15.7902 cls=1.0720 smmd=0.3116 ct=9.1171 rec=1.3200 | train/val/test=1.000/0.720/0.723 | c=0.999014
[Epoch 0054] loss=15.8735 cls=1.1326 smmd=0.3098 ct=9.1121 rec=1.3200 | train/val/test=1.000/0.720/0.721 | c=0.999014
[Epoch 0055] loss=15.8803 cls=1.1397 smmd=0.3138 ct=9.1107 rec=1.3171 | train/val/test=1.000/0.720/0.719 | c=0.999014
[Epoch 0056] loss=15.5461 cls=0.9190 smmd=0.3118 ct=9.1093 rec=1.3171 | train/val/test=1.000/0.720/0.721 | c=0.999014
[Epoch 0057] loss=15.6463 cls=0.9789 smmd=0.3119 ct=9.1182 rec=1.3163 | train/val/test=1.000/0.722/0.720 | c=0.999014
[Epoch 0058] loss=15.5088 cls=0.8991 smmd=0.3097 ct=9.1097 rec=1.3130 | train/val/test=1.000/0.724/0.726 | c=0.999014
[Epoch 0059] loss=15.9669 cls=1.1984 smmd=0.3076 ct=9.1167 rec=1.3139 | train/val/test=1.000/0.726/0.729 | c=0.999014
[Epoch 0060] loss=15.5364 cls=0.9243 smmd=0.2983 ct=9.1121 rec=1.3096 | train/val/test=1.000/0.724/0.731 | c=0.999014
[Epoch 0061] loss=15.9734 cls=1.2183 smmd=0.2931 ct=9.1093 rec=1.3117 | train/val/test=1.000/0.720/0.732 | c=0.999014
[Epoch 0062] loss=16.3479 cls=1.4613 smmd=0.2938 ct=9.1164 rec=1.3119 | train/val/test=1.000/0.716/0.735 | c=0.999014
[Epoch 0063] loss=15.6720 cls=1.0221 smmd=0.2820 ct=9.1098 rec=1.3117 | train/val/test=1.000/0.720/0.733 | c=0.999014
[Epoch 0064] loss=16.3152 cls=1.4391 smmd=0.2899 ct=9.1177 rec=1.3129 | train/val/test=1.000/0.716/0.727 | c=0.999014
[Epoch 0065] loss=15.8748 cls=1.1547 smmd=0.2874 ct=9.1136 rec=1.3086 | train/val/test=0.983/0.710/0.722 | c=0.999014
[Epoch 0066] loss=15.5166 cls=0.9150 smmd=0.2885 ct=9.1158 rec=1.3073 | train/val/test=0.983/0.708/0.721 | c=0.999014
[Epoch 0067] loss=15.6138 cls=0.9756 smmd=0.2905 ct=9.1166 rec=1.3096 | train/val/test=0.983/0.712/0.721 | c=0.999014
[Epoch 0068] loss=15.8242 cls=1.1205 smmd=0.2852 ct=9.1144 rec=1.3094 | train/val/test=1.000/0.712/0.724 | c=0.999014
[Epoch 0069] loss=15.6916 cls=1.0374 smmd=0.2874 ct=9.1074 rec=1.3092 | train/val/test=1.000/0.710/0.726 | c=0.999014
[Epoch 0070] loss=15.5606 cls=0.9525 smmd=0.2863 ct=9.1053 rec=1.3091 | train/val/test=0.966/0.716/0.722 | c=0.999014
[Epoch 0071] loss=15.6117 cls=0.9883 smmd=0.2818 ct=9.1039 rec=1.3106 | train/val/test=0.966/0.712/0.721 | c=0.999014
[Epoch 0072] loss=15.7694 cls=1.0876 smmd=0.2868 ct=9.1121 rec=1.3072 | train/val/test=0.966/0.714/0.722 | c=0.999014
[Epoch 0073] loss=15.7762 cls=1.0954 smmd=0.2900 ct=9.1063 rec=1.3075 | train/val/test=0.966/0.720/0.718 | c=0.999014
[Epoch 0074] loss=15.5217 cls=0.9267 smmd=0.2787 ct=9.1101 rec=1.3084 | train/val/test=0.983/0.718/0.717 | c=0.999014
[Epoch 0075] loss=15.7889 cls=1.1035 smmd=0.2841 ct=9.1089 rec=1.3083 | train/val/test=0.983/0.718/0.717 | c=0.999014
[Epoch 0076] loss=15.6643 cls=1.0225 smmd=0.2842 ct=9.1096 rec=1.3057 | train/val/test=0.983/0.722/0.717 | c=0.999014
[Epoch 0077] loss=15.7184 cls=1.0630 smmd=0.2819 ct=9.1056 rec=1.3058 | train/val/test=0.983/0.718/0.719 | c=0.999014
[Epoch 0078] loss=15.9129 cls=1.1862 smmd=0.2816 ct=9.1102 rec=1.3082 | train/val/test=0.983/0.722/0.719 | c=0.999014
[Epoch 0079] loss=15.3881 cls=0.8416 smmd=0.2855 ct=9.1073 rec=1.3039 | train/val/test=0.983/0.720/0.719 | c=0.999014
[Epoch 0080] loss=15.8734 cls=1.1657 smmd=0.2797 ct=9.1056 rec=1.3073 | train/val/test=0.983/0.720/0.719 | c=0.999014
[Epoch 0081] loss=15.4382 cls=0.8773 smmd=0.2839 ct=9.1060 rec=1.3036 | train/val/test=0.983/0.720/0.718 | c=0.999014
[Epoch 0082] loss=15.5403 cls=0.9399 smmd=0.2837 ct=9.1087 rec=1.3066 | train/val/test=0.983/0.720/0.721 | c=0.999014
[Epoch 0083] loss=15.8927 cls=1.1780 smmd=0.2821 ct=9.1052 rec=1.3072 | train/val/test=0.966/0.720/0.721 | c=0.999014
[Epoch 0084] loss=15.9531 cls=1.2177 smmd=0.2788 ct=9.1137 rec=1.3023 | train/val/test=0.966/0.720/0.722 | c=0.999014
[Epoch 0085] loss=15.4926 cls=0.9163 smmd=0.2799 ct=9.1057 rec=1.3030 | train/val/test=0.966/0.720/0.720 | c=0.999014
[Epoch 0086] loss=15.4970 cls=0.9171 smmd=0.2797 ct=9.1076 rec=1.3036 | train/val/test=0.966/0.720/0.720 | c=0.999014
[Epoch 0087] loss=15.5641 cls=0.9633 smmd=0.2798 ct=9.1081 rec=1.3017 | train/val/test=0.966/0.720/0.720 | c=0.999014
[Epoch 0088] loss=15.4388 cls=0.8767 smmd=0.2857 ct=9.1070 rec=1.3029 | train/val/test=0.966/0.720/0.721 | c=0.999014
[Epoch 0089] loss=15.8661 cls=1.1635 smmd=0.2840 ct=9.1035 rec=1.3047 | train/val/test=0.966/0.720/0.720 | c=0.999014
[Epoch 0090] loss=15.3445 cls=0.8121 smmd=0.2831 ct=9.1071 rec=1.3057 | train/val/test=0.966/0.720/0.720 | c=0.999014
[Epoch 0091] loss=15.5096 cls=0.9263 smmd=0.2809 ct=9.1036 rec=1.3055 | train/val/test=0.966/0.718/0.720 | c=0.999014
[Epoch 0092] loss=15.6604 cls=1.0225 smmd=0.2799 ct=9.1113 rec=1.3038 | train/val/test=0.966/0.720/0.720 | c=0.999014
[Epoch 0093] loss=15.5395 cls=0.9479 smmd=0.2801 ct=9.1053 rec=1.3029 | train/val/test=0.966/0.720/0.721 | c=0.999014
[Epoch 0094] loss=15.2769 cls=0.7734 smmd=0.2774 ct=9.1032 rec=1.3052 | train/val/test=0.966/0.720/0.720 | c=0.999014
[Epoch 0095] loss=15.3061 cls=0.7943 smmd=0.2795 ct=9.1051 rec=1.3015 | train/val/test=0.966/0.720/0.719 | c=0.999014
[Epoch 0096] loss=15.6654 cls=1.0280 smmd=0.2797 ct=9.1060 rec=1.3062 | train/val/test=0.966/0.720/0.719 | c=0.999014
[Epoch 0097] loss=16.0382 cls=1.2774 smmd=0.2798 ct=9.1036 rec=1.3073 | train/val/test=0.966/0.720/0.719 | c=0.999014
[Epoch 0098] loss=16.2421 cls=1.4129 smmd=0.2837 ct=9.1050 rec=1.3047 | train/val/test=0.966/0.720/0.719 | c=0.999014
[Epoch 0099] loss=16.2247 cls=1.4049 smmd=0.2781 ct=9.1029 rec=1.3055 | train/val/test=0.966/0.720/0.719 | c=0.999014
=== Best @ epoch 59: val=0.7260, test=0.7290 ===
