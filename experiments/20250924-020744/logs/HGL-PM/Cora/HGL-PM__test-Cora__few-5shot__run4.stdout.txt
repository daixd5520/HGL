Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.8783 cls=1.9469 smmd=2.4185 ct=9.2636 rec=1.3889 | train/val/test=0.207/0.096/0.108 | c=0.999014
[Epoch 0001] loss=18.7574 cls=1.9285 smmd=2.2926 ct=9.2597 rec=1.3889 | train/val/test=0.172/0.084/0.102 | c=0.999014
[Epoch 0002] loss=18.6340 cls=1.9374 smmd=2.1092 ct=9.2532 rec=1.3889 | train/val/test=0.172/0.096/0.116 | c=0.999014
[Epoch 0003] loss=18.4418 cls=1.9224 smmd=1.8794 ct=9.2463 rec=1.3890 | train/val/test=0.172/0.102/0.128 | c=0.999014
[Epoch 0004] loss=18.1912 cls=1.9095 smmd=1.5764 ct=9.2315 rec=1.3890 | train/val/test=0.310/0.162/0.168 | c=0.999014
[Epoch 0005] loss=17.9227 cls=1.9097 smmd=1.2336 ct=9.2093 rec=1.3891 | train/val/test=0.345/0.312/0.315 | c=0.999014
[Epoch 0006] loss=17.6197 cls=1.8957 smmd=0.8931 ct=9.1757 rec=1.3892 | train/val/test=0.345/0.358/0.361 | c=0.999014
[Epoch 0007] loss=17.2632 cls=1.8596 smmd=0.5721 ct=9.1159 rec=1.3892 | train/val/test=0.379/0.346/0.344 | c=0.999014
[Epoch 0008] loss=16.9793 cls=1.8311 smmd=0.3737 ct=9.0373 rec=1.3891 | train/val/test=0.448/0.350/0.353 | c=0.999014
[Epoch 0009] loss=16.9520 cls=1.8822 smmd=0.3240 ct=8.9841 rec=1.3890 | train/val/test=0.517/0.370/0.391 | c=0.999014
[Epoch 0010] loss=16.7817 cls=1.7690 smmd=0.3944 ct=8.9460 rec=1.3889 | train/val/test=0.724/0.408/0.417 | c=0.999014
[Epoch 0011] loss=16.6647 cls=1.6773 smmd=0.5204 ct=8.8943 rec=1.3887 | train/val/test=0.862/0.394/0.421 | c=0.999014
[Epoch 0012] loss=16.6459 cls=1.6487 smmd=0.6376 ct=8.8503 rec=1.3882 | train/val/test=0.862/0.470/0.470 | c=0.999014
[Epoch 0013] loss=16.2911 cls=1.4008 smmd=0.7265 ct=8.8174 rec=1.3867 | train/val/test=0.931/0.552/0.547 | c=0.999014
[Epoch 0014] loss=16.1551 cls=1.3244 smmd=0.7674 ct=8.7832 rec=1.3833 | train/val/test=0.931/0.566/0.567 | c=0.999014
[Epoch 0015] loss=15.8650 cls=1.1609 smmd=0.7672 ct=8.7614 rec=1.3730 | train/val/test=0.897/0.632/0.623 | c=0.999014
[Epoch 0016] loss=15.5158 cls=0.9749 smmd=0.7131 ct=8.7545 rec=1.3583 | train/val/test=0.931/0.660/0.647 | c=0.999014
[Epoch 0017] loss=15.9688 cls=1.3671 smmd=0.6233 ct=8.7448 rec=1.3210 | train/val/test=0.966/0.606/0.653 | c=0.999014
[Epoch 0018] loss=15.8236 cls=1.3120 smmd=0.5331 ct=8.7544 rec=1.3136 | train/val/test=0.966/0.664/0.684 | c=0.999014
[Epoch 0019] loss=15.8914 cls=1.4042 smmd=0.4350 ct=8.7764 rec=1.2946 | train/val/test=0.966/0.628/0.682 | c=0.999014
[Epoch 0020] loss=15.7617 cls=1.3151 smmd=0.3612 ct=8.8091 rec=1.3027 | train/val/test=1.000/0.604/0.664 | c=0.999014
[Epoch 0021] loss=17.0217 cls=2.1749 smmd=0.2893 ct=8.8031 rec=1.3205 | train/val/test=1.000/0.592/0.637 | c=0.999014
[Epoch 0022] loss=15.7735 cls=1.3458 smmd=0.2580 ct=8.8015 rec=1.3326 | train/val/test=1.000/0.610/0.634 | c=0.999014
[Epoch 0023] loss=15.0185 cls=0.8611 smmd=0.2375 ct=8.7932 rec=1.3310 | train/val/test=0.966/0.606/0.623 | c=0.999014
[Epoch 0024] loss=16.2046 cls=1.6440 smmd=0.2529 ct=8.7934 rec=1.3313 | train/val/test=0.966/0.604/0.635 | c=0.999014
[Epoch 0025] loss=15.3777 cls=1.0805 smmd=0.2824 ct=8.7941 rec=1.3293 | train/val/test=0.966/0.648/0.667 | c=0.999014
[Epoch 0026] loss=16.3298 cls=1.6823 smmd=0.3054 ct=8.8095 rec=1.3377 | train/val/test=0.966/0.666/0.673 | c=0.999014
[Epoch 0027] loss=16.1670 cls=1.5812 smmd=0.2938 ct=8.8030 rec=1.3411 | train/val/test=1.000/0.650/0.669 | c=0.999014
[Epoch 0028] loss=16.1114 cls=1.5616 smmd=0.2706 ct=8.7890 rec=1.3462 | train/val/test=1.000/0.624/0.647 | c=0.999014
[Epoch 0029] loss=16.0763 cls=1.5635 smmd=0.2363 ct=8.7767 rec=1.3474 | train/val/test=1.000/0.610/0.638 | c=0.999014
[Epoch 0030] loss=15.7046 cls=1.3438 smmd=0.2097 ct=8.7628 rec=1.3441 | train/val/test=0.966/0.610/0.632 | c=0.999014
[Epoch 0031] loss=15.3661 cls=1.1231 smmd=0.1909 ct=8.7620 rec=1.3482 | train/val/test=1.000/0.600/0.639 | c=0.999014
[Epoch 0032] loss=15.5756 cls=1.2687 smmd=0.1822 ct=8.7544 rec=1.3527 | train/val/test=1.000/0.594/0.629 | c=0.999014
[Epoch 0033] loss=15.6175 cls=1.3025 smmd=0.1802 ct=8.7500 rec=1.3516 | train/val/test=1.000/0.594/0.634 | c=0.999014
[Epoch 0034] loss=15.6889 cls=1.3498 smmd=0.1844 ct=8.7479 rec=1.3517 | train/val/test=1.000/0.614/0.643 | c=0.999014
[Epoch 0035] loss=15.6575 cls=1.3368 smmd=0.1790 ct=8.7400 rec=1.3531 | train/val/test=1.000/0.628/0.652 | c=0.999014
[Epoch 0036] loss=15.3053 cls=1.1156 smmd=0.1816 ct=8.7302 rec=1.3472 | train/val/test=1.000/0.648/0.660 | c=0.999014
[Epoch 0037] loss=15.2475 cls=1.0794 smmd=0.1861 ct=8.7247 rec=1.3475 | train/val/test=1.000/0.648/0.666 | c=0.999014
[Epoch 0038] loss=15.4564 cls=1.2189 smmd=0.1927 ct=8.7263 rec=1.3431 | train/val/test=1.000/0.650/0.675 | c=0.999014
[Epoch 0039] loss=15.5699 cls=1.2901 smmd=0.1915 ct=8.7296 rec=1.3452 | train/val/test=1.000/0.656/0.682 | c=0.999014
[Epoch 0040] loss=15.4708 cls=1.2323 smmd=0.1829 ct=8.7254 rec=1.3446 | train/val/test=1.000/0.666/0.686 | c=0.999014
[Epoch 0041] loss=15.2184 cls=1.0665 smmd=0.1785 ct=8.7251 rec=1.3444 | train/val/test=1.000/0.668/0.694 | c=0.999014
[Epoch 0042] loss=15.7417 cls=1.4195 smmd=0.1694 ct=8.7257 rec=1.3440 | train/val/test=1.000/0.666/0.688 | c=0.999014
[Epoch 0043] loss=14.8566 cls=0.8373 smmd=0.1606 ct=8.7259 rec=1.3403 | train/val/test=1.000/0.662/0.684 | c=0.999014
[Epoch 0044] loss=16.3190 cls=1.2119 smmd=0.1552 ct=9.4221 rec=1.3399 | train/val/test=1.000/0.658/0.686 | c=0.999014
[Epoch 0045] loss=16.1401 cls=1.1465 smmd=0.1510 ct=9.3675 rec=1.3356 | train/val/test=1.000/0.662/0.689 | c=0.999014
[Epoch 0046] loss=16.3702 cls=1.3463 smmd=0.1686 ct=9.3029 rec=1.3369 | train/val/test=1.000/0.670/0.693 | c=0.999014
[Epoch 0047] loss=16.2873 cls=1.3240 smmd=0.2197 ct=9.2359 rec=1.3380 | train/val/test=1.000/0.654/0.694 | c=0.999014
[Epoch 0048] loss=15.2859 cls=0.6697 smmd=0.2895 ct=9.1843 rec=1.3370 | train/val/test=1.000/0.654/0.692 | c=0.999014
[Epoch 0049] loss=15.9060 cls=1.0835 smmd=0.3713 ct=9.1425 rec=1.3347 | train/val/test=1.000/0.660/0.691 | c=0.999014
[Epoch 0050] loss=15.5941 cls=0.8700 smmd=0.4459 ct=9.1084 rec=1.3350 | train/val/test=1.000/0.670/0.696 | c=0.999014
[Epoch 0051] loss=16.1837 cls=1.2521 smmd=0.5071 ct=9.0902 rec=1.3334 | train/val/test=1.000/0.670/0.699 | c=0.999014
[Epoch 0052] loss=15.4949 cls=0.7967 smmd=0.5481 ct=9.0682 rec=1.3296 | train/val/test=1.000/0.670/0.697 | c=0.999014
[Epoch 0053] loss=16.0917 cls=1.1987 smmd=0.5549 ct=9.0595 rec=1.3299 | train/val/test=1.000/0.674/0.704 | c=0.999014
[Epoch 0054] loss=15.9041 cls=1.0797 smmd=0.5540 ct=9.0533 rec=1.3296 | train/val/test=1.000/0.672/0.705 | c=0.999014
[Epoch 0055] loss=16.0110 cls=1.1579 smmd=0.5392 ct=9.0591 rec=1.3249 | train/val/test=1.000/0.660/0.703 | c=0.999014
[Epoch 0056] loss=15.3228 cls=0.7108 smmd=0.5003 ct=9.0702 rec=1.3219 | train/val/test=1.000/0.658/0.700 | c=0.999014
[Epoch 0057] loss=16.0406 cls=1.1982 smmd=0.4723 ct=9.0749 rec=1.3221 | train/val/test=1.000/0.656/0.694 | c=0.999014
[Epoch 0058] loss=15.6165 cls=0.9200 smmd=0.4352 ct=9.0897 rec=1.3220 | train/val/test=1.000/0.660/0.692 | c=0.999014
[Epoch 0059] loss=15.8977 cls=1.1183 smmd=0.3924 ct=9.1079 rec=1.3158 | train/val/test=1.000/0.650/0.688 | c=0.999014
[Epoch 0060] loss=15.2766 cls=0.7024 smmd=0.3742 ct=9.1202 rec=1.3155 | train/val/test=1.000/0.654/0.680 | c=0.999014
[Epoch 0061] loss=15.7058 cls=0.9899 smmd=0.3394 ct=9.1386 rec=1.3146 | train/val/test=1.000/0.650/0.680 | c=0.999014
[Epoch 0062] loss=15.5215 cls=0.8698 smmd=0.3192 ct=9.1460 rec=1.3147 | train/val/test=1.000/0.650/0.677 | c=0.999014
[Epoch 0063] loss=15.6794 cls=0.9782 smmd=0.3001 ct=9.1538 rec=1.3139 | train/val/test=1.000/0.656/0.678 | c=0.999014
[Epoch 0064] loss=15.6465 cls=0.9642 smmd=0.2882 ct=9.1576 rec=1.3085 | train/val/test=1.000/0.668/0.686 | c=0.999014
[Epoch 0065] loss=15.4953 cls=0.8652 smmd=0.2758 ct=9.1610 rec=1.3095 | train/val/test=1.000/0.672/0.691 | c=0.999014
[Epoch 0066] loss=15.8507 cls=1.1015 smmd=0.2695 ct=9.1647 rec=1.3099 | train/val/test=1.000/0.670/0.694 | c=0.999014
[Epoch 0067] loss=15.7130 cls=1.0190 smmd=0.2621 ct=9.1627 rec=1.3060 | train/val/test=1.000/0.662/0.699 | c=0.999014
[Epoch 0068] loss=15.1806 cls=0.6673 smmd=0.2677 ct=9.1587 rec=1.3037 | train/val/test=1.000/0.662/0.700 | c=0.999014
[Epoch 0069] loss=16.0869 cls=1.2647 smmd=0.2654 ct=9.1621 rec=1.3083 | train/val/test=1.000/0.658/0.696 | c=0.999014
[Epoch 0070] loss=15.1714 cls=0.6639 smmd=0.2716 ct=9.1528 rec=1.3042 | train/val/test=1.000/0.652/0.692 | c=0.999014
[Epoch 0071] loss=15.0630 cls=0.5896 smmd=0.2828 ct=9.1509 rec=1.3027 | train/val/test=1.000/0.658/0.695 | c=0.999014
[Epoch 0072] loss=16.0924 cls=1.2721 smmd=0.2850 ct=9.1499 rec=1.3061 | train/val/test=1.000/0.662/0.695 | c=0.999014
[Epoch 0073] loss=15.7280 cls=1.0350 smmd=0.2886 ct=9.1472 rec=1.3013 | train/val/test=1.000/0.668/0.696 | c=0.999014
[Epoch 0074] loss=15.5203 cls=0.8941 smmd=0.2978 ct=9.1445 rec=1.3017 | train/val/test=1.000/0.664/0.697 | c=0.999014
[Epoch 0075] loss=15.8178 cls=1.0956 smmd=0.2982 ct=9.1396 rec=1.3026 | train/val/test=1.000/0.666/0.697 | c=0.999014
[Epoch 0076] loss=16.2866 cls=1.4131 smmd=0.2925 ct=9.1370 rec=1.3026 | train/val/test=1.000/0.668/0.697 | c=0.999014
[Epoch 0077] loss=15.5046 cls=0.8923 smmd=0.2994 ct=9.1353 rec=1.3004 | train/val/test=1.000/0.668/0.698 | c=0.999014
[Epoch 0078] loss=16.1695 cls=1.3326 smmd=0.3004 ct=9.1424 rec=1.2970 | train/val/test=1.000/0.672/0.703 | c=0.999014
[Epoch 0079] loss=15.3185 cls=0.7681 smmd=0.2964 ct=9.1374 rec=1.3001 | train/val/test=1.000/0.670/0.706 | c=0.999014
[Epoch 0080] loss=15.6998 cls=1.0190 smmd=0.2997 ct=9.1345 rec=1.3042 | train/val/test=1.000/0.676/0.707 | c=0.999014
[Epoch 0081] loss=15.4506 cls=0.8539 smmd=0.2980 ct=9.1354 rec=1.3032 | train/val/test=1.000/0.680/0.711 | c=0.999014
[Epoch 0082] loss=15.1560 cls=0.6598 smmd=0.3057 ct=9.1374 rec=1.2961 | train/val/test=1.000/0.678/0.711 | c=0.999014
[Epoch 0083] loss=15.8721 cls=1.1363 smmd=0.2989 ct=9.1346 rec=1.3022 | train/val/test=1.000/0.678/0.712 | c=0.999014
[Epoch 0084] loss=15.2209 cls=0.7055 smmd=0.2987 ct=9.1353 rec=1.2986 | train/val/test=1.000/0.676/0.709 | c=0.999014
[Epoch 0085] loss=15.1882 cls=0.6833 smmd=0.3016 ct=9.1312 rec=1.3010 | train/val/test=1.000/0.672/0.707 | c=0.999014
[Epoch 0086] loss=15.1178 cls=0.6379 smmd=0.2987 ct=9.1317 rec=1.3004 | train/val/test=1.000/0.672/0.708 | c=0.999014
[Epoch 0087] loss=16.0374 cls=1.2469 smmd=0.2980 ct=9.1327 rec=1.3038 | train/val/test=1.000/0.670/0.708 | c=0.999014
[Epoch 0088] loss=15.1922 cls=0.6869 smmd=0.2988 ct=9.1346 rec=1.2986 | train/val/test=1.000/0.668/0.706 | c=0.999014
[Epoch 0089] loss=15.1843 cls=0.6823 smmd=0.2979 ct=9.1293 rec=1.3026 | train/val/test=1.000/0.668/0.706 | c=0.999014
[Epoch 0090] loss=15.2100 cls=0.7020 smmd=0.2970 ct=9.1295 rec=1.3005 | train/val/test=1.000/0.672/0.705 | c=0.999014
[Epoch 0091] loss=15.7617 cls=1.0692 smmd=0.2960 ct=9.1344 rec=1.2975 | train/val/test=1.000/0.674/0.705 | c=0.999014
[Epoch 0092] loss=15.1361 cls=0.6513 smmd=0.2947 ct=9.1336 rec=1.2995 | train/val/test=1.000/0.674/0.705 | c=0.999014
[Epoch 0093] loss=15.3366 cls=0.7886 smmd=0.2905 ct=9.1288 rec=1.3018 | train/val/test=1.000/0.674/0.706 | c=0.999014
[Epoch 0094] loss=15.0033 cls=0.5669 smmd=0.2908 ct=9.1326 rec=1.2982 | train/val/test=1.000/0.674/0.706 | c=0.999014
[Epoch 0095] loss=15.7477 cls=1.0582 smmd=0.2986 ct=9.1293 rec=1.3021 | train/val/test=1.000/0.674/0.706 | c=0.999014
[Epoch 0096] loss=15.4085 cls=0.8338 smmd=0.2974 ct=9.1303 rec=1.3002 | train/val/test=1.000/0.674/0.705 | c=0.999014
[Epoch 0097] loss=15.1223 cls=0.6446 smmd=0.2937 ct=9.1307 rec=1.2999 | train/val/test=1.000/0.674/0.704 | c=0.999014
[Epoch 0098] loss=15.7185 cls=1.0393 smmd=0.2920 ct=9.1315 rec=1.3026 | train/val/test=1.000/0.674/0.704 | c=0.999014
[Epoch 0099] loss=15.3239 cls=0.7728 smmd=0.2936 ct=9.1376 rec=1.3002 | train/val/test=1.000/0.674/0.704 | c=0.999014
=== Best @ epoch 81: val=0.6800, test=0.7110 ===
