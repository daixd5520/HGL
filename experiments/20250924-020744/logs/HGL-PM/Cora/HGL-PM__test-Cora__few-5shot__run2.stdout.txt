Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.8475 cls=1.9457 smmd=2.4045 ct=9.2489 rec=1.3889 | train/val/test=0.172/0.128/0.143 | c=0.999014
[Epoch 0001] loss=18.7241 cls=1.9339 smmd=2.2631 ct=9.2438 rec=1.3889 | train/val/test=0.172/0.086/0.110 | c=0.999014
[Epoch 0002] loss=18.5933 cls=1.9389 smmd=2.0824 ct=9.2347 rec=1.3889 | train/val/test=0.172/0.072/0.093 | c=0.999014
[Epoch 0003] loss=18.4087 cls=1.9287 smmd=1.8641 ct=9.2219 rec=1.3890 | train/val/test=0.172/0.072/0.092 | c=0.999014
[Epoch 0004] loss=18.1864 cls=1.9341 smmd=1.5770 ct=9.1992 rec=1.3890 | train/val/test=0.172/0.074/0.093 | c=0.999014
[Epoch 0005] loss=17.8810 cls=1.9110 smmd=1.2581 ct=9.1626 rec=1.3891 | train/val/test=0.172/0.120/0.139 | c=0.999014
[Epoch 0006] loss=17.5706 cls=1.9140 smmd=0.9263 ct=9.0989 rec=1.3891 | train/val/test=0.345/0.234/0.265 | c=0.999014
[Epoch 0007] loss=17.2511 cls=1.9070 smmd=0.6408 ct=9.0149 rec=1.3891 | train/val/test=0.345/0.296/0.320 | c=0.999014
[Epoch 0008] loss=17.0188 cls=1.8950 smmd=0.4465 ct=8.9546 rec=1.3891 | train/val/test=0.345/0.286/0.303 | c=0.999014
[Epoch 0009] loss=16.8134 cls=1.8301 smmd=0.3724 ct=8.9115 rec=1.3891 | train/val/test=0.414/0.314/0.328 | c=0.999014
[Epoch 0010] loss=16.7917 cls=1.8261 smmd=0.4165 ct=8.8758 rec=1.3890 | train/val/test=0.483/0.356/0.376 | c=0.999014
[Epoch 0011] loss=16.7344 cls=1.7694 smmd=0.5269 ct=8.8380 rec=1.3889 | train/val/test=0.759/0.436/0.453 | c=0.999014
[Epoch 0012] loss=16.6435 cls=1.6786 smmd=0.6451 ct=8.8097 rec=1.3884 | train/val/test=0.828/0.432/0.456 | c=0.999014
[Epoch 0013] loss=16.5346 cls=1.5858 smmd=0.7371 ct=8.7847 rec=1.3873 | train/val/test=0.897/0.428/0.467 | c=0.999014
[Epoch 0014] loss=16.6249 cls=1.6449 smmd=0.7807 ct=8.7658 rec=1.3847 | train/val/test=0.897/0.522/0.553 | c=0.999014
[Epoch 0015] loss=16.2662 cls=1.4321 smmd=0.7671 ct=8.7514 rec=1.3777 | train/val/test=0.931/0.576/0.591 | c=0.999014
[Epoch 0016] loss=15.7818 cls=1.1612 smmd=0.7030 ct=8.7422 rec=1.3644 | train/val/test=0.931/0.572/0.587 | c=0.999014
[Epoch 0017] loss=15.7188 cls=1.1928 smmd=0.6117 ct=8.7446 rec=1.3334 | train/val/test=0.931/0.554/0.583 | c=0.999014
[Epoch 0018] loss=14.9259 cls=0.7461 smmd=0.5159 ct=8.7527 rec=1.2919 | train/val/test=0.931/0.542/0.554 | c=0.999014
[Epoch 0019] loss=15.9438 cls=1.5016 smmd=0.4291 ct=8.7672 rec=1.2461 | train/val/test=0.931/0.562/0.596 | c=0.999014
[Epoch 0020] loss=16.4926 cls=1.8444 smmd=0.3683 ct=8.7923 rec=1.2738 | train/val/test=0.931/0.578/0.613 | c=0.999014
[Epoch 0021] loss=15.6871 cls=1.3409 smmd=0.3036 ct=8.7899 rec=1.2728 | train/val/test=0.966/0.604/0.628 | c=0.999014
[Epoch 0022] loss=16.5531 cls=1.8866 smmd=0.2714 ct=8.8148 rec=1.2962 | train/val/test=0.931/0.518/0.556 | c=0.999014
[Epoch 0023] loss=17.0424 cls=2.1842 smmd=0.2644 ct=8.8187 rec=1.3230 | train/val/test=0.931/0.540/0.574 | c=0.999014
[Epoch 0024] loss=15.2199 cls=0.9713 smmd=0.2650 ct=8.8059 rec=1.3311 | train/val/test=0.931/0.548/0.590 | c=0.999014
[Epoch 0025] loss=15.9370 cls=1.4475 smmd=0.2712 ct=8.7940 rec=1.3398 | train/val/test=0.966/0.572/0.604 | c=0.999014
[Epoch 0026] loss=15.9856 cls=1.4852 smmd=0.2754 ct=8.7841 rec=1.3410 | train/val/test=0.966/0.574/0.596 | c=0.999014
[Epoch 0027] loss=15.6182 cls=1.2394 smmd=0.2740 ct=8.7770 rec=1.3482 | train/val/test=0.931/0.572/0.602 | c=0.999014
[Epoch 0028] loss=15.7978 cls=1.3626 smmd=0.2761 ct=8.7665 rec=1.3526 | train/val/test=0.931/0.572/0.583 | c=0.999014
[Epoch 0029] loss=16.6968 cls=1.9696 smmd=0.2620 ct=8.7605 rec=1.3564 | train/val/test=0.966/0.578/0.586 | c=0.999014
[Epoch 0030] loss=16.5733 cls=1.8939 smmd=0.2454 ct=8.7554 rec=1.3616 | train/val/test=0.966/0.586/0.593 | c=0.999014
[Epoch 0031] loss=15.7207 cls=1.3445 smmd=0.2194 ct=8.7471 rec=1.3621 | train/val/test=0.966/0.600/0.610 | c=0.999014
[Epoch 0032] loss=16.4591 cls=1.2316 smmd=0.1984 ct=9.4555 rec=1.3628 | train/val/test=0.966/0.598/0.620 | c=0.999014
[Epoch 0033] loss=16.5970 cls=1.3967 smmd=0.1895 ct=9.3739 rec=1.3645 | train/val/test=0.966/0.594/0.618 | c=0.999014
[Epoch 0034] loss=16.2227 cls=1.2257 smmd=0.2158 ct=9.2706 rec=1.3634 | train/val/test=0.966/0.612/0.630 | c=0.999014
[Epoch 0035] loss=16.5155 cls=1.4600 smmd=0.2949 ct=9.1811 rec=1.3648 | train/val/test=0.966/0.610/0.634 | c=0.999014
[Epoch 0036] loss=16.4635 cls=1.4307 smmd=0.3980 ct=9.1198 rec=1.3644 | train/val/test=1.000/0.594/0.618 | c=0.999014
[Epoch 0037] loss=15.8613 cls=1.0137 smmd=0.5081 ct=9.0822 rec=1.3614 | train/val/test=1.000/0.586/0.600 | c=0.999014
[Epoch 0038] loss=16.4663 cls=1.4030 smmd=0.5967 ct=9.0508 rec=1.3613 | train/val/test=1.000/0.584/0.603 | c=0.999014
[Epoch 0039] loss=16.1221 cls=1.1668 smmd=0.6513 ct=9.0301 rec=1.3605 | train/val/test=1.000/0.604/0.607 | c=0.999014
[Epoch 0040] loss=16.1763 cls=1.2046 smmd=0.6876 ct=9.0095 rec=1.3599 | train/val/test=1.000/0.618/0.624 | c=0.999014
[Epoch 0041] loss=16.0182 cls=1.1178 smmd=0.6937 ct=8.9870 rec=1.3581 | train/val/test=1.000/0.634/0.646 | c=0.999014
[Epoch 0042] loss=16.4639 cls=1.4290 smmd=0.6750 ct=8.9830 rec=1.3562 | train/val/test=1.000/0.652/0.659 | c=0.999014
[Epoch 0043] loss=16.0154 cls=1.1420 smmd=0.6389 ct=8.9930 rec=1.3527 | train/val/test=1.000/0.680/0.676 | c=0.999014
[Epoch 0044] loss=16.0738 cls=1.1945 smmd=0.5863 ct=9.0087 rec=1.3501 | train/val/test=1.000/0.690/0.692 | c=0.999014
[Epoch 0045] loss=16.0362 cls=1.1739 smmd=0.5356 ct=9.0301 rec=1.3508 | train/val/test=0.966/0.686/0.691 | c=0.999014
[Epoch 0046] loss=15.5709 cls=0.8727 smmd=0.4767 ct=9.0553 rec=1.3477 | train/val/test=0.966/0.676/0.686 | c=0.999014
[Epoch 0047] loss=16.0159 cls=1.1717 smmd=0.4415 ct=9.0766 rec=1.3435 | train/val/test=0.966/0.662/0.680 | c=0.999014
[Epoch 0048] loss=15.9130 cls=1.1068 smmd=0.3915 ct=9.0969 rec=1.3455 | train/val/test=0.966/0.664/0.680 | c=0.999014
[Epoch 0049] loss=16.1212 cls=1.2497 smmd=0.3660 ct=9.1088 rec=1.3432 | train/val/test=0.966/0.670/0.683 | c=0.999014
[Epoch 0050] loss=15.6441 cls=0.9423 smmd=0.3386 ct=9.1142 rec=1.3407 | train/val/test=0.966/0.680/0.687 | c=0.999014
[Epoch 0051] loss=15.4133 cls=0.7936 smmd=0.3228 ct=9.1197 rec=1.3384 | train/val/test=0.966/0.686/0.693 | c=0.999014
[Epoch 0052] loss=15.6843 cls=0.9753 smmd=0.3204 ct=9.1202 rec=1.3381 | train/val/test=0.966/0.688/0.695 | c=0.999014
[Epoch 0053] loss=16.1788 cls=1.3035 smmd=0.3160 ct=9.1268 rec=1.3360 | train/val/test=0.966/0.686/0.697 | c=0.999014
[Epoch 0054] loss=15.1266 cls=0.6068 smmd=0.3233 ct=9.1201 rec=1.3337 | train/val/test=0.966/0.682/0.692 | c=0.999014
[Epoch 0055] loss=16.2965 cls=1.3851 smmd=0.3329 ct=9.1162 rec=1.3343 | train/val/test=0.966/0.672/0.691 | c=0.999014
[Epoch 0056] loss=15.5340 cls=0.8833 smmd=0.3390 ct=9.1089 rec=1.3313 | train/val/test=0.966/0.660/0.691 | c=0.999014
[Epoch 0057] loss=15.6706 cls=0.9788 smmd=0.3436 ct=9.1053 rec=1.3282 | train/val/test=0.966/0.664/0.686 | c=0.999014
[Epoch 0058] loss=15.2066 cls=0.6791 smmd=0.3458 ct=9.0973 rec=1.3247 | train/val/test=0.966/0.664/0.685 | c=0.999014
[Epoch 0059] loss=15.7092 cls=1.0207 smmd=0.3482 ct=9.0867 rec=1.3261 | train/val/test=0.966/0.666/0.682 | c=0.999014
[Epoch 0060] loss=15.7819 cls=1.0720 smmd=0.3435 ct=9.0918 rec=1.3213 | train/val/test=0.966/0.666/0.673 | c=0.999014
[Epoch 0061] loss=15.5273 cls=0.9061 smmd=0.3519 ct=9.0829 rec=1.3213 | train/val/test=0.966/0.666/0.674 | c=0.999014
[Epoch 0062] loss=15.4603 cls=0.8662 smmd=0.3451 ct=9.0840 rec=1.3189 | train/val/test=0.966/0.662/0.674 | c=0.999014
[Epoch 0063] loss=15.1719 cls=0.6776 smmd=0.3483 ct=9.0839 rec=1.3142 | train/val/test=0.966/0.664/0.677 | c=0.999014
[Epoch 0064] loss=15.3732 cls=0.8143 smmd=0.3418 ct=9.0821 rec=1.3161 | train/val/test=0.966/0.660/0.679 | c=0.999014
[Epoch 0065] loss=15.6087 cls=0.9715 smmd=0.3415 ct=9.0823 rec=1.3159 | train/val/test=0.966/0.658/0.680 | c=0.999014
[Epoch 0066] loss=15.1660 cls=0.6810 smmd=0.3392 ct=9.0820 rec=1.3128 | train/val/test=0.966/0.658/0.681 | c=0.999014
[Epoch 0067] loss=15.1257 cls=0.6530 smmd=0.3387 ct=9.0870 rec=1.3099 | train/val/test=0.966/0.658/0.682 | c=0.999014
[Epoch 0068] loss=15.2177 cls=0.7135 smmd=0.3423 ct=9.0825 rec=1.3130 | train/val/test=0.966/0.652/0.685 | c=0.999014
[Epoch 0069] loss=15.4221 cls=0.8546 smmd=0.3296 ct=9.0879 rec=1.3095 | train/val/test=0.966/0.662/0.690 | c=0.999014
[Epoch 0070] loss=15.5436 cls=0.9373 smmd=0.3330 ct=9.0838 rec=1.3098 | train/val/test=0.966/0.670/0.690 | c=0.999014
[Epoch 0071] loss=15.3388 cls=0.8033 smmd=0.3338 ct=9.0872 rec=1.3043 | train/val/test=1.000/0.666/0.689 | c=0.999014
[Epoch 0072] loss=15.2422 cls=0.7391 smmd=0.3336 ct=9.0851 rec=1.3059 | train/val/test=1.000/0.668/0.685 | c=0.999014
[Epoch 0073] loss=15.2311 cls=0.7329 smmd=0.3315 ct=9.0900 rec=1.3018 | train/val/test=1.000/0.668/0.682 | c=0.999014
[Epoch 0074] loss=16.0564 cls=1.2738 smmd=0.3327 ct=9.0922 rec=1.3081 | train/val/test=1.000/0.664/0.684 | c=0.999014
[Epoch 0075] loss=15.6351 cls=1.0028 smmd=0.3338 ct=9.0822 rec=1.3065 | train/val/test=1.000/0.668/0.682 | c=0.999014
[Epoch 0076] loss=15.2648 cls=0.7591 smmd=0.3339 ct=9.0826 rec=1.3031 | train/val/test=1.000/0.674/0.684 | c=0.999014
[Epoch 0077] loss=15.6100 cls=0.9874 smmd=0.3319 ct=9.0824 rec=1.3059 | train/val/test=1.000/0.674/0.684 | c=0.999014
[Epoch 0078] loss=15.1849 cls=0.7040 smmd=0.3297 ct=9.0842 rec=1.3053 | train/val/test=1.000/0.672/0.685 | c=0.999014
[Epoch 0079] loss=15.5815 cls=0.9660 smmd=0.3320 ct=9.0872 rec=1.3043 | train/val/test=1.000/0.674/0.684 | c=0.999014
[Epoch 0080] loss=15.5960 cls=0.9746 smmd=0.3307 ct=9.0856 rec=1.3071 | train/val/test=1.000/0.674/0.684 | c=0.999014
[Epoch 0081] loss=15.3627 cls=0.8188 smmd=0.3294 ct=9.0902 rec=1.3042 | train/val/test=1.000/0.674/0.687 | c=0.999014
[Epoch 0082] loss=15.4759 cls=0.8978 smmd=0.3318 ct=9.0857 rec=1.3035 | train/val/test=1.000/0.676/0.690 | c=0.999014
[Epoch 0083] loss=16.4637 cls=1.5461 smmd=0.3321 ct=9.0878 rec=1.3112 | train/val/test=1.000/0.672/0.688 | c=0.999014
[Epoch 0084] loss=14.9986 cls=0.5807 smmd=0.3255 ct=9.0887 rec=1.3027 | train/val/test=1.000/0.670/0.689 | c=0.999014
[Epoch 0085] loss=14.7077 cls=0.3871 smmd=0.3237 ct=9.0921 rec=1.3005 | train/val/test=1.000/0.666/0.687 | c=0.999014
[Epoch 0086] loss=15.5775 cls=0.9683 smmd=0.3253 ct=9.0836 rec=1.3054 | train/val/test=1.000/0.664/0.684 | c=0.999014
[Epoch 0087] loss=15.7503 cls=1.0772 smmd=0.3308 ct=9.0873 rec=1.3059 | train/val/test=1.000/0.664/0.683 | c=0.999014
[Epoch 0088] loss=15.5928 cls=0.9684 smmd=0.3289 ct=9.0904 rec=1.3078 | train/val/test=1.000/0.664/0.682 | c=0.999014
[Epoch 0089] loss=15.1780 cls=0.6973 smmd=0.3297 ct=9.0880 rec=1.3043 | train/val/test=1.000/0.662/0.683 | c=0.999014
[Epoch 0090] loss=15.2563 cls=0.7495 smmd=0.3227 ct=9.0912 rec=1.3048 | train/val/test=1.000/0.660/0.680 | c=0.999014
[Epoch 0091] loss=15.3219 cls=0.8014 smmd=0.3229 ct=9.0846 rec=1.3024 | train/val/test=1.000/0.662/0.680 | c=0.999014
[Epoch 0092] loss=15.4157 cls=0.8659 smmd=0.3223 ct=9.0824 rec=1.3026 | train/val/test=1.000/0.660/0.680 | c=0.999014
[Epoch 0093] loss=14.9792 cls=0.5720 smmd=0.3243 ct=9.0888 rec=1.2991 | train/val/test=1.000/0.660/0.680 | c=0.999014
[Epoch 0094] loss=15.8234 cls=1.1259 smmd=0.3277 ct=9.0880 rec=1.3067 | train/val/test=1.000/0.660/0.679 | c=0.999014
[Epoch 0095] loss=15.4553 cls=0.8905 smmd=0.3260 ct=9.0846 rec=1.3009 | train/val/test=1.000/0.660/0.680 | c=0.999014
[Epoch 0096] loss=16.2485 cls=1.4144 smmd=0.3287 ct=9.0843 rec=1.3045 | train/val/test=1.000/0.660/0.680 | c=0.999014
[Epoch 0097] loss=15.6046 cls=0.9837 smmd=0.3251 ct=9.0830 rec=1.3085 | train/val/test=1.000/0.660/0.680 | c=0.999014
[Epoch 0098] loss=16.1204 cls=1.3325 smmd=0.3235 ct=9.0864 rec=1.3018 | train/val/test=1.000/0.660/0.680 | c=0.999014
[Epoch 0099] loss=15.1236 cls=0.6658 smmd=0.3245 ct=9.0926 rec=1.2984 | train/val/test=1.000/0.660/0.679 | c=0.999014
=== Best @ epoch 44: val=0.6900, test=0.6920 ===
