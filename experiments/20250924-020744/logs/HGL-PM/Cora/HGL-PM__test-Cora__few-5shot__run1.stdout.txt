Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.8094 cls=1.9455 smmd=2.3741 ct=9.2362 rec=1.3889 | train/val/test=0.207/0.294/0.283 | c=0.999014
[Epoch 0001] loss=18.7176 cls=1.9455 smmd=2.2537 ct=9.2304 rec=1.3889 | train/val/test=0.172/0.316/0.319 | c=0.999014
[Epoch 0002] loss=18.5503 cls=1.9324 smmd=2.0655 ct=9.2182 rec=1.3889 | train/val/test=0.172/0.316/0.319 | c=0.999014
[Epoch 0003] loss=18.3759 cls=1.9349 smmd=1.8353 ct=9.2051 rec=1.3889 | train/val/test=0.172/0.316/0.319 | c=0.999014
[Epoch 0004] loss=18.1382 cls=1.9263 smmd=1.5627 ct=9.1789 rec=1.3889 | train/val/test=0.172/0.308/0.313 | c=0.999014
[Epoch 0005] loss=17.8227 cls=1.9029 smmd=1.2470 ct=9.1332 rec=1.3890 | train/val/test=0.310/0.328/0.316 | c=0.999014
[Epoch 0006] loss=17.5270 cls=1.9093 smmd=0.9285 ct=9.0697 rec=1.3890 | train/val/test=0.345/0.334/0.317 | c=0.999014
[Epoch 0007] loss=17.2089 cls=1.8917 smmd=0.6453 ct=8.9979 rec=1.3891 | train/val/test=0.379/0.346/0.331 | c=0.999014
[Epoch 0008] loss=16.9609 cls=1.8702 smmd=0.4541 ct=8.9348 rec=1.3891 | train/val/test=0.414/0.342/0.336 | c=0.999014
[Epoch 0009] loss=16.8005 cls=1.8436 smmd=0.3880 ct=8.8778 rec=1.3890 | train/val/test=0.483/0.346/0.349 | c=0.999014
[Epoch 0010] loss=16.7059 cls=1.8031 smmd=0.4250 ct=8.8320 rec=1.3889 | train/val/test=0.517/0.374/0.389 | c=0.999014
[Epoch 0011] loss=16.6615 cls=1.7490 smmd=0.5395 ct=8.7987 rec=1.3887 | train/val/test=0.724/0.404/0.421 | c=0.999014
[Epoch 0012] loss=16.5803 cls=1.6581 smmd=0.6623 ct=8.7757 rec=1.3882 | train/val/test=0.862/0.512/0.522 | c=0.999014
[Epoch 0013] loss=16.5380 cls=1.6058 smmd=0.7505 ct=8.7575 rec=1.3871 | train/val/test=0.966/0.586/0.584 | c=0.999014
[Epoch 0014] loss=16.1327 cls=1.3284 smmd=0.7937 ct=8.7468 rec=1.3835 | train/val/test=0.966/0.576/0.581 | c=0.999014
[Epoch 0015] loss=15.8716 cls=1.1730 smmd=0.7844 ct=8.7399 rec=1.3757 | train/val/test=0.931/0.578/0.561 | c=0.999014
[Epoch 0016] loss=15.6438 cls=1.0704 smmd=0.7251 ct=8.7402 rec=1.3553 | train/val/test=0.966/0.594/0.597 | c=0.999014
[Epoch 0017] loss=15.5678 cls=1.0760 smmd=0.6389 ct=8.7516 rec=1.3309 | train/val/test=1.000/0.578/0.587 | c=0.999014
[Epoch 0018] loss=16.3318 cls=1.6680 smmd=0.5301 ct=8.7509 rec=1.3016 | train/val/test=0.931/0.588/0.612 | c=0.999014
[Epoch 0019] loss=16.0138 cls=1.4848 smmd=0.4291 ct=8.7673 rec=1.3054 | train/val/test=0.966/0.650/0.659 | c=0.999014
[Epoch 0020] loss=15.9050 cls=1.4506 smmd=0.3419 ct=8.7774 rec=1.2995 | train/val/test=0.966/0.630/0.635 | c=0.999014
[Epoch 0021] loss=16.2195 cls=1.7081 smmd=0.2676 ct=8.7564 rec=1.3041 | train/val/test=0.966/0.612/0.629 | c=0.999014
[Epoch 0022] loss=15.1450 cls=0.9805 smmd=0.2389 ct=8.7742 rec=1.3129 | train/val/test=1.000/0.618/0.641 | c=0.999014
[Epoch 0023] loss=15.4352 cls=1.1769 smmd=0.2263 ct=8.7741 rec=1.3157 | train/val/test=0.966/0.644/0.648 | c=0.999014
[Epoch 0024] loss=15.6156 cls=1.2935 smmd=0.2256 ct=8.7734 rec=1.3200 | train/val/test=0.966/0.636/0.638 | c=0.999014
[Epoch 0025] loss=16.0842 cls=1.6080 smmd=0.2351 ct=8.7581 rec=1.3263 | train/val/test=0.966/0.630/0.636 | c=0.999014
[Epoch 0026] loss=15.7780 cls=1.3997 smmd=0.2443 ct=8.7513 rec=1.3317 | train/val/test=1.000/0.606/0.638 | c=0.999014
[Epoch 0027] loss=15.6994 cls=1.3368 smmd=0.2497 ct=8.7509 rec=1.3395 | train/val/test=0.966/0.598/0.619 | c=0.999014
[Epoch 0028] loss=16.0888 cls=1.5791 smmd=0.2575 ct=8.7561 rec=1.3481 | train/val/test=0.966/0.612/0.627 | c=0.999014
[Epoch 0029] loss=15.6375 cls=1.2939 smmd=0.2383 ct=8.7498 rec=1.3469 | train/val/test=0.966/0.616/0.629 | c=0.999014
[Epoch 0030] loss=15.4099 cls=1.1550 smmd=0.2161 ct=8.7431 rec=1.3500 | train/val/test=0.966/0.606/0.621 | c=0.999014
[Epoch 0031] loss=14.9301 cls=0.8470 smmd=0.2027 ct=8.7422 rec=1.3455 | train/val/test=1.000/0.604/0.618 | c=0.999014
[Epoch 0032] loss=16.9532 cls=1.5801 smmd=0.1877 ct=9.4585 rec=1.3473 | train/val/test=1.000/0.580/0.606 | c=0.999014
[Epoch 0033] loss=16.1778 cls=1.1130 smmd=0.1870 ct=9.4044 rec=1.3448 | train/val/test=1.000/0.594/0.609 | c=0.999014
[Epoch 0034] loss=16.9068 cls=1.6660 smmd=0.2002 ct=9.3146 rec=1.3493 | train/val/test=1.000/0.610/0.628 | c=0.999014
[Epoch 0035] loss=15.7782 cls=0.9718 smmd=0.2480 ct=9.2272 rec=1.3447 | train/val/test=1.000/0.632/0.632 | c=0.999014
[Epoch 0036] loss=15.9590 cls=1.1064 smmd=0.3346 ct=9.1693 rec=1.3407 | train/val/test=1.000/0.638/0.643 | c=0.999014
[Epoch 0037] loss=16.3782 cls=1.3819 smmd=0.4252 ct=9.1261 rec=1.3399 | train/val/test=1.000/0.630/0.635 | c=0.999014
[Epoch 0038] loss=15.8300 cls=1.0064 smmd=0.5081 ct=9.0952 rec=1.3382 | train/val/test=1.000/0.622/0.634 | c=0.999014
[Epoch 0039] loss=15.5250 cls=0.7833 smmd=0.5791 ct=9.0801 rec=1.3379 | train/val/test=1.000/0.622/0.631 | c=0.999014
[Epoch 0040] loss=16.7945 cls=1.6355 smmd=0.5968 ct=9.0619 rec=1.3394 | train/val/test=1.000/0.616/0.632 | c=0.999014
[Epoch 0041] loss=15.7877 cls=0.9740 smmd=0.6062 ct=9.0484 rec=1.3372 | train/val/test=1.000/0.612/0.630 | c=0.999014
[Epoch 0042] loss=16.3314 cls=1.3495 smmd=0.5780 ct=9.0472 rec=1.3382 | train/val/test=1.000/0.596/0.626 | c=0.999014
[Epoch 0043] loss=16.0258 cls=1.1501 smmd=0.5351 ct=9.0697 rec=1.3346 | train/val/test=0.966/0.596/0.621 | c=0.999014
[Epoch 0044] loss=16.5341 cls=1.5020 smmd=0.4877 ct=9.0767 rec=1.3374 | train/val/test=0.966/0.594/0.619 | c=0.999014
[Epoch 0045] loss=16.0603 cls=1.1887 smmd=0.4456 ct=9.1027 rec=1.3324 | train/val/test=0.966/0.598/0.621 | c=0.999014
[Epoch 0046] loss=15.9173 cls=1.1067 smmd=0.4055 ct=9.1141 rec=1.3282 | train/val/test=0.966/0.608/0.631 | c=0.999014
[Epoch 0047] loss=15.7283 cls=0.9814 smmd=0.3837 ct=9.1188 rec=1.3332 | train/val/test=0.966/0.622/0.636 | c=0.999014
[Epoch 0048] loss=15.7524 cls=0.9926 smmd=0.3599 ct=9.1371 rec=1.3333 | train/val/test=0.966/0.630/0.641 | c=0.999014
[Epoch 0049] loss=15.5297 cls=0.8546 smmd=0.3468 ct=9.1451 rec=1.3227 | train/val/test=1.000/0.644/0.643 | c=0.999014
[Epoch 0050] loss=15.6349 cls=0.9291 smmd=0.3191 ct=9.1497 rec=1.3271 | train/val/test=1.000/0.646/0.644 | c=0.999014
[Epoch 0051] loss=15.7944 cls=1.0364 smmd=0.3157 ct=9.1514 rec=1.3263 | train/val/test=1.000/0.640/0.638 | c=0.999014
[Epoch 0052] loss=15.7436 cls=1.0055 smmd=0.3072 ct=9.1546 rec=1.3246 | train/val/test=1.000/0.626/0.641 | c=0.999014
[Epoch 0053] loss=15.3617 cls=0.7561 smmd=0.3049 ct=9.1532 rec=1.3218 | train/val/test=1.000/0.628/0.650 | c=0.999014
[Epoch 0054] loss=15.3772 cls=0.7738 smmd=0.3097 ct=9.1444 rec=1.3200 | train/val/test=1.000/0.630/0.654 | c=0.999014
[Epoch 0055] loss=15.7858 cls=1.0495 smmd=0.3146 ct=9.1390 rec=1.3191 | train/val/test=1.000/0.650/0.654 | c=0.999014
[Epoch 0056] loss=15.5278 cls=0.8782 smmd=0.3275 ct=9.1269 rec=1.3227 | train/val/test=1.000/0.662/0.657 | c=0.999014
[Epoch 0057] loss=15.8973 cls=1.1258 smmd=0.3375 ct=9.1267 rec=1.3173 | train/val/test=1.000/0.662/0.670 | c=0.999014
[Epoch 0058] loss=15.8188 cls=1.0806 smmd=0.3358 ct=9.1198 rec=1.3169 | train/val/test=1.000/0.664/0.680 | c=0.999014
[Epoch 0059] loss=15.4118 cls=0.8058 smmd=0.3406 ct=9.1214 rec=1.3167 | train/val/test=1.000/0.668/0.673 | c=0.999014
[Epoch 0060] loss=15.2022 cls=0.6646 smmd=0.3411 ct=9.1275 rec=1.3131 | train/val/test=1.000/0.670/0.672 | c=0.999014
[Epoch 0061] loss=16.0862 cls=1.2553 smmd=0.3459 ct=9.1174 rec=1.3178 | train/val/test=1.000/0.668/0.671 | c=0.999014
[Epoch 0062] loss=15.7992 cls=1.0741 smmd=0.3371 ct=9.1150 rec=1.3142 | train/val/test=1.000/0.670/0.664 | c=0.999014
[Epoch 0063] loss=16.1808 cls=1.3180 smmd=0.3281 ct=9.1268 rec=1.3183 | train/val/test=1.000/0.658/0.670 | c=0.999014
[Epoch 0064] loss=16.1653 cls=1.3225 smmd=0.3177 ct=9.1215 rec=1.3133 | train/val/test=1.000/0.656/0.666 | c=0.999014
[Epoch 0065] loss=16.1971 cls=1.3424 smmd=0.3202 ct=9.1234 rec=1.3118 | train/val/test=1.000/0.652/0.667 | c=0.999014
[Epoch 0066] loss=15.9408 cls=1.1705 smmd=0.3114 ct=9.1300 rec=1.3113 | train/val/test=1.000/0.648/0.665 | c=0.999014
[Epoch 0067] loss=15.7482 cls=1.0438 smmd=0.3065 ct=9.1302 rec=1.3117 | train/val/test=1.000/0.644/0.667 | c=0.999014
[Epoch 0068] loss=15.4206 cls=0.8238 smmd=0.3084 ct=9.1302 rec=1.3123 | train/val/test=1.000/0.652/0.668 | c=0.999014
[Epoch 0069] loss=15.1770 cls=0.6663 smmd=0.3041 ct=9.1320 rec=1.3081 | train/val/test=1.000/0.654/0.674 | c=0.999014
[Epoch 0070] loss=15.3642 cls=0.7904 smmd=0.3006 ct=9.1298 rec=1.3122 | train/val/test=1.000/0.664/0.673 | c=0.999014
[Epoch 0071] loss=15.5325 cls=0.9104 smmd=0.2964 ct=9.1262 rec=1.3095 | train/val/test=1.000/0.674/0.675 | c=0.999014
[Epoch 0072] loss=16.1058 cls=1.2924 smmd=0.2955 ct=9.1246 rec=1.3115 | train/val/test=1.000/0.676/0.681 | c=0.999014
[Epoch 0073] loss=15.3140 cls=0.7663 smmd=0.2976 ct=9.1257 rec=1.3080 | train/val/test=1.000/0.680/0.694 | c=0.999014
[Epoch 0074] loss=15.8889 cls=1.1475 smmd=0.2978 ct=9.1201 rec=1.3143 | train/val/test=1.000/0.680/0.696 | c=0.999014
[Epoch 0075] loss=15.9736 cls=1.1975 smmd=0.3026 ct=9.1235 rec=1.3156 | train/val/test=1.000/0.678/0.700 | c=0.999014
[Epoch 0076] loss=15.4890 cls=0.8797 smmd=0.3020 ct=9.1242 rec=1.3104 | train/val/test=1.000/0.680/0.699 | c=0.999014
[Epoch 0077] loss=16.0829 cls=1.2780 smmd=0.3016 ct=9.1181 rec=1.3132 | train/val/test=1.000/0.680/0.697 | c=0.999014
[Epoch 0078] loss=15.3389 cls=0.7850 smmd=0.2929 ct=9.1206 rec=1.3122 | train/val/test=1.000/0.678/0.701 | c=0.999014
[Epoch 0079] loss=15.2951 cls=0.7472 smmd=0.2981 ct=9.1304 rec=1.3100 | train/val/test=1.000/0.676/0.698 | c=0.999014
[Epoch 0080] loss=15.7456 cls=1.0548 smmd=0.2937 ct=9.1245 rec=1.3100 | train/val/test=1.000/0.674/0.697 | c=0.999014
[Epoch 0081] loss=15.6176 cls=0.9724 smmd=0.2926 ct=9.1176 rec=1.3133 | train/val/test=1.000/0.674/0.693 | c=0.999014
[Epoch 0082] loss=15.8117 cls=1.0939 smmd=0.2928 ct=9.1239 rec=1.3154 | train/val/test=1.000/0.670/0.691 | c=0.999014
[Epoch 0083] loss=15.3173 cls=0.7671 smmd=0.2915 ct=9.1283 rec=1.3099 | train/val/test=1.000/0.674/0.688 | c=0.999014
[Epoch 0084] loss=15.3332 cls=0.7787 smmd=0.2908 ct=9.1279 rec=1.3096 | train/val/test=1.000/0.668/0.688 | c=0.999014
[Epoch 0085] loss=15.7435 cls=1.0503 smmd=0.2933 ct=9.1269 rec=1.3111 | train/val/test=1.000/0.668/0.687 | c=0.999014
[Epoch 0086] loss=15.0779 cls=0.6114 smmd=0.2876 ct=9.1292 rec=1.3072 | train/val/test=1.000/0.664/0.686 | c=0.999014
[Epoch 0087] loss=15.9194 cls=1.1656 smmd=0.2917 ct=9.1271 rec=1.3134 | train/val/test=1.000/0.666/0.687 | c=0.999014
[Epoch 0088] loss=15.1044 cls=0.6293 smmd=0.2851 ct=9.1278 rec=1.3093 | train/val/test=1.000/0.662/0.688 | c=0.999014
[Epoch 0089] loss=15.9646 cls=1.2027 smmd=0.2907 ct=9.1250 rec=1.3091 | train/val/test=1.000/0.662/0.689 | c=0.999014
[Epoch 0090] loss=15.7026 cls=1.0298 smmd=0.2901 ct=9.1240 rec=1.3086 | train/val/test=1.000/0.660/0.690 | c=0.999014
[Epoch 0091] loss=15.2282 cls=0.7142 smmd=0.2902 ct=9.1229 rec=1.3088 | train/val/test=1.000/0.662/0.687 | c=0.999014
[Epoch 0092] loss=15.4507 cls=0.8642 smmd=0.2858 ct=9.1234 rec=1.3087 | train/val/test=1.000/0.660/0.687 | c=0.999014
[Epoch 0093] loss=15.1555 cls=0.6617 smmd=0.2896 ct=9.1226 rec=1.3130 | train/val/test=1.000/0.658/0.687 | c=0.999014
[Epoch 0094] loss=15.2987 cls=0.7556 smmd=0.2915 ct=9.1285 rec=1.3088 | train/val/test=1.000/0.658/0.687 | c=0.999014
[Epoch 0095] loss=15.4881 cls=0.8845 smmd=0.2857 ct=9.1233 rec=1.3132 | train/val/test=1.000/0.658/0.686 | c=0.999014
[Epoch 0096] loss=15.2179 cls=0.7069 smmd=0.2882 ct=9.1215 rec=1.3111 | train/val/test=1.000/0.658/0.686 | c=0.999014
[Epoch 0097] loss=15.5233 cls=0.9047 smmd=0.2918 ct=9.1263 rec=1.3112 | train/val/test=1.000/0.658/0.686 | c=0.999014
[Epoch 0098] loss=15.5473 cls=0.9236 smmd=0.2851 ct=9.1262 rec=1.3114 | train/val/test=1.000/0.658/0.686 | c=0.999014
[Epoch 0099] loss=15.6375 cls=0.9873 smmd=0.2862 ct=9.1313 rec=1.3035 | train/val/test=1.000/0.658/0.686 | c=0.999014
=== Best @ epoch 73: val=0.6800, test=0.6940 ===
