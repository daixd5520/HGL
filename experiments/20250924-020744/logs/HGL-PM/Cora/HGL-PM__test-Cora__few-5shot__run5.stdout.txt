Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.8817 cls=1.9497 smmd=2.4260 ct=9.2591 rec=1.3889 | train/val/test=0.138/0.158/0.149 | c=0.999014
[Epoch 0001] loss=18.7700 cls=1.9380 smmd=2.3032 ct=9.2527 rec=1.3889 | train/val/test=0.172/0.072/0.091 | c=0.999014
[Epoch 0002] loss=18.6136 cls=1.9247 smmd=2.1195 ct=9.2466 rec=1.3889 | train/val/test=0.172/0.072/0.091 | c=0.999014
[Epoch 0003] loss=18.4553 cls=1.9329 smmd=1.8901 ct=9.2389 rec=1.3889 | train/val/test=0.172/0.072/0.092 | c=0.999014
[Epoch 0004] loss=18.2132 cls=1.9232 smmd=1.5979 ct=9.2212 rec=1.3890 | train/val/test=0.172/0.072/0.093 | c=0.999014
[Epoch 0005] loss=17.9356 cls=1.9117 smmd=1.2656 ct=9.1997 rec=1.3891 | train/val/test=0.172/0.074/0.096 | c=0.999014
[Epoch 0006] loss=17.6271 cls=1.9030 smmd=0.9160 ct=9.1606 rec=1.3891 | train/val/test=0.241/0.086/0.113 | c=0.999014
[Epoch 0007] loss=17.3418 cls=1.9065 smmd=0.6038 ct=9.1052 rec=1.3892 | train/val/test=0.310/0.134/0.155 | c=0.999014
[Epoch 0008] loss=17.0211 cls=1.8551 smmd=0.3914 ct=9.0321 rec=1.3892 | train/val/test=0.379/0.272/0.287 | c=0.999014
[Epoch 0009] loss=16.8312 cls=1.8204 smmd=0.3256 ct=8.9616 rec=1.3891 | train/val/test=0.483/0.382/0.405 | c=0.999014
[Epoch 0010] loss=16.7601 cls=1.7907 smmd=0.3916 ct=8.9058 rec=1.3890 | train/val/test=0.655/0.470/0.486 | c=0.999014
[Epoch 0011] loss=16.7609 cls=1.7603 smmd=0.5247 ct=8.8701 rec=1.3887 | train/val/test=0.793/0.512/0.517 | c=0.999014
[Epoch 0012] loss=17.5720 cls=1.6716 smmd=0.6648 ct=9.5215 rec=1.3882 | train/val/test=0.897/0.560/0.579 | c=0.999014
[Epoch 0013] loss=17.0990 cls=1.5384 smmd=0.7865 ct=9.2475 rec=1.3870 | train/val/test=0.931/0.610/0.610 | c=0.999014
[Epoch 0014] loss=16.8479 cls=1.4437 smmd=0.9167 ct=9.0968 rec=1.3843 | train/val/test=0.931/0.608/0.619 | c=0.999014
[Epoch 0015] loss=16.1749 cls=1.0080 smmd=1.0538 ct=9.0189 rec=1.3754 | train/val/test=0.931/0.596/0.617 | c=0.999014
[Epoch 0016] loss=16.1578 cls=1.0149 smmd=1.1392 ct=8.9700 rec=1.3606 | train/val/test=0.931/0.646/0.629 | c=0.999014
[Epoch 0017] loss=16.6939 cls=1.4010 smmd=1.1840 ct=8.9449 rec=1.3345 | train/val/test=0.931/0.564/0.569 | c=0.999014
[Epoch 0018] loss=16.5626 cls=1.3536 smmd=1.1782 ct=8.9333 rec=1.3089 | train/val/test=0.931/0.534/0.527 | c=0.999014
[Epoch 0019] loss=16.3636 cls=1.2553 smmd=1.1285 ct=8.9336 rec=1.2981 | train/val/test=0.966/0.610/0.617 | c=0.999014
[Epoch 0020] loss=16.0015 cls=1.0678 smmd=1.0418 ct=8.9375 rec=1.2824 | train/val/test=1.000/0.628/0.636 | c=0.999014
[Epoch 0021] loss=17.1051 cls=1.8402 smmd=0.9303 ct=8.9544 rec=1.2831 | train/val/test=1.000/0.654/0.635 | c=0.999014
[Epoch 0022] loss=16.0018 cls=1.1318 smmd=0.8175 ct=8.9718 rec=1.2928 | train/val/test=1.000/0.626/0.648 | c=0.999014
[Epoch 0023] loss=16.3751 cls=1.3588 smmd=0.7285 ct=9.0213 rec=1.3120 | train/val/test=1.000/0.588/0.644 | c=0.999014
[Epoch 0024] loss=16.2099 cls=1.2080 smmd=0.6707 ct=9.0806 rec=1.3272 | train/val/test=1.000/0.618/0.649 | c=0.999014
[Epoch 0025] loss=15.9544 cls=1.0296 smmd=0.6004 ct=9.1317 rec=1.3241 | train/val/test=1.000/0.628/0.653 | c=0.999014
[Epoch 0026] loss=15.9495 cls=1.0332 smmd=0.5277 ct=9.1589 rec=1.3273 | train/val/test=0.966/0.628/0.649 | c=0.999014
[Epoch 0027] loss=16.2671 cls=1.2807 smmd=0.4728 ct=9.1529 rec=1.3228 | train/val/test=0.966/0.602/0.615 | c=0.999014
[Epoch 0028] loss=16.1444 cls=1.2251 smmd=0.4157 ct=9.1568 rec=1.3199 | train/val/test=0.966/0.616/0.615 | c=0.999014
[Epoch 0029] loss=16.2270 cls=1.2793 smmd=0.3911 ct=9.1676 rec=1.3227 | train/val/test=0.966/0.640/0.637 | c=0.999014
[Epoch 0030] loss=15.6027 cls=0.8652 smmd=0.3861 ct=9.1757 rec=1.3164 | train/val/test=0.966/0.658/0.668 | c=0.999014
[Epoch 0031] loss=16.3839 cls=1.3891 smmd=0.3806 ct=9.1694 rec=1.3210 | train/val/test=0.966/0.664/0.686 | c=0.999014
[Epoch 0032] loss=15.8786 cls=1.0610 smmd=0.3820 ct=9.1569 rec=1.3224 | train/val/test=1.000/0.666/0.665 | c=0.999014
[Epoch 0033] loss=15.7931 cls=1.0219 smmd=0.3870 ct=9.1281 rec=1.3267 | train/val/test=1.000/0.636/0.651 | c=0.999014
[Epoch 0034] loss=16.1079 cls=1.2383 smmd=0.3962 ct=9.1140 rec=1.3281 | train/val/test=1.000/0.634/0.646 | c=0.999014
[Epoch 0035] loss=15.9942 cls=1.1611 smmd=0.4044 ct=9.1017 rec=1.3358 | train/val/test=1.000/0.600/0.642 | c=0.999014
[Epoch 0036] loss=16.1651 cls=1.2669 smmd=0.4157 ct=9.1025 rec=1.3378 | train/val/test=1.000/0.604/0.627 | c=0.999014
[Epoch 0037] loss=16.2044 cls=1.2826 smmd=0.4218 ct=9.1110 rec=1.3381 | train/val/test=1.000/0.600/0.621 | c=0.999014
[Epoch 0038] loss=16.1431 cls=1.2497 smmd=0.4111 ct=9.1100 rec=1.3361 | train/val/test=0.966/0.594/0.619 | c=0.999014
[Epoch 0039] loss=15.4680 cls=0.8110 smmd=0.3913 ct=9.1082 rec=1.3357 | train/val/test=0.966/0.606/0.609 | c=0.999014
[Epoch 0040] loss=17.1600 cls=1.9462 smmd=0.3751 ct=9.1058 rec=1.3379 | train/val/test=0.931/0.606/0.614 | c=0.999014
[Epoch 0041] loss=15.8415 cls=1.0721 smmd=0.3559 ct=9.1133 rec=1.3356 | train/val/test=0.931/0.612/0.611 | c=0.999014
[Epoch 0042] loss=15.7229 cls=0.9987 smmd=0.3391 ct=9.1183 rec=1.3336 | train/val/test=0.931/0.614/0.610 | c=0.999014
[Epoch 0043] loss=16.1187 cls=1.2515 smmd=0.3314 ct=9.1339 rec=1.3346 | train/val/test=0.931/0.604/0.616 | c=0.999014
[Epoch 0044] loss=16.0954 cls=1.2328 smmd=0.3280 ct=9.1361 rec=1.3373 | train/val/test=0.931/0.590/0.613 | c=0.999014
[Epoch 0045] loss=15.7102 cls=0.9735 smmd=0.3212 ct=9.1451 rec=1.3353 | train/val/test=0.931/0.592/0.612 | c=0.999014
[Epoch 0046] loss=16.1259 cls=1.2550 smmd=0.3266 ct=9.1392 rec=1.3337 | train/val/test=0.931/0.594/0.617 | c=0.999014
[Epoch 0047] loss=16.3538 cls=1.4154 smmd=0.3221 ct=9.1267 rec=1.3378 | train/val/test=0.931/0.598/0.621 | c=0.999014
[Epoch 0048] loss=15.4469 cls=0.8162 smmd=0.3247 ct=9.1298 rec=1.3291 | train/val/test=0.931/0.602/0.619 | c=0.999014
[Epoch 0049] loss=16.0015 cls=1.1867 smmd=0.3299 ct=9.1237 rec=1.3311 | train/val/test=0.931/0.606/0.618 | c=0.999014
[Epoch 0050] loss=15.9304 cls=1.1408 smmd=0.3346 ct=9.1196 rec=1.3310 | train/val/test=0.931/0.614/0.614 | c=0.999014
[Epoch 0051] loss=15.8341 cls=1.0777 smmd=0.3393 ct=9.1119 rec=1.3341 | train/val/test=0.931/0.606/0.615 | c=0.999014
[Epoch 0052] loss=15.8358 cls=1.0832 smmd=0.3395 ct=9.1104 rec=1.3312 | train/val/test=0.931/0.606/0.617 | c=0.999014
[Epoch 0053] loss=15.1024 cls=0.6000 smmd=0.3376 ct=9.1135 rec=1.3241 | train/val/test=0.897/0.604/0.618 | c=0.999014
[Epoch 0054] loss=15.1214 cls=0.6167 smmd=0.3350 ct=9.1102 rec=1.3241 | train/val/test=0.966/0.602/0.621 | c=0.999014
[Epoch 0055] loss=15.5256 cls=0.8854 smmd=0.3279 ct=9.1126 rec=1.3260 | train/val/test=1.000/0.602/0.624 | c=0.999014
[Epoch 0056] loss=15.3216 cls=0.7519 smmd=0.3287 ct=9.1101 rec=1.3254 | train/val/test=1.000/0.608/0.630 | c=0.999014
[Epoch 0057] loss=15.9354 cls=1.1654 smmd=0.3158 ct=9.1107 rec=1.3265 | train/val/test=1.000/0.612/0.635 | c=0.999014
[Epoch 0058] loss=15.6128 cls=0.9544 smmd=0.3113 ct=9.1099 rec=1.3252 | train/val/test=1.000/0.614/0.636 | c=0.999014
[Epoch 0059] loss=15.6164 cls=0.9575 smmd=0.3061 ct=9.1112 rec=1.3258 | train/val/test=1.000/0.620/0.640 | c=0.999014
[Epoch 0060] loss=15.6682 cls=0.9903 smmd=0.3102 ct=9.1159 rec=1.3219 | train/val/test=1.000/0.624/0.644 | c=0.999014
[Epoch 0061] loss=16.3968 cls=1.4756 smmd=0.3054 ct=9.1169 rec=1.3235 | train/val/test=1.000/0.628/0.647 | c=0.999014
[Epoch 0062] loss=15.2201 cls=0.6912 smmd=0.3076 ct=9.1176 rec=1.3219 | train/val/test=1.000/0.634/0.648 | c=0.999014
[Epoch 0063] loss=15.6277 cls=0.9621 smmd=0.3103 ct=9.1200 rec=1.3196 | train/val/test=1.000/0.636/0.647 | c=0.999014
[Epoch 0064] loss=15.4715 cls=0.8567 smmd=0.3121 ct=9.1193 rec=1.3206 | train/val/test=1.000/0.626/0.648 | c=0.999014
[Epoch 0065] loss=15.5995 cls=0.9397 smmd=0.3178 ct=9.1189 rec=1.3206 | train/val/test=1.000/0.632/0.649 | c=0.999014
[Epoch 0066] loss=15.4816 cls=0.8627 smmd=0.3156 ct=9.1207 rec=1.3185 | train/val/test=1.000/0.632/0.651 | c=0.999014
[Epoch 0067] loss=15.4246 cls=0.8250 smmd=0.3148 ct=9.1187 rec=1.3203 | train/val/test=1.000/0.630/0.654 | c=0.999014
[Epoch 0068] loss=16.4131 cls=1.4822 smmd=0.3087 ct=9.1239 rec=1.3204 | train/val/test=1.000/0.632/0.659 | c=0.999014
[Epoch 0069] loss=15.7495 cls=1.0500 smmd=0.3055 ct=9.1155 rec=1.3190 | train/val/test=1.000/0.634/0.664 | c=0.999014
[Epoch 0070] loss=15.1480 cls=0.6556 smmd=0.3015 ct=9.1141 rec=1.3158 | train/val/test=1.000/0.646/0.672 | c=0.999014
[Epoch 0071] loss=16.5885 cls=1.6171 smmd=0.2963 ct=9.1141 rec=1.3169 | train/val/test=1.000/0.646/0.673 | c=0.999014
[Epoch 0072] loss=15.9021 cls=1.1642 smmd=0.2897 ct=9.1142 rec=1.3154 | train/val/test=1.000/0.640/0.679 | c=0.999014
[Epoch 0073] loss=15.2827 cls=0.7496 smmd=0.2910 ct=9.1184 rec=1.3129 | train/val/test=1.000/0.644/0.679 | c=0.999014
[Epoch 0074] loss=15.4515 cls=0.8643 smmd=0.2904 ct=9.1129 rec=1.3157 | train/val/test=1.000/0.646/0.676 | c=0.999014
[Epoch 0075] loss=15.1182 cls=0.6423 smmd=0.2886 ct=9.1172 rec=1.3127 | train/val/test=1.000/0.648/0.676 | c=0.999014
[Epoch 0076] loss=15.2290 cls=0.7169 smmd=0.2840 ct=9.1162 rec=1.3148 | train/val/test=1.000/0.646/0.676 | c=0.999014
[Epoch 0077] loss=15.3434 cls=0.7948 smmd=0.2850 ct=9.1199 rec=1.3099 | train/val/test=1.000/0.646/0.677 | c=0.999014
[Epoch 0078] loss=15.8217 cls=1.1089 smmd=0.2814 ct=9.1203 rec=1.3156 | train/val/test=1.000/0.648/0.674 | c=0.999014
[Epoch 0079] loss=15.4318 cls=0.8574 smmd=0.2795 ct=9.1160 rec=1.3120 | train/val/test=1.000/0.652/0.674 | c=0.999014
[Epoch 0080] loss=16.5387 cls=1.5882 smmd=0.2831 ct=9.1163 rec=1.3170 | train/val/test=1.000/0.654/0.671 | c=0.999014
[Epoch 0081] loss=15.6719 cls=1.0191 smmd=0.2785 ct=9.1117 rec=1.3145 | train/val/test=1.000/0.650/0.674 | c=0.999014
[Epoch 0082] loss=15.1391 cls=0.6616 smmd=0.2786 ct=9.1148 rec=1.3141 | train/val/test=1.000/0.644/0.673 | c=0.999014
[Epoch 0083] loss=15.5974 cls=0.9661 smmd=0.2813 ct=9.1148 rec=1.3139 | train/val/test=1.000/0.644/0.671 | c=0.999014
[Epoch 0084] loss=15.7827 cls=1.0888 smmd=0.2812 ct=9.1165 rec=1.3133 | train/val/test=1.000/0.644/0.671 | c=0.999014
[Epoch 0085] loss=15.7749 cls=1.0802 smmd=0.2841 ct=9.1123 rec=1.3186 | train/val/test=1.000/0.646/0.671 | c=0.999014
[Epoch 0086] loss=15.6158 cls=0.9804 smmd=0.2803 ct=9.1102 rec=1.3160 | train/val/test=1.000/0.646/0.671 | c=0.999014
[Epoch 0087] loss=15.7072 cls=1.0414 smmd=0.2815 ct=9.1109 rec=1.3149 | train/val/test=1.000/0.648/0.673 | c=0.999014
[Epoch 0088] loss=15.1193 cls=0.6485 smmd=0.2786 ct=9.1154 rec=1.3135 | train/val/test=1.000/0.648/0.671 | c=0.999014
[Epoch 0089] loss=15.0925 cls=0.6313 smmd=0.2834 ct=9.1127 rec=1.3129 | train/val/test=1.000/0.650/0.671 | c=0.999014
[Epoch 0090] loss=15.7381 cls=1.0607 smmd=0.2825 ct=9.1107 rec=1.3158 | train/val/test=1.000/0.652/0.672 | c=0.999014
[Epoch 0091] loss=15.5811 cls=0.9562 smmd=0.2830 ct=9.1098 rec=1.3162 | train/val/test=1.000/0.652/0.673 | c=0.999014
[Epoch 0092] loss=15.2646 cls=0.7462 smmd=0.2808 ct=9.1126 rec=1.3140 | train/val/test=1.000/0.652/0.673 | c=0.999014
[Epoch 0093] loss=15.9567 cls=1.2029 smmd=0.2790 ct=9.1125 rec=1.3192 | train/val/test=1.000/0.652/0.673 | c=0.999014
[Epoch 0094] loss=15.3694 cls=0.8146 smmd=0.2809 ct=9.1114 rec=1.3163 | train/val/test=1.000/0.652/0.673 | c=0.999014
[Epoch 0095] loss=15.1250 cls=0.6551 smmd=0.2803 ct=9.1099 rec=1.3145 | train/val/test=1.000/0.652/0.673 | c=0.999014
[Epoch 0096] loss=15.5635 cls=0.9463 smmd=0.2806 ct=9.1107 rec=1.3148 | train/val/test=1.000/0.652/0.673 | c=0.999014
[Epoch 0097] loss=15.0161 cls=0.5826 smmd=0.2804 ct=9.1127 rec=1.3121 | train/val/test=1.000/0.652/0.673 | c=0.999014
[Epoch 0098] loss=15.2561 cls=0.7404 smmd=0.2819 ct=9.1114 rec=1.3146 | train/val/test=1.000/0.652/0.673 | c=0.999014
[Epoch 0099] loss=16.1627 cls=1.3415 smmd=0.2805 ct=9.1118 rec=1.3180 | train/val/test=1.000/0.652/0.673 | c=0.999014
=== Best @ epoch 32: val=0.6660, test=0.6650 ===
