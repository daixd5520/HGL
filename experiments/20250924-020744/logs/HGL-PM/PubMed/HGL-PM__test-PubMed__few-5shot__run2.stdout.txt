Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=23.1385 cls=1.1079 smmd=4.0474 ct=11.2762 rec=1.4138 | train/val/test=0.308/0.416/0.407 | c=0.999014
[Epoch 0001] loss=22.7270 cls=1.1002 smmd=3.8175 ct=11.2737 rec=1.4137 | train/val/test=0.308/0.416/0.407 | c=0.999014
[Epoch 0002] loss=22.0614 cls=1.1001 smmd=3.4406 ct=11.2690 rec=1.4137 | train/val/test=0.308/0.416/0.407 | c=0.999014
[Epoch 0003] loss=21.0605 cls=1.0997 smmd=2.8758 ct=11.2597 rec=1.4136 | train/val/test=0.308/0.416/0.407 | c=0.999014
[Epoch 0004] loss=19.6721 cls=1.0996 smmd=2.0978 ct=11.2390 rec=1.4136 | train/val/test=0.462/0.428/0.433 | c=0.999014
[Epoch 0005] loss=18.0063 cls=1.0919 smmd=1.1799 ct=11.1978 rec=1.4136 | train/val/test=0.538/0.470/0.456 | c=0.999014
[Epoch 0006] loss=17.1016 cls=1.0843 smmd=0.6828 ct=11.1754 rec=1.4136 | train/val/test=0.385/0.390/0.417 | c=0.999014
[Epoch 0007] loss=17.8486 cls=1.0853 smmd=1.1009 ct=11.1865 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.999014
[Epoch 0008] loss=18.8301 cls=1.0847 smmd=1.6648 ct=11.1829 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.999014
[Epoch 0009] loss=19.0245 cls=1.0758 smmd=1.8107 ct=11.1412 rec=1.4136 | train/val/test=0.462/0.390/0.416 | c=0.999014
[Epoch 0010] loss=18.3233 cls=1.0659 smmd=1.4816 ct=11.0505 rec=1.4136 | train/val/test=0.538/0.418/0.447 | c=0.999014
[Epoch 0011] loss=17.3099 cls=1.0685 smmd=0.9693 ct=10.9592 rec=1.4136 | train/val/test=0.615/0.484/0.525 | c=0.999014
[Epoch 0012] loss=16.8996 cls=1.0510 smmd=0.7630 ct=10.9312 rec=1.4136 | train/val/test=0.615/0.546/0.571 | c=0.999014
[Epoch 0013] loss=17.0111 cls=1.0392 smmd=0.8381 ct=10.9228 rec=1.4135 | train/val/test=0.615/0.564/0.601 | c=0.999014
[Epoch 0014] loss=17.0065 cls=1.0389 smmd=0.8471 ct=10.9073 rec=1.4134 | train/val/test=0.615/0.604/0.634 | c=0.999014
[Epoch 0015] loss=17.5928 cls=1.0280 smmd=0.7214 ct=11.5340 rec=1.4132 | train/val/test=0.615/0.498/0.546 | c=0.999014
[Epoch 0016] loss=17.1811 cls=0.9871 smmd=0.6887 ct=11.2847 rec=1.4134 | train/val/test=0.615/0.498/0.533 | c=0.999014
[Epoch 0017] loss=17.2001 cls=0.9588 smmd=0.7900 ct=11.1793 rec=1.4135 | train/val/test=0.692/0.584/0.611 | c=0.999014
[Epoch 0018] loss=17.3687 cls=0.9548 smmd=0.8606 ct=11.2165 rec=1.4129 | train/val/test=0.692/0.626/0.637 | c=0.999014
[Epoch 0019] loss=17.5020 cls=0.9533 smmd=0.8809 ct=11.2926 rec=1.4126 | train/val/test=0.615/0.574/0.608 | c=0.999014
[Epoch 0020] loss=17.5181 cls=0.8965 smmd=0.9181 ct=11.2877 rec=1.4127 | train/val/test=0.615/0.568/0.601 | c=0.999014
[Epoch 0021] loss=17.5930 cls=0.8942 smmd=0.9675 ct=11.2801 rec=1.4126 | train/val/test=0.615/0.578/0.610 | c=0.999014
[Epoch 0022] loss=17.5894 cls=0.8664 smmd=0.9912 ct=11.2616 rec=1.4123 | train/val/test=0.692/0.614/0.638 | c=0.999014
[Epoch 0023] loss=17.6450 cls=0.9007 smmd=1.0135 ct=11.2550 rec=1.4112 | train/val/test=0.846/0.650/0.673 | c=0.999014
[Epoch 0024] loss=17.4761 cls=0.7802 smmd=0.9797 ct=11.2406 rec=1.4092 | train/val/test=0.846/0.658/0.677 | c=0.999014
[Epoch 0025] loss=17.3266 cls=0.8196 smmd=0.8851 ct=11.2310 rec=1.4067 | train/val/test=0.846/0.678/0.691 | c=0.999014
[Epoch 0026] loss=17.1717 cls=0.8509 smmd=0.7530 ct=11.2727 rec=1.4029 | train/val/test=0.923/0.692/0.687 | c=0.999014
[Epoch 0027] loss=17.0793 cls=0.8982 smmd=0.6563 ct=11.3059 rec=1.3984 | train/val/test=0.923/0.684/0.678 | c=0.999014
[Epoch 0028] loss=16.9651 cls=0.8139 smmd=0.6345 ct=11.2970 rec=1.3953 | train/val/test=0.846/0.684/0.682 | c=0.999014
[Epoch 0029] loss=16.8289 cls=0.6724 smmd=0.6433 ct=11.2623 rec=1.3944 | train/val/test=0.846/0.684/0.686 | c=0.999014
[Epoch 0030] loss=16.7860 cls=0.6551 smmd=0.6413 ct=11.2425 rec=1.3926 | train/val/test=0.923/0.680/0.683 | c=0.999014
[Epoch 0031] loss=16.8198 cls=0.6649 smmd=0.6528 ct=11.2480 rec=1.3909 | train/val/test=0.923/0.690/0.693 | c=0.999014
[Epoch 0032] loss=16.8694 cls=0.6644 smmd=0.6760 ct=11.2552 rec=1.3907 | train/val/test=0.923/0.686/0.689 | c=0.999014
[Epoch 0033] loss=16.9408 cls=0.7098 smmd=0.6895 ct=11.2658 rec=1.3905 | train/val/test=1.000/0.688/0.696 | c=0.999014
[Epoch 0034] loss=16.9188 cls=0.6162 smmd=0.7010 ct=11.2885 rec=1.3873 | train/val/test=1.000/0.690/0.699 | c=0.999014
[Epoch 0035] loss=16.9365 cls=0.6222 smmd=0.7312 ct=11.2575 rec=1.3886 | train/val/test=1.000/0.694/0.703 | c=0.999014
[Epoch 0036] loss=17.0394 cls=0.8115 smmd=0.7066 ct=11.2612 rec=1.3865 | train/val/test=1.000/0.692/0.704 | c=0.999014
[Epoch 0037] loss=16.9053 cls=0.6818 smmd=0.6813 ct=11.2686 rec=1.3812 | train/val/test=1.000/0.690/0.699 | c=0.999014
[Epoch 0038] loss=17.0310 cls=0.9439 smmd=0.6725 ct=11.2264 rec=1.3799 | train/val/test=1.000/0.702/0.698 | c=0.999014
[Epoch 0039] loss=16.6599 cls=0.4881 smmd=0.6541 ct=11.2277 rec=1.3827 | train/val/test=1.000/0.706/0.697 | c=0.999014
[Epoch 0040] loss=16.7149 cls=0.6764 smmd=0.5950 ct=11.2442 rec=1.3721 | train/val/test=1.000/0.700/0.694 | c=0.999014
[Epoch 0041] loss=16.9490 cls=1.0289 smmd=0.5722 ct=11.2526 rec=1.3692 | train/val/test=1.000/0.702/0.705 | c=0.999014
[Epoch 0042] loss=16.5853 cls=0.5593 smmd=0.5712 ct=11.2436 rec=1.3735 | train/val/test=1.000/0.710/0.710 | c=0.999014
[Epoch 0043] loss=16.5900 cls=0.5847 smmd=0.5639 ct=11.2424 rec=1.3739 | train/val/test=1.000/0.702/0.689 | c=0.999014
[Epoch 0044] loss=16.9929 cls=1.1316 smmd=0.5556 ct=11.2494 rec=1.3691 | train/val/test=0.923/0.712/0.696 | c=0.999014
[Epoch 0045] loss=16.5611 cls=0.5487 smmd=0.5686 ct=11.2353 rec=1.3713 | train/val/test=0.923/0.694/0.691 | c=0.999014
[Epoch 0046] loss=16.8809 cls=0.9560 smmd=0.5852 ct=11.2231 rec=1.3748 | train/val/test=0.923/0.696/0.685 | c=0.999014
[Epoch 0047] loss=16.7415 cls=0.7638 smmd=0.5861 ct=11.2258 rec=1.3735 | train/val/test=0.923/0.696/0.680 | c=0.999014
[Epoch 0048] loss=17.2085 cls=1.3715 smmd=0.5790 ct=11.2454 rec=1.3688 | train/val/test=0.923/0.668/0.672 | c=0.999014
[Epoch 0049] loss=16.9871 cls=1.0822 smmd=0.5863 ct=11.2313 rec=1.3716 | train/val/test=0.923/0.648/0.644 | c=0.999014
[Epoch 0050] loss=16.8466 cls=0.8780 smmd=0.5927 ct=11.2309 rec=1.3765 | train/val/test=0.923/0.684/0.651 | c=0.999014
[Epoch 0051] loss=17.1026 cls=1.2216 smmd=0.5866 ct=11.2387 rec=1.3738 | train/val/test=0.923/0.672/0.665 | c=0.999014
[Epoch 0052] loss=17.0136 cls=1.0958 smmd=0.5837 ct=11.2476 rec=1.3714 | train/val/test=0.923/0.664/0.653 | c=0.999014
[Epoch 0053] loss=17.0205 cls=1.1393 smmd=0.5892 ct=11.2200 rec=1.3724 | train/val/test=0.923/0.640/0.634 | c=0.999014
[Epoch 0054] loss=16.9427 cls=1.0050 smmd=0.6024 ct=11.2171 rec=1.3810 | train/val/test=0.923/0.650/0.635 | c=0.999014
[Epoch 0055] loss=16.9393 cls=1.0472 smmd=0.5728 ct=11.2303 rec=1.3803 | train/val/test=1.000/0.674/0.655 | c=0.999014
[Epoch 0056] loss=16.8610 cls=0.9629 smmd=0.5570 ct=11.2415 rec=1.3750 | train/val/test=1.000/0.686/0.669 | c=0.999014
[Epoch 0057] loss=16.7197 cls=0.7925 smmd=0.5533 ct=11.2360 rec=1.3754 | train/val/test=1.000/0.674/0.662 | c=0.999014
[Epoch 0058] loss=16.8152 cls=0.9005 smmd=0.5667 ct=11.2279 rec=1.3794 | train/val/test=1.000/0.646/0.657 | c=0.999014
[Epoch 0059] loss=16.8240 cls=0.8964 smmd=0.5768 ct=11.2221 rec=1.3840 | train/val/test=1.000/0.676/0.669 | c=0.999014
[Epoch 0060] loss=16.7945 cls=0.8818 smmd=0.5707 ct=11.2162 rec=1.3834 | train/val/test=1.000/0.694/0.681 | c=0.999014
[Epoch 0061] loss=16.7273 cls=0.7518 smmd=0.5802 ct=11.2265 rec=1.3840 | train/val/test=1.000/0.680/0.678 | c=0.999014
[Epoch 0062] loss=17.1826 cls=1.3633 smmd=0.5816 ct=11.2217 rec=1.3853 | train/val/test=1.000/0.672/0.668 | c=0.999014
[Epoch 0063] loss=16.4995 cls=0.4474 smmd=0.5912 ct=11.2109 rec=1.3881 | train/val/test=1.000/0.662/0.675 | c=0.999014
[Epoch 0064] loss=16.7013 cls=0.6856 smmd=0.6038 ct=11.2109 rec=1.3910 | train/val/test=1.000/0.672/0.684 | c=0.999014
[Epoch 0065] loss=16.5859 cls=0.5244 smmd=0.6067 ct=11.2113 rec=1.3904 | train/val/test=1.000/0.682/0.691 | c=0.999014
[Epoch 0066] loss=16.8082 cls=0.8094 smmd=0.6085 ct=11.2153 rec=1.3911 | train/val/test=1.000/0.680/0.692 | c=0.999014
[Epoch 0067] loss=16.5542 cls=0.4518 smmd=0.6176 ct=11.2136 rec=1.3921 | train/val/test=1.000/0.674/0.684 | c=0.999014
[Epoch 0068] loss=16.8771 cls=0.8773 smmd=0.6255 ct=11.2051 rec=1.3946 | train/val/test=0.923/0.668/0.679 | c=0.999014
[Epoch 0069] loss=16.6741 cls=0.5923 smmd=0.6357 ct=11.1991 rec=1.3962 | train/val/test=0.923/0.674/0.686 | c=0.999014
[Epoch 0070] loss=16.5798 cls=0.4678 smmd=0.6344 ct=11.2004 rec=1.3955 | train/val/test=0.923/0.680/0.691 | c=0.999014
[Epoch 0071] loss=16.6514 cls=0.5692 smmd=0.6261 ct=11.2086 rec=1.3942 | train/val/test=0.923/0.676/0.693 | c=0.999014
[Epoch 0072] loss=16.9221 cls=0.9277 smmd=0.6228 ct=11.2146 rec=1.3935 | train/val/test=0.923/0.680/0.688 | c=0.999014
[Epoch 0073] loss=16.7306 cls=0.6751 smmd=0.6209 ct=11.2156 rec=1.3933 | train/val/test=0.923/0.672/0.682 | c=0.999014
[Epoch 0074] loss=16.7261 cls=0.6827 smmd=0.6205 ct=11.2081 rec=1.3942 | train/val/test=0.923/0.666/0.679 | c=0.999014
[Epoch 0075] loss=16.5736 cls=0.4874 smmd=0.6211 ct=11.2025 rec=1.3948 | train/val/test=0.923/0.670/0.677 | c=0.999014
[Epoch 0076] loss=16.7586 cls=0.7378 smmd=0.6216 ct=11.1998 rec=1.3944 | train/val/test=0.923/0.684/0.681 | c=0.999014
[Epoch 0077] loss=16.7630 cls=0.7395 smmd=0.6215 ct=11.2028 rec=1.3930 | train/val/test=0.923/0.686/0.682 | c=0.999014
[Epoch 0078] loss=16.7387 cls=0.7067 smmd=0.6195 ct=11.2059 rec=1.3918 | train/val/test=0.923/0.690/0.687 | c=0.999014
[Epoch 0079] loss=16.6252 cls=0.5654 smmd=0.6167 ct=11.2039 rec=1.3918 | train/val/test=0.923/0.680/0.688 | c=0.999014
[Epoch 0080] loss=16.6404 cls=0.5849 smmd=0.6187 ct=11.2015 rec=1.3925 | train/val/test=0.923/0.672/0.678 | c=0.999014
[Epoch 0081] loss=16.6874 cls=0.6471 smmd=0.6206 ct=11.1991 rec=1.3933 | train/val/test=0.923/0.664/0.674 | c=0.999014
[Epoch 0082] loss=16.7196 cls=0.6896 smmd=0.6208 ct=11.1988 rec=1.3939 | train/val/test=0.923/0.666/0.679 | c=0.999014
[Epoch 0083] loss=16.7544 cls=0.7316 smmd=0.6232 ct=11.1982 rec=1.3937 | train/val/test=0.923/0.674/0.683 | c=0.999014
[Epoch 0084] loss=16.5708 cls=0.4928 smmd=0.6208 ct=11.1981 rec=1.3931 | train/val/test=0.923/0.680/0.682 | c=0.999014
[Epoch 0085] loss=16.6979 cls=0.6589 smmd=0.6217 ct=11.1989 rec=1.3927 | train/val/test=0.923/0.680/0.687 | c=0.999014
[Epoch 0086] loss=16.6054 cls=0.5309 smmd=0.6235 ct=11.1995 rec=1.3920 | train/val/test=0.923/0.682/0.689 | c=0.999014
[Epoch 0087] loss=16.6115 cls=0.5419 smmd=0.6215 ct=11.2006 rec=1.3918 | train/val/test=0.923/0.684/0.689 | c=0.999014
[Epoch 0088] loss=16.7274 cls=0.6886 smmd=0.6245 ct=11.2010 rec=1.3918 | train/val/test=0.923/0.684/0.689 | c=0.999014
[Epoch 0089] loss=16.6642 cls=0.6064 smmd=0.6235 ct=11.2013 rec=1.3916 | train/val/test=0.923/0.682/0.690 | c=0.999014
[Epoch 0090] loss=16.8186 cls=0.8090 smmd=0.6253 ct=11.2007 rec=1.3919 | train/val/test=0.923/0.680/0.687 | c=0.999014
[Epoch 0091] loss=16.6226 cls=0.5503 smmd=0.6244 ct=11.2004 rec=1.3920 | train/val/test=0.923/0.678/0.687 | c=0.999014
[Epoch 0092] loss=16.6641 cls=0.6058 smmd=0.6252 ct=11.1990 rec=1.3923 | train/val/test=0.923/0.676/0.687 | c=0.999014
[Epoch 0093] loss=16.7262 cls=0.6844 smmd=0.6273 ct=11.1985 rec=1.3924 | train/val/test=0.923/0.676/0.685 | c=0.999014
[Epoch 0094] loss=16.6349 cls=0.5577 smmd=0.6291 ct=11.1990 rec=1.3924 | train/val/test=0.923/0.678/0.685 | c=0.999014
[Epoch 0095] loss=16.8086 cls=0.7880 smmd=0.6300 ct=11.1986 rec=1.3925 | train/val/test=0.923/0.678/0.685 | c=0.999014
[Epoch 0096] loss=16.7167 cls=0.6716 smmd=0.6275 ct=11.1984 rec=1.3925 | train/val/test=0.923/0.680/0.685 | c=0.999014
[Epoch 0097] loss=16.6755 cls=0.6105 smmd=0.6302 ct=11.1983 rec=1.3925 | train/val/test=0.923/0.680/0.684 | c=0.999014
[Epoch 0098] loss=16.7718 cls=0.7402 smmd=0.6298 ct=11.1980 rec=1.3926 | train/val/test=0.923/0.680/0.684 | c=0.999014
[Epoch 0099] loss=16.5710 cls=0.4675 smmd=0.6319 ct=11.1981 rec=1.3925 | train/val/test=0.923/0.680/0.684 | c=0.999014
=== Best @ epoch 44: val=0.7120, test=0.6960 ===
