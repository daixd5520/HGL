Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=30.2003 cls=1.1046 smmd=4.1726 ct=11.2729 rec=1.4137 | train/val/test=0.346/0.388/0.413 | c=0.999014
[Epoch 0001] loss=29.2081 cls=1.1072 smmd=3.8898 ct=11.2694 rec=1.4137 | train/val/test=0.346/0.388/0.413 | c=0.999014
[Epoch 0002] loss=27.5568 cls=1.0998 smmd=3.4221 ct=11.2627 rec=1.4137 | train/val/test=0.346/0.388/0.413 | c=0.999014
[Epoch 0003] loss=24.9794 cls=1.0911 smmd=2.6926 ct=11.2493 rec=1.4137 | train/val/test=0.654/0.438/0.424 | c=0.999014
[Epoch 0004] loss=21.4185 cls=1.0886 smmd=1.6867 ct=11.2197 rec=1.4137 | train/val/test=0.346/0.198/0.184 | c=0.999014
[Epoch 0005] loss=17.8475 cls=1.0853 smmd=0.6860 ct=11.1687 rec=1.4137 | train/val/test=0.346/0.196/0.180 | c=0.999014
[Epoch 0006] loss=17.6502 cls=1.0838 smmd=0.6298 ct=11.1693 rec=1.4137 | train/val/test=0.346/0.196/0.180 | c=0.999014
[Epoch 0007] loss=19.8959 cls=1.0848 smmd=1.2626 ct=11.1924 rec=1.4138 | train/val/test=0.346/0.196/0.180 | c=0.999014
[Epoch 0008] loss=21.1821 cls=1.0689 smmd=1.6361 ct=11.1854 rec=1.4139 | train/val/test=0.346/0.216/0.215 | c=0.999014
[Epoch 0009] loss=20.7917 cls=1.0682 smmd=1.5396 ct=11.1452 rec=1.4139 | train/val/test=0.423/0.260/0.254 | c=0.999014
[Epoch 0010] loss=19.1268 cls=1.0443 smmd=1.0941 ct=11.0778 rec=1.4139 | train/val/test=0.500/0.328/0.309 | c=0.999014
[Epoch 0011] loss=17.7137 cls=1.0336 smmd=0.7167 ct=11.0132 rec=1.4135 | train/val/test=0.615/0.448/0.446 | c=0.999014
[Epoch 0012] loss=18.5378 cls=1.0151 smmd=0.7349 ct=11.6087 rec=1.4127 | train/val/test=0.654/0.526/0.508 | c=0.999014
[Epoch 0013] loss=18.9795 cls=0.9326 smmd=0.9681 ct=11.3683 rec=1.4110 | train/val/test=0.769/0.646/0.643 | c=0.999014
[Epoch 0014] loss=19.2099 cls=0.9243 smmd=1.0785 ct=11.2532 rec=1.4085 | train/val/test=0.846/0.730/0.700 | c=0.999014
[Epoch 0015] loss=18.7137 cls=0.8109 smmd=0.9651 ct=11.2426 rec=1.4040 | train/val/test=0.846/0.754/0.704 | c=0.999014
[Epoch 0016] loss=17.9542 cls=0.8074 smmd=0.7310 ct=11.2910 rec=1.3969 | train/val/test=0.885/0.744/0.697 | c=0.999014
[Epoch 0017] loss=17.4553 cls=0.8338 smmd=0.5542 ct=11.3685 rec=1.3892 | train/val/test=0.923/0.760/0.699 | c=0.999014
[Epoch 0018] loss=17.4468 cls=0.5986 smmd=0.5756 ct=11.4405 rec=1.3821 | train/val/test=1.000/0.758/0.704 | c=0.999014
[Epoch 0019] loss=17.9103 cls=0.6281 smmd=0.6911 ct=11.4697 rec=1.3740 | train/val/test=0.962/0.766/0.725 | c=0.999014
[Epoch 0020] loss=18.0512 cls=0.6870 smmd=0.7286 ct=11.4433 rec=1.3681 | train/val/test=0.923/0.766/0.739 | c=0.999014
[Epoch 0021] loss=17.8383 cls=0.6327 smmd=0.6951 ct=11.4015 rec=1.3602 | train/val/test=0.962/0.770/0.736 | c=0.999014
[Epoch 0022] loss=17.8492 cls=0.6736 smmd=0.7048 ct=11.3604 rec=1.3568 | train/val/test=0.962/0.764/0.725 | c=0.999014
[Epoch 0023] loss=17.8688 cls=0.7054 smmd=0.7134 ct=11.3348 rec=1.3463 | train/val/test=0.962/0.750/0.726 | c=0.999014
[Epoch 0024] loss=17.8752 cls=0.7660 smmd=0.6997 ct=11.3417 rec=1.3445 | train/val/test=0.962/0.768/0.728 | c=0.999014
[Epoch 0025] loss=17.7776 cls=0.9443 smmd=0.6218 ct=11.3741 rec=1.3356 | train/val/test=0.962/0.768/0.715 | c=0.999014
[Epoch 0026] loss=17.6141 cls=1.2168 smmd=0.5192 ct=11.3673 rec=1.3370 | train/val/test=0.962/0.764/0.705 | c=0.999014
[Epoch 0027] loss=17.1850 cls=0.8915 smmd=0.4732 ct=11.3482 rec=1.3443 | train/val/test=0.923/0.782/0.703 | c=0.999014
[Epoch 0028] loss=17.3318 cls=1.2063 smmd=0.4494 ct=11.3434 rec=1.3458 | train/val/test=0.923/0.764/0.699 | c=0.999014
[Epoch 0029] loss=17.5578 cls=1.6214 smmd=0.4160 ct=11.3674 rec=1.3531 | train/val/test=0.923/0.754/0.706 | c=0.999014
[Epoch 0030] loss=17.2074 cls=1.2366 smmd=0.3867 ct=11.3980 rec=1.3625 | train/val/test=0.923/0.770/0.710 | c=0.999014
[Epoch 0031] loss=16.9689 cls=0.9952 smmd=0.3778 ct=11.3773 rec=1.3708 | train/val/test=0.923/0.744/0.711 | c=0.999014
[Epoch 0032] loss=16.8355 cls=0.8197 smmd=0.3899 ct=11.3426 rec=1.3845 | train/val/test=0.962/0.726/0.705 | c=0.999014
[Epoch 0033] loss=17.0776 cls=1.0225 smmd=0.4267 ct=11.3121 rec=1.3930 | train/val/test=0.962/0.728/0.718 | c=0.999014
[Epoch 0034] loss=17.1576 cls=0.9709 smmd=0.4600 ct=11.3134 rec=1.3988 | train/val/test=0.962/0.738/0.729 | c=0.999014
[Epoch 0035] loss=17.2410 cls=1.0244 smmd=0.4616 ct=11.3424 rec=1.4020 | train/val/test=0.923/0.714/0.719 | c=0.999014
[Epoch 0036] loss=17.1504 cls=0.8080 smmd=0.4689 ct=11.3776 rec=1.4032 | train/val/test=0.885/0.732/0.723 | c=0.999014
[Epoch 0037] loss=17.3136 cls=0.8955 smmd=0.4929 ct=11.3880 rec=1.4039 | train/val/test=0.769/0.724/0.701 | c=0.999014
[Epoch 0038] loss=17.2740 cls=0.8731 smmd=0.4924 ct=11.3720 rec=1.4043 | train/val/test=0.769/0.720/0.691 | c=0.999014
[Epoch 0039] loss=17.2063 cls=0.8669 smmd=0.4828 ct=11.3493 rec=1.4042 | train/val/test=0.808/0.710/0.673 | c=0.999014
[Epoch 0040] loss=17.1842 cls=0.9124 smmd=0.4722 ct=11.3346 rec=1.4034 | train/val/test=0.808/0.688/0.669 | c=0.999014
[Epoch 0041] loss=16.9499 cls=0.7505 smmd=0.4421 ct=11.3287 rec=1.4021 | train/val/test=0.846/0.680/0.663 | c=0.999014
[Epoch 0042] loss=16.8452 cls=0.7103 smmd=0.4216 ct=11.3267 rec=1.4004 | train/val/test=0.923/0.676/0.669 | c=0.999014
[Epoch 0043] loss=16.7695 cls=0.6892 smmd=0.4059 ct=11.3232 rec=1.3992 | train/val/test=0.923/0.694/0.685 | c=0.999014
[Epoch 0044] loss=16.8172 cls=0.8402 smmd=0.3878 ct=11.3213 rec=1.3983 | train/val/test=0.923/0.704/0.685 | c=0.999014
[Epoch 0045] loss=16.7176 cls=0.7385 smmd=0.3808 ct=11.3225 rec=1.3976 | train/val/test=0.923/0.716/0.692 | c=0.999014
[Epoch 0046] loss=16.7721 cls=0.8192 smmd=0.3794 ct=11.3216 rec=1.3969 | train/val/test=0.923/0.724/0.697 | c=0.999014
[Epoch 0047] loss=16.7358 cls=0.7516 smmd=0.3844 ct=11.3193 rec=1.3967 | train/val/test=0.923/0.736/0.699 | c=0.999014
[Epoch 0048] loss=16.7521 cls=0.7423 smmd=0.3931 ct=11.3137 rec=1.3963 | train/val/test=0.962/0.742/0.704 | c=0.999014
[Epoch 0049] loss=16.8097 cls=0.7832 smmd=0.4033 ct=11.3070 rec=1.3960 | train/val/test=1.000/0.752/0.716 | c=0.999014
[Epoch 0050] loss=16.9482 cls=0.9344 smmd=0.4141 ct=11.2972 rec=1.3957 | train/val/test=0.962/0.758/0.716 | c=0.999014
[Epoch 0051] loss=16.7272 cls=0.6025 smmd=0.4229 ct=11.2949 rec=1.3961 | train/val/test=0.962/0.768/0.727 | c=0.999014
[Epoch 0052] loss=16.7945 cls=0.6919 smmd=0.4224 ct=11.2965 rec=1.3956 | train/val/test=1.000/0.776/0.728 | c=0.999014
[Epoch 0053] loss=16.7350 cls=0.6299 smmd=0.4166 ct=11.3022 rec=1.3951 | train/val/test=1.000/0.760/0.732 | c=0.999014
[Epoch 0054] loss=17.0139 cls=1.0256 smmd=0.4104 ct=11.3052 rec=1.3933 | train/val/test=1.000/0.766/0.732 | c=0.999014
[Epoch 0055] loss=16.7489 cls=0.7072 smmd=0.4042 ct=11.3019 rec=1.3935 | train/val/test=1.000/0.762/0.728 | c=0.999014
[Epoch 0056] loss=16.7303 cls=0.7156 smmd=0.4001 ct=11.2937 rec=1.3934 | train/val/test=1.000/0.756/0.719 | c=0.999014
[Epoch 0057] loss=16.6439 cls=0.6239 smmd=0.3987 ct=11.2841 rec=1.3924 | train/val/test=1.000/0.754/0.708 | c=0.999014
[Epoch 0058] loss=16.7578 cls=0.8235 smmd=0.3911 ct=11.2768 rec=1.3917 | train/val/test=1.000/0.754/0.711 | c=0.999014
[Epoch 0059] loss=16.7102 cls=0.7712 smmd=0.3899 ct=11.2737 rec=1.3912 | train/val/test=1.000/0.734/0.706 | c=0.999014
[Epoch 0060] loss=16.7874 cls=0.8957 smmd=0.3847 ct=11.2753 rec=1.3913 | train/val/test=1.000/0.732/0.712 | c=0.999014
[Epoch 0061] loss=16.6189 cls=0.6748 smmd=0.3839 ct=11.2754 rec=1.3913 | train/val/test=1.000/0.738/0.712 | c=0.999014
[Epoch 0062] loss=16.7901 cls=0.8838 smmd=0.3880 ct=11.2755 rec=1.3910 | train/val/test=1.000/0.750/0.718 | c=0.999014
[Epoch 0063] loss=16.7048 cls=0.7716 smmd=0.3885 ct=11.2730 rec=1.3913 | train/val/test=1.000/0.734/0.711 | c=0.999014
[Epoch 0064] loss=16.7277 cls=0.7948 smmd=0.3904 ct=11.2722 rec=1.3920 | train/val/test=1.000/0.720/0.706 | c=0.999014
[Epoch 0065] loss=16.6398 cls=0.6575 smmd=0.3947 ct=11.2721 rec=1.3920 | train/val/test=1.000/0.718/0.710 | c=0.999014
[Epoch 0066] loss=16.6977 cls=0.7203 smmd=0.3986 ct=11.2699 rec=1.3925 | train/val/test=1.000/0.716/0.700 | c=0.999014
[Epoch 0067] loss=16.6457 cls=0.6524 smmd=0.3974 ct=11.2725 rec=1.3917 | train/val/test=1.000/0.716/0.703 | c=0.999014
[Epoch 0068] loss=16.8290 cls=0.8896 smmd=0.3981 ct=11.2748 rec=1.3916 | train/val/test=1.000/0.710/0.702 | c=0.999014
[Epoch 0069] loss=16.7293 cls=0.7471 smmd=0.3992 ct=11.2774 rec=1.3920 | train/val/test=1.000/0.718/0.700 | c=0.999014
[Epoch 0070] loss=16.8153 cls=0.8550 smmd=0.4007 ct=11.2770 rec=1.3917 | train/val/test=1.000/0.716/0.699 | c=0.999014
[Epoch 0071] loss=16.7066 cls=0.7075 smmd=0.4029 ct=11.2728 rec=1.3915 | train/val/test=1.000/0.724/0.698 | c=0.999014
[Epoch 0072] loss=16.9265 cls=1.0038 smmd=0.4031 ct=11.2702 rec=1.3916 | train/val/test=1.000/0.726/0.699 | c=0.999014
[Epoch 0073] loss=16.7360 cls=0.7370 smmd=0.4063 ct=11.2691 rec=1.3913 | train/val/test=1.000/0.730/0.699 | c=0.999014
[Epoch 0074] loss=16.7469 cls=0.7559 smmd=0.4052 ct=11.2696 rec=1.3913 | train/val/test=1.000/0.730/0.703 | c=0.999014
[Epoch 0075] loss=16.7886 cls=0.8103 smmd=0.4056 ct=11.2692 rec=1.3918 | train/val/test=1.000/0.732/0.704 | c=0.999014
[Epoch 0076] loss=16.7405 cls=0.7600 smmd=0.4032 ct=11.2677 rec=1.3917 | train/val/test=1.000/0.736/0.708 | c=0.999014
[Epoch 0077] loss=16.7005 cls=0.7110 smmd=0.4024 ct=11.2674 rec=1.3917 | train/val/test=1.000/0.742/0.707 | c=0.999014
[Epoch 0078] loss=16.7415 cls=0.7697 smmd=0.4014 ct=11.2677 rec=1.3916 | train/val/test=1.000/0.738/0.708 | c=0.999014
[Epoch 0079] loss=16.6133 cls=0.6135 smmd=0.3981 ct=11.2680 rec=1.3912 | train/val/test=1.000/0.736/0.710 | c=0.999014
[Epoch 0080] loss=16.7439 cls=0.7867 smmd=0.3979 ct=11.2692 rec=1.3910 | train/val/test=1.000/0.740/0.710 | c=0.999014
[Epoch 0081] loss=16.6831 cls=0.7115 smmd=0.3969 ct=11.2686 rec=1.3912 | train/val/test=0.962/0.742/0.707 | c=0.999014
[Epoch 0082] loss=16.6290 cls=0.6338 smmd=0.3978 ct=11.2693 rec=1.3913 | train/val/test=0.962/0.746/0.709 | c=0.999014
[Epoch 0083] loss=16.4808 cls=0.4448 smmd=0.3964 ct=11.2680 rec=1.3910 | train/val/test=0.962/0.756/0.710 | c=0.999014
[Epoch 0084] loss=16.8396 cls=0.9101 smmd=0.3995 ct=11.2674 rec=1.3911 | train/val/test=0.962/0.752/0.713 | c=0.999014
[Epoch 0085] loss=16.6772 cls=0.7017 smmd=0.3986 ct=11.2651 rec=1.3910 | train/val/test=0.962/0.746/0.712 | c=0.999014
[Epoch 0086] loss=16.6917 cls=0.7217 smmd=0.3999 ct=11.2612 rec=1.3912 | train/val/test=0.962/0.746/0.714 | c=0.999014
[Epoch 0087] loss=16.6624 cls=0.6760 smmd=0.4013 ct=11.2611 rec=1.3911 | train/val/test=0.962/0.746/0.716 | c=0.999014
[Epoch 0088] loss=16.6157 cls=0.6196 smmd=0.4004 ct=11.2602 rec=1.3910 | train/val/test=0.962/0.746/0.715 | c=0.999014
[Epoch 0089] loss=16.6492 cls=0.6567 smmd=0.4020 ct=11.2603 rec=1.3909 | train/val/test=0.962/0.742/0.714 | c=0.999014
[Epoch 0090] loss=16.6585 cls=0.6672 smmd=0.4021 ct=11.2611 rec=1.3907 | train/val/test=0.962/0.742/0.714 | c=0.999014
[Epoch 0091] loss=16.6295 cls=0.6312 smmd=0.4016 ct=11.2609 rec=1.3906 | train/val/test=0.962/0.744/0.714 | c=0.999014
[Epoch 0092] loss=16.6731 cls=0.6989 smmd=0.3992 ct=11.2618 rec=1.3905 | train/val/test=0.962/0.744/0.712 | c=0.999014
[Epoch 0093] loss=16.6562 cls=0.6673 smmd=0.4013 ct=11.2615 rec=1.3905 | train/val/test=0.962/0.744/0.712 | c=0.999014
[Epoch 0094] loss=16.6519 cls=0.6660 smmd=0.4003 ct=11.2617 rec=1.3906 | train/val/test=0.962/0.744/0.714 | c=0.999014
[Epoch 0095] loss=16.6862 cls=0.7129 smmd=0.4002 ct=11.2613 rec=1.3907 | train/val/test=0.962/0.744/0.714 | c=0.999014
[Epoch 0096] loss=16.6818 cls=0.7037 smmd=0.4009 ct=11.2613 rec=1.3908 | train/val/test=0.962/0.744/0.714 | c=0.999014
[Epoch 0097] loss=16.8640 cls=0.9463 smmd=0.4010 ct=11.2610 rec=1.3910 | train/val/test=0.962/0.742/0.714 | c=0.999014
[Epoch 0098] loss=16.6792 cls=0.7084 smmd=0.3992 ct=11.2611 rec=1.3909 | train/val/test=0.962/0.742/0.715 | c=0.999014
[Epoch 0099] loss=16.6296 cls=0.6285 smmd=0.4018 ct=11.2621 rec=1.3908 | train/val/test=0.962/0.742/0.715 | c=0.999014
=== Best @ epoch 27: val=0.7820, test=0.7030 ===
