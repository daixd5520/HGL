Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=23.3502 cls=1.1150 smmd=4.1648 ct=11.2769 rec=1.4136 | train/val/test=0.308/0.196/0.180 | c=0.999014
[Epoch 0001] loss=22.9398 cls=1.0918 smmd=3.9418 ct=11.2749 rec=1.4136 | train/val/test=0.308/0.196/0.180 | c=0.999014
[Epoch 0002] loss=22.3116 cls=1.1006 smmd=3.5816 ct=11.2715 rec=1.4136 | train/val/test=0.308/0.196/0.180 | c=0.999014
[Epoch 0003] loss=21.3568 cls=1.1017 smmd=3.0402 ct=11.2652 rec=1.4136 | train/val/test=0.308/0.196/0.180 | c=0.999014
[Epoch 0004] loss=19.9843 cls=1.0956 smmd=2.2686 ct=11.2517 rec=1.4136 | train/val/test=0.308/0.196/0.180 | c=0.999014
[Epoch 0005] loss=18.3146 cls=1.0929 smmd=1.3355 ct=11.2249 rec=1.4136 | train/val/test=0.308/0.196/0.180 | c=0.999014
[Epoch 0006] loss=17.2221 cls=1.0893 smmd=0.7309 ct=11.2005 rec=1.4136 | train/val/test=0.308/0.196/0.180 | c=0.999014
[Epoch 0007] loss=17.7990 cls=1.0901 smmd=1.0563 ct=11.2057 rec=1.4136 | train/val/test=0.308/0.198/0.180 | c=0.999014
[Epoch 0008] loss=18.8387 cls=1.0840 smmd=1.6544 ct=11.2039 rec=1.4136 | train/val/test=0.462/0.442/0.453 | c=0.999014
[Epoch 0009] loss=19.1626 cls=1.0826 smmd=1.8670 ct=11.1677 rec=1.4136 | train/val/test=0.692/0.536/0.531 | c=0.999014
[Epoch 0010] loss=18.5844 cls=1.0781 smmd=1.5998 ct=11.0852 rec=1.4136 | train/val/test=0.769/0.538/0.552 | c=0.999014
[Epoch 0011] loss=18.2298 cls=1.0571 smmd=1.0636 ct=11.5464 rec=1.4136 | train/val/test=0.385/0.390/0.416 | c=0.999014
[Epoch 0012] loss=17.5927 cls=1.0495 smmd=0.9539 ct=11.2082 rec=1.4139 | train/val/test=0.462/0.390/0.425 | c=0.999014
[Epoch 0013] loss=17.7162 cls=1.0243 smmd=1.0668 ct=11.1658 rec=1.4141 | train/val/test=0.538/0.446/0.472 | c=0.999014
[Epoch 0014] loss=17.8534 cls=1.0154 smmd=1.1064 ct=11.2231 rec=1.4138 | train/val/test=0.615/0.524/0.573 | c=0.999014
[Epoch 0015] loss=17.7115 cls=1.0100 smmd=0.9785 ct=11.2895 rec=1.4132 | train/val/test=0.615/0.612/0.638 | c=0.999014
[Epoch 0016] loss=17.2990 cls=0.9786 smmd=0.7697 ct=11.2716 rec=1.4127 | train/val/test=0.692/0.622/0.644 | c=0.999014
[Epoch 0017] loss=17.1092 cls=0.9949 smmd=0.6727 ct=11.2468 rec=1.4124 | train/val/test=0.692/0.628/0.647 | c=0.999014
[Epoch 0018] loss=17.2165 cls=0.9868 smmd=0.7313 ct=11.2553 rec=1.4121 | train/val/test=0.692/0.612/0.642 | c=0.999014
[Epoch 0019] loss=17.5354 cls=0.9325 smmd=0.9111 ct=11.2898 rec=1.4121 | train/val/test=0.615/0.574/0.599 | c=0.999014
[Epoch 0020] loss=17.6625 cls=0.9332 smmd=1.0149 ct=11.2474 rec=1.4123 | train/val/test=0.615/0.556/0.581 | c=0.999014
[Epoch 0021] loss=17.6454 cls=0.9623 smmd=1.0271 ct=11.2011 rec=1.4121 | train/val/test=0.692/0.604/0.626 | c=0.999014
[Epoch 0022] loss=17.5523 cls=0.9421 smmd=0.9679 ct=11.2211 rec=1.4113 | train/val/test=0.769/0.626/0.649 | c=0.999014
[Epoch 0023] loss=17.6595 cls=0.9487 smmd=1.0092 ct=11.2443 rec=1.4105 | train/val/test=0.769/0.626/0.657 | c=0.999014
[Epoch 0024] loss=17.6403 cls=0.9150 smmd=1.0466 ct=11.1992 rec=1.4092 | train/val/test=0.923/0.662/0.692 | c=0.999014
[Epoch 0025] loss=17.4017 cls=0.8995 smmd=0.9047 ct=11.2164 rec=1.4061 | train/val/test=0.923/0.700/0.710 | c=0.999014
[Epoch 0026] loss=17.1041 cls=0.7954 smmd=0.7489 ct=11.2586 rec=1.4020 | train/val/test=0.923/0.698/0.707 | c=0.999014
[Epoch 0027] loss=16.9214 cls=0.7196 smmd=0.6913 ct=11.2405 rec=1.3979 | train/val/test=0.923/0.696/0.708 | c=0.999014
[Epoch 0028] loss=16.8495 cls=0.6910 smmd=0.6688 ct=11.2332 rec=1.3938 | train/val/test=0.923/0.708/0.704 | c=0.999014
[Epoch 0029] loss=16.7449 cls=0.6113 smmd=0.6322 ct=11.2493 rec=1.3903 | train/val/test=0.923/0.700/0.700 | c=0.999014
[Epoch 0030] loss=16.8475 cls=0.8036 smmd=0.6041 ct=11.2559 rec=1.3871 | train/val/test=0.923/0.704/0.699 | c=0.999014
[Epoch 0031] loss=16.8702 cls=0.8066 smmd=0.6302 ct=11.2373 rec=1.3849 | train/val/test=0.923/0.710/0.708 | c=0.999014
[Epoch 0032] loss=16.8249 cls=0.6626 smmd=0.6733 ct=11.2277 rec=1.3841 | train/val/test=0.923/0.702/0.704 | c=0.999014
[Epoch 0033] loss=17.0942 cls=0.9299 smmd=0.7066 ct=11.2360 rec=1.3837 | train/val/test=0.923/0.694/0.703 | c=0.999014
[Epoch 0034] loss=16.8400 cls=0.5645 smmd=0.7267 ct=11.2243 rec=1.3833 | train/val/test=0.923/0.686/0.699 | c=0.999014
[Epoch 0035] loss=16.9042 cls=0.6447 smmd=0.7380 ct=11.2120 rec=1.3836 | train/val/test=0.923/0.696/0.699 | c=0.999014
[Epoch 0036] loss=16.8162 cls=0.5397 smmd=0.7227 ct=11.2263 rec=1.3810 | train/val/test=0.923/0.698/0.696 | c=0.999014
[Epoch 0037] loss=16.8733 cls=0.6836 smmd=0.6991 ct=11.2194 rec=1.3800 | train/val/test=0.923/0.700/0.703 | c=0.999014
[Epoch 0038] loss=16.9117 cls=0.8238 smmd=0.6707 ct=11.2069 rec=1.3780 | train/val/test=0.923/0.674/0.701 | c=0.999014
[Epoch 0039] loss=16.6612 cls=0.5395 smmd=0.6373 ct=11.2248 rec=1.3729 | train/val/test=0.923/0.710/0.711 | c=0.999014
[Epoch 0040] loss=16.8784 cls=0.9277 smmd=0.6124 ct=11.2019 rec=1.3711 | train/val/test=1.000/0.696/0.702 | c=0.999014
[Epoch 0041] loss=16.6644 cls=0.6300 smmd=0.6021 ct=11.2227 rec=1.3717 | train/val/test=0.923/0.710/0.717 | c=0.999014
[Epoch 0042] loss=16.6651 cls=0.6574 smmd=0.5887 ct=11.2274 rec=1.3658 | train/val/test=0.923/0.704/0.717 | c=0.999014
[Epoch 0043] loss=16.4977 cls=0.4813 smmd=0.5814 ct=11.2103 rec=1.3644 | train/val/test=1.000/0.706/0.718 | c=0.999014
[Epoch 0044] loss=16.5634 cls=0.5503 smmd=0.5931 ct=11.2056 rec=1.3635 | train/val/test=1.000/0.692/0.708 | c=0.999014
[Epoch 0045] loss=16.6690 cls=0.6739 smmd=0.5931 ct=11.2167 rec=1.3600 | train/val/test=1.000/0.684/0.712 | c=0.999014
[Epoch 0046] loss=17.1012 cls=1.2295 smmd=0.6056 ct=11.2118 rec=1.3602 | train/val/test=1.000/0.692/0.694 | c=0.999014
[Epoch 0047] loss=16.6506 cls=0.5788 smmd=0.6248 ct=11.2145 rec=1.3605 | train/val/test=1.000/0.682/0.699 | c=0.999014
[Epoch 0048] loss=16.7807 cls=0.7827 smmd=0.6183 ct=11.2068 rec=1.3572 | train/val/test=1.000/0.682/0.674 | c=0.999014
[Epoch 0049] loss=16.6167 cls=0.4995 smmd=0.6266 ct=11.2328 rec=1.3574 | train/val/test=1.000/0.700/0.683 | c=0.999014
[Epoch 0050] loss=16.8236 cls=0.8489 smmd=0.6145 ct=11.2070 rec=1.3563 | train/val/test=1.000/0.694/0.673 | c=0.999014
[Epoch 0051] loss=16.6784 cls=0.6615 smmd=0.6031 ct=11.2189 rec=1.3559 | train/val/test=1.000/0.688/0.680 | c=0.999014
[Epoch 0052] loss=16.6977 cls=0.7319 smmd=0.5832 ct=11.2207 rec=1.3533 | train/val/test=1.000/0.690/0.670 | c=0.999014
[Epoch 0053] loss=16.7203 cls=0.7658 smmd=0.5869 ct=11.2132 rec=1.3542 | train/val/test=0.923/0.694/0.671 | c=0.999014
[Epoch 0054] loss=16.5837 cls=0.5877 smmd=0.5914 ct=11.2039 rec=1.3571 | train/val/test=0.923/0.692/0.673 | c=0.999014
[Epoch 0055] loss=16.7228 cls=0.7842 smmd=0.5776 ct=11.2171 rec=1.3541 | train/val/test=1.000/0.690/0.671 | c=0.999014
[Epoch 0056] loss=16.5482 cls=0.5319 smmd=0.5721 ct=11.2354 rec=1.3553 | train/val/test=0.923/0.692/0.671 | c=0.999014
[Epoch 0057] loss=16.6306 cls=0.6423 smmd=0.5850 ct=11.2166 rec=1.3588 | train/val/test=0.923/0.694/0.679 | c=0.999014
[Epoch 0058] loss=16.4938 cls=0.4101 smmd=0.6143 ct=11.2044 rec=1.3638 | train/val/test=0.923/0.696/0.667 | c=0.999014
[Epoch 0059] loss=16.5890 cls=0.5500 smmd=0.6154 ct=11.1963 rec=1.3609 | train/val/test=1.000/0.694/0.679 | c=0.999014
[Epoch 0060] loss=16.6649 cls=0.6155 smmd=0.6213 ct=11.2083 rec=1.3629 | train/val/test=1.000/0.708/0.684 | c=0.999014
[Epoch 0061] loss=16.9577 cls=1.0199 smmd=0.6155 ct=11.2079 rec=1.3633 | train/val/test=1.000/0.700/0.681 | c=0.999014
[Epoch 0062] loss=16.7036 cls=0.6760 smmd=0.6154 ct=11.2111 rec=1.3628 | train/val/test=1.000/0.686/0.687 | c=0.999014
[Epoch 0063] loss=16.7419 cls=0.7149 smmd=0.6217 ct=11.2100 rec=1.3619 | train/val/test=1.000/0.694/0.691 | c=0.999014
[Epoch 0064] loss=16.6265 cls=0.5877 smmd=0.6182 ct=11.2000 rec=1.3595 | train/val/test=1.000/0.686/0.685 | c=0.999014
[Epoch 0065] loss=17.0484 cls=1.1581 smmd=0.6120 ct=11.2041 rec=1.3587 | train/val/test=1.000/0.692/0.687 | c=0.999014
[Epoch 0066] loss=16.7531 cls=0.7555 smmd=0.6053 ct=11.2181 rec=1.3594 | train/val/test=1.000/0.678/0.695 | c=0.999014
[Epoch 0067] loss=16.7200 cls=0.7639 smmd=0.5877 ct=11.2123 rec=1.3563 | train/val/test=1.000/0.680/0.692 | c=0.999014
[Epoch 0068] loss=16.6472 cls=0.6507 smmd=0.5901 ct=11.2181 rec=1.3574 | train/val/test=1.000/0.678/0.694 | c=0.999014
[Epoch 0069] loss=16.6189 cls=0.6205 smmd=0.5927 ct=11.2104 rec=1.3573 | train/val/test=1.000/0.678/0.696 | c=0.999014
[Epoch 0070] loss=16.5092 cls=0.4855 smmd=0.5989 ct=11.1955 rec=1.3572 | train/val/test=1.000/0.678/0.695 | c=0.999014
[Epoch 0071] loss=16.5671 cls=0.5566 smmd=0.6002 ct=11.1970 rec=1.3577 | train/val/test=1.000/0.666/0.690 | c=0.999014
[Epoch 0072] loss=16.8912 cls=0.9594 smmd=0.6067 ct=11.2048 rec=1.3591 | train/val/test=1.000/0.666/0.688 | c=0.999014
[Epoch 0073] loss=16.5593 cls=0.5237 smmd=0.6053 ct=11.2028 rec=1.3592 | train/val/test=1.000/0.664/0.696 | c=0.999014
[Epoch 0074] loss=16.7578 cls=0.7856 smmd=0.6094 ct=11.1987 rec=1.3597 | train/val/test=1.000/0.676/0.697 | c=0.999014
[Epoch 0075] loss=16.7749 cls=0.7887 smmd=0.6161 ct=11.2009 rec=1.3601 | train/val/test=1.000/0.680/0.703 | c=0.999014
[Epoch 0076] loss=16.5465 cls=0.4671 smmd=0.6217 ct=11.2033 rec=1.3599 | train/val/test=1.000/0.680/0.699 | c=0.999014
[Epoch 0077] loss=16.7547 cls=0.7473 smmd=0.6227 ct=11.2004 rec=1.3600 | train/val/test=1.000/0.688/0.698 | c=0.999014
[Epoch 0078] loss=16.5841 cls=0.5118 smmd=0.6278 ct=11.1980 rec=1.3606 | train/val/test=1.000/0.684/0.699 | c=0.999014
[Epoch 0079] loss=16.5734 cls=0.4877 smmd=0.6325 ct=11.1969 rec=1.3620 | train/val/test=1.000/0.682/0.696 | c=0.999014
[Epoch 0080] loss=16.5166 cls=0.4012 smmd=0.6377 ct=11.1957 rec=1.3635 | train/val/test=1.000/0.684/0.697 | c=0.999014
[Epoch 0081] loss=16.6294 cls=0.5528 smmd=0.6409 ct=11.1905 rec=1.3640 | train/val/test=1.000/0.690/0.700 | c=0.999014
[Epoch 0082] loss=16.5670 cls=0.4711 smmd=0.6410 ct=11.1894 rec=1.3642 | train/val/test=1.000/0.688/0.702 | c=0.999014
[Epoch 0083] loss=16.6716 cls=0.6075 smmd=0.6421 ct=11.1897 rec=1.3643 | train/val/test=1.000/0.688/0.701 | c=0.999014
[Epoch 0084] loss=16.6879 cls=0.6241 smmd=0.6429 ct=11.1916 rec=1.3641 | train/val/test=1.000/0.688/0.700 | c=0.999014
[Epoch 0085] loss=16.8248 cls=0.8090 smmd=0.6409 ct=11.1931 rec=1.3637 | train/val/test=1.000/0.692/0.698 | c=0.999014
[Epoch 0086] loss=16.7132 cls=0.6527 smmd=0.6427 ct=11.1952 rec=1.3630 | train/val/test=1.000/0.692/0.697 | c=0.999014
[Epoch 0087] loss=16.9925 cls=1.0257 smmd=0.6430 ct=11.1943 rec=1.3636 | train/val/test=1.000/0.694/0.703 | c=0.999014
[Epoch 0088] loss=16.6139 cls=0.5148 smmd=0.6463 ct=11.1933 rec=1.3640 | train/val/test=1.000/0.692/0.702 | c=0.999014
[Epoch 0089] loss=16.6453 cls=0.5654 smmd=0.6433 ct=11.1921 rec=1.3646 | train/val/test=1.000/0.688/0.704 | c=0.999014
[Epoch 0090] loss=16.6710 cls=0.5970 smmd=0.6449 ct=11.1913 rec=1.3650 | train/val/test=1.000/0.688/0.705 | c=0.999014
[Epoch 0091] loss=16.5800 cls=0.4724 smmd=0.6466 ct=11.1908 rec=1.3651 | train/val/test=1.000/0.690/0.705 | c=0.999014
[Epoch 0092] loss=16.6151 cls=0.5158 smmd=0.6484 ct=11.1904 rec=1.3652 | train/val/test=1.000/0.690/0.707 | c=0.999014
[Epoch 0093] loss=16.6634 cls=0.5839 smmd=0.6477 ct=11.1891 rec=1.3653 | train/val/test=1.000/0.690/0.707 | c=0.999014
[Epoch 0094] loss=16.4847 cls=0.3516 smmd=0.6452 ct=11.1891 rec=1.3650 | train/val/test=1.000/0.690/0.707 | c=0.999014
[Epoch 0095] loss=16.8298 cls=0.8026 smmd=0.6491 ct=11.1890 rec=1.3653 | train/val/test=1.000/0.688/0.706 | c=0.999014
[Epoch 0096] loss=16.7407 cls=0.6914 smmd=0.6461 ct=11.1888 rec=1.3650 | train/val/test=1.000/0.688/0.706 | c=0.999014
[Epoch 0097] loss=16.9634 cls=0.9801 smmd=0.6500 ct=11.1883 rec=1.3652 | train/val/test=1.000/0.688/0.706 | c=0.999014
[Epoch 0098] loss=16.5590 cls=0.4437 smmd=0.6485 ct=11.1888 rec=1.3650 | train/val/test=1.000/0.690/0.706 | c=0.999014
[Epoch 0099] loss=16.6292 cls=0.5373 smmd=0.6487 ct=11.1885 rec=1.3650 | train/val/test=1.000/0.690/0.706 | c=0.999014
=== Best @ epoch 31: val=0.7100, test=0.7080 ===
