Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=57.8333 cls=1.0906 smmd=4.2087 ct=7.2470 rec=1.4136 | train/val/test=0.400/0.400/0.398 | c=0.999014
[Epoch 0001] loss=34.1409 cls=1.0593 smmd=1.8502 ct=7.2007 rec=1.4156 | train/val/test=0.400/0.400/0.398 | c=0.999014
[Epoch 0002] loss=22.8285 cls=1.0599 smmd=0.7329 ct=7.1314 rec=1.4141 | train/val/test=0.596/0.578/0.608 | c=0.999014
[Epoch 0003] loss=26.2564 cls=1.0518 smmd=1.0789 ct=7.1174 rec=1.4135 | train/val/test=0.580/0.562/0.595 | c=0.999014
[Epoch 0004] loss=25.8890 cls=1.0165 smmd=1.0492 ct=7.0908 rec=1.4140 | train/val/test=0.578/0.561/0.592 | c=0.999014
[Epoch 0005] loss=23.4109 cls=0.9853 smmd=0.8087 ct=7.0615 rec=1.4160 | train/val/test=0.570/0.554/0.582 | c=0.999014
[Epoch 0006] loss=20.6976 cls=0.9682 smmd=0.5442 ct=7.0314 rec=1.4170 | train/val/test=0.566/0.548/0.578 | c=0.999014
[Epoch 0007] loss=20.5388 cls=0.9451 smmd=0.5325 ct=7.0171 rec=1.4146 | train/val/test=0.565/0.548/0.577 | c=0.999014
[Epoch 0008] loss=23.2475 cls=0.9041 smmd=0.6711 ct=7.6901 rec=1.4083 | train/val/test=0.574/0.560/0.582 | c=0.999014
[Epoch 0009] loss=23.1125 cls=0.8545 smmd=0.6914 ct=7.5360 rec=1.3992 | train/val/test=0.653/0.642/0.659 | c=0.999014
[Epoch 0010] loss=21.7476 cls=0.8101 smmd=0.5822 ct=7.4132 rec=1.3891 | train/val/test=0.695/0.686/0.703 | c=0.999014
[Epoch 0011] loss=20.3033 cls=0.7749 smmd=0.4465 ct=7.3806 rec=1.3794 | train/val/test=0.707/0.699/0.713 | c=0.999014
[Epoch 0012] loss=19.9833 cls=0.7458 smmd=0.4082 ct=7.4216 rec=1.3715 | train/val/test=0.714/0.708/0.722 | c=0.999014
[Epoch 0013] loss=20.3138 cls=0.7188 smmd=0.4349 ct=7.4616 rec=1.3650 | train/val/test=0.722/0.716/0.735 | c=0.999014
[Epoch 0014] loss=20.2263 cls=0.6950 smmd=0.4283 ct=7.4581 rec=1.3592 | train/val/test=0.733/0.735/0.745 | c=0.999014
[Epoch 0015] loss=19.8504 cls=0.6758 smmd=0.3948 ct=7.4442 rec=1.3533 | train/val/test=0.743/0.748/0.755 | c=0.999014
[Epoch 0016] loss=19.6898 cls=0.6609 smmd=0.3787 ct=7.4491 rec=1.3475 | train/val/test=0.752/0.757/0.766 | c=0.999014
[Epoch 0017] loss=19.6489 cls=0.6452 smmd=0.3722 ct=7.4665 rec=1.3427 | train/val/test=0.758/0.761/0.773 | c=0.999014
[Epoch 0018] loss=19.4475 cls=0.6248 smmd=0.3515 ct=7.4753 rec=1.3389 | train/val/test=0.768/0.768/0.779 | c=0.999014
[Epoch 0019] loss=19.2367 cls=0.6031 smmd=0.3344 ct=7.4618 rec=1.3354 | train/val/test=0.781/0.778/0.793 | c=0.999014
[Epoch 0020] loss=19.2573 cls=0.5828 smmd=0.3439 ct=7.4304 rec=1.3316 | train/val/test=0.789/0.790/0.804 | c=0.999014
[Epoch 0021] loss=19.2591 cls=0.5637 smmd=0.3511 ct=7.4014 rec=1.3279 | train/val/test=0.798/0.798/0.810 | c=0.999014
[Epoch 0022] loss=18.9642 cls=0.5456 smmd=0.3241 ct=7.3940 rec=1.3246 | train/val/test=0.801/0.803/0.816 | c=0.999014
[Epoch 0023] loss=18.6589 cls=0.5295 smmd=0.2911 ct=7.4111 rec=1.3212 | train/val/test=0.802/0.806/0.815 | c=0.999014
[Epoch 0024] loss=18.5733 cls=0.5170 smmd=0.2789 ct=7.4337 rec=1.3173 | train/val/test=0.803/0.809/0.820 | c=0.999014
[Epoch 0025] loss=18.4901 cls=0.5076 smmd=0.2708 ct=7.4357 rec=1.3137 | train/val/test=0.804/0.809/0.823 | c=0.999014
[Epoch 0026] loss=18.3603 cls=0.4998 smmd=0.2628 ct=7.4137 rec=1.3110 | train/val/test=0.806/0.811/0.822 | c=0.999014
[Epoch 0027] loss=18.2914 cls=0.4918 smmd=0.2612 ct=7.3894 rec=1.3094 | train/val/test=0.809/0.815/0.822 | c=0.999014
[Epoch 0028] loss=18.2751 cls=0.4838 smmd=0.2618 ct=7.3803 rec=1.3089 | train/val/test=0.812/0.816/0.823 | c=0.999014
[Epoch 0029] loss=18.2097 cls=0.4773 smmd=0.2540 ct=7.3879 rec=1.3095 | train/val/test=0.816/0.820/0.825 | c=0.999014
[Epoch 0030] loss=18.1277 cls=0.4733 smmd=0.2437 ct=7.3992 rec=1.3103 | train/val/test=0.816/0.821/0.826 | c=0.999014
[Epoch 0031] loss=18.1382 cls=0.4714 smmd=0.2438 ct=7.4048 rec=1.3104 | train/val/test=0.817/0.822/0.828 | c=0.999014
[Epoch 0032] loss=18.2026 cls=0.4698 smmd=0.2515 ct=7.3987 rec=1.3098 | train/val/test=0.817/0.825/0.828 | c=0.999014
[Epoch 0033] loss=18.1987 cls=0.4685 smmd=0.2542 ct=7.3839 rec=1.3100 | train/val/test=0.818/0.821/0.828 | c=0.999014
[Epoch 0034] loss=18.1465 cls=0.4678 smmd=0.2508 ct=7.3746 rec=1.3113 | train/val/test=0.818/0.821/0.828 | c=0.999014
[Epoch 0035] loss=18.1230 cls=0.4672 smmd=0.2477 ct=7.3779 rec=1.3125 | train/val/test=0.821/0.824/0.829 | c=0.999014
[Epoch 0036] loss=18.1176 cls=0.4661 smmd=0.2459 ct=7.3846 rec=1.3126 | train/val/test=0.821/0.825/0.831 | c=0.999014
[Epoch 0037] loss=18.0842 cls=0.4654 smmd=0.2429 ct=7.3832 rec=1.3116 | train/val/test=0.821/0.826/0.832 | c=0.999014
[Epoch 0038] loss=18.0428 cls=0.4656 smmd=0.2402 ct=7.3763 rec=1.3108 | train/val/test=0.822/0.826/0.832 | c=0.999014
[Epoch 0039] loss=17.9955 cls=0.4656 smmd=0.2364 ct=7.3717 rec=1.3105 | train/val/test=0.823/0.825/0.833 | c=0.999014
[Epoch 0040] loss=17.9612 cls=0.4653 smmd=0.2331 ct=7.3712 rec=1.3108 | train/val/test=0.823/0.825/0.832 | c=0.999014
[Epoch 0041] loss=17.8902 cls=0.4652 smmd=0.2264 ct=7.3690 rec=1.3113 | train/val/test=0.823/0.825/0.833 | c=0.999014
[Epoch 0042] loss=17.8695 cls=0.4654 smmd=0.2256 ct=7.3624 rec=1.3119 | train/val/test=0.823/0.826/0.832 | c=0.999014
[Epoch 0043] loss=17.8638 cls=0.4660 smmd=0.2264 ct=7.3550 rec=1.3126 | train/val/test=0.823/0.828/0.833 | c=0.999014
[Epoch 0044] loss=17.8289 cls=0.4672 smmd=0.2235 ct=7.3517 rec=1.3131 | train/val/test=0.823/0.827/0.832 | c=0.999014
[Epoch 0045] loss=17.8328 cls=0.4691 smmd=0.2236 ct=7.3529 rec=1.3135 | train/val/test=0.821/0.827/0.832 | c=0.999014
[Epoch 0046] loss=17.8272 cls=0.4710 smmd=0.2223 ct=7.3560 rec=1.3143 | train/val/test=0.821/0.826/0.831 | c=0.999014
[Epoch 0047] loss=17.8266 cls=0.4719 smmd=0.2220 ct=7.3562 rec=1.3157 | train/val/test=0.822/0.826/0.831 | c=0.999014
[Epoch 0048] loss=17.8250 cls=0.4724 smmd=0.2229 ct=7.3507 rec=1.3171 | train/val/test=0.823/0.826/0.833 | c=0.999014
[Epoch 0049] loss=17.8323 cls=0.4735 smmd=0.2249 ct=7.3439 rec=1.3181 | train/val/test=0.822/0.827/0.831 | c=0.999014
[Epoch 0050] loss=17.8281 cls=0.4742 smmd=0.2252 ct=7.3401 rec=1.3185 | train/val/test=0.821/0.827/0.831 | c=0.999014
[Epoch 0051] loss=17.7987 cls=0.4745 smmd=0.2225 ct=7.3388 rec=1.3186 | train/val/test=0.821/0.826/0.831 | c=0.999014
[Epoch 0052] loss=17.7943 cls=0.4748 smmd=0.2221 ct=7.3382 rec=1.3183 | train/val/test=0.822/0.827/0.831 | c=0.999014
[Epoch 0053] loss=17.7750 cls=0.4748 smmd=0.2205 ct=7.3366 rec=1.3180 | train/val/test=0.823/0.827/0.830 | c=0.999014
[Epoch 0054] loss=17.7451 cls=0.4746 smmd=0.2181 ct=7.3339 rec=1.3177 | train/val/test=0.823/0.828/0.832 | c=0.999014
[Epoch 0055] loss=17.7115 cls=0.4740 smmd=0.2156 ct=7.3299 rec=1.3178 | train/val/test=0.823/0.827/0.832 | c=0.999014
[Epoch 0056] loss=17.7041 cls=0.4735 smmd=0.2154 ct=7.3273 rec=1.3181 | train/val/test=0.823/0.828/0.832 | c=0.999014
[Epoch 0057] loss=17.6985 cls=0.4737 smmd=0.2154 ct=7.3245 rec=1.3181 | train/val/test=0.824/0.828/0.833 | c=0.999014
[Epoch 0058] loss=17.6991 cls=0.4743 smmd=0.2162 ct=7.3203 rec=1.3181 | train/val/test=0.823/0.828/0.832 | c=0.999014
[Epoch 0059] loss=17.6946 cls=0.4746 smmd=0.2160 ct=7.3189 rec=1.3186 | train/val/test=0.823/0.829/0.833 | c=0.999014
[Epoch 0060] loss=17.7067 cls=0.4752 smmd=0.2178 ct=7.3156 rec=1.3191 | train/val/test=0.824/0.829/0.833 | c=0.999014
[Epoch 0061] loss=17.7072 cls=0.4756 smmd=0.2185 ct=7.3122 rec=1.3196 | train/val/test=0.824/0.830/0.833 | c=0.999014
[Epoch 0062] loss=17.7118 cls=0.4757 smmd=0.2187 ct=7.3134 rec=1.3203 | train/val/test=0.824/0.828/0.832 | c=0.999014
[Epoch 0063] loss=17.6988 cls=0.4760 smmd=0.2176 ct=7.3120 rec=1.3210 | train/val/test=0.825/0.830/0.834 | c=0.999014
[Epoch 0064] loss=17.6873 cls=0.4758 smmd=0.2173 ct=7.3079 rec=1.3214 | train/val/test=0.825/0.829/0.833 | c=0.999014
[Epoch 0065] loss=17.6947 cls=0.4761 smmd=0.2187 ct=7.3043 rec=1.3214 | train/val/test=0.825/0.828/0.834 | c=0.999014
[Epoch 0066] loss=17.6745 cls=0.4765 smmd=0.2175 ct=7.3002 rec=1.3213 | train/val/test=0.825/0.828/0.833 | c=0.999014
[Epoch 0067] loss=17.6520 cls=0.4761 smmd=0.2163 ct=7.2954 rec=1.3215 | train/val/test=0.825/0.830/0.834 | c=0.999014
[Epoch 0068] loss=17.6506 cls=0.4755 smmd=0.2165 ct=7.2933 rec=1.3218 | train/val/test=0.825/0.829/0.834 | c=0.999014
[Epoch 0069] loss=17.6312 cls=0.4753 smmd=0.2141 ct=7.2957 rec=1.3220 | train/val/test=0.824/0.828/0.834 | c=0.999014
[Epoch 0070] loss=17.6243 cls=0.4754 smmd=0.2135 ct=7.2953 rec=1.3221 | train/val/test=0.825/0.828/0.833 | c=0.999014
[Epoch 0071] loss=17.6160 cls=0.4757 smmd=0.2137 ct=7.2900 rec=1.3223 | train/val/test=0.825/0.829/0.835 | c=0.999014
[Epoch 0072] loss=17.6175 cls=0.4767 smmd=0.2139 ct=7.2897 rec=1.3226 | train/val/test=0.825/0.829/0.835 | c=0.999014
[Epoch 0073] loss=17.6088 cls=0.4771 smmd=0.2136 ct=7.2863 rec=1.3228 | train/val/test=0.826/0.827/0.833 | c=0.999014
[Epoch 0074] loss=17.6396 cls=0.4776 smmd=0.2176 ct=7.2817 rec=1.3234 | train/val/test=0.825/0.828/0.834 | c=0.999014
[Epoch 0075] loss=17.6237 cls=0.4783 smmd=0.2159 ct=7.2818 rec=1.3236 | train/val/test=0.825/0.829/0.834 | c=0.999014
[Epoch 0076] loss=17.6299 cls=0.4790 smmd=0.2164 ct=7.2821 rec=1.3238 | train/val/test=0.826/0.828/0.834 | c=0.999014
[Epoch 0077] loss=17.6337 cls=0.4793 smmd=0.2168 ct=7.2819 rec=1.3242 | train/val/test=0.826/0.829/0.833 | c=0.999014
[Epoch 0078] loss=17.6170 cls=0.4799 smmd=0.2153 ct=7.2810 rec=1.3240 | train/val/test=0.825/0.827/0.832 | c=0.999014
[Epoch 0079] loss=17.6075 cls=0.4803 smmd=0.2151 ct=7.2772 rec=1.3239 | train/val/test=0.826/0.830/0.834 | c=0.999014
[Epoch 0080] loss=17.5864 cls=0.4805 smmd=0.2134 ct=7.2748 rec=1.3241 | train/val/test=0.824/0.829/0.834 | c=0.999014
[Epoch 0081] loss=17.5791 cls=0.4809 smmd=0.2130 ct=7.2732 rec=1.3241 | train/val/test=0.825/0.828/0.834 | c=0.999014
[Epoch 0082] loss=17.5889 cls=0.4815 smmd=0.2141 ct=7.2727 rec=1.3242 | train/val/test=0.825/0.830/0.833 | c=0.999014
[Epoch 0083] loss=17.5792 cls=0.4825 smmd=0.2132 ct=7.2719 rec=1.3244 | train/val/test=0.825/0.827/0.834 | c=0.999014
[Epoch 0084] loss=17.5882 cls=0.4830 smmd=0.2144 ct=7.2703 rec=1.3246 | train/val/test=0.825/0.828/0.833 | c=0.999014
[Epoch 0085] loss=17.5969 cls=0.4834 smmd=0.2152 ct=7.2702 rec=1.3252 | train/val/test=0.825/0.829/0.833 | c=0.999014
[Epoch 0086] loss=17.5855 cls=0.4843 smmd=0.2142 ct=7.2693 rec=1.3253 | train/val/test=0.825/0.828/0.832 | c=0.999014
[Epoch 0087] loss=17.5874 cls=0.4847 smmd=0.2146 ct=7.2680 rec=1.3256 | train/val/test=0.824/0.828/0.832 | c=0.999014
[Epoch 0088] loss=17.5721 cls=0.4851 smmd=0.2135 ct=7.2656 rec=1.3260 | train/val/test=0.824/0.827/0.833 | c=0.999014
[Epoch 0089] loss=17.5739 cls=0.4855 smmd=0.2138 ct=7.2650 rec=1.3262 | train/val/test=0.825/0.829/0.833 | c=0.999014
[Epoch 0090] loss=17.5728 cls=0.4863 smmd=0.2137 ct=7.2646 rec=1.3262 | train/val/test=0.824/0.828/0.832 | c=0.999014
[Epoch 0091] loss=17.5877 cls=0.4865 smmd=0.2159 ct=7.2612 rec=1.3264 | train/val/test=0.824/0.828/0.833 | c=0.999014
[Epoch 0092] loss=17.5839 cls=0.4865 smmd=0.2153 ct=7.2623 rec=1.3265 | train/val/test=0.824/0.829/0.832 | c=0.999014
[Epoch 0093] loss=17.5535 cls=0.4869 smmd=0.2126 ct=7.2604 rec=1.3264 | train/val/test=0.824/0.828/0.833 | c=0.999014
[Epoch 0094] loss=17.5702 cls=0.4869 smmd=0.2144 ct=7.2595 rec=1.3264 | train/val/test=0.824/0.829/0.832 | c=0.999014
[Epoch 0095] loss=17.5459 cls=0.4875 smmd=0.2117 ct=7.2608 rec=1.3262 | train/val/test=0.824/0.829/0.832 | c=0.999014
[Epoch 0096] loss=17.5317 cls=0.4879 smmd=0.2113 ct=7.2556 rec=1.3264 | train/val/test=0.823/0.827/0.833 | c=0.999014
[Epoch 0097] loss=17.5619 cls=0.4883 smmd=0.2146 ct=7.2544 rec=1.3266 | train/val/test=0.824/0.828/0.833 | c=0.999014
[Epoch 0098] loss=17.5584 cls=0.4887 smmd=0.2137 ct=7.2567 rec=1.3268 | train/val/test=0.824/0.828/0.832 | c=0.999014
[Epoch 0099] loss=17.5540 cls=0.4895 smmd=0.2133 ct=7.2563 rec=1.3270 | train/val/test=0.824/0.827/0.831 | c=0.999014
=== Best @ epoch 82: val=0.8303, test=0.8332 ===
