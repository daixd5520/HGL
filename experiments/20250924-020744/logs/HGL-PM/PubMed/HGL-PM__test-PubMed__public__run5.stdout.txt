Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=57.7114 cls=1.0825 smmd=4.1961 ct=7.2510 rec=1.4139 | train/val/test=0.392/0.395/0.392 | c=0.999014
[Epoch 0001] loss=34.0077 cls=1.0590 smmd=1.8374 ct=7.1980 rec=1.4163 | train/val/test=0.565/0.574/0.565 | c=0.999014
[Epoch 0002] loss=22.5322 cls=1.0567 smmd=0.7077 ct=7.1098 rec=1.4145 | train/val/test=0.559/0.569/0.562 | c=0.999014
[Epoch 0003] loss=26.3617 cls=1.0445 smmd=1.0874 ct=7.1294 rec=1.4140 | train/val/test=0.545/0.560/0.546 | c=0.999014
[Epoch 0004] loss=25.8356 cls=1.0126 smmd=1.0373 ct=7.1248 rec=1.4147 | train/val/test=0.539/0.549/0.540 | c=0.999014
[Epoch 0005] loss=23.0426 cls=0.9840 smmd=0.7671 ct=7.0856 rec=1.4161 | train/val/test=0.536/0.550/0.534 | c=0.999014
[Epoch 0006] loss=20.4839 cls=0.9678 smmd=0.5221 ct=7.0355 rec=1.4166 | train/val/test=0.535/0.546/0.533 | c=0.999014
[Epoch 0007] loss=20.9473 cls=0.9449 smmd=0.5755 ct=7.0066 rec=1.4135 | train/val/test=0.536/0.542/0.534 | c=0.999014
[Epoch 0008] loss=21.9720 cls=0.9046 smmd=0.6849 ct=6.9835 rec=1.4062 | train/val/test=0.539/0.551/0.540 | c=0.999014
[Epoch 0009] loss=21.5546 cls=0.8586 smmd=0.6519 ct=6.9541 rec=1.3965 | train/val/test=0.601/0.611/0.603 | c=0.999014
[Epoch 0010] loss=20.1933 cls=0.8175 smmd=0.5230 ct=6.9308 rec=1.3858 | train/val/test=0.655/0.666/0.659 | c=0.999014
[Epoch 0011] loss=19.0815 cls=0.7847 smmd=0.4166 ct=6.9177 rec=1.3751 | train/val/test=0.672/0.687/0.675 | c=0.999014
[Epoch 0012] loss=18.8749 cls=0.7589 smmd=0.3984 ct=6.9145 rec=1.3656 | train/val/test=0.682/0.694/0.683 | c=0.999014
[Epoch 0013] loss=18.9649 cls=0.7350 smmd=0.4098 ct=6.9102 rec=1.3578 | train/val/test=0.691/0.700/0.691 | c=0.999014
[Epoch 0014] loss=20.2069 cls=0.7111 smmd=0.3978 ct=7.5989 rec=1.3518 | train/val/test=0.704/0.716/0.701 | c=0.999014
[Epoch 0015] loss=19.8838 cls=0.6882 smmd=0.3864 ct=7.5013 rec=1.3469 | train/val/test=0.716/0.726/0.711 | c=0.999014
[Epoch 0016] loss=19.7851 cls=0.6680 smmd=0.3937 ct=7.4212 rec=1.3424 | train/val/test=0.731/0.739/0.725 | c=0.999014
[Epoch 0017] loss=19.6236 cls=0.6512 smmd=0.3820 ct=7.4044 rec=1.3382 | train/val/test=0.746/0.755/0.742 | c=0.999014
[Epoch 0018] loss=19.4184 cls=0.6369 smmd=0.3577 ct=7.4279 rec=1.3345 | train/val/test=0.758/0.766/0.752 | c=0.999014
[Epoch 0019] loss=19.3103 cls=0.6206 smmd=0.3450 ct=7.4424 rec=1.3313 | train/val/test=0.763/0.773/0.759 | c=0.999014
[Epoch 0020] loss=19.3411 cls=0.5988 smmd=0.3499 ct=7.4392 rec=1.3283 | train/val/test=0.767/0.778/0.764 | c=0.999014
[Epoch 0021] loss=19.1819 cls=0.5769 smmd=0.3355 ct=7.4378 rec=1.3263 | train/val/test=0.778/0.787/0.776 | c=0.999014
[Epoch 0022] loss=18.8653 cls=0.5569 smmd=0.3029 ct=7.4480 rec=1.3243 | train/val/test=0.790/0.793/0.785 | c=0.999014
[Epoch 0023] loss=18.7347 cls=0.5387 smmd=0.2902 ct=7.4514 rec=1.3218 | train/val/test=0.798/0.800/0.787 | c=0.999014
[Epoch 0024] loss=18.6759 cls=0.5239 smmd=0.2889 ct=7.4325 rec=1.3193 | train/val/test=0.803/0.807/0.794 | c=0.999014
[Epoch 0025] loss=18.5080 cls=0.5120 smmd=0.2786 ct=7.4037 rec=1.3172 | train/val/test=0.808/0.814/0.801 | c=0.999014
[Epoch 0026] loss=18.3484 cls=0.5044 smmd=0.2666 ct=7.3863 rec=1.3161 | train/val/test=0.811/0.822/0.802 | c=0.999014
[Epoch 0027] loss=18.3340 cls=0.4997 smmd=0.2647 ct=7.3892 rec=1.3165 | train/val/test=0.814/0.823/0.803 | c=0.999014
[Epoch 0028] loss=18.3110 cls=0.4914 smmd=0.2600 ct=7.4032 rec=1.3167 | train/val/test=0.815/0.821/0.806 | c=0.999014
[Epoch 0029] loss=18.2226 cls=0.4837 smmd=0.2499 ct=7.4116 rec=1.3166 | train/val/test=0.814/0.820/0.805 | c=0.999014
[Epoch 0030] loss=18.1867 cls=0.4811 smmd=0.2474 ct=7.4065 rec=1.3171 | train/val/test=0.815/0.823/0.806 | c=0.999014
[Epoch 0031] loss=18.2098 cls=0.4784 smmd=0.2530 ct=7.3913 rec=1.3168 | train/val/test=0.819/0.826/0.808 | c=0.999014
[Epoch 0032] loss=18.2135 cls=0.4754 smmd=0.2561 ct=7.3783 rec=1.3163 | train/val/test=0.819/0.827/0.811 | c=0.999014
[Epoch 0033] loss=18.1911 cls=0.4734 smmd=0.2547 ct=7.3749 rec=1.3158 | train/val/test=0.820/0.829/0.812 | c=0.999014
[Epoch 0034] loss=18.1587 cls=0.4717 smmd=0.2512 ct=7.3765 rec=1.3155 | train/val/test=0.822/0.828/0.813 | c=0.999014
[Epoch 0035] loss=18.1386 cls=0.4703 smmd=0.2489 ct=7.3781 rec=1.3156 | train/val/test=0.823/0.828/0.813 | c=0.999014
[Epoch 0036] loss=18.1215 cls=0.4692 smmd=0.2473 ct=7.3778 rec=1.3157 | train/val/test=0.823/0.826/0.815 | c=0.999014
[Epoch 0037] loss=18.0611 cls=0.4678 smmd=0.2424 ct=7.3729 rec=1.3145 | train/val/test=0.821/0.826/0.812 | c=0.999014
[Epoch 0038] loss=18.0171 cls=0.4674 smmd=0.2398 ct=7.3647 rec=1.3129 | train/val/test=0.820/0.827/0.814 | c=0.999014
[Epoch 0039] loss=17.9832 cls=0.4680 smmd=0.2383 ct=7.3551 rec=1.3116 | train/val/test=0.821/0.825/0.817 | c=0.999014
[Epoch 0040] loss=17.9406 cls=0.4682 smmd=0.2348 ct=7.3517 rec=1.3110 | train/val/test=0.822/0.828/0.816 | c=0.999014
[Epoch 0041] loss=17.9008 cls=0.4677 smmd=0.2300 ct=7.3559 rec=1.3115 | train/val/test=0.822/0.828/0.816 | c=0.999014
[Epoch 0042] loss=17.8647 cls=0.4678 smmd=0.2259 ct=7.3576 rec=1.3125 | train/val/test=0.824/0.830/0.817 | c=0.999014
[Epoch 0043] loss=17.8463 cls=0.4682 smmd=0.2249 ct=7.3532 rec=1.3136 | train/val/test=0.825/0.832/0.816 | c=0.999014
[Epoch 0044] loss=17.8247 cls=0.4693 smmd=0.2246 ct=7.3433 rec=1.3147 | train/val/test=0.824/0.831/0.816 | c=0.999014
[Epoch 0045] loss=17.8352 cls=0.4712 smmd=0.2274 ct=7.3340 rec=1.3157 | train/val/test=0.825/0.831/0.816 | c=0.999014
[Epoch 0046] loss=17.8212 cls=0.4729 smmd=0.2263 ct=7.3319 rec=1.3169 | train/val/test=0.825/0.832/0.817 | c=0.999014
[Epoch 0047] loss=17.8368 cls=0.4739 smmd=0.2274 ct=7.3335 rec=1.3181 | train/val/test=0.826/0.831/0.818 | c=0.999014
[Epoch 0048] loss=17.8206 cls=0.4746 smmd=0.2254 ct=7.3348 rec=1.3193 | train/val/test=0.826/0.831/0.818 | c=0.999014
[Epoch 0049] loss=17.8190 cls=0.4751 smmd=0.2256 ct=7.3325 rec=1.3203 | train/val/test=0.826/0.831/0.818 | c=0.999014
[Epoch 0050] loss=17.8153 cls=0.4754 smmd=0.2259 ct=7.3290 rec=1.3206 | train/val/test=0.825/0.832/0.818 | c=0.999014
[Epoch 0051] loss=17.7775 cls=0.4753 smmd=0.2225 ct=7.3273 rec=1.3208 | train/val/test=0.826/0.832/0.819 | c=0.999014
[Epoch 0052] loss=17.7581 cls=0.4754 smmd=0.2215 ct=7.3225 rec=1.3204 | train/val/test=0.825/0.831/0.817 | c=0.999014
[Epoch 0053] loss=17.7366 cls=0.4749 smmd=0.2205 ct=7.3170 rec=1.3202 | train/val/test=0.825/0.832/0.816 | c=0.999014
[Epoch 0054] loss=17.7289 cls=0.4741 smmd=0.2205 ct=7.3134 rec=1.3205 | train/val/test=0.825/0.831/0.817 | c=0.999014
[Epoch 0055] loss=17.7112 cls=0.4738 smmd=0.2195 ct=7.3096 rec=1.3203 | train/val/test=0.825/0.833/0.816 | c=0.999014
[Epoch 0056] loss=17.7083 cls=0.4734 smmd=0.2192 ct=7.3099 rec=1.3202 | train/val/test=0.826/0.832/0.817 | c=0.999014
[Epoch 0057] loss=17.7004 cls=0.4736 smmd=0.2182 ct=7.3108 rec=1.3200 | train/val/test=0.826/0.831/0.819 | c=0.999014
[Epoch 0058] loss=17.6885 cls=0.4739 smmd=0.2175 ct=7.3081 rec=1.3199 | train/val/test=0.826/0.833/0.819 | c=0.999014
[Epoch 0059] loss=17.7061 cls=0.4736 smmd=0.2200 ct=7.3044 rec=1.3203 | train/val/test=0.827/0.834/0.818 | c=0.999014
[Epoch 0060] loss=17.7166 cls=0.4734 smmd=0.2216 ct=7.3018 rec=1.3208 | train/val/test=0.826/0.834/0.819 | c=0.999014
[Epoch 0061] loss=17.6865 cls=0.4732 smmd=0.2185 ct=7.3021 rec=1.3210 | train/val/test=0.827/0.833/0.820 | c=0.999014
[Epoch 0062] loss=17.7005 cls=0.4732 smmd=0.2201 ct=7.3013 rec=1.3210 | train/val/test=0.827/0.833/0.821 | c=0.999014
[Epoch 0063] loss=17.6770 cls=0.4732 smmd=0.2183 ct=7.2983 rec=1.3208 | train/val/test=0.827/0.834/0.819 | c=0.999014
[Epoch 0064] loss=17.6781 cls=0.4729 smmd=0.2189 ct=7.2960 rec=1.3209 | train/val/test=0.828/0.835/0.820 | c=0.999014
[Epoch 0065] loss=17.6691 cls=0.4723 smmd=0.2185 ct=7.2935 rec=1.3212 | train/val/test=0.827/0.834/0.821 | c=0.999014
[Epoch 0066] loss=17.6560 cls=0.4716 smmd=0.2181 ct=7.2891 rec=1.3214 | train/val/test=0.828/0.834/0.821 | c=0.999014
[Epoch 0067] loss=17.6370 cls=0.4716 smmd=0.2166 ct=7.2873 rec=1.3211 | train/val/test=0.828/0.831/0.822 | c=0.999014
[Epoch 0068] loss=17.6323 cls=0.4715 smmd=0.2155 ct=7.2903 rec=1.3213 | train/val/test=0.828/0.831/0.822 | c=0.999014
[Epoch 0069] loss=17.6345 cls=0.4715 smmd=0.2157 ct=7.2906 rec=1.3216 | train/val/test=0.828/0.834/0.822 | c=0.999014
[Epoch 0070] loss=17.6430 cls=0.4712 smmd=0.2172 ct=7.2871 rec=1.3218 | train/val/test=0.828/0.833/0.823 | c=0.999014
[Epoch 0071] loss=17.6358 cls=0.4714 smmd=0.2173 ct=7.2830 rec=1.3220 | train/val/test=0.827/0.833/0.823 | c=0.999014
[Epoch 0072] loss=17.6391 cls=0.4717 smmd=0.2179 ct=7.2816 rec=1.3223 | train/val/test=0.828/0.833/0.823 | c=0.999014
[Epoch 0073] loss=17.6298 cls=0.4717 smmd=0.2171 ct=7.2810 rec=1.3227 | train/val/test=0.828/0.833/0.824 | c=0.999014
[Epoch 0074] loss=17.6363 cls=0.4721 smmd=0.2181 ct=7.2788 rec=1.3229 | train/val/test=0.828/0.834/0.823 | c=0.999014
[Epoch 0075] loss=17.6353 cls=0.4724 smmd=0.2181 ct=7.2785 rec=1.3229 | train/val/test=0.828/0.832/0.823 | c=0.999014
[Epoch 0076] loss=17.6267 cls=0.4721 smmd=0.2171 ct=7.2791 rec=1.3233 | train/val/test=0.828/0.835/0.823 | c=0.999014
[Epoch 0077] loss=17.5961 cls=0.4723 smmd=0.2142 ct=7.2783 rec=1.3233 | train/val/test=0.828/0.833/0.823 | c=0.999014
[Epoch 0078] loss=17.5906 cls=0.4729 smmd=0.2142 ct=7.2752 rec=1.3229 | train/val/test=0.828/0.832/0.823 | c=0.999014
[Epoch 0079] loss=17.5875 cls=0.4734 smmd=0.2144 ct=7.2728 rec=1.3231 | train/val/test=0.828/0.833/0.824 | c=0.999014
[Epoch 0080] loss=17.5946 cls=0.4731 smmd=0.2148 ct=7.2740 rec=1.3234 | train/val/test=0.829/0.835/0.823 | c=0.999014
[Epoch 0081] loss=17.5768 cls=0.4738 smmd=0.2135 ct=7.2714 rec=1.3233 | train/val/test=0.828/0.831/0.824 | c=0.999014
[Epoch 0082] loss=17.5746 cls=0.4741 smmd=0.2134 ct=7.2707 rec=1.3236 | train/val/test=0.828/0.833/0.824 | c=0.999014
[Epoch 0083] loss=17.5899 cls=0.4744 smmd=0.2149 ct=7.2709 rec=1.3238 | train/val/test=0.829/0.833/0.823 | c=0.999014
[Epoch 0084] loss=17.5905 cls=0.4749 smmd=0.2150 ct=7.2704 rec=1.3239 | train/val/test=0.829/0.831/0.823 | c=0.999014
[Epoch 0085] loss=17.6012 cls=0.4756 smmd=0.2164 ct=7.2687 rec=1.3241 | train/val/test=0.829/0.831/0.824 | c=0.999014
[Epoch 0086] loss=17.5970 cls=0.4754 smmd=0.2165 ct=7.2662 rec=1.3242 | train/val/test=0.828/0.832/0.825 | c=0.999014
[Epoch 0087] loss=17.5902 cls=0.4752 smmd=0.2157 ct=7.2665 rec=1.3244 | train/val/test=0.828/0.832/0.824 | c=0.999014
[Epoch 0088] loss=17.5676 cls=0.4756 smmd=0.2137 ct=7.2652 rec=1.3242 | train/val/test=0.829/0.833/0.825 | c=0.999014
[Epoch 0089] loss=17.5865 cls=0.4752 smmd=0.2155 ct=7.2659 rec=1.3243 | train/val/test=0.828/0.832/0.825 | c=0.999014
[Epoch 0090] loss=17.5822 cls=0.4748 smmd=0.2155 ct=7.2638 rec=1.3246 | train/val/test=0.829/0.834/0.824 | c=0.999014
[Epoch 0091] loss=17.5410 cls=0.4757 smmd=0.2119 ct=7.2611 rec=1.3239 | train/val/test=0.829/0.833/0.824 | c=0.999014
[Epoch 0092] loss=17.5478 cls=0.4753 smmd=0.2123 ct=7.2623 rec=1.3243 | train/val/test=0.828/0.832/0.825 | c=0.999014
[Epoch 0093] loss=17.5636 cls=0.4752 smmd=0.2141 ct=7.2615 rec=1.3248 | train/val/test=0.829/0.833/0.825 | c=0.999014
[Epoch 0094] loss=17.5750 cls=0.4760 smmd=0.2153 ct=7.2607 rec=1.3246 | train/val/test=0.828/0.833/0.825 | c=0.999014
[Epoch 0095] loss=17.5673 cls=0.4759 smmd=0.2148 ct=7.2593 rec=1.3251 | train/val/test=0.829/0.832/0.824 | c=0.999014
[Epoch 0096] loss=17.5628 cls=0.4764 smmd=0.2145 ct=7.2587 rec=1.3247 | train/val/test=0.829/0.832/0.825 | c=0.999014
[Epoch 0097] loss=17.5642 cls=0.4765 smmd=0.2140 ct=7.2617 rec=1.3248 | train/val/test=0.828/0.833/0.824 | c=0.999014
[Epoch 0098] loss=17.5791 cls=0.4761 smmd=0.2159 ct=7.2595 rec=1.3251 | train/val/test=0.829/0.832/0.824 | c=0.999014
[Epoch 0099] loss=17.5580 cls=0.4764 smmd=0.2148 ct=7.2547 rec=1.3247 | train/val/test=0.829/0.832/0.825 | c=0.999014
=== Best @ epoch 64: val=0.8352, test=0.8200 ===
