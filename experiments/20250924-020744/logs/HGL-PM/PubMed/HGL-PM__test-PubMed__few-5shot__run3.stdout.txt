Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=23.3156 cls=1.0920 smmd=4.1561 ct=11.2754 rec=1.4136 | train/val/test=0.308/0.416/0.408 | c=0.999014
[Epoch 0001] loss=22.9304 cls=1.0962 smmd=3.9356 ct=11.2735 rec=1.4136 | train/val/test=0.308/0.424/0.409 | c=0.999014
[Epoch 0002] loss=22.3049 cls=1.0972 smmd=3.5807 ct=11.2694 rec=1.4136 | train/val/test=0.231/0.502/0.494 | c=0.999014
[Epoch 0003] loss=21.3523 cls=1.0992 smmd=3.0409 ct=11.2623 rec=1.4135 | train/val/test=0.538/0.540/0.508 | c=0.999014
[Epoch 0004] loss=19.9913 cls=1.0933 smmd=2.2760 ct=11.2484 rec=1.4135 | train/val/test=0.308/0.222/0.197 | c=0.999014
[Epoch 0005] loss=18.2997 cls=1.0884 smmd=1.3348 ct=11.2171 rec=1.4136 | train/val/test=0.308/0.196/0.181 | c=0.999014
[Epoch 0006] loss=17.1218 cls=1.0907 smmd=0.6908 ct=11.1766 rec=1.4136 | train/val/test=0.308/0.196/0.180 | c=0.999014
[Epoch 0007] loss=17.7846 cls=1.0955 smmd=1.0588 ct=11.1881 rec=1.4136 | train/val/test=0.308/0.196/0.180 | c=0.999014
[Epoch 0008] loss=18.8906 cls=1.0935 smmd=1.6873 ct=11.1941 rec=1.4136 | train/val/test=0.308/0.200/0.187 | c=0.999014
[Epoch 0009] loss=19.1676 cls=1.0847 smmd=1.8720 ct=11.1636 rec=1.4136 | train/val/test=0.538/0.422/0.410 | c=0.999014
[Epoch 0010] loss=18.5208 cls=1.0761 smmd=1.5619 ct=11.0884 rec=1.4135 | train/val/test=0.769/0.618/0.612 | c=0.999014
[Epoch 0011] loss=17.4181 cls=1.0517 smmd=1.0127 ct=10.9936 rec=1.4135 | train/val/test=0.769/0.640/0.644 | c=0.999014
[Epoch 0012] loss=16.8548 cls=1.0357 smmd=0.7365 ct=10.9414 rec=1.4135 | train/val/test=0.769/0.660/0.657 | c=0.999014
[Epoch 0013] loss=17.0047 cls=1.0635 smmd=0.8238 ct=10.9231 rec=1.4133 | train/val/test=0.769/0.670/0.666 | c=0.999014
[Epoch 0014] loss=17.0532 cls=1.0036 smmd=0.8865 ct=10.9106 rec=1.4131 | train/val/test=0.846/0.682/0.681 | c=0.999014
[Epoch 0015] loss=16.8392 cls=1.0111 smmd=0.7715 ct=10.8966 rec=1.4126 | train/val/test=0.846/0.686/0.679 | c=0.999014
[Epoch 0016] loss=16.4671 cls=0.9588 smmd=0.5910 ct=10.8837 rec=1.4121 | train/val/test=0.846/0.686/0.672 | c=0.999014
[Epoch 0017] loss=16.3439 cls=0.9631 smmd=0.5210 ct=10.8809 rec=1.4116 | train/val/test=0.846/0.680/0.677 | c=0.999014
[Epoch 0018] loss=17.3331 cls=0.9259 smmd=0.6150 ct=11.5369 rec=1.4113 | train/val/test=0.923/0.668/0.662 | c=0.999014
[Epoch 0019] loss=17.5405 cls=0.9407 smmd=0.8958 ct=11.3100 rec=1.4105 | train/val/test=0.846/0.668/0.663 | c=0.999014
[Epoch 0020] loss=17.6176 cls=0.8917 smmd=1.0313 ct=11.2154 rec=1.4101 | train/val/test=0.846/0.682/0.670 | c=0.999014
[Epoch 0021] loss=17.6164 cls=0.9356 smmd=0.9535 ct=11.2939 rec=1.4100 | train/val/test=0.846/0.674/0.673 | c=0.999014
[Epoch 0022] loss=17.5522 cls=0.8890 smmd=0.9087 ct=11.3318 rec=1.4097 | train/val/test=0.846/0.678/0.676 | c=0.999014
[Epoch 0023] loss=17.6612 cls=0.9021 smmd=0.9856 ct=11.3049 rec=1.4088 | train/val/test=0.846/0.670/0.675 | c=0.999014
[Epoch 0024] loss=17.6102 cls=0.8861 smmd=0.9650 ct=11.3033 rec=1.4066 | train/val/test=0.846/0.670/0.679 | c=0.999014
[Epoch 0025] loss=17.4162 cls=0.8926 smmd=0.8350 ct=11.3261 rec=1.4039 | train/val/test=0.846/0.674/0.689 | c=0.999014
[Epoch 0026] loss=17.1399 cls=0.7836 smmd=0.7201 ct=11.3320 rec=1.4008 | train/val/test=0.923/0.692/0.688 | c=0.999014
[Epoch 0027] loss=17.0040 cls=0.7252 smmd=0.6826 ct=11.3128 rec=1.3972 | train/val/test=0.923/0.704/0.695 | c=0.999014
[Epoch 0028] loss=16.9892 cls=0.7669 smmd=0.6680 ct=11.2983 rec=1.3935 | train/val/test=0.923/0.702/0.694 | c=0.999014
[Epoch 0029] loss=16.8606 cls=0.7028 smmd=0.6246 ct=11.2956 rec=1.3905 | train/val/test=0.923/0.704/0.694 | c=0.999014
[Epoch 0030] loss=16.8178 cls=0.6582 smmd=0.6078 ct=11.3113 rec=1.3897 | train/val/test=0.923/0.700/0.695 | c=0.999014
[Epoch 0031] loss=16.8901 cls=0.7087 smmd=0.6284 ct=11.3103 rec=1.3888 | train/val/test=0.923/0.688/0.695 | c=0.999014
[Epoch 0032] loss=16.8959 cls=0.6471 smmd=0.6687 ct=11.2960 rec=1.3886 | train/val/test=0.923/0.694/0.695 | c=0.999014
[Epoch 0033] loss=16.8920 cls=0.5934 smmd=0.7045 ct=11.2757 rec=1.3892 | train/val/test=0.923/0.690/0.688 | c=0.999014
[Epoch 0034] loss=16.9960 cls=0.7026 smmd=0.7232 ct=11.2673 rec=1.3899 | train/val/test=0.923/0.688/0.697 | c=0.999014
[Epoch 0035] loss=17.0180 cls=0.7215 smmd=0.7284 ct=11.2668 rec=1.3881 | train/val/test=0.923/0.692/0.691 | c=0.999014
[Epoch 0036] loss=16.9810 cls=0.7127 smmd=0.7091 ct=11.2696 rec=1.3875 | train/val/test=0.923/0.678/0.685 | c=0.999014
[Epoch 0037] loss=16.9776 cls=0.7850 smmd=0.6683 ct=11.2801 rec=1.3881 | train/val/test=0.923/0.692/0.689 | c=0.999014
[Epoch 0038] loss=16.7683 cls=0.6043 smmd=0.6362 ct=11.2685 rec=1.3819 | train/val/test=0.923/0.698/0.685 | c=0.999014
[Epoch 0039] loss=16.6429 cls=0.5344 smmd=0.6095 ct=11.2493 rec=1.3783 | train/val/test=0.923/0.708/0.692 | c=0.999014
[Epoch 0040] loss=16.6532 cls=0.6100 smmd=0.5828 ct=11.2493 rec=1.3793 | train/val/test=0.923/0.708/0.698 | c=0.999014
[Epoch 0041] loss=16.5776 cls=0.5573 smmd=0.5660 ct=11.2454 rec=1.3751 | train/val/test=0.923/0.700/0.697 | c=0.999014
[Epoch 0042] loss=16.5259 cls=0.4959 smmd=0.5494 ct=11.2637 rec=1.3742 | train/val/test=0.923/0.714/0.691 | c=0.999014
[Epoch 0043] loss=16.8390 cls=0.8884 smmd=0.5630 ct=11.2601 rec=1.3733 | train/val/test=0.923/0.708/0.704 | c=0.999014
[Epoch 0044] loss=16.7410 cls=0.7165 smmd=0.5901 ct=11.2487 rec=1.3691 | train/val/test=0.923/0.718/0.704 | c=0.999014
[Epoch 0045] loss=16.9178 cls=0.9379 smmd=0.5989 ct=11.2462 rec=1.3658 | train/val/test=1.000/0.720/0.700 | c=0.999014
[Epoch 0046] loss=16.7736 cls=0.7395 smmd=0.6018 ct=11.2460 rec=1.3653 | train/val/test=1.000/0.700/0.688 | c=0.999014
[Epoch 0047] loss=16.6051 cls=0.4963 smmd=0.5965 ct=11.2633 rec=1.3668 | train/val/test=0.923/0.718/0.705 | c=0.999014
[Epoch 0048] loss=16.7503 cls=0.6780 smmd=0.6013 ct=11.2652 rec=1.3618 | train/val/test=0.923/0.710/0.688 | c=0.999014
[Epoch 0049] loss=16.8944 cls=0.9035 smmd=0.5787 ct=11.2759 rec=1.3632 | train/val/test=1.000/0.698/0.682 | c=0.999014
[Epoch 0050] loss=16.8438 cls=0.7853 smmd=0.5951 ct=11.2835 rec=1.3622 | train/val/test=1.000/0.706/0.698 | c=0.999014
[Epoch 0051] loss=16.7322 cls=0.7401 smmd=0.5680 ct=11.2627 rec=1.3541 | train/val/test=0.923/0.696/0.700 | c=0.999014
[Epoch 0052] loss=16.9685 cls=1.0567 smmd=0.5570 ct=11.2764 rec=1.3547 | train/val/test=1.000/0.688/0.703 | c=0.999014
[Epoch 0053] loss=16.8299 cls=0.8829 smmd=0.5616 ct=11.2644 rec=1.3532 | train/val/test=1.000/0.706/0.709 | c=0.999014
[Epoch 0054] loss=16.8968 cls=1.0058 smmd=0.5516 ct=11.2585 rec=1.3526 | train/val/test=1.000/0.702/0.689 | c=0.999014
[Epoch 0055] loss=17.3478 cls=1.5653 smmd=0.5375 ct=11.2987 rec=1.3622 | train/val/test=0.923/0.696/0.692 | c=0.999014
[Epoch 0056] loss=16.9306 cls=1.0554 smmd=0.5196 ct=11.2969 rec=1.3597 | train/val/test=0.923/0.698/0.701 | c=0.999014
[Epoch 0057] loss=16.3827 cls=0.3609 smmd=0.5200 ct=11.2768 rec=1.3557 | train/val/test=0.923/0.690/0.698 | c=0.999014
[Epoch 0058] loss=16.6981 cls=0.7697 smmd=0.5391 ct=11.2574 rec=1.3569 | train/val/test=0.923/0.694/0.680 | c=0.999014
[Epoch 0059] loss=16.6497 cls=0.6877 smmd=0.5428 ct=11.2596 rec=1.3664 | train/val/test=0.923/0.660/0.656 | c=0.999014
[Epoch 0060] loss=16.8520 cls=0.9055 smmd=0.5459 ct=11.2816 rec=1.3784 | train/val/test=0.923/0.694/0.688 | c=0.999014
[Epoch 0061] loss=16.7200 cls=0.7797 smmd=0.5462 ct=11.2545 rec=1.3714 | train/val/test=0.923/0.700/0.701 | c=0.999014
[Epoch 0062] loss=16.6262 cls=0.6226 smmd=0.5682 ct=11.2443 rec=1.3683 | train/val/test=0.923/0.688/0.699 | c=0.999014
[Epoch 0063] loss=16.9939 cls=1.0804 smmd=0.5860 ct=11.2386 rec=1.3702 | train/val/test=0.923/0.684/0.699 | c=0.999014
[Epoch 0064] loss=17.2342 cls=1.3953 smmd=0.5978 ct=11.2254 rec=1.3713 | train/val/test=0.923/0.682/0.694 | c=0.999014
[Epoch 0065] loss=16.6739 cls=0.6416 smmd=0.6030 ct=11.2210 rec=1.3753 | train/val/test=0.923/0.674/0.687 | c=0.999014
[Epoch 0066] loss=17.0050 cls=1.0736 smmd=0.6011 ct=11.2280 rec=1.3788 | train/val/test=0.923/0.674/0.682 | c=0.999014
[Epoch 0067] loss=16.8952 cls=0.9271 smmd=0.5914 ct=11.2402 rec=1.3819 | train/val/test=0.923/0.668/0.688 | c=0.999014
[Epoch 0068] loss=16.6544 cls=0.5976 smmd=0.5959 ct=11.2392 rec=1.3813 | train/val/test=0.923/0.672/0.688 | c=0.999014
[Epoch 0069] loss=16.9398 cls=0.9687 smmd=0.6023 ct=11.2358 rec=1.3819 | train/val/test=0.923/0.676/0.687 | c=0.999014
[Epoch 0070] loss=16.7182 cls=0.6801 smmd=0.6018 ct=11.2319 rec=1.3839 | train/val/test=0.923/0.682/0.681 | c=0.999014
[Epoch 0071] loss=17.0534 cls=1.1212 smmd=0.6015 ct=11.2346 rec=1.3874 | train/val/test=0.923/0.676/0.678 | c=0.999014
[Epoch 0072] loss=16.7572 cls=0.7209 smmd=0.5987 ct=11.2407 rec=1.3896 | train/val/test=0.923/0.682/0.680 | c=0.999014
[Epoch 0073] loss=16.7905 cls=0.7694 smmd=0.5949 ct=11.2434 rec=1.3897 | train/val/test=0.923/0.686/0.686 | c=0.999014
[Epoch 0074] loss=17.0338 cls=1.1007 smmd=0.5942 ct=11.2410 rec=1.3878 | train/val/test=0.923/0.692/0.689 | c=0.999014
[Epoch 0075] loss=16.5862 cls=0.4971 smmd=0.6023 ct=11.2348 rec=1.3855 | train/val/test=0.923/0.690/0.690 | c=0.999014
[Epoch 0076] loss=16.9449 cls=0.9687 smmd=0.6085 ct=11.2305 rec=1.3845 | train/val/test=0.923/0.694/0.688 | c=0.999014
[Epoch 0077] loss=16.7584 cls=0.7225 smmd=0.6118 ct=11.2249 rec=1.3840 | train/val/test=0.923/0.696/0.690 | c=0.999014
[Epoch 0078] loss=16.6039 cls=0.5111 smmd=0.6183 ct=11.2194 rec=1.3836 | train/val/test=0.923/0.702/0.696 | c=0.999014
[Epoch 0079] loss=16.6510 cls=0.5809 smmd=0.6189 ct=11.2145 rec=1.3833 | train/val/test=0.923/0.700/0.696 | c=0.999014
[Epoch 0080] loss=16.6058 cls=0.5143 smmd=0.6207 ct=11.2158 rec=1.3834 | train/val/test=0.923/0.698/0.692 | c=0.999014
[Epoch 0081] loss=16.6093 cls=0.5099 smmd=0.6213 ct=11.2200 rec=1.3841 | train/val/test=0.923/0.696/0.692 | c=0.999014
[Epoch 0082] loss=16.7464 cls=0.6964 smmd=0.6174 ct=11.2230 rec=1.3843 | train/val/test=0.923/0.692/0.690 | c=0.999014
[Epoch 0083] loss=16.6315 cls=0.5408 smmd=0.6120 ct=11.2314 rec=1.3853 | train/val/test=0.923/0.688/0.689 | c=0.999014
[Epoch 0084] loss=16.8005 cls=0.7514 smmd=0.6151 ct=11.2356 rec=1.3857 | train/val/test=0.923/0.690/0.689 | c=0.999014
[Epoch 0085] loss=16.7059 cls=0.6249 smmd=0.6161 ct=11.2347 rec=1.3848 | train/val/test=0.923/0.694/0.689 | c=0.999014
[Epoch 0086] loss=16.6130 cls=0.4977 smmd=0.6202 ct=11.2315 rec=1.3836 | train/val/test=0.923/0.696/0.687 | c=0.999014
[Epoch 0087] loss=16.6771 cls=0.5853 smmd=0.6209 ct=11.2296 rec=1.3829 | train/val/test=1.000/0.698/0.685 | c=0.999014
[Epoch 0088] loss=16.5343 cls=0.3913 smmd=0.6244 ct=11.2271 rec=1.3824 | train/val/test=1.000/0.698/0.688 | c=0.999014
[Epoch 0089] loss=16.6078 cls=0.4861 smmd=0.6256 ct=11.2272 rec=1.3825 | train/val/test=1.000/0.698/0.689 | c=0.999014
[Epoch 0090] loss=16.6486 cls=0.5386 smmd=0.6254 ct=11.2285 rec=1.3828 | train/val/test=1.000/0.696/0.691 | c=0.999014
[Epoch 0091] loss=16.7276 cls=0.6419 smmd=0.6261 ct=11.2287 rec=1.3830 | train/val/test=1.000/0.700/0.689 | c=0.999014
[Epoch 0092] loss=16.7251 cls=0.6325 smmd=0.6281 ct=11.2293 rec=1.3835 | train/val/test=1.000/0.700/0.691 | c=0.999014
[Epoch 0093] loss=16.6576 cls=0.5416 smmd=0.6283 ct=11.2296 rec=1.3835 | train/val/test=1.000/0.700/0.692 | c=0.999014
[Epoch 0094] loss=16.7579 cls=0.6792 smmd=0.6270 ct=11.2290 rec=1.3835 | train/val/test=1.000/0.700/0.691 | c=0.999014
[Epoch 0095] loss=16.7165 cls=0.6264 smmd=0.6252 ct=11.2302 rec=1.3835 | train/val/test=1.000/0.698/0.690 | c=0.999014
[Epoch 0096] loss=16.7246 cls=0.6322 smmd=0.6269 ct=11.2306 rec=1.3838 | train/val/test=1.000/0.698/0.690 | c=0.999014
[Epoch 0097] loss=16.6428 cls=0.5172 smmd=0.6294 ct=11.2308 rec=1.3837 | train/val/test=1.000/0.698/0.689 | c=0.999014
[Epoch 0098] loss=16.5367 cls=0.3817 smmd=0.6268 ct=11.2308 rec=1.3837 | train/val/test=1.000/0.698/0.689 | c=0.999014
[Epoch 0099] loss=16.7204 cls=0.6287 smmd=0.6260 ct=11.2307 rec=1.3837 | train/val/test=1.000/0.698/0.689 | c=0.999014
=== Best @ epoch 45: val=0.7200, test=0.7000 ===
