Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=23.1538 cls=1.0965 smmd=4.0602 ct=11.2774 rec=1.4136 | train/val/test=0.154/0.188/0.178 | c=0.999014
[Epoch 0001] loss=22.7597 cls=1.1049 smmd=3.8327 ct=11.2757 rec=1.4136 | train/val/test=0.385/0.362/0.393 | c=0.999014
[Epoch 0002] loss=22.0950 cls=1.0959 smmd=3.4589 ct=11.2728 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.999014
[Epoch 0003] loss=21.1099 cls=1.0862 smmd=2.9044 ct=11.2670 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.999014
[Epoch 0004] loss=19.7490 cls=1.0965 smmd=2.1317 ct=11.2545 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.999014
[Epoch 0005] loss=18.1093 cls=1.0896 smmd=1.2182 ct=11.2267 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.999014
[Epoch 0006] loss=17.0996 cls=1.0857 smmd=0.6746 ct=11.1841 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.999014
[Epoch 0007] loss=17.8194 cls=1.0892 smmd=1.0826 ct=11.1865 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.999014
[Epoch 0008] loss=18.8679 cls=1.0873 smmd=1.6783 ct=11.1924 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.999014
[Epoch 0009] loss=19.1029 cls=1.0793 smmd=1.8369 ct=11.1642 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.999014
[Epoch 0010] loss=18.4310 cls=1.0791 smmd=1.5066 ct=11.0921 rec=1.4137 | train/val/test=0.385/0.390/0.421 | c=0.999014
[Epoch 0011] loss=17.4051 cls=1.0668 smmd=0.9904 ct=11.0049 rec=1.4137 | train/val/test=0.538/0.434/0.462 | c=0.999014
[Epoch 0012] loss=16.9443 cls=1.0521 smmd=0.7632 ct=10.9648 rec=1.4136 | train/val/test=0.538/0.462/0.492 | c=0.999014
[Epoch 0013] loss=17.0157 cls=1.0323 smmd=0.8251 ct=10.9479 rec=1.4135 | train/val/test=0.538/0.494/0.532 | c=0.999014
[Epoch 0014] loss=17.0260 cls=1.0077 smmd=0.8568 ct=10.9273 rec=1.4134 | train/val/test=0.538/0.516/0.559 | c=0.999014
[Epoch 0015] loss=16.8366 cls=1.0389 smmd=0.7549 ct=10.9009 rec=1.4130 | train/val/test=0.615/0.540/0.572 | c=0.999014
[Epoch 0016] loss=16.5253 cls=0.9993 smmd=0.6089 ct=10.8809 rec=1.4126 | train/val/test=0.615/0.550/0.590 | c=0.999014
[Epoch 0017] loss=17.3054 cls=0.9988 smmd=0.5557 ct=11.5531 rec=1.4120 | train/val/test=0.538/0.528/0.562 | c=0.999014
[Epoch 0018] loss=17.3597 cls=0.9823 smmd=0.7790 ct=11.3037 rec=1.4126 | train/val/test=0.538/0.488/0.529 | c=0.999014
[Epoch 0019] loss=17.5882 cls=0.9742 smmd=0.9650 ct=11.2335 rec=1.4132 | train/val/test=0.615/0.490/0.530 | c=0.999014
[Epoch 0020] loss=17.7021 cls=0.9558 smmd=0.9734 ct=11.3204 rec=1.4129 | train/val/test=0.615/0.518/0.568 | c=0.999014
[Epoch 0021] loss=17.6307 cls=0.9352 smmd=0.9063 ct=11.3680 rec=1.4122 | train/val/test=0.615/0.504/0.555 | c=0.999014
[Epoch 0022] loss=17.6706 cls=0.9501 smmd=0.9824 ct=11.2876 rec=1.4122 | train/val/test=0.615/0.514/0.573 | c=0.999014
[Epoch 0023] loss=17.6986 cls=0.9356 smmd=1.0073 ct=11.2843 rec=1.4115 | train/val/test=0.692/0.610/0.634 | c=0.999014
[Epoch 0024] loss=17.5690 cls=0.8229 smmd=0.9477 ct=11.3306 rec=1.4092 | train/val/test=0.769/0.668/0.676 | c=0.999014
[Epoch 0025] loss=17.4027 cls=0.7977 smmd=0.8718 ct=11.3204 rec=1.4056 | train/val/test=0.923/0.674/0.696 | c=0.999014
[Epoch 0026] loss=17.1873 cls=0.7891 smmd=0.7628 ct=11.3076 rec=1.4015 | train/val/test=0.923/0.686/0.692 | c=0.999014
[Epoch 0027] loss=17.0890 cls=0.8550 smmd=0.6677 ct=11.3234 rec=1.3973 | train/val/test=0.923/0.698/0.693 | c=0.999014
[Epoch 0028] loss=16.8720 cls=0.6151 smmd=0.6320 ct=11.3441 rec=1.3933 | train/val/test=0.923/0.698/0.695 | c=0.999014
[Epoch 0029] loss=16.9921 cls=0.7869 smmd=0.6388 ct=11.3293 rec=1.3899 | train/val/test=0.923/0.700/0.700 | c=0.999014
[Epoch 0030] loss=17.0252 cls=0.8686 smmd=0.6406 ct=11.3058 rec=1.3877 | train/val/test=0.923/0.706/0.691 | c=0.999014
[Epoch 0031] loss=17.0879 cls=0.9342 smmd=0.6525 ct=11.2997 rec=1.3890 | train/val/test=0.923/0.710/0.698 | c=0.999014
[Epoch 0032] loss=17.1199 cls=0.8801 smmd=0.6818 ct=11.3159 rec=1.3898 | train/val/test=0.923/0.710/0.715 | c=0.999014
[Epoch 0033] loss=16.9947 cls=0.6224 smmd=0.7196 ct=11.3179 rec=1.3884 | train/val/test=0.923/0.708/0.715 | c=0.999014
[Epoch 0034] loss=17.0890 cls=0.7257 smmd=0.7493 ct=11.2904 rec=1.3900 | train/val/test=0.923/0.712/0.713 | c=0.999014
[Epoch 0035] loss=17.1070 cls=0.7966 smmd=0.7311 ct=11.2880 rec=1.3889 | train/val/test=0.923/0.716/0.701 | c=0.999014
[Epoch 0036] loss=17.0957 cls=0.7943 smmd=0.7234 ct=11.2911 rec=1.3891 | train/val/test=0.923/0.714/0.711 | c=0.999014
[Epoch 0037] loss=17.1228 cls=0.9025 smmd=0.6944 ct=11.2894 rec=1.3861 | train/val/test=1.000/0.708/0.700 | c=0.999014
[Epoch 0038] loss=16.9550 cls=0.7752 smmd=0.6591 ct=11.2816 rec=1.3851 | train/val/test=1.000/0.702/0.696 | c=0.999014
[Epoch 0039] loss=17.3001 cls=1.3222 smmd=0.6205 ct=11.2832 rec=1.3860 | train/val/test=1.000/0.690/0.682 | c=0.999014
[Epoch 0040] loss=16.8701 cls=0.8258 smmd=0.5833 ct=11.2903 rec=1.3814 | train/val/test=1.000/0.678/0.683 | c=0.999014
[Epoch 0041] loss=17.2344 cls=1.3905 smmd=0.5595 ct=11.2771 rec=1.3805 | train/val/test=1.000/0.670/0.681 | c=0.999014
[Epoch 0042] loss=16.8245 cls=0.8812 smmd=0.5516 ct=11.2659 rec=1.3816 | train/val/test=1.000/0.674/0.684 | c=0.999014
[Epoch 0043] loss=16.7014 cls=0.7225 smmd=0.5439 ct=11.2738 rec=1.3793 | train/val/test=1.000/0.690/0.696 | c=0.999014
[Epoch 0044] loss=16.7093 cls=0.7031 smmd=0.5393 ct=11.2980 rec=1.3769 | train/val/test=1.000/0.678/0.682 | c=0.999014
[Epoch 0045] loss=16.7044 cls=0.6764 smmd=0.5621 ct=11.2767 rec=1.3841 | train/val/test=0.923/0.660/0.667 | c=0.999014
[Epoch 0046] loss=16.7774 cls=0.6939 smmd=0.6032 ct=11.2663 rec=1.3880 | train/val/test=0.923/0.678/0.680 | c=0.999014
[Epoch 0047] loss=16.7893 cls=0.6717 smmd=0.6171 ct=11.2703 rec=1.3852 | train/val/test=1.000/0.700/0.689 | c=0.999014
[Epoch 0048] loss=16.9039 cls=0.7740 smmd=0.6333 ct=11.2780 rec=1.3844 | train/val/test=0.923/0.704/0.691 | c=0.999014
[Epoch 0049] loss=17.1364 cls=1.0457 smmd=0.6597 ct=11.2635 rec=1.3877 | train/val/test=0.923/0.688/0.682 | c=0.999014
[Epoch 0050] loss=16.9536 cls=0.7951 smmd=0.6670 ct=11.2580 rec=1.3866 | train/val/test=0.923/0.690/0.679 | c=0.999014
[Epoch 0051] loss=16.9298 cls=0.7868 smmd=0.6578 ct=11.2563 rec=1.3882 | train/val/test=0.923/0.688/0.674 | c=0.999014
[Epoch 0052] loss=16.7512 cls=0.5936 smmd=0.6324 ct=11.2655 rec=1.3856 | train/val/test=0.923/0.684/0.672 | c=0.999014
[Epoch 0053] loss=16.7571 cls=0.6507 smmd=0.6141 ct=11.2620 rec=1.3844 | train/val/test=0.923/0.686/0.685 | c=0.999014
[Epoch 0054] loss=16.7824 cls=0.7221 smmd=0.6035 ct=11.2554 rec=1.3820 | train/val/test=0.923/0.674/0.682 | c=0.999014
[Epoch 0055] loss=16.6364 cls=0.5652 smmd=0.5827 ct=11.2631 rec=1.3770 | train/val/test=1.000/0.678/0.669 | c=0.999014
[Epoch 0056] loss=16.8724 cls=0.8918 smmd=0.5741 ct=11.2672 rec=1.3787 | train/val/test=1.000/0.672/0.661 | c=0.999014
[Epoch 0057] loss=16.7596 cls=0.7352 smmd=0.5741 ct=11.2704 rec=1.3798 | train/val/test=0.923/0.684/0.676 | c=0.999014
[Epoch 0058] loss=16.9446 cls=0.9796 smmd=0.5832 ct=11.2597 rec=1.3791 | train/val/test=0.923/0.672/0.675 | c=0.999014
[Epoch 0059] loss=16.7808 cls=0.7386 smmd=0.5975 ct=11.2528 rec=1.3814 | train/val/test=0.923/0.678/0.666 | c=0.999014
[Epoch 0060] loss=16.8513 cls=0.8394 smmd=0.5937 ct=11.2545 rec=1.3797 | train/val/test=0.923/0.664/0.659 | c=0.999014
[Epoch 0061] loss=16.6832 cls=0.5924 smmd=0.5969 ct=11.2638 rec=1.3787 | train/val/test=0.923/0.672/0.669 | c=0.999014
[Epoch 0062] loss=16.7679 cls=0.6966 smmd=0.6014 ct=11.2627 rec=1.3787 | train/val/test=0.923/0.672/0.685 | c=0.999014
[Epoch 0063] loss=16.6586 cls=0.5398 smmd=0.6136 ct=11.2523 rec=1.3802 | train/val/test=0.923/0.674/0.687 | c=0.999014
[Epoch 0064] loss=16.6780 cls=0.5417 smmd=0.6290 ct=11.2447 rec=1.3823 | train/val/test=0.923/0.670/0.681 | c=0.999014
[Epoch 0065] loss=16.8474 cls=0.7566 smmd=0.6350 ct=11.2420 rec=1.3853 | train/val/test=0.923/0.680/0.690 | c=0.999014
[Epoch 0066] loss=16.7090 cls=0.5657 smmd=0.6352 ct=11.2458 rec=1.3841 | train/val/test=0.923/0.686/0.686 | c=0.999014
[Epoch 0067] loss=16.8167 cls=0.6990 smmd=0.6326 ct=11.2559 rec=1.3817 | train/val/test=0.923/0.690/0.690 | c=0.999014
[Epoch 0068] loss=16.7879 cls=0.6636 smmd=0.6329 ct=11.2543 rec=1.3804 | train/val/test=1.000/0.692/0.688 | c=0.999014
[Epoch 0069] loss=16.8700 cls=0.7913 smmd=0.6346 ct=11.2409 rec=1.3821 | train/val/test=1.000/0.680/0.684 | c=0.999014
[Epoch 0070] loss=16.8927 cls=0.8275 smmd=0.6360 ct=11.2354 rec=1.3825 | train/val/test=1.000/0.688/0.680 | c=0.999014
[Epoch 0071] loss=16.7746 cls=0.6810 smmd=0.6327 ct=11.2338 rec=1.3815 | train/val/test=1.000/0.688/0.679 | c=0.999014
[Epoch 0072] loss=16.7443 cls=0.6523 smmd=0.6242 ct=11.2389 rec=1.3802 | train/val/test=1.000/0.696/0.684 | c=0.999014
[Epoch 0073] loss=16.6423 cls=0.5223 smmd=0.6173 ct=11.2452 rec=1.3793 | train/val/test=1.000/0.694/0.680 | c=0.999014
[Epoch 0074] loss=16.6172 cls=0.4945 smmd=0.6142 ct=11.2459 rec=1.3794 | train/val/test=1.000/0.682/0.680 | c=0.999014
[Epoch 0075] loss=16.7660 cls=0.7067 smmd=0.6124 ct=11.2400 rec=1.3804 | train/val/test=1.000/0.690/0.684 | c=0.999014
[Epoch 0076] loss=16.6555 cls=0.5641 smmd=0.6134 ct=11.2365 rec=1.3789 | train/val/test=1.000/0.694/0.690 | c=0.999014
[Epoch 0077] loss=17.0350 cls=1.0688 smmd=0.6146 ct=11.2361 rec=1.3775 | train/val/test=1.000/0.696/0.693 | c=0.999014
[Epoch 0078] loss=16.7673 cls=0.7124 smmd=0.6150 ct=11.2356 rec=1.3765 | train/val/test=1.000/0.704/0.697 | c=0.999014
[Epoch 0079] loss=16.7657 cls=0.7164 smmd=0.6130 ct=11.2347 rec=1.3761 | train/val/test=1.000/0.700/0.702 | c=0.999014
[Epoch 0080] loss=16.7007 cls=0.6297 smmd=0.6131 ct=11.2348 rec=1.3756 | train/val/test=1.000/0.704/0.704 | c=0.999014
[Epoch 0081] loss=16.8552 cls=0.8359 smmd=0.6135 ct=11.2341 rec=1.3759 | train/val/test=1.000/0.704/0.705 | c=0.999014
[Epoch 0082] loss=16.7670 cls=0.7163 smmd=0.6151 ct=11.2331 rec=1.3761 | train/val/test=1.000/0.700/0.702 | c=0.999014
[Epoch 0083] loss=16.8851 cls=0.8721 smmd=0.6162 ct=11.2324 rec=1.3767 | train/val/test=1.000/0.700/0.701 | c=0.999014
[Epoch 0084] loss=16.6939 cls=0.6138 smmd=0.6168 ct=11.2334 rec=1.3770 | train/val/test=1.000/0.702/0.700 | c=0.999014
[Epoch 0085] loss=16.6490 cls=0.5479 smmd=0.6190 ct=11.2338 rec=1.3773 | train/val/test=1.000/0.704/0.699 | c=0.999014
[Epoch 0086] loss=16.7453 cls=0.6694 smmd=0.6209 ct=11.2351 rec=1.3772 | train/val/test=1.000/0.704/0.701 | c=0.999014
[Epoch 0087] loss=16.6767 cls=0.5752 smmd=0.6216 ct=11.2361 rec=1.3766 | train/val/test=1.000/0.704/0.709 | c=0.999014
[Epoch 0088] loss=16.6311 cls=0.5174 smmd=0.6198 ct=11.2369 rec=1.3759 | train/val/test=1.000/0.706/0.708 | c=0.999014
[Epoch 0089] loss=16.5403 cls=0.3908 smmd=0.6216 ct=11.2379 rec=1.3753 | train/val/test=1.000/0.706/0.710 | c=0.999014
[Epoch 0090] loss=16.7980 cls=0.7282 smmd=0.6245 ct=11.2376 rec=1.3751 | train/val/test=1.000/0.706/0.710 | c=0.999014
[Epoch 0091] loss=16.6031 cls=0.4661 smmd=0.6251 ct=11.2381 rec=1.3749 | train/val/test=1.000/0.704/0.710 | c=0.999014
[Epoch 0092] loss=16.6800 cls=0.5731 smmd=0.6242 ct=11.2367 rec=1.3750 | train/val/test=1.000/0.704/0.709 | c=0.999014
[Epoch 0093] loss=16.7204 cls=0.6260 smmd=0.6259 ct=11.2350 rec=1.3751 | train/val/test=1.000/0.706/0.708 | c=0.999014
[Epoch 0094] loss=16.5887 cls=0.4504 smmd=0.6264 ct=11.2343 rec=1.3753 | train/val/test=1.000/0.708/0.708 | c=0.999014
[Epoch 0095] loss=16.5789 cls=0.4282 smmd=0.6307 ct=11.2338 rec=1.3754 | train/val/test=1.000/0.708/0.708 | c=0.999014
[Epoch 0096] loss=16.6843 cls=0.5716 smmd=0.6296 ct=11.2336 rec=1.3755 | train/val/test=1.000/0.708/0.708 | c=0.999014
[Epoch 0097] loss=16.7409 cls=0.6511 smmd=0.6284 ct=11.2328 rec=1.3756 | train/val/test=1.000/0.708/0.707 | c=0.999014
[Epoch 0098] loss=16.5801 cls=0.4293 smmd=0.6314 ct=11.2330 rec=1.3756 | train/val/test=1.000/0.708/0.707 | c=0.999014
[Epoch 0099] loss=16.6092 cls=0.4700 smmd=0.6309 ct=11.2326 rec=1.3757 | train/val/test=1.000/0.708/0.707 | c=0.999014
=== Best @ epoch 35: val=0.7160, test=0.7010 ===
