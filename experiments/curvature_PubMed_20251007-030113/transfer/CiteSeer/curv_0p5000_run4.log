Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[Epoch 0000] loss=16.9135 cls=1.7902 smmd=2.3457 ct=6.9470 rec=1.3917 | train/val/test=0.199/0.214/0.194 | c=0.500000
[Epoch 0001] loss=16.7677 cls=1.7795 smmd=2.2800 ct=6.9394 rec=1.3917 | train/val/test=0.199/0.214/0.194 | c=0.500000
[Epoch 0002] loss=15.5189 cls=1.7699 smmd=1.6640 ct=6.9248 rec=1.3917 | train/val/test=0.201/0.214/0.194 | c=0.500000
[Epoch 0003] loss=14.4765 cls=1.7569 smmd=1.1575 ct=6.8908 rec=1.3918 | train/val/test=0.304/0.320/0.290 | c=0.500000
[Epoch 0004] loss=13.9725 cls=1.7412 smmd=0.9211 ct=6.8586 rec=1.3920 | train/val/test=0.371/0.377/0.356 | c=0.500000
[Epoch 0005] loss=13.5263 cls=1.7228 smmd=0.7154 ct=6.8246 rec=1.3921 | train/val/test=0.464/0.477/0.467 | c=0.500000
[Epoch 0006] loss=13.2911 cls=1.7001 smmd=0.6225 ct=6.7720 rec=1.3920 | train/val/test=0.520/0.525/0.523 | c=0.500000
[Epoch 0007] loss=13.0831 cls=1.6720 smmd=0.5481 ct=6.7119 rec=1.3918 | train/val/test=0.562/0.562/0.551 | c=0.500000
[Epoch 0008] loss=12.7139 cls=1.6392 smmd=0.3933 ct=6.6623 rec=1.3914 | train/val/test=0.635/0.639/0.622 | c=0.500000
[Epoch 0009] loss=12.4663 cls=1.6025 smmd=0.2969 ct=6.6325 rec=1.3908 | train/val/test=0.689/0.669/0.668 | c=0.500000
[Epoch 0010] loss=12.4891 cls=1.5624 smmd=0.3333 ct=6.6217 rec=1.3899 | train/val/test=0.708/0.710/0.692 | c=0.500000
[Epoch 0011] loss=12.5002 cls=1.5190 smmd=0.3649 ct=6.6167 rec=1.3886 | train/val/test=0.721/0.713/0.704 | c=0.500000
[Epoch 0012] loss=12.2951 cls=1.4728 smmd=0.2933 ct=6.6041 rec=1.3867 | train/val/test=0.727/0.713/0.704 | c=0.500000
[Epoch 0013] loss=12.0562 cls=1.4243 smmd=0.2094 ct=6.5845 rec=1.3842 | train/val/test=0.731/0.708/0.716 | c=0.500000
[Epoch 0014] loss=12.3724 cls=1.3737 smmd=0.2297 ct=7.2715 rec=1.3807 | train/val/test=0.734/0.716/0.718 | c=0.500000
[Epoch 0015] loss=12.3648 cls=1.3209 smmd=0.2836 ct=7.1910 rec=1.3762 | train/val/test=0.736/0.726/0.725 | c=0.500000
[Epoch 0016] loss=12.2226 cls=1.2667 smmd=0.2796 ct=7.0883 rec=1.3705 | train/val/test=0.737/0.726/0.725 | c=0.500000
[Epoch 0017] loss=12.0152 cls=1.2117 smmd=0.2360 ct=7.0285 rec=1.3634 | train/val/test=0.737/0.728/0.719 | c=0.500000
[Epoch 0018] loss=11.9029 cls=1.1567 smmd=0.2286 ct=7.0312 rec=1.3547 | train/val/test=0.731/0.723/0.721 | c=0.500000
[Epoch 0019] loss=11.8502 cls=1.1035 smmd=0.2430 ct=7.0802 rec=1.3441 | train/val/test=0.728/0.714/0.715 | c=0.500000
[Epoch 0020] loss=11.7274 cls=1.0533 smmd=0.2225 ct=7.1390 rec=1.3319 | train/val/test=0.729/0.713/0.715 | c=0.500000
[Epoch 0021] loss=11.5371 cls=1.0054 smmd=0.1751 ct=7.1755 rec=1.3188 | train/val/test=0.733/0.722/0.715 | c=0.500000
[Epoch 0022] loss=11.3971 cls=0.9593 smmd=0.1618 ct=7.1738 rec=1.3055 | train/val/test=0.741/0.722/0.724 | c=0.500000
[Epoch 0023] loss=11.3213 cls=0.9154 smmd=0.1863 ct=7.1406 rec=1.2926 | train/val/test=0.748/0.737/0.730 | c=0.500000
[Epoch 0024] loss=11.2197 cls=0.8755 smmd=0.1967 ct=7.0975 rec=1.2804 | train/val/test=0.752/0.743/0.736 | c=0.500000
[Epoch 0025] loss=11.0819 cls=0.8412 smmd=0.1811 ct=7.0674 rec=1.2690 | train/val/test=0.756/0.744/0.731 | c=0.500000
[Epoch 0026] loss=10.9857 cls=0.8130 smmd=0.1743 ct=7.0628 rec=1.2585 | train/val/test=0.758/0.744/0.733 | c=0.500000
[Epoch 0027] loss=10.9368 cls=0.7902 smmd=0.1795 ct=7.0817 rec=1.2493 | train/val/test=0.759/0.744/0.731 | c=0.500000
[Epoch 0028] loss=10.8790 cls=0.7709 smmd=0.1734 ct=7.1079 rec=1.2415 | train/val/test=0.760/0.743/0.730 | c=0.500000
[Epoch 0029] loss=10.8017 cls=0.7531 smmd=0.1557 ct=7.1252 rec=1.2349 | train/val/test=0.765/0.743/0.736 | c=0.500000
[Epoch 0030] loss=10.7506 cls=0.7372 smmd=0.1504 ct=7.1277 rec=1.2298 | train/val/test=0.767/0.740/0.740 | c=0.500000
[Epoch 0031] loss=10.7357 cls=0.7238 smmd=0.1624 ct=7.1164 rec=1.2258 | train/val/test=0.770/0.740/0.740 | c=0.500000
[Epoch 0032] loss=10.7132 cls=0.7127 smmd=0.1689 ct=7.1006 rec=1.2225 | train/val/test=0.772/0.740/0.740 | c=0.500000
[Epoch 0033] loss=10.6740 cls=0.7036 smmd=0.1638 ct=7.0911 rec=1.2195 | train/val/test=0.773/0.743/0.737 | c=0.500000
[Epoch 0034] loss=10.6517 cls=0.6961 smmd=0.1624 ct=7.0934 rec=1.2168 | train/val/test=0.775/0.741/0.737 | c=0.500000
[Epoch 0035] loss=10.6476 cls=0.6889 smmd=0.1673 ct=7.1024 rec=1.2146 | train/val/test=0.777/0.744/0.742 | c=0.500000
[Epoch 0036] loss=10.6380 cls=0.6817 smmd=0.1687 ct=7.1118 rec=1.2126 | train/val/test=0.778/0.744/0.743 | c=0.500000
[Epoch 0037] loss=10.6183 cls=0.6750 smmd=0.1656 ct=7.1166 rec=1.2107 | train/val/test=0.780/0.744/0.745 | c=0.500000
[Epoch 0038] loss=10.6062 cls=0.6690 smmd=0.1674 ct=7.1155 rec=1.2090 | train/val/test=0.782/0.744/0.746 | c=0.500000
[Epoch 0039] loss=10.5903 cls=0.6637 smmd=0.1677 ct=7.1103 rec=1.2072 | train/val/test=0.782/0.744/0.746 | c=0.500000
[Epoch 0040] loss=10.5764 cls=0.6589 smmd=0.1683 ct=7.1048 rec=1.2057 | train/val/test=0.783/0.746/0.746 | c=0.500000
[Epoch 0041] loss=10.5679 cls=0.6539 smmd=0.1698 ct=7.1026 rec=1.2046 | train/val/test=0.782/0.747/0.748 | c=0.500000
[Epoch 0042] loss=10.5553 cls=0.6490 smmd=0.1676 ct=7.1037 rec=1.2039 | train/val/test=0.785/0.746/0.749 | c=0.500000
[Epoch 0043] loss=10.5523 cls=0.6446 smmd=0.1687 ct=7.1069 rec=1.2034 | train/val/test=0.783/0.746/0.748 | c=0.500000
[Epoch 0044] loss=10.5392 cls=0.6412 smmd=0.1641 ct=7.1098 rec=1.2030 | train/val/test=0.784/0.746/0.749 | c=0.500000
[Epoch 0045] loss=10.5349 cls=0.6383 smmd=0.1637 ct=7.1108 rec=1.2028 | train/val/test=0.784/0.747/0.749 | c=0.500000
[Epoch 0046] loss=10.5343 cls=0.6355 smmd=0.1649 ct=7.1098 rec=1.2028 | train/val/test=0.786/0.746/0.748 | c=0.500000
[Epoch 0047] loss=10.5358 cls=0.6327 smmd=0.1671 ct=7.1077 rec=1.2030 | train/val/test=0.787/0.746/0.749 | c=0.500000
[Epoch 0048] loss=10.5291 cls=0.6303 smmd=0.1653 ct=7.1055 rec=1.2031 | train/val/test=0.788/0.746/0.749 | c=0.500000
[Epoch 0049] loss=10.5214 cls=0.6286 smmd=0.1626 ct=7.1042 rec=1.2031 | train/val/test=0.787/0.746/0.748 | c=0.500000
[Epoch 0050] loss=10.5155 cls=0.6275 smmd=0.1600 ct=7.1065 rec=1.2030 | train/val/test=0.786/0.744/0.746 | c=0.500000
[Epoch 0051] loss=10.5157 cls=0.6267 smmd=0.1600 ct=7.1090 rec=1.2029 | train/val/test=0.789/0.744/0.746 | c=0.500000
[Epoch 0052] loss=10.5100 cls=0.6256 smmd=0.1576 ct=7.1094 rec=1.2029 | train/val/test=0.789/0.747/0.748 | c=0.500000
[Epoch 0053] loss=10.5069 cls=0.6247 smmd=0.1566 ct=7.1077 rec=1.2030 | train/val/test=0.788/0.744/0.746 | c=0.500000
[Epoch 0054] loss=10.5072 cls=0.6243 smmd=0.1573 ct=7.1058 rec=1.2031 | train/val/test=0.787/0.744/0.746 | c=0.500000
[Epoch 0055] loss=10.5003 cls=0.6241 smmd=0.1540 ct=7.1041 rec=1.2032 | train/val/test=0.786/0.741/0.748 | c=0.500000
[Epoch 0056] loss=10.5104 cls=0.6240 smmd=0.1585 ct=7.1046 rec=1.2034 | train/val/test=0.786/0.741/0.746 | c=0.500000
[Epoch 0057] loss=10.4979 cls=0.6236 smmd=0.1518 ct=7.1053 rec=1.2036 | train/val/test=0.788/0.741/0.748 | c=0.500000
[Epoch 0058] loss=10.5010 cls=0.6236 smmd=0.1524 ct=7.1065 rec=1.2039 | train/val/test=0.785/0.743/0.748 | c=0.500000
[Epoch 0059] loss=10.4983 cls=0.6236 smmd=0.1507 ct=7.1050 rec=1.2042 | train/val/test=0.785/0.741/0.748 | c=0.500000
[Epoch 0060] loss=10.5054 cls=0.6236 smmd=0.1540 ct=7.1027 rec=1.2045 | train/val/test=0.786/0.741/0.748 | c=0.500000
[Epoch 0061] loss=10.5026 cls=0.6237 smmd=0.1522 ct=7.1022 rec=1.2046 | train/val/test=0.786/0.741/0.748 | c=0.500000
[Epoch 0062] loss=10.4987 cls=0.6241 smmd=0.1497 ct=7.1031 rec=1.2047 | train/val/test=0.786/0.741/0.749 | c=0.500000
[Epoch 0063] loss=10.5025 cls=0.6243 smmd=0.1510 ct=7.1041 rec=1.2048 | train/val/test=0.785/0.741/0.748 | c=0.500000
[Epoch 0064] loss=10.4990 cls=0.6246 smmd=0.1488 ct=7.1050 rec=1.2049 | train/val/test=0.785/0.741/0.748 | c=0.500000
[Epoch 0065] loss=10.4977 cls=0.6248 smmd=0.1479 ct=7.1046 rec=1.2049 | train/val/test=0.786/0.741/0.748 | c=0.500000
[Epoch 0066] loss=10.4969 cls=0.6248 smmd=0.1475 ct=7.1037 rec=1.2050 | train/val/test=0.788/0.735/0.746 | c=0.500000
[Epoch 0067] loss=10.4984 cls=0.6246 smmd=0.1486 ct=7.1013 rec=1.2052 | train/val/test=0.787/0.735/0.746 | c=0.500000
[Epoch 0068] loss=10.4965 cls=0.6244 smmd=0.1476 ct=7.1003 rec=1.2054 | train/val/test=0.787/0.738/0.746 | c=0.500000
[Epoch 0069] loss=10.4966 cls=0.6243 smmd=0.1470 ct=7.1015 rec=1.2055 | train/val/test=0.787/0.735/0.746 | c=0.500000
[Epoch 0070] loss=10.5011 cls=0.6240 smmd=0.1487 ct=7.1031 rec=1.2056 | train/val/test=0.787/0.735/0.745 | c=0.500000
[Epoch 0071] loss=10.4995 cls=0.6243 smmd=0.1480 ct=7.1032 rec=1.2055 | train/val/test=0.788/0.735/0.745 | c=0.500000
[Epoch 0072] loss=10.4930 cls=0.6240 smmd=0.1457 ct=7.1015 rec=1.2054 | train/val/test=0.787/0.737/0.745 | c=0.500000
[Epoch 0073] loss=10.4928 cls=0.6235 smmd=0.1465 ct=7.1001 rec=1.2053 | train/val/test=0.789/0.737/0.746 | c=0.500000
[Epoch 0074] loss=10.4916 cls=0.6224 smmd=0.1464 ct=7.0996 rec=1.2053 | train/val/test=0.789/0.735/0.748 | c=0.500000
[Epoch 0075] loss=10.4932 cls=0.6221 smmd=0.1473 ct=7.1010 rec=1.2052 | train/val/test=0.789/0.737/0.748 | c=0.500000
[Epoch 0076] loss=10.4953 cls=0.6222 smmd=0.1482 ct=7.1036 rec=1.2050 | train/val/test=0.789/0.738/0.746 | c=0.500000
[Epoch 0077] loss=10.4913 cls=0.6217 smmd=0.1471 ct=7.1025 rec=1.2048 | train/val/test=0.790/0.735/0.751 | c=0.500000
[Epoch 0078] loss=10.4910 cls=0.6203 smmd=0.1484 ct=7.0990 rec=1.2049 | train/val/test=0.792/0.735/0.752 | c=0.500000
[Epoch 0079] loss=10.4882 cls=0.6192 smmd=0.1479 ct=7.0983 rec=1.2048 | train/val/test=0.790/0.738/0.752 | c=0.500000
[Epoch 0080] loss=10.4860 cls=0.6194 smmd=0.1471 ct=7.0998 rec=1.2045 | train/val/test=0.790/0.738/0.752 | c=0.500000
[Epoch 0081] loss=10.4786 cls=0.6190 smmd=0.1436 ct=7.1008 rec=1.2044 | train/val/test=0.791/0.738/0.754 | c=0.500000
[Epoch 0082] loss=10.4858 cls=0.6175 smmd=0.1475 ct=7.1015 rec=1.2045 | train/val/test=0.792/0.737/0.754 | c=0.500000
[Epoch 0083] loss=10.4842 cls=0.6163 smmd=0.1477 ct=7.0998 rec=1.2045 | train/val/test=0.792/0.737/0.752 | c=0.500000
[Epoch 0084] loss=10.4834 cls=0.6161 smmd=0.1482 ct=7.0993 rec=1.2042 | train/val/test=0.791/0.737/0.752 | c=0.500000
[Epoch 0085] loss=10.4829 cls=0.6160 smmd=0.1487 ct=7.0991 rec=1.2040 | train/val/test=0.791/0.740/0.755 | c=0.500000
[Epoch 0086] loss=10.4757 cls=0.6147 smmd=0.1459 ct=7.0985 rec=1.2040 | train/val/test=0.793/0.738/0.755 | c=0.500000
[Epoch 0087] loss=10.4758 cls=0.6133 smmd=0.1464 ct=7.0989 rec=1.2040 | train/val/test=0.793/0.740/0.754 | c=0.500000
[Epoch 0088] loss=10.4744 cls=0.6132 smmd=0.1454 ct=7.1021 rec=1.2038 | train/val/test=0.793/0.738/0.754 | c=0.500000
[Epoch 0089] loss=10.4778 cls=0.6129 smmd=0.1478 ct=7.1011 rec=1.2037 | train/val/test=0.793/0.740/0.755 | c=0.500000
[Epoch 0090] loss=10.4744 cls=0.6120 smmd=0.1472 ct=7.0985 rec=1.2037 | train/val/test=0.794/0.737/0.755 | c=0.500000
[Epoch 0091] loss=10.4745 cls=0.6108 smmd=0.1483 ct=7.0966 rec=1.2038 | train/val/test=0.794/0.740/0.755 | c=0.500000
[Epoch 0092] loss=10.4734 cls=0.6106 smmd=0.1478 ct=7.0990 rec=1.2036 | train/val/test=0.795/0.743/0.758 | c=0.500000
[Epoch 0093] loss=10.4711 cls=0.6099 smmd=0.1468 ct=7.1006 rec=1.2034 | train/val/test=0.794/0.740/0.758 | c=0.500000
[Epoch 0094] loss=10.4683 cls=0.6088 smmd=0.1463 ct=7.0997 rec=1.2034 | train/val/test=0.795/0.738/0.760 | c=0.500000
[Epoch 0095] loss=10.4682 cls=0.6082 smmd=0.1473 ct=7.0980 rec=1.2033 | train/val/test=0.795/0.740/0.758 | c=0.500000
[Epoch 0096] loss=10.4631 cls=0.6080 smmd=0.1455 ct=7.0973 rec=1.2031 | train/val/test=0.797/0.740/0.758 | c=0.500000
[Epoch 0097] loss=10.4626 cls=0.6072 smmd=0.1458 ct=7.0965 rec=1.2031 | train/val/test=0.799/0.738/0.758 | c=0.500000
[Epoch 0098] loss=10.4641 cls=0.6062 smmd=0.1466 ct=7.0973 rec=1.2032 | train/val/test=0.798/0.738/0.758 | c=0.500000
[Epoch 0099] loss=10.4588 cls=0.6058 smmd=0.1437 ct=7.0997 rec=1.2031 | train/val/test=0.797/0.740/0.757 | c=0.500000
[Epoch 0100] loss=10.4614 cls=0.6058 smmd=0.1453 ct=7.0996 rec=1.2030 | train/val/test=0.798/0.738/0.758 | c=0.500000
[Epoch 0101] loss=10.4614 cls=0.6054 smmd=0.1465 ct=7.0963 rec=1.2030 | train/val/test=0.800/0.738/0.758 | c=0.500000
[Epoch 0102] loss=10.4559 cls=0.6046 smmd=0.1445 ct=7.0947 rec=1.2030 | train/val/test=0.797/0.738/0.757 | c=0.500000
[Epoch 0103] loss=10.4584 cls=0.6042 smmd=0.1451 ct=7.0978 rec=1.2030 | train/val/test=0.797/0.738/0.757 | c=0.500000
[Epoch 0104] loss=10.4631 cls=0.6042 smmd=0.1468 ct=7.1007 rec=1.2030 | train/val/test=0.798/0.740/0.757 | c=0.500000
[Epoch 0105] loss=10.4627 cls=0.6027 smmd=0.1478 ct=7.0974 rec=1.2031 | train/val/test=0.798/0.740/0.758 | c=0.500000
[Epoch 0106] loss=10.4610 cls=0.6020 smmd=0.1488 ct=7.0924 rec=1.2030 | train/val/test=0.797/0.740/0.757 | c=0.500000
[Epoch 0107] loss=10.4590 cls=0.6022 smmd=0.1482 ct=7.0935 rec=1.2027 | train/val/test=0.798/0.740/0.757 | c=0.500000
[Epoch 0108] loss=10.4504 cls=0.6022 smmd=0.1435 ct=7.0979 rec=1.2025 | train/val/test=0.798/0.740/0.758 | c=0.500000
[Epoch 0109] loss=10.4564 cls=0.6011 smmd=0.1463 ct=7.0997 rec=1.2026 | train/val/test=0.799/0.740/0.757 | c=0.500000
[Epoch 0110] loss=10.4556 cls=0.6001 smmd=0.1467 ct=7.0978 rec=1.2026 | train/val/test=0.799/0.741/0.757 | c=0.500000
[Epoch 0111] loss=10.4475 cls=0.6002 smmd=0.1442 ct=7.0933 rec=1.2024 | train/val/test=0.798/0.740/0.757 | c=0.500000
[Epoch 0112] loss=10.4538 cls=0.6006 smmd=0.1479 ct=7.0919 rec=1.2023 | train/val/test=0.799/0.740/0.757 | c=0.500000
[Epoch 0113] loss=10.4482 cls=0.6001 smmd=0.1442 ct=7.0950 rec=1.2024 | train/val/test=0.799/0.741/0.758 | c=0.500000
[Epoch 0114] loss=10.4547 cls=0.5990 smmd=0.1469 ct=7.0970 rec=1.2027 | train/val/test=0.799/0.741/0.760 | c=0.500000
[Epoch 0115] loss=10.4534 cls=0.5988 smmd=0.1467 ct=7.0962 rec=1.2026 | train/val/test=0.799/0.740/0.760 | c=0.500000
[Epoch 0116] loss=10.4470 cls=0.5989 smmd=0.1445 ct=7.0937 rec=1.2024 | train/val/test=0.799/0.740/0.760 | c=0.500000
[Epoch 0117] loss=10.4487 cls=0.5986 smmd=0.1457 ct=7.0934 rec=1.2024 | train/val/test=0.799/0.741/0.760 | c=0.500000
[Epoch 0118] loss=10.4448 cls=0.5980 smmd=0.1439 ct=7.0947 rec=1.2024 | train/val/test=0.800/0.740/0.761 | c=0.500000
[Epoch 0119] loss=10.4494 cls=0.5975 smmd=0.1462 ct=7.0955 rec=1.2023 | train/val/test=0.799/0.738/0.761 | c=0.500000
[Epoch 0120] loss=10.4452 cls=0.5976 smmd=0.1447 ct=7.0946 rec=1.2022 | train/val/test=0.799/0.740/0.761 | c=0.500000
[Epoch 0121] loss=10.4491 cls=0.5974 smmd=0.1472 ct=7.0933 rec=1.2021 | train/val/test=0.799/0.741/0.761 | c=0.500000
[Epoch 0122] loss=10.4453 cls=0.5967 smmd=0.1456 ct=7.0929 rec=1.2022 | train/val/test=0.800/0.741/0.761 | c=0.500000
[Epoch 0123] loss=10.4451 cls=0.5964 smmd=0.1452 ct=7.0945 rec=1.2022 | train/val/test=0.799/0.740/0.761 | c=0.500000
[Epoch 0124] loss=10.4449 cls=0.5968 smmd=0.1447 ct=7.0964 rec=1.2021 | train/val/test=0.799/0.740/0.761 | c=0.500000
[Epoch 0125] loss=10.4401 cls=0.5964 smmd=0.1429 ct=7.0944 rec=1.2021 | train/val/test=0.798/0.740/0.761 | c=0.500000
[Epoch 0126] loss=10.4436 cls=0.5957 smmd=0.1451 ct=7.0929 rec=1.2022 | train/val/test=0.800/0.741/0.760 | c=0.500000
[Epoch 0127] loss=10.4486 cls=0.5955 smmd=0.1480 ct=7.0921 rec=1.2022 | train/val/test=0.798/0.741/0.761 | c=0.500000
[Epoch 0128] loss=10.4411 cls=0.5958 smmd=0.1444 ct=7.0931 rec=1.2020 | train/val/test=0.798/0.740/0.760 | c=0.500000
[Epoch 0129] loss=10.4423 cls=0.5963 smmd=0.1451 ct=7.0938 rec=1.2018 | train/val/test=0.799/0.740/0.761 | c=0.500000
[Epoch 0130] loss=10.4410 cls=0.5951 smmd=0.1448 ct=7.0935 rec=1.2019 | train/val/test=0.802/0.738/0.761 | c=0.500000
[Epoch 0131] loss=10.4412 cls=0.5943 smmd=0.1448 ct=7.0942 rec=1.2021 | train/val/test=0.800/0.740/0.760 | c=0.500000
[Epoch 0132] loss=10.4431 cls=0.5949 smmd=0.1455 ct=7.0949 rec=1.2020 | train/val/test=0.799/0.741/0.758 | c=0.500000
[Epoch 0133] loss=10.4396 cls=0.5962 smmd=0.1436 ct=7.0945 rec=1.2018 | train/val/test=0.800/0.738/0.761 | c=0.500000
[Epoch 0134] loss=10.4401 cls=0.5945 smmd=0.1448 ct=7.0904 rec=1.2022 | train/val/test=0.803/0.740/0.763 | c=0.500000
[Epoch 0135] loss=10.4414 cls=0.5935 smmd=0.1455 ct=7.0900 rec=1.2024 | train/val/test=0.800/0.741/0.760 | c=0.500000
[Epoch 0136] loss=10.4438 cls=0.5948 smmd=0.1459 ct=7.0942 rec=1.2020 | train/val/test=0.800/0.740/0.758 | c=0.500000
[Epoch 0137] loss=10.4378 cls=0.5958 smmd=0.1431 ct=7.0950 rec=1.2017 | train/val/test=0.801/0.737/0.763 | c=0.500000
[Epoch 0138] loss=10.4396 cls=0.5943 smmd=0.1454 ct=7.0908 rec=1.2018 | train/val/test=0.801/0.741/0.760 | c=0.500000
[Epoch 0139] loss=10.4410 cls=0.5939 smmd=0.1466 ct=7.0895 rec=1.2018 | train/val/test=0.800/0.740/0.760 | c=0.500000
[Epoch 0140] loss=10.4430 cls=0.5948 smmd=0.1469 ct=7.0921 rec=1.2017 | train/val/test=0.801/0.738/0.761 | c=0.500000
[Epoch 0141] loss=10.4403 cls=0.5942 smmd=0.1457 ct=7.0919 rec=1.2018 | train/val/test=0.801/0.743/0.763 | c=0.500000
[Epoch 0142] loss=10.4341 cls=0.5935 smmd=0.1426 ct=7.0921 rec=1.2018 | train/val/test=0.800/0.743/0.760 | c=0.500000
[Epoch 0143] loss=10.4370 cls=0.5938 smmd=0.1440 ct=7.0925 rec=1.2018 | train/val/test=0.800/0.740/0.758 | c=0.500000
[Epoch 0144] loss=10.4337 cls=0.5945 smmd=0.1425 ct=7.0918 rec=1.2017 | train/val/test=0.802/0.738/0.760 | c=0.500000
[Epoch 0145] loss=10.4342 cls=0.5941 smmd=0.1429 ct=7.0900 rec=1.2018 | train/val/test=0.802/0.741/0.761 | c=0.500000
[Epoch 0146] loss=10.4338 cls=0.5932 smmd=0.1430 ct=7.0896 rec=1.2019 | train/val/test=0.801/0.741/0.760 | c=0.500000
[Epoch 0147] loss=10.4390 cls=0.5934 smmd=0.1454 ct=7.0902 rec=1.2019 | train/val/test=0.801/0.737/0.760 | c=0.500000
[Epoch 0148] loss=10.4385 cls=0.5945 smmd=0.1446 ct=7.0926 rec=1.2017 | train/val/test=0.800/0.737/0.761 | c=0.500000
[Epoch 0149] loss=10.4421 cls=0.5941 smmd=0.1469 ct=7.0915 rec=1.2017 | train/val/test=0.801/0.741/0.760 | c=0.500000
[Epoch 0150] loss=10.4380 cls=0.5929 smmd=0.1460 ct=7.0880 rec=1.2018 | train/val/test=0.800/0.740/0.760 | c=0.500000
[Epoch 0151] loss=10.4345 cls=0.5930 smmd=0.1444 ct=7.0885 rec=1.2017 | train/val/test=0.801/0.738/0.761 | c=0.500000
[Epoch 0152] loss=10.4292 cls=0.5935 smmd=0.1412 ct=7.0912 rec=1.2015 | train/val/test=0.801/0.741/0.761 | c=0.500000
[Epoch 0153] loss=10.4316 cls=0.5929 smmd=0.1422 ct=7.0915 rec=1.2017 | train/val/test=0.801/0.740/0.761 | c=0.500000
[Epoch 0154] loss=10.4324 cls=0.5927 smmd=0.1428 ct=7.0895 rec=1.2019 | train/val/test=0.801/0.737/0.760 | c=0.500000
[Epoch 0155] loss=10.4376 cls=0.5932 smmd=0.1452 ct=7.0889 rec=1.2019 | train/val/test=0.800/0.740/0.760 | c=0.500000
[Epoch 0156] loss=10.4349 cls=0.5935 smmd=0.1437 ct=7.0898 rec=1.2018 | train/val/test=0.802/0.741/0.761 | c=0.500000
[Epoch 0157] loss=10.4375 cls=0.5927 smmd=0.1453 ct=7.0890 rec=1.2019 | train/val/test=0.800/0.740/0.760 | c=0.500000
[Epoch 0158] loss=10.4390 cls=0.5929 smmd=0.1467 ct=7.0880 rec=1.2017 | train/val/test=0.801/0.740/0.760 | c=0.500000
[Epoch 0159] loss=10.4291 cls=0.5932 smmd=0.1420 ct=7.0894 rec=1.2015 | train/val/test=0.801/0.741/0.760 | c=0.500000
[Epoch 0160] loss=10.4363 cls=0.5926 smmd=0.1451 ct=7.0912 rec=1.2016 | train/val/test=0.801/0.743/0.761 | c=0.500000
[Epoch 0161] loss=10.4314 cls=0.5923 smmd=0.1432 ct=7.0889 rec=1.2016 | train/val/test=0.801/0.740/0.760 | c=0.500000
[Epoch 0162] loss=10.4288 cls=0.5935 smmd=0.1419 ct=7.0884 rec=1.2015 | train/val/test=0.800/0.741/0.760 | c=0.500000
[Epoch 0163] loss=10.4320 cls=0.5932 smmd=0.1428 ct=7.0894 rec=1.2017 | train/val/test=0.801/0.741/0.761 | c=0.500000
[Epoch 0164] loss=10.4427 cls=0.5919 smmd=0.1480 ct=7.0879 rec=1.2022 | train/val/test=0.801/0.740/0.763 | c=0.500000
[Epoch 0165] loss=10.4304 cls=0.5923 smmd=0.1420 ct=7.0882 rec=1.2020 | train/val/test=0.800/0.740/0.758 | c=0.500000
[Epoch 0166] loss=10.4387 cls=0.5938 smmd=0.1459 ct=7.0901 rec=1.2016 | train/val/test=0.799/0.737/0.760 | c=0.500000
[Epoch 0167] loss=10.4352 cls=0.5930 smmd=0.1451 ct=7.0888 rec=1.2015 | train/val/test=0.802/0.741/0.761 | c=0.500000
[Epoch 0168] loss=10.4280 cls=0.5916 smmd=0.1425 ct=7.0867 rec=1.2016 | train/val/test=0.801/0.740/0.760 | c=0.500000
[Epoch 0169] loss=10.4243 cls=0.5924 smmd=0.1405 ct=7.0884 rec=1.2013 | train/val/test=0.801/0.737/0.760 | c=0.500000
[Epoch 0170] loss=10.4244 cls=0.5924 smmd=0.1403 ct=7.0885 rec=1.2014 | train/val/test=0.802/0.743/0.761 | c=0.500000
[Epoch 0171] loss=10.4329 cls=0.5918 smmd=0.1443 ct=7.0871 rec=1.2018 | train/val/test=0.801/0.741/0.761 | c=0.500000
[Epoch 0172] loss=10.4305 cls=0.5928 smmd=0.1427 ct=7.0869 rec=1.2017 | train/val/test=0.801/0.735/0.760 | c=0.500000
[Epoch 0173] loss=10.4306 cls=0.5926 smmd=0.1425 ct=7.0869 rec=1.2019 | train/val/test=0.801/0.743/0.760 | c=0.500000
[Epoch 0174] loss=10.4327 cls=0.5925 smmd=0.1430 ct=7.0884 rec=1.2020 | train/val/test=0.801/0.743/0.761 | c=0.500000
[Epoch 0175] loss=10.4312 cls=0.5925 smmd=0.1423 ct=7.0892 rec=1.2019 | train/val/test=0.801/0.740/0.761 | c=0.500000
[Epoch 0176] loss=10.4256 cls=0.5926 smmd=0.1404 ct=7.0868 rec=1.2018 | train/val/test=0.801/0.738/0.760 | c=0.500000
[Epoch 0177] loss=10.4349 cls=0.5928 smmd=0.1451 ct=7.0868 rec=1.2017 | train/val/test=0.801/0.737/0.760 | c=0.500000
[Epoch 0178] loss=10.4395 cls=0.5926 smmd=0.1481 ct=7.0860 rec=1.2016 | train/val/test=0.802/0.741/0.763 | c=0.500000
[Epoch 0179] loss=10.4329 cls=0.5922 smmd=0.1452 ct=7.0863 rec=1.2014 | train/val/test=0.802/0.741/0.760 | c=0.500000
[Epoch 0180] loss=10.4262 cls=0.5921 smmd=0.1420 ct=7.0872 rec=1.2013 | train/val/test=0.801/0.740/0.761 | c=0.500000
[Epoch 0181] loss=10.4261 cls=0.5919 smmd=0.1424 ct=7.0861 rec=1.2013 | train/val/test=0.802/0.741/0.760 | c=0.500000
[Epoch 0182] loss=10.4323 cls=0.5921 smmd=0.1454 ct=7.0856 rec=1.2013 | train/val/test=0.801/0.738/0.760 | c=0.500000
[Epoch 0183] loss=10.4298 cls=0.5912 smmd=0.1442 ct=7.0850 rec=1.2016 | train/val/test=0.802/0.738/0.760 | c=0.500000
[Epoch 0184] loss=10.4268 cls=0.5916 smmd=0.1423 ct=7.0852 rec=1.2016 | train/val/test=0.800/0.740/0.758 | c=0.500000
[Epoch 0185] loss=10.4304 cls=0.5928 smmd=0.1429 ct=7.0892 rec=1.2014 | train/val/test=0.801/0.738/0.760 | c=0.500000
[Epoch 0186] loss=10.4265 cls=0.5924 smmd=0.1415 ct=7.0868 rec=1.2015 | train/val/test=0.803/0.741/0.763 | c=0.500000
[Epoch 0187] loss=10.4217 cls=0.5914 smmd=0.1396 ct=7.0833 rec=1.2019 | train/val/test=0.802/0.740/0.760 | c=0.500000
[Epoch 0188] loss=10.4256 cls=0.5917 smmd=0.1414 ct=7.0836 rec=1.2019 | train/val/test=0.803/0.740/0.760 | c=0.500000
[Epoch 0189] loss=10.4359 cls=0.5920 smmd=0.1457 ct=7.0865 rec=1.2019 | train/val/test=0.802/0.737/0.763 | c=0.500000
[Epoch 0190] loss=10.4312 cls=0.5925 smmd=0.1432 ct=7.0876 rec=1.2017 | train/val/test=0.801/0.737/0.760 | c=0.500000
[Epoch 0191] loss=10.4272 cls=0.5926 smmd=0.1414 ct=7.0883 rec=1.2015 | train/val/test=0.803/0.741/0.763 | c=0.500000
[Epoch 0192] loss=10.4337 cls=0.5913 smmd=0.1461 ct=7.0825 rec=1.2018 | train/val/test=0.802/0.738/0.764 | c=0.500000
[Epoch 0193] loss=10.4221 cls=0.5911 smmd=0.1407 ct=7.0818 rec=1.2018 | train/val/test=0.800/0.737/0.760 | c=0.500000
[Epoch 0194] loss=10.4253 cls=0.5924 smmd=0.1406 ct=7.0877 rec=1.2016 | train/val/test=0.802/0.740/0.763 | c=0.500000
[Epoch 0195] loss=10.4319 cls=0.5920 smmd=0.1440 ct=7.0867 rec=1.2017 | train/val/test=0.803/0.738/0.761 | c=0.500000
[Epoch 0196] loss=10.4351 cls=0.5912 smmd=0.1469 ct=7.0815 rec=1.2019 | train/val/test=0.801/0.737/0.761 | c=0.500000
[Epoch 0197] loss=10.4344 cls=0.5923 smmd=0.1469 ct=7.0812 rec=1.2016 | train/val/test=0.800/0.738/0.763 | c=0.500000
[Epoch 0198] loss=10.4230 cls=0.5923 smmd=0.1409 ct=7.0844 rec=1.2013 | train/val/test=0.802/0.740/0.763 | c=0.500000
[Epoch 0199] loss=10.4316 cls=0.5914 smmd=0.1447 ct=7.0872 rec=1.2015 | train/val/test=0.801/0.738/0.761 | c=0.500000
=== Best @ epoch 41: val=0.7474, test=0.7477 ===
