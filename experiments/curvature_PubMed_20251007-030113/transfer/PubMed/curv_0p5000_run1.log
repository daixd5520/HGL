Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=57.8083 cls=1.0787 smmd=4.2062 ct=7.2502 rec=1.4139 | train/val/test=0.431/0.427/0.433 | c=0.500000
[Epoch 0001] loss=33.8956 cls=1.0528 smmd=1.8267 ct=7.1970 rec=1.4162 | train/val/test=0.401/0.399/0.396 | c=0.500000
[Epoch 0002] loss=22.4513 cls=1.0524 smmd=0.6962 ct=7.1282 rec=1.4142 | train/val/test=0.415/0.410/0.409 | c=0.500000
[Epoch 0003] loss=26.4174 cls=1.0385 smmd=1.0922 ct=7.1346 rec=1.4136 | train/val/test=0.562/0.557/0.551 | c=0.500000
[Epoch 0004] loss=26.0601 cls=0.9992 smmd=1.0617 ct=7.1180 rec=1.4142 | train/val/test=0.561/0.548/0.553 | c=0.500000
[Epoch 0005] loss=24.5588 cls=0.9633 smmd=0.7830 ct=7.7698 rec=1.4159 | train/val/test=0.554/0.542/0.550 | c=0.500000
[Epoch 0006] loss=21.3765 cls=0.9478 smmd=0.5225 ct=7.4839 rec=1.4188 | train/val/test=0.552/0.538/0.545 | c=0.500000
[Epoch 0007] loss=21.8047 cls=0.9288 smmd=0.5882 ct=7.3748 rec=1.4176 | train/val/test=0.549/0.536/0.545 | c=0.500000
[Epoch 0008] loss=23.4651 cls=0.8829 smmd=0.7516 ct=7.4011 rec=1.4110 | train/val/test=0.578/0.568/0.574 | c=0.500000
[Epoch 0009] loss=23.4048 cls=0.8277 smmd=0.7401 ct=7.4447 rec=1.4008 | train/val/test=0.647/0.644/0.647 | c=0.500000
[Epoch 0010] loss=21.7475 cls=0.7813 smmd=0.5767 ct=7.4477 rec=1.3891 | train/val/test=0.677/0.674/0.672 | c=0.500000
[Epoch 0011] loss=20.0135 cls=0.7470 smmd=0.4098 ct=7.4267 rec=1.3775 | train/val/test=0.682/0.686/0.684 | c=0.500000
[Epoch 0012] loss=19.7066 cls=0.7233 smmd=0.3793 ct=7.4343 rec=1.3667 | train/val/test=0.684/0.692/0.688 | c=0.500000
[Epoch 0013] loss=20.3289 cls=0.7072 smmd=0.4360 ct=7.4680 rec=1.3577 | train/val/test=0.690/0.699/0.695 | c=0.500000
[Epoch 0014] loss=20.5225 cls=0.6928 smmd=0.4529 ct=7.4860 rec=1.3509 | train/val/test=0.702/0.710/0.705 | c=0.500000
[Epoch 0015] loss=20.0614 cls=0.6768 smmd=0.4104 ct=7.4728 rec=1.3461 | train/val/test=0.717/0.724/0.720 | c=0.500000
[Epoch 0016] loss=19.5420 cls=0.6604 smmd=0.3657 ct=7.4415 rec=1.3427 | train/val/test=0.730/0.738/0.734 | c=0.500000
[Epoch 0017] loss=19.3912 cls=0.6434 smmd=0.3578 ct=7.4109 rec=1.3398 | train/val/test=0.742/0.749/0.748 | c=0.500000
[Epoch 0018] loss=19.4121 cls=0.6253 smmd=0.3640 ct=7.3957 rec=1.3367 | train/val/test=0.760/0.764/0.769 | c=0.500000
[Epoch 0019] loss=19.4531 cls=0.6089 smmd=0.3683 ct=7.3995 rec=1.3339 | train/val/test=0.774/0.780/0.782 | c=0.500000
[Epoch 0020] loss=19.4159 cls=0.5945 smmd=0.3631 ct=7.4111 rec=1.3313 | train/val/test=0.785/0.789/0.791 | c=0.500000
[Epoch 0021] loss=19.1227 cls=0.5780 smmd=0.3342 ct=7.4139 rec=1.3281 | train/val/test=0.792/0.796/0.799 | c=0.500000
[Epoch 0022] loss=18.7421 cls=0.5587 smmd=0.2985 ct=7.4078 rec=1.3245 | train/val/test=0.793/0.795/0.800 | c=0.500000
[Epoch 0023] loss=18.5777 cls=0.5427 smmd=0.2849 ct=7.3981 rec=1.3217 | train/val/test=0.796/0.799/0.802 | c=0.500000
[Epoch 0024] loss=18.5517 cls=0.5304 smmd=0.2848 ct=7.3893 rec=1.3197 | train/val/test=0.804/0.806/0.809 | c=0.500000
[Epoch 0025] loss=18.4864 cls=0.5169 smmd=0.2798 ct=7.3859 rec=1.3172 | train/val/test=0.813/0.809/0.815 | c=0.500000
[Epoch 0026] loss=18.3450 cls=0.5038 smmd=0.2665 ct=7.3853 rec=1.3153 | train/val/test=0.819/0.817/0.819 | c=0.500000
[Epoch 0027] loss=18.2300 cls=0.4940 smmd=0.2556 ct=7.3846 rec=1.3148 | train/val/test=0.821/0.817/0.817 | c=0.500000
[Epoch 0028] loss=18.1722 cls=0.4862 smmd=0.2505 ct=7.3831 rec=1.3152 | train/val/test=0.822/0.819/0.822 | c=0.500000
[Epoch 0029] loss=18.1537 cls=0.4805 smmd=0.2510 ct=7.3726 rec=1.3155 | train/val/test=0.822/0.820/0.822 | c=0.500000
[Epoch 0030] loss=18.1648 cls=0.4771 smmd=0.2554 ct=7.3574 rec=1.3151 | train/val/test=0.822/0.823/0.823 | c=0.500000
[Epoch 0031] loss=18.1620 cls=0.4751 smmd=0.2570 ct=7.3488 rec=1.3141 | train/val/test=0.824/0.823/0.821 | c=0.500000
[Epoch 0032] loss=18.1238 cls=0.4735 smmd=0.2527 ct=7.3520 rec=1.3132 | train/val/test=0.824/0.823/0.824 | c=0.500000
[Epoch 0033] loss=18.0905 cls=0.4715 smmd=0.2478 ct=7.3601 rec=1.3132 | train/val/test=0.823/0.824/0.827 | c=0.500000
[Epoch 0034] loss=18.0877 cls=0.4698 smmd=0.2466 ct=7.3652 rec=1.3138 | train/val/test=0.824/0.826/0.825 | c=0.500000
[Epoch 0035] loss=18.0953 cls=0.4688 smmd=0.2474 ct=7.3649 rec=1.3141 | train/val/test=0.822/0.826/0.822 | c=0.500000
[Epoch 0036] loss=18.0794 cls=0.4686 smmd=0.2468 ct=7.3600 rec=1.3138 | train/val/test=0.821/0.825/0.822 | c=0.500000
[Epoch 0037] loss=18.0133 cls=0.4681 smmd=0.2419 ct=7.3517 rec=1.3130 | train/val/test=0.822/0.826/0.826 | c=0.500000
[Epoch 0038] loss=17.9389 cls=0.4670 smmd=0.2361 ct=7.3441 rec=1.3119 | train/val/test=0.823/0.826/0.825 | c=0.500000
[Epoch 0039] loss=17.9157 cls=0.4664 smmd=0.2350 ct=7.3386 rec=1.3111 | train/val/test=0.824/0.829/0.826 | c=0.500000
[Epoch 0040] loss=17.9016 cls=0.4666 smmd=0.2345 ct=7.3340 rec=1.3106 | train/val/test=0.825/0.829/0.826 | c=0.500000
[Epoch 0041] loss=17.8442 cls=0.4677 smmd=0.2290 ct=7.3324 rec=1.3106 | train/val/test=0.825/0.828/0.827 | c=0.500000
[Epoch 0042] loss=17.8060 cls=0.4682 smmd=0.2250 ct=7.3332 rec=1.3111 | train/val/test=0.824/0.827/0.826 | c=0.500000
[Epoch 0043] loss=17.7985 cls=0.4688 smmd=0.2243 ct=7.3326 rec=1.3118 | train/val/test=0.822/0.827/0.824 | c=0.500000
[Epoch 0044] loss=17.8027 cls=0.4712 smmd=0.2248 ct=7.3314 rec=1.3132 | train/val/test=0.823/0.827/0.826 | c=0.500000
[Epoch 0045] loss=17.7897 cls=0.4716 smmd=0.2237 ct=7.3299 rec=1.3146 | train/val/test=0.825/0.828/0.827 | c=0.500000
[Epoch 0046] loss=17.8041 cls=0.4722 smmd=0.2258 ct=7.3261 rec=1.3157 | train/val/test=0.826/0.828/0.827 | c=0.500000
[Epoch 0047] loss=17.8060 cls=0.4742 smmd=0.2268 ct=7.3211 rec=1.3166 | train/val/test=0.827/0.828/0.827 | c=0.500000
[Epoch 0048] loss=17.7894 cls=0.4753 smmd=0.2255 ct=7.3190 rec=1.3176 | train/val/test=0.826/0.829/0.828 | c=0.500000
[Epoch 0049] loss=17.7879 cls=0.4754 smmd=0.2255 ct=7.3181 rec=1.3187 | train/val/test=0.825/0.828/0.828 | c=0.500000
[Epoch 0050] loss=17.7917 cls=0.4757 smmd=0.2259 ct=7.3178 rec=1.3191 | train/val/test=0.825/0.828/0.828 | c=0.500000
[Epoch 0051] loss=17.7555 cls=0.4763 smmd=0.2226 ct=7.3157 rec=1.3189 | train/val/test=0.825/0.827/0.827 | c=0.500000
[Epoch 0052] loss=17.7236 cls=0.4762 smmd=0.2203 ct=7.3116 rec=1.3188 | train/val/test=0.825/0.828/0.827 | c=0.500000
[Epoch 0053] loss=17.7139 cls=0.4751 smmd=0.2199 ct=7.3092 rec=1.3185 | train/val/test=0.826/0.828/0.827 | c=0.500000
[Epoch 0054] loss=17.6981 cls=0.4747 smmd=0.2185 ct=7.3085 rec=1.3180 | train/val/test=0.826/0.827/0.826 | c=0.500000
[Epoch 0055] loss=17.6718 cls=0.4744 smmd=0.2165 ct=7.3057 rec=1.3175 | train/val/test=0.826/0.827/0.826 | c=0.500000
[Epoch 0056] loss=17.6602 cls=0.4737 smmd=0.2156 ct=7.3042 rec=1.3173 | train/val/test=0.826/0.826/0.826 | c=0.500000
[Epoch 0057] loss=17.6784 cls=0.4734 smmd=0.2174 ct=7.3044 rec=1.3170 | train/val/test=0.826/0.826/0.826 | c=0.500000
[Epoch 0058] loss=17.6699 cls=0.4736 smmd=0.2166 ct=7.3041 rec=1.3166 | train/val/test=0.826/0.826/0.826 | c=0.500000
[Epoch 0059] loss=17.6792 cls=0.4737 smmd=0.2181 ct=7.3015 rec=1.3164 | train/val/test=0.826/0.826/0.826 | c=0.500000
[Epoch 0060] loss=17.6829 cls=0.4733 smmd=0.2190 ct=7.2991 rec=1.3164 | train/val/test=0.826/0.827/0.827 | c=0.500000
[Epoch 0061] loss=17.6777 cls=0.4729 smmd=0.2183 ct=7.3002 rec=1.3165 | train/val/test=0.826/0.826/0.826 | c=0.500000
[Epoch 0062] loss=17.6775 cls=0.4726 smmd=0.2186 ct=7.2986 rec=1.3166 | train/val/test=0.825/0.827/0.827 | c=0.500000
[Epoch 0063] loss=17.6739 cls=0.4724 smmd=0.2184 ct=7.2975 rec=1.3166 | train/val/test=0.825/0.826/0.826 | c=0.500000
[Epoch 0064] loss=17.6751 cls=0.4719 smmd=0.2186 ct=7.2974 rec=1.3164 | train/val/test=0.826/0.827/0.828 | c=0.500000
[Epoch 0065] loss=17.6722 cls=0.4711 smmd=0.2188 ct=7.2950 rec=1.3163 | train/val/test=0.825/0.828/0.827 | c=0.500000
[Epoch 0066] loss=17.6607 cls=0.4707 smmd=0.2181 ct=7.2933 rec=1.3161 | train/val/test=0.825/0.828/0.827 | c=0.500000
[Epoch 0067] loss=17.6459 cls=0.4703 smmd=0.2165 ct=7.2938 rec=1.3160 | train/val/test=0.825/0.828/0.827 | c=0.500000
[Epoch 0068] loss=17.6239 cls=0.4694 smmd=0.2147 ct=7.2919 rec=1.3161 | train/val/test=0.826/0.828/0.828 | c=0.500000
[Epoch 0069] loss=17.6347 cls=0.4689 smmd=0.2166 ct=7.2880 rec=1.3162 | train/val/test=0.825/0.828/0.827 | c=0.500000
[Epoch 0070] loss=17.6341 cls=0.4689 smmd=0.2166 ct=7.2877 rec=1.3161 | train/val/test=0.826/0.829/0.827 | c=0.500000
[Epoch 0071] loss=17.6250 cls=0.4687 smmd=0.2156 ct=7.2882 rec=1.3161 | train/val/test=0.826/0.829/0.828 | c=0.500000
[Epoch 0072] loss=17.6147 cls=0.4686 smmd=0.2149 ct=7.2864 rec=1.3163 | train/val/test=0.826/0.829/0.828 | c=0.500000
[Epoch 0073] loss=17.6187 cls=0.4687 smmd=0.2152 ct=7.2868 rec=1.3164 | train/val/test=0.825/0.829/0.828 | c=0.500000
[Epoch 0074] loss=17.6229 cls=0.4690 smmd=0.2157 ct=7.2865 rec=1.3165 | train/val/test=0.825/0.829/0.828 | c=0.500000
[Epoch 0075] loss=17.6186 cls=0.4690 smmd=0.2157 ct=7.2845 rec=1.3166 | train/val/test=0.825/0.829/0.828 | c=0.500000
[Epoch 0076] loss=17.6177 cls=0.4691 smmd=0.2155 ct=7.2847 rec=1.3167 | train/val/test=0.826/0.829/0.827 | c=0.500000
[Epoch 0077] loss=17.6218 cls=0.4694 smmd=0.2162 ct=7.2834 rec=1.3166 | train/val/test=0.826/0.829/0.828 | c=0.500000
[Epoch 0078] loss=17.6153 cls=0.4695 smmd=0.2159 ct=7.2816 rec=1.3166 | train/val/test=0.826/0.829/0.829 | c=0.500000
[Epoch 0079] loss=17.6000 cls=0.4695 smmd=0.2144 ct=7.2817 rec=1.3165 | train/val/test=0.825/0.828/0.828 | c=0.500000
[Epoch 0080] loss=17.5929 cls=0.4696 smmd=0.2137 ct=7.2813 rec=1.3165 | train/val/test=0.825/0.828/0.827 | c=0.500000
[Epoch 0081] loss=17.5892 cls=0.4696 smmd=0.2137 ct=7.2797 rec=1.3165 | train/val/test=0.826/0.829/0.828 | c=0.500000
[Epoch 0082] loss=17.6197 cls=0.4696 smmd=0.2169 ct=7.2790 rec=1.3165 | train/val/test=0.826/0.829/0.828 | c=0.500000
[Epoch 0083] loss=17.5869 cls=0.4697 smmd=0.2139 ct=7.2772 rec=1.3165 | train/val/test=0.825/0.828/0.827 | c=0.500000
[Epoch 0084] loss=17.6004 cls=0.4697 smmd=0.2152 ct=7.2777 rec=1.3166 | train/val/test=0.825/0.827/0.827 | c=0.500000
[Epoch 0085] loss=17.5817 cls=0.4700 smmd=0.2133 ct=7.2778 rec=1.3166 | train/val/test=0.826/0.829/0.829 | c=0.500000
[Epoch 0086] loss=17.5642 cls=0.4699 smmd=0.2117 ct=7.2769 rec=1.3167 | train/val/test=0.826/0.829/0.828 | c=0.500000
[Epoch 0087] loss=17.5907 cls=0.4699 smmd=0.2146 ct=7.2754 rec=1.3171 | train/val/test=0.826/0.827/0.828 | c=0.500000
[Epoch 0088] loss=17.5856 cls=0.4705 smmd=0.2140 ct=7.2758 rec=1.3170 | train/val/test=0.825/0.827/0.828 | c=0.500000
[Epoch 0089] loss=17.5986 cls=0.4705 smmd=0.2153 ct=7.2758 rec=1.3171 | train/val/test=0.826/0.829/0.828 | c=0.500000
[Epoch 0090] loss=17.5970 cls=0.4703 smmd=0.2154 ct=7.2745 rec=1.3174 | train/val/test=0.825/0.828/0.828 | c=0.500000
[Epoch 0091] loss=17.5916 cls=0.4705 smmd=0.2150 ct=7.2740 rec=1.3171 | train/val/test=0.826/0.827/0.829 | c=0.500000
[Epoch 0092] loss=17.5883 cls=0.4705 smmd=0.2147 ct=7.2737 rec=1.3169 | train/val/test=0.826/0.827/0.827 | c=0.500000
[Epoch 0093] loss=17.5787 cls=0.4704 smmd=0.2144 ct=7.2705 rec=1.3170 | train/val/test=0.826/0.828/0.829 | c=0.500000
[Epoch 0094] loss=17.5787 cls=0.4702 smmd=0.2143 ct=7.2712 rec=1.3168 | train/val/test=0.826/0.828/0.829 | c=0.500000
[Epoch 0095] loss=17.5657 cls=0.4701 smmd=0.2126 ct=7.2732 rec=1.3167 | train/val/test=0.826/0.828/0.828 | c=0.500000
[Epoch 0096] loss=17.5653 cls=0.4699 smmd=0.2128 ct=7.2722 rec=1.3168 | train/val/test=0.826/0.829/0.826 | c=0.500000
[Epoch 0097] loss=17.5582 cls=0.4701 smmd=0.2123 ct=7.2709 rec=1.3167 | train/val/test=0.826/0.828/0.828 | c=0.500000
[Epoch 0098] loss=17.5681 cls=0.4702 smmd=0.2136 ct=7.2691 rec=1.3168 | train/val/test=0.825/0.827/0.828 | c=0.500000
[Epoch 0099] loss=17.5568 cls=0.4704 smmd=0.2126 ct=7.2686 rec=1.3168 | train/val/test=0.826/0.828/0.828 | c=0.500000
=== Best @ epoch 71: val=0.8293, test=0.8281 ===
