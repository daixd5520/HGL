Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=57.1794 cls=1.0932 smmd=4.1416 ct=7.2553 rec=1.4136 | train/val/test=0.375/0.365/0.378 | c=0.100000
[Epoch 0001] loss=33.3911 cls=1.0594 smmd=1.7708 ct=7.2224 rec=1.4163 | train/val/test=0.550/0.539/0.553 | c=0.100000
[Epoch 0002] loss=22.3970 cls=1.0648 smmd=0.6890 ct=7.1340 rec=1.4141 | train/val/test=0.457/0.444/0.461 | c=0.100000
[Epoch 0003] loss=26.4559 cls=1.0674 smmd=1.0918 ct=7.1488 rec=1.4134 | train/val/test=0.424/0.413/0.427 | c=0.100000
[Epoch 0004] loss=25.6988 cls=1.0296 smmd=1.0205 ct=7.1360 rec=1.4142 | train/val/test=0.536/0.523/0.546 | c=0.100000
[Epoch 0005] loss=22.9456 cls=1.0003 smmd=0.7525 ct=7.1059 rec=1.4179 | train/val/test=0.549/0.542/0.549 | c=0.100000
[Epoch 0006] loss=20.4220 cls=0.9900 smmd=0.5079 ct=7.0689 rec=1.4211 | train/val/test=0.553/0.549/0.546 | c=0.100000
[Epoch 0007] loss=20.8072 cls=0.9689 smmd=0.5526 ct=7.0433 rec=1.4204 | train/val/test=0.559/0.549/0.550 | c=0.100000
[Epoch 0008] loss=22.0594 cls=0.9276 smmd=0.6847 ct=7.0205 rec=1.4159 | train/val/test=0.567/0.555/0.557 | c=0.100000
[Epoch 0009] loss=21.8466 cls=0.8770 smmd=0.6719 ct=6.9923 rec=1.4087 | train/val/test=0.605/0.601/0.594 | c=0.100000
[Epoch 0010] loss=20.4165 cls=0.8287 smmd=0.5354 ct=6.9741 rec=1.3997 | train/val/test=0.671/0.671/0.662 | c=0.100000
[Epoch 0011] loss=18.9111 cls=0.7862 smmd=0.3909 ct=6.9572 rec=1.3892 | train/val/test=0.688/0.687/0.678 | c=0.100000
[Epoch 0012] loss=18.6030 cls=0.7541 smmd=0.3661 ct=6.9377 rec=1.3792 | train/val/test=0.693/0.686/0.687 | c=0.100000
[Epoch 0013] loss=19.0652 cls=0.7313 smmd=0.4169 ct=6.9224 rec=1.3709 | train/val/test=0.701/0.695/0.692 | c=0.100000
[Epoch 0014] loss=19.1386 cls=0.7061 smmd=0.4285 ct=6.9093 rec=1.3628 | train/val/test=0.715/0.707/0.702 | c=0.100000
[Epoch 0015] loss=18.6814 cls=0.6790 smmd=0.3866 ct=6.8993 rec=1.3545 | train/val/test=0.730/0.721/0.715 | c=0.100000
[Epoch 0016] loss=19.6484 cls=0.6573 smmd=0.3525 ct=7.5604 rec=1.3472 | train/val/test=0.738/0.727/0.723 | c=0.100000
[Epoch 0017] loss=19.4641 cls=0.6372 smmd=0.3519 ct=7.4779 rec=1.3411 | train/val/test=0.748/0.735/0.733 | c=0.100000
[Epoch 0018] loss=19.3918 cls=0.6175 smmd=0.3587 ct=7.4142 rec=1.3354 | train/val/test=0.759/0.745/0.744 | c=0.100000
[Epoch 0019] loss=19.3515 cls=0.5985 smmd=0.3565 ct=7.4110 rec=1.3303 | train/val/test=0.771/0.759/0.759 | c=0.100000
[Epoch 0020] loss=19.3317 cls=0.5795 smmd=0.3497 ct=7.4412 rec=1.3259 | train/val/test=0.783/0.772/0.773 | c=0.100000
[Epoch 0021] loss=19.1827 cls=0.5611 smmd=0.3323 ct=7.4592 rec=1.3223 | train/val/test=0.791/0.781/0.783 | c=0.100000
[Epoch 0022] loss=18.8405 cls=0.5450 smmd=0.3000 ct=7.4546 rec=1.3185 | train/val/test=0.795/0.787/0.790 | c=0.100000
[Epoch 0023] loss=18.6226 cls=0.5312 smmd=0.2812 ct=7.4441 rec=1.3142 | train/val/test=0.798/0.793/0.794 | c=0.100000
[Epoch 0024] loss=18.5908 cls=0.5194 smmd=0.2803 ct=7.4365 rec=1.3104 | train/val/test=0.802/0.798/0.795 | c=0.100000
[Epoch 0025] loss=18.5583 cls=0.5078 smmd=0.2795 ct=7.4279 rec=1.3079 | train/val/test=0.805/0.802/0.801 | c=0.100000
[Epoch 0026] loss=18.4191 cls=0.4961 smmd=0.2685 ct=7.4161 rec=1.3067 | train/val/test=0.809/0.806/0.804 | c=0.100000
[Epoch 0027] loss=18.2925 cls=0.4847 smmd=0.2583 ct=7.4070 rec=1.3068 | train/val/test=0.813/0.808/0.812 | c=0.100000
[Epoch 0028] loss=18.2393 cls=0.4754 smmd=0.2537 ct=7.4055 rec=1.3080 | train/val/test=0.817/0.811/0.817 | c=0.100000
[Epoch 0029] loss=18.2103 cls=0.4693 smmd=0.2505 ct=7.4079 rec=1.3093 | train/val/test=0.819/0.813/0.820 | c=0.100000
[Epoch 0030] loss=18.2204 cls=0.4650 smmd=0.2511 ct=7.4110 rec=1.3092 | train/val/test=0.819/0.816/0.823 | c=0.100000
[Epoch 0031] loss=18.2220 cls=0.4629 smmd=0.2514 ct=7.4114 rec=1.3082 | train/val/test=0.820/0.815/0.824 | c=0.100000
[Epoch 0032] loss=18.1650 cls=0.4620 smmd=0.2459 ct=7.4106 rec=1.3080 | train/val/test=0.822/0.819/0.825 | c=0.100000
[Epoch 0033] loss=18.1276 cls=0.4589 smmd=0.2430 ct=7.4066 rec=1.3090 | train/val/test=0.823/0.820/0.827 | c=0.100000
[Epoch 0034] loss=18.1354 cls=0.4566 smmd=0.2455 ct=7.3982 rec=1.3106 | train/val/test=0.823/0.821/0.827 | c=0.100000
[Epoch 0035] loss=18.1439 cls=0.4554 smmd=0.2482 ct=7.3893 rec=1.3110 | train/val/test=0.823/0.822/0.827 | c=0.100000
[Epoch 0036] loss=18.1070 cls=0.4543 smmd=0.2457 ct=7.3841 rec=1.3098 | train/val/test=0.823/0.822/0.827 | c=0.100000
[Epoch 0037] loss=18.0445 cls=0.4537 smmd=0.2395 ct=7.3842 rec=1.3081 | train/val/test=0.823/0.822/0.828 | c=0.100000
[Epoch 0038] loss=18.0478 cls=0.4532 smmd=0.2392 ct=7.3878 rec=1.3068 | train/val/test=0.822/0.822/0.827 | c=0.100000
[Epoch 0039] loss=17.9879 cls=0.4527 smmd=0.2331 ct=7.3886 rec=1.3061 | train/val/test=0.822/0.822/0.826 | c=0.100000
[Epoch 0040] loss=17.9663 cls=0.4525 smmd=0.2320 ct=7.3836 rec=1.3055 | train/val/test=0.822/0.821/0.828 | c=0.100000
[Epoch 0041] loss=17.9206 cls=0.4527 smmd=0.2287 ct=7.3773 rec=1.3052 | train/val/test=0.823/0.821/0.828 | c=0.100000
[Epoch 0042] loss=17.8710 cls=0.4531 smmd=0.2244 ct=7.3738 rec=1.3051 | train/val/test=0.822/0.820/0.824 | c=0.100000
[Epoch 0043] loss=17.8813 cls=0.4539 smmd=0.2259 ct=7.3714 rec=1.3052 | train/val/test=0.822/0.821/0.825 | c=0.100000
[Epoch 0044] loss=17.8799 cls=0.4549 smmd=0.2264 ct=7.3680 rec=1.3055 | train/val/test=0.823/0.822/0.826 | c=0.100000
[Epoch 0045] loss=17.8613 cls=0.4556 smmd=0.2250 ct=7.3651 rec=1.3059 | train/val/test=0.823/0.822/0.828 | c=0.100000
[Epoch 0046] loss=17.8448 cls=0.4563 smmd=0.2235 ct=7.3641 rec=1.3067 | train/val/test=0.823/0.822/0.828 | c=0.100000
[Epoch 0047] loss=17.8438 cls=0.4569 smmd=0.2235 ct=7.3633 rec=1.3079 | train/val/test=0.823/0.822/0.828 | c=0.100000
[Epoch 0048] loss=17.8416 cls=0.4572 smmd=0.2237 ct=7.3609 rec=1.3093 | train/val/test=0.825/0.823/0.830 | c=0.100000
[Epoch 0049] loss=17.8247 cls=0.4576 smmd=0.2227 ct=7.3570 rec=1.3107 | train/val/test=0.825/0.824/0.831 | c=0.100000
[Epoch 0050] loss=17.8269 cls=0.4581 smmd=0.2233 ct=7.3547 rec=1.3115 | train/val/test=0.824/0.822/0.829 | c=0.100000
[Epoch 0051] loss=17.8139 cls=0.4590 smmd=0.2222 ct=7.3535 rec=1.3117 | train/val/test=0.825/0.822/0.829 | c=0.100000
[Epoch 0052] loss=17.7925 cls=0.4597 smmd=0.2204 ct=7.3512 rec=1.3118 | train/val/test=0.825/0.823/0.830 | c=0.100000
[Epoch 0053] loss=17.7859 cls=0.4597 smmd=0.2201 ct=7.3496 rec=1.3120 | train/val/test=0.825/0.823/0.831 | c=0.100000
[Epoch 0054] loss=17.7540 cls=0.4597 smmd=0.2176 ct=7.3459 rec=1.3122 | train/val/test=0.824/0.823/0.830 | c=0.100000
[Epoch 0055] loss=17.7488 cls=0.4597 smmd=0.2182 ct=7.3403 rec=1.3121 | train/val/test=0.824/0.823/0.830 | c=0.100000
[Epoch 0056] loss=17.7225 cls=0.4598 smmd=0.2163 ct=7.3367 rec=1.3120 | train/val/test=0.824/0.823/0.830 | c=0.100000
[Epoch 0057] loss=17.7208 cls=0.4597 smmd=0.2163 ct=7.3362 rec=1.3119 | train/val/test=0.824/0.822/0.828 | c=0.100000
[Epoch 0058] loss=17.7333 cls=0.4601 smmd=0.2172 ct=7.3378 rec=1.3117 | train/val/test=0.824/0.822/0.827 | c=0.100000
[Epoch 0059] loss=17.7112 cls=0.4604 smmd=0.2151 ct=7.3372 rec=1.3116 | train/val/test=0.824/0.822/0.829 | c=0.100000
[Epoch 0060] loss=17.7277 cls=0.4604 smmd=0.2176 ct=7.3329 rec=1.3117 | train/val/test=0.824/0.822/0.829 | c=0.100000
[Epoch 0061] loss=17.7303 cls=0.4604 smmd=0.2191 ct=7.3265 rec=1.3119 | train/val/test=0.825/0.823/0.828 | c=0.100000
[Epoch 0062] loss=17.7270 cls=0.4604 smmd=0.2192 ct=7.3245 rec=1.3121 | train/val/test=0.825/0.825/0.828 | c=0.100000
[Epoch 0063] loss=17.7219 cls=0.4601 smmd=0.2186 ct=7.3247 rec=1.3123 | train/val/test=0.825/0.824/0.829 | c=0.100000
[Epoch 0064] loss=17.7006 cls=0.4598 smmd=0.2170 ct=7.3224 rec=1.3125 | train/val/test=0.825/0.825/0.830 | c=0.100000
[Epoch 0065] loss=17.6935 cls=0.4598 smmd=0.2169 ct=7.3193 rec=1.3124 | train/val/test=0.825/0.825/0.830 | c=0.100000
[Epoch 0066] loss=17.6954 cls=0.4594 smmd=0.2173 ct=7.3179 rec=1.3128 | train/val/test=0.825/0.826/0.829 | c=0.100000
[Epoch 0067] loss=17.6748 cls=0.4591 smmd=0.2154 ct=7.3174 rec=1.3132 | train/val/test=0.825/0.824/0.831 | c=0.100000
[Epoch 0068] loss=17.6777 cls=0.4586 smmd=0.2165 ct=7.3135 rec=1.3135 | train/val/test=0.826/0.825/0.831 | c=0.100000
[Epoch 0069] loss=17.6626 cls=0.4585 smmd=0.2157 ct=7.3097 rec=1.3135 | train/val/test=0.826/0.826/0.831 | c=0.100000
[Epoch 0070] loss=17.6526 cls=0.4585 smmd=0.2152 ct=7.3076 rec=1.3135 | train/val/test=0.826/0.826/0.831 | c=0.100000
[Epoch 0071] loss=17.6540 cls=0.4580 smmd=0.2158 ct=7.3049 rec=1.3138 | train/val/test=0.825/0.825/0.831 | c=0.100000
[Epoch 0072] loss=17.6567 cls=0.4578 smmd=0.2161 ct=7.3051 rec=1.3141 | train/val/test=0.826/0.825/0.831 | c=0.100000
[Epoch 0073] loss=17.6499 cls=0.4574 smmd=0.2152 ct=7.3061 rec=1.3140 | train/val/test=0.827/0.825/0.829 | c=0.100000
[Epoch 0074] loss=17.6614 cls=0.4571 smmd=0.2166 ct=7.3051 rec=1.3139 | train/val/test=0.827/0.825/0.830 | c=0.100000
[Epoch 0075] loss=17.6455 cls=0.4570 smmd=0.2157 ct=7.3016 rec=1.3138 | train/val/test=0.827/0.825/0.831 | c=0.100000
[Epoch 0076] loss=17.6500 cls=0.4568 smmd=0.2171 ct=7.2970 rec=1.3137 | train/val/test=0.827/0.824/0.832 | c=0.100000
[Epoch 0077] loss=17.6501 cls=0.4565 smmd=0.2174 ct=7.2954 rec=1.3135 | train/val/test=0.827/0.824/0.831 | c=0.100000
[Epoch 0078] loss=17.6369 cls=0.4563 smmd=0.2156 ct=7.2981 rec=1.3133 | train/val/test=0.827/0.824/0.833 | c=0.100000
[Epoch 0079] loss=17.6158 cls=0.4561 smmd=0.2134 ct=7.2983 rec=1.3133 | train/val/test=0.827/0.824/0.832 | c=0.100000
[Epoch 0080] loss=17.6219 cls=0.4560 smmd=0.2147 ct=7.2951 rec=1.3135 | train/val/test=0.828/0.824/0.832 | c=0.100000
[Epoch 0081] loss=17.6221 cls=0.4561 smmd=0.2152 ct=7.2925 rec=1.3134 | train/val/test=0.827/0.825/0.833 | c=0.100000
[Epoch 0082] loss=17.6052 cls=0.4565 smmd=0.2139 ct=7.2907 rec=1.3134 | train/val/test=0.827/0.825/0.832 | c=0.100000
[Epoch 0083] loss=17.6139 cls=0.4568 smmd=0.2149 ct=7.2898 rec=1.3137 | train/val/test=0.827/0.825/0.833 | c=0.100000
[Epoch 0084] loss=17.6156 cls=0.4570 smmd=0.2148 ct=7.2909 rec=1.3140 | train/val/test=0.827/0.824/0.833 | c=0.100000
[Epoch 0085] loss=17.6133 cls=0.4574 smmd=0.2144 ct=7.2915 rec=1.3144 | train/val/test=0.828/0.826/0.833 | c=0.100000
[Epoch 0086] loss=17.6131 cls=0.4580 smmd=0.2152 ct=7.2875 rec=1.3146 | train/val/test=0.828/0.825/0.833 | c=0.100000
[Epoch 0087] loss=17.6079 cls=0.4583 smmd=0.2151 ct=7.2854 rec=1.3149 | train/val/test=0.828/0.824/0.833 | c=0.100000
[Epoch 0088] loss=17.6178 cls=0.4584 smmd=0.2159 ct=7.2860 rec=1.3152 | train/val/test=0.828/0.824/0.834 | c=0.100000
[Epoch 0089] loss=17.6155 cls=0.4587 smmd=0.2157 ct=7.2860 rec=1.3153 | train/val/test=0.828/0.824/0.833 | c=0.100000
[Epoch 0090] loss=17.6177 cls=0.4590 smmd=0.2161 ct=7.2848 rec=1.3152 | train/val/test=0.827/0.823/0.831 | c=0.100000
[Epoch 0091] loss=17.5814 cls=0.4591 smmd=0.2128 ct=7.2831 rec=1.3152 | train/val/test=0.828/0.823/0.833 | c=0.100000
[Epoch 0092] loss=17.5804 cls=0.4591 smmd=0.2132 ct=7.2804 rec=1.3153 | train/val/test=0.828/0.824/0.832 | c=0.100000
[Epoch 0093] loss=17.5932 cls=0.4593 smmd=0.2146 ct=7.2800 rec=1.3152 | train/val/test=0.827/0.823/0.832 | c=0.100000
[Epoch 0094] loss=17.6041 cls=0.4598 smmd=0.2153 ct=7.2817 rec=1.3151 | train/val/test=0.827/0.823/0.831 | c=0.100000
[Epoch 0095] loss=17.5805 cls=0.4598 smmd=0.2130 ct=7.2817 rec=1.3154 | train/val/test=0.828/0.823/0.831 | c=0.100000
[Epoch 0096] loss=17.5720 cls=0.4598 smmd=0.2124 ct=7.2800 rec=1.3156 | train/val/test=0.828/0.823/0.831 | c=0.100000
[Epoch 0097] loss=17.5814 cls=0.4606 smmd=0.2136 ct=7.2784 rec=1.3155 | train/val/test=0.828/0.823/0.832 | c=0.100000
[Epoch 0098] loss=17.5839 cls=0.4608 smmd=0.2145 ct=7.2754 rec=1.3157 | train/val/test=0.828/0.823/0.831 | c=0.100000
[Epoch 0099] loss=17.5755 cls=0.4608 smmd=0.2137 ct=7.2750 rec=1.3162 | train/val/test=0.827/0.823/0.830 | c=0.100000
=== Best @ epoch 66: val=0.8255, test=0.8294 ===
