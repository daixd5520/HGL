Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=57.6142 cls=1.1069 smmd=4.1856 ct=7.2490 rec=1.4136 | train/val/test=0.463/0.454/0.452 | c=0.998905
[Epoch 0001] loss=33.8228 cls=1.0646 smmd=1.8202 ct=7.1907 rec=1.4151 | train/val/test=0.530/0.524/0.524 | c=0.998905
[Epoch 0002] loss=22.5245 cls=1.0729 smmd=0.7049 ct=7.1161 rec=1.4139 | train/val/test=0.575/0.560/0.563 | c=0.998905
[Epoch 0003] loss=26.5035 cls=1.0680 smmd=1.1051 ct=7.1057 rec=1.4135 | train/val/test=0.559/0.552/0.553 | c=0.998905
[Epoch 0004] loss=25.9484 cls=1.0319 smmd=1.0571 ct=7.0772 rec=1.4142 | train/val/test=0.553/0.548/0.546 | c=0.998905
[Epoch 0005] loss=23.1303 cls=0.9989 smmd=0.7857 ct=7.0329 rec=1.4161 | train/val/test=0.543/0.534/0.535 | c=0.998905
[Epoch 0006] loss=20.0820 cls=0.9778 smmd=0.4911 ct=6.9867 rec=1.4169 | train/val/test=0.542/0.534/0.531 | c=0.998905
[Epoch 0007] loss=20.5484 cls=0.9554 smmd=0.5412 ct=6.9754 rec=1.4148 | train/val/test=0.540/0.530/0.536 | c=0.998905
[Epoch 0008] loss=22.2976 cls=0.9198 smmd=0.7210 ct=6.9615 rec=1.4095 | train/val/test=0.546/0.534/0.535 | c=0.998905
[Epoch 0009] loss=22.1060 cls=0.8778 smmd=0.7101 ct=6.9326 rec=1.4020 | train/val/test=0.558/0.550/0.549 | c=0.998905
[Epoch 0010] loss=20.2388 cls=0.8373 smmd=0.5320 ct=6.9016 rec=1.3935 | train/val/test=0.617/0.606/0.606 | c=0.998905
[Epoch 0011] loss=18.5681 cls=0.8000 smmd=0.3718 ct=6.8789 rec=1.3845 | train/val/test=0.659/0.657/0.655 | c=0.998905
[Epoch 0012] loss=18.5698 cls=0.7689 smmd=0.3748 ct=6.8746 rec=1.3762 | train/val/test=0.678/0.675/0.679 | c=0.998905
[Epoch 0013] loss=19.2723 cls=0.7426 smmd=0.4456 ct=6.8802 rec=1.3682 | train/val/test=0.689/0.685/0.686 | c=0.998905
[Epoch 0014] loss=19.2058 cls=0.7197 smmd=0.4414 ct=6.8759 rec=1.3602 | train/val/test=0.695/0.694/0.695 | c=0.998905
[Epoch 0015] loss=18.5038 cls=0.7022 smmd=0.3744 ct=6.8658 rec=1.3531 | train/val/test=0.703/0.704/0.706 | c=0.998905
[Epoch 0016] loss=18.1801 cls=0.6867 smmd=0.3439 ct=6.8623 rec=1.3471 | train/val/test=0.710/0.714/0.713 | c=0.998905
[Epoch 0017] loss=18.2640 cls=0.6677 smmd=0.3541 ct=6.8592 rec=1.3421 | train/val/test=0.721/0.727/0.723 | c=0.998905
[Epoch 0018] loss=18.2303 cls=0.6445 smmd=0.3540 ct=6.8496 rec=1.3381 | train/val/test=0.733/0.740/0.736 | c=0.998905
[Epoch 0019] loss=18.1176 cls=0.6220 smmd=0.3461 ct=6.8393 rec=1.3348 | train/val/test=0.748/0.756/0.751 | c=0.998905
[Epoch 0020] loss=18.0355 cls=0.6028 smmd=0.3403 ct=6.8326 rec=1.3311 | train/val/test=0.759/0.765/0.759 | c=0.998905
[Epoch 0021] loss=17.8029 cls=0.5896 smmd=0.3191 ct=6.8270 rec=1.3266 | train/val/test=0.772/0.774/0.768 | c=0.998905
[Epoch 0022] loss=17.5003 cls=0.5820 smmd=0.2906 ct=6.8214 rec=1.3220 | train/val/test=0.777/0.784/0.775 | c=0.998905
[Epoch 0023] loss=17.3587 cls=0.5720 smmd=0.2783 ct=6.8155 rec=1.3178 | train/val/test=0.783/0.790/0.784 | c=0.998905
[Epoch 0024] loss=17.3040 cls=0.5546 smmd=0.2748 ct=6.8108 rec=1.3146 | train/val/test=0.791/0.795/0.792 | c=0.998905
[Epoch 0025] loss=17.2289 cls=0.5325 smmd=0.2691 ct=6.8074 rec=1.3132 | train/val/test=0.803/0.805/0.797 | c=0.998905
[Epoch 0026] loss=17.0569 cls=0.5132 smmd=0.2538 ct=6.8028 rec=1.3131 | train/val/test=0.807/0.814/0.805 | c=0.998905
[Epoch 0027] loss=16.9854 cls=0.5018 smmd=0.2483 ct=6.7975 rec=1.3136 | train/val/test=0.812/0.816/0.809 | c=0.998905
[Epoch 0028] loss=16.9881 cls=0.4950 smmd=0.2497 ct=6.7938 rec=1.3127 | train/val/test=0.813/0.815/0.813 | c=0.998905
[Epoch 0029] loss=16.9543 cls=0.4899 smmd=0.2470 ct=6.7919 rec=1.3111 | train/val/test=0.815/0.814/0.816 | c=0.998905
[Epoch 0030] loss=16.9020 cls=0.4859 smmd=0.2422 ct=6.7911 rec=1.3105 | train/val/test=0.816/0.814/0.815 | c=0.998905
[Epoch 0031] loss=16.9159 cls=0.4815 smmd=0.2439 ct=6.7904 rec=1.3109 | train/val/test=0.817/0.814/0.818 | c=0.998905
[Epoch 0032] loss=16.9256 cls=0.4778 smmd=0.2452 ct=6.7893 rec=1.3116 | train/val/test=0.817/0.815/0.818 | c=0.998905
[Epoch 0033] loss=16.9126 cls=0.4752 smmd=0.2444 ct=6.7876 rec=1.3125 | train/val/test=0.820/0.816/0.816 | c=0.998905
[Epoch 0034] loss=16.8888 cls=0.4725 smmd=0.2426 ct=6.7848 rec=1.3135 | train/val/test=0.822/0.819/0.818 | c=0.998905
[Epoch 0035] loss=16.8718 cls=0.4701 smmd=0.2416 ct=6.7819 rec=1.3139 | train/val/test=0.824/0.822/0.821 | c=0.998905
[Epoch 0036] loss=16.8399 cls=0.4677 smmd=0.2388 ct=6.7809 rec=1.3129 | train/val/test=0.825/0.821/0.824 | c=0.998905
[Epoch 0037] loss=16.8095 cls=0.4657 smmd=0.2360 ct=6.7806 rec=1.3109 | train/val/test=0.825/0.821/0.825 | c=0.998905
[Epoch 0038] loss=16.7668 cls=0.4643 smmd=0.2324 ct=6.7782 rec=1.3092 | train/val/test=0.824/0.821/0.824 | c=0.998905
[Epoch 0039] loss=16.7105 cls=0.4628 smmd=0.2275 ct=6.7749 rec=1.3083 | train/val/test=0.824/0.819/0.824 | c=0.998905
[Epoch 0040] loss=16.6588 cls=0.4617 smmd=0.2229 ct=6.7726 rec=1.3079 | train/val/test=0.824/0.820/0.824 | c=0.998905
[Epoch 0041] loss=16.6599 cls=0.4610 smmd=0.2233 ct=6.7712 rec=1.3076 | train/val/test=0.823/0.822/0.825 | c=0.998905
[Epoch 0042] loss=16.6508 cls=0.4610 smmd=0.2226 ct=6.7702 rec=1.3072 | train/val/test=0.824/0.821/0.825 | c=0.998905
[Epoch 0043] loss=16.6117 cls=0.4616 smmd=0.2190 ct=6.7686 rec=1.3069 | train/val/test=0.824/0.822/0.825 | c=0.998905
[Epoch 0044] loss=16.6093 cls=0.4622 smmd=0.2193 ct=6.7657 rec=1.3072 | train/val/test=0.824/0.822/0.825 | c=0.998905
[Epoch 0045] loss=16.6158 cls=0.4625 smmd=0.2203 ct=6.7637 rec=1.3079 | train/val/test=0.823/0.822/0.826 | c=0.998905
[Epoch 0046] loss=16.6171 cls=0.4629 smmd=0.2205 ct=6.7632 rec=1.3086 | train/val/test=0.823/0.823/0.825 | c=0.998905
[Epoch 0047] loss=16.6265 cls=0.4639 smmd=0.2213 ct=6.7637 rec=1.3091 | train/val/test=0.823/0.822/0.825 | c=0.998905
[Epoch 0048] loss=16.6053 cls=0.4646 smmd=0.2190 ct=6.7639 rec=1.3096 | train/val/test=0.823/0.821/0.825 | c=0.998905
[Epoch 0049] loss=16.6209 cls=0.4649 smmd=0.2207 ct=6.7633 rec=1.3102 | train/val/test=0.824/0.822/0.827 | c=0.998905
[Epoch 0050] loss=16.5856 cls=0.4650 smmd=0.2175 ct=6.7614 rec=1.3106 | train/val/test=0.825/0.824/0.829 | c=0.998905
[Epoch 0051] loss=16.5648 cls=0.4654 smmd=0.2158 ct=6.7592 rec=1.3106 | train/val/test=0.824/0.822/0.828 | c=0.998905
[Epoch 0052] loss=16.5507 cls=0.4651 smmd=0.2149 ct=6.7570 rec=1.3109 | train/val/test=0.825/0.822/0.827 | c=0.998905
[Epoch 0053] loss=16.5299 cls=0.4648 smmd=0.2132 ct=6.7548 rec=1.3112 | train/val/test=0.825/0.823/0.827 | c=0.998905
[Epoch 0054] loss=16.5257 cls=0.4648 smmd=0.2130 ct=6.7539 rec=1.3111 | train/val/test=0.825/0.823/0.827 | c=0.998905
[Epoch 0055] loss=16.5125 cls=0.4649 smmd=0.2115 ct=6.7548 rec=1.3110 | train/val/test=0.825/0.823/0.827 | c=0.998905
[Epoch 0056] loss=16.5240 cls=0.4652 smmd=0.2126 ct=6.7550 rec=1.3107 | train/val/test=0.825/0.823/0.828 | c=0.998905
[Epoch 0057] loss=16.5028 cls=0.4655 smmd=0.2107 ct=6.7541 rec=1.3103 | train/val/test=0.825/0.822/0.827 | c=0.998905
[Epoch 0058] loss=16.5203 cls=0.4655 smmd=0.2126 ct=6.7530 rec=1.3101 | train/val/test=0.825/0.823/0.827 | c=0.998905
[Epoch 0059] loss=16.5144 cls=0.4652 smmd=0.2123 ct=6.7518 rec=1.3102 | train/val/test=0.825/0.823/0.827 | c=0.998905
[Epoch 0060] loss=16.5171 cls=0.4652 smmd=0.2127 ct=6.7513 rec=1.3100 | train/val/test=0.825/0.822/0.826 | c=0.998905
[Epoch 0061] loss=16.5326 cls=0.4653 smmd=0.2143 ct=6.7512 rec=1.3096 | train/val/test=0.825/0.821/0.827 | c=0.998905
[Epoch 0062] loss=16.5169 cls=0.4651 smmd=0.2129 ct=6.7503 rec=1.3094 | train/val/test=0.826/0.822/0.827 | c=0.998905
[Epoch 0063] loss=16.5184 cls=0.4647 smmd=0.2130 ct=6.7505 rec=1.3092 | train/val/test=0.826/0.821/0.827 | c=0.998905
[Epoch 0064] loss=16.5169 cls=0.4643 smmd=0.2130 ct=6.7503 rec=1.3090 | train/val/test=0.825/0.821/0.824 | c=0.998905
[Epoch 0065] loss=16.5137 cls=0.4638 smmd=0.2130 ct=6.7487 rec=1.3088 | train/val/test=0.826/0.821/0.827 | c=0.998905
[Epoch 0066] loss=16.5032 cls=0.4632 smmd=0.2121 ct=6.7479 rec=1.3086 | train/val/test=0.826/0.822/0.827 | c=0.998905
[Epoch 0067] loss=16.4951 cls=0.4628 smmd=0.2114 ct=6.7478 rec=1.3085 | train/val/test=0.826/0.822/0.828 | c=0.998905
[Epoch 0068] loss=16.4913 cls=0.4624 smmd=0.2111 ct=6.7477 rec=1.3084 | train/val/test=0.826/0.821/0.828 | c=0.998905
[Epoch 0069] loss=16.4890 cls=0.4618 smmd=0.2110 ct=6.7469 rec=1.3085 | train/val/test=0.826/0.822/0.827 | c=0.998905
[Epoch 0070] loss=16.4887 cls=0.4612 smmd=0.2113 ct=6.7454 rec=1.3087 | train/val/test=0.826/0.822/0.826 | c=0.998905
[Epoch 0071] loss=16.4849 cls=0.4607 smmd=0.2110 ct=6.7451 rec=1.3090 | train/val/test=0.826/0.821/0.826 | c=0.998905
[Epoch 0072] loss=16.4862 cls=0.4605 smmd=0.2111 ct=6.7454 rec=1.3090 | train/val/test=0.826/0.821/0.826 | c=0.998905
[Epoch 0073] loss=16.4786 cls=0.4605 smmd=0.2105 ct=6.7442 rec=1.3089 | train/val/test=0.826/0.822/0.827 | c=0.998905
[Epoch 0074] loss=16.4883 cls=0.4604 smmd=0.2116 ct=6.7439 rec=1.3089 | train/val/test=0.827/0.822/0.827 | c=0.998905
[Epoch 0075] loss=16.4822 cls=0.4602 smmd=0.2108 ct=6.7447 rec=1.3089 | train/val/test=0.827/0.822/0.827 | c=0.998905
[Epoch 0076] loss=16.4864 cls=0.4600 smmd=0.2114 ct=6.7440 rec=1.3089 | train/val/test=0.827/0.822/0.828 | c=0.998905
[Epoch 0077] loss=16.4744 cls=0.4598 smmd=0.2105 ct=6.7425 rec=1.3090 | train/val/test=0.827/0.822/0.827 | c=0.998905
[Epoch 0078] loss=16.4973 cls=0.4596 smmd=0.2128 ct=6.7424 rec=1.3088 | train/val/test=0.827/0.822/0.827 | c=0.998905
[Epoch 0079] loss=16.4807 cls=0.4595 smmd=0.2112 ct=6.7425 rec=1.3085 | train/val/test=0.826/0.822/0.827 | c=0.998905
[Epoch 0080] loss=16.4709 cls=0.4593 smmd=0.2104 ct=6.7414 rec=1.3084 | train/val/test=0.826/0.821/0.828 | c=0.998905
[Epoch 0081] loss=16.4568 cls=0.4593 smmd=0.2092 ct=6.7406 rec=1.3082 | train/val/test=0.827/0.821/0.829 | c=0.998905
[Epoch 0082] loss=16.4542 cls=0.4595 smmd=0.2087 ct=6.7417 rec=1.3079 | train/val/test=0.826/0.821/0.828 | c=0.998905
[Epoch 0083] loss=16.4634 cls=0.4593 smmd=0.2096 ct=6.7416 rec=1.3082 | train/val/test=0.827/0.821/0.828 | c=0.998905
[Epoch 0084] loss=16.4617 cls=0.4593 smmd=0.2097 ct=6.7404 rec=1.3084 | train/val/test=0.827/0.822/0.828 | c=0.998905
[Epoch 0085] loss=16.4638 cls=0.4597 smmd=0.2100 ct=6.7401 rec=1.3083 | train/val/test=0.827/0.822/0.829 | c=0.998905
[Epoch 0086] loss=16.4739 cls=0.4597 smmd=0.2110 ct=6.7398 rec=1.3086 | train/val/test=0.826/0.822/0.828 | c=0.998905
[Epoch 0087] loss=16.4651 cls=0.4596 smmd=0.2102 ct=6.7393 rec=1.3089 | train/val/test=0.826/0.822/0.828 | c=0.998905
[Epoch 0088] loss=16.4578 cls=0.4596 smmd=0.2095 ct=6.7393 rec=1.3090 | train/val/test=0.826/0.822/0.828 | c=0.998905
[Epoch 0089] loss=16.4640 cls=0.4598 smmd=0.2100 ct=6.7398 rec=1.3089 | train/val/test=0.826/0.821/0.827 | c=0.998905
[Epoch 0090] loss=16.4667 cls=0.4599 smmd=0.2103 ct=6.7398 rec=1.3088 | train/val/test=0.826/0.822/0.830 | c=0.998905
[Epoch 0091] loss=16.4637 cls=0.4598 smmd=0.2102 ct=6.7385 rec=1.3089 | train/val/test=0.827/0.822/0.829 | c=0.998905
[Epoch 0092] loss=16.4514 cls=0.4596 smmd=0.2091 ct=6.7378 rec=1.3089 | train/val/test=0.827/0.823/0.828 | c=0.998905
[Epoch 0093] loss=16.4519 cls=0.4595 smmd=0.2092 ct=6.7380 rec=1.3088 | train/val/test=0.827/0.822/0.829 | c=0.998905
[Epoch 0094] loss=16.4562 cls=0.4595 smmd=0.2097 ct=6.7376 rec=1.3087 | train/val/test=0.827/0.821/0.829 | c=0.998905
[Epoch 0095] loss=16.4534 cls=0.4596 smmd=0.2096 ct=6.7369 rec=1.3085 | train/val/test=0.826/0.822/0.827 | c=0.998905
[Epoch 0096] loss=16.4328 cls=0.4598 smmd=0.2074 ct=6.7373 rec=1.3083 | train/val/test=0.827/0.822/0.829 | c=0.998905
[Epoch 0097] loss=16.4405 cls=0.4597 smmd=0.2082 ct=6.7374 rec=1.3084 | train/val/test=0.827/0.823/0.830 | c=0.998905
[Epoch 0098] loss=16.4536 cls=0.4596 smmd=0.2096 ct=6.7365 rec=1.3088 | train/val/test=0.827/0.822/0.829 | c=0.998905
[Epoch 0099] loss=16.4327 cls=0.4597 smmd=0.2076 ct=6.7365 rec=1.3088 | train/val/test=0.826/0.822/0.826 | c=0.998905
=== Best @ epoch 50: val=0.8237, test=0.8286 ===
