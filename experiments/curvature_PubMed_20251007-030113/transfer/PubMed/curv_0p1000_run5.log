Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=57.4767 cls=1.1017 smmd=4.1718 ct=7.2507 rec=1.4136 | train/val/test=0.393/0.400/0.384 | c=0.100000
[Epoch 0001] loss=33.5967 cls=1.0626 smmd=1.7971 ct=7.1934 rec=1.4153 | train/val/test=0.546/0.536/0.539 | c=0.100000
[Epoch 0002] loss=22.9121 cls=1.0730 smmd=0.7374 ct=7.1474 rec=1.4136 | train/val/test=0.678/0.677/0.677 | c=0.100000
[Epoch 0003] loss=26.3601 cls=1.0698 smmd=1.0789 ct=7.1647 rec=1.4133 | train/val/test=0.551/0.540/0.547 | c=0.100000
[Epoch 0004] loss=25.8596 cls=1.0255 smmd=1.0339 ct=7.1504 rec=1.4139 | train/val/test=0.536/0.529/0.539 | c=0.100000
[Epoch 0005] loss=23.3452 cls=0.9936 smmd=0.7935 ct=7.1025 rec=1.4170 | train/val/test=0.542/0.531/0.540 | c=0.100000
[Epoch 0006] loss=20.5563 cls=0.9784 smmd=0.5286 ct=7.0357 rec=1.4188 | train/val/test=0.549/0.535/0.548 | c=0.100000
[Epoch 0007] loss=20.6876 cls=0.9528 smmd=0.5496 ct=7.0037 rec=1.4164 | train/val/test=0.551/0.537/0.549 | c=0.100000
[Epoch 0008] loss=22.0577 cls=0.9120 smmd=0.6928 ct=6.9845 rec=1.4103 | train/val/test=0.554/0.542/0.550 | c=0.100000
[Epoch 0009] loss=21.8920 cls=0.8682 smmd=0.6845 ct=6.9560 rec=1.4025 | train/val/test=0.585/0.573/0.578 | c=0.100000
[Epoch 0010] loss=20.3878 cls=0.8276 smmd=0.5406 ct=6.9354 rec=1.3941 | train/val/test=0.636/0.623/0.630 | c=0.100000
[Epoch 0011] loss=18.9999 cls=0.7912 smmd=0.4054 ct=6.9289 rec=1.3854 | train/val/test=0.670/0.659/0.667 | c=0.100000
[Epoch 0012] loss=18.7386 cls=0.7582 smmd=0.3819 ct=6.9259 rec=1.3765 | train/val/test=0.691/0.685/0.692 | c=0.100000
[Epoch 0013] loss=20.1041 cls=0.7288 smmd=0.4155 ct=7.4502 rec=1.3675 | train/val/test=0.705/0.698/0.707 | c=0.100000
[Epoch 0014] loss=20.0416 cls=0.7046 smmd=0.4277 ct=7.3665 rec=1.3590 | train/val/test=0.714/0.712/0.715 | c=0.100000
[Epoch 0015] loss=19.7364 cls=0.6861 smmd=0.4100 ct=7.3090 rec=1.3514 | train/val/test=0.721/0.722/0.724 | c=0.100000
[Epoch 0016] loss=19.4612 cls=0.6727 smmd=0.3826 ct=7.3132 rec=1.3453 | train/val/test=0.730/0.728/0.730 | c=0.100000
[Epoch 0017] loss=19.3963 cls=0.6595 smmd=0.3712 ct=7.3423 rec=1.3408 | train/val/test=0.742/0.742/0.745 | c=0.100000
[Epoch 0018] loss=19.2325 cls=0.6390 smmd=0.3547 ct=7.3488 rec=1.3371 | train/val/test=0.759/0.762/0.761 | c=0.100000
[Epoch 0019] loss=19.1394 cls=0.6136 smmd=0.3489 ct=7.3381 rec=1.3341 | train/val/test=0.771/0.771/0.771 | c=0.100000
[Epoch 0020] loss=19.1991 cls=0.5909 smmd=0.3556 ct=7.3409 rec=1.3312 | train/val/test=0.778/0.780/0.778 | c=0.100000
[Epoch 0021] loss=19.0887 cls=0.5727 smmd=0.3436 ct=7.3512 rec=1.3273 | train/val/test=0.783/0.787/0.782 | c=0.100000
[Epoch 0022] loss=18.7109 cls=0.5572 smmd=0.3071 ct=7.3498 rec=1.3227 | train/val/test=0.790/0.795/0.791 | c=0.100000
[Epoch 0023] loss=18.4921 cls=0.5426 smmd=0.2897 ct=7.3325 rec=1.3183 | train/val/test=0.796/0.801/0.798 | c=0.100000
[Epoch 0024] loss=18.4484 cls=0.5297 smmd=0.2896 ct=7.3152 rec=1.3144 | train/val/test=0.801/0.806/0.802 | c=0.100000
[Epoch 0025] loss=18.3483 cls=0.5187 smmd=0.2817 ct=7.3082 rec=1.3113 | train/val/test=0.806/0.808/0.806 | c=0.100000
[Epoch 0026] loss=18.2206 cls=0.5073 smmd=0.2691 ct=7.3106 rec=1.3092 | train/val/test=0.808/0.810/0.810 | c=0.100000
[Epoch 0027] loss=18.1189 cls=0.4962 smmd=0.2581 ct=7.3179 rec=1.3082 | train/val/test=0.811/0.814/0.815 | c=0.100000
[Epoch 0028] loss=18.0747 cls=0.4876 smmd=0.2527 ct=7.3247 rec=1.3079 | train/val/test=0.813/0.817/0.818 | c=0.100000
[Epoch 0029] loss=18.0196 cls=0.4815 smmd=0.2476 ct=7.3247 rec=1.3076 | train/val/test=0.814/0.818/0.818 | c=0.100000
[Epoch 0030] loss=18.0089 cls=0.4767 smmd=0.2488 ct=7.3145 rec=1.3075 | train/val/test=0.815/0.819/0.818 | c=0.100000
[Epoch 0031] loss=17.9998 cls=0.4733 smmd=0.2511 ct=7.2989 rec=1.3082 | train/val/test=0.817/0.820/0.820 | c=0.100000
[Epoch 0032] loss=18.0338 cls=0.4704 smmd=0.2564 ct=7.2901 rec=1.3091 | train/val/test=0.818/0.825/0.822 | c=0.100000
[Epoch 0033] loss=18.0081 cls=0.4677 smmd=0.2528 ct=7.2958 rec=1.3098 | train/val/test=0.820/0.827/0.824 | c=0.100000
[Epoch 0034] loss=17.9704 cls=0.4657 smmd=0.2466 ct=7.3082 rec=1.3100 | train/val/test=0.821/0.828/0.826 | c=0.100000
[Epoch 0035] loss=17.9934 cls=0.4639 smmd=0.2476 ct=7.3152 rec=1.3101 | train/val/test=0.822/0.828/0.829 | c=0.100000
[Epoch 0036] loss=17.9913 cls=0.4622 smmd=0.2487 ct=7.3093 rec=1.3099 | train/val/test=0.824/0.829/0.828 | c=0.100000
[Epoch 0037] loss=17.9373 cls=0.4608 smmd=0.2453 ct=7.2998 rec=1.3088 | train/val/test=0.823/0.829/0.827 | c=0.100000
[Epoch 0038] loss=17.8947 cls=0.4600 smmd=0.2424 ct=7.2933 rec=1.3076 | train/val/test=0.824/0.828/0.826 | c=0.100000
[Epoch 0039] loss=17.8465 cls=0.4591 smmd=0.2391 ct=7.2865 rec=1.3068 | train/val/test=0.823/0.828/0.828 | c=0.100000
[Epoch 0040] loss=17.7938 cls=0.4581 smmd=0.2344 ct=7.2836 rec=1.3065 | train/val/test=0.823/0.829/0.829 | c=0.100000
[Epoch 0041] loss=17.7540 cls=0.4577 smmd=0.2293 ct=7.2895 rec=1.3065 | train/val/test=0.823/0.829/0.830 | c=0.100000
[Epoch 0042] loss=17.7188 cls=0.4576 smmd=0.2247 ct=7.2947 rec=1.3064 | train/val/test=0.824/0.830/0.830 | c=0.100000
[Epoch 0043] loss=17.7017 cls=0.4579 smmd=0.2239 ct=7.2901 rec=1.3063 | train/val/test=0.823/0.830/0.830 | c=0.100000
[Epoch 0044] loss=17.6770 cls=0.4589 smmd=0.2229 ct=7.2826 rec=1.3064 | train/val/test=0.824/0.829/0.830 | c=0.100000
[Epoch 0045] loss=17.6731 cls=0.4601 smmd=0.2229 ct=7.2804 rec=1.3068 | train/val/test=0.823/0.830/0.831 | c=0.100000
[Epoch 0046] loss=17.6634 cls=0.4609 smmd=0.2222 ct=7.2787 rec=1.3079 | train/val/test=0.823/0.831/0.831 | c=0.100000
[Epoch 0047] loss=17.6723 cls=0.4615 smmd=0.2236 ct=7.2757 rec=1.3093 | train/val/test=0.824/0.832/0.830 | c=0.100000
[Epoch 0048] loss=17.6919 cls=0.4623 smmd=0.2255 ct=7.2751 rec=1.3105 | train/val/test=0.824/0.832/0.830 | c=0.100000
[Epoch 0049] loss=17.6845 cls=0.4630 smmd=0.2242 ct=7.2778 rec=1.3115 | train/val/test=0.824/0.831/0.831 | c=0.100000
[Epoch 0050] loss=17.6646 cls=0.4636 smmd=0.2225 ct=7.2759 rec=1.3120 | train/val/test=0.825/0.833/0.831 | c=0.100000
[Epoch 0051] loss=17.6524 cls=0.4640 smmd=0.2220 ct=7.2721 rec=1.3123 | train/val/test=0.824/0.833/0.831 | c=0.100000
[Epoch 0052] loss=17.6484 cls=0.4642 smmd=0.2224 ct=7.2681 rec=1.3126 | train/val/test=0.825/0.833/0.831 | c=0.100000
[Epoch 0053] loss=17.6010 cls=0.4641 smmd=0.2184 ct=7.2644 rec=1.3126 | train/val/test=0.825/0.833/0.831 | c=0.100000
[Epoch 0054] loss=17.5866 cls=0.4639 smmd=0.2173 ct=7.2625 rec=1.3126 | train/val/test=0.825/0.834/0.831 | c=0.100000
[Epoch 0055] loss=17.5755 cls=0.4637 smmd=0.2159 ct=7.2641 rec=1.3126 | train/val/test=0.825/0.833/0.832 | c=0.100000
[Epoch 0056] loss=17.5607 cls=0.4637 smmd=0.2142 ct=7.2654 rec=1.3124 | train/val/test=0.826/0.832/0.832 | c=0.100000
[Epoch 0057] loss=17.5606 cls=0.4639 smmd=0.2148 ct=7.2625 rec=1.3122 | train/val/test=0.825/0.833/0.833 | c=0.100000
[Epoch 0058] loss=17.5578 cls=0.4640 smmd=0.2155 ct=7.2571 rec=1.3122 | train/val/test=0.825/0.834/0.832 | c=0.100000
[Epoch 0059] loss=17.5592 cls=0.4638 smmd=0.2160 ct=7.2557 rec=1.3125 | train/val/test=0.826/0.833/0.832 | c=0.100000
[Epoch 0060] loss=17.5772 cls=0.4638 smmd=0.2179 ct=7.2549 rec=1.3127 | train/val/test=0.826/0.832/0.832 | c=0.100000
[Epoch 0061] loss=17.5740 cls=0.4637 smmd=0.2182 ct=7.2518 rec=1.3130 | train/val/test=0.826/0.833/0.833 | c=0.100000
[Epoch 0062] loss=17.5456 cls=0.4637 smmd=0.2156 ct=7.2507 rec=1.3130 | train/val/test=0.826/0.833/0.833 | c=0.100000
[Epoch 0063] loss=17.5436 cls=0.4639 smmd=0.2150 ct=7.2525 rec=1.3129 | train/val/test=0.827/0.833/0.833 | c=0.100000
[Epoch 0064] loss=17.5577 cls=0.4634 smmd=0.2165 ct=7.2521 rec=1.3132 | train/val/test=0.827/0.833/0.833 | c=0.100000
[Epoch 0065] loss=17.5499 cls=0.4627 smmd=0.2168 ct=7.2466 rec=1.3137 | train/val/test=0.827/0.832/0.832 | c=0.100000
[Epoch 0066] loss=17.5272 cls=0.4624 smmd=0.2154 ct=7.2425 rec=1.3137 | train/val/test=0.827/0.832/0.832 | c=0.100000
[Epoch 0067] loss=17.5470 cls=0.4620 smmd=0.2176 ct=7.2413 rec=1.3138 | train/val/test=0.828/0.832/0.831 | c=0.100000
[Epoch 0068] loss=17.5299 cls=0.4612 smmd=0.2160 ct=7.2411 rec=1.3142 | train/val/test=0.827/0.831/0.833 | c=0.100000
[Epoch 0069] loss=17.5000 cls=0.4610 smmd=0.2134 ct=7.2390 rec=1.3142 | train/val/test=0.828/0.831/0.833 | c=0.100000
[Epoch 0070] loss=17.4879 cls=0.4606 smmd=0.2128 ct=7.2364 rec=1.3142 | train/val/test=0.828/0.832/0.831 | c=0.100000
[Epoch 0071] loss=17.4754 cls=0.4600 smmd=0.2119 ct=7.2345 rec=1.3147 | train/val/test=0.828/0.831/0.831 | c=0.100000
[Epoch 0072] loss=17.4637 cls=0.4599 smmd=0.2112 ct=7.2321 rec=1.3150 | train/val/test=0.829/0.832/0.831 | c=0.100000
[Epoch 0073] loss=17.4757 cls=0.4601 smmd=0.2126 ct=7.2309 rec=1.3154 | train/val/test=0.829/0.833/0.832 | c=0.100000
[Epoch 0074] loss=17.4838 cls=0.4602 smmd=0.2139 ct=7.2283 rec=1.3159 | train/val/test=0.829/0.833/0.832 | c=0.100000
[Epoch 0075] loss=17.4867 cls=0.4605 smmd=0.2147 ct=7.2256 rec=1.3161 | train/val/test=0.830/0.833/0.833 | c=0.100000
[Epoch 0076] loss=17.4937 cls=0.4606 smmd=0.2153 ct=7.2258 rec=1.3165 | train/val/test=0.830/0.833/0.834 | c=0.100000
[Epoch 0077] loss=17.4822 cls=0.4605 smmd=0.2144 ct=7.2248 rec=1.3169 | train/val/test=0.830/0.833/0.834 | c=0.100000
[Epoch 0078] loss=17.4680 cls=0.4607 smmd=0.2135 ct=7.2219 rec=1.3168 | train/val/test=0.830/0.833/0.834 | c=0.100000
[Epoch 0079] loss=17.4595 cls=0.4608 smmd=0.2131 ct=7.2200 rec=1.3167 | train/val/test=0.830/0.833/0.835 | c=0.100000
[Epoch 0080] loss=17.4636 cls=0.4606 smmd=0.2139 ct=7.2181 rec=1.3169 | train/val/test=0.830/0.833/0.834 | c=0.100000
[Epoch 0081] loss=17.4501 cls=0.4607 smmd=0.2129 ct=7.2163 rec=1.3169 | train/val/test=0.830/0.833/0.834 | c=0.100000
[Epoch 0082] loss=17.4251 cls=0.4609 smmd=0.2107 ct=7.2146 rec=1.3170 | train/val/test=0.830/0.833/0.833 | c=0.100000
[Epoch 0083] loss=17.4322 cls=0.4611 smmd=0.2115 ct=7.2140 rec=1.3172 | train/val/test=0.830/0.834/0.834 | c=0.100000
[Epoch 0084] loss=17.4601 cls=0.4613 smmd=0.2145 ct=7.2131 rec=1.3174 | train/val/test=0.830/0.833/0.834 | c=0.100000
[Epoch 0085] loss=17.4415 cls=0.4620 smmd=0.2128 ct=7.2119 rec=1.3174 | train/val/test=0.830/0.833/0.834 | c=0.100000
[Epoch 0086] loss=17.4303 cls=0.4624 smmd=0.2123 ct=7.2087 rec=1.3177 | train/val/test=0.829/0.833/0.834 | c=0.100000
[Epoch 0087] loss=17.4336 cls=0.4623 smmd=0.2128 ct=7.2077 rec=1.3183 | train/val/test=0.830/0.833/0.835 | c=0.100000
[Epoch 0088] loss=17.4208 cls=0.4630 smmd=0.2113 ct=7.2088 rec=1.3185 | train/val/test=0.831/0.834/0.835 | c=0.100000
[Epoch 0089] loss=17.4292 cls=0.4636 smmd=0.2126 ct=7.2059 rec=1.3187 | train/val/test=0.830/0.834/0.834 | c=0.100000
[Epoch 0090] loss=17.4387 cls=0.4638 smmd=0.2137 ct=7.2051 rec=1.3189 | train/val/test=0.830/0.834/0.836 | c=0.100000
[Epoch 0091] loss=17.4330 cls=0.4642 smmd=0.2128 ct=7.2066 rec=1.3192 | train/val/test=0.830/0.834/0.835 | c=0.100000
[Epoch 0092] loss=17.4375 cls=0.4644 smmd=0.2139 ct=7.2032 rec=1.3194 | train/val/test=0.830/0.834/0.835 | c=0.100000
[Epoch 0093] loss=17.4307 cls=0.4644 smmd=0.2137 ct=7.2009 rec=1.3196 | train/val/test=0.830/0.834/0.835 | c=0.100000
[Epoch 0094] loss=17.4020 cls=0.4645 smmd=0.2107 ct=7.2017 rec=1.3195 | train/val/test=0.830/0.834/0.835 | c=0.100000
[Epoch 0095] loss=17.4107 cls=0.4648 smmd=0.2117 ct=7.2011 rec=1.3194 | train/val/test=0.830/0.834/0.835 | c=0.100000
[Epoch 0096] loss=17.4049 cls=0.4650 smmd=0.2113 ct=7.1996 rec=1.3196 | train/val/test=0.830/0.834/0.835 | c=0.100000
[Epoch 0097] loss=17.3979 cls=0.4653 smmd=0.2111 ct=7.1972 rec=1.3197 | train/val/test=0.829/0.834/0.835 | c=0.100000
[Epoch 0098] loss=17.4055 cls=0.4657 smmd=0.2117 ct=7.1980 rec=1.3198 | train/val/test=0.830/0.834/0.834 | c=0.100000
[Epoch 0099] loss=17.3954 cls=0.4659 smmd=0.2104 ct=7.1990 rec=1.3200 | train/val/test=0.830/0.834/0.834 | c=0.100000
=== Best @ epoch 83: val=0.8341, test=0.8344 ===
