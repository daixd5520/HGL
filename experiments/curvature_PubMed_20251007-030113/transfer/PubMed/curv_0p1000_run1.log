Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=56.5500 cls=1.1086 smmd=4.0788 ct=7.2506 rec=1.4137 | train/val/test=0.391/0.396/0.392 | c=0.100000
[Epoch 0001] loss=32.7044 cls=1.0624 smmd=1.7063 ct=7.2015 rec=1.4152 | train/val/test=0.407/0.412/0.409 | c=0.100000
[Epoch 0002] loss=23.1228 cls=1.0686 smmd=0.7615 ct=7.1332 rec=1.4139 | train/val/test=0.511/0.512/0.525 | c=0.100000
[Epoch 0003] loss=26.2357 cls=1.0523 smmd=1.0729 ct=7.1368 rec=1.4138 | train/val/test=0.576/0.579/0.583 | c=0.100000
[Epoch 0004] loss=25.6478 cls=1.0153 smmd=1.0184 ct=7.1242 rec=1.4156 | train/val/test=0.582/0.588/0.586 | c=0.100000
[Epoch 0005] loss=23.5262 cls=0.9967 smmd=0.8103 ct=7.1076 rec=1.4188 | train/val/test=0.568/0.575/0.571 | c=0.100000
[Epoch 0006] loss=20.7470 cls=0.9813 smmd=0.5382 ct=7.0826 rec=1.4190 | train/val/test=0.563/0.569/0.565 | c=0.100000
[Epoch 0007] loss=20.3855 cls=0.9533 smmd=0.5116 ct=7.0427 rec=1.4156 | train/val/test=0.563/0.569/0.569 | c=0.100000
[Epoch 0008] loss=21.9548 cls=0.9157 smmd=0.6783 ct=7.0047 rec=1.4096 | train/val/test=0.564/0.571/0.576 | c=0.100000
[Epoch 0009] loss=22.0297 cls=0.8742 smmd=0.6947 ct=6.9721 rec=1.4021 | train/val/test=0.578/0.587/0.586 | c=0.100000
[Epoch 0010] loss=20.5628 cls=0.8340 smmd=0.5563 ct=6.9428 rec=1.3938 | train/val/test=0.644/0.652/0.653 | c=0.100000
[Epoch 0011] loss=18.9783 cls=0.7981 smmd=0.4030 ct=6.9282 rec=1.3854 | train/val/test=0.685/0.697/0.697 | c=0.100000
[Epoch 0012] loss=18.5888 cls=0.7668 smmd=0.3663 ct=6.9269 rec=1.3773 | train/val/test=0.705/0.715/0.722 | c=0.100000
[Epoch 0013] loss=19.0656 cls=0.7385 smmd=0.4160 ct=6.9258 rec=1.3690 | train/val/test=0.716/0.727/0.738 | c=0.100000
[Epoch 0014] loss=19.1868 cls=0.7148 smmd=0.4306 ct=6.9214 rec=1.3615 | train/val/test=0.723/0.734/0.742 | c=0.100000
[Epoch 0015] loss=18.7524 cls=0.6927 smmd=0.3899 ct=6.9148 rec=1.3547 | train/val/test=0.731/0.743/0.752 | c=0.100000
[Epoch 0016] loss=18.2905 cls=0.6678 smmd=0.3473 ct=6.9050 rec=1.3481 | train/val/test=0.746/0.761/0.766 | c=0.100000
[Epoch 0017] loss=18.1572 cls=0.6445 smmd=0.3380 ct=6.8920 rec=1.3425 | train/val/test=0.760/0.774/0.777 | c=0.100000
[Epoch 0018] loss=18.1505 cls=0.6225 smmd=0.3414 ct=6.8783 rec=1.3372 | train/val/test=0.768/0.779/0.787 | c=0.100000
[Epoch 0019] loss=18.1372 cls=0.6008 smmd=0.3434 ct=6.8685 rec=1.3320 | train/val/test=0.777/0.784/0.793 | c=0.100000
[Epoch 0020] loss=18.1054 cls=0.5795 smmd=0.3426 ct=6.8631 rec=1.3272 | train/val/test=0.789/0.800/0.802 | c=0.100000
[Epoch 0021] loss=17.9071 cls=0.5586 smmd=0.3249 ct=6.8588 rec=1.3226 | train/val/test=0.797/0.809/0.809 | c=0.100000
[Epoch 0022] loss=17.5875 cls=0.5432 smmd=0.2950 ct=6.8535 rec=1.3183 | train/val/test=0.801/0.813/0.812 | c=0.100000
[Epoch 0023] loss=17.3650 cls=0.5331 smmd=0.2747 ct=6.8474 rec=1.3136 | train/val/test=0.801/0.812/0.812 | c=0.100000
[Epoch 0024] loss=17.3407 cls=0.5240 smmd=0.2745 ct=6.8399 rec=1.3089 | train/val/test=0.803/0.813/0.811 | c=0.100000
[Epoch 0025] loss=17.3285 cls=0.5118 smmd=0.2756 ct=6.8321 rec=1.3054 | train/val/test=0.807/0.815/0.815 | c=0.100000
[Epoch 0026] loss=17.1834 cls=0.4973 smmd=0.2629 ct=6.8271 rec=1.3036 | train/val/test=0.810/0.816/0.819 | c=0.100000
[Epoch 0027] loss=17.0172 cls=0.4858 smmd=0.2476 ct=6.8234 rec=1.3035 | train/val/test=0.813/0.818/0.821 | c=0.100000
[Epoch 0028] loss=16.9604 cls=0.4780 smmd=0.2429 ct=6.8202 rec=1.3041 | train/val/test=0.816/0.819/0.822 | c=0.100000
[Epoch 0029] loss=17.0147 cls=0.4724 smmd=0.2491 ct=6.8178 rec=1.3046 | train/val/test=0.816/0.820/0.824 | c=0.100000
[Epoch 0030] loss=17.0054 cls=0.4690 smmd=0.2490 ct=6.8145 rec=1.3047 | train/val/test=0.818/0.821/0.827 | c=0.100000
[Epoch 0031] loss=16.9758 cls=0.4670 smmd=0.2467 ct=6.8118 rec=1.3043 | train/val/test=0.820/0.822/0.828 | c=0.100000
[Epoch 0032] loss=18.3008 cls=0.4656 smmd=0.2440 ct=7.4878 rec=1.3041 | train/val/test=0.820/0.822/0.830 | c=0.100000
[Epoch 0033] loss=18.2681 cls=0.4670 smmd=0.2555 ct=7.4138 rec=1.3033 | train/val/test=0.821/0.822/0.830 | c=0.100000
[Epoch 0034] loss=18.2765 cls=0.4665 smmd=0.2651 ct=7.3704 rec=1.3035 | train/val/test=0.822/0.823/0.833 | c=0.100000
[Epoch 0035] loss=18.2617 cls=0.4623 smmd=0.2601 ct=7.3887 rec=1.3049 | train/val/test=0.822/0.824/0.832 | c=0.100000
[Epoch 0036] loss=18.2572 cls=0.4601 smmd=0.2524 ct=7.4251 rec=1.3067 | train/val/test=0.821/0.825/0.830 | c=0.100000
[Epoch 0037] loss=18.1951 cls=0.4597 smmd=0.2442 ct=7.4347 rec=1.3068 | train/val/test=0.821/0.823/0.831 | c=0.100000
[Epoch 0038] loss=18.1278 cls=0.4598 smmd=0.2387 ct=7.4288 rec=1.3060 | train/val/test=0.823/0.824/0.832 | c=0.100000
[Epoch 0039] loss=18.0820 cls=0.4594 smmd=0.2353 ct=7.4231 rec=1.3057 | train/val/test=0.823/0.824/0.832 | c=0.100000
[Epoch 0040] loss=18.0464 cls=0.4590 smmd=0.2339 ct=7.4123 rec=1.3057 | train/val/test=0.824/0.825/0.833 | c=0.100000
[Epoch 0041] loss=18.0103 cls=0.4593 smmd=0.2337 ct=7.3954 rec=1.3064 | train/val/test=0.824/0.828/0.831 | c=0.100000
[Epoch 0042] loss=17.9839 cls=0.4604 smmd=0.2330 ct=7.3849 rec=1.3072 | train/val/test=0.823/0.828/0.832 | c=0.100000
[Epoch 0043] loss=17.9426 cls=0.4605 smmd=0.2285 ct=7.3868 rec=1.3073 | train/val/test=0.822/0.826/0.830 | c=0.100000
[Epoch 0044] loss=17.9249 cls=0.4607 smmd=0.2258 ct=7.3914 rec=1.3073 | train/val/test=0.822/0.824/0.831 | c=0.100000
[Epoch 0045] loss=17.9197 cls=0.4624 smmd=0.2248 ct=7.3932 rec=1.3084 | train/val/test=0.822/0.825/0.829 | c=0.100000
[Epoch 0046] loss=17.9077 cls=0.4629 smmd=0.2234 ct=7.3938 rec=1.3098 | train/val/test=0.822/0.827/0.832 | c=0.100000
[Epoch 0047] loss=17.9062 cls=0.4630 smmd=0.2239 ct=7.3899 rec=1.3108 | train/val/test=0.822/0.828/0.832 | c=0.100000
[Epoch 0048] loss=17.8910 cls=0.4641 smmd=0.2241 ct=7.3812 rec=1.3112 | train/val/test=0.822/0.828/0.832 | c=0.100000
[Epoch 0049] loss=17.9103 cls=0.4649 smmd=0.2274 ct=7.3739 rec=1.3117 | train/val/test=0.822/0.829/0.832 | c=0.100000
[Epoch 0050] loss=17.9086 cls=0.4653 smmd=0.2277 ct=7.3714 rec=1.3124 | train/val/test=0.822/0.829/0.833 | c=0.100000
[Epoch 0051] loss=17.8722 cls=0.4654 smmd=0.2243 ct=7.3699 rec=1.3125 | train/val/test=0.822/0.828/0.832 | c=0.100000
[Epoch 0052] loss=17.8575 cls=0.4654 smmd=0.2236 ct=7.3664 rec=1.3122 | train/val/test=0.824/0.827/0.832 | c=0.100000
[Epoch 0053] loss=17.8283 cls=0.4654 smmd=0.2211 ct=7.3642 rec=1.3118 | train/val/test=0.824/0.826/0.831 | c=0.100000
[Epoch 0054] loss=17.7857 cls=0.4653 smmd=0.2173 ct=7.3621 rec=1.3113 | train/val/test=0.825/0.826/0.831 | c=0.100000
[Epoch 0055] loss=17.7815 cls=0.4649 smmd=0.2176 ct=7.3588 rec=1.3111 | train/val/test=0.825/0.827/0.832 | c=0.100000
[Epoch 0056] loss=17.7611 cls=0.4648 smmd=0.2165 ct=7.3542 rec=1.3109 | train/val/test=0.825/0.827/0.832 | c=0.100000
[Epoch 0057] loss=17.7474 cls=0.4650 smmd=0.2156 ct=7.3520 rec=1.3106 | train/val/test=0.825/0.827/0.832 | c=0.100000
[Epoch 0058] loss=17.7605 cls=0.4653 smmd=0.2170 ct=7.3514 rec=1.3105 | train/val/test=0.825/0.828/0.832 | c=0.100000
[Epoch 0059] loss=17.7585 cls=0.4651 smmd=0.2173 ct=7.3490 rec=1.3108 | train/val/test=0.826/0.829/0.832 | c=0.100000
[Epoch 0060] loss=17.7444 cls=0.4646 smmd=0.2163 ct=7.3465 rec=1.3114 | train/val/test=0.825/0.829/0.831 | c=0.100000
[Epoch 0061] loss=17.7629 cls=0.4649 smmd=0.2194 ct=7.3403 rec=1.3114 | train/val/test=0.825/0.829/0.832 | c=0.100000
[Epoch 0062] loss=17.7640 cls=0.4652 smmd=0.2205 ct=7.3353 rec=1.3114 | train/val/test=0.825/0.829/0.831 | c=0.100000
[Epoch 0063] loss=17.7529 cls=0.4649 smmd=0.2192 ct=7.3364 rec=1.3117 | train/val/test=0.825/0.829/0.832 | c=0.100000
[Epoch 0064] loss=17.7520 cls=0.4643 smmd=0.2189 ct=7.3376 rec=1.3121 | train/val/test=0.825/0.830/0.832 | c=0.100000
[Epoch 0065] loss=17.7205 cls=0.4640 smmd=0.2164 ct=7.3343 rec=1.3123 | train/val/test=0.825/0.830/0.832 | c=0.100000
[Epoch 0066] loss=17.7194 cls=0.4634 smmd=0.2173 ct=7.3294 rec=1.3125 | train/val/test=0.825/0.831/0.834 | c=0.100000
[Epoch 0067] loss=17.7103 cls=0.4628 smmd=0.2169 ct=7.3266 rec=1.3127 | train/val/test=0.825/0.831/0.834 | c=0.100000
[Epoch 0068] loss=17.6899 cls=0.4628 smmd=0.2159 ct=7.3214 rec=1.3126 | train/val/test=0.825/0.831/0.831 | c=0.100000
[Epoch 0069] loss=17.6625 cls=0.4627 smmd=0.2140 ct=7.3173 rec=1.3127 | train/val/test=0.825/0.832/0.834 | c=0.100000
[Epoch 0070] loss=17.6583 cls=0.4622 smmd=0.2135 ct=7.3178 rec=1.3133 | train/val/test=0.825/0.831/0.833 | c=0.100000
[Epoch 0071] loss=17.6628 cls=0.4621 smmd=0.2137 ct=7.3187 rec=1.3137 | train/val/test=0.825/0.831/0.832 | c=0.100000
[Epoch 0072] loss=17.6804 cls=0.4624 smmd=0.2163 ct=7.3148 rec=1.3140 | train/val/test=0.826/0.832/0.834 | c=0.100000
[Epoch 0073] loss=17.6701 cls=0.4623 smmd=0.2154 ct=7.3137 rec=1.3146 | train/val/test=0.826/0.831/0.835 | c=0.100000
[Epoch 0074] loss=17.6874 cls=0.4624 smmd=0.2175 ct=7.3116 rec=1.3149 | train/val/test=0.826/0.831/0.834 | c=0.100000
[Epoch 0075] loss=17.6849 cls=0.4627 smmd=0.2183 ct=7.3065 rec=1.3147 | train/val/test=0.826/0.831/0.833 | c=0.100000
[Epoch 0076] loss=17.6542 cls=0.4625 smmd=0.2156 ct=7.3047 rec=1.3148 | train/val/test=0.826/0.832/0.833 | c=0.100000
[Epoch 0077] loss=17.6516 cls=0.4622 smmd=0.2153 ct=7.3051 rec=1.3150 | train/val/test=0.826/0.831/0.833 | c=0.100000
[Epoch 0078] loss=17.6586 cls=0.4623 smmd=0.2163 ct=7.3036 rec=1.3147 | train/val/test=0.826/0.831/0.833 | c=0.100000
[Epoch 0079] loss=17.6235 cls=0.4622 smmd=0.2132 ct=7.3017 rec=1.3147 | train/val/test=0.827/0.832/0.834 | c=0.100000
[Epoch 0080] loss=17.6269 cls=0.4621 smmd=0.2139 ct=7.2995 rec=1.3151 | train/val/test=0.827/0.832/0.833 | c=0.100000
[Epoch 0081] loss=17.6226 cls=0.4624 smmd=0.2142 ct=7.2958 rec=1.3151 | train/val/test=0.827/0.833/0.834 | c=0.100000
[Epoch 0082] loss=17.6168 cls=0.4627 smmd=0.2138 ct=7.2948 rec=1.3153 | train/val/test=0.827/0.833/0.835 | c=0.100000
[Epoch 0083] loss=17.6280 cls=0.4629 smmd=0.2146 ct=7.2961 rec=1.3157 | train/val/test=0.827/0.833/0.835 | c=0.100000
[Epoch 0084] loss=17.6290 cls=0.4632 smmd=0.2152 ct=7.2937 rec=1.3160 | train/val/test=0.827/0.834/0.834 | c=0.100000
[Epoch 0085] loss=17.6206 cls=0.4637 smmd=0.2150 ct=7.2903 rec=1.3159 | train/val/test=0.828/0.834/0.834 | c=0.100000
[Epoch 0086] loss=17.6217 cls=0.4638 smmd=0.2149 ct=7.2912 rec=1.3162 | train/val/test=0.827/0.833/0.835 | c=0.100000
[Epoch 0087] loss=17.6255 cls=0.4639 smmd=0.2156 ct=7.2899 rec=1.3164 | train/val/test=0.828/0.834/0.834 | c=0.100000
[Epoch 0088] loss=17.6246 cls=0.4640 smmd=0.2159 ct=7.2879 rec=1.3163 | train/val/test=0.827/0.834/0.835 | c=0.100000
[Epoch 0089] loss=17.6043 cls=0.4640 smmd=0.2139 ct=7.2878 rec=1.3164 | train/val/test=0.826/0.833/0.834 | c=0.100000
[Epoch 0090] loss=17.5997 cls=0.4641 smmd=0.2135 ct=7.2870 rec=1.3165 | train/val/test=0.828/0.835/0.834 | c=0.100000
[Epoch 0091] loss=17.5916 cls=0.4641 smmd=0.2137 ct=7.2821 rec=1.3164 | train/val/test=0.827/0.834/0.834 | c=0.100000
[Epoch 0092] loss=17.5906 cls=0.4640 smmd=0.2136 ct=7.2821 rec=1.3165 | train/val/test=0.827/0.833/0.835 | c=0.100000
[Epoch 0093] loss=17.5868 cls=0.4643 smmd=0.2131 ct=7.2825 rec=1.3166 | train/val/test=0.828/0.834/0.834 | c=0.100000
[Epoch 0094] loss=17.5853 cls=0.4644 smmd=0.2130 ct=7.2823 rec=1.3167 | train/val/test=0.827/0.833/0.833 | c=0.100000
[Epoch 0095] loss=17.5949 cls=0.4645 smmd=0.2140 ct=7.2821 rec=1.3170 | train/val/test=0.827/0.833/0.834 | c=0.100000
[Epoch 0096] loss=17.5896 cls=0.4648 smmd=0.2140 ct=7.2791 rec=1.3172 | train/val/test=0.827/0.833/0.833 | c=0.100000
[Epoch 0097] loss=17.5937 cls=0.4649 smmd=0.2151 ct=7.2756 rec=1.3173 | train/val/test=0.827/0.834/0.833 | c=0.100000
[Epoch 0098] loss=17.6059 cls=0.4651 smmd=0.2161 ct=7.2769 rec=1.3174 | train/val/test=0.827/0.833/0.833 | c=0.100000
[Epoch 0099] loss=17.5680 cls=0.4652 smmd=0.2123 ct=7.2769 rec=1.3173 | train/val/test=0.827/0.833/0.834 | c=0.100000
=== Best @ epoch 90: val=0.8349, test=0.8344 ===
