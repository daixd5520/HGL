Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=55.8791 cls=1.1083 smmd=4.0117 ct=7.2504 rec=1.4140 | train/val/test=0.397/0.400/0.407 | c=0.500000
[Epoch 0001] loss=31.8622 cls=1.0660 smmd=1.6249 ct=7.1860 rec=1.4154 | train/val/test=0.442/0.445/0.454 | c=0.500000
[Epoch 0002] loss=23.6136 cls=1.0689 smmd=0.8097 ct=7.1377 rec=1.4140 | train/val/test=0.550/0.555/0.552 | c=0.500000
[Epoch 0003] loss=26.2288 cls=1.0565 smmd=1.0723 ct=7.1352 rec=1.4140 | train/val/test=0.552/0.557/0.561 | c=0.500000
[Epoch 0004] loss=25.0511 cls=1.0294 smmd=0.9594 ct=7.1171 rec=1.4155 | train/val/test=0.550/0.554/0.561 | c=0.500000
[Epoch 0005] loss=23.2744 cls=1.0083 smmd=0.7869 ct=7.0964 rec=1.4178 | train/val/test=0.545/0.550/0.554 | c=0.500000
[Epoch 0006] loss=21.1343 cls=0.9897 smmd=0.5842 ct=7.0438 rec=1.4187 | train/val/test=0.536/0.544/0.543 | c=0.500000
[Epoch 0007] loss=20.4759 cls=0.9658 smmd=0.5316 ct=6.9843 rec=1.4168 | train/val/test=0.533/0.540/0.537 | c=0.500000
[Epoch 0008] loss=21.4173 cls=0.9332 smmd=0.6325 ct=6.9598 rec=1.4121 | train/val/test=0.532/0.543/0.536 | c=0.500000
[Epoch 0009] loss=21.6582 cls=0.8946 smmd=0.6613 ct=6.9479 rec=1.4051 | train/val/test=0.547/0.552/0.549 | c=0.500000
[Epoch 0010] loss=20.5615 cls=0.8548 smmd=0.5563 ct=6.9365 rec=1.3966 | train/val/test=0.612/0.608/0.620 | c=0.500000
[Epoch 0011] loss=19.1531 cls=0.8181 smmd=0.4203 ct=6.9237 rec=1.3874 | train/val/test=0.656/0.652/0.659 | c=0.500000
[Epoch 0012] loss=18.6044 cls=0.7871 smmd=0.3695 ct=6.9133 rec=1.3780 | train/val/test=0.670/0.669/0.674 | c=0.500000
[Epoch 0013] loss=18.8037 cls=0.7610 smmd=0.3933 ct=6.9030 rec=1.3691 | train/val/test=0.677/0.675/0.679 | c=0.500000
[Epoch 0014] loss=18.9632 cls=0.7384 smmd=0.4136 ct=6.8885 rec=1.3611 | train/val/test=0.684/0.678/0.687 | c=0.500000
[Epoch 0015] loss=18.7102 cls=0.7193 smmd=0.3923 ct=6.8749 rec=1.3546 | train/val/test=0.693/0.687/0.697 | c=0.500000
[Epoch 0016] loss=18.3950 cls=0.7005 smmd=0.3637 ct=6.8665 rec=1.3488 | train/val/test=0.701/0.695/0.705 | c=0.500000
[Epoch 0017] loss=18.2904 cls=0.6811 smmd=0.3553 ct=6.8626 rec=1.3434 | train/val/test=0.711/0.708/0.714 | c=0.500000
[Epoch 0018] loss=18.0771 cls=0.6628 smmd=0.3357 ct=6.8598 rec=1.3390 | train/val/test=0.727/0.721/0.725 | c=0.500000
[Epoch 0019] loss=17.8383 cls=0.6439 smmd=0.3133 ct=6.8577 rec=1.3355 | train/val/test=0.743/0.738/0.747 | c=0.500000
[Epoch 0020] loss=17.9514 cls=0.6240 smmd=0.3263 ct=6.8552 rec=1.3324 | train/val/test=0.760/0.754/0.765 | c=0.500000
[Epoch 0021] loss=18.0247 cls=0.6052 smmd=0.3364 ct=6.8468 rec=1.3293 | train/val/test=0.772/0.768/0.776 | c=0.500000
[Epoch 0022] loss=17.7060 cls=0.5885 smmd=0.3082 ct=6.8333 rec=1.3260 | train/val/test=0.781/0.775/0.782 | c=0.500000
[Epoch 0023] loss=17.2774 cls=0.5726 smmd=0.2683 ct=6.8233 rec=1.3227 | train/val/test=0.785/0.781/0.788 | c=0.500000
[Epoch 0024] loss=17.1675 cls=0.5570 smmd=0.2591 ct=6.8192 rec=1.3199 | train/val/test=0.789/0.785/0.792 | c=0.500000
[Epoch 0025] loss=17.2717 cls=0.5426 smmd=0.2706 ct=6.8178 rec=1.3179 | train/val/test=0.795/0.791/0.796 | c=0.500000
[Epoch 0026] loss=17.2206 cls=0.5298 smmd=0.2667 ct=6.8150 rec=1.3166 | train/val/test=0.799/0.796/0.803 | c=0.500000
[Epoch 0027] loss=17.0266 cls=0.5189 smmd=0.2488 ct=6.8104 rec=1.3158 | train/val/test=0.802/0.798/0.806 | c=0.500000
[Epoch 0028] loss=16.9275 cls=0.5101 smmd=0.2405 ct=6.8050 rec=1.3152 | train/val/test=0.803/0.802/0.808 | c=0.500000
[Epoch 0029] loss=16.9208 cls=0.5030 smmd=0.2412 ct=6.7999 rec=1.3150 | train/val/test=0.805/0.807/0.811 | c=0.500000
[Epoch 0030] loss=16.9246 cls=0.4968 smmd=0.2423 ct=6.7977 rec=1.3155 | train/val/test=0.810/0.808/0.818 | c=0.500000
[Epoch 0031] loss=16.9399 cls=0.4911 smmd=0.2441 ct=6.7976 rec=1.3163 | train/val/test=0.815/0.808/0.825 | c=0.500000
[Epoch 0032] loss=16.9378 cls=0.4863 smmd=0.2441 ct=6.7977 rec=1.3171 | train/val/test=0.817/0.812/0.824 | c=0.500000
[Epoch 0033] loss=16.9014 cls=0.4826 smmd=0.2407 ct=6.7972 rec=1.3174 | train/val/test=0.817/0.812/0.827 | c=0.500000
[Epoch 0034] loss=16.8579 cls=0.4794 smmd=0.2369 ct=6.7955 rec=1.3170 | train/val/test=0.818/0.812/0.827 | c=0.500000
[Epoch 0035] loss=16.8448 cls=0.4766 smmd=0.2363 ct=6.7928 rec=1.3161 | train/val/test=0.817/0.813/0.826 | c=0.500000
[Epoch 0036] loss=16.8566 cls=0.4739 smmd=0.2383 ct=6.7896 rec=1.3146 | train/val/test=0.818/0.814/0.826 | c=0.500000
[Epoch 0037] loss=18.2345 cls=0.4718 smmd=0.2347 ct=7.4979 rec=1.3125 | train/val/test=0.820/0.816/0.828 | c=0.500000
[Epoch 0038] loss=18.1147 cls=0.4698 smmd=0.2366 ct=7.4291 rec=1.3105 | train/val/test=0.823/0.818/0.830 | c=0.500000
[Epoch 0039] loss=18.1035 cls=0.4689 smmd=0.2441 ct=7.3866 rec=1.3097 | train/val/test=0.824/0.818/0.829 | c=0.500000
[Epoch 0040] loss=18.0915 cls=0.4678 smmd=0.2412 ct=7.3955 rec=1.3093 | train/val/test=0.822/0.819/0.831 | c=0.500000
[Epoch 0041] loss=18.0402 cls=0.4665 smmd=0.2323 ct=7.4147 rec=1.3085 | train/val/test=0.822/0.816/0.830 | c=0.500000
[Epoch 0042] loss=18.0069 cls=0.4662 smmd=0.2285 ct=7.4174 rec=1.3077 | train/val/test=0.820/0.817/0.830 | c=0.500000
[Epoch 0043] loss=18.0107 cls=0.4665 smmd=0.2288 ct=7.4179 rec=1.3072 | train/val/test=0.820/0.816/0.830 | c=0.500000
[Epoch 0044] loss=17.9626 cls=0.4671 smmd=0.2228 ct=7.4235 rec=1.3072 | train/val/test=0.820/0.818/0.829 | c=0.500000
[Epoch 0045] loss=17.9622 cls=0.4679 smmd=0.2236 ct=7.4194 rec=1.3074 | train/val/test=0.820/0.817/0.829 | c=0.500000
[Epoch 0046] loss=17.9707 cls=0.4684 smmd=0.2283 ct=7.3998 rec=1.3080 | train/val/test=0.821/0.819/0.830 | c=0.500000
[Epoch 0047] loss=17.9502 cls=0.4680 smmd=0.2293 ct=7.3844 rec=1.3092 | train/val/test=0.822/0.820/0.830 | c=0.500000
[Epoch 0048] loss=17.9306 cls=0.4675 smmd=0.2268 ct=7.3867 rec=1.3106 | train/val/test=0.823/0.819/0.831 | c=0.500000
[Epoch 0049] loss=17.9254 cls=0.4673 smmd=0.2241 ct=7.3975 rec=1.3119 | train/val/test=0.825/0.819/0.833 | c=0.500000
[Epoch 0050] loss=17.9083 cls=0.4674 smmd=0.2217 ct=7.4006 rec=1.3128 | train/val/test=0.824/0.820/0.834 | c=0.500000
[Epoch 0051] loss=17.8607 cls=0.4676 smmd=0.2188 ct=7.3911 rec=1.3132 | train/val/test=0.823/0.821/0.833 | c=0.500000
[Epoch 0052] loss=17.8348 cls=0.4677 smmd=0.2188 ct=7.3783 rec=1.3134 | train/val/test=0.824/0.821/0.834 | c=0.500000
[Epoch 0053] loss=17.8327 cls=0.4678 smmd=0.2198 ct=7.3722 rec=1.3135 | train/val/test=0.824/0.821/0.832 | c=0.500000
[Epoch 0054] loss=17.8138 cls=0.4679 smmd=0.2179 ct=7.3718 rec=1.3137 | train/val/test=0.824/0.821/0.833 | c=0.500000
[Epoch 0055] loss=17.8032 cls=0.4680 smmd=0.2166 ct=7.3735 rec=1.3132 | train/val/test=0.822/0.821/0.832 | c=0.500000
[Epoch 0056] loss=17.7891 cls=0.4684 smmd=0.2154 ct=7.3721 rec=1.3128 | train/val/test=0.823/0.820/0.832 | c=0.500000
[Epoch 0057] loss=17.7978 cls=0.4681 smmd=0.2171 ct=7.3683 rec=1.3126 | train/val/test=0.824/0.821/0.833 | c=0.500000
[Epoch 0058] loss=17.7831 cls=0.4677 smmd=0.2165 ct=7.3638 rec=1.3126 | train/val/test=0.825/0.822/0.833 | c=0.500000
[Epoch 0059] loss=17.7856 cls=0.4676 smmd=0.2178 ct=7.3589 rec=1.3124 | train/val/test=0.824/0.821/0.834 | c=0.500000
[Epoch 0060] loss=17.7859 cls=0.4673 smmd=0.2191 ct=7.3524 rec=1.3121 | train/val/test=0.823/0.821/0.833 | c=0.500000
[Epoch 0061] loss=17.7701 cls=0.4673 smmd=0.2181 ct=7.3500 rec=1.3116 | train/val/test=0.823/0.821/0.833 | c=0.500000
[Epoch 0062] loss=17.7761 cls=0.4671 smmd=0.2182 ct=7.3524 rec=1.3113 | train/val/test=0.824/0.821/0.833 | c=0.500000
[Epoch 0063] loss=17.7727 cls=0.4665 smmd=0.2177 ct=7.3534 rec=1.3112 | train/val/test=0.824/0.821/0.834 | c=0.500000
[Epoch 0064] loss=17.7324 cls=0.4657 smmd=0.2149 ct=7.3473 rec=1.3113 | train/val/test=0.825/0.823/0.833 | c=0.500000
[Epoch 0065] loss=17.7288 cls=0.4649 smmd=0.2160 ct=7.3404 rec=1.3115 | train/val/test=0.825/0.823/0.833 | c=0.500000
[Epoch 0066] loss=17.7186 cls=0.4645 smmd=0.2154 ct=7.3381 rec=1.3117 | train/val/test=0.825/0.821/0.833 | c=0.500000
[Epoch 0067] loss=17.7186 cls=0.4639 smmd=0.2157 ct=7.3368 rec=1.3119 | train/val/test=0.825/0.821/0.833 | c=0.500000
[Epoch 0068] loss=17.6847 cls=0.4634 smmd=0.2128 ct=7.3344 rec=1.3122 | train/val/test=0.825/0.822/0.833 | c=0.500000
[Epoch 0069] loss=17.6991 cls=0.4632 smmd=0.2145 ct=7.3329 rec=1.3125 | train/val/test=0.825/0.821/0.833 | c=0.500000
[Epoch 0070] loss=17.6860 cls=0.4631 smmd=0.2135 ct=7.3314 rec=1.3127 | train/val/test=0.825/0.822/0.833 | c=0.500000
[Epoch 0071] loss=17.6923 cls=0.4630 smmd=0.2146 ct=7.3291 rec=1.3129 | train/val/test=0.826/0.821/0.834 | c=0.500000
[Epoch 0072] loss=17.7080 cls=0.4629 smmd=0.2170 ct=7.3250 rec=1.3131 | train/val/test=0.825/0.820/0.834 | c=0.500000
[Epoch 0073] loss=17.6933 cls=0.4630 smmd=0.2160 ct=7.3225 rec=1.3130 | train/val/test=0.825/0.820/0.835 | c=0.500000
[Epoch 0074] loss=17.6798 cls=0.4628 smmd=0.2150 ct=7.3209 rec=1.3131 | train/val/test=0.826/0.821/0.836 | c=0.500000
[Epoch 0075] loss=17.6789 cls=0.4625 smmd=0.2150 ct=7.3204 rec=1.3131 | train/val/test=0.825/0.820/0.834 | c=0.500000
[Epoch 0076] loss=17.6682 cls=0.4627 smmd=0.2143 ct=7.3187 rec=1.3129 | train/val/test=0.826/0.821/0.836 | c=0.500000
[Epoch 0077] loss=17.6488 cls=0.4625 smmd=0.2132 ct=7.3144 rec=1.3128 | train/val/test=0.827/0.821/0.836 | c=0.500000
[Epoch 0078] loss=17.6437 cls=0.4626 smmd=0.2131 ct=7.3124 rec=1.3129 | train/val/test=0.827/0.821/0.836 | c=0.500000
[Epoch 0079] loss=17.6318 cls=0.4631 smmd=0.2119 ct=7.3126 rec=1.3127 | train/val/test=0.826/0.822/0.835 | c=0.500000
[Epoch 0080] loss=17.6586 cls=0.4633 smmd=0.2145 ct=7.3125 rec=1.3131 | train/val/test=0.827/0.821/0.836 | c=0.500000
[Epoch 0081] loss=17.6502 cls=0.4635 smmd=0.2142 ct=7.3098 rec=1.3134 | train/val/test=0.827/0.821/0.837 | c=0.500000
[Epoch 0082] loss=17.6457 cls=0.4640 smmd=0.2145 ct=7.3060 rec=1.3135 | train/val/test=0.827/0.822/0.836 | c=0.500000
[Epoch 0083] loss=17.6347 cls=0.4640 smmd=0.2135 ct=7.3056 rec=1.3139 | train/val/test=0.827/0.823/0.836 | c=0.500000
[Epoch 0084] loss=17.6189 cls=0.4641 smmd=0.2120 ct=7.3050 rec=1.3141 | train/val/test=0.827/0.823/0.836 | c=0.500000
[Epoch 0085] loss=17.6376 cls=0.4645 smmd=0.2141 ct=7.3037 rec=1.3141 | train/val/test=0.826/0.823/0.836 | c=0.500000
[Epoch 0086] loss=17.6333 cls=0.4645 smmd=0.2138 ct=7.3028 rec=1.3142 | train/val/test=0.826/0.822/0.837 | c=0.500000
[Epoch 0087] loss=17.6250 cls=0.4646 smmd=0.2128 ct=7.3036 rec=1.3143 | train/val/test=0.827/0.822/0.837 | c=0.500000
[Epoch 0088] loss=17.6251 cls=0.4646 smmd=0.2136 ct=7.3001 rec=1.3142 | train/val/test=0.827/0.823/0.836 | c=0.500000
[Epoch 0089] loss=17.6291 cls=0.4644 smmd=0.2144 ct=7.2978 rec=1.3143 | train/val/test=0.827/0.823/0.836 | c=0.500000
[Epoch 0090] loss=17.6203 cls=0.4644 smmd=0.2135 ct=7.2980 rec=1.3143 | train/val/test=0.826/0.821/0.834 | c=0.500000
[Epoch 0091] loss=17.6090 cls=0.4646 smmd=0.2124 ct=7.2977 rec=1.3143 | train/val/test=0.827/0.823/0.836 | c=0.500000
[Epoch 0092] loss=17.5826 cls=0.4645 smmd=0.2100 ct=7.2965 rec=1.3142 | train/val/test=0.827/0.822/0.837 | c=0.500000
[Epoch 0093] loss=17.6032 cls=0.4647 smmd=0.2123 ct=7.2955 rec=1.3144 | train/val/test=0.826/0.821/0.837 | c=0.500000
[Epoch 0094] loss=17.5871 cls=0.4649 smmd=0.2110 ct=7.2934 rec=1.3148 | train/val/test=0.826/0.822/0.836 | c=0.500000
[Epoch 0095] loss=17.6140 cls=0.4652 smmd=0.2139 ct=7.2926 rec=1.3150 | train/val/test=0.826/0.822/0.836 | c=0.500000
[Epoch 0096] loss=17.5976 cls=0.4655 smmd=0.2120 ct=7.2937 rec=1.3151 | train/val/test=0.826/0.822/0.836 | c=0.500000
[Epoch 0097] loss=17.5975 cls=0.4657 smmd=0.2123 ct=7.2918 rec=1.3154 | train/val/test=0.826/0.822/0.836 | c=0.500000
[Epoch 0098] loss=17.6031 cls=0.4658 smmd=0.2127 ct=7.2927 rec=1.3155 | train/val/test=0.826/0.822/0.837 | c=0.500000
[Epoch 0099] loss=17.5950 cls=0.4659 smmd=0.2122 ct=7.2909 rec=1.3155 | train/val/test=0.827/0.822/0.836 | c=0.500000
=== Best @ epoch 85: val=0.8232, test=0.8362 ===
