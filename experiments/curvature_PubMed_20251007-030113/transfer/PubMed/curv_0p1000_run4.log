Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=57.3917 cls=1.0934 smmd=4.1638 ct=7.2500 rec=1.4136 | train/val/test=0.398/0.405/0.402 | c=0.100000
[Epoch 0001] loss=33.8888 cls=1.0592 smmd=1.8284 ct=7.1837 rec=1.4155 | train/val/test=0.397/0.405/0.402 | c=0.100000
[Epoch 0002] loss=22.9819 cls=1.0623 smmd=0.7447 ct=7.1482 rec=1.4140 | train/val/test=0.458/0.460/0.456 | c=0.100000
[Epoch 0003] loss=26.0110 cls=1.0438 smmd=1.0478 ct=7.1523 rec=1.4139 | train/val/test=0.588/0.593/0.586 | c=0.100000
[Epoch 0004] loss=25.9625 cls=1.0098 smmd=1.0475 ct=7.1375 rec=1.4153 | train/val/test=0.586/0.587/0.584 | c=0.100000
[Epoch 0005] loss=23.7985 cls=0.9839 smmd=0.8383 ct=7.1074 rec=1.4176 | train/val/test=0.585/0.588/0.583 | c=0.100000
[Epoch 0006] loss=20.7262 cls=0.9599 smmd=0.5439 ct=7.0492 rec=1.4176 | train/val/test=0.569/0.573/0.563 | c=0.100000
[Epoch 0007] loss=20.3160 cls=0.9264 smmd=0.5153 ct=6.9967 rec=1.4138 | train/val/test=0.557/0.565/0.557 | c=0.100000
[Epoch 0008] loss=21.8171 cls=0.8810 smmd=0.6725 ct=6.9740 rec=1.4069 | train/val/test=0.584/0.585/0.581 | c=0.100000
[Epoch 0009] loss=22.1735 cls=0.8326 smmd=0.7146 ct=6.9561 rec=1.3981 | train/val/test=0.653/0.658/0.649 | c=0.100000
[Epoch 0010] loss=22.1298 cls=0.7896 smmd=0.5778 ct=7.6314 rec=1.3887 | train/val/test=0.689/0.691/0.676 | c=0.100000
[Epoch 0011] loss=20.1440 cls=0.7549 smmd=0.4129 ct=7.4739 rec=1.3798 | train/val/test=0.702/0.708/0.691 | c=0.100000
[Epoch 0012] loss=19.8798 cls=0.7218 smmd=0.4063 ct=7.3852 rec=1.3700 | train/val/test=0.707/0.714/0.695 | c=0.100000
[Epoch 0013] loss=20.3981 cls=0.6927 smmd=0.4606 ct=7.3826 rec=1.3605 | train/val/test=0.712/0.717/0.698 | c=0.100000
[Epoch 0014] loss=20.4225 cls=0.6698 smmd=0.4567 ct=7.4223 rec=1.3528 | train/val/test=0.720/0.726/0.708 | c=0.100000
[Epoch 0015] loss=19.9293 cls=0.6487 smmd=0.4017 ct=7.4576 rec=1.3465 | train/val/test=0.732/0.740/0.721 | c=0.100000
[Epoch 0016] loss=19.5864 cls=0.6295 smmd=0.3668 ct=7.4666 rec=1.3406 | train/val/test=0.749/0.761/0.737 | c=0.100000
[Epoch 0017] loss=19.5799 cls=0.6142 smmd=0.3685 ct=7.4600 rec=1.3351 | train/val/test=0.760/0.769/0.744 | c=0.100000
[Epoch 0018] loss=19.5023 cls=0.6023 smmd=0.3635 ct=7.4507 rec=1.3302 | train/val/test=0.764/0.773/0.749 | c=0.100000
[Epoch 0019] loss=19.3656 cls=0.5893 smmd=0.3518 ct=7.4450 rec=1.3261 | train/val/test=0.774/0.779/0.759 | c=0.100000
[Epoch 0020] loss=19.3236 cls=0.5699 smmd=0.3500 ct=7.4385 rec=1.3225 | train/val/test=0.787/0.792/0.773 | c=0.100000
[Epoch 0021] loss=19.2477 cls=0.5449 smmd=0.3465 ct=7.4251 rec=1.3198 | train/val/test=0.798/0.800/0.785 | c=0.100000
[Epoch 0022] loss=18.9246 cls=0.5228 smmd=0.3183 ct=7.4103 rec=1.3182 | train/val/test=0.805/0.810/0.795 | c=0.100000
[Epoch 0023] loss=18.6488 cls=0.5081 smmd=0.2932 ct=7.4025 rec=1.3164 | train/val/test=0.810/0.819/0.797 | c=0.100000
[Epoch 0024] loss=18.5865 cls=0.4978 smmd=0.2872 ct=7.4046 rec=1.3132 | train/val/test=0.812/0.819/0.800 | c=0.100000
[Epoch 0025] loss=18.5262 cls=0.4884 smmd=0.2802 ct=7.4126 rec=1.3092 | train/val/test=0.812/0.816/0.804 | c=0.100000
[Epoch 0026] loss=18.3951 cls=0.4804 smmd=0.2665 ct=7.4182 rec=1.3063 | train/val/test=0.812/0.816/0.806 | c=0.100000
[Epoch 0027] loss=18.2661 cls=0.4746 smmd=0.2549 ct=7.4136 rec=1.3055 | train/val/test=0.816/0.819/0.808 | c=0.100000
[Epoch 0028] loss=18.2115 cls=0.4683 smmd=0.2527 ct=7.3985 rec=1.3055 | train/val/test=0.819/0.825/0.810 | c=0.100000
[Epoch 0029] loss=18.2222 cls=0.4625 smmd=0.2577 ct=7.3804 rec=1.3060 | train/val/test=0.822/0.828/0.814 | c=0.100000
[Epoch 0030] loss=18.2042 cls=0.4592 smmd=0.2578 ct=7.3717 rec=1.3072 | train/val/test=0.824/0.829/0.815 | c=0.100000
[Epoch 0031] loss=18.1619 cls=0.4570 smmd=0.2526 ct=7.3764 rec=1.3081 | train/val/test=0.825/0.829/0.816 | c=0.100000
[Epoch 0032] loss=18.1451 cls=0.4553 smmd=0.2488 ct=7.3873 rec=1.3087 | train/val/test=0.825/0.827/0.815 | c=0.100000
[Epoch 0033] loss=18.1716 cls=0.4547 smmd=0.2501 ct=7.3945 rec=1.3092 | train/val/test=0.826/0.828/0.816 | c=0.100000
[Epoch 0034] loss=18.1584 cls=0.4537 smmd=0.2493 ct=7.3921 rec=1.3092 | train/val/test=0.826/0.830/0.818 | c=0.100000
[Epoch 0035] loss=18.1583 cls=0.4523 smmd=0.2519 ct=7.3795 rec=1.3089 | train/val/test=0.827/0.833/0.818 | c=0.100000
[Epoch 0036] loss=18.0814 cls=0.4515 smmd=0.2474 ct=7.3634 rec=1.3088 | train/val/test=0.827/0.833/0.818 | c=0.100000
[Epoch 0037] loss=18.0425 cls=0.4510 smmd=0.2454 ct=7.3543 rec=1.3083 | train/val/test=0.828/0.832/0.818 | c=0.100000
[Epoch 0038] loss=18.0223 cls=0.4508 smmd=0.2432 ct=7.3558 rec=1.3070 | train/val/test=0.827/0.830/0.817 | c=0.100000
[Epoch 0039] loss=17.9526 cls=0.4515 smmd=0.2349 ct=7.3625 rec=1.3058 | train/val/test=0.826/0.830/0.815 | c=0.100000
[Epoch 0040] loss=17.9065 cls=0.4525 smmd=0.2297 ct=7.3654 rec=1.3053 | train/val/test=0.826/0.832/0.816 | c=0.100000
[Epoch 0041] loss=17.8565 cls=0.4527 smmd=0.2258 ct=7.3598 rec=1.3053 | train/val/test=0.826/0.834/0.816 | c=0.100000
[Epoch 0042] loss=17.8396 cls=0.4526 smmd=0.2262 ct=7.3492 rec=1.3060 | train/val/test=0.826/0.834/0.816 | c=0.100000
[Epoch 0043] loss=17.8334 cls=0.4534 smmd=0.2273 ct=7.3401 rec=1.3068 | train/val/test=0.827/0.833/0.817 | c=0.100000
[Epoch 0044] loss=17.8005 cls=0.4548 smmd=0.2254 ct=7.3330 rec=1.3072 | train/val/test=0.827/0.832/0.816 | c=0.100000
[Epoch 0045] loss=17.7828 cls=0.4560 smmd=0.2238 ct=7.3316 rec=1.3082 | train/val/test=0.827/0.833/0.816 | c=0.100000
[Epoch 0046] loss=17.7749 cls=0.4566 smmd=0.2225 ct=7.3332 rec=1.3098 | train/val/test=0.828/0.833/0.817 | c=0.100000
[Epoch 0047] loss=17.7894 cls=0.4575 smmd=0.2232 ct=7.3364 rec=1.3113 | train/val/test=0.828/0.833/0.817 | c=0.100000
[Epoch 0048] loss=17.7793 cls=0.4587 smmd=0.2221 ct=7.3363 rec=1.3122 | train/val/test=0.828/0.833/0.817 | c=0.100000
[Epoch 0049] loss=17.7861 cls=0.4598 smmd=0.2242 ct=7.3291 rec=1.3128 | train/val/test=0.828/0.832/0.816 | c=0.100000
[Epoch 0050] loss=17.7744 cls=0.4603 smmd=0.2247 ct=7.3203 rec=1.3133 | train/val/test=0.828/0.832/0.817 | c=0.100000
[Epoch 0051] loss=17.7543 cls=0.4605 smmd=0.2237 ct=7.3152 rec=1.3136 | train/val/test=0.828/0.832/0.817 | c=0.100000
[Epoch 0052] loss=17.7363 cls=0.4603 smmd=0.2223 ct=7.3131 rec=1.3136 | train/val/test=0.828/0.833/0.817 | c=0.100000
[Epoch 0053] loss=17.6978 cls=0.4597 smmd=0.2185 ct=7.3133 rec=1.3137 | train/val/test=0.828/0.831/0.816 | c=0.100000
[Epoch 0054] loss=17.6990 cls=0.4589 smmd=0.2188 ct=7.3125 rec=1.3138 | train/val/test=0.829/0.833/0.816 | c=0.100000
[Epoch 0055] loss=17.6717 cls=0.4584 smmd=0.2168 ct=7.3090 rec=1.3135 | train/val/test=0.828/0.832/0.816 | c=0.100000
[Epoch 0056] loss=17.6592 cls=0.4586 smmd=0.2164 ct=7.3048 rec=1.3127 | train/val/test=0.828/0.833/0.814 | c=0.100000
[Epoch 0057] loss=17.6403 cls=0.4590 smmd=0.2151 ct=7.3019 rec=1.3122 | train/val/test=0.828/0.834/0.814 | c=0.100000
[Epoch 0058] loss=17.6611 cls=0.4591 smmd=0.2175 ct=7.3003 rec=1.3121 | train/val/test=0.828/0.833/0.814 | c=0.100000
[Epoch 0059] loss=17.6587 cls=0.4589 smmd=0.2173 ct=7.3002 rec=1.3122 | train/val/test=0.829/0.834/0.815 | c=0.100000
[Epoch 0060] loss=17.6516 cls=0.4585 smmd=0.2169 ct=7.2983 rec=1.3126 | train/val/test=0.829/0.835/0.816 | c=0.100000
[Epoch 0061] loss=17.6610 cls=0.4583 smmd=0.2181 ct=7.2969 rec=1.3131 | train/val/test=0.829/0.834/0.816 | c=0.100000
[Epoch 0062] loss=17.6732 cls=0.4584 smmd=0.2196 ct=7.2958 rec=1.3131 | train/val/test=0.830/0.834/0.815 | c=0.100000
[Epoch 0063] loss=17.6591 cls=0.4586 smmd=0.2190 ct=7.2916 rec=1.3129 | train/val/test=0.829/0.834/0.815 | c=0.100000
[Epoch 0064] loss=17.6598 cls=0.4582 smmd=0.2194 ct=7.2902 rec=1.3129 | train/val/test=0.829/0.834/0.815 | c=0.100000
[Epoch 0065] loss=17.6337 cls=0.4576 smmd=0.2165 ct=7.2919 rec=1.3128 | train/val/test=0.830/0.834/0.815 | c=0.100000
[Epoch 0066] loss=17.6429 cls=0.4574 smmd=0.2173 ct=7.2923 rec=1.3127 | train/val/test=0.829/0.834/0.815 | c=0.100000
[Epoch 0067] loss=17.6268 cls=0.4568 smmd=0.2167 ct=7.2878 rec=1.3125 | train/val/test=0.829/0.835/0.815 | c=0.100000
[Epoch 0068] loss=17.6182 cls=0.4561 smmd=0.2165 ct=7.2844 rec=1.3126 | train/val/test=0.829/0.834/0.815 | c=0.100000
[Epoch 0069] loss=17.6041 cls=0.4557 smmd=0.2155 ct=7.2827 rec=1.3126 | train/val/test=0.829/0.835/0.814 | c=0.100000
[Epoch 0070] loss=17.5923 cls=0.4555 smmd=0.2145 ct=7.2818 rec=1.3125 | train/val/test=0.829/0.834/0.814 | c=0.100000
[Epoch 0071] loss=17.5968 cls=0.4557 smmd=0.2150 ct=7.2812 rec=1.3124 | train/val/test=0.829/0.834/0.815 | c=0.100000
[Epoch 0072] loss=17.6063 cls=0.4557 smmd=0.2161 ct=7.2808 rec=1.3126 | train/val/test=0.829/0.833/0.816 | c=0.100000
[Epoch 0073] loss=17.5904 cls=0.4557 smmd=0.2144 ct=7.2810 rec=1.3129 | train/val/test=0.829/0.833/0.815 | c=0.100000
[Epoch 0074] loss=17.6012 cls=0.4561 smmd=0.2157 ct=7.2796 rec=1.3129 | train/val/test=0.829/0.833/0.816 | c=0.100000
[Epoch 0075] loss=17.5844 cls=0.4563 smmd=0.2144 ct=7.2778 rec=1.3132 | train/val/test=0.829/0.833/0.816 | c=0.100000
[Epoch 0076] loss=17.5984 cls=0.4566 smmd=0.2162 ct=7.2759 rec=1.3134 | train/val/test=0.830/0.834/0.817 | c=0.100000
[Epoch 0077] loss=17.6075 cls=0.4570 smmd=0.2172 ct=7.2752 rec=1.3133 | train/val/test=0.829/0.834/0.816 | c=0.100000
[Epoch 0078] loss=17.5884 cls=0.4572 smmd=0.2151 ct=7.2760 rec=1.3134 | train/val/test=0.829/0.833/0.817 | c=0.100000
[Epoch 0079] loss=17.5804 cls=0.4573 smmd=0.2144 ct=7.2752 rec=1.3135 | train/val/test=0.829/0.833/0.817 | c=0.100000
[Epoch 0080] loss=17.5813 cls=0.4575 smmd=0.2149 ct=7.2733 rec=1.3135 | train/val/test=0.829/0.834/0.817 | c=0.100000
[Epoch 0081] loss=17.5674 cls=0.4578 smmd=0.2136 ct=7.2729 rec=1.3134 | train/val/test=0.829/0.833/0.817 | c=0.100000
[Epoch 0082] loss=17.5556 cls=0.4581 smmd=0.2127 ct=7.2711 rec=1.3135 | train/val/test=0.829/0.833/0.817 | c=0.100000
[Epoch 0083] loss=17.5636 cls=0.4581 smmd=0.2138 ct=7.2698 rec=1.3139 | train/val/test=0.829/0.834/0.817 | c=0.100000
[Epoch 0084] loss=17.5564 cls=0.4585 smmd=0.2131 ct=7.2698 rec=1.3140 | train/val/test=0.828/0.832/0.816 | c=0.100000
[Epoch 0085] loss=17.5590 cls=0.4591 smmd=0.2132 ct=7.2704 rec=1.3140 | train/val/test=0.828/0.833/0.817 | c=0.100000
[Epoch 0086] loss=17.5732 cls=0.4590 smmd=0.2149 ct=7.2685 rec=1.3145 | train/val/test=0.829/0.833/0.817 | c=0.100000
[Epoch 0087] loss=17.5764 cls=0.4595 smmd=0.2154 ct=7.2675 rec=1.3145 | train/val/test=0.828/0.832/0.816 | c=0.100000
[Epoch 0088] loss=17.5541 cls=0.4601 smmd=0.2130 ct=7.2683 rec=1.3143 | train/val/test=0.829/0.833/0.817 | c=0.100000
[Epoch 0089] loss=17.5563 cls=0.4595 smmd=0.2136 ct=7.2663 rec=1.3149 | train/val/test=0.829/0.834/0.817 | c=0.100000
[Epoch 0090] loss=17.5674 cls=0.4597 smmd=0.2150 ct=7.2652 rec=1.3148 | train/val/test=0.829/0.831/0.817 | c=0.100000
[Epoch 0091] loss=17.5474 cls=0.4600 smmd=0.2128 ct=7.2663 rec=1.3147 | train/val/test=0.830/0.833/0.816 | c=0.100000
[Epoch 0092] loss=17.5549 cls=0.4598 smmd=0.2137 ct=7.2654 rec=1.3148 | train/val/test=0.830/0.833/0.817 | c=0.100000
[Epoch 0093] loss=17.5392 cls=0.4601 smmd=0.2125 ct=7.2632 rec=1.3146 | train/val/test=0.829/0.832/0.817 | c=0.100000
[Epoch 0094] loss=17.5490 cls=0.4600 smmd=0.2138 ct=7.2620 rec=1.3148 | train/val/test=0.828/0.833/0.816 | c=0.100000
[Epoch 0095] loss=17.5324 cls=0.4600 smmd=0.2120 ct=7.2624 rec=1.3150 | train/val/test=0.829/0.832/0.816 | c=0.100000
[Epoch 0096] loss=17.5332 cls=0.4603 smmd=0.2122 ct=7.2619 rec=1.3148 | train/val/test=0.829/0.833/0.817 | c=0.100000
[Epoch 0097] loss=17.5309 cls=0.4606 smmd=0.2117 ct=7.2630 rec=1.3148 | train/val/test=0.828/0.832/0.816 | c=0.100000
[Epoch 0098] loss=17.5323 cls=0.4608 smmd=0.2121 ct=7.2617 rec=1.3150 | train/val/test=0.829/0.835/0.817 | c=0.100000
[Epoch 0099] loss=17.5381 cls=0.4607 smmd=0.2131 ct=7.2594 rec=1.3153 | train/val/test=0.829/0.834/0.816 | c=0.100000
=== Best @ epoch 60: val=0.8354, test=0.8157 ===
