Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=57.3021 cls=1.1145 smmd=4.1519 ct=7.2595 rec=1.4138 | train/val/test=0.578/0.572/0.574 | c=0.500000
[Epoch 0001] loss=33.0350 cls=1.0610 smmd=1.7350 ct=7.2236 rec=1.4154 | train/val/test=0.594/0.588/0.588 | c=0.500000
[Epoch 0002] loss=23.1488 cls=1.0774 smmd=0.7611 ct=7.1462 rec=1.4136 | train/val/test=0.555/0.530/0.543 | c=0.500000
[Epoch 0003] loss=26.7214 cls=1.0784 smmd=1.1193 ct=7.1413 rec=1.4134 | train/val/test=0.602/0.595/0.598 | c=0.500000
[Epoch 0004] loss=25.5326 cls=1.0309 smmd=1.0082 ct=7.1140 rec=1.4140 | train/val/test=0.590/0.582/0.583 | c=0.500000
[Epoch 0005] loss=22.9474 cls=1.0019 smmd=0.7571 ct=7.0833 rec=1.4180 | train/val/test=0.577/0.571/0.572 | c=0.500000
[Epoch 0006] loss=20.7474 cls=0.9924 smmd=0.5405 ct=7.0679 rec=1.4209 | train/val/test=0.569/0.568/0.567 | c=0.500000
[Epoch 0007] loss=20.8218 cls=0.9690 smmd=0.5522 ct=7.0529 rec=1.4197 | train/val/test=0.569/0.563/0.561 | c=0.500000
[Epoch 0008] loss=22.0125 cls=0.9244 smmd=0.6795 ct=7.0239 rec=1.4145 | train/val/test=0.567/0.561/0.563 | c=0.500000
[Epoch 0009] loss=21.8961 cls=0.8701 smmd=0.6787 ct=6.9854 rec=1.4064 | train/val/test=0.625/0.615/0.619 | c=0.500000
[Epoch 0010] loss=20.1797 cls=0.8189 smmd=0.5193 ct=6.9397 rec=1.3965 | train/val/test=0.680/0.668/0.675 | c=0.500000
[Epoch 0011] loss=18.6347 cls=0.7773 smmd=0.3756 ct=6.8985 rec=1.3861 | train/val/test=0.696/0.678/0.689 | c=0.500000
[Epoch 0012] loss=18.6740 cls=0.7445 smmd=0.3832 ct=6.8905 rec=1.3765 | train/val/test=0.703/0.685/0.692 | c=0.500000
[Epoch 0013] loss=19.2585 cls=0.7174 smmd=0.4406 ct=6.9048 rec=1.3687 | train/val/test=0.710/0.694/0.702 | c=0.500000
[Epoch 0014] loss=19.0634 cls=0.6920 smmd=0.4223 ct=6.9070 rec=1.3610 | train/val/test=0.718/0.705/0.716 | c=0.500000
[Epoch 0015] loss=18.4370 cls=0.6699 smmd=0.3632 ct=6.8967 rec=1.3526 | train/val/test=0.731/0.717/0.730 | c=0.500000
[Epoch 0016] loss=18.2104 cls=0.6549 smmd=0.3435 ct=6.8877 rec=1.3445 | train/val/test=0.736/0.728/0.734 | c=0.500000
[Epoch 0017] loss=18.3469 cls=0.6452 smmd=0.3595 ct=6.8804 rec=1.3379 | train/val/test=0.743/0.735/0.744 | c=0.500000
[Epoch 0018] loss=18.2211 cls=0.6322 smmd=0.3503 ct=6.8679 rec=1.3327 | train/val/test=0.756/0.748/0.753 | c=0.500000
[Epoch 0019] loss=17.9872 cls=0.6102 smmd=0.3304 ct=6.8570 rec=1.3284 | train/val/test=0.770/0.763/0.768 | c=0.500000
[Epoch 0020] loss=17.9729 cls=0.5857 smmd=0.3309 ct=6.8542 rec=1.3252 | train/val/test=0.780/0.775/0.780 | c=0.500000
[Epoch 0021] loss=17.9422 cls=0.5662 smmd=0.3295 ct=6.8517 rec=1.3218 | train/val/test=0.786/0.781/0.783 | c=0.500000
[Epoch 0022] loss=17.6147 cls=0.5516 smmd=0.2993 ct=6.8437 rec=1.3173 | train/val/test=0.789/0.784/0.783 | c=0.500000
[Epoch 0023] loss=17.3281 cls=0.5413 smmd=0.2730 ct=6.8355 rec=1.3126 | train/val/test=0.794/0.783/0.788 | c=0.500000
[Epoch 0024] loss=17.3082 cls=0.5318 smmd=0.2727 ct=6.8303 rec=1.3091 | train/val/test=0.800/0.787/0.795 | c=0.500000
[Epoch 0025] loss=17.2730 cls=0.5189 smmd=0.2712 ct=6.8240 rec=1.3068 | train/val/test=0.807/0.791/0.803 | c=0.500000
[Epoch 0026] loss=17.1059 cls=0.5042 smmd=0.2569 ct=6.8162 rec=1.3056 | train/val/test=0.812/0.797/0.813 | c=0.500000
[Epoch 0027] loss=17.0097 cls=0.4914 smmd=0.2490 ct=6.8109 rec=1.3054 | train/val/test=0.815/0.803/0.817 | c=0.500000
[Epoch 0028] loss=16.9992 cls=0.4824 smmd=0.2487 ct=6.8093 rec=1.3055 | train/val/test=0.817/0.806/0.821 | c=0.500000
[Epoch 0029] loss=16.9540 cls=0.4766 smmd=0.2445 ct=6.8092 rec=1.3055 | train/val/test=0.819/0.808/0.821 | c=0.500000
[Epoch 0030] loss=16.9041 cls=0.4728 smmd=0.2398 ct=6.8087 rec=1.3052 | train/val/test=0.820/0.811/0.822 | c=0.500000
[Epoch 0031] loss=16.9535 cls=0.4698 smmd=0.2452 ct=6.8071 rec=1.3051 | train/val/test=0.821/0.812/0.822 | c=0.500000
[Epoch 0032] loss=16.9756 cls=0.4664 smmd=0.2479 ct=6.8051 rec=1.3056 | train/val/test=0.823/0.814/0.824 | c=0.500000
[Epoch 0033] loss=16.9076 cls=0.4632 smmd=0.2415 ct=6.8036 rec=1.3066 | train/val/test=0.824/0.816/0.824 | c=0.500000
[Epoch 0034] loss=16.8773 cls=0.4610 smmd=0.2388 ct=6.8027 rec=1.3076 | train/val/test=0.824/0.817/0.824 | c=0.500000
[Epoch 0035] loss=16.9127 cls=0.4592 smmd=0.2426 ct=6.8016 rec=1.3077 | train/val/test=0.825/0.815/0.825 | c=0.500000
[Epoch 0036] loss=16.8834 cls=0.4574 smmd=0.2404 ct=6.7989 rec=1.3069 | train/val/test=0.825/0.819/0.826 | c=0.500000
[Epoch 0037] loss=16.8216 cls=0.4558 smmd=0.2350 ct=6.7957 rec=1.3056 | train/val/test=0.825/0.816/0.825 | c=0.500000
[Epoch 0038] loss=16.7732 cls=0.4548 smmd=0.2307 ct=6.7935 rec=1.3044 | train/val/test=0.825/0.815/0.825 | c=0.500000
[Epoch 0039] loss=16.7716 cls=0.4542 smmd=0.2310 ct=6.7915 rec=1.3034 | train/val/test=0.824/0.816/0.825 | c=0.500000
[Epoch 0040] loss=16.7010 cls=0.4532 smmd=0.2242 ct=6.7905 rec=1.3033 | train/val/test=0.824/0.817/0.826 | c=0.500000
[Epoch 0041] loss=16.6650 cls=0.4524 smmd=0.2209 ct=6.7892 rec=1.3035 | train/val/test=0.825/0.818/0.827 | c=0.500000
[Epoch 0042] loss=16.6547 cls=0.4523 smmd=0.2203 ct=6.7870 rec=1.3036 | train/val/test=0.825/0.816/0.826 | c=0.500000
[Epoch 0043] loss=16.6395 cls=0.4526 smmd=0.2192 ct=6.7845 rec=1.3036 | train/val/test=0.824/0.814/0.825 | c=0.500000
[Epoch 0044] loss=18.0544 cls=0.4534 smmd=0.2195 ct=7.4903 rec=1.3036 | train/val/test=0.824/0.815/0.826 | c=0.500000
[Epoch 0045] loss=18.0042 cls=0.4557 smmd=0.2285 ct=7.4200 rec=1.3035 | train/val/test=0.824/0.814/0.825 | c=0.500000
[Epoch 0046] loss=18.0361 cls=0.4578 smmd=0.2385 ct=7.3853 rec=1.3041 | train/val/test=0.825/0.815/0.825 | c=0.500000
[Epoch 0047] loss=18.0143 cls=0.4570 smmd=0.2330 ct=7.4015 rec=1.3053 | train/val/test=0.826/0.817/0.826 | c=0.500000
[Epoch 0048] loss=18.0143 cls=0.4561 smmd=0.2278 ct=7.4276 rec=1.3069 | train/val/test=0.825/0.817/0.826 | c=0.500000
[Epoch 0049] loss=18.0135 cls=0.4565 smmd=0.2261 ct=7.4349 rec=1.3080 | train/val/test=0.826/0.817/0.827 | c=0.500000
[Epoch 0050] loss=17.9938 cls=0.4570 smmd=0.2253 ct=7.4292 rec=1.3086 | train/val/test=0.826/0.818/0.825 | c=0.500000
[Epoch 0051] loss=17.9690 cls=0.4575 smmd=0.2247 ct=7.4193 rec=1.3088 | train/val/test=0.827/0.818/0.825 | c=0.500000
[Epoch 0052] loss=17.9504 cls=0.4582 smmd=0.2243 ct=7.4118 rec=1.3089 | train/val/test=0.827/0.819/0.825 | c=0.500000
[Epoch 0053] loss=17.9255 cls=0.4586 smmd=0.2222 ct=7.4100 rec=1.3087 | train/val/test=0.826/0.818/0.825 | c=0.500000
[Epoch 0054] loss=17.8928 cls=0.4579 smmd=0.2190 ct=7.4098 rec=1.3087 | train/val/test=0.826/0.819/0.825 | c=0.500000
[Epoch 0055] loss=17.8872 cls=0.4577 smmd=0.2187 ct=7.4086 rec=1.3086 | train/val/test=0.826/0.818/0.827 | c=0.500000
[Epoch 0056] loss=17.8632 cls=0.4579 smmd=0.2167 ct=7.4066 rec=1.3082 | train/val/test=0.826/0.818/0.827 | c=0.500000
[Epoch 0057] loss=17.8667 cls=0.4582 smmd=0.2180 ct=7.4017 rec=1.3079 | train/val/test=0.826/0.816/0.826 | c=0.500000
[Epoch 0058] loss=17.8423 cls=0.4587 smmd=0.2167 ct=7.3961 rec=1.3076 | train/val/test=0.826/0.817/0.825 | c=0.500000
[Epoch 0059] loss=17.8460 cls=0.4589 smmd=0.2173 ct=7.3951 rec=1.3075 | train/val/test=0.826/0.818/0.825 | c=0.500000
[Epoch 0060] loss=17.8583 cls=0.4589 smmd=0.2176 ct=7.3995 rec=1.3077 | train/val/test=0.826/0.817/0.826 | c=0.500000
[Epoch 0061] loss=17.8592 cls=0.4586 smmd=0.2175 ct=7.4003 rec=1.3078 | train/val/test=0.826/0.816/0.826 | c=0.500000
[Epoch 0062] loss=17.8680 cls=0.4587 smmd=0.2191 ct=7.3970 rec=1.3077 | train/val/test=0.826/0.816/0.826 | c=0.500000
[Epoch 0063] loss=17.8512 cls=0.4589 smmd=0.2183 ct=7.3926 rec=1.3072 | train/val/test=0.826/0.817/0.826 | c=0.500000
[Epoch 0064] loss=17.8407 cls=0.4589 smmd=0.2189 ct=7.3844 rec=1.3068 | train/val/test=0.826/0.817/0.826 | c=0.500000
[Epoch 0065] loss=17.8357 cls=0.4578 smmd=0.2196 ct=7.3787 rec=1.3070 | train/val/test=0.827/0.818/0.826 | c=0.500000
[Epoch 0066] loss=17.8148 cls=0.4568 smmd=0.2168 ct=7.3826 rec=1.3071 | train/val/test=0.827/0.817/0.826 | c=0.500000
[Epoch 0067] loss=17.7992 cls=0.4563 smmd=0.2147 ct=7.3853 rec=1.3069 | train/val/test=0.827/0.819/0.826 | c=0.500000
[Epoch 0068] loss=17.7782 cls=0.4560 smmd=0.2132 ct=7.3826 rec=1.3067 | train/val/test=0.827/0.819/0.826 | c=0.500000
[Epoch 0069] loss=17.7797 cls=0.4558 smmd=0.2141 ct=7.3785 rec=1.3065 | train/val/test=0.827/0.819/0.826 | c=0.500000
[Epoch 0070] loss=17.7712 cls=0.4555 smmd=0.2141 ct=7.3745 rec=1.3066 | train/val/test=0.827/0.819/0.826 | c=0.500000
[Epoch 0071] loss=17.7771 cls=0.4549 smmd=0.2153 ct=7.3713 rec=1.3070 | train/val/test=0.827/0.819/0.827 | c=0.500000
[Epoch 0072] loss=17.7754 cls=0.4544 smmd=0.2153 ct=7.3707 rec=1.3074 | train/val/test=0.828/0.819/0.826 | c=0.500000
[Epoch 0073] loss=17.7575 cls=0.4542 smmd=0.2133 ct=7.3717 rec=1.3076 | train/val/test=0.828/0.819/0.826 | c=0.500000
[Epoch 0074] loss=17.7718 cls=0.4542 smmd=0.2153 ct=7.3687 rec=1.3078 | train/val/test=0.828/0.819/0.827 | c=0.500000
[Epoch 0075] loss=17.7782 cls=0.4541 smmd=0.2164 ct=7.3665 rec=1.3079 | train/val/test=0.828/0.819/0.827 | c=0.500000
[Epoch 0076] loss=17.7646 cls=0.4539 smmd=0.2154 ct=7.3651 rec=1.3080 | train/val/test=0.828/0.820/0.827 | c=0.500000
[Epoch 0077] loss=17.7582 cls=0.4536 smmd=0.2150 ct=7.3634 rec=1.3082 | train/val/test=0.828/0.819/0.826 | c=0.500000
[Epoch 0078] loss=17.7518 cls=0.4534 smmd=0.2145 ct=7.3630 rec=1.3082 | train/val/test=0.828/0.819/0.827 | c=0.500000
[Epoch 0079] loss=17.7384 cls=0.4530 smmd=0.2137 ct=7.3603 rec=1.3083 | train/val/test=0.828/0.819/0.827 | c=0.500000
[Epoch 0080] loss=17.7293 cls=0.4531 smmd=0.2134 ct=7.3573 rec=1.3082 | train/val/test=0.829/0.820/0.827 | c=0.500000
[Epoch 0081] loss=17.7266 cls=0.4529 smmd=0.2132 ct=7.3572 rec=1.3083 | train/val/test=0.829/0.820/0.827 | c=0.500000
[Epoch 0082] loss=17.7183 cls=0.4528 smmd=0.2125 ct=7.3563 rec=1.3085 | train/val/test=0.829/0.819/0.828 | c=0.500000
[Epoch 0083] loss=17.7148 cls=0.4533 smmd=0.2128 ct=7.3528 rec=1.3084 | train/val/test=0.829/0.819/0.828 | c=0.500000
[Epoch 0084] loss=17.7211 cls=0.4532 smmd=0.2136 ct=7.3520 rec=1.3088 | train/val/test=0.830/0.822/0.828 | c=0.500000
[Epoch 0085] loss=17.7157 cls=0.4531 smmd=0.2131 ct=7.3517 rec=1.3094 | train/val/test=0.830/0.820/0.828 | c=0.500000
[Epoch 0086] loss=17.7278 cls=0.4533 smmd=0.2146 ct=7.3502 rec=1.3095 | train/val/test=0.829/0.819/0.829 | c=0.500000
[Epoch 0087] loss=17.7161 cls=0.4536 smmd=0.2137 ct=7.3486 rec=1.3096 | train/val/test=0.830/0.823/0.828 | c=0.500000
[Epoch 0088] loss=17.7098 cls=0.4535 smmd=0.2134 ct=7.3473 rec=1.3099 | train/val/test=0.829/0.819/0.829 | c=0.500000
[Epoch 0089] loss=17.6961 cls=0.4538 smmd=0.2126 ct=7.3440 rec=1.3097 | train/val/test=0.829/0.820/0.829 | c=0.500000
[Epoch 0090] loss=17.7094 cls=0.4537 smmd=0.2144 ct=7.3418 rec=1.3099 | train/val/test=0.830/0.821/0.829 | c=0.500000
[Epoch 0091] loss=17.6967 cls=0.4532 smmd=0.2132 ct=7.3414 rec=1.3103 | train/val/test=0.829/0.821/0.830 | c=0.500000
[Epoch 0092] loss=17.7024 cls=0.4532 smmd=0.2138 ct=7.3413 rec=1.3103 | train/val/test=0.829/0.821/0.830 | c=0.500000
[Epoch 0093] loss=17.6770 cls=0.4535 smmd=0.2117 ct=7.3393 rec=1.3102 | train/val/test=0.830/0.822/0.830 | c=0.500000
[Epoch 0094] loss=17.6759 cls=0.4534 smmd=0.2118 ct=7.3378 rec=1.3104 | train/val/test=0.830/0.821/0.830 | c=0.500000
[Epoch 0095] loss=17.6696 cls=0.4535 smmd=0.2117 ct=7.3355 rec=1.3106 | train/val/test=0.830/0.821/0.830 | c=0.500000
[Epoch 0096] loss=17.6763 cls=0.4536 smmd=0.2127 ct=7.3333 rec=1.3109 | train/val/test=0.830/0.821/0.831 | c=0.500000
[Epoch 0097] loss=17.6800 cls=0.4538 smmd=0.2130 ct=7.3339 rec=1.3112 | train/val/test=0.830/0.821/0.831 | c=0.500000
[Epoch 0098] loss=17.6745 cls=0.4542 smmd=0.2125 ct=7.3336 rec=1.3113 | train/val/test=0.830/0.822/0.831 | c=0.500000
[Epoch 0099] loss=17.6632 cls=0.4543 smmd=0.2122 ct=7.3293 rec=1.3116 | train/val/test=0.830/0.823/0.831 | c=0.500000
=== Best @ epoch 87: val=0.8227, test=0.8283 ===
