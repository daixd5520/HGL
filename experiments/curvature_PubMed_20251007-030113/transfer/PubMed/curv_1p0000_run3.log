Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=57.7498 cls=1.0853 smmd=4.1988 ct=7.2562 rec=1.4139 | train/val/test=0.403/0.390/0.397 | c=0.998905
[Epoch 0001] loss=33.9691 cls=1.0578 smmd=1.8318 ct=7.2069 rec=1.4167 | train/val/test=0.575/0.578/0.563 | c=0.998905
[Epoch 0002] loss=22.8985 cls=1.0639 smmd=0.7441 ct=7.1094 rec=1.4142 | train/val/test=0.587/0.592/0.580 | c=0.998905
[Epoch 0003] loss=26.3651 cls=1.0577 smmd=1.0879 ct=7.1252 rec=1.4137 | train/val/test=0.582/0.583/0.580 | c=0.998905
[Epoch 0004] loss=25.6681 cls=1.0225 smmd=1.0245 ct=7.1021 rec=1.4148 | train/val/test=0.575/0.574/0.570 | c=0.998905
[Epoch 0005] loss=23.1319 cls=0.9928 smmd=0.7809 ct=7.0590 rec=1.4177 | train/val/test=0.575/0.574/0.571 | c=0.998905
[Epoch 0006] loss=20.5450 cls=0.9698 smmd=0.5316 ct=7.0173 rec=1.4194 | train/val/test=0.569/0.568/0.566 | c=0.998905
[Epoch 0007] loss=20.7596 cls=0.9379 smmd=0.5602 ct=6.9901 rec=1.4177 | train/val/test=0.557/0.555/0.555 | c=0.998905
[Epoch 0008] loss=23.3846 cls=0.8954 smmd=0.6939 ct=7.6456 rec=1.4127 | train/val/test=0.576/0.569/0.584 | c=0.998905
[Epoch 0009] loss=22.9636 cls=0.8511 smmd=0.6828 ct=7.5034 rec=1.4055 | train/val/test=0.645/0.634/0.652 | c=0.998905
[Epoch 0010] loss=21.4612 cls=0.8107 smmd=0.5552 ct=7.4025 rec=1.3972 | train/val/test=0.669/0.666/0.680 | c=0.998905
[Epoch 0011] loss=20.1366 cls=0.7746 smmd=0.4260 ct=7.3979 rec=1.3879 | train/val/test=0.680/0.679/0.691 | c=0.998905
[Epoch 0012] loss=20.0802 cls=0.7425 smmd=0.4141 ct=7.4395 rec=1.3781 | train/val/test=0.688/0.690/0.691 | c=0.998905
[Epoch 0013] loss=20.4922 cls=0.7173 smmd=0.4520 ct=7.4646 rec=1.3683 | train/val/test=0.694/0.699/0.696 | c=0.998905
[Epoch 0014] loss=20.2894 cls=0.7006 smmd=0.4342 ct=7.4588 rec=1.3591 | train/val/test=0.695/0.701/0.704 | c=0.998905
[Epoch 0015] loss=19.7292 cls=0.6897 smmd=0.3816 ct=7.4466 rec=1.3511 | train/val/test=0.699/0.704/0.712 | c=0.998905
[Epoch 0016] loss=19.5485 cls=0.6772 smmd=0.3644 ct=7.4465 rec=1.3448 | train/val/test=0.709/0.714/0.720 | c=0.998905
[Epoch 0017] loss=19.6211 cls=0.6568 smmd=0.3725 ct=7.4487 rec=1.3401 | train/val/test=0.728/0.731/0.733 | c=0.998905
[Epoch 0018] loss=19.5565 cls=0.6333 smmd=0.3683 ct=7.4440 rec=1.3370 | train/val/test=0.740/0.743/0.740 | c=0.998905
[Epoch 0019] loss=19.3995 cls=0.6136 smmd=0.3559 ct=7.4330 rec=1.3347 | train/val/test=0.753/0.754/0.752 | c=0.998905
[Epoch 0020] loss=19.2218 cls=0.5945 smmd=0.3419 ct=7.4202 rec=1.3310 | train/val/test=0.769/0.767/0.770 | c=0.998905
[Epoch 0021] loss=19.0198 cls=0.5775 smmd=0.3246 ct=7.4109 rec=1.3265 | train/val/test=0.779/0.777/0.784 | c=0.998905
[Epoch 0022] loss=18.8290 cls=0.5648 smmd=0.3068 ct=7.4084 rec=1.3226 | train/val/test=0.787/0.787/0.794 | c=0.998905
[Epoch 0023] loss=18.7223 cls=0.5512 smmd=0.2965 ct=7.4112 rec=1.3195 | train/val/test=0.794/0.795/0.801 | c=0.998905
[Epoch 0024] loss=18.6104 cls=0.5343 smmd=0.2863 ct=7.4106 rec=1.3174 | train/val/test=0.799/0.800/0.808 | c=0.998905
[Epoch 0025] loss=18.4267 cls=0.5181 smmd=0.2700 ct=7.4047 rec=1.3162 | train/val/test=0.805/0.805/0.810 | c=0.998905
[Epoch 0026] loss=18.3027 cls=0.5054 smmd=0.2604 ct=7.3941 rec=1.3151 | train/val/test=0.808/0.806/0.811 | c=0.998905
[Epoch 0027] loss=18.2525 cls=0.4959 smmd=0.2581 ct=7.3832 rec=1.3140 | train/val/test=0.810/0.811/0.811 | c=0.998905
[Epoch 0028] loss=18.2345 cls=0.4891 smmd=0.2574 ct=7.3795 rec=1.3135 | train/val/test=0.812/0.812/0.813 | c=0.998905
[Epoch 0029] loss=18.2089 cls=0.4831 smmd=0.2542 ct=7.3844 rec=1.3136 | train/val/test=0.815/0.815/0.815 | c=0.998905
[Epoch 0030] loss=18.1516 cls=0.4781 smmd=0.2476 ct=7.3896 rec=1.3142 | train/val/test=0.818/0.820/0.816 | c=0.998905
[Epoch 0031] loss=18.1307 cls=0.4754 smmd=0.2466 ct=7.3848 rec=1.3158 | train/val/test=0.820/0.822/0.818 | c=0.998905
[Epoch 0032] loss=18.1318 cls=0.4733 smmd=0.2491 ct=7.3726 rec=1.3171 | train/val/test=0.820/0.824/0.818 | c=0.998905
[Epoch 0033] loss=18.1441 cls=0.4711 smmd=0.2524 ct=7.3630 rec=1.3173 | train/val/test=0.819/0.823/0.817 | c=0.998905
[Epoch 0034] loss=18.1255 cls=0.4699 smmd=0.2511 ct=7.3605 rec=1.3167 | train/val/test=0.820/0.823/0.819 | c=0.998905
[Epoch 0035] loss=18.1109 cls=0.4689 smmd=0.2493 ct=7.3625 rec=1.3158 | train/val/test=0.820/0.824/0.821 | c=0.998905
[Epoch 0036] loss=18.0713 cls=0.4676 smmd=0.2450 ct=7.3649 rec=1.3146 | train/val/test=0.821/0.826/0.823 | c=0.998905
[Epoch 0037] loss=18.0116 cls=0.4661 smmd=0.2392 ct=7.3648 rec=1.3137 | train/val/test=0.822/0.826/0.824 | c=0.998905
[Epoch 0038] loss=17.9915 cls=0.4649 smmd=0.2379 ct=7.3614 rec=1.3134 | train/val/test=0.822/0.826/0.824 | c=0.998905
[Epoch 0039] loss=17.9349 cls=0.4646 smmd=0.2339 ct=7.3533 rec=1.3131 | train/val/test=0.822/0.827/0.825 | c=0.998905
[Epoch 0040] loss=17.8639 cls=0.4647 smmd=0.2290 ct=7.3425 rec=1.3126 | train/val/test=0.821/0.825/0.825 | c=0.998905
[Epoch 0041] loss=17.8446 cls=0.4651 smmd=0.2287 ct=7.3347 rec=1.3118 | train/val/test=0.822/0.825/0.825 | c=0.998905
[Epoch 0042] loss=17.8037 cls=0.4659 smmd=0.2249 ct=7.3328 rec=1.3116 | train/val/test=0.823/0.826/0.826 | c=0.998905
[Epoch 0043] loss=17.8005 cls=0.4669 smmd=0.2241 ct=7.3349 rec=1.3122 | train/val/test=0.824/0.824/0.827 | c=0.998905
[Epoch 0044] loss=17.7940 cls=0.4680 smmd=0.2225 ct=7.3390 rec=1.3131 | train/val/test=0.824/0.824/0.828 | c=0.998905
[Epoch 0045] loss=17.7980 cls=0.4694 smmd=0.2228 ct=7.3388 rec=1.3143 | train/val/test=0.824/0.825/0.827 | c=0.998905
[Epoch 0046] loss=17.7948 cls=0.4707 smmd=0.2237 ct=7.3321 rec=1.3156 | train/val/test=0.824/0.825/0.828 | c=0.998905
[Epoch 0047] loss=17.7835 cls=0.4722 smmd=0.2239 ct=7.3252 rec=1.3169 | train/val/test=0.823/0.824/0.828 | c=0.998905
[Epoch 0048] loss=17.8204 cls=0.4738 smmd=0.2283 ct=7.3207 rec=1.3178 | train/val/test=0.823/0.825/0.827 | c=0.998905
[Epoch 0049] loss=17.7953 cls=0.4747 smmd=0.2263 ct=7.3181 rec=1.3185 | train/val/test=0.824/0.826/0.826 | c=0.998905
[Epoch 0050] loss=17.7911 cls=0.4750 smmd=0.2260 ct=7.3169 rec=1.3193 | train/val/test=0.823/0.826/0.825 | c=0.998905
[Epoch 0051] loss=17.7704 cls=0.4751 smmd=0.2238 ct=7.3177 rec=1.3196 | train/val/test=0.823/0.824/0.826 | c=0.998905
[Epoch 0052] loss=17.7591 cls=0.4751 smmd=0.2225 ct=7.3186 rec=1.3196 | train/val/test=0.823/0.824/0.825 | c=0.998905
[Epoch 0053] loss=17.7172 cls=0.4748 smmd=0.2189 ct=7.3154 rec=1.3193 | train/val/test=0.823/0.826/0.825 | c=0.998905
[Epoch 0054] loss=17.7058 cls=0.4748 smmd=0.2191 ct=7.3092 rec=1.3189 | train/val/test=0.823/0.824/0.824 | c=0.998905
[Epoch 0055] loss=17.6658 cls=0.4746 smmd=0.2162 ct=7.3036 rec=1.3186 | train/val/test=0.823/0.824/0.824 | c=0.998905
[Epoch 0056] loss=17.6747 cls=0.4742 smmd=0.2176 ct=7.3013 rec=1.3184 | train/val/test=0.823/0.825/0.826 | c=0.998905
[Epoch 0057] loss=17.6633 cls=0.4737 smmd=0.2165 ct=7.3009 rec=1.3185 | train/val/test=0.823/0.825/0.826 | c=0.998905
[Epoch 0058] loss=17.6612 cls=0.4737 smmd=0.2163 ct=7.3009 rec=1.3184 | train/val/test=0.823/0.824/0.826 | c=0.998905
[Epoch 0059] loss=17.6716 cls=0.4739 smmd=0.2173 ct=7.3011 rec=1.3183 | train/val/test=0.823/0.825/0.825 | c=0.998905
[Epoch 0060] loss=17.6757 cls=0.4740 smmd=0.2177 ct=7.3011 rec=1.3185 | train/val/test=0.823/0.826/0.825 | c=0.998905
[Epoch 0061] loss=17.6821 cls=0.4740 smmd=0.2189 ct=7.2981 rec=1.3187 | train/val/test=0.824/0.824/0.825 | c=0.998905
[Epoch 0062] loss=17.6972 cls=0.4739 smmd=0.2211 ct=7.2947 rec=1.3187 | train/val/test=0.824/0.824/0.825 | c=0.998905
[Epoch 0063] loss=17.6841 cls=0.4737 smmd=0.2200 ct=7.2938 rec=1.3186 | train/val/test=0.824/0.825/0.825 | c=0.998905
[Epoch 0064] loss=17.6808 cls=0.4734 smmd=0.2199 ct=7.2928 rec=1.3184 | train/val/test=0.825/0.826/0.825 | c=0.998905
[Epoch 0065] loss=17.6677 cls=0.4726 smmd=0.2190 ct=7.2911 rec=1.3184 | train/val/test=0.824/0.826/0.825 | c=0.998905
[Epoch 0066] loss=17.6618 cls=0.4720 smmd=0.2189 ct=7.2889 rec=1.3182 | train/val/test=0.824/0.824/0.826 | c=0.998905
[Epoch 0067] loss=17.6395 cls=0.4717 smmd=0.2170 ct=7.2873 rec=1.3179 | train/val/test=0.824/0.825/0.827 | c=0.998905
[Epoch 0068] loss=17.6257 cls=0.4714 smmd=0.2159 ct=7.2861 rec=1.3177 | train/val/test=0.824/0.825/0.827 | c=0.998905
[Epoch 0069] loss=17.6222 cls=0.4712 smmd=0.2155 ct=7.2865 rec=1.3177 | train/val/test=0.824/0.827/0.826 | c=0.998905
[Epoch 0070] loss=17.6116 cls=0.4706 smmd=0.2149 ct=7.2842 rec=1.3181 | train/val/test=0.824/0.828/0.826 | c=0.998905
[Epoch 0071] loss=17.6098 cls=0.4707 smmd=0.2152 ct=7.2816 rec=1.3184 | train/val/test=0.824/0.825/0.826 | c=0.998905
[Epoch 0072] loss=17.6099 cls=0.4715 smmd=0.2155 ct=7.2802 rec=1.3183 | train/val/test=0.824/0.826/0.824 | c=0.998905
[Epoch 0073] loss=17.6141 cls=0.4718 smmd=0.2162 ct=7.2784 rec=1.3185 | train/val/test=0.824/0.827/0.826 | c=0.998905
[Epoch 0074] loss=17.6176 cls=0.4720 smmd=0.2166 ct=7.2782 rec=1.3190 | train/val/test=0.824/0.827/0.825 | c=0.998905
[Epoch 0075] loss=17.6109 cls=0.4724 smmd=0.2159 ct=7.2782 rec=1.3192 | train/val/test=0.825/0.827/0.825 | c=0.998905
[Epoch 0076] loss=17.6355 cls=0.4725 smmd=0.2184 ct=7.2776 rec=1.3194 | train/val/test=0.824/0.828/0.826 | c=0.998905
[Epoch 0077] loss=17.6252 cls=0.4725 smmd=0.2176 ct=7.2765 rec=1.3195 | train/val/test=0.824/0.827/0.825 | c=0.998905
[Epoch 0078] loss=17.6197 cls=0.4728 smmd=0.2174 ct=7.2751 rec=1.3191 | train/val/test=0.824/0.825/0.827 | c=0.998905
[Epoch 0079] loss=17.5930 cls=0.4728 smmd=0.2152 ct=7.2725 rec=1.3190 | train/val/test=0.824/0.826/0.825 | c=0.998905
[Epoch 0080] loss=17.5892 cls=0.4728 smmd=0.2154 ct=7.2697 rec=1.3189 | train/val/test=0.824/0.828/0.825 | c=0.998905
[Epoch 0081] loss=17.5826 cls=0.4726 smmd=0.2146 ct=7.2703 rec=1.3190 | train/val/test=0.824/0.827/0.826 | c=0.998905
[Epoch 0082] loss=17.5724 cls=0.4728 smmd=0.2133 ct=7.2716 rec=1.3191 | train/val/test=0.824/0.826/0.826 | c=0.998905
[Epoch 0083] loss=17.5934 cls=0.4735 smmd=0.2157 ct=7.2702 rec=1.3191 | train/val/test=0.824/0.828/0.825 | c=0.998905
[Epoch 0084] loss=17.5961 cls=0.4738 smmd=0.2160 ct=7.2696 rec=1.3193 | train/val/test=0.825/0.827/0.826 | c=0.998905
[Epoch 0085] loss=17.5928 cls=0.4741 smmd=0.2158 ct=7.2688 rec=1.3197 | train/val/test=0.824/0.827/0.826 | c=0.998905
[Epoch 0086] loss=17.5960 cls=0.4745 smmd=0.2166 ct=7.2666 rec=1.3198 | train/val/test=0.825/0.828/0.825 | c=0.998905
[Epoch 0087] loss=17.5989 cls=0.4747 smmd=0.2170 ct=7.2657 rec=1.3200 | train/val/test=0.824/0.827/0.826 | c=0.998905
[Epoch 0088] loss=17.5904 cls=0.4749 smmd=0.2161 ct=7.2660 rec=1.3200 | train/val/test=0.825/0.825/0.826 | c=0.998905
[Epoch 0089] loss=17.5933 cls=0.4751 smmd=0.2166 ct=7.2650 rec=1.3200 | train/val/test=0.825/0.828/0.824 | c=0.998905
[Epoch 0090] loss=17.5779 cls=0.4750 smmd=0.2150 ct=7.2655 rec=1.3200 | train/val/test=0.825/0.826/0.825 | c=0.998905
[Epoch 0091] loss=17.5648 cls=0.4753 smmd=0.2143 ct=7.2621 rec=1.3199 | train/val/test=0.825/0.827/0.825 | c=0.998905
[Epoch 0092] loss=17.5706 cls=0.4753 smmd=0.2151 ct=7.2611 rec=1.3200 | train/val/test=0.825/0.827/0.825 | c=0.998905
[Epoch 0093] loss=17.5531 cls=0.4754 smmd=0.2128 ct=7.2636 rec=1.3201 | train/val/test=0.825/0.827/0.825 | c=0.998905
[Epoch 0094] loss=17.5775 cls=0.4758 smmd=0.2156 ct=7.2616 rec=1.3202 | train/val/test=0.825/0.826/0.826 | c=0.998905
[Epoch 0095] loss=17.5688 cls=0.4762 smmd=0.2152 ct=7.2591 rec=1.3202 | train/val/test=0.825/0.827/0.825 | c=0.998905
[Epoch 0096] loss=17.5525 cls=0.4764 smmd=0.2134 ct=7.2599 rec=1.3204 | train/val/test=0.825/0.827/0.826 | c=0.998905
[Epoch 0097] loss=17.5676 cls=0.4767 smmd=0.2150 ct=7.2596 rec=1.3205 | train/val/test=0.825/0.826/0.826 | c=0.998905
[Epoch 0098] loss=17.5631 cls=0.4770 smmd=0.2147 ct=7.2584 rec=1.3205 | train/val/test=0.825/0.827/0.825 | c=0.998905
[Epoch 0099] loss=17.5522 cls=0.4772 smmd=0.2138 ct=7.2578 rec=1.3204 | train/val/test=0.825/0.827/0.826 | c=0.998905
=== Best @ epoch 80: val=0.8283, test=0.8248 ===
