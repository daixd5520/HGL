Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=58.7009 cls=1.0880 smmd=4.2939 ct=7.2553 rec=1.4141 | train/val/test=0.489/0.498/0.490 | c=0.500000
[Epoch 0001] loss=34.9267 cls=1.0592 smmd=1.9277 ct=7.2063 rec=1.4158 | train/val/test=0.487/0.492/0.491 | c=0.500000
[Epoch 0002] loss=22.3309 cls=1.0642 smmd=0.6799 ct=7.1466 rec=1.4139 | train/val/test=0.518/0.530/0.522 | c=0.500000
[Epoch 0003] loss=26.6366 cls=1.0553 smmd=1.1094 ct=7.1539 rec=1.4135 | train/val/test=0.537/0.543/0.533 | c=0.500000
[Epoch 0004] loss=26.3334 cls=1.0147 smmd=1.0851 ct=7.1340 rec=1.4144 | train/val/test=0.571/0.576/0.563 | c=0.500000
[Epoch 0005] loss=24.4290 cls=0.9840 smmd=0.7862 ct=7.6832 rec=1.4174 | train/val/test=0.553/0.556/0.542 | c=0.500000
[Epoch 0006] loss=21.4531 cls=0.9754 smmd=0.5224 ct=7.5158 rec=1.4203 | train/val/test=0.549/0.552/0.536 | c=0.500000
[Epoch 0007] loss=21.9085 cls=0.9484 smmd=0.5811 ct=7.4570 rec=1.4181 | train/val/test=0.554/0.558/0.549 | c=0.500000
[Epoch 0008] loss=23.4390 cls=0.8966 smmd=0.7407 ct=7.4392 rec=1.4112 | train/val/test=0.579/0.582/0.572 | c=0.500000
[Epoch 0009] loss=23.3650 cls=0.8461 smmd=0.7413 ct=7.4139 rec=1.4028 | train/val/test=0.654/0.655/0.651 | c=0.500000
[Epoch 0010] loss=21.6731 cls=0.8058 smmd=0.5781 ct=7.3961 rec=1.3950 | train/val/test=0.691/0.694/0.690 | c=0.500000
[Epoch 0011] loss=20.0282 cls=0.7706 smmd=0.4164 ct=7.3928 rec=1.3872 | train/val/test=0.704/0.709/0.704 | c=0.500000
[Epoch 0012] loss=19.8025 cls=0.7395 smmd=0.3922 ct=7.4102 rec=1.3798 | train/val/test=0.719/0.717/0.711 | c=0.500000
[Epoch 0013] loss=20.3683 cls=0.7132 smmd=0.4438 ct=7.4439 rec=1.3727 | train/val/test=0.732/0.730/0.725 | c=0.500000
[Epoch 0014] loss=20.4586 cls=0.6880 smmd=0.4495 ct=7.4687 rec=1.3650 | train/val/test=0.736/0.736/0.727 | c=0.500000
[Epoch 0015] loss=19.9604 cls=0.6668 smmd=0.4006 ct=7.4710 rec=1.3579 | train/val/test=0.739/0.741/0.733 | c=0.500000
[Epoch 0016] loss=19.4646 cls=0.6482 smmd=0.3570 ct=7.4472 rec=1.3520 | train/val/test=0.749/0.750/0.739 | c=0.500000
[Epoch 0017] loss=19.3518 cls=0.6275 smmd=0.3548 ct=7.4086 rec=1.3460 | train/val/test=0.761/0.765/0.749 | c=0.500000
[Epoch 0018] loss=19.4141 cls=0.6073 smmd=0.3680 ct=7.3800 rec=1.3402 | train/val/test=0.773/0.782/0.760 | c=0.500000
[Epoch 0019] loss=19.4040 cls=0.5898 smmd=0.3697 ct=7.3721 rec=1.3350 | train/val/test=0.783/0.792/0.770 | c=0.500000
[Epoch 0020] loss=19.2473 cls=0.5730 smmd=0.3542 ct=7.3767 rec=1.3304 | train/val/test=0.791/0.799/0.783 | c=0.500000
[Epoch 0021] loss=18.9712 cls=0.5557 smmd=0.3257 ct=7.3865 rec=1.3263 | train/val/test=0.798/0.804/0.790 | c=0.500000
[Epoch 0022] loss=18.7103 cls=0.5396 smmd=0.2990 ct=7.3944 rec=1.3225 | train/val/test=0.803/0.808/0.793 | c=0.500000
[Epoch 0023] loss=18.6264 cls=0.5250 smmd=0.2916 ct=7.3945 rec=1.3183 | train/val/test=0.806/0.809/0.794 | c=0.500000
[Epoch 0024] loss=18.5244 cls=0.5116 smmd=0.2836 ct=7.3876 rec=1.3140 | train/val/test=0.807/0.810/0.797 | c=0.500000
[Epoch 0025] loss=18.3779 cls=0.5003 smmd=0.2714 ct=7.3792 rec=1.3111 | train/val/test=0.811/0.814/0.800 | c=0.500000
[Epoch 0026] loss=18.2774 cls=0.4903 smmd=0.2633 ct=7.3723 rec=1.3096 | train/val/test=0.814/0.816/0.801 | c=0.500000
[Epoch 0027] loss=18.2226 cls=0.4819 smmd=0.2594 ct=7.3669 rec=1.3087 | train/val/test=0.818/0.820/0.805 | c=0.500000
[Epoch 0028] loss=18.1883 cls=0.4755 smmd=0.2571 ct=7.3626 rec=1.3080 | train/val/test=0.820/0.823/0.811 | c=0.500000
[Epoch 0029] loss=18.1273 cls=0.4699 smmd=0.2520 ct=7.3593 rec=1.3080 | train/val/test=0.823/0.826/0.814 | c=0.500000
[Epoch 0030] loss=18.1178 cls=0.4654 smmd=0.2521 ct=7.3548 rec=1.3089 | train/val/test=0.826/0.827/0.817 | c=0.500000
[Epoch 0031] loss=18.1109 cls=0.4625 smmd=0.2529 ct=7.3481 rec=1.3100 | train/val/test=0.826/0.827/0.819 | c=0.500000
[Epoch 0032] loss=18.0983 cls=0.4608 smmd=0.2526 ct=7.3433 rec=1.3102 | train/val/test=0.827/0.829/0.818 | c=0.500000
[Epoch 0033] loss=18.0376 cls=0.4596 smmd=0.2467 ct=7.3427 rec=1.3101 | train/val/test=0.827/0.828/0.819 | c=0.500000
[Epoch 0034] loss=18.0532 cls=0.4584 smmd=0.2479 ct=7.3451 rec=1.3106 | train/val/test=0.828/0.828/0.817 | c=0.500000
[Epoch 0035] loss=18.0491 cls=0.4574 smmd=0.2466 ct=7.3491 rec=1.3115 | train/val/test=0.829/0.828/0.817 | c=0.500000
[Epoch 0036] loss=17.9980 cls=0.4567 smmd=0.2418 ct=7.3481 rec=1.3118 | train/val/test=0.829/0.829/0.819 | c=0.500000
[Epoch 0037] loss=17.9596 cls=0.4561 smmd=0.2391 ct=7.3427 rec=1.3111 | train/val/test=0.829/0.828/0.821 | c=0.500000
[Epoch 0038] loss=17.9328 cls=0.4560 smmd=0.2379 ct=7.3350 rec=1.3104 | train/val/test=0.829/0.829/0.818 | c=0.500000
[Epoch 0039] loss=17.8953 cls=0.4562 smmd=0.2358 ct=7.3270 rec=1.3102 | train/val/test=0.830/0.829/0.819 | c=0.500000
[Epoch 0040] loss=17.8707 cls=0.4567 smmd=0.2343 ct=7.3223 rec=1.3096 | train/val/test=0.829/0.827/0.819 | c=0.500000
[Epoch 0041] loss=17.8108 cls=0.4572 smmd=0.2288 ct=7.3199 rec=1.3091 | train/val/test=0.828/0.828/0.818 | c=0.500000
[Epoch 0042] loss=17.7747 cls=0.4579 smmd=0.2255 ct=7.3179 rec=1.3090 | train/val/test=0.828/0.829/0.818 | c=0.500000
[Epoch 0043] loss=17.7891 cls=0.4584 smmd=0.2268 ct=7.3185 rec=1.3099 | train/val/test=0.827/0.830/0.818 | c=0.500000
[Epoch 0044] loss=17.7600 cls=0.4591 smmd=0.2238 ct=7.3186 rec=1.3110 | train/val/test=0.828/0.831/0.818 | c=0.500000
[Epoch 0045] loss=17.7428 cls=0.4597 smmd=0.2224 ct=7.3164 rec=1.3118 | train/val/test=0.828/0.829/0.820 | c=0.500000
[Epoch 0046] loss=17.7285 cls=0.4605 smmd=0.2211 ct=7.3153 rec=1.3128 | train/val/test=0.829/0.830/0.820 | c=0.500000
[Epoch 0047] loss=17.7431 cls=0.4617 smmd=0.2228 ct=7.3136 rec=1.3140 | train/val/test=0.829/0.830/0.820 | c=0.500000
[Epoch 0048] loss=17.7488 cls=0.4624 smmd=0.2243 ct=7.3085 rec=1.3154 | train/val/test=0.830/0.830/0.821 | c=0.500000
[Epoch 0049] loss=17.7592 cls=0.4634 smmd=0.2265 ct=7.3020 rec=1.3163 | train/val/test=0.829/0.829/0.821 | c=0.500000
[Epoch 0050] loss=17.7385 cls=0.4641 smmd=0.2254 ct=7.2972 rec=1.3168 | train/val/test=0.830/0.830/0.822 | c=0.500000
[Epoch 0051] loss=17.7017 cls=0.4642 smmd=0.2217 ct=7.2969 rec=1.3172 | train/val/test=0.830/0.829/0.822 | c=0.500000
[Epoch 0052] loss=17.7204 cls=0.4642 smmd=0.2229 ct=7.3003 rec=1.3172 | train/val/test=0.830/0.830/0.821 | c=0.500000
[Epoch 0053] loss=17.6764 cls=0.4641 smmd=0.2184 ct=7.3012 rec=1.3169 | train/val/test=0.829/0.830/0.821 | c=0.500000
[Epoch 0054] loss=17.6601 cls=0.4642 smmd=0.2176 ct=7.2968 rec=1.3163 | train/val/test=0.829/0.829/0.822 | c=0.500000
[Epoch 0055] loss=17.6304 cls=0.4640 smmd=0.2157 ct=7.2915 rec=1.3159 | train/val/test=0.829/0.830/0.821 | c=0.500000
[Epoch 0056] loss=17.6242 cls=0.4637 smmd=0.2157 ct=7.2889 rec=1.3157 | train/val/test=0.829/0.830/0.820 | c=0.500000
[Epoch 0057] loss=17.6250 cls=0.4637 smmd=0.2165 ct=7.2850 rec=1.3154 | train/val/test=0.828/0.829/0.820 | c=0.500000
[Epoch 0058] loss=17.6356 cls=0.4639 smmd=0.2181 ct=7.2827 rec=1.3152 | train/val/test=0.829/0.829/0.820 | c=0.500000
[Epoch 0059] loss=17.6259 cls=0.4638 smmd=0.2169 ct=7.2836 rec=1.3153 | train/val/test=0.829/0.828/0.821 | c=0.500000
[Epoch 0060] loss=17.6184 cls=0.4637 smmd=0.2161 ct=7.2841 rec=1.3156 | train/val/test=0.828/0.828/0.822 | c=0.500000
[Epoch 0061] loss=17.6236 cls=0.4640 smmd=0.2166 ct=7.2838 rec=1.3158 | train/val/test=0.828/0.828/0.823 | c=0.500000
[Epoch 0062] loss=17.6228 cls=0.4640 smmd=0.2170 ct=7.2812 rec=1.3160 | train/val/test=0.828/0.828/0.822 | c=0.500000
[Epoch 0063] loss=17.6252 cls=0.4641 smmd=0.2181 ct=7.2770 rec=1.3162 | train/val/test=0.829/0.828/0.824 | c=0.500000
[Epoch 0064] loss=17.6176 cls=0.4636 smmd=0.2180 ct=7.2737 rec=1.3167 | train/val/test=0.830/0.830/0.822 | c=0.500000
[Epoch 0065] loss=17.6105 cls=0.4631 smmd=0.2176 ct=7.2721 rec=1.3170 | train/val/test=0.830/0.829/0.822 | c=0.500000
[Epoch 0066] loss=17.5974 cls=0.4627 smmd=0.2166 ct=7.2708 rec=1.3172 | train/val/test=0.830/0.829/0.824 | c=0.500000
[Epoch 0067] loss=17.5952 cls=0.4623 smmd=0.2164 ct=7.2709 rec=1.3174 | train/val/test=0.830/0.829/0.823 | c=0.500000
[Epoch 0068] loss=17.5701 cls=0.4619 smmd=0.2143 ct=7.2688 rec=1.3175 | train/val/test=0.830/0.828/0.823 | c=0.500000
[Epoch 0069] loss=17.5509 cls=0.4616 smmd=0.2130 ct=7.2655 rec=1.3176 | train/val/test=0.830/0.828/0.825 | c=0.500000
[Epoch 0070] loss=17.5584 cls=0.4617 smmd=0.2139 ct=7.2648 rec=1.3178 | train/val/test=0.830/0.828/0.824 | c=0.500000
[Epoch 0071] loss=17.5587 cls=0.4620 smmd=0.2140 ct=7.2644 rec=1.3179 | train/val/test=0.830/0.830/0.825 | c=0.500000
[Epoch 0072] loss=17.5606 cls=0.4617 smmd=0.2145 ct=7.2627 rec=1.3182 | train/val/test=0.830/0.829/0.824 | c=0.500000
[Epoch 0073] loss=17.5538 cls=0.4620 smmd=0.2146 ct=7.2590 rec=1.3182 | train/val/test=0.830/0.829/0.825 | c=0.500000
[Epoch 0074] loss=17.5573 cls=0.4621 smmd=0.2151 ct=7.2582 rec=1.3184 | train/val/test=0.830/0.829/0.824 | c=0.500000
[Epoch 0075] loss=17.5563 cls=0.4624 smmd=0.2148 ct=7.2587 rec=1.3185 | train/val/test=0.830/0.828/0.824 | c=0.500000
[Epoch 0076] loss=17.5615 cls=0.4631 smmd=0.2152 ct=7.2595 rec=1.3184 | train/val/test=0.830/0.829/0.825 | c=0.500000
[Epoch 0077] loss=17.5470 cls=0.4630 smmd=0.2141 ct=7.2575 rec=1.3185 | train/val/test=0.829/0.828/0.825 | c=0.500000
[Epoch 0078] loss=17.5462 cls=0.4630 smmd=0.2145 ct=7.2554 rec=1.3185 | train/val/test=0.830/0.828/0.825 | c=0.500000
[Epoch 0079] loss=17.5381 cls=0.4631 smmd=0.2142 ct=7.2524 rec=1.3186 | train/val/test=0.830/0.828/0.824 | c=0.500000
[Epoch 0080] loss=17.5332 cls=0.4632 smmd=0.2141 ct=7.2506 rec=1.3185 | train/val/test=0.830/0.827/0.824 | c=0.500000
[Epoch 0081] loss=17.5088 cls=0.4635 smmd=0.2116 ct=7.2512 rec=1.3183 | train/val/test=0.830/0.828/0.825 | c=0.500000
[Epoch 0082] loss=17.5185 cls=0.4634 smmd=0.2121 ct=7.2532 rec=1.3187 | train/val/test=0.830/0.827/0.825 | c=0.500000
[Epoch 0083] loss=17.5251 cls=0.4637 smmd=0.2130 ct=7.2518 rec=1.3188 | train/val/test=0.830/0.827/0.826 | c=0.500000
[Epoch 0084] loss=17.5170 cls=0.4638 smmd=0.2126 ct=7.2498 rec=1.3191 | train/val/test=0.830/0.827/0.826 | c=0.500000
[Epoch 0085] loss=17.5132 cls=0.4642 smmd=0.2128 ct=7.2468 rec=1.3192 | train/val/test=0.830/0.827/0.825 | c=0.500000
[Epoch 0086] loss=17.5237 cls=0.4651 smmd=0.2137 ct=7.2472 rec=1.3190 | train/val/test=0.830/0.827/0.825 | c=0.500000
[Epoch 0087] loss=17.5180 cls=0.4651 smmd=0.2130 ct=7.2477 rec=1.3193 | train/val/test=0.830/0.828/0.826 | c=0.500000
[Epoch 0088] loss=17.5260 cls=0.4648 smmd=0.2140 ct=7.2471 rec=1.3198 | train/val/test=0.830/0.827/0.825 | c=0.500000
[Epoch 0089] loss=17.5155 cls=0.4654 smmd=0.2131 ct=7.2461 rec=1.3194 | train/val/test=0.830/0.828/0.825 | c=0.500000
[Epoch 0090] loss=17.5126 cls=0.4651 smmd=0.2127 ct=7.2465 rec=1.3194 | train/val/test=0.830/0.828/0.826 | c=0.500000
[Epoch 0091] loss=17.5000 cls=0.4650 smmd=0.2118 ct=7.2447 rec=1.3195 | train/val/test=0.829/0.827/0.824 | c=0.500000
[Epoch 0092] loss=17.5128 cls=0.4657 smmd=0.2135 ct=7.2429 rec=1.3191 | train/val/test=0.830/0.826/0.826 | c=0.500000
[Epoch 0093] loss=17.5046 cls=0.4651 smmd=0.2126 ct=7.2430 rec=1.3194 | train/val/test=0.829/0.828/0.825 | c=0.500000
[Epoch 0094] loss=17.5005 cls=0.4652 smmd=0.2124 ct=7.2424 rec=1.3193 | train/val/test=0.830/0.828/0.826 | c=0.500000
[Epoch 0095] loss=17.5075 cls=0.4651 smmd=0.2130 ct=7.2425 rec=1.3193 | train/val/test=0.829/0.827/0.826 | c=0.500000
[Epoch 0096] loss=17.4994 cls=0.4650 smmd=0.2124 ct=7.2417 rec=1.3195 | train/val/test=0.830/0.828/0.826 | c=0.500000
[Epoch 0097] loss=17.4923 cls=0.4655 smmd=0.2116 ct=7.2418 rec=1.3191 | train/val/test=0.829/0.827/0.825 | c=0.500000
[Epoch 0098] loss=17.4925 cls=0.4654 smmd=0.2121 ct=7.2397 rec=1.3193 | train/val/test=0.829/0.828/0.826 | c=0.500000
[Epoch 0099] loss=17.4851 cls=0.4655 smmd=0.2116 ct=7.2384 rec=1.3195 | train/val/test=0.829/0.828/0.825 | c=0.500000
=== Best @ epoch 44: val=0.8308, test=0.8180 ===
