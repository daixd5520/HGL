Parsed from filename: Pretrained backbone is Hyperbolic.
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=56.5812 cls=1.0890 smmd=4.0839 ct=7.2457 rec=1.4136 | train/val/test=0.401/0.400/0.403 | c=0.500000
[Epoch 0001] loss=33.0158 cls=1.0617 smmd=1.7430 ct=7.1738 rec=1.4152 | train/val/test=0.512/0.507/0.514 | c=0.500000
[Epoch 0002] loss=23.0904 cls=1.0682 smmd=0.7585 ct=7.1323 rec=1.4137 | train/val/test=0.560/0.561/0.553 | c=0.500000
[Epoch 0003] loss=25.9270 cls=1.0450 smmd=1.0426 ct=7.1357 rec=1.4138 | train/val/test=0.558/0.556/0.551 | c=0.500000
[Epoch 0004] loss=25.6256 cls=1.0088 smmd=1.0178 ct=7.1176 rec=1.4158 | train/val/test=0.546/0.546/0.537 | c=0.500000
[Epoch 0005] loss=23.6773 cls=0.9831 smmd=0.8327 ct=7.0749 rec=1.4180 | train/val/test=0.531/0.537/0.532 | c=0.500000
[Epoch 0006] loss=21.9473 cls=0.9560 smmd=0.5599 ct=7.5808 rec=1.4178 | train/val/test=0.529/0.534/0.529 | c=0.500000
[Epoch 0007] loss=21.1616 cls=0.9283 smmd=0.5127 ct=7.4311 rec=1.4162 | train/val/test=0.531/0.536/0.532 | c=0.500000
[Epoch 0008] loss=22.6959 cls=0.8864 smmd=0.6807 ct=7.3700 rec=1.4111 | train/val/test=0.577/0.578/0.572 | c=0.500000
[Epoch 0009] loss=23.1291 cls=0.8311 smmd=0.7248 ct=7.3825 rec=1.4017 | train/val/test=0.676/0.678/0.664 | c=0.500000
[Epoch 0010] loss=21.9556 cls=0.7846 smmd=0.6026 ct=7.4211 rec=1.3903 | train/val/test=0.698/0.699/0.675 | c=0.500000
[Epoch 0011] loss=20.2470 cls=0.7534 smmd=0.4304 ct=7.4383 rec=1.3799 | train/val/test=0.703/0.703/0.679 | c=0.500000
[Epoch 0012] loss=19.5807 cls=0.7262 smmd=0.3683 ct=7.4246 rec=1.3713 | train/val/test=0.702/0.704/0.682 | c=0.500000
[Epoch 0013] loss=20.0073 cls=0.6994 smmd=0.4149 ct=7.4134 rec=1.3634 | train/val/test=0.700/0.707/0.680 | c=0.500000
[Epoch 0014] loss=20.2664 cls=0.6773 smmd=0.4417 ct=7.4164 rec=1.3562 | train/val/test=0.708/0.715/0.686 | c=0.500000
[Epoch 0015] loss=19.9573 cls=0.6599 smmd=0.4102 ct=7.4254 rec=1.3500 | train/val/test=0.719/0.723/0.694 | c=0.500000
[Epoch 0016] loss=19.5486 cls=0.6441 smmd=0.3688 ct=7.4332 rec=1.3440 | train/val/test=0.730/0.733/0.704 | c=0.500000
[Epoch 0017] loss=19.4150 cls=0.6301 smmd=0.3574 ct=7.4282 rec=1.3383 | train/val/test=0.746/0.746/0.714 | c=0.500000
[Epoch 0018] loss=19.2889 cls=0.6163 smmd=0.3508 ct=7.4028 rec=1.3332 | train/val/test=0.760/0.756/0.729 | c=0.500000
[Epoch 0019] loss=19.1992 cls=0.5985 smmd=0.3485 ct=7.3752 rec=1.3288 | train/val/test=0.770/0.767/0.741 | c=0.500000
[Epoch 0020] loss=19.2217 cls=0.5785 smmd=0.3540 ct=7.3652 rec=1.3248 | train/val/test=0.780/0.773/0.753 | c=0.500000
[Epoch 0021] loss=19.1587 cls=0.5600 smmd=0.3472 ct=7.3732 rec=1.3210 | train/val/test=0.790/0.782/0.762 | c=0.500000
[Epoch 0022] loss=18.8162 cls=0.5425 smmd=0.3120 ct=7.3830 rec=1.3171 | train/val/test=0.800/0.792/0.772 | c=0.500000
[Epoch 0023] loss=18.4789 cls=0.5254 smmd=0.2791 ct=7.3841 rec=1.3139 | train/val/test=0.804/0.801/0.777 | c=0.500000
[Epoch 0024] loss=18.3945 cls=0.5106 smmd=0.2723 ct=7.3802 rec=1.3111 | train/val/test=0.807/0.802/0.780 | c=0.500000
[Epoch 0025] loss=18.4437 cls=0.4983 smmd=0.2791 ct=7.3747 rec=1.3091 | train/val/test=0.812/0.808/0.788 | c=0.500000
[Epoch 0026] loss=18.3031 cls=0.4852 smmd=0.2668 ct=7.3693 rec=1.3081 | train/val/test=0.821/0.816/0.794 | c=0.500000
[Epoch 0027] loss=18.1528 cls=0.4737 smmd=0.2526 ct=7.3680 rec=1.3084 | train/val/test=0.825/0.823/0.798 | c=0.500000
[Epoch 0028] loss=18.1402 cls=0.4677 smmd=0.2512 ct=7.3700 rec=1.3089 | train/val/test=0.826/0.823/0.798 | c=0.500000
[Epoch 0029] loss=18.1620 cls=0.4642 smmd=0.2534 ct=7.3709 rec=1.3083 | train/val/test=0.827/0.826/0.800 | c=0.500000
[Epoch 0030] loss=18.1261 cls=0.4602 smmd=0.2518 ct=7.3620 rec=1.3073 | train/val/test=0.826/0.824/0.799 | c=0.500000
[Epoch 0031] loss=18.1119 cls=0.4576 smmd=0.2531 ct=7.3490 rec=1.3078 | train/val/test=0.824/0.823/0.800 | c=0.500000
[Epoch 0032] loss=18.1417 cls=0.4569 smmd=0.2574 ct=7.3425 rec=1.3092 | train/val/test=0.827/0.827/0.801 | c=0.500000
[Epoch 0033] loss=18.1321 cls=0.4530 smmd=0.2560 ct=7.3455 rec=1.3096 | train/val/test=0.830/0.829/0.809 | c=0.500000
[Epoch 0034] loss=18.0817 cls=0.4505 smmd=0.2495 ct=7.3530 rec=1.3103 | train/val/test=0.829/0.830/0.808 | c=0.500000
[Epoch 0035] loss=18.0616 cls=0.4499 smmd=0.2466 ct=7.3578 rec=1.3106 | train/val/test=0.829/0.829/0.807 | c=0.500000
[Epoch 0036] loss=18.0482 cls=0.4487 smmd=0.2457 ct=7.3562 rec=1.3097 | train/val/test=0.830/0.828/0.806 | c=0.500000
[Epoch 0037] loss=17.9782 cls=0.4478 smmd=0.2401 ct=7.3499 rec=1.3073 | train/val/test=0.829/0.833/0.805 | c=0.500000
[Epoch 0038] loss=17.9150 cls=0.4482 smmd=0.2362 ct=7.3384 rec=1.3047 | train/val/test=0.828/0.831/0.802 | c=0.500000
[Epoch 0039] loss=17.8765 cls=0.4483 smmd=0.2344 ct=7.3284 rec=1.3038 | train/val/test=0.828/0.832/0.802 | c=0.500000
[Epoch 0040] loss=17.8497 cls=0.4475 smmd=0.2319 ct=7.3273 rec=1.3040 | train/val/test=0.828/0.833/0.803 | c=0.500000
[Epoch 0041] loss=17.8121 cls=0.4475 smmd=0.2285 ct=7.3253 rec=1.3046 | train/val/test=0.828/0.832/0.802 | c=0.500000
[Epoch 0042] loss=17.7801 cls=0.4476 smmd=0.2260 ct=7.3218 rec=1.3056 | train/val/test=0.830/0.831/0.801 | c=0.500000
[Epoch 0043] loss=17.7649 cls=0.4484 smmd=0.2242 ct=7.3228 rec=1.3063 | train/val/test=0.830/0.833/0.803 | c=0.500000
[Epoch 0044] loss=17.7840 cls=0.4507 smmd=0.2253 ct=7.3263 rec=1.3065 | train/val/test=0.830/0.834/0.803 | c=0.500000
[Epoch 0045] loss=17.7778 cls=0.4531 smmd=0.2246 ct=7.3257 rec=1.3073 | train/val/test=0.830/0.834/0.802 | c=0.500000
[Epoch 0046] loss=17.7697 cls=0.4539 smmd=0.2249 ct=7.3196 rec=1.3089 | train/val/test=0.830/0.835/0.803 | c=0.500000
[Epoch 0047] loss=17.7718 cls=0.4545 smmd=0.2265 ct=7.3124 rec=1.3105 | train/val/test=0.831/0.836/0.802 | c=0.500000
[Epoch 0048] loss=17.7867 cls=0.4554 smmd=0.2293 ct=7.3050 rec=1.3117 | train/val/test=0.831/0.837/0.804 | c=0.500000
[Epoch 0049] loss=17.7613 cls=0.4557 smmd=0.2272 ct=7.3023 rec=1.3127 | train/val/test=0.832/0.836/0.804 | c=0.500000
[Epoch 0050] loss=17.7387 cls=0.4564 smmd=0.2243 ct=7.3054 rec=1.3131 | train/val/test=0.832/0.836/0.802 | c=0.500000
[Epoch 0051] loss=17.7173 cls=0.4571 smmd=0.2222 ct=7.3052 rec=1.3131 | train/val/test=0.832/0.835/0.802 | c=0.500000
[Epoch 0052] loss=17.6868 cls=0.4573 smmd=0.2195 ct=7.3032 rec=1.3130 | train/val/test=0.833/0.836/0.805 | c=0.500000
[Epoch 0053] loss=17.6794 cls=0.4571 smmd=0.2199 ct=7.2976 rec=1.3129 | train/val/test=0.832/0.835/0.805 | c=0.500000
[Epoch 0054] loss=17.6269 cls=0.4574 smmd=0.2164 ct=7.2888 rec=1.3127 | train/val/test=0.833/0.834/0.805 | c=0.500000
[Epoch 0055] loss=17.6226 cls=0.4576 smmd=0.2167 ct=7.2851 rec=1.3127 | train/val/test=0.833/0.835/0.804 | c=0.500000
[Epoch 0056] loss=17.6111 cls=0.4577 smmd=0.2153 ct=7.2864 rec=1.3127 | train/val/test=0.832/0.835/0.804 | c=0.500000
[Epoch 0057] loss=17.6186 cls=0.4580 smmd=0.2163 ct=7.2850 rec=1.3129 | train/val/test=0.833/0.835/0.804 | c=0.500000
[Epoch 0058] loss=17.6235 cls=0.4588 smmd=0.2171 ct=7.2832 rec=1.3130 | train/val/test=0.833/0.835/0.803 | c=0.500000
[Epoch 0059] loss=17.6264 cls=0.4592 smmd=0.2182 ct=7.2789 rec=1.3134 | train/val/test=0.833/0.835/0.803 | c=0.500000
[Epoch 0060] loss=17.6551 cls=0.4594 smmd=0.2219 ct=7.2746 rec=1.3138 | train/val/test=0.833/0.835/0.803 | c=0.500000
[Epoch 0061] loss=17.6183 cls=0.4598 smmd=0.2186 ct=7.2729 rec=1.3139 | train/val/test=0.833/0.834/0.803 | c=0.500000
[Epoch 0062] loss=17.6500 cls=0.4597 smmd=0.2215 ct=7.2740 rec=1.3140 | train/val/test=0.833/0.833/0.804 | c=0.500000
[Epoch 0063] loss=17.6163 cls=0.4589 smmd=0.2187 ct=7.2713 rec=1.3142 | train/val/test=0.833/0.833/0.805 | c=0.500000
[Epoch 0064] loss=17.5875 cls=0.4587 smmd=0.2171 ct=7.2652 rec=1.3141 | train/val/test=0.833/0.834/0.805 | c=0.500000
[Epoch 0065] loss=17.5902 cls=0.4585 smmd=0.2180 ct=7.2620 rec=1.3139 | train/val/test=0.833/0.833/0.804 | c=0.500000
[Epoch 0066] loss=17.5633 cls=0.4579 smmd=0.2157 ct=7.2601 rec=1.3141 | train/val/test=0.833/0.834/0.805 | c=0.500000
[Epoch 0067] loss=17.5595 cls=0.4574 smmd=0.2158 ct=7.2579 rec=1.3143 | train/val/test=0.834/0.835/0.805 | c=0.500000
[Epoch 0068] loss=17.5620 cls=0.4576 smmd=0.2160 ct=7.2583 rec=1.3142 | train/val/test=0.833/0.834/0.804 | c=0.500000
[Epoch 0069] loss=17.5800 cls=0.4578 smmd=0.2176 ct=7.2588 rec=1.3143 | train/val/test=0.834/0.834/0.805 | c=0.500000
[Epoch 0070] loss=17.5636 cls=0.4579 smmd=0.2170 ct=7.2535 rec=1.3145 | train/val/test=0.832/0.834/0.805 | c=0.500000
[Epoch 0071] loss=17.5489 cls=0.4581 smmd=0.2163 ct=7.2499 rec=1.3147 | train/val/test=0.833/0.834/0.805 | c=0.500000
[Epoch 0072] loss=17.5636 cls=0.4585 smmd=0.2176 ct=7.2505 rec=1.3148 | train/val/test=0.833/0.834/0.804 | c=0.500000
[Epoch 0073] loss=17.5511 cls=0.4592 smmd=0.2165 ct=7.2496 rec=1.3148 | train/val/test=0.834/0.835/0.805 | c=0.500000
[Epoch 0074] loss=17.5643 cls=0.4599 smmd=0.2183 ct=7.2472 rec=1.3149 | train/val/test=0.834/0.835/0.805 | c=0.500000
[Epoch 0075] loss=17.5616 cls=0.4602 smmd=0.2186 ct=7.2438 rec=1.3150 | train/val/test=0.833/0.835/0.804 | c=0.500000
[Epoch 0076] loss=17.5433 cls=0.4605 smmd=0.2166 ct=7.2449 rec=1.3150 | train/val/test=0.833/0.834/0.805 | c=0.500000
[Epoch 0077] loss=17.5380 cls=0.4606 smmd=0.2163 ct=7.2436 rec=1.3151 | train/val/test=0.834/0.835/0.804 | c=0.500000
[Epoch 0078] loss=17.5232 cls=0.4610 smmd=0.2155 ct=7.2398 rec=1.3151 | train/val/test=0.833/0.835/0.803 | c=0.500000
[Epoch 0079] loss=17.5169 cls=0.4616 smmd=0.2148 ct=7.2403 rec=1.3151 | train/val/test=0.833/0.835/0.803 | c=0.500000
[Epoch 0080] loss=17.5268 cls=0.4620 smmd=0.2162 ct=7.2383 rec=1.3154 | train/val/test=0.833/0.835/0.804 | c=0.500000
[Epoch 0081] loss=17.5248 cls=0.4624 smmd=0.2162 ct=7.2368 rec=1.3157 | train/val/test=0.833/0.836/0.804 | c=0.500000
[Epoch 0082] loss=17.5276 cls=0.4627 smmd=0.2167 ct=7.2357 rec=1.3161 | train/val/test=0.833/0.836/0.804 | c=0.500000
[Epoch 0083] loss=17.5265 cls=0.4632 smmd=0.2169 ct=7.2340 rec=1.3162 | train/val/test=0.833/0.836/0.804 | c=0.500000
[Epoch 0084] loss=17.5255 cls=0.4638 smmd=0.2170 ct=7.2329 rec=1.3164 | train/val/test=0.833/0.835/0.804 | c=0.500000
[Epoch 0085] loss=17.5148 cls=0.4641 smmd=0.2157 ct=7.2338 rec=1.3165 | train/val/test=0.834/0.836/0.805 | c=0.500000
[Epoch 0086] loss=17.5145 cls=0.4643 smmd=0.2163 ct=7.2307 rec=1.3168 | train/val/test=0.833/0.836/0.805 | c=0.500000
[Epoch 0087] loss=17.5182 cls=0.4646 smmd=0.2168 ct=7.2296 rec=1.3168 | train/val/test=0.833/0.835/0.805 | c=0.500000
[Epoch 0088] loss=17.5062 cls=0.4650 smmd=0.2154 ct=7.2309 rec=1.3168 | train/val/test=0.833/0.836/0.805 | c=0.500000
[Epoch 0089] loss=17.5076 cls=0.4658 smmd=0.2159 ct=7.2286 rec=1.3169 | train/val/test=0.833/0.836/0.804 | c=0.500000
[Epoch 0090] loss=17.5051 cls=0.4657 smmd=0.2163 ct=7.2255 rec=1.3171 | train/val/test=0.833/0.836/0.806 | c=0.500000
[Epoch 0091] loss=17.5105 cls=0.4660 smmd=0.2168 ct=7.2253 rec=1.3173 | train/val/test=0.833/0.836/0.804 | c=0.500000
[Epoch 0092] loss=17.4955 cls=0.4668 smmd=0.2150 ct=7.2268 rec=1.3171 | train/val/test=0.833/0.835/0.805 | c=0.500000
[Epoch 0093] loss=17.5106 cls=0.4664 smmd=0.2169 ct=7.2249 rec=1.3174 | train/val/test=0.832/0.835/0.805 | c=0.500000
[Epoch 0094] loss=17.4991 cls=0.4666 smmd=0.2162 ct=7.2226 rec=1.3173 | train/val/test=0.833/0.835/0.805 | c=0.500000
[Epoch 0095] loss=17.4898 cls=0.4671 smmd=0.2150 ct=7.2241 rec=1.3170 | train/val/test=0.832/0.835/0.806 | c=0.500000
[Epoch 0096] loss=17.4936 cls=0.4666 smmd=0.2158 ct=7.2221 rec=1.3173 | train/val/test=0.832/0.834/0.805 | c=0.500000
[Epoch 0097] loss=17.4791 cls=0.4671 smmd=0.2148 ct=7.2195 rec=1.3173 | train/val/test=0.832/0.834/0.805 | c=0.500000
[Epoch 0098] loss=17.4791 cls=0.4672 smmd=0.2146 ct=7.2204 rec=1.3170 | train/val/test=0.832/0.834/0.805 | c=0.500000
[Epoch 0099] loss=17.4925 cls=0.4674 smmd=0.2161 ct=7.2194 rec=1.3173 | train/val/test=0.832/0.834/0.805 | c=0.500000
=== Best @ epoch 48: val=0.8367, test=0.8038 ===
