
================================================================================
[2025-09-20 03:15:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 03:15:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 03:17:34] Public, r: 32, Cora to Photo: Best @ epoch 199: val=0.9314, test=0.9405 ===

================================================================================
[2025-09-20 03:17:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-20 03:19:37] Few(5), r: 32, Cora to Photo: Best @ epoch 172: val=0.8633, test=0.8630 ===

================================================================================
[2025-09-20 03:19:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 03:21:41] Few(10), r: 32, Cora to Photo: Best @ epoch 54: val=0.8923, test=0.8947 ===

================================================================================
[2025-09-20 03:21:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 03:30:37] Public, r: 32, Cora to Computers: Best @ epoch 181: val=0.8967, test=0.8986 ===

================================================================================
[2025-09-20 03:30:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 03:39:37] Few(5), r: 32, Cora to Computers: Best @ epoch 203: val=0.7573, test=0.7554 ===

================================================================================
[2025-09-20 03:39:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 03:48:32] Few(10), r: 32, Cora to Computers: Best @ epoch 379: val=0.7934, test=0.7985 ===

================================================================================
[2025-09-20 03:48:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-20 03:51:56] Public, r: 32, Photo to PubMed: Best @ epoch 91: val=0.8417, test=0.8299 ===

================================================================================
[2025-09-20 03:52:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 03:55:13] Few(5), r: 32, Photo to PubMed: Best @ epoch 95: val=0.7620, test=0.7540 ===

================================================================================
[2025-09-20 03:55:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 03:58:29] Few(10), r: 32, Photo to PubMed: Best @ epoch 48: val=0.8200, test=0.7750 ===

================================================================================
[2025-09-20 03:58:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-20 03:59:41] Public, r: 32, Photo to CiteSeer: Best @ epoch 44: val=0.7308, test=0.7523 ===

================================================================================
[2025-09-20 03:59:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 04:00:52] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 50: val=0.7360, test=0.7370 ===

================================================================================
[2025-09-20 04:01:03] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 04:02:04] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 63: val=0.7360, test=0.7250 ===

================================================================================
[2025-09-20 04:02:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-20 04:02:56] Public, r: 32, Photo to Cora: Best @ epoch 90: val=0.8967, test=0.8708 ===

================================================================================
[2025-09-20 04:03:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 04:03:35] Few(5), r: 32, Photo to Cora: Best @ epoch 43: val=0.7120, test=0.7300 ===

================================================================================
[2025-09-20 04:03:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 04:04:15] Few(10), r: 32, Photo to Cora: Best @ epoch 48: val=0.7540, test=0.7410 ===

================================================================================
[2025-09-20 04:04:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 04:06:44] Public, r: 32, Photo to Photo: Best @ epoch 177: val=0.9359, test=0.9255 ===

================================================================================
[2025-09-20 04:06:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-20 04:09:12] Few(5), r: 32, Photo to Photo: Best @ epoch 162: val=0.8804, test=0.8729 ===

================================================================================
[2025-09-20 04:09:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 04:11:16] Few(10), r: 32, Photo to Photo: Best @ epoch 96: val=0.9082, test=0.9028 ===

================================================================================
[2025-09-20 04:11:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 04:20:42] Public, r: 32, Photo to Computers: Best @ epoch 490: val=0.8942, test=0.8895 ===

================================================================================
[2025-09-20 04:20:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 04:30:03] Few(5), r: 32, Photo to Computers: Best @ epoch 352: val=0.7398, test=0.7397 ===

================================================================================
[2025-09-20 04:30:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 04:40:58] Few(10), r: 32, Photo to Computers: Best @ epoch 366: val=0.7604, test=0.7531 ===

================================================================================
[2025-09-20 04:41:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-20 04:44:30] Public, r: 32, Computers to PubMed: Best @ epoch 43: val=0.8511, test=0.8337 ===

================================================================================
[2025-09-20 04:44:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 04:47:48] Few(5), r: 32, Computers to PubMed: Best @ epoch 92: val=0.7660, test=0.7450 ===

================================================================================
[2025-09-20 04:47:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 04:50:44] Few(10), r: 32, Computers to PubMed: Best @ epoch 45: val=0.8200, test=0.7730 ===

================================================================================
[2025-09-20 04:50:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-20 04:51:46] Public, r: 32, Computers to CiteSeer: Best @ epoch 77: val=0.7594, test=0.7432 ===

================================================================================
[2025-09-20 04:51:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 04:52:48] Few(5), r: 32, Computers to CiteSeer: Best @ epoch 37: val=0.6600, test=0.6250 ===

================================================================================
[2025-09-20 04:52:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 04:53:50] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 44: val=0.7020, test=0.7030 ===

================================================================================
[2025-09-20 04:54:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-20 04:54:56] Public, r: 32, Computers to Cora: Best @ epoch 68: val=0.8801, test=0.8727 ===

================================================================================
[2025-09-20 04:55:06] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 04:55:27] Few(5), r: 32, Computers to Cora: Best @ epoch 15: val=0.6420, test=0.6400 ===

================================================================================
[2025-09-20 04:55:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 04:56:06] Few(10), r: 32, Computers to Cora: Best @ epoch 85: val=0.7420, test=0.7290 ===

================================================================================
[2025-09-20 04:56:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 04:58:46] Public, r: 32, Computers to Photo: Best @ epoch 96: val=0.9157, test=0.9176 ===

================================================================================
[2025-09-20 04:58:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-20 05:01:24] Few(5), r: 32, Computers to Photo: Best @ epoch 110: val=0.8811, test=0.8706 ===

================================================================================
[2025-09-20 05:01:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 05:04:08] Few(10), r: 32, Computers to Photo: Best @ epoch 138: val=0.8937, test=0.8970 ===

================================================================================
[2025-09-20 05:04:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 05:15:28] Public, r: 32, Computers to Computers: Best @ epoch 479: val=0.8876, test=0.8909 ===

================================================================================
[2025-09-20 05:15:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 05:25:10] Few(5), r: 32, Computers to Computers: Best @ epoch 305: val=0.7723, test=0.7642 ===

================================================================================
[2025-09-20 05:25:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 05:36:25] Few(10), r: 32, Computers to Computers: Best @ epoch 147: val=0.7634, test=0.7550 ===
[2025-09-20 05:37:34] Public, r: 32, Cora to Photo: Best @ epoch 104: val=0.9425, test=0.9307 ===

================================================================================
[2025-09-20 05:37:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-20 05:51:59] Few(5), r: 32, Cora to Photo: Best @ epoch 64: val=0.8555, test=0.8563 ===

================================================================================
[2025-09-20 05:52:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 06:06:29] Few(10), r: 32, Cora to Photo: Best @ epoch 168: val=0.8910, test=0.8940 ===

================================================================================
[2025-09-20 06:06:39] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)

================================================================================
[2025-09-20 13:10:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 13:14:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 13:14:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)

================================================================================
[2025-09-20 13:14:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 13:14:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 13:14:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 13:14:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 13:14:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-20 13:15:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 13:16:20] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 67: val=0.7320, test=0.7340 ===
[2025-09-20 13:16:23] Public, r: 32, Photo to CiteSeer: Best @ epoch 88: val=0.7594, test=0.7252 ===

================================================================================
[2025-09-20 13:16:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 13:16:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 13:17:28] Public, r: 32, Photo to PubMed: Best @ epoch 40: val=0.8415, test=0.8322 ===

================================================================================
[2025-09-20 13:17:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-20 13:17:55] Few(5), r: 32, Photo to PubMed: Best @ epoch 86: val=0.7740, test=0.7650 ===
[2025-09-20 13:17:57] Few(10), r: 32, Photo to PubMed: Best @ epoch 91: val=0.8220, test=0.7630 ===

================================================================================
[2025-09-20 13:18:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 13:18:03] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 13:18:06] Public, r: 32, Photo to CiteSeer: Best @ epoch 155: val=0.7429, test=0.7417 ===
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 13:18:10] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 137: val=0.7280, test=0.7160 ===

================================================================================
[2025-09-20 13:18:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)

================================================================================
[2025-09-20 13:18:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 13:19:42] Public, r: 32, Photo to CiteSeer: Best @ epoch 136: val=0.7534, test=0.7237 ===

================================================================================
[2025-09-20 13:19:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-20 13:20:01] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 41: val=0.6700, test=0.6650 ===

================================================================================
[2025-09-20 13:20:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 13:20:29] Few(5), r: 32, Photo to PubMed: Best @ epoch 96: val=0.8000, test=0.7790 ===
[2025-09-20 13:20:34] Public, r: 32, Photo to PubMed: Best @ epoch 49: val=0.8466, test=0.8387 ===

================================================================================
[2025-09-20 13:20:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-20 13:20:39] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-20 13:20:56] Few(10), r: 32, Photo to PubMed: Best @ epoch 42: val=0.8260, test=0.7820 ===

================================================================================
[2025-09-20 13:21:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 13:21:18] Public, r: 32, Photo to CiteSeer: Best @ epoch 58: val=0.7609, test=0.7568 ===

================================================================================
[2025-09-20 13:21:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-20 13:21:44] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 161: val=0.7480, test=0.7340 ===

================================================================================
[2025-09-20 13:21:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 13:22:53] Public, r: 32, Photo to CiteSeer: Best @ epoch 79: val=0.7549, test=0.7372 ===
[2025-09-20 13:23:27] Few(5), r: 32, Photo to PubMed: Best @ epoch 96: val=0.7500, test=0.7390 ===

================================================================================
[2025-09-20 13:23:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 13:23:34] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 187: val=0.7620, test=0.7470 ===
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 13:23:38] Public, r: 32, Photo to PubMed: Best @ epoch 77: val=0.8392, test=0.8398 ===

================================================================================
[2025-09-20 13:23:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-20 13:23:54] Few(10), r: 32, Photo to PubMed: Best @ epoch 55: val=0.8300, test=0.7670 ===

================================================================================
[2025-09-20 13:23:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 13:24:31] Few(5), r: 32, Cora to Computers: Best @ epoch 178: val=0.8004, test=0.7918 ===

================================================================================
[2025-09-20 13:24:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 13:26:00] Few(5), r: 32, Photo to PubMed: Best @ epoch 66: val=0.7480, test=0.7340 ===

================================================================================
[2025-09-20 13:26:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 13:26:28] Public, r: 32, Photo to PubMed: Best @ epoch 47: val=0.8483, test=0.8507 ===

================================================================================
[2025-09-20 13:26:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-20 13:26:39] Few(10), r: 32, Photo to PubMed: Best @ epoch 20: val=0.8160, test=0.7920 ===

================================================================================
[2025-09-20 13:26:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 13:28:17] Public, r: 32, Cora to Computers: Best @ epoch 313: val=0.9051, test=0.9008 ===

================================================================================
[2025-09-20 13:28:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 13:28:52] Few(10), r: 32, Cora to Computers: Best @ epoch 94: val=0.7780, test=0.7682 ===

================================================================================
[2025-09-20 13:28:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 13:28:58] Few(5), r: 32, Photo to PubMed: Best @ epoch 90: val=0.7440, test=0.7470 ===
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 13:29:19] Few(10), r: 32, Photo to PubMed: Best @ epoch 88: val=0.8100, test=0.7610 ===
[2025-09-20 13:29:26] Public, r: 32, Photo to PubMed: Best @ epoch 89: val=0.8407, test=0.8433 ===
[2025-09-20 13:33:42] Few(5), r: 32, Cora to Computers: Best @ epoch 44: val=0.7708, test=0.7618 ===

================================================================================
[2025-09-20 13:33:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 13:38:15] Public, r: 32, Cora to Computers: Best @ epoch 400: val=0.8945, test=0.9011 ===

================================================================================
[2025-09-20 13:38:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 13:40:53] Few(10), r: 32, Cora to Computers: Best @ epoch 150: val=0.7974, test=0.7930 ===

================================================================================
[2025-09-20 13:40:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 13:43:03] Few(5), r: 32, Cora to Computers: Best @ epoch 266: val=0.7675, test=0.7587 ===

================================================================================
[2025-09-20 13:43:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 13:48:44] Public, r: 32, Cora to Computers: Best @ epoch 312: val=0.9011, test=0.8971 ===

================================================================================
[2025-09-20 13:48:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 13:52:10] Few(5), r: 32, Cora to Computers: Best @ epoch 120: val=0.7595, test=0.7483 ===

================================================================================
[2025-09-20 13:52:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 13:52:43] Few(10), r: 32, Cora to Computers: Best @ epoch 441: val=0.7788, test=0.7748 ===

================================================================================
[2025-09-20 13:52:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 13:59:11] Public, r: 32, Cora to Computers: Best @ epoch 353: val=0.9120, test=0.8993 ===

================================================================================
[2025-09-20 13:59:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 14:02:05] Few(5), r: 32, Cora to Computers: Best @ epoch 30: val=0.7416, test=0.7274 ===
[2025-09-20 14:04:35] Few(10), r: 32, Cora to Computers: Best @ epoch 255: val=0.7872, test=0.7867 ===

================================================================================
[2025-09-20 14:04:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 14:09:37] Public, r: 32, Cora to Computers: Best @ epoch 263: val=0.8935, test=0.8979 ===
[2025-09-20 14:14:11] Few(10), r: 32, Cora to Computers: Best @ epoch 450: val=0.7799, test=0.7775 ===

================================================================================
[2025-09-20 17:47:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 17:47:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)

================================================================================
[2025-09-20 17:47:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 17:47:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-20 17:47:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 17:47:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)

================================================================================
[2025-09-20 17:47:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 17:47:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 17:47:39] Few(10), r: 32, Photo to Cora: Best @ epoch 29: val=0.7740, test=0.7380 ===

================================================================================
[2025-09-20 17:47:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 17:47:49] Few(5), r: 32, Photo to Cora: Best @ epoch 68: val=0.7120, test=0.7260 ===

================================================================================
[2025-09-20 17:47:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 17:47:56] Public, r: 32, Photo to Cora: Best @ epoch 58: val=0.8911, test=0.8579 ===

================================================================================
[2025-09-20 17:48:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 17:48:11] Few(10), r: 32, Photo to Cora: Best @ epoch 68: val=0.7600, test=0.7360 ===

================================================================================
[2025-09-20 17:48:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 17:48:26] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 48: val=0.5500, test=0.5700 ===

================================================================================
[2025-09-20 17:48:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 17:48:37] Few(5), r: 32, Photo to Cora: Best @ epoch 45: val=0.7180, test=0.7100 ===
[2025-09-20 17:48:38] Few(10), r: 32, Photo to Cora: Best @ epoch 57: val=0.7400, test=0.7210 ===
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-20 17:48:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 17:48:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 17:48:48] Public, r: 32, Photo to Cora: Best @ epoch 114: val=0.8856, test=0.8745 ===
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-20 17:48:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-20 17:49:03] Few(10), r: 32, Photo to Cora: Best @ epoch 83: val=0.7460, test=0.7410 ===

================================================================================
[2025-09-20 17:49:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 17:49:20] Public, r: 32, Photo to Photo: Best @ epoch 192: val=0.9261, test=0.9307 ===

================================================================================
[2025-09-20 17:49:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 17:49:25] Few(5), r: 32, Photo to Cora: Best @ epoch 94: val=0.6860, test=0.6850 ===
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 17:49:29] Few(5), r: 32, Photo to Photo: Best @ epoch 86: val=0.8876, test=0.8844 ===

================================================================================
[2025-09-20 17:49:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 17:49:31] Few(10), r: 32, Photo to Cora: Best @ epoch 27: val=0.7500, test=0.7310 ===

================================================================================
[2025-09-20 17:49:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 17:49:38] Public, r: 32, Photo to Cora: Best @ epoch 160: val=0.8764, test=0.8561 ===

================================================================================
[2025-09-20 17:49:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-20 17:50:00] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 52: val=0.7200, test=0.7110 ===

================================================================================
[2025-09-20 17:50:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 17:50:07] Few(10), r: 32, Photo to Photo: Best @ epoch 88: val=0.8871, test=0.8927 ===
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 17:50:10] Few(5), r: 32, Photo to Cora: Best @ epoch 49: val=0.7180, test=0.7440 ===

================================================================================
[2025-09-20 17:50:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 17:50:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 17:50:20] Public, r: 32, Photo to Cora: Best @ epoch 107: val=0.8782, test=0.8708 ===
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)

================================================================================
[2025-09-20 17:50:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-20 17:50:55] Few(5), r: 32, Photo to Cora: Best @ epoch 47: val=0.7360, test=0.7350 ===
[2025-09-20 17:51:10] Public, r: 32, Photo to Cora: Best @ epoch 87: val=0.8635, test=0.8635 ===
[2025-09-20 17:51:19] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 56: val=0.7300, test=0.7140 ===

================================================================================
[2025-09-20 17:51:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 17:51:28] Public, r: 32, Photo to Photo: Best @ epoch 190: val=0.9033, test=0.9092 ===
[2025-09-20 17:51:32] Few(5), r: 32, Photo to Photo: Best @ epoch 83: val=0.8673, test=0.8576 ===

================================================================================
[2025-09-20 17:51:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-20 17:51:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-20 17:52:37] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 67: val=0.7200, test=0.7220 ===

================================================================================
[2025-09-20 17:52:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 17:52:55] Few(10), r: 32, Photo to Photo: Best @ epoch 117: val=0.8956, test=0.8995 ===

================================================================================
[2025-09-20 17:53:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 17:53:36] Few(5), r: 32, Photo to Photo: Best @ epoch 183: val=0.8804, test=0.8773 ===

================================================================================
[2025-09-20 17:53:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-20 17:53:44] Public, r: 32, Photo to Photo: Best @ epoch 124: val=0.9281, test=0.9072 ===

================================================================================
[2025-09-20 17:53:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 17:53:56] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 182: val=0.7080, test=0.7090 ===
[2025-09-20 17:55:28] Few(10), r: 32, Photo to Photo: Best @ epoch 79: val=0.8884, test=0.8917 ===

================================================================================
[2025-09-20 17:55:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 17:55:50] Few(5), r: 32, Photo to Photo: Best @ epoch 89: val=0.8778, test=0.8734 ===

================================================================================
[2025-09-20 17:55:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 17:55:56] Public, r: 32, Photo to Photo: Best @ epoch 159: val=0.9255, test=0.9092 ===
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)

================================================================================
[2025-09-20 17:56:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 17:57:52] Few(10), r: 32, Photo to Photo: Best @ epoch 94: val=0.8970, test=0.9028 ===

================================================================================
[2025-09-20 17:57:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 17:58:05] Few(5), r: 32, Photo to Photo: Best @ epoch 110: val=0.8791, test=0.8699 ===
[2025-09-20 17:58:09] Public, r: 32, Photo to Photo: Best @ epoch 194: val=0.9379, test=0.9098 ===
[2025-09-20 17:59:01] Public, r: 32, Photo to Computers: Best @ epoch 490: val=0.8873, test=0.8899 ===

================================================================================
[2025-09-20 17:59:06] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 17:59:58] Few(10), r: 32, Photo to Photo: Best @ epoch 115: val=0.8884, test=0.8881 ===

================================================================================
[2025-09-20 18:04:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 18:04:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)

================================================================================
[2025-09-20 18:04:39] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 18:04:39] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)

================================================================================
[2025-09-20 18:04:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 18:04:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 18:04:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)

================================================================================
[2025-09-20 18:04:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 18:06:19] Public, r: 32, Photo to CiteSeer: Best @ epoch 162: val=0.7669, test=0.7192 ===

================================================================================
[2025-09-20 18:06:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-20 18:06:29] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 27: val=0.7000, test=0.6880 ===

================================================================================
[2025-09-20 18:06:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 18:07:22] Few(10), r: 32, Photo to PubMed: Best @ epoch 91: val=0.8140, test=0.7590 ===

================================================================================
[2025-09-20 18:07:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 18:07:40] Public, r: 32, Photo to PubMed: Best @ epoch 37: val=0.8516, test=0.8360 ===

================================================================================
[2025-09-20 18:07:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 18:07:47] Few(5), r: 32, Photo to PubMed: Best @ epoch 92: val=0.7460, test=0.7380 ===
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)

================================================================================
[2025-09-20 18:07:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 18:07:56] Public, r: 32, Photo to CiteSeer: Best @ epoch 186: val=0.7429, test=0.7598 ===
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-20 18:08:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-20 18:08:17] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 45: val=0.7180, test=0.7000 ===

================================================================================
[2025-09-20 18:08:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 18:09:33] Public, r: 32, Photo to CiteSeer: Best @ epoch 137: val=0.7699, test=0.7432 ===

================================================================================
[2025-09-20 18:09:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-20 18:10:11] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 105: val=0.7460, test=0.7410 ===

================================================================================
[2025-09-20 18:10:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 18:10:26] Few(10), r: 32, Photo to PubMed: Best @ epoch 43: val=0.8120, test=0.7630 ===
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-20 18:10:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 18:10:44] Public, r: 32, Photo to PubMed: Best @ epoch 93: val=0.8417, test=0.8392 ===
[2025-09-20 18:10:45] Few(5), r: 32, Photo to PubMed: Best @ epoch 65: val=0.7740, test=0.7680 ===

================================================================================
[2025-09-20 18:10:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 18:10:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 18:11:10] Public, r: 32, Photo to CiteSeer: Best @ epoch 162: val=0.7744, test=0.7477 ===

================================================================================
[2025-09-20 18:11:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-20 18:11:57] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 70: val=0.7320, test=0.7180 ===

================================================================================
[2025-09-20 18:12:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 18:12:47] Public, r: 32, Photo to CiteSeer: Best @ epoch 117: val=0.7549, test=0.7673 ===
[2025-09-20 18:13:13] Public, r: 32, Photo to PubMed: Best @ epoch 40: val=0.8425, test=0.8337 ===

================================================================================
[2025-09-20 18:13:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 18:13:20] Few(10), r: 32, Photo to PubMed: Best @ epoch 43: val=0.8260, test=0.7680 ===
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)

================================================================================
[2025-09-20 18:13:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 18:13:33] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 62: val=0.7520, test=0.7420 ===
[2025-09-20 18:13:44] Few(5), r: 32, Photo to PubMed: Best @ epoch 99: val=0.7600, test=0.7620 ===

================================================================================
[2025-09-20 18:13:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 18:14:20] Few(5), r: 32, Cora to Computers: Best @ epoch 101: val=0.7558, test=0.7496 ===

================================================================================
[2025-09-20 18:14:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 18:16:11] Public, r: 32, Photo to PubMed: Best @ epoch 81: val=0.8499, test=0.8367 ===
[2025-09-20 18:16:14] Few(10), r: 32, Photo to PubMed: Best @ epoch 27: val=0.8300, test=0.7880 ===

================================================================================
[2025-09-20 18:16:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 18:16:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 18:16:35] Few(5), r: 32, Photo to PubMed: Best @ epoch 23: val=0.7680, test=0.7640 ===

================================================================================
[2025-09-20 18:16:39] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 18:18:11] Public, r: 32, Cora to Computers: Best @ epoch 486: val=0.9109, test=0.8902 ===

================================================================================
[2025-09-20 18:18:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 18:18:18] Few(10), r: 32, Cora to Computers: Best @ epoch 391: val=0.7927, test=0.7785 ===
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)

================================================================================
[2025-09-20 18:18:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 18:18:46] Public, r: 32, Photo to PubMed: Best @ epoch 49: val=0.8369, test=0.8413 ===
[2025-09-20 18:19:04] Few(5), r: 32, Photo to PubMed: Best @ epoch 99: val=0.7700, test=0.7530 ===
[2025-09-20 18:19:11] Few(10), r: 32, Photo to PubMed: Best @ epoch 82: val=0.8260, test=0.7620 ===
[2025-09-20 18:23:24] Few(5), r: 32, Cora to Computers: Best @ epoch 35: val=0.7464, test=0.7443 ===

================================================================================
[2025-09-20 18:23:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 18:29:08] Few(10), r: 32, Cora to Computers: Best @ epoch 354: val=0.7784, test=0.7682 ===
[2025-09-20 18:29:08] Public, r: 32, Cora to Computers: Best @ epoch 319: val=0.9029, test=0.8993 ===

================================================================================
[2025-09-20 18:29:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 18:29:13] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 18:32:30] Few(5), r: 32, Cora to Computers: Best @ epoch 43: val=0.7434, test=0.7360 ===

================================================================================
[2025-09-20 18:32:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 18:39:29] Public, r: 32, Cora to Computers: Best @ epoch 403: val=0.9105, test=0.9055 ===

================================================================================
[2025-09-20 18:39:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 18:40:36] Few(10), r: 32, Cora to Computers: Best @ epoch 93: val=0.7813, test=0.7663 ===

================================================================================
[2025-09-20 18:40:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 18:42:23] Few(5), r: 32, Cora to Computers: Best @ epoch 254: val=0.7650, test=0.7627 ===

================================================================================
[2025-09-20 18:42:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 18:51:08] Public, r: 32, Cora to Computers: Best @ epoch 420: val=0.9058, test=0.8986 ===

================================================================================
[2025-09-20 18:51:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 18:52:28] Few(10), r: 32, Cora to Computers: Best @ epoch 442: val=0.7938, test=0.7870 ===
[2025-09-20 18:52:28] Few(5), r: 32, Cora to Computers: Best @ epoch 241: val=0.7558, test=0.7539 ===

================================================================================
[2025-09-20 18:52:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-20 19:02:32] Public, r: 32, Cora to Computers: Best @ epoch 416: val=0.9036, test=0.9095 ===
[2025-09-20 19:03:27] Few(10), r: 32, Cora to Computers: Best @ epoch 184: val=0.7839, test=0.7765 ===

================================================================================
[2025-09-20 23:27:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-20 23:27:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 23:27:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 23:27:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)

================================================================================
[2025-09-20 23:27:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 23:27:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-20 23:27:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 23:27:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-20 23:34:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 23:34:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)

================================================================================
[2025-09-20 23:34:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)

================================================================================
[2025-09-20 23:34:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-20 23:34:13] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-20 23:34:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 23:34:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)

================================================================================
[2025-09-20 23:34:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 23:34:35] Few(10), r: 32, Photo to Cora: Best @ epoch 9: val=0.7040, test=0.7120 ===

================================================================================
[2025-09-20 23:34:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 23:34:53] Few(5), r: 32, Photo to Cora: Best @ epoch 44: val=0.7280, test=0.7300 ===

================================================================================
[2025-09-20 23:34:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 23:35:02] Public, r: 32, Photo to Cora: Best @ epoch 47: val=0.8764, test=0.8524 ===
[2025-09-20 23:35:03] Few(10), r: 32, Photo to Cora: Best @ epoch 29: val=0.6960, test=0.7160 ===
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-20 23:35:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 23:35:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 23:35:32] Few(10), r: 32, Photo to Cora: Best @ epoch 79: val=0.7180, test=0.7070 ===

================================================================================
[2025-09-20 23:35:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 23:35:42] Public, r: 32, Photo to Cora: Best @ epoch 145: val=0.8708, test=0.8653 ===
[2025-09-20 23:35:43] Few(5), r: 32, Photo to Cora: Best @ epoch 27: val=0.6680, test=0.6570 ===
[2025-09-20 23:35:45] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 88: val=0.7300, test=0.7220 ===

================================================================================
[2025-09-20 23:35:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 23:35:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)

================================================================================
[2025-09-20 23:35:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 23:35:58] Few(10), r: 32, Photo to Cora: Best @ epoch 81: val=0.7360, test=0.7190 ===

================================================================================
[2025-09-20 23:36:03] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 23:36:12] Public, r: 32, Photo to Photo: Best @ epoch 196: val=0.9281, test=0.9176 ===

================================================================================
[2025-09-20 23:36:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 23:36:25] Few(10), r: 32, Photo to Cora: Best @ epoch 22: val=0.7540, test=0.7170 ===
[2025-09-20 23:36:25] Few(5), r: 32, Photo to Photo: Best @ epoch 129: val=0.8725, test=0.8688 ===
[2025-09-20 23:36:28] Few(5), r: 32, Photo to Cora: Best @ epoch 6: val=0.6140, test=0.6130 ===

================================================================================
[2025-09-20 23:36:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)

================================================================================
[2025-09-20 23:36:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 23:36:39] Public, r: 32, Photo to Cora: Best @ epoch 86: val=0.8616, test=0.8708 ===
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-20 23:36:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-20 23:36:48] Few(10), r: 32, Photo to Photo: Best @ epoch 92: val=0.8844, test=0.8892 ===

================================================================================
[2025-09-20 23:36:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 23:37:12] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 61: val=0.7260, test=0.7350 ===
[2025-09-20 23:37:14] Few(5), r: 32, Photo to Cora: Best @ epoch 30: val=0.6840, test=0.7090 ===

================================================================================
[2025-09-20 23:37:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 23:37:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-20 23:37:28] Public, r: 32, Photo to Cora: Best @ epoch 117: val=0.8801, test=0.8635 ===

================================================================================
[2025-09-20 23:37:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-20 23:38:03] Few(5), r: 32, Photo to Cora: Best @ epoch 45: val=0.7200, test=0.7320 ===
[2025-09-20 23:38:19] Public, r: 32, Photo to Photo: Best @ epoch 170: val=0.9340, test=0.9209 ===
[2025-09-20 23:38:20] Public, r: 32, Photo to Cora: Best @ epoch 60: val=0.8967, test=0.8579 ===

================================================================================
[2025-09-20 23:38:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 23:38:30] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 190: val=0.6300, test=0.6220 ===

================================================================================
[2025-09-20 23:38:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 23:38:49] Few(5), r: 32, Photo to Photo: Best @ epoch 115: val=0.8817, test=0.8765 ===

================================================================================
[2025-09-20 23:38:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-20 23:39:42] Few(10), r: 32, Photo to Photo: Best @ epoch 53: val=0.8844, test=0.8871 ===

================================================================================
[2025-09-20 23:39:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 23:39:48] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 52: val=0.6660, test=0.6440 ===
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)

================================================================================
[2025-09-20 23:39:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-20 23:40:35] Public, r: 32, Photo to Photo: Best @ epoch 127: val=0.9288, test=0.9268 ===

================================================================================
[2025-09-20 23:40:39] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 23:40:46] Few(5), r: 32, Photo to Photo: Best @ epoch 75: val=0.8903, test=0.8742 ===

================================================================================
[2025-09-20 23:40:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-20 23:41:09] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 182: val=0.6920, test=0.6960 ===
[2025-09-20 23:42:11] Few(10), r: 32, Photo to Photo: Best @ epoch 109: val=0.8844, test=0.8862 ===

================================================================================
[2025-09-20 23:42:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 23:42:34] Public, r: 32, Photo to Photo: Best @ epoch 143: val=0.9275, test=0.9242 ===

================================================================================
[2025-09-20 23:42:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 23:42:42] Few(5), r: 32, Photo to Photo: Best @ epoch 87: val=0.8804, test=0.8758 ===

================================================================================
[2025-09-20 23:42:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-20 23:44:21] Few(10), r: 32, Photo to Photo: Best @ epoch 78: val=0.9122, test=0.9061 ===

================================================================================
[2025-09-20 23:44:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 23:44:41] Public, r: 32, Photo to Photo: Best @ epoch 167: val=0.9451, test=0.9294 ===
[2025-09-20 23:44:53] Few(5), r: 32, Photo to Photo: Best @ epoch 125: val=0.8778, test=0.8699 ===
[2025-09-20 23:45:34] Public, r: 32, Photo to Computers: Best @ epoch 461: val=0.8847, test=0.8891 ===

================================================================================
[2025-09-20 23:45:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 23:46:48] Few(10), r: 32, Photo to Photo: Best @ epoch 127: val=0.8890, test=0.9008 ===
[2025-09-20 23:53:59] Public, r: 32, Photo to Computers: Best @ epoch 447: val=0.8815, test=0.8840 ===

================================================================================
[2025-09-20 23:54:03] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-21 00:03:12] Public, r: 32, Photo to Computers: Best @ epoch 426: val=0.8913, test=0.9059 ===

================================================================================
[2025-09-21 00:03:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-21 00:11:16] Public, r: 32, Photo to Computers: Best @ epoch 398: val=0.8916, test=0.8855 ===

================================================================================
[2025-09-21 00:11:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-21 00:18:51] Public, r: 32, Photo to Computers: Best @ epoch 432: val=0.8920, test=0.8975 ===

================================================================================
[2025-09-21 01:55:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-21 01:56:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 01:56:44] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 51: val=0.5540, test=0.5550 ===
[2025-09-21 01:56:49] Few(5), r: 32, Photo to Cora: Best @ epoch 49: val=0.7060, test=0.7010 ===

================================================================================
[2025-09-21 01:56:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-21 01:56:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 01:57:20] Few(5), r: 32, Photo to Cora: Best @ epoch 5: val=0.7220, test=0.7170 ===

================================================================================
[2025-09-21 01:57:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 01:57:45] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 156: val=0.6840, test=0.6900 ===

================================================================================
[2025-09-21 01:57:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-21 01:57:50] Few(5), r: 32, Photo to Cora: Best @ epoch 27: val=0.6960, test=0.6800 ===
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-21 01:57:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 01:58:14] Few(5), r: 32, Photo to Cora: Best @ epoch 32: val=0.7320, test=0.7240 ===

================================================================================
[2025-09-21 01:58:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 01:58:44] Few(5), r: 32, Photo to Cora: Best @ epoch 43: val=0.6800, test=0.6690 ===
[2025-09-21 01:58:48] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 77: val=0.7100, test=0.7270 ===

================================================================================
[2025-09-21 01:58:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 01:59:38] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 86: val=0.7160, test=0.7070 ===

================================================================================
[2025-09-21 01:59:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-21 02:00:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)

================================================================================
[2025-09-21 02:00:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-21 02:00:28] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 59: val=0.7240, test=0.7190 ===

================================================================================
[2025-09-21 02:01:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 02:01:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)

================================================================================
[2025-09-21 02:07:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-21 02:07:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 02:07:31] Few(5), r: 32, Photo to Cora: Best @ epoch 65: val=0.7280, test=0.7310 ===

================================================================================
[2025-09-21 02:07:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 02:08:02] Few(5), r: 32, Photo to Cora: Best @ epoch 84: val=0.6880, test=0.6860 ===

================================================================================
[2025-09-21 02:08:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 02:08:11] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 53: val=0.7180, test=0.7060 ===

================================================================================
[2025-09-21 02:08:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 02:08:34] Few(5), r: 32, Photo to Cora: Best @ epoch 73: val=0.7040, test=0.7210 ===

================================================================================
[2025-09-21 02:08:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 02:08:56] Few(5), r: 32, Photo to Computers: Best @ epoch 488: val=0.7398, test=0.7289 ===
[2025-09-21 02:08:58] Few(5), r: 32, Photo to Cora: Best @ epoch 68: val=0.7380, test=0.7300 ===

================================================================================
[2025-09-21 02:09:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 02:09:03] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 02:09:11] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 64: val=0.6960, test=0.7060 ===

================================================================================
[2025-09-21 02:09:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 02:09:26] Few(5), r: 32, Photo to Cora: Best @ epoch 33: val=0.7020, test=0.7130 ===
[2025-09-21 02:10:10] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 85: val=0.7220, test=0.7280 ===

================================================================================
[2025-09-21 02:10:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 02:10:18] Few(10), r: 32, Photo to Computers: Best @ epoch 321: val=0.7751, test=0.7711 ===

================================================================================
[2025-09-21 02:10:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-21 02:11:04] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 73: val=0.7080, test=0.7180 ===

================================================================================
[2025-09-21 02:11:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 02:12:07] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 120: val=0.7220, test=0.7280 ===
[2025-09-21 02:18:10] Few(5), r: 32, Photo to Computers: Best @ epoch 161: val=0.7697, test=0.7556 ===

================================================================================
[2025-09-21 02:18:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-21 02:19:32] Few(10), r: 32, Photo to Computers: Best @ epoch 111: val=0.7744, test=0.7666 ===

================================================================================
[2025-09-21 02:19:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-21 02:26:00] Few(5), r: 32, Photo to Computers: Best @ epoch 77: val=0.7464, test=0.7400 ===

================================================================================
[2025-09-21 02:26:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-21 02:28:57] Few(10), r: 32, Photo to Computers: Best @ epoch 221: val=0.7667, test=0.7555 ===

================================================================================
[2025-09-21 02:29:03] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-21 02:34:54] Few(5), r: 32, Photo to Computers: Best @ epoch 63: val=0.7551, test=0.7370 ===

================================================================================
[2025-09-21 02:35:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-21 02:36:41] Few(10), r: 32, Photo to Computers: Best @ epoch 143: val=0.7663, test=0.7619 ===

================================================================================
[2025-09-21 02:36:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-21 02:43:28] Few(5), r: 32, Photo to Computers: Best @ epoch 77: val=0.7540, test=0.7396 ===
[2025-09-21 02:45:47] Few(10), r: 32, Photo to Computers: Best @ epoch 159: val=0.7681, test=0.7530 ===

================================================================================
[2025-09-21 02:58:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:01:08] Public, r: 32, Photo to PubMed: Best @ epoch 52: val=0.8374, test=0.8354 ===

================================================================================
[2025-09-21 03:01:13] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:03:29] Public, r: 32, Photo to PubMed: Best @ epoch 43: val=0.8402, test=0.8390 ===

================================================================================
[2025-09-21 03:03:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:05:48] Public, r: 32, Photo to PubMed: Best @ epoch 73: val=0.8448, test=0.8380 ===

================================================================================
[2025-09-21 03:05:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:08:07] Public, r: 32, Photo to PubMed: Best @ epoch 54: val=0.8382, test=0.8463 ===

================================================================================
[2025-09-21 03:08:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:10:35] Public, r: 32, Photo to PubMed: Best @ epoch 78: val=0.8494, test=0.8329 ===

================================================================================
[2025-09-21 03:10:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)

================================================================================
[2025-09-21 03:14:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:17:18] Public, r: 32, Photo to PubMed: Best @ epoch 75: val=0.8395, test=0.8398 ===

================================================================================
[2025-09-21 03:17:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:19:36] Public, r: 32, Photo to PubMed: Best @ epoch 54: val=0.8397, test=0.8413 ===

================================================================================
[2025-09-21 03:19:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:22:03] Public, r: 32, Photo to PubMed: Best @ epoch 45: val=0.8463, test=0.8410 ===

================================================================================
[2025-09-21 03:22:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:24:24] Public, r: 32, Photo to PubMed: Best @ epoch 44: val=0.8336, test=0.8479 ===

================================================================================
[2025-09-21 03:24:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:27:28] Public, r: 32, Photo to PubMed: Best @ epoch 79: val=0.8468, test=0.8319 ===

================================================================================
[2025-09-21 03:27:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:29:52] Public, r: 32, Photo to PubMed: Best @ epoch 77: val=0.8435, test=0.8496 ===

================================================================================
[2025-09-21 03:29:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:32:12] Public, r: 32, Photo to PubMed: Best @ epoch 69: val=0.8425, test=0.8392 ===

================================================================================
[2025-09-21 03:32:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:35:01] Public, r: 32, Photo to PubMed: Best @ epoch 44: val=0.8412, test=0.8398 ===

================================================================================
[2025-09-21 03:35:06] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:37:28] Public, r: 32, Photo to PubMed: Best @ epoch 99: val=0.8392, test=0.8296 ===

================================================================================
[2025-09-21 03:37:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 03:39:49] Public, r: 32, Photo to PubMed: Best @ epoch 91: val=0.8445, test=0.8360 ===

================================================================================
[2025-09-21 03:39:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 03:42:08] Few(5), r: 32, Photo to PubMed: Best @ epoch 78: val=0.7820, test=0.7700 ===

================================================================================
[2025-09-21 03:42:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 03:44:26] Few(5), r: 32, Photo to PubMed: Best @ epoch 57: val=0.7480, test=0.7410 ===

================================================================================
[2025-09-21 03:44:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 03:46:47] Few(5), r: 32, Photo to PubMed: Best @ epoch 70: val=0.7640, test=0.7640 ===

================================================================================
[2025-09-21 03:46:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 03:49:06] Few(5), r: 32, Photo to PubMed: Best @ epoch 28: val=0.7380, test=0.7350 ===

================================================================================
[2025-09-21 03:49:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 03:51:25] Few(5), r: 32, Photo to PubMed: Best @ epoch 56: val=0.7500, test=0.7430 ===

================================================================================
[2025-09-21 03:51:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 03:53:45] Few(10), r: 32, Photo to PubMed: Best @ epoch 27: val=0.8040, test=0.7630 ===

================================================================================
[2025-09-21 03:53:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 03:56:04] Few(10), r: 32, Photo to PubMed: Best @ epoch 54: val=0.8100, test=0.7630 ===

================================================================================
[2025-09-21 03:56:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 03:58:23] Few(10), r: 32, Photo to PubMed: Best @ epoch 37: val=0.8240, test=0.7630 ===

================================================================================
[2025-09-21 03:58:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:00:45] Few(10), r: 32, Photo to PubMed: Best @ epoch 50: val=0.8240, test=0.7720 ===

================================================================================
[2025-09-21 04:00:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:03:17] Few(10), r: 32, Photo to PubMed: Best @ epoch 47: val=0.8280, test=0.7630 ===

================================================================================
[2025-09-21 04:03:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 04:04:23] Public, r: 32, Photo to CiteSeer: Best @ epoch 48: val=0.7910, test=0.7432 ===

================================================================================
[2025-09-21 04:04:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 04:05:15] Public, r: 32, Photo to CiteSeer: Best @ epoch 196: val=0.7579, test=0.7432 ===

================================================================================
[2025-09-21 04:05:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 04:06:04] Public, r: 32, Photo to CiteSeer: Best @ epoch 61: val=0.7594, test=0.7658 ===

================================================================================
[2025-09-21 04:06:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 04:06:53] Public, r: 32, Photo to CiteSeer: Best @ epoch 46: val=0.7278, test=0.7342 ===

================================================================================
[2025-09-21 04:06:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 04:07:43] Public, r: 32, Photo to CiteSeer: Best @ epoch 77: val=0.7880, test=0.7447 ===

================================================================================
[2025-09-21 04:07:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 04:08:34] Public, r: 32, Photo to CiteSeer: Best @ epoch 71: val=0.7835, test=0.7492 ===

================================================================================
[2025-09-21 04:08:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 04:09:21] Public, r: 32, Photo to CiteSeer: Best @ epoch 103: val=0.7654, test=0.7432 ===

================================================================================
[2025-09-21 04:09:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 04:10:13] Public, r: 32, Photo to CiteSeer: Best @ epoch 93: val=0.7699, test=0.7417 ===

================================================================================
[2025-09-21 04:10:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 04:11:02] Public, r: 32, Photo to CiteSeer: Best @ epoch 107: val=0.7549, test=0.7553 ===

================================================================================
[2025-09-21 04:11:06] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 04:11:52] Public, r: 32, Photo to CiteSeer: Best @ epoch 117: val=0.7639, test=0.7417 ===

================================================================================
[2025-09-21 04:11:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 04:12:42] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 59: val=0.5660, test=0.5890 ===

================================================================================
[2025-09-21 04:12:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 04:13:34] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 178: val=0.7420, test=0.7340 ===

================================================================================
[2025-09-21 04:13:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 04:14:19] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 29: val=0.6920, test=0.6570 ===

================================================================================
[2025-09-21 04:14:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 04:15:03] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 30: val=0.6920, test=0.6780 ===

================================================================================
[2025-09-21 04:15:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 04:15:49] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 165: val=0.6960, test=0.7000 ===

================================================================================
[2025-09-21 04:15:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:16:34] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 84: val=0.7280, test=0.7250 ===

================================================================================
[2025-09-21 04:16:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:17:27] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 47: val=0.7280, test=0.7300 ===

================================================================================
[2025-09-21 04:17:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:18:15] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 60: val=0.7420, test=0.7310 ===

================================================================================
[2025-09-21 04:18:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:19:04] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 43: val=0.7140, test=0.6870 ===

================================================================================
[2025-09-21 04:19:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:19:53] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 60: val=0.7280, test=0.7150 ===

================================================================================
[2025-09-21 04:19:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 04:20:32] Public, r: 32, Photo to Cora: Best @ epoch 178: val=0.8782, test=0.8782 ===

================================================================================
[2025-09-21 04:20:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 04:21:13] Public, r: 32, Photo to Cora: Best @ epoch 133: val=0.8653, test=0.8469 ===

================================================================================
[2025-09-21 04:21:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 04:21:54] Public, r: 32, Photo to Cora: Best @ epoch 65: val=0.8782, test=0.8708 ===

================================================================================
[2025-09-21 04:21:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 04:22:39] Public, r: 32, Photo to Cora: Best @ epoch 63: val=0.8690, test=0.8948 ===

================================================================================
[2025-09-21 04:22:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 04:23:21] Public, r: 32, Photo to Cora: Best @ epoch 136: val=0.8524, test=0.8635 ===

================================================================================
[2025-09-21 04:23:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 04:23:58] Public, r: 32, Photo to Cora: Best @ epoch 141: val=0.8708, test=0.8469 ===

================================================================================
[2025-09-21 04:24:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 04:24:38] Public, r: 32, Photo to Cora: Best @ epoch 47: val=0.8653, test=0.8745 ===

================================================================================
[2025-09-21 04:24:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 04:25:18] Public, r: 32, Photo to Cora: Best @ epoch 159: val=0.8856, test=0.8690 ===

================================================================================
[2025-09-21 04:25:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 04:25:57] Public, r: 32, Photo to Cora: Best @ epoch 93: val=0.8856, test=0.8358 ===

================================================================================
[2025-09-21 04:26:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 04:26:40] Public, r: 32, Photo to Cora: Best @ epoch 45: val=0.8838, test=0.8432 ===

================================================================================
[2025-09-21 04:26:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 04:27:01] Few(5), r: 32, Photo to Cora: Best @ epoch 87: val=0.6420, test=0.6410 ===

================================================================================
[2025-09-21 04:27:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 04:27:22] Few(5), r: 32, Photo to Cora: Best @ epoch 56: val=0.6820, test=0.6870 ===

================================================================================
[2025-09-21 04:27:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 04:27:46] Few(5), r: 32, Photo to Cora: Best @ epoch 60: val=0.7260, test=0.7390 ===

================================================================================
[2025-09-21 04:27:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 04:28:10] Few(5), r: 32, Photo to Cora: Best @ epoch 43: val=0.7080, test=0.7240 ===

================================================================================
[2025-09-21 04:28:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 04:28:31] Few(5), r: 32, Photo to Cora: Best @ epoch 77: val=0.7340, test=0.7350 ===

================================================================================
[2025-09-21 04:28:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:28:55] Few(10), r: 32, Photo to Cora: Best @ epoch 28: val=0.7640, test=0.7430 ===

================================================================================
[2025-09-21 04:28:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:29:24] Few(10), r: 32, Photo to Cora: Best @ epoch 28: val=0.6980, test=0.6940 ===

================================================================================
[2025-09-21 04:29:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:29:49] Few(10), r: 32, Photo to Cora: Best @ epoch 29: val=0.7700, test=0.7530 ===

================================================================================
[2025-09-21 04:29:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:30:18] Few(10), r: 32, Photo to Cora: Best @ epoch 42: val=0.7240, test=0.7030 ===

================================================================================
[2025-09-21 04:30:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 04:30:48] Few(10), r: 32, Photo to Cora: Best @ epoch 78: val=0.7220, test=0.7080 ===

================================================================================
[2025-09-21 04:30:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 04:32:31] Public, r: 32, Photo to Photo: Best @ epoch 178: val=0.9405, test=0.9255 ===

================================================================================
[2025-09-21 04:32:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 04:34:21] Public, r: 32, Photo to Photo: Best @ epoch 145: val=0.9275, test=0.9229 ===

================================================================================
[2025-09-21 04:34:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 04:35:58] Public, r: 32, Photo to Photo: Best @ epoch 124: val=0.9294, test=0.9176 ===

================================================================================
[2025-09-21 04:36:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 04:37:42] Public, r: 32, Photo to Photo: Best @ epoch 115: val=0.9281, test=0.9111 ===

================================================================================
[2025-09-21 04:37:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 04:39:24] Public, r: 32, Photo to Photo: Best @ epoch 163: val=0.9183, test=0.9170 ===

================================================================================
[2025-09-21 04:39:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 04:41:05] Public, r: 32, Photo to Photo: Best @ epoch 178: val=0.9320, test=0.9183 ===

================================================================================
[2025-09-21 04:41:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 04:42:43] Public, r: 32, Photo to Photo: Best @ epoch 145: val=0.9157, test=0.9157 ===

================================================================================
[2025-09-21 04:42:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 04:44:27] Public, r: 32, Photo to Photo: Best @ epoch 169: val=0.9386, test=0.9275 ===

================================================================================
[2025-09-21 04:44:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 04:46:02] Public, r: 32, Photo to Photo: Best @ epoch 168: val=0.9301, test=0.9229 ===

================================================================================
[2025-09-21 04:46:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 04:48:24] Public, r: 32, Photo to Photo: Best @ epoch 134: val=0.9163, test=0.9209 ===

================================================================================
[2025-09-21 04:48:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 04:50:39] Few(5), r: 32, Photo to Photo: Best @ epoch 144: val=0.8883, test=0.8803 ===

================================================================================
[2025-09-21 04:50:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 04:52:39] Few(5), r: 32, Photo to Photo: Best @ epoch 123: val=0.8844, test=0.8763 ===

================================================================================
[2025-09-21 04:52:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 04:54:49] Few(5), r: 32, Photo to Photo: Best @ epoch 198: val=0.8699, test=0.8627 ===

================================================================================
[2025-09-21 04:54:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 04:56:28] Few(5), r: 32, Photo to Photo: Best @ epoch 144: val=0.8870, test=0.8868 ===

================================================================================
[2025-09-21 04:56:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 04:58:13] Few(5), r: 32, Photo to Photo: Best @ epoch 179: val=0.8673, test=0.8653 ===

================================================================================
[2025-09-21 04:58:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 05:00:09] Few(10), r: 32, Photo to Photo: Best @ epoch 91: val=0.9036, test=0.9041 ===

================================================================================
[2025-09-21 05:00:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 05:02:02] Few(10), r: 32, Photo to Photo: Best @ epoch 114: val=0.8917, test=0.8899 ===

================================================================================
[2025-09-21 05:02:06] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 05:03:38] Few(10), r: 32, Photo to Photo: Best @ epoch 127: val=0.8904, test=0.8958 ===

================================================================================
[2025-09-21 05:03:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 05:05:37] Few(10), r: 32, Photo to Photo: Best @ epoch 98: val=0.8851, test=0.8861 ===

================================================================================
[2025-09-21 05:05:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 05:07:52] Few(10), r: 32, Photo to Photo: Best @ epoch 117: val=0.8851, test=0.8912 ===

================================================================================
[2025-09-21 05:09:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 05:12:15] Public, r: 32, Computers to PubMed: Best @ epoch 48: val=0.8400, test=0.8436 ===

================================================================================
[2025-09-21 05:12:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 05:15:27] Public, r: 32, Computers to PubMed: Best @ epoch 83: val=0.8473, test=0.8377 ===

================================================================================
[2025-09-21 05:15:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 05:18:40] Public, r: 32, Computers to PubMed: Best @ epoch 79: val=0.8423, test=0.8463 ===

================================================================================
[2025-09-21 05:18:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 05:21:50] Public, r: 32, Computers to PubMed: Best @ epoch 45: val=0.8410, test=0.8283 ===

================================================================================
[2025-09-21 05:21:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 05:24:46] Public, r: 32, Computers to PubMed: Best @ epoch 74: val=0.8494, test=0.8385 ===

================================================================================
[2025-09-21 05:24:51] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 05:27:53] Public, r: 32, Computers to PubMed: Best @ epoch 90: val=0.8491, test=0.8415 ===

================================================================================
[2025-09-21 05:27:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 05:30:16] Public, r: 32, Computers to PubMed: Best @ epoch 51: val=0.8453, test=0.8456 ===

================================================================================
[2025-09-21 05:30:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 05:32:38] Public, r: 32, Computers to PubMed: Best @ epoch 97: val=0.8476, test=0.8408 ===

================================================================================
[2025-09-21 05:32:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 05:35:38] Public, r: 32, Computers to PubMed: Best @ epoch 99: val=0.8445, test=0.8281 ===

================================================================================
[2025-09-21 05:35:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 05:38:48] Public, r: 32, Computers to PubMed: Best @ epoch 72: val=0.8331, test=0.8332 ===

================================================================================
[2025-09-21 05:38:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 05:42:04] Few(5), r: 32, Computers to PubMed: Best @ epoch 82: val=0.7560, test=0.7390 ===

================================================================================
[2025-09-21 05:42:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 05:45:17] Few(5), r: 32, Computers to PubMed: Best @ epoch 73: val=0.7740, test=0.7520 ===

================================================================================
[2025-09-21 05:45:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 05:47:43] Few(5), r: 32, Computers to PubMed: Best @ epoch 95: val=0.8000, test=0.7790 ===

================================================================================
[2025-09-21 05:47:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 05:50:53] Few(5), r: 32, Computers to PubMed: Best @ epoch 90: val=0.7500, test=0.7390 ===

================================================================================
[2025-09-21 05:50:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 05:54:05] Few(5), r: 32, Computers to PubMed: Best @ epoch 22: val=0.7400, test=0.7350 ===

================================================================================
[2025-09-21 05:54:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 05:57:18] Few(10), r: 32, Computers to PubMed: Best @ epoch 94: val=0.8100, test=0.7660 ===

================================================================================
[2025-09-21 05:57:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:00:31] Few(10), r: 32, Computers to PubMed: Best @ epoch 37: val=0.8280, test=0.7700 ===

================================================================================
[2025-09-21 06:00:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:03:41] Few(10), r: 32, Computers to PubMed: Best @ epoch 63: val=0.8180, test=0.7770 ===

================================================================================
[2025-09-21 06:03:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:06:52] Few(10), r: 32, Computers to PubMed: Best @ epoch 40: val=0.8160, test=0.7800 ===

================================================================================
[2025-09-21 06:06:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:09:15] Few(10), r: 32, Computers to PubMed: Best @ epoch 22: val=0.8220, test=0.7670 ===

================================================================================
[2025-09-21 06:09:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 06:10:13] Public, r: 32, Computers to CiteSeer: Best @ epoch 36: val=0.7489, test=0.7462 ===

================================================================================
[2025-09-21 06:10:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 06:11:04] Public, r: 32, Computers to CiteSeer: Best @ epoch 173: val=0.7684, test=0.7402 ===

================================================================================
[2025-09-21 06:11:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 06:11:56] Public, r: 32, Computers to CiteSeer: Best @ epoch 173: val=0.7519, test=0.7538 ===

================================================================================
[2025-09-21 06:12:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 06:12:44] Public, r: 32, Computers to CiteSeer: Best @ epoch 29: val=0.7639, test=0.7417 ===

================================================================================
[2025-09-21 06:12:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 06:13:31] Public, r: 32, Computers to CiteSeer: Best @ epoch 156: val=0.7759, test=0.7387 ===

================================================================================
[2025-09-21 06:13:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 06:14:25] Public, r: 32, Computers to CiteSeer: Best @ epoch 184: val=0.7489, test=0.7628 ===

================================================================================
[2025-09-21 06:14:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 06:15:27] Public, r: 32, Computers to CiteSeer: Best @ epoch 77: val=0.7684, test=0.7613 ===

================================================================================
[2025-09-21 06:15:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 06:16:30] Public, r: 32, Computers to CiteSeer: Best @ epoch 78: val=0.7278, test=0.7598 ===

================================================================================
[2025-09-21 06:16:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 06:17:19] Public, r: 32, Computers to CiteSeer: Best @ epoch 132: val=0.7865, test=0.7598 ===

================================================================================
[2025-09-21 06:17:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 06:18:06] Public, r: 32, Computers to CiteSeer: Best @ epoch 66: val=0.7729, test=0.7823 ===

================================================================================
[2025-09-21 06:18:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 06:18:52] Few(5), r: 32, Computers to CiteSeer: Best @ epoch 33: val=0.7540, test=0.7190 ===

================================================================================
[2025-09-21 06:18:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 06:19:41] Few(5), r: 32, Computers to CiteSeer: Best @ epoch 159: val=0.7620, test=0.7410 ===

================================================================================
[2025-09-21 06:19:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 06:20:30] Few(5), r: 32, Computers to CiteSeer: Best @ epoch 49: val=0.7260, test=0.7280 ===

================================================================================
[2025-09-21 06:20:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 06:21:17] Few(5), r: 32, Computers to CiteSeer: Best @ epoch 85: val=0.6760, test=0.6810 ===

================================================================================
[2025-09-21 06:21:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 06:22:04] Few(5), r: 32, Computers to CiteSeer: Best @ epoch 26: val=0.6900, test=0.6860 ===

================================================================================
[2025-09-21 06:22:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:22:55] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 65: val=0.7180, test=0.7250 ===

================================================================================
[2025-09-21 06:22:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:23:41] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 49: val=0.7240, test=0.7310 ===

================================================================================
[2025-09-21 06:23:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:24:30] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 65: val=0.6680, test=0.6820 ===

================================================================================
[2025-09-21 06:24:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:25:26] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 73: val=0.7220, test=0.7260 ===

================================================================================
[2025-09-21 06:25:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:26:13] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 48: val=0.7200, test=0.7100 ===

================================================================================
[2025-09-21 06:26:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 06:26:51] Public, r: 32, Computers to Cora: Best @ epoch 56: val=0.8745, test=0.8450 ===

================================================================================
[2025-09-21 06:26:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 06:27:36] Public, r: 32, Computers to Cora: Best @ epoch 89: val=0.8745, test=0.9004 ===

================================================================================
[2025-09-21 06:27:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 06:28:20] Public, r: 32, Computers to Cora: Best @ epoch 160: val=0.8967, test=0.8561 ===

================================================================================
[2025-09-21 06:28:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 06:29:13] Public, r: 32, Computers to Cora: Best @ epoch 58: val=0.8524, test=0.8930 ===

================================================================================
[2025-09-21 06:29:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 06:29:54] Public, r: 32, Computers to Cora: Best @ epoch 70: val=0.8469, test=0.8542 ===

================================================================================
[2025-09-21 06:29:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 06:30:33] Public, r: 32, Computers to Cora: Best @ epoch 136: val=0.8506, test=0.8542 ===

================================================================================
[2025-09-21 06:30:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 06:31:11] Public, r: 32, Computers to Cora: Best @ epoch 130: val=0.9077, test=0.8616 ===

================================================================================
[2025-09-21 06:31:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 06:31:51] Public, r: 32, Computers to Cora: Best @ epoch 176: val=0.9004, test=0.8967 ===

================================================================================
[2025-09-21 06:31:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 06:32:30] Public, r: 32, Computers to Cora: Best @ epoch 45: val=0.8727, test=0.8616 ===

================================================================================
[2025-09-21 06:32:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 06:33:09] Public, r: 32, Computers to Cora: Best @ epoch 165: val=0.8911, test=0.8561 ===

================================================================================
[2025-09-21 06:33:13] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 06:33:32] Few(5), r: 32, Computers to Cora: Best @ epoch 43: val=0.6960, test=0.7050 ===

================================================================================
[2025-09-21 06:33:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 06:33:56] Few(5), r: 32, Computers to Cora: Best @ epoch 29: val=0.6860, test=0.6670 ===

================================================================================
[2025-09-21 06:34:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 06:34:17] Few(5), r: 32, Computers to Cora: Best @ epoch 76: val=0.6540, test=0.6610 ===

================================================================================
[2025-09-21 06:34:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 06:34:43] Few(5), r: 32, Computers to Cora: Best @ epoch 24: val=0.6140, test=0.6030 ===

================================================================================
[2025-09-21 06:34:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 06:35:04] Few(5), r: 32, Computers to Cora: Best @ epoch 24: val=0.6620, test=0.6590 ===

================================================================================
[2025-09-21 06:35:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:35:27] Few(10), r: 32, Computers to Cora: Best @ epoch 29: val=0.7220, test=0.7030 ===

================================================================================
[2025-09-21 06:35:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:35:49] Few(10), r: 32, Computers to Cora: Best @ epoch 31: val=0.7300, test=0.7320 ===

================================================================================
[2025-09-21 06:35:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:36:12] Few(10), r: 32, Computers to Cora: Best @ epoch 70: val=0.7160, test=0.7110 ===

================================================================================
[2025-09-21 06:36:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:36:35] Few(10), r: 32, Computers to Cora: Best @ epoch 63: val=0.7600, test=0.7200 ===

================================================================================
[2025-09-21 06:36:39] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 06:36:56] Few(10), r: 32, Computers to Cora: Best @ epoch 27: val=0.7180, test=0.7090 ===

================================================================================
[2025-09-21 06:37:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 06:38:45] Public, r: 32, Computers to Photo: Best @ epoch 151: val=0.9288, test=0.9366 ===

================================================================================
[2025-09-21 06:38:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 06:40:34] Public, r: 32, Computers to Photo: Best @ epoch 147: val=0.9163, test=0.9255 ===

================================================================================
[2025-09-21 06:40:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 06:42:29] Public, r: 32, Computers to Photo: Best @ epoch 179: val=0.9196, test=0.9281 ===

================================================================================
[2025-09-21 06:42:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 06:44:12] Public, r: 32, Computers to Photo: Best @ epoch 147: val=0.9196, test=0.9216 ===

================================================================================
[2025-09-21 06:44:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 06:45:54] Public, r: 32, Computers to Photo: Best @ epoch 139: val=0.9229, test=0.9065 ===

================================================================================
[2025-09-21 06:45:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 06:47:45] Public, r: 32, Computers to Photo: Best @ epoch 86: val=0.9242, test=0.9216 ===

================================================================================
[2025-09-21 06:47:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 06:49:26] Public, r: 32, Computers to Photo: Best @ epoch 96: val=0.9059, test=0.9268 ===

================================================================================
[2025-09-21 06:49:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 06:51:28] Public, r: 32, Computers to Photo: Best @ epoch 128: val=0.9255, test=0.9261 ===

================================================================================
[2025-09-21 06:51:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 06:53:18] Public, r: 32, Computers to Photo: Best @ epoch 174: val=0.9320, test=0.9314 ===

================================================================================
[2025-09-21 06:53:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 06:55:06] Public, r: 32, Computers to Photo: Best @ epoch 144: val=0.9203, test=0.9261 ===

================================================================================
[2025-09-21 06:55:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 06:56:44] Few(5), r: 32, Computers to Photo: Best @ epoch 145: val=0.8811, test=0.8762 ===

================================================================================
[2025-09-21 06:56:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 06:58:32] Few(5), r: 32, Computers to Photo: Best @ epoch 95: val=0.8784, test=0.8693 ===

================================================================================
[2025-09-21 06:58:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 07:00:33] Few(5), r: 32, Computers to Photo: Best @ epoch 145: val=0.8515, test=0.8591 ===

================================================================================
[2025-09-21 07:00:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 07:02:18] Few(5), r: 32, Computers to Photo: Best @ epoch 79: val=0.8857, test=0.8793 ===

================================================================================
[2025-09-21 07:02:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 07:03:57] Few(5), r: 32, Computers to Photo: Best @ epoch 149: val=0.8883, test=0.8735 ===

================================================================================
[2025-09-21 07:04:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 07:05:35] Few(10), r: 32, Computers to Photo: Best @ epoch 85: val=0.8890, test=0.8924 ===

================================================================================
[2025-09-21 07:05:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 07:07:17] Few(10), r: 32, Computers to Photo: Best @ epoch 129: val=0.8904, test=0.8922 ===

================================================================================
[2025-09-21 07:07:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 07:08:59] Few(10), r: 32, Computers to Photo: Best @ epoch 121: val=0.8910, test=0.8836 ===

================================================================================
[2025-09-21 07:09:03] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 07:10:49] Few(10), r: 32, Computers to Photo: Best @ epoch 99: val=0.8871, test=0.8942 ===

================================================================================
[2025-09-21 07:10:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 07:12:33] Few(10), r: 32, Computers to Photo: Best @ epoch 161: val=0.8851, test=0.8919 ===

================================================================================
[2025-09-21 13:03:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 13:03:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 13:03:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 13:03:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 13:03:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 13:07:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 13:07:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 13:07:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 13:07:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 13:07:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 13:09:55] Public, r: 32, Photo to PubMed: Best @ epoch 50: val=0.8425, test=0.8408 ===
[2025-09-21 13:10:19] Public, r: 32, Photo to PubMed: Best @ epoch 50: val=0.8433, test=0.8367 ===
[2025-09-21 13:10:21] Public, r: 32, Photo to PubMed: Best @ epoch 55: val=0.8392, test=0.8309 ===
[2025-09-21 13:10:24] Public, r: 32, Photo to PubMed: Best @ epoch 40: val=0.8324, test=0.8415 ===
[2025-09-21 13:10:26] Public, r: 32, Photo to PubMed: Best @ epoch 46: val=0.8453, test=0.8322 ===

================================================================================
[2025-09-21 15:13:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 15:13:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 15:13:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 15:13:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 15:13:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-21 15:15:44] Public, r: 32, Photo to PubMed: Best @ epoch 87: val=0.8379, test=0.8431 ===

================================================================================
[2025-09-21 15:15:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 15:16:13] Public, r: 32, Photo to PubMed: Best @ epoch 87: val=0.8463, test=0.8382 ===

================================================================================
[2025-09-21 15:16:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-21 15:16:23] Public, r: 32, Photo to PubMed: Best @ epoch 67: val=0.8509, test=0.8294 ===
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 15:16:28] Public, r: 32, Photo to PubMed: Best @ epoch 74: val=0.8524, test=0.8347 ===

================================================================================
[2025-09-21 15:16:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-21 15:16:30] Public, r: 32, Photo to PubMed: Best @ epoch 43: val=0.8362, test=0.8456 ===
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-21 15:16:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 15:16:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 15:18:41] Few(5), r: 32, Photo to PubMed: Best @ epoch 21: val=0.7460, test=0.7300 ===

================================================================================
[2025-09-21 15:18:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:19:02] Few(5), r: 32, Photo to PubMed: Best @ epoch 91: val=0.7580, test=0.7620 ===

================================================================================
[2025-09-21 15:19:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:19:13] Few(5), r: 32, Photo to PubMed: Best @ epoch 88: val=0.7740, test=0.7250 ===

================================================================================
[2025-09-21 15:19:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:19:28] Few(5), r: 32, Photo to PubMed: Best @ epoch 92: val=0.7560, test=0.7440 ===
[2025-09-21 15:19:29] Few(5), r: 32, Photo to PubMed: Best @ epoch 93: val=0.7540, test=0.7630 ===

================================================================================
[2025-09-21 15:19:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 15:19:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:21:32] Few(10), r: 32, Photo to PubMed: Best @ epoch 66: val=0.7980, test=0.7590 ===

================================================================================
[2025-09-21 15:21:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 15:22:07] Few(10), r: 32, Photo to PubMed: Best @ epoch 25: val=0.8140, test=0.7780 ===
[2025-09-21 15:22:10] Few(10), r: 32, Photo to PubMed: Best @ epoch 37: val=0.8320, test=0.7630 ===
[2025-09-21 15:22:12] Few(10), r: 32, Photo to PubMed: Best @ epoch 90: val=0.8140, test=0.7490 ===

================================================================================
[2025-09-21 15:22:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)

================================================================================
[2025-09-21 15:22:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)

================================================================================
[2025-09-21 15:22:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-21 15:22:25] Few(10), r: 32, Photo to PubMed: Best @ epoch 38: val=0.8000, test=0.7600 ===
[2025-09-21 15:22:29] Public, r: 32, Photo to CiteSeer: Best @ epoch 199: val=0.7504, test=0.7447 ===

================================================================================
[2025-09-21 15:22:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)

================================================================================
[2025-09-21 15:22:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 15:23:10] Public, r: 32, Photo to CiteSeer: Best @ epoch 39: val=0.7534, test=0.7508 ===
[2025-09-21 15:23:13] Public, r: 32, Photo to CiteSeer: Best @ epoch 51: val=0.7308, test=0.7748 ===
[2025-09-21 15:23:14] Public, r: 32, Photo to CiteSeer: Best @ epoch 35: val=0.7534, test=0.7342 ===

================================================================================
[2025-09-21 15:23:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-21 15:23:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-21 15:23:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 15:23:29] Public, r: 32, Photo to CiteSeer: Best @ epoch 44: val=0.7383, test=0.7252 ===

================================================================================
[2025-09-21 15:23:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-21 15:23:34] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 82: val=0.7080, test=0.7180 ===
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-21 15:23:39] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:24:06] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 78: val=0.6860, test=0.6810 ===

================================================================================
[2025-09-21 15:24:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:24:12] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 189: val=0.7440, test=0.7430 ===

================================================================================
[2025-09-21 15:24:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:24:20] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 163: val=0.6620, test=0.6420 ===

================================================================================
[2025-09-21 15:24:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:24:32] Few(5), r: 32, Photo to CiteSeer: Best @ epoch 138: val=0.6940, test=0.7110 ===
[2025-09-21 15:24:33] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 97: val=0.7220, test=0.7330 ===

================================================================================
[2025-09-21 15:24:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 15:24:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 15:25:03] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 68: val=0.7160, test=0.7300 ===
[2025-09-21 15:25:05] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 82: val=0.6820, test=0.6960 ===

================================================================================
[2025-09-21 15:25:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)

================================================================================
[2025-09-21 15:25:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 15:25:21] Public, r: 32, Photo to Cora: Best @ epoch 109: val=0.8579, test=0.8524 ===

================================================================================
[2025-09-21 15:25:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-21 15:25:26] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 71: val=0.7280, test=0.7260 ===
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-21 15:25:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 15:25:38] Few(10), r: 32, Photo to CiteSeer: Best @ epoch 93: val=0.7040, test=0.6980 ===

================================================================================
[2025-09-21 15:25:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-21 15:25:48] Few(5), r: 32, Photo to Cora: Best @ epoch 35: val=0.5920, test=0.5940 ===

================================================================================
[2025-09-21 15:25:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:25:54] Public, r: 32, Photo to Cora: Best @ epoch 133: val=0.8616, test=0.8524 ===
[2025-09-21 15:25:56] Public, r: 32, Photo to Cora: Best @ epoch 113: val=0.8727, test=0.8727 ===

================================================================================
[2025-09-21 15:26:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-21 15:26:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 15:26:16] Few(10), r: 32, Photo to Cora: Best @ epoch 41: val=0.7260, test=0.6950 ===
[2025-09-21 15:26:21] Public, r: 32, Photo to Cora: Best @ epoch 125: val=0.8708, test=0.8542 ===

================================================================================
[2025-09-21 15:26:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 15:26:24] Few(5), r: 32, Photo to Cora: Best @ epoch 96: val=0.5760, test=0.5800 ===
[2025-09-21 15:26:25] Few(5), r: 32, Photo to Cora: Best @ epoch 31: val=0.6600, test=0.6630 ===

================================================================================
[2025-09-21 15:26:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-21 15:26:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-21 15:26:30] Public, r: 32, Photo to Cora: Best @ epoch 169: val=0.8616, test=0.8339 ===
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-21 15:26:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-21 15:26:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-21 15:26:48] Few(5), r: 32, Photo to Cora: Best @ epoch 70: val=0.6580, test=0.6450 ===
[2025-09-21 15:26:53] Few(10), r: 32, Photo to Cora: Best @ epoch 46: val=0.7520, test=0.7630 ===

================================================================================
[2025-09-21 15:26:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:26:54] Few(10), r: 32, Photo to Cora: Best @ epoch 28: val=0.7360, test=0.7120 ===

================================================================================
[2025-09-21 15:26:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-21 15:26:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-21 15:27:00] Few(5), r: 32, Photo to Cora: Best @ epoch 46: val=0.6920, test=0.6970 ===
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-21 15:27:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-21 15:27:15] Few(10), r: 32, Photo to Cora: Best @ epoch 27: val=0.7300, test=0.7200 ===

================================================================================
[2025-09-21 15:27:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 15:27:28] Few(10), r: 32, Photo to Cora: Best @ epoch 43: val=0.7560, test=0.7400 ===

================================================================================
[2025-09-21 15:27:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-21 15:28:22] Public, r: 32, Photo to Photo: Best @ epoch 177: val=0.9216, test=0.9268 ===

================================================================================
[2025-09-21 15:28:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 15:29:08] Public, r: 32, Photo to Photo: Best @ epoch 164: val=0.9235, test=0.9255 ===
[2025-09-21 15:29:13] Public, r: 32, Photo to Photo: Best @ epoch 112: val=0.9340, test=0.9176 ===

================================================================================
[2025-09-21 15:29:13] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)

================================================================================
[2025-09-21 15:29:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 15:29:29] Public, r: 32, Photo to Photo: Best @ epoch 119: val=0.9209, test=0.9216 ===

================================================================================
[2025-09-21 15:29:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 15:29:46] Public, r: 32, Photo to Photo: Best @ epoch 159: val=0.9346, test=0.9281 ===

================================================================================
[2025-09-21 15:29:51] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-21 15:30:26] Few(5), r: 32, Photo to Photo: Best @ epoch 97: val=0.8916, test=0.8798 ===

================================================================================
[2025-09-21 15:30:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 15:31:13] Few(5), r: 32, Photo to Photo: Best @ epoch 107: val=0.8922, test=0.8877 ===
[2025-09-21 15:31:16] Few(5), r: 32, Photo to Photo: Best @ epoch 130: val=0.8515, test=0.8514 ===

================================================================================
[2025-09-21 15:31:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)

================================================================================
[2025-09-21 15:31:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 15:31:37] Few(5), r: 32, Photo to Photo: Best @ epoch 132: val=0.8653, test=0.8653 ===

================================================================================
[2025-09-21 15:31:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 15:32:02] Few(5), r: 32, Photo to Photo: Best @ epoch 123: val=0.8857, test=0.8816 ===

================================================================================
[2025-09-21 15:32:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-21 15:32:26] Few(10), r: 32, Photo to Photo: Best @ epoch 103: val=0.8937, test=0.8976 ===

================================================================================
[2025-09-21 15:32:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-21 15:33:20] Few(10), r: 32, Photo to Photo: Best @ epoch 101: val=0.8956, test=0.9003 ===

================================================================================
[2025-09-21 15:33:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-21 15:33:29] Few(10), r: 32, Photo to Photo: Best @ epoch 97: val=0.9003, test=0.8996 ===

================================================================================
[2025-09-21 15:33:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-21 15:33:55] Few(10), r: 32, Photo to Photo: Best @ epoch 64: val=0.8890, test=0.8899 ===
[2025-09-21 15:33:56] Few(10), r: 32, Photo to Photo: Best @ epoch 67: val=0.8950, test=0.8986 ===

================================================================================
[2025-09-21 15:34:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-21 15:34:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-21 15:41:00] Public, r: 32, Photo to Computers: Best @ epoch 493: val=0.8942, test=0.8848 ===

================================================================================
[2025-09-21 15:41:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-21 15:42:47] Public, r: 32, Photo to Computers: Best @ epoch 329: val=0.8967, test=0.8830 ===

================================================================================
[2025-09-21 15:42:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-21 15:43:18] Public, r: 32, Photo to Computers: Best @ epoch 411: val=0.8924, test=0.8949 ===

================================================================================
[2025-09-21 15:43:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-21 15:44:03] Public, r: 32, Photo to Computers: Best @ epoch 399: val=0.8949, test=0.8931 ===

================================================================================
[2025-09-21 15:44:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-21 15:44:22] Public, r: 32, Photo to Computers: Best @ epoch 494: val=0.8825, test=0.8862 ===

================================================================================
[2025-09-21 15:44:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-21 15:49:15] Few(5), r: 32, Photo to Computers: Best @ epoch 60: val=0.7810, test=0.7722 ===

================================================================================
[2025-09-21 15:49:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-21 15:51:17] Few(5), r: 32, Photo to Computers: Best @ epoch 79: val=0.7599, test=0.7564 ===

================================================================================
[2025-09-21 15:51:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-21 15:53:02] Few(5), r: 32, Photo to Computers: Best @ epoch 447: val=0.7766, test=0.7667 ===

================================================================================
[2025-09-21 15:53:06] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-21 15:54:27] Few(5), r: 32, Photo to Computers: Best @ epoch 50: val=0.7839, test=0.7825 ===

================================================================================
[2025-09-21 15:54:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-21 15:54:46] Few(5), r: 32, Photo to Computers: Best @ epoch 307: val=0.7405, test=0.7336 ===

================================================================================
[2025-09-21 15:54:51] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-21 15:58:13] Few(10), r: 32, Photo to Computers: Best @ epoch 152: val=0.7670, test=0.7514 ===
[2025-09-21 15:59:44] Few(10), r: 32, Photo to Computers: Best @ epoch 146: val=0.7824, test=0.7778 ===
[2025-09-21 16:02:52] Few(10), r: 32, Photo to Computers: Best @ epoch 225: val=0.7692, test=0.7567 ===
[2025-09-21 16:03:25] Few(10), r: 32, Photo to Computers: Best @ epoch 132: val=0.7681, test=0.7567 ===
[2025-09-21 16:03:46] Few(10), r: 32, Photo to Computers: Best @ epoch 213: val=0.7711, test=0.7593 ===

================================================================================
[2025-09-22 01:35:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-22 01:35:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-22 01:35:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-22 01:35:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-22 01:35:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-22 01:44:48] Public, r: 32, Computers to Computers: Best @ epoch 488: val=0.9000, test=0.8939 ===

================================================================================
[2025-09-22 01:44:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-22 01:45:01] Public, r: 32, Computers to Computers: Best @ epoch 373: val=0.8953, test=0.8855 ===

================================================================================
[2025-09-22 01:45:06] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-22 01:45:12] Public, r: 32, Computers to Computers: Best @ epoch 350: val=0.8884, test=0.8909 ===

================================================================================
[2025-09-22 01:45:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-22 01:46:10] Public, r: 32, Computers to Computers: Best @ epoch 396: val=0.8811, test=0.8989 ===

================================================================================
[2025-09-22 01:46:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-22 01:46:21] Public, r: 32, Computers to Computers: Best @ epoch 496: val=0.8949, test=0.8793 ===

================================================================================
[2025-09-22 01:46:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-22 01:55:04] Few(5), r: 32, Computers to Computers: Best @ epoch 70: val=0.7544, test=0.7536 ===

================================================================================
[2025-09-22 01:55:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-22 01:55:32] Few(5), r: 32, Computers to Computers: Best @ epoch 66: val=0.7310, test=0.7241 ===

================================================================================
[2025-09-22 01:55:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-22 01:55:48] Few(5), r: 32, Computers to Computers: Best @ epoch 74: val=0.7259, test=0.7242 ===

================================================================================
[2025-09-22 01:55:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-22 01:56:24] Few(5), r: 32, Computers to Computers: Best @ epoch 68: val=0.7755, test=0.7711 ===

================================================================================
[2025-09-22 01:56:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-22 01:56:32] Few(5), r: 32, Computers to Computers: Best @ epoch 65: val=0.7551, test=0.7468 ===

================================================================================
[2025-09-22 01:56:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-22 02:05:15] Few(10), r: 32, Computers to Computers: Best @ epoch 261: val=0.7623, test=0.7517 ===
[2025-09-22 02:05:22] Few(10), r: 32, Computers to Computers: Best @ epoch 156: val=0.7758, test=0.7591 ===
[2025-09-22 02:05:51] Few(10), r: 32, Computers to Computers: Best @ epoch 209: val=0.7692, test=0.7497 ===
[2025-09-22 02:06:00] Few(10), r: 32, Computers to Computers: Best @ epoch 443: val=0.7663, test=0.7657 ===
[2025-09-22 02:06:37] Few(10), r: 32, Computers to Computers: Best @ epoch 342: val=0.7740, test=0.7745 ===

================================================================================
[2025-09-22 23:31:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 16, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 32.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-22 23:34:14] Public, r: 16, PubMed to CiteSeer: Best @ epoch 174: val=0.7579, test=0.7477 ===

================================================================================
[2025-09-22 23:36:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=99, val=2730, test=10923 (mode=few, shot=10)
[2025-09-23 03:32:38] Few(10), r: 32, Computers to Computers: Best @ epoch 214: val=0.7868, test=0.7774 ===

================================================================================
[2025-09-24 02:05:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-24 02:06:43] Public, r: 32, PubMed to CiteSeer: Best @ epoch 198: val=0.7474, test=0.7703 ===

================================================================================
[2025-09-24 02:07:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-24 02:07:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-24 02:07:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-24 02:07:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-24 02:07:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-24 02:10:31] Public, r: 32, PubMed to PubMed: Best @ epoch 39: val=0.8308, test=0.8233 ===

================================================================================
[2025-09-24 02:10:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-24 02:10:46] Public, r: 32, PubMed to PubMed: Best @ epoch 95: val=0.8319, test=0.8266 ===
[2025-09-24 02:10:49] Public, r: 32, PubMed to PubMed: Best @ epoch 76: val=0.8298, test=0.8294 ===

================================================================================
[2025-09-24 02:10:51] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-24 02:10:51] Public, r: 32, PubMed to PubMed: Best @ epoch 64: val=0.8352, test=0.8200 ===

================================================================================
[2025-09-24 02:10:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-24 02:10:54] Public, r: 32, PubMed to PubMed: Best @ epoch 82: val=0.8303, test=0.8332 ===

================================================================================
[2025-09-24 02:10:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-24 02:11:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-24 02:13:35] Few(5), r: 32, PubMed to PubMed: Best @ epoch 45: val=0.7200, test=0.7000 ===
[2025-09-24 02:13:40] Few(5), r: 32, PubMed to PubMed: Best @ epoch 35: val=0.7160, test=0.7010 ===

================================================================================
[2025-09-24 02:13:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-24 02:13:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-24 02:13:45] Few(5), r: 32, PubMed to PubMed: Best @ epoch 31: val=0.7100, test=0.7080 ===
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-24 02:13:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-24 02:13:54] Few(5), r: 32, PubMed to PubMed: Best @ epoch 44: val=0.7120, test=0.6960 ===
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-24 02:13:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-24 02:14:00] Few(5), r: 32, PubMed to PubMed: Best @ epoch 41: val=0.7300, test=0.7080 ===

================================================================================
[2025-09-24 02:14:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-24 02:16:21] Few(10), r: 32, PubMed to PubMed: Best @ epoch 49: val=0.7880, test=0.7130 ===

================================================================================
[2025-09-24 02:16:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-24 02:16:28] Few(10), r: 32, PubMed to PubMed: Best @ epoch 27: val=0.7820, test=0.7030 ===

================================================================================
[2025-09-24 02:16:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-24 02:16:46] Few(10), r: 32, PubMed to PubMed: Best @ epoch 17: val=0.7800, test=0.7420 ===

================================================================================
[2025-09-24 02:16:51] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-24 02:16:53] Few(10), r: 32, PubMed to PubMed: Best @ epoch 83: val=0.8000, test=0.7510 ===

================================================================================
[2025-09-24 02:16:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-24 02:16:59] Few(10), r: 32, PubMed to PubMed: Best @ epoch 46: val=0.7900, test=0.7450 ===

================================================================================
[2025-09-24 02:17:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-24 02:17:11] Public, r: 32, PubMed to Cora: Best @ epoch 138: val=0.8672, test=0.8524 ===

================================================================================
[2025-09-24 02:17:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-24 02:17:21] Public, r: 32, PubMed to Cora: Best @ epoch 151: val=0.8727, test=0.8764 ===

================================================================================
[2025-09-24 02:17:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-24 02:17:36] Public, r: 32, PubMed to Cora: Best @ epoch 162: val=0.8432, test=0.8967 ===
[2025-09-24 02:17:38] Few(5), r: 32, PubMed to Cora: Best @ epoch 53: val=0.6680, test=0.6540 ===

================================================================================
[2025-09-24 02:17:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-24 02:17:42] Public, r: 32, PubMed to Cora: Best @ epoch 71: val=0.8801, test=0.8838 ===

================================================================================
[2025-09-24 02:17:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-24 02:17:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-24 02:17:50] Few(5), r: 32, PubMed to Cora: Best @ epoch 81: val=0.6800, test=0.7110 ===

================================================================================
[2025-09-24 02:17:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-24 02:17:57] Public, r: 32, PubMed to Cora: Best @ epoch 172: val=0.8856, test=0.8819 ===

================================================================================
[2025-09-24 02:18:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-24 02:18:06] Few(5), r: 32, PubMed to Cora: Best @ epoch 73: val=0.6800, test=0.6940 ===
[2025-09-24 02:18:10] Few(10), r: 32, PubMed to Cora: Best @ epoch 24: val=0.7340, test=0.7480 ===

================================================================================
[2025-09-24 02:18:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-24 02:18:12] Few(5), r: 32, PubMed to Cora: Best @ epoch 44: val=0.6900, test=0.6920 ===

================================================================================
[2025-09-24 02:18:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-24 02:18:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-24 02:18:22] Few(10), r: 32, PubMed to Cora: Best @ epoch 78: val=0.7520, test=0.7130 ===
[2025-09-24 02:18:27] Few(5), r: 32, PubMed to Cora: Best @ epoch 32: val=0.6660, test=0.6650 ===

================================================================================
[2025-09-24 02:18:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-24 02:18:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-24 02:18:35] Few(10), r: 32, PubMed to Cora: Best @ epoch 20: val=0.7600, test=0.7580 ===

================================================================================
[2025-09-24 02:18:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-24 02:18:40] Few(10), r: 32, PubMed to Cora: Best @ epoch 66: val=0.7520, test=0.7220 ===
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-24 02:18:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-24 02:18:54] Few(10), r: 32, PubMed to Cora: Best @ epoch 59: val=0.7260, test=0.7290 ===

================================================================================
[2025-09-24 02:18:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-24 02:20:35] Public, r: 32, PubMed to Photo: Best @ epoch 156: val=0.9359, test=0.9275 ===
[2025-09-24 02:20:36] Public, r: 32, PubMed to Photo: Best @ epoch 198: val=0.9386, test=0.9418 ===

================================================================================
[2025-09-24 02:20:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-24 02:20:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-24 02:20:45] Public, r: 32, PubMed to Photo: Best @ epoch 159: val=0.9359, test=0.9359 ===
[2025-09-24 02:20:45] Public, r: 32, PubMed to Photo: Best @ epoch 186: val=0.9392, test=0.9386 ===

================================================================================
[2025-09-24 02:20:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-24 02:20:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-24 02:21:02] Public, r: 32, PubMed to Photo: Best @ epoch 191: val=0.9451, test=0.9373 ===

================================================================================
[2025-09-24 02:21:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-24 02:22:30] Few(5), r: 32, PubMed to Photo: Best @ epoch 135: val=0.8765, test=0.8699 ===

================================================================================
[2025-09-24 02:22:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-24 02:22:55] Few(5), r: 32, PubMed to Photo: Best @ epoch 81: val=0.8627, test=0.8652 ===

================================================================================
[2025-09-24 02:23:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-24 02:23:00] Few(5), r: 32, PubMed to Photo: Best @ epoch 66: val=0.8673, test=0.8617 ===
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)

================================================================================
[2025-09-24 02:23:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-24 02:23:05] Few(5), r: 32, PubMed to Photo: Best @ epoch 126: val=0.8693, test=0.8657 ===
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-24 02:23:10] Few(5), r: 32, PubMed to Photo: Best @ epoch 81: val=0.8673, test=0.8620 ===

================================================================================
[2025-09-24 02:23:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)

================================================================================
[2025-09-24 02:23:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/PubMed.GRACE.GAT.hyp_True.True.20250911-161024.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-24 02:24:47] Few(10), r: 32, PubMed to Photo: Best @ epoch 137: val=0.8712, test=0.8800 ===
[2025-09-24 02:25:00] Few(10), r: 32, PubMed to Photo: Best @ epoch 129: val=0.8758, test=0.8744 ===
[2025-09-24 02:25:03] Few(10), r: 32, PubMed to Photo: Best @ epoch 78: val=0.8818, test=0.8843 ===
[2025-09-24 02:25:17] Few(10), r: 32, PubMed to Photo: Best @ epoch 94: val=0.8705, test=0.8810 ===
[2025-09-24 02:25:20] Few(10), r: 32, PubMed to Photo: Best @ epoch 119: val=0.8923, test=0.8963 ===

================================================================================
[2025-10-02 17:02:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-10-02 17:04:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:04:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:04:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:04:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:04:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-10-02 17:17:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:17:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:17:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:17:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:17:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-10-02 17:17:51] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 16: val=0.4640, test=0.4490 ===
[2025-10-02 17:17:51] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 20: val=0.4580, test=0.4420 ===
[2025-10-02 17:17:52] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 18: val=0.5140, test=0.5340 ===
[2025-10-02 17:17:52] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 17: val=0.4860, test=0.5030 ===
[2025-10-02 17:17:55] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 15: val=0.6680, test=0.6400 ===

================================================================================
[2025-10-02 17:26:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:26:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:26:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:26:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:26:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-10-02 17:26:43] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 17: val=0.4620, test=0.4500 ===
[2025-10-02 17:26:43] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 73: val=0.4960, test=0.4780 ===
[2025-10-02 17:26:44] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 34: val=0.5140, test=0.4590 ===
[2025-10-02 17:26:44] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 136: val=0.3860, test=0.3810 ===
[2025-10-02 17:26:44] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 16: val=0.5480, test=0.5280 ===

================================================================================
[2025-10-02 17:27:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:27:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:27:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:27:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:27:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-10-02 17:28:31] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 16: val=0.4520, test=0.4160 ===
[2025-10-02 17:28:32] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 66: val=0.5360, test=0.5150 ===
[2025-10-02 17:28:32] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 64: val=0.5160, test=0.4840 ===
[2025-10-02 17:28:32] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 17: val=0.5720, test=0.5420 ===
[2025-10-02 17:28:32] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 19: val=0.4080, test=0.3820 ===

================================================================================
[2025-10-02 17:29:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:29:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:29:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:29:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:29:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-10-02 17:30:25] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 28: val=0.4800, test=0.4610 ===
[2025-10-02 17:30:25] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 26: val=0.4860, test=0.4800 ===
[2025-10-02 17:30:25] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 17: val=0.5780, test=0.5580 ===
[2025-10-02 17:30:26] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 62: val=0.4320, test=0.3940 ===
[2025-10-02 17:30:27] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 16: val=0.5080, test=0.4620 ===

================================================================================
[2025-10-02 17:30:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:30:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:30:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:30:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:30:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-10-02 17:31:20] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 65: val=0.7020, test=0.6800 ===
[2025-10-02 17:31:20] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 62: val=0.6660, test=0.6590 ===
[2025-10-02 17:31:21] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 72: val=0.6700, test=0.6650 ===
[2025-10-02 17:31:21] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 63: val=0.7300, test=0.7110 ===
[2025-10-02 17:31:22] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 45: val=0.6740, test=0.6740 ===

================================================================================
[2025-10-02 17:54:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:54:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:54:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:54:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:54:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-10-02 17:54:59] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 71: val=0.7200, test=0.7130 ===
[2025-10-02 17:55:00] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 143: val=0.6860, test=0.6490 ===
[2025-10-02 17:55:00] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 101: val=0.7140, test=0.6900 ===
[2025-10-02 17:55:00] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 81: val=0.6960, test=0.6810 ===
[2025-10-02 17:55:00] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 43: val=0.7220, test=0.7130 ===

================================================================================
[2025-10-02 17:56:06] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:56:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:56:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:56:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-10-02 17:56:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 0, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-10-02 17:56:46] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 23: val=0.7140, test=0.7080 ===
[2025-10-02 17:56:46] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 58: val=0.6920, test=0.6700 ===
[2025-10-02 17:56:47] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 96: val=0.7100, test=0.7090 ===
[2025-10-02 17:56:47] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 48: val=0.7240, test=0.6940 ===
[2025-10-02 17:56:48] Few(10), r: 32, Computers to CiteSeer: Best @ epoch 72: val=0.7060, test=0.6610 ===
