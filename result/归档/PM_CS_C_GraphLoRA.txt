
================================================================================
[2025-09-19 20:49:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:49:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:49:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:49:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:49:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:49:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 20:52:23] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 13: val=0.8220, test=0.7740 ===
[2025-09-19 20:52:23] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 39: val=0.8220, test=0.7740 ===
[2025-09-19 20:52:24] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 67: val=0.8140, test=0.7550 ===
[2025-09-19 20:52:24] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 14: val=0.8200, test=0.7590 ===
[2025-09-19 20:52:24] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 69: val=0.8280, test=0.7620 ===
[2025-09-19 20:52:25] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 14: val=0.8260, test=0.7660 ===

================================================================================
[2025-09-19 20:52:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:52:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:52:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:52:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:52:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:52:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 20:55:15] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 85: val=0.7200, test=0.7080 ===
[2025-09-19 20:55:16] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 36: val=0.7300, test=0.7310 ===
[2025-09-19 20:55:17] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 99: val=0.7220, test=0.7150 ===
[2025-09-19 20:55:17] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 36: val=0.7300, test=0.7350 ===
[2025-09-19 20:55:18] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 36: val=0.7200, test=0.7040 ===

================================================================================
[2025-09-19 20:55:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 20:55:19] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 77: val=0.7240, test=0.7180 ===

================================================================================
[2025-09-19 20:55:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:55:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:55:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:55:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 20:55:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 20:58:06] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 16: val=0.8200, test=0.7550 ===
[2025-09-19 20:58:09] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 55: val=0.8140, test=0.7530 ===
[2025-09-19 20:58:09] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 68: val=0.8200, test=0.7690 ===
[2025-09-19 20:58:10] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 14: val=0.8320, test=0.7710 ===
[2025-09-19 20:58:11] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 15: val=0.8240, test=0.7480 ===
[2025-09-19 20:58:12] Few: shot, r: 32, CiteSeer to PubMed: Best @ epoch 14: val=0.8300, test=0.7660 ===

================================================================================
#################################################################################################################################











[2025-09-19 21:23:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-19 21:26:14] Public, r: 32, CiteSeer to PubMed: Best @ epoch 52: val=0.8382, test=0.8347 ===

================================================================================
[2025-09-19 21:40:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:40:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:40:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:40:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)

================================================================================
[2025-09-19 21:40:51] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:40:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-19 21:43:50] Public, r: 32, CiteSeer to PubMed: Best @ epoch 31: val=0.8473, test=0.8382 ===

================================================================================
[2025-09-19 21:43:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 21:43:56] Public, r: 32, CiteSeer to PubMed: Best @ epoch 31: val=0.8341, test=0.8385 ===
[2025-09-19 21:43:57] Public, r: 32, CiteSeer to PubMed: Best @ epoch 46: val=0.8397, test=0.8387 ===
[2025-09-19 21:43:59] Public, r: 32, CiteSeer to PubMed: Best @ epoch 43: val=0.8463, test=0.8377 ===
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 21:44:01] Public, r: 32, CiteSeer to PubMed: Best @ epoch 42: val=0.8438, test=0.8342 ===

================================================================================
[2025-09-19 21:44:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:44:03] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:44:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 21:44:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 21:44:14] Public, r: 32, CiteSeer to PubMed: Best @ epoch 44: val=0.8400, test=0.8370 ===

================================================================================
[2025-09-19 21:44:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 21:46:51] Few(5), r: 32, CiteSeer to PubMed: Best @ epoch 77: val=0.7120, test=0.7040 ===

================================================================================
[2025-09-19 21:46:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:47:13] Few(5), r: 32, CiteSeer to PubMed: Best @ epoch 49: val=0.7240, test=0.7100 ===
[2025-09-19 21:47:13] Few(5), r: 32, CiteSeer to PubMed: Best @ epoch 37: val=0.7280, test=0.7170 ===
[2025-09-19 21:47:17] Few(5), r: 32, CiteSeer to PubMed: Best @ epoch 43: val=0.7160, test=0.7210 ===

================================================================================
[2025-09-19 21:47:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:47:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 21:47:21] Few(5), r: 32, CiteSeer to PubMed: Best @ epoch 34: val=0.7140, test=0.7030 ===

================================================================================
[2025-09-19 21:47:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-19 21:47:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:47:42] Few(5), r: 32, CiteSeer to PubMed: Best @ epoch 88: val=0.7240, test=0.7080 ===

================================================================================
[2025-09-19 21:47:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:50:07] Few(10), r: 32, CiteSeer to PubMed: Best @ epoch 92: val=0.8180, test=0.7580 ===
[2025-09-19 21:50:19] Few(10), r: 32, CiteSeer to PubMed: Best @ epoch 65: val=0.8220, test=0.7680 ===

================================================================================
[2025-09-19 21:50:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-19 21:50:29] Few(10), r: 32, CiteSeer to PubMed: Best @ epoch 18: val=0.8180, test=0.7650 ===
[2025-09-19 21:50:31] Few(10), r: 32, CiteSeer to PubMed: Best @ epoch 13: val=0.8280, test=0.7710 ===

================================================================================
[2025-09-19 21:50:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-19 21:50:36] Few(10), r: 32, CiteSeer to PubMed: Best @ epoch 84: val=0.8200, test=0.7690 ===

================================================================================
[2025-09-19 21:50:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)

================================================================================
[2025-09-19 21:50:47] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)

================================================================================
[2025-09-19 21:50:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-19 21:50:55] Few(10), r: 32, CiteSeer to PubMed: Best @ epoch 59: val=0.8260, test=0.7760 ===

================================================================================
[2025-09-19 21:51:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-19 21:51:18] Public, r: 32, CiteSeer to CiteSeer: Best @ epoch 54: val=0.7594, test=0.7703 ===

================================================================================
[2025-09-19 21:51:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 21:51:35] Public, r: 32, CiteSeer to CiteSeer: Best @ epoch 197: val=0.7805, test=0.7673 ===

================================================================================
[2025-09-19 21:51:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 21:51:45] Public, r: 32, CiteSeer to CiteSeer: Best @ epoch 108: val=0.7820, test=0.7898 ===
[2025-09-19 21:51:48] Public, r: 32, CiteSeer to CiteSeer: Best @ epoch 151: val=0.7609, test=0.7432 ===

================================================================================
[2025-09-19 21:51:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 21:51:53] Public, r: 32, CiteSeer to CiteSeer: Best @ epoch 31: val=0.7940, test=0.7973 ===
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 21:51:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 21:51:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 21:52:11] Public, r: 32, CiteSeer to CiteSeer: Best @ epoch 60: val=0.7789, test=0.7583 ===

================================================================================
[2025-09-19 21:52:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 21:52:23] Few(5), r: 32, CiteSeer to CiteSeer: Best @ epoch 31: val=0.7620, test=0.7390 ===

================================================================================
[2025-09-19 21:52:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:52:40] Few(5), r: 32, CiteSeer to CiteSeer: Best @ epoch 27: val=0.7220, test=0.7160 ===

================================================================================
[2025-09-19 21:52:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:52:53] Few(5), r: 32, CiteSeer to CiteSeer: Best @ epoch 183: val=0.7100, test=0.7180 ===
[2025-09-19 21:52:54] Few(5), r: 32, CiteSeer to CiteSeer: Best @ epoch 33: val=0.7600, test=0.7390 ===

================================================================================
[2025-09-19 21:52:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:52:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 21:53:00] Few(5), r: 32, CiteSeer to CiteSeer: Best @ epoch 40: val=0.7500, test=0.7370 ===
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-19 21:53:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:53:15] Few(5), r: 32, CiteSeer to CiteSeer: Best @ epoch 39: val=0.7420, test=0.7360 ===

================================================================================
[2025-09-19 21:53:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:53:28] Few(10), r: 32, CiteSeer to CiteSeer: Best @ epoch 37: val=0.7480, test=0.7290 ===

================================================================================
[2025-09-19 21:53:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 21:53:44] Few(10), r: 32, CiteSeer to CiteSeer: Best @ epoch 32: val=0.7360, test=0.7270 ===
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-19 21:53:58] Few(10), r: 32, CiteSeer to CiteSeer: Best @ epoch 38: val=0.7380, test=0.7310 ===
[2025-09-19 21:53:58] Few(10), r: 32, CiteSeer to CiteSeer: Best @ epoch 33: val=0.7400, test=0.7300 ===

================================================================================
[2025-09-19 21:53:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-19 21:54:05] Few(10), r: 32, CiteSeer to CiteSeer: Best @ epoch 33: val=0.7600, test=0.7390 ===

================================================================================
[2025-09-19 21:54:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:54:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-19 21:54:20] Few(10), r: 32, CiteSeer to CiteSeer: Best @ epoch 39: val=0.7360, test=0.7190 ===

================================================================================
[2025-09-19 21:54:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-19 21:54:27] Public, r: 32, CiteSeer to Cora: Best @ epoch 38: val=0.9041, test=0.8893 ===

================================================================================
[2025-09-19 21:54:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 21:54:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-19 21:54:48] Public, r: 32, CiteSeer to Cora: Best @ epoch 36: val=0.8672, test=0.8708 ===

================================================================================
[2025-09-19 21:54:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 21:54:57] Few(5), r: 32, CiteSeer to Cora: Best @ epoch 50: val=0.7400, test=0.7540 ===

================================================================================
[2025-09-19 21:55:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 21:55:02] Public, r: 32, CiteSeer to Cora: Best @ epoch 69: val=0.8930, test=0.8561 ===
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:55:05] Public, r: 32, CiteSeer to Cora: Best @ epoch 32: val=0.8819, test=0.8856 ===

================================================================================
[2025-09-19 21:55:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 21:55:08] Public, r: 32, CiteSeer to Cora: Best @ epoch 33: val=0.8875, test=0.8856 ===
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 21:55:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 21:55:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 21:55:21] Public, r: 32, CiteSeer to Cora: Best @ epoch 87: val=0.8616, test=0.8745 ===
[2025-09-19 21:55:23] Few(5), r: 32, CiteSeer to Cora: Best @ epoch 13: val=0.7200, test=0.7260 ===
[2025-09-19 21:55:25] Few(10), r: 32, CiteSeer to Cora: Best @ epoch 13: val=0.7680, test=0.7420 ===

================================================================================
[2025-09-19 21:55:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 21:55:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:55:35] Few(5), r: 32, CiteSeer to Cora: Best @ epoch 28: val=0.7340, test=0.7580 ===
[2025-09-19 21:55:36] Few(5), r: 32, CiteSeer to Cora: Best @ epoch 53: val=0.7440, test=0.7540 ===
[2025-09-19 21:55:40] Few(5), r: 32, CiteSeer to Cora: Best @ epoch 74: val=0.7400, test=0.7500 ===

================================================================================
[2025-09-19 21:55:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-19 21:55:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-19 21:55:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:55:51] Few(5), r: 32, CiteSeer to Cora: Best @ epoch 77: val=0.7260, test=0.7290 ===
[2025-09-19 21:55:53] Few(10), r: 32, CiteSeer to Cora: Best @ epoch 18: val=0.7640, test=0.7380 ===

================================================================================
[2025-09-19 21:55:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 21:56:07] Few(10), r: 32, CiteSeer to Cora: Best @ epoch 97: val=0.7640, test=0.7670 ===
[2025-09-19 21:56:10] Few(10), r: 32, CiteSeer to Cora: Best @ epoch 75: val=0.7300, test=0.7670 ===
[2025-09-19 21:56:11] Few(10), r: 32, CiteSeer to Cora: Best @ epoch 52: val=0.7600, test=0.7410 ===
[2025-09-19 21:56:21] Few(10), r: 32, CiteSeer to Cora: Best @ epoch 15: val=0.7520, test=0.7290 ===

================================================================================
[2025-09-19 21:56:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)

================================================================================
[2025-09-19 21:56:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)

================================================================================
[2025-09-19 21:57:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)

================================================================================
[2025-09-19 21:57:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:57:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)

================================================================================
[2025-09-19 21:57:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[2025-09-19 21:59:35] Public, r: 32, Cora to PubMed: Best @ epoch 35: val=0.8377, test=0.8294 ===

================================================================================
[2025-09-19 21:59:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 21:59:43] Public, r: 32, Cora to PubMed: Best @ epoch 35: val=0.8301, test=0.8357 ===
[2025-09-19 21:59:43] Public, r: 32, Cora to PubMed: Best @ epoch 39: val=0.8313, test=0.8403 ===
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 21:59:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 21:59:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:00:19] Public, r: 32, Cora to PubMed: Best @ epoch 66: val=0.8387, test=0.8398 ===
[2025-09-19 22:00:22] Public, r: 32, Cora to PubMed: Best @ epoch 34: val=0.8435, test=0.8433 ===

================================================================================
[2025-09-19 22:00:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:00:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:00:30] Public, r: 32, Cora to PubMed: Best @ epoch 53: val=0.8303, test=0.8377 ===
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 22:00:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:02:34] Few(5), r: 32, Cora to PubMed: Best @ epoch 92: val=0.7220, test=0.7100 ===

================================================================================
[2025-09-19 22:02:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 22:02:41] Few(5), r: 32, Cora to PubMed: Best @ epoch 49: val=0.7380, test=0.7100 ===
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-19 22:02:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 22:02:49] Few(5), r: 32, Cora to PubMed: Best @ epoch 53: val=0.7460, test=0.7290 ===
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-19 22:02:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:03:02] Few(5), r: 32, Cora to PubMed: Best @ epoch 58: val=0.7360, test=0.7140 ===

================================================================================
[2025-09-19 22:03:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:03:16] Few(5), r: 32, Cora to PubMed: Best @ epoch 47: val=0.7260, test=0.7160 ===

================================================================================
[2025-09-19 22:03:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:03:30] Few(5), r: 32, Cora to PubMed: Best @ epoch 70: val=0.7260, test=0.7070 ===

================================================================================
[2025-09-19 22:03:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:05:54] Few(10), r: 32, Cora to PubMed: Best @ epoch 35: val=0.8240, test=0.7610 ===
[2025-09-19 22:05:55] Few(10), r: 32, Cora to PubMed: Best @ epoch 18: val=0.8300, test=0.7700 ===
[2025-09-19 22:06:10] Few(10), r: 32, Cora to PubMed: Best @ epoch 19: val=0.8360, test=0.7690 ===
[2025-09-19 22:06:11] Few(10), r: 32, Cora to PubMed: Best @ epoch 19: val=0.8400, test=0.7690 ===

================================================================================
[2025-09-19 22:06:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:06:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-19 22:06:26] Few(10), r: 32, Cora to PubMed: Best @ epoch 40: val=0.8240, test=0.7530 ===

================================================================================
[2025-09-19 22:06:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:06:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-19 22:06:40] Few(10), r: 32, Cora to PubMed: Best @ epoch 20: val=0.8340, test=0.7600 ===

================================================================================
[2025-09-19 22:06:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)

================================================================================
[2025-09-19 22:06:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1996, val=665, test=666 (mode=public, shot=N/A)
[2025-09-19 22:07:04] Public, r: 32, Cora to CiteSeer: Best @ epoch 39: val=0.7549, test=0.7673 ===

================================================================================
[2025-09-19 22:07:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:07:12] Public, r: 32, Cora to CiteSeer: Best @ epoch 50: val=0.7444, test=0.7508 ===

================================================================================
[2025-09-19 22:07:17] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:07:20] Public, r: 32, Cora to CiteSeer: Best @ epoch 171: val=0.7474, test=0.7688 ===

================================================================================
[2025-09-19 22:07:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:07:34] Public, r: 32, Cora to CiteSeer: Best @ epoch 50: val=0.7714, test=0.7628 ===

================================================================================
[2025-09-19 22:07:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 22:07:41] Public, r: 32, Cora to CiteSeer: Best @ epoch 168: val=0.7714, test=0.7943 ===
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 22:07:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:07:53] Public, r: 32, Cora to CiteSeer: Best @ epoch 199: val=0.7865, test=0.7538 ===

================================================================================
[2025-09-19 22:07:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:08:17] Few(5), r: 32, Cora to CiteSeer: Best @ epoch 138: val=0.7080, test=0.7060 ===
[2025-09-19 22:08:19] Few(5), r: 32, Cora to CiteSeer: Best @ epoch 36: val=0.7060, test=0.7050 ===

================================================================================
[2025-09-19 22:08:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 22:08:23] Few(5), r: 32, Cora to CiteSeer: Best @ epoch 39: val=0.7560, test=0.7460 ===
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-19 22:08:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-19 22:08:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:08:44] Few(5), r: 32, Cora to CiteSeer: Best @ epoch 160: val=0.6980, test=0.6950 ===
[2025-09-19 22:08:45] Few(5), r: 32, Cora to CiteSeer: Best @ epoch 45: val=0.7440, test=0.7300 ===

================================================================================
[2025-09-19 22:08:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-19 22:08:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:08:58] Few(5), r: 32, Cora to CiteSeer: Best @ epoch 37: val=0.7480, test=0.7440 ===

================================================================================
[2025-09-19 22:09:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:09:20] Few(10), r: 32, Cora to CiteSeer: Best @ epoch 28: val=0.7320, test=0.7300 ===
[2025-09-19 22:09:27] Few(10), r: 32, Cora to CiteSeer: Best @ epoch 136: val=0.7260, test=0.7410 ===
[2025-09-19 22:09:28] Few(10), r: 32, Cora to CiteSeer: Best @ epoch 41: val=0.7400, test=0.7280 ===

================================================================================
[2025-09-19 22:09:35] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)

================================================================================
[2025-09-19 22:09:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)

================================================================================
[2025-09-19 22:09:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-19 22:09:46] Few(10), r: 32, Cora to CiteSeer: Best @ epoch 38: val=0.7640, test=0.7480 ===
[2025-09-19 22:09:48] Few(10), r: 32, Cora to CiteSeer: Best @ epoch 30: val=0.7300, test=0.7200 ===
[2025-09-19 22:09:57] Few(10), r: 32, Cora to CiteSeer: Best @ epoch 38: val=0.7300, test=0.7250 ===

================================================================================
[2025-09-19 22:10:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)

================================================================================
[2025-09-19 22:10:03] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)

================================================================================
[2025-09-19 22:10:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[2025-09-19 22:10:22] Public, r: 32, Cora to Cora: Best @ epoch 33: val=0.8967, test=0.8561 ===
[2025-09-19 22:10:27] Public, r: 32, Cora to Cora: Best @ epoch 104: val=0.8948, test=0.8672 ===

================================================================================
[2025-09-19 22:10:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)

================================================================================
[2025-09-19 22:10:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:10:38] Public, r: 32, Cora to Cora: Best @ epoch 146: val=0.8745, test=0.8358 ===

================================================================================
[2025-09-19 22:10:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:10:49] Public, r: 32, Cora to Cora: Best @ epoch 173: val=0.8819, test=0.8745 ===
[2025-09-19 22:10:50] Public, r: 32, Cora to Cora: Best @ epoch 41: val=0.8727, test=0.8875 ===

================================================================================
[2025-09-19 22:10:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:10:56] Few(5), r: 32, Cora to Cora: Best @ epoch 22: val=0.7380, test=0.7440 ===

================================================================================
[2025-09-19 22:10:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[2025-09-19 22:10:57] Public, r: 32, Cora to Cora: Best @ epoch 147: val=0.8690, test=0.8653 ===
[2025-09-19 22:10:58] Few(5), r: 32, Cora to Cora: Best @ epoch 65: val=0.7240, test=0.7410 ===

================================================================================
[2025-09-19 22:11:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:11:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)

================================================================================
[2025-09-19 22:11:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:11:07] Few(5), r: 32, Cora to Cora: Best @ epoch 59: val=0.7420, test=0.7450 ===

================================================================================
[2025-09-19 22:11:12] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:11:19] Few(5), r: 32, Cora to Cora: Best @ epoch 45: val=0.7520, test=0.7560 ===
[2025-09-19 22:11:21] Few(5), r: 32, Cora to Cora: Best @ epoch 93: val=0.7340, test=0.7450 ===

================================================================================
[2025-09-19 22:11:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:11:25] Few(10), r: 32, Cora to Cora: Best @ epoch 68: val=0.7440, test=0.7610 ===

================================================================================
[2025-09-19 22:11:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-19 22:11:26] Few(5), r: 32, Cora to Cora: Best @ epoch 25: val=0.7040, test=0.6990 ===
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:11:29] Few(10), r: 32, Cora to Cora: Best @ epoch 19: val=0.7820, test=0.7600 ===

================================================================================
[2025-09-19 22:11:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[2025-09-19 22:11:35] Few(10), r: 32, Cora to Cora: Best @ epoch 21: val=0.7700, test=0.7520 ===
[2025-09-19 22:11:47] Few(10), r: 32, Cora to Cora: Best @ epoch 64: val=0.7380, test=0.7350 ===
[2025-09-19 22:11:49] Few(10), r: 32, Cora to Cora: Best @ epoch 19: val=0.7780, test=0.7610 ===
[2025-09-19 22:11:53] Few(10), r: 32, Cora to Cora: Best @ epoch 21: val=0.7720, test=0.7690 ===

================================================================================
[2025-09-19 22:12:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:43] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:12:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:28] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:31] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:36] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:38] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:13:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:14:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:14:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:14:05] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:14:48] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:14:51] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:14:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:14:54] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:14:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:14:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:00] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:02] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:03] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:13] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 10.0, 'l3': 2.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:19] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:21] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:23] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 2.5, 'l3': 1.0, 'l4': 0.5, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:25] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'PubMed', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.1, 'wd2': 0.0005, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.05, 'lr3': 1e-05, 'l1': 0.5, 'l2': 5.0, 'l3': 1.0, 'l4': 0.1, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:30] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:37] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:40] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:42] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:45] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:46] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.02, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.7, 'l2': 0.5, 'l3': 1.0, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:52] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:53] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:15:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'CiteSeer', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.002, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 0.5, 'l2': 1.0, 'l3': 2.0, 'l4': 10.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:16:07] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:16:08] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:16:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.001, 'wd3': 0.1, 'lr1': 0.001, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 2.0, 'l3': 0.5, 'l4': 5.0, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:16:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:16:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:16:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:16:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:16:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-19 22:16:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Cora', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth', 'wd1': 0.01, 'wd2': 0.0001, 'wd3': 0.1, 'lr1': 0.005, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 1.0, 'l4': 2.0, 'num_epochs': 100}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
