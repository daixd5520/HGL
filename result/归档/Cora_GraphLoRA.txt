
================================================================================
[2025-09-20 00:35:50] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 00:37:29] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-20 00:37:57] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 00:37:58] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-20 00:37:59] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-20 00:38:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 00:38:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)

================================================================================
[2025-09-20 00:38:01] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-07, 'wd3': 0.1, 'lr1': 0.02, 'lr2': 0.1, 'lr3': 1e-05, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=4590, val=1530, test=1530 (mode=public, shot=N/A)
[2025-09-20 00:40:04] Public, r: 32, CiteSeer to Photo: Best @ epoch 155: val=0.9314, test=0.9275 ===
[2025-09-20 00:40:05] Public, r: 32, CiteSeer to Photo: Best @ epoch 199: val=0.9294, test=0.9301 ===
[2025-09-20 00:40:06] Public, r: 32, CiteSeer to Photo: Best @ epoch 120: val=0.9392, test=0.9261 ===
[2025-09-20 00:40:09] Public, r: 32, CiteSeer to Photo: Best @ epoch 165: val=0.9353, test=0.9203 ===

================================================================================
[2025-09-20 00:40:09] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 00:40:09] Public, r: 32, CiteSeer to Photo: Best @ epoch 165: val=0.9386, test=0.9281 ===

================================================================================
[2025-09-20 00:40:10] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)

================================================================================
[2025-09-20 00:40:11] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 00:40:11] Public, r: 32, CiteSeer to Photo: Best @ epoch 112: val=0.9340, test=0.9294 ===
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)

================================================================================
[2025-09-20 00:40:14] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 00:40:15] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)

================================================================================
[2025-09-20 00:40:16] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[2025-09-20 00:42:12] Few(5), r: 32, CiteSeer to Photo: Best @ epoch 44: val=0.8975, test=0.8921 ===
[2025-09-20 00:42:15] Few(5), r: 32, CiteSeer to Photo: Best @ epoch 185: val=0.8909, test=0.8826 ===

================================================================================
[2025-09-20 00:42:18] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 00:42:18] Few(5), r: 32, CiteSeer to Photo: Best @ epoch 54: val=0.8830, test=0.8822 ===
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)

================================================================================
[2025-09-20 00:42:20] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 00:42:23] Few(5), r: 32, CiteSeer to Photo: Best @ epoch 176: val=0.8863, test=0.8775 ===

================================================================================
[2025-09-20 00:42:24] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)

================================================================================
[2025-09-20 00:42:27] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 00:42:28] Few(5), r: 32, CiteSeer to Photo: Best @ epoch 46: val=0.8817, test=0.8803 ===
[2025-09-20 00:42:29] Few(5), r: 32, CiteSeer to Photo: Best @ epoch 88: val=0.8863, test=0.8855 ===

================================================================================
[2025-09-20 00:42:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)

================================================================================
[2025-09-20 00:42:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Photo', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 5e-05, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 0.001, 'l1': 1.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.1, 'num_epochs': 200}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[2025-09-20 00:44:17] Few(10), r: 32, CiteSeer to Photo: Best @ epoch 43: val=0.8983, test=0.9009 ===
[2025-09-20 00:44:18] Few(10), r: 32, CiteSeer to Photo: Best @ epoch 126: val=0.8897, test=0.9008 ===
[2025-09-20 00:44:25] Few(10), r: 32, CiteSeer to Photo: Best @ epoch 153: val=0.8890, test=0.8991 ===
[2025-09-20 00:44:29] Few(10), r: 32, CiteSeer to Photo: Best @ epoch 59: val=0.9016, test=0.9107 ===

================================================================================
[2025-09-20 00:44:32] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 00:44:33] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 00:44:34] Few(10), r: 32, CiteSeer to Photo: Best @ epoch 99: val=0.8989, test=0.9090 ===
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)

================================================================================
[2025-09-20 00:44:41] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
[2025-09-20 00:44:41] Few(10), r: 32, CiteSeer to Photo: Best @ epoch 54: val=0.9029, test=0.9108 ===
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)

================================================================================
[2025-09-20 00:44:44] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)

================================================================================
[2025-09-20 00:44:49] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)

================================================================================
[2025-09-20 00:44:56] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': False, 'shot': 10, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 0.0, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.2, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 0.2, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=8251, val=2750, test=2751 (mode=public, shot=N/A)
[2025-09-20 00:54:21] Public, r: 32, CiteSeer to Computers: Best @ epoch 470: val=0.8956, test=0.9022 ===

================================================================================
[2025-09-20 00:54:26] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 00:54:28] Public, r: 32, CiteSeer to Computers: Best @ epoch 408: val=0.9051, test=0.8953 ===

================================================================================
[2025-09-20 00:54:34] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 00:54:46] Public, r: 32, CiteSeer to Computers: Best @ epoch 463: val=0.9015, test=0.9011 ===
[2025-09-20 00:54:49] Public, r: 32, CiteSeer to Computers: Best @ epoch 451: val=0.9018, test=0.8964 ===
[2025-09-20 00:54:50] Public, r: 32, CiteSeer to Computers: Best @ epoch 378: val=0.9022, test=0.8895 ===

================================================================================
[2025-09-20 00:54:51] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)

================================================================================
[2025-09-20 00:54:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 00:54:55] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)
[2025-09-20 00:54:59] Public, r: 32, CiteSeer to Computers: Best @ epoch 275: val=0.9025, test=0.9029 ===

================================================================================
[2025-09-20 00:55:04] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
Split sizes | train=49, val=2740, test=10963 (mode=few, shot=5)

================================================================================
[2025-09-20 01:38:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================

================================================================================
[2025-09-20 01:39:22] New Experiment: c trainable during transfer
Args: {'pretrain_dataset': 'PubMed', 'test_dataset': 'Computers', 'gpu_id': 1, 'pretext': 'GRACE', 'config': './config.yaml', 'para_config': './config2.yaml', 'is_pretrain': False, 'is_transfer': True, 'is_reduction': True, 'few': True, 'shot': 5, 'tau': 0.5, 'sup_weight': 0.2, 'r': 32, 'hyperbolic_lora': True, 'curvature': 1.0, 'lora_alpha': 16.0, 'pretrained_model_name': '/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/CiteSeer.GRACE.GAT.hyp_True.True.20250912-232342.pth', 'wd1': 0.0001, 'wd2': 1e-05, 'wd3': 0.1, 'lr1': 0.01, 'lr2': 0.01, 'lr3': 1e-05, 'l1': 2.0, 'l2': 1.0, 'l3': 1.0, 'l4': 0.2, 'num_epochs': 500}
Config: {'hidden_dim': 64, 'output_dim': 256, 'activation': 'relu', 'gnn_type': 'GAT', 'num_layers': 2, 'learning_rate': 0.001, 'weight_decay': 0, 'epoch': 0, 'epoch1': 100, 'epoch2': 10000, 'decay_epoch': 1000, 'b1': 0.5, 'b2': 0.999, 'batch_size': 128, 'lambda_cyc': 15, 'lambda_anc': 5, 'lambda_cos': 0, 'lambda_dis': 5, 'lambda_str': 0, 'lambda_map': 5, 'lambda_id': 5, 'checkpoint_interval': 10, 'lr2': 0.01, 'wd2': 1e-06, 'curvature': 1.0, 'learnable_curvature': True, 'min_curvature': 0.0001, 'max_curvature': 10.0}
================================================================================
