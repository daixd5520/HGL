Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-5 - 2025-09-21 03:27:29:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-5...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.8939 cls=1.1109 smmd=5.6121 ct=7.2552 rec=1.4137 | train/val/test=0.462/0.468/0.464 | c=0.998437
[Epoch 0001] loss=52.4636 cls=1.0684 smmd=3.6810 ct=7.2060 rec=1.4150 | train/val/test=0.398/0.409/0.394 | c=0.998437
[Epoch 0002] loss=37.5045 cls=1.0766 smmd=2.2038 ct=7.1107 rec=1.4140 | train/val/test=0.398/0.409/0.394 | c=0.998437
[Epoch 0003] loss=40.7403 cls=1.0724 smmd=2.5272 ct=7.1124 rec=1.4137 | train/val/test=0.507/0.513/0.508 | c=0.998437
[Epoch 0004] loss=40.2874 cls=1.0418 smmd=2.4919 ct=7.0699 rec=1.4149 | train/val/test=0.516/0.511/0.520 | c=0.998437
[Epoch 0005] loss=35.3260 cls=1.0193 smmd=2.0089 ct=7.0094 rec=1.4169 | train/val/test=0.510/0.506/0.515 | c=0.998437
[Epoch 0006] loss=30.1061 cls=0.9960 smmd=1.5013 ct=6.9439 rec=1.4153 | train/val/test=0.506/0.501/0.508 | c=0.998437
[Epoch 0007] loss=33.7032 cls=0.9615 smmd=1.8649 ct=6.9346 rec=1.4093 | train/val/test=0.517/0.511/0.520 | c=0.998437
[Epoch 0008] loss=36.0458 cls=0.9222 smmd=1.9657 ct=7.6134 rec=1.4021 | train/val/test=0.527/0.522/0.532 | c=0.998437
[Epoch 0009] loss=29.1993 cls=0.8918 smmd=1.3111 ct=7.4722 rec=1.3957 | train/val/test=0.522/0.517/0.527 | c=0.998437
[Epoch 0010] loss=27.9268 cls=0.8588 smmd=1.1810 ct=7.4963 rec=1.3894 | train/val/test=0.570/0.559/0.572 | c=0.998437
[Epoch 0011] loss=30.7500 cls=0.8302 smmd=1.4635 ct=7.5035 rec=1.3859 | train/val/test=0.649/0.637/0.648 | c=0.998437
[Epoch 0012] loss=27.5698 cls=0.8031 smmd=1.1490 ct=7.4933 rec=1.3829 | train/val/test=0.692/0.682/0.691 | c=0.998437
[Epoch 0013] loss=26.1548 cls=0.7782 smmd=1.0019 ct=7.5285 rec=1.3791 | train/val/test=0.707/0.700/0.709 | c=0.998437
[Epoch 0014] loss=25.9780 cls=0.7521 smmd=0.9743 ct=7.5858 rec=1.3750 | train/val/test=0.714/0.712/0.712 | c=0.998437
[Epoch 0015] loss=25.6648 cls=0.7236 smmd=0.9522 ct=7.5472 rec=1.3725 | train/val/test=0.728/0.730/0.725 | c=0.998437
[Epoch 0016] loss=24.9526 cls=0.7003 smmd=0.8894 ct=7.5124 rec=1.3678 | train/val/test=0.743/0.743/0.742 | c=0.998437
[Epoch 0017] loss=23.3529 cls=0.6783 smmd=0.7385 ct=7.4745 rec=1.3599 | train/val/test=0.739/0.739/0.741 | c=0.998437
[Epoch 0018] loss=23.4324 cls=0.6580 smmd=0.7436 ct=7.4953 rec=1.3528 | train/val/test=0.747/0.744/0.746 | c=0.998437
[Epoch 0019] loss=22.9161 cls=0.6444 smmd=0.6794 ct=7.5633 rec=1.3458 | train/val/test=0.773/0.775/0.774 | c=0.998437
[Epoch 0020] loss=22.1319 cls=0.6168 smmd=0.6066 ct=7.5436 rec=1.3410 | train/val/test=0.790/0.797/0.787 | c=0.998437
[Epoch 0021] loss=21.6616 cls=0.5956 smmd=0.5692 ct=7.5012 rec=1.3389 | train/val/test=0.789/0.790/0.785 | c=0.998437
[Epoch 0022] loss=21.6637 cls=0.5842 smmd=0.5726 ct=7.4900 rec=1.3315 | train/val/test=0.782/0.779/0.783 | c=0.998437
[Epoch 0023] loss=20.9582 cls=0.5770 smmd=0.4995 ct=7.5061 rec=1.3253 | train/val/test=0.792/0.795/0.790 | c=0.998437
[Epoch 0024] loss=20.6045 cls=0.5588 smmd=0.4654 ct=7.5046 rec=1.3231 | train/val/test=0.801/0.805/0.800 | c=0.998437
[Epoch 0025] loss=20.4257 cls=0.5443 smmd=0.4465 ct=7.5136 rec=1.3236 | train/val/test=0.803/0.810/0.806 | c=0.998437
[Epoch 0026] loss=20.0922 cls=0.5352 smmd=0.4147 ct=7.5079 rec=1.3229 | train/val/test=0.803/0.806/0.803 | c=0.998437
[Epoch 0027] loss=19.8933 cls=0.5297 smmd=0.3949 ct=7.5099 rec=1.3183 | train/val/test=0.804/0.806/0.805 | c=0.998437
[Epoch 0028] loss=19.6422 cls=0.5232 smmd=0.3677 ct=7.5224 rec=1.3170 | train/val/test=0.810/0.816/0.813 | c=0.998437
[Epoch 0029] loss=19.4434 cls=0.5133 smmd=0.3538 ct=7.4949 rec=1.3188 | train/val/test=0.815/0.826/0.819 | c=0.998437
[Epoch 0030] loss=19.2064 cls=0.5071 smmd=0.3317 ct=7.4880 rec=1.3192 | train/val/test=0.814/0.818/0.816 | c=0.998437
[Epoch 0031] loss=18.9909 cls=0.5006 smmd=0.3072 ct=7.5056 rec=1.3154 | train/val/test=0.812/0.812/0.813 | c=0.998437
[Epoch 0032] loss=18.8719 cls=0.4986 smmd=0.2948 ct=7.5085 rec=1.3144 | train/val/test=0.820/0.832/0.822 | c=0.998437
[Epoch 0033] loss=18.5258 cls=0.4890 smmd=0.2621 ct=7.5014 rec=1.3148 | train/val/test=0.822/0.834/0.825 | c=0.998437
[Epoch 0034] loss=18.5110 cls=0.4856 smmd=0.2658 ct=7.4762 rec=1.3153 | train/val/test=0.821/0.829/0.824 | c=0.998437
[Epoch 0035] loss=18.3095 cls=0.4829 smmd=0.2470 ct=7.4708 rec=1.3137 | train/val/test=0.825/0.835/0.825 | c=0.998437
[Epoch 0036] loss=18.1714 cls=0.4830 smmd=0.2290 ct=7.4917 rec=1.3135 | train/val/test=0.825/0.835/0.825 | c=0.998437
[Epoch 0037] loss=18.0238 cls=0.4805 smmd=0.2155 ct=7.4853 rec=1.3155 | train/val/test=0.828/0.838/0.828 | c=0.998437
[Epoch 0038] loss=17.9184 cls=0.4811 smmd=0.2067 ct=7.4764 rec=1.3170 | train/val/test=0.830/0.840/0.830 | c=0.998437
[Epoch 0039] loss=17.8328 cls=0.4829 smmd=0.1997 ct=7.4680 rec=1.3175 | train/val/test=0.829/0.839/0.827 | c=0.998437
[Epoch 0040] loss=17.7460 cls=0.4843 smmd=0.1892 ct=7.4762 rec=1.3184 | train/val/test=0.832/0.843/0.831 | c=0.998437
[Epoch 0041] loss=17.6778 cls=0.4861 smmd=0.1807 ct=7.4838 rec=1.3196 | train/val/test=0.829/0.840/0.829 | c=0.998437
[Epoch 0042] loss=17.5819 cls=0.4856 smmd=0.1763 ct=7.4579 rec=1.3210 | train/val/test=0.834/0.844/0.830 | c=0.998437
[Epoch 0043] loss=17.5417 cls=0.4866 smmd=0.1706 ct=7.4659 rec=1.3208 | train/val/test=0.827/0.834/0.828 | c=0.998437
[Epoch 0044] loss=17.4447 cls=0.4872 smmd=0.1587 ct=7.4767 rec=1.3208 | train/val/test=0.834/0.844/0.830 | c=0.998437
[Epoch 0045] loss=17.3722 cls=0.4853 smmd=0.1548 ct=7.4608 rec=1.3202 | train/val/test=0.829/0.837/0.829 | c=0.998437
[Epoch 0046] loss=17.3382 cls=0.4836 smmd=0.1530 ct=7.4534 rec=1.3202 | train/val/test=0.832/0.843/0.830 | c=0.998437
[Epoch 0047] loss=17.2326 cls=0.4828 smmd=0.1423 ct=7.4541 rec=1.3203 | train/val/test=0.829/0.836/0.829 | c=0.998437
[Epoch 0048] loss=17.1885 cls=0.4833 smmd=0.1384 ct=7.4514 rec=1.3202 | train/val/test=0.831/0.838/0.829 | c=0.998437
[Epoch 0049] loss=17.1686 cls=0.4836 smmd=0.1359 ct=7.4538 rec=1.3205 | train/val/test=0.831/0.839/0.829 | c=0.998437
[Epoch 0050] loss=17.0902 cls=0.4829 smmd=0.1290 ct=7.4488 rec=1.3219 | train/val/test=0.834/0.844/0.829 | c=0.998437
[Epoch 0051] loss=17.0805 cls=0.4845 smmd=0.1307 ct=7.4350 rec=1.3226 | train/val/test=0.831/0.837/0.829 | c=0.998437
[Epoch 0052] loss=17.0016 cls=0.4866 smmd=0.1207 ct=7.4449 rec=1.3232 | train/val/test=0.836/0.843/0.829 | c=0.998437
[Epoch 0053] loss=17.0024 cls=0.4866 smmd=0.1217 ct=7.4396 rec=1.3251 | train/val/test=0.832/0.840/0.829 | c=0.998437
[Epoch 0054] loss=17.0152 cls=0.4887 smmd=0.1235 ct=7.4363 rec=1.3260 | train/val/test=0.837/0.842/0.830 | c=0.998437
[Epoch 0055] loss=17.0115 cls=0.4900 smmd=0.1229 ct=7.4369 rec=1.3271 | train/val/test=0.832/0.839/0.831 | c=0.998437
[Epoch 0056] loss=17.0028 cls=0.4912 smmd=0.1233 ct=7.4299 rec=1.3280 | train/val/test=0.837/0.843/0.831 | c=0.998437
[Epoch 0057] loss=16.9404 cls=0.4914 smmd=0.1173 ct=7.4288 rec=1.3280 | train/val/test=0.833/0.838/0.830 | c=0.998437
[Epoch 0058] loss=16.9111 cls=0.4899 smmd=0.1141 ct=7.4308 rec=1.3276 | train/val/test=0.836/0.843/0.831 | c=0.998437
[Epoch 0059] loss=16.9121 cls=0.4881 smmd=0.1156 ct=7.4243 rec=1.3272 | train/val/test=0.834/0.838/0.831 | c=0.998437
[Epoch 0060] loss=16.8636 cls=0.4871 smmd=0.1112 ct=7.4225 rec=1.3262 | train/val/test=0.837/0.844/0.831 | c=0.998437
[Epoch 0061] loss=16.8905 cls=0.4870 smmd=0.1142 ct=7.4211 rec=1.3259 | train/val/test=0.831/0.832/0.831 | c=0.998437
[Epoch 0062] loss=16.8485 cls=0.4868 smmd=0.1103 ct=7.4195 rec=1.3266 | train/val/test=0.835/0.845/0.829 | c=0.998437
[Epoch 0063] loss=16.8825 cls=0.4909 smmd=0.1134 ct=7.4201 rec=1.3264 | train/val/test=0.822/0.825/0.826 | c=0.998437
[Epoch 0064] loss=16.9321 cls=0.4949 smmd=0.1171 ct=7.4245 rec=1.3293 | train/val/test=0.832/0.845/0.830 | c=0.998437
[Epoch 0065] loss=16.9742 cls=0.5005 smmd=0.1222 ct=7.4190 rec=1.3286 | train/val/test=0.809/0.808/0.817 | c=0.998437
[Epoch 0066] loss=17.0674 cls=0.5093 smmd=0.1299 ct=7.4236 rec=1.3337 | train/val/test=0.823/0.837/0.824 | c=0.998437
[Epoch 0067] loss=17.1269 cls=0.5207 smmd=0.1351 ct=7.4242 rec=1.3336 | train/val/test=0.797/0.797/0.803 | c=0.998437
[Epoch 0068] loss=17.2168 cls=0.5292 smmd=0.1421 ct=7.4310 rec=1.3386 | train/val/test=0.820/0.832/0.822 | c=0.998437
[Epoch 0069] loss=17.2317 cls=0.5243 smmd=0.1466 ct=7.4183 rec=1.3335 | train/val/test=0.809/0.808/0.815 | c=0.998437
[Epoch 0070] loss=17.1741 cls=0.5068 smmd=0.1413 ct=7.4212 rec=1.3303 | train/val/test=0.830/0.845/0.826 | c=0.998437
[Epoch 0071] loss=16.9538 cls=0.4923 smmd=0.1230 ct=7.4081 rec=1.3224 | train/val/test=0.830/0.836/0.830 | c=0.998437
[Epoch 0072] loss=16.7844 cls=0.4775 smmd=0.1078 ct=7.4037 rec=1.3204 | train/val/test=0.830/0.838/0.831 | c=0.998437
[Epoch 0073] loss=16.8121 cls=0.4816 smmd=0.1101 ct=7.4050 rec=1.3216 | train/val/test=0.833/0.845/0.829 | c=0.998437
[Epoch 0074] loss=16.8297 cls=0.4910 smmd=0.1118 ct=7.4015 rec=1.3258 | train/val/test=0.823/0.826/0.830 | c=0.998437
[Epoch 0075] loss=16.8528 cls=0.4989 smmd=0.1107 ct=7.4155 rec=1.3306 | train/val/test=0.834/0.847/0.831 | c=0.998437
[Epoch 0076] loss=16.8599 cls=0.5038 smmd=0.1127 ct=7.4077 rec=1.3316 | train/val/test=0.824/0.827/0.830 | c=0.998437
[Epoch 0077] loss=16.9086 cls=0.5067 smmd=0.1157 ct=7.4151 rec=1.3354 | train/val/test=0.835/0.846/0.832 | c=0.998437
[Epoch 0078] loss=17.0139 cls=0.5086 smmd=0.1279 ct=7.4068 rec=1.3342 | train/val/test=0.821/0.824/0.828 | c=0.998437
[Epoch 0079] loss=17.0493 cls=0.5090 smmd=0.1282 ct=7.4221 rec=1.3368 | train/val/test=0.833/0.847/0.832 | c=0.998437
[Epoch 0080] loss=17.0344 cls=0.5061 smmd=0.1318 ct=7.3983 rec=1.3329 | train/val/test=0.822/0.827/0.830 | c=0.998437
[Epoch 0081] loss=16.9744 cls=0.4994 smmd=0.1230 ct=7.4146 rec=1.3318 | train/val/test=0.834/0.844/0.830 | c=0.998437
[Epoch 0082] loss=16.8834 cls=0.4968 smmd=0.1176 ct=7.3974 rec=1.3283 | train/val/test=0.827/0.828/0.831 | c=0.998437
[Epoch 0083] loss=16.8561 cls=0.4896 smmd=0.1149 ct=7.3992 rec=1.3273 | train/val/test=0.835/0.842/0.830 | c=0.998437
[Epoch 0084] loss=16.8144 cls=0.4915 smmd=0.1106 ct=7.4000 rec=1.3251 | train/val/test=0.830/0.836/0.830 | c=0.998437
[Epoch 0085] loss=16.7476 cls=0.4888 smmd=0.1050 ct=7.3946 rec=1.3274 | train/val/test=0.834/0.842/0.831 | c=0.998437
[Epoch 0086] loss=16.7493 cls=0.4945 smmd=0.1044 ct=7.3976 rec=1.3267 | train/val/test=0.833/0.838/0.832 | c=0.998437
[Epoch 0087] loss=16.8035 cls=0.4960 smmd=0.1094 ct=7.3980 rec=1.3310 | train/val/test=0.833/0.840/0.831 | c=0.998437
[Epoch 0088] loss=16.7826 cls=0.4998 smmd=0.1064 ct=7.4015 rec=1.3310 | train/val/test=0.834/0.841/0.829 | c=0.998437
[Epoch 0089] loss=16.8382 cls=0.5003 smmd=0.1123 ct=7.3990 rec=1.3331 | train/val/test=0.832/0.838/0.831 | c=0.998437
[Epoch 0090] loss=16.8768 cls=0.4998 smmd=0.1161 ct=7.3998 rec=1.3328 | train/val/test=0.835/0.843/0.830 | c=0.998437
[Epoch 0091] loss=16.8725 cls=0.4961 smmd=0.1166 ct=7.3964 rec=1.3320 | train/val/test=0.831/0.836/0.831 | c=0.998437
[Epoch 0092] loss=16.8324 cls=0.4935 smmd=0.1123 ct=7.3988 rec=1.3309 | train/val/test=0.835/0.843/0.830 | c=0.998437
[Epoch 0093] loss=16.8048 cls=0.4904 smmd=0.1114 ct=7.3905 rec=1.3289 | train/val/test=0.829/0.830/0.831 | c=0.998437
[Epoch 0094] loss=16.7814 cls=0.4890 smmd=0.1079 ct=7.3966 rec=1.3287 | train/val/test=0.833/0.842/0.828 | c=0.998437
[Epoch 0095] loss=16.7937 cls=0.4911 smmd=0.1106 ct=7.3892 rec=1.3274 | train/val/test=0.822/0.824/0.827 | c=0.998437
[Epoch 0096] loss=16.7806 cls=0.4937 smmd=0.1068 ct=7.4003 rec=1.3296 | train/val/test=0.829/0.844/0.828 | c=0.998437
[Epoch 0097] loss=16.8362 cls=0.5053 smmd=0.1133 ct=7.3925 rec=1.3304 | train/val/test=0.804/0.804/0.808 | c=0.998437
[Epoch 0098] loss=17.0180 cls=0.5212 smmd=0.1260 ct=7.4143 rec=1.3379 | train/val/test=0.795/0.804/0.797 | c=0.998437
[Epoch 0099] loss=17.3171 cls=0.5619 smmd=0.1544 ct=7.4103 rec=1.3429 | train/val/test=0.753/0.754/0.753 | c=0.998437
=== Best @ epoch 79: val=0.8468, test=0.8319 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-5 - 2025-09-21 03:27:29:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-5...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.8939 cls=1.1109 smmd=5.6121 ct=7.2552 rec=1.4137 | train/val/test=0.462/0.468/0.464 | c=0.998437
[Epoch 0001] loss=52.4636 cls=1.0684 smmd=3.6810 ct=7.2060 rec=1.4150 | train/val/test=0.398/0.409/0.394 | c=0.998437
[Epoch 0002] loss=37.5045 cls=1.0766 smmd=2.2038 ct=7.1107 rec=1.4140 | train/val/test=0.398/0.409/0.394 | c=0.998437
[Epoch 0003] loss=40.7403 cls=1.0724 smmd=2.5272 ct=7.1124 rec=1.4137 | train/val/test=0.507/0.513/0.508 | c=0.998437
[Epoch 0004] loss=40.2874 cls=1.0418 smmd=2.4919 ct=7.0699 rec=1.4149 | train/val/test=0.516/0.511/0.520 | c=0.998437
[Epoch 0005] loss=35.3260 cls=1.0193 smmd=2.0089 ct=7.0094 rec=1.4169 | train/val/test=0.510/0.506/0.515 | c=0.998437
[Epoch 0006] loss=30.1061 cls=0.9960 smmd=1.5013 ct=6.9439 rec=1.4153 | train/val/test=0.506/0.501/0.508 | c=0.998437
[Epoch 0007] loss=33.7032 cls=0.9615 smmd=1.8649 ct=6.9346 rec=1.4093 | train/val/test=0.517/0.511/0.520 | c=0.998437
[Epoch 0008] loss=36.0458 cls=0.9222 smmd=1.9657 ct=7.6134 rec=1.4021 | train/val/test=0.527/0.522/0.532 | c=0.998437
[Epoch 0009] loss=29.1993 cls=0.8918 smmd=1.3111 ct=7.4722 rec=1.3957 | train/val/test=0.522/0.517/0.527 | c=0.998437
[Epoch 0010] loss=27.9268 cls=0.8588 smmd=1.1810 ct=7.4963 rec=1.3894 | train/val/test=0.570/0.559/0.572 | c=0.998437
[Epoch 0011] loss=30.7500 cls=0.8302 smmd=1.4635 ct=7.5035 rec=1.3859 | train/val/test=0.649/0.637/0.648 | c=0.998437
[Epoch 0012] loss=27.5698 cls=0.8031 smmd=1.1490 ct=7.4933 rec=1.3829 | train/val/test=0.692/0.682/0.691 | c=0.998437
[Epoch 0013] loss=26.1548 cls=0.7782 smmd=1.0019 ct=7.5285 rec=1.3791 | train/val/test=0.707/0.700/0.709 | c=0.998437
[Epoch 0014] loss=25.9780 cls=0.7521 smmd=0.9743 ct=7.5858 rec=1.3750 | train/val/test=0.714/0.712/0.712 | c=0.998437
[Epoch 0015] loss=25.6648 cls=0.7236 smmd=0.9522 ct=7.5472 rec=1.3725 | train/val/test=0.728/0.730/0.725 | c=0.998437
[Epoch 0016] loss=24.9526 cls=0.7003 smmd=0.8894 ct=7.5124 rec=1.3678 | train/val/test=0.743/0.743/0.742 | c=0.998437
[Epoch 0017] loss=23.3529 cls=0.6783 smmd=0.7385 ct=7.4745 rec=1.3599 | train/val/test=0.739/0.739/0.741 | c=0.998437
[Epoch 0018] loss=23.4324 cls=0.6580 smmd=0.7436 ct=7.4953 rec=1.3528 | train/val/test=0.747/0.744/0.746 | c=0.998437
[Epoch 0019] loss=22.9161 cls=0.6444 smmd=0.6794 ct=7.5633 rec=1.3458 | train/val/test=0.773/0.775/0.774 | c=0.998437
[Epoch 0020] loss=22.1319 cls=0.6168 smmd=0.6066 ct=7.5436 rec=1.3410 | train/val/test=0.790/0.797/0.787 | c=0.998437
[Epoch 0021] loss=21.6616 cls=0.5956 smmd=0.5692 ct=7.5012 rec=1.3389 | train/val/test=0.789/0.790/0.785 | c=0.998437
[Epoch 0022] loss=21.6637 cls=0.5842 smmd=0.5726 ct=7.4900 rec=1.3315 | train/val/test=0.782/0.779/0.783 | c=0.998437
[Epoch 0023] loss=20.9582 cls=0.5770 smmd=0.4995 ct=7.5061 rec=1.3253 | train/val/test=0.792/0.795/0.790 | c=0.998437
[Epoch 0024] loss=20.6045 cls=0.5588 smmd=0.4654 ct=7.5046 rec=1.3231 | train/val/test=0.801/0.805/0.800 | c=0.998437
[Epoch 0025] loss=20.4257 cls=0.5443 smmd=0.4465 ct=7.5136 rec=1.3236 | train/val/test=0.803/0.810/0.806 | c=0.998437
[Epoch 0026] loss=20.0922 cls=0.5352 smmd=0.4147 ct=7.5079 rec=1.3229 | train/val/test=0.803/0.806/0.803 | c=0.998437
[Epoch 0027] loss=19.8933 cls=0.5297 smmd=0.3949 ct=7.5099 rec=1.3183 | train/val/test=0.804/0.806/0.805 | c=0.998437
[Epoch 0028] loss=19.6422 cls=0.5232 smmd=0.3677 ct=7.5224 rec=1.3170 | train/val/test=0.810/0.816/0.813 | c=0.998437
[Epoch 0029] loss=19.4434 cls=0.5133 smmd=0.3538 ct=7.4949 rec=1.3188 | train/val/test=0.815/0.826/0.819 | c=0.998437
[Epoch 0030] loss=19.2064 cls=0.5071 smmd=0.3317 ct=7.4880 rec=1.3192 | train/val/test=0.814/0.818/0.816 | c=0.998437
[Epoch 0031] loss=18.9909 cls=0.5006 smmd=0.3072 ct=7.5056 rec=1.3154 | train/val/test=0.812/0.812/0.813 | c=0.998437
[Epoch 0032] loss=18.8719 cls=0.4986 smmd=0.2948 ct=7.5085 rec=1.3144 | train/val/test=0.820/0.832/0.822 | c=0.998437
[Epoch 0033] loss=18.5258 cls=0.4890 smmd=0.2621 ct=7.5014 rec=1.3148 | train/val/test=0.822/0.834/0.825 | c=0.998437
[Epoch 0034] loss=18.5110 cls=0.4856 smmd=0.2658 ct=7.4762 rec=1.3153 | train/val/test=0.821/0.829/0.824 | c=0.998437
[Epoch 0035] loss=18.3095 cls=0.4829 smmd=0.2470 ct=7.4708 rec=1.3137 | train/val/test=0.825/0.835/0.825 | c=0.998437
[Epoch 0036] loss=18.1714 cls=0.4830 smmd=0.2290 ct=7.4917 rec=1.3135 | train/val/test=0.825/0.835/0.825 | c=0.998437
[Epoch 0037] loss=18.0238 cls=0.4805 smmd=0.2155 ct=7.4853 rec=1.3155 | train/val/test=0.828/0.838/0.828 | c=0.998437
[Epoch 0038] loss=17.9184 cls=0.4811 smmd=0.2067 ct=7.4764 rec=1.3170 | train/val/test=0.830/0.840/0.830 | c=0.998437
[Epoch 0039] loss=17.8328 cls=0.4829 smmd=0.1997 ct=7.4680 rec=1.3175 | train/val/test=0.829/0.839/0.827 | c=0.998437
[Epoch 0040] loss=17.7460 cls=0.4843 smmd=0.1892 ct=7.4762 rec=1.3184 | train/val/test=0.832/0.843/0.831 | c=0.998437
[Epoch 0041] loss=17.6778 cls=0.4861 smmd=0.1807 ct=7.4838 rec=1.3196 | train/val/test=0.829/0.840/0.829 | c=0.998437
[Epoch 0042] loss=17.5819 cls=0.4856 smmd=0.1763 ct=7.4579 rec=1.3210 | train/val/test=0.834/0.844/0.830 | c=0.998437
[Epoch 0043] loss=17.5417 cls=0.4866 smmd=0.1706 ct=7.4659 rec=1.3208 | train/val/test=0.827/0.834/0.828 | c=0.998437
[Epoch 0044] loss=17.4447 cls=0.4872 smmd=0.1587 ct=7.4767 rec=1.3208 | train/val/test=0.834/0.844/0.830 | c=0.998437
[Epoch 0045] loss=17.3722 cls=0.4853 smmd=0.1548 ct=7.4608 rec=1.3202 | train/val/test=0.829/0.837/0.829 | c=0.998437
[Epoch 0046] loss=17.3382 cls=0.4836 smmd=0.1530 ct=7.4534 rec=1.3202 | train/val/test=0.832/0.843/0.830 | c=0.998437
[Epoch 0047] loss=17.2326 cls=0.4828 smmd=0.1423 ct=7.4541 rec=1.3203 | train/val/test=0.829/0.836/0.829 | c=0.998437
[Epoch 0048] loss=17.1885 cls=0.4833 smmd=0.1384 ct=7.4514 rec=1.3202 | train/val/test=0.831/0.838/0.829 | c=0.998437
[Epoch 0049] loss=17.1686 cls=0.4836 smmd=0.1359 ct=7.4538 rec=1.3205 | train/val/test=0.831/0.839/0.829 | c=0.998437
[Epoch 0050] loss=17.0902 cls=0.4829 smmd=0.1290 ct=7.4488 rec=1.3219 | train/val/test=0.834/0.844/0.829 | c=0.998437
[Epoch 0051] loss=17.0805 cls=0.4845 smmd=0.1307 ct=7.4350 rec=1.3226 | train/val/test=0.831/0.837/0.829 | c=0.998437
[Epoch 0052] loss=17.0016 cls=0.4866 smmd=0.1207 ct=7.4449 rec=1.3232 | train/val/test=0.836/0.843/0.829 | c=0.998437
[Epoch 0053] loss=17.0024 cls=0.4866 smmd=0.1217 ct=7.4396 rec=1.3251 | train/val/test=0.832/0.840/0.829 | c=0.998437
[Epoch 0054] loss=17.0152 cls=0.4887 smmd=0.1235 ct=7.4363 rec=1.3260 | train/val/test=0.837/0.842/0.830 | c=0.998437
[Epoch 0055] loss=17.0115 cls=0.4900 smmd=0.1229 ct=7.4369 rec=1.3271 | train/val/test=0.832/0.839/0.831 | c=0.998437
[Epoch 0056] loss=17.0028 cls=0.4912 smmd=0.1233 ct=7.4299 rec=1.3280 | train/val/test=0.837/0.843/0.831 | c=0.998437
[Epoch 0057] loss=16.9404 cls=0.4914 smmd=0.1173 ct=7.4288 rec=1.3280 | train/val/test=0.833/0.838/0.830 | c=0.998437
[Epoch 0058] loss=16.9111 cls=0.4899 smmd=0.1141 ct=7.4308 rec=1.3276 | train/val/test=0.836/0.843/0.831 | c=0.998437
[Epoch 0059] loss=16.9121 cls=0.4881 smmd=0.1156 ct=7.4243 rec=1.3272 | train/val/test=0.834/0.838/0.831 | c=0.998437
[Epoch 0060] loss=16.8636 cls=0.4871 smmd=0.1112 ct=7.4225 rec=1.3262 | train/val/test=0.837/0.844/0.831 | c=0.998437
[Epoch 0061] loss=16.8905 cls=0.4870 smmd=0.1142 ct=7.4211 rec=1.3259 | train/val/test=0.831/0.832/0.831 | c=0.998437
[Epoch 0062] loss=16.8485 cls=0.4868 smmd=0.1103 ct=7.4195 rec=1.3266 | train/val/test=0.835/0.845/0.829 | c=0.998437
[Epoch 0063] loss=16.8825 cls=0.4909 smmd=0.1134 ct=7.4201 rec=1.3264 | train/val/test=0.822/0.825/0.826 | c=0.998437
[Epoch 0064] loss=16.9321 cls=0.4949 smmd=0.1171 ct=7.4245 rec=1.3293 | train/val/test=0.832/0.845/0.830 | c=0.998437
[Epoch 0065] loss=16.9742 cls=0.5005 smmd=0.1222 ct=7.4190 rec=1.3286 | train/val/test=0.809/0.808/0.817 | c=0.998437
[Epoch 0066] loss=17.0674 cls=0.5093 smmd=0.1299 ct=7.4236 rec=1.3337 | train/val/test=0.823/0.837/0.824 | c=0.998437
[Epoch 0067] loss=17.1269 cls=0.5207 smmd=0.1351 ct=7.4242 rec=1.3336 | train/val/test=0.797/0.797/0.803 | c=0.998437
[Epoch 0068] loss=17.2168 cls=0.5292 smmd=0.1421 ct=7.4310 rec=1.3386 | train/val/test=0.820/0.832/0.822 | c=0.998437
[Epoch 0069] loss=17.2317 cls=0.5243 smmd=0.1466 ct=7.4183 rec=1.3335 | train/val/test=0.809/0.808/0.815 | c=0.998437
[Epoch 0070] loss=17.1741 cls=0.5068 smmd=0.1413 ct=7.4212 rec=1.3303 | train/val/test=0.830/0.845/0.826 | c=0.998437
[Epoch 0071] loss=16.9538 cls=0.4923 smmd=0.1230 ct=7.4081 rec=1.3224 | train/val/test=0.830/0.836/0.830 | c=0.998437
[Epoch 0072] loss=16.7844 cls=0.4775 smmd=0.1078 ct=7.4037 rec=1.3204 | train/val/test=0.830/0.838/0.831 | c=0.998437
[Epoch 0073] loss=16.8121 cls=0.4816 smmd=0.1101 ct=7.4050 rec=1.3216 | train/val/test=0.833/0.845/0.829 | c=0.998437
[Epoch 0074] loss=16.8297 cls=0.4910 smmd=0.1118 ct=7.4015 rec=1.3258 | train/val/test=0.823/0.826/0.830 | c=0.998437
[Epoch 0075] loss=16.8528 cls=0.4989 smmd=0.1107 ct=7.4155 rec=1.3306 | train/val/test=0.834/0.847/0.831 | c=0.998437
[Epoch 0076] loss=16.8599 cls=0.5038 smmd=0.1127 ct=7.4077 rec=1.3316 | train/val/test=0.824/0.827/0.830 | c=0.998437
[Epoch 0077] loss=16.9086 cls=0.5067 smmd=0.1157 ct=7.4151 rec=1.3354 | train/val/test=0.835/0.846/0.832 | c=0.998437
[Epoch 0078] loss=17.0139 cls=0.5086 smmd=0.1279 ct=7.4068 rec=1.3342 | train/val/test=0.821/0.824/0.828 | c=0.998437
[Epoch 0079] loss=17.0493 cls=0.5090 smmd=0.1282 ct=7.4221 rec=1.3368 | train/val/test=0.833/0.847/0.832 | c=0.998437
[Epoch 0080] loss=17.0344 cls=0.5061 smmd=0.1318 ct=7.3983 rec=1.3329 | train/val/test=0.822/0.827/0.830 | c=0.998437
[Epoch 0081] loss=16.9744 cls=0.4994 smmd=0.1230 ct=7.4146 rec=1.3318 | train/val/test=0.834/0.844/0.830 | c=0.998437
[Epoch 0082] loss=16.8834 cls=0.4968 smmd=0.1176 ct=7.3974 rec=1.3283 | train/val/test=0.827/0.828/0.831 | c=0.998437
[Epoch 0083] loss=16.8561 cls=0.4896 smmd=0.1149 ct=7.3992 rec=1.3273 | train/val/test=0.835/0.842/0.830 | c=0.998437
[Epoch 0084] loss=16.8144 cls=0.4915 smmd=0.1106 ct=7.4000 rec=1.3251 | train/val/test=0.830/0.836/0.830 | c=0.998437
[Epoch 0085] loss=16.7476 cls=0.4888 smmd=0.1050 ct=7.3946 rec=1.3274 | train/val/test=0.834/0.842/0.831 | c=0.998437
[Epoch 0086] loss=16.7493 cls=0.4945 smmd=0.1044 ct=7.3976 rec=1.3267 | train/val/test=0.833/0.838/0.832 | c=0.998437
[Epoch 0087] loss=16.8035 cls=0.4960 smmd=0.1094 ct=7.3980 rec=1.3310 | train/val/test=0.833/0.840/0.831 | c=0.998437
[Epoch 0088] loss=16.7826 cls=0.4998 smmd=0.1064 ct=7.4015 rec=1.3310 | train/val/test=0.834/0.841/0.829 | c=0.998437
[Epoch 0089] loss=16.8382 cls=0.5003 smmd=0.1123 ct=7.3990 rec=1.3331 | train/val/test=0.832/0.838/0.831 | c=0.998437
[Epoch 0090] loss=16.8768 cls=0.4998 smmd=0.1161 ct=7.3998 rec=1.3328 | train/val/test=0.835/0.843/0.830 | c=0.998437
[Epoch 0091] loss=16.8725 cls=0.4961 smmd=0.1166 ct=7.3964 rec=1.3320 | train/val/test=0.831/0.836/0.831 | c=0.998437
[Epoch 0092] loss=16.8324 cls=0.4935 smmd=0.1123 ct=7.3988 rec=1.3309 | train/val/test=0.835/0.843/0.830 | c=0.998437
[Epoch 0093] loss=16.8048 cls=0.4904 smmd=0.1114 ct=7.3905 rec=1.3289 | train/val/test=0.829/0.830/0.831 | c=0.998437
[Epoch 0094] loss=16.7814 cls=0.4890 smmd=0.1079 ct=7.3966 rec=1.3287 | train/val/test=0.833/0.842/0.828 | c=0.998437
[Epoch 0095] loss=16.7937 cls=0.4911 smmd=0.1106 ct=7.3892 rec=1.3274 | train/val/test=0.822/0.824/0.827 | c=0.998437
[Epoch 0096] loss=16.7806 cls=0.4937 smmd=0.1068 ct=7.4003 rec=1.3296 | train/val/test=0.829/0.844/0.828 | c=0.998437
[Epoch 0097] loss=16.8362 cls=0.5053 smmd=0.1133 ct=7.3925 rec=1.3304 | train/val/test=0.804/0.804/0.808 | c=0.998437
[Epoch 0098] loss=17.0180 cls=0.5212 smmd=0.1260 ct=7.4143 rec=1.3379 | train/val/test=0.795/0.804/0.797 | c=0.998437
[Epoch 0099] loss=17.3171 cls=0.5619 smmd=0.1544 ct=7.4103 rec=1.3429 | train/val/test=0.753/0.754/0.753 | c=0.998437
=== Best @ epoch 79: val=0.8468, test=0.8319 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-5 completed in 184.13 seconds.
==================================================
