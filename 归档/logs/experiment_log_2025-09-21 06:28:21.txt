Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3 - 2025-09-21 06:28:21:
Running experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3...
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[Epoch 0000] loss=20.7701 cls=1.9531 smmd=4.2131 ct=6.8926 rec=1.3889 | train/val/test=0.306/0.315/0.299 | c=0.998347
[Epoch 0001] loss=20.0957 cls=1.8518 smmd=3.9232 ct=6.8849 rec=1.3910 | train/val/test=0.301/0.312/0.295 | c=0.998347
[Epoch 0002] loss=19.4651 cls=1.8096 smmd=3.6259 ct=6.8746 rec=1.3933 | train/val/test=0.301/0.312/0.295 | c=0.998347
[Epoch 0003] loss=18.7793 cls=1.7967 smmd=3.2915 ct=6.8603 rec=1.3939 | train/val/test=0.304/0.314/0.297 | c=0.998347
[Epoch 0004] loss=18.0419 cls=1.7656 smmd=2.9472 ct=6.8420 rec=1.3922 | train/val/test=0.305/0.319/0.297 | c=0.998347
[Epoch 0005] loss=17.2919 cls=1.7274 smmd=2.6013 ct=6.8211 rec=1.3903 | train/val/test=0.440/0.446/0.430 | c=0.998347
[Epoch 0006] loss=16.5580 cls=1.6896 smmd=2.2629 ct=6.7975 rec=1.3888 | train/val/test=0.548/0.565/0.535 | c=0.998347
[Epoch 0007] loss=15.8103 cls=1.6427 smmd=1.9239 ct=6.7689 rec=1.3871 | train/val/test=0.560/0.565/0.548 | c=0.998347
[Epoch 0008] loss=15.0879 cls=1.5765 smmd=1.6115 ct=6.7334 rec=1.3844 | train/val/test=0.567/0.570/0.565 | c=0.998347
[Epoch 0009] loss=14.5304 cls=1.4909 smmd=1.3969 ct=6.6925 rec=1.3799 | train/val/test=0.579/0.579/0.566 | c=0.998347
[Epoch 0010] loss=13.9694 cls=1.3940 smmd=1.1935 ct=6.6509 rec=1.3726 | train/val/test=0.599/0.598/0.590 | c=0.998347
[Epoch 0011] loss=13.6293 cls=1.2938 smmd=1.1106 ct=6.6136 rec=1.3615 | train/val/test=0.627/0.627/0.625 | c=0.998347
[Epoch 0012] loss=13.3323 cls=1.1968 smmd=1.0549 ct=6.5828 rec=1.3468 | train/val/test=0.648/0.646/0.640 | c=0.998347
[Epoch 0013] loss=13.1605 cls=1.1047 smmd=1.0612 ct=6.5588 rec=1.3308 | train/val/test=0.671/0.673/0.672 | c=0.998347
[Epoch 0014] loss=13.3113 cls=1.0141 smmd=1.0609 ct=7.2012 rec=1.3150 | train/val/test=0.706/0.716/0.697 | c=0.998347
[Epoch 0015] loss=13.2637 cls=0.9276 smmd=1.1256 ct=7.1718 rec=1.2998 | train/val/test=0.725/0.736/0.708 | c=0.998347
[Epoch 0016] loss=13.0806 cls=0.8516 smmd=1.1160 ct=7.1437 rec=1.2850 | train/val/test=0.735/0.742/0.731 | c=0.998347
[Epoch 0017] loss=12.9469 cls=0.7891 smmd=1.1240 ct=7.1213 rec=1.2698 | train/val/test=0.746/0.747/0.744 | c=0.998347
[Epoch 0018] loss=12.8107 cls=0.7406 smmd=1.1202 ct=7.1049 rec=1.2554 | train/val/test=0.754/0.749/0.747 | c=0.998347
[Epoch 0019] loss=12.5790 cls=0.6995 smmd=1.0568 ct=7.0939 rec=1.2438 | train/val/test=0.762/0.766/0.764 | c=0.998347
[Epoch 0020] loss=12.4108 cls=0.6599 smmd=1.0156 ct=7.0876 rec=1.2352 | train/val/test=0.780/0.780/0.779 | c=0.998347
[Epoch 0021] loss=12.2296 cls=0.6227 smmd=0.9590 ct=7.0868 rec=1.2291 | train/val/test=0.799/0.797/0.780 | c=0.998347
[Epoch 0022] loss=12.0296 cls=0.5910 smmd=0.8856 ct=7.0904 rec=1.2245 | train/val/test=0.812/0.812/0.786 | c=0.998347
[Epoch 0023] loss=11.8801 cls=0.5655 smmd=0.8314 ct=7.0961 rec=1.2208 | train/val/test=0.820/0.819/0.793 | c=0.998347
[Epoch 0024] loss=11.8228 cls=0.5448 smmd=0.8184 ct=7.1019 rec=1.2181 | train/val/test=0.826/0.823/0.795 | c=0.998347
[Epoch 0025] loss=11.6978 cls=0.5272 smmd=0.7676 ct=7.1067 rec=1.2164 | train/val/test=0.830/0.825/0.801 | c=0.998347
[Epoch 0026] loss=11.6433 cls=0.5128 smmd=0.7488 ct=7.1098 rec=1.2156 | train/val/test=0.837/0.828/0.810 | c=0.998347
[Epoch 0027] loss=11.4780 cls=0.5016 smmd=0.6721 ct=7.1113 rec=1.2153 | train/val/test=0.839/0.827/0.814 | c=0.998347
[Epoch 0028] loss=11.5271 cls=0.4930 smmd=0.7011 ct=7.1113 rec=1.2153 | train/val/test=0.843/0.827/0.812 | c=0.998347
[Epoch 0029] loss=11.4821 cls=0.4871 smmd=0.6816 ct=7.1107 rec=1.2153 | train/val/test=0.845/0.828/0.812 | c=0.998347
[Epoch 0030] loss=11.4429 cls=0.4839 smmd=0.6636 ct=7.1101 rec=1.2154 | train/val/test=0.847/0.828/0.817 | c=0.998347
[Epoch 0031] loss=11.4266 cls=0.4821 smmd=0.6559 ct=7.1096 rec=1.2156 | train/val/test=0.849/0.832/0.819 | c=0.998347
[Epoch 0032] loss=11.2323 cls=0.4809 smmd=0.5586 ct=7.1094 rec=1.2159 | train/val/test=0.847/0.836/0.825 | c=0.998347
[Epoch 0033] loss=11.2365 cls=0.4792 smmd=0.5605 ct=7.1086 rec=1.2164 | train/val/test=0.848/0.834/0.828 | c=0.998347
[Epoch 0034] loss=11.1910 cls=0.4769 smmd=0.5380 ct=7.1074 rec=1.2169 | train/val/test=0.847/0.834/0.832 | c=0.998347
[Epoch 0035] loss=11.0990 cls=0.4744 smmd=0.4928 ct=7.1066 rec=1.2172 | train/val/test=0.849/0.836/0.832 | c=0.998347
[Epoch 0036] loss=11.0064 cls=0.4713 smmd=0.4481 ct=7.1064 rec=1.2171 | train/val/test=0.850/0.836/0.834 | c=0.998347
[Epoch 0037] loss=10.9573 cls=0.4675 smmd=0.4264 ct=7.1071 rec=1.2167 | train/val/test=0.851/0.836/0.836 | c=0.998347
[Epoch 0038] loss=10.9179 cls=0.4625 smmd=0.4106 ct=7.1086 rec=1.2160 | train/val/test=0.852/0.838/0.834 | c=0.998347
[Epoch 0039] loss=10.8073 cls=0.4566 smmd=0.3601 ct=7.1110 rec=1.2150 | train/val/test=0.855/0.836/0.834 | c=0.998347
[Epoch 0040] loss=10.7694 cls=0.4503 smmd=0.3468 ct=7.1136 rec=1.2138 | train/val/test=0.855/0.838/0.834 | c=0.998347
[Epoch 0041] loss=10.7321 cls=0.4443 smmd=0.3340 ct=7.1155 rec=1.2124 | train/val/test=0.856/0.839/0.832 | c=0.998347
[Epoch 0042] loss=10.7012 cls=0.4392 smmd=0.3243 ct=7.1169 rec=1.2110 | train/val/test=0.858/0.845/0.832 | c=0.998347
[Epoch 0043] loss=10.5765 cls=0.4349 smmd=0.2667 ct=7.1187 rec=1.2098 | train/val/test=0.859/0.841/0.832 | c=0.998347
[Epoch 0044] loss=10.5687 cls=0.4306 smmd=0.2667 ct=7.1207 rec=1.2089 | train/val/test=0.859/0.841/0.830 | c=0.998347
[Epoch 0045] loss=10.4952 cls=0.4265 smmd=0.2328 ct=7.1226 rec=1.2084 | train/val/test=0.860/0.841/0.830 | c=0.998347
[Epoch 0046] loss=10.4507 cls=0.4230 smmd=0.2126 ct=7.1236 rec=1.2081 | train/val/test=0.860/0.839/0.830 | c=0.998347
[Epoch 0047] loss=10.3994 cls=0.4209 smmd=0.1883 ct=7.1239 rec=1.2080 | train/val/test=0.861/0.841/0.832 | c=0.998347
[Epoch 0048] loss=10.4213 cls=0.4196 smmd=0.1997 ct=7.1241 rec=1.2081 | train/val/test=0.862/0.843/0.832 | c=0.998347
[Epoch 0049] loss=10.3616 cls=0.4189 smmd=0.1691 ct=7.1254 rec=1.2083 | train/val/test=0.861/0.843/0.832 | c=0.998347
[Epoch 0050] loss=10.3050 cls=0.4187 smmd=0.1396 ct=7.1268 rec=1.2087 | train/val/test=0.861/0.845/0.832 | c=0.998347
[Epoch 0051] loss=10.2672 cls=0.4189 smmd=0.1191 ct=7.1279 rec=1.2092 | train/val/test=0.861/0.845/0.832 | c=0.998347
[Epoch 0052] loss=10.2619 cls=0.4190 smmd=0.1151 ct=7.1283 rec=1.2097 | train/val/test=0.860/0.843/0.828 | c=0.998347
[Epoch 0053] loss=10.2514 cls=0.4193 smmd=0.1085 ct=7.1289 rec=1.2101 | train/val/test=0.862/0.843/0.828 | c=0.998347
[Epoch 0054] loss=10.2362 cls=0.4197 smmd=0.0995 ct=7.1305 rec=1.2105 | train/val/test=0.863/0.847/0.827 | c=0.998347
[Epoch 0055] loss=10.2041 cls=0.4194 smmd=0.0824 ct=7.1313 rec=1.2109 | train/val/test=0.863/0.847/0.825 | c=0.998347
[Epoch 0056] loss=10.1653 cls=0.4187 smmd=0.0627 ct=7.1314 rec=1.2111 | train/val/test=0.864/0.847/0.827 | c=0.998347
[Epoch 0057] loss=10.1462 cls=0.4167 smmd=0.0538 ct=7.1307 rec=1.2113 | train/val/test=0.869/0.851/0.827 | c=0.998347
[Epoch 0058] loss=10.1391 cls=0.4138 smmd=0.0517 ct=7.1295 rec=1.2114 | train/val/test=0.869/0.852/0.830 | c=0.998347
[Epoch 0059] loss=10.1215 cls=0.4117 smmd=0.0446 ct=7.1295 rec=1.2112 | train/val/test=0.869/0.854/0.834 | c=0.998347
[Epoch 0060] loss=10.1079 cls=0.4094 smmd=0.0397 ct=7.1303 rec=1.2108 | train/val/test=0.871/0.856/0.834 | c=0.998347
[Epoch 0061] loss=10.1079 cls=0.4061 smmd=0.0420 ct=7.1306 rec=1.2105 | train/val/test=0.873/0.860/0.836 | c=0.998347
[Epoch 0062] loss=10.0830 cls=0.4032 smmd=0.0318 ct=7.1305 rec=1.2102 | train/val/test=0.878/0.856/0.836 | c=0.998347
[Epoch 0063] loss=10.0594 cls=0.4001 smmd=0.0228 ct=7.1298 rec=1.2098 | train/val/test=0.880/0.867/0.841 | c=0.998347
[Epoch 0064] loss=10.0519 cls=0.3968 smmd=0.0218 ct=7.1289 rec=1.2094 | train/val/test=0.883/0.867/0.845 | c=0.998347
[Epoch 0065] loss=10.0292 cls=0.3942 smmd=0.0131 ct=7.1284 rec=1.2089 | train/val/test=0.885/0.863/0.845 | c=0.998347
[Epoch 0066] loss=10.0327 cls=0.3916 smmd=0.0177 ct=7.1277 rec=1.2084 | train/val/test=0.887/0.863/0.845 | c=0.998347
[Epoch 0067] loss=10.0088 cls=0.3879 smmd=0.0087 ct=7.1265 rec=1.2081 | train/val/test=0.890/0.867/0.845 | c=0.998347
[Epoch 0068] loss=9.9957 cls=0.3848 smmd=0.0050 ct=7.1255 rec=1.2076 | train/val/test=0.891/0.869/0.841 | c=0.998347
[Epoch 0069] loss=10.0016 cls=0.3820 smmd=0.0109 ct=7.1247 rec=1.2071 | train/val/test=0.896/0.876/0.845 | c=0.998347
[Epoch 0070] loss=9.9867 cls=0.3786 smmd=0.0062 ct=7.1239 rec=1.2067 | train/val/test=0.898/0.878/0.845 | c=0.998347
[Epoch 0071] loss=9.9666 cls=0.3751 smmd=-0.0009 ct=7.1229 rec=1.2064 | train/val/test=0.900/0.880/0.852 | c=0.998347
[Epoch 0072] loss=9.9646 cls=0.3714 smmd=0.0014 ct=7.1214 rec=1.2060 | train/val/test=0.903/0.887/0.852 | c=0.998347
[Epoch 0073] loss=9.9569 cls=0.3685 smmd=0.0003 ct=7.1210 rec=1.2054 | train/val/test=0.907/0.889/0.856 | c=0.998347
[Epoch 0074] loss=9.9554 cls=0.3658 smmd=0.0026 ct=7.1198 rec=1.2049 | train/val/test=0.908/0.891/0.858 | c=0.998347
[Epoch 0075] loss=9.9528 cls=0.3634 smmd=0.0040 ct=7.1192 rec=1.2044 | train/val/test=0.908/0.893/0.860 | c=0.998347
[Epoch 0076] loss=9.9355 cls=0.3613 smmd=-0.0026 ct=7.1194 rec=1.2040 | train/val/test=0.909/0.893/0.862 | c=0.998347
[Epoch 0077] loss=9.9186 cls=0.3594 smmd=-0.0094 ct=7.1196 rec=1.2036 | train/val/test=0.909/0.893/0.862 | c=0.998347
[Epoch 0078] loss=9.9117 cls=0.3578 smmd=-0.0107 ct=7.1183 rec=1.2032 | train/val/test=0.909/0.893/0.862 | c=0.998347
[Epoch 0079] loss=9.9149 cls=0.3557 smmd=-0.0065 ct=7.1162 rec=1.2028 | train/val/test=0.909/0.893/0.862 | c=0.998347
[Epoch 0080] loss=9.9047 cls=0.3544 smmd=-0.0096 ct=7.1160 rec=1.2023 | train/val/test=0.910/0.893/0.862 | c=0.998347
[Epoch 0081] loss=9.8968 cls=0.3532 smmd=-0.0115 ct=7.1161 rec=1.2017 | train/val/test=0.910/0.893/0.862 | c=0.998347
[Epoch 0082] loss=9.8941 cls=0.3520 smmd=-0.0106 ct=7.1149 rec=1.2012 | train/val/test=0.909/0.895/0.862 | c=0.998347
[Epoch 0083] loss=9.8881 cls=0.3505 smmd=-0.0118 ct=7.1139 rec=1.2009 | train/val/test=0.910/0.895/0.862 | c=0.998347
[Epoch 0084] loss=9.8783 cls=0.3492 smmd=-0.0155 ct=7.1142 rec=1.2006 | train/val/test=0.909/0.895/0.862 | c=0.998347
[Epoch 0085] loss=9.8835 cls=0.3480 smmd=-0.0113 ct=7.1139 rec=1.2002 | train/val/test=0.909/0.893/0.860 | c=0.998347
[Epoch 0086] loss=9.8757 cls=0.3474 smmd=-0.0139 ct=7.1134 rec=1.1999 | train/val/test=0.910/0.893/0.862 | c=0.998347
[Epoch 0087] loss=9.8765 cls=0.3455 smmd=-0.0114 ct=7.1106 rec=1.1997 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0088] loss=9.8757 cls=0.3452 smmd=-0.0105 ct=7.1100 rec=1.1993 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0089] loss=9.8690 cls=0.3448 smmd=-0.0131 ct=7.1106 rec=1.1990 | train/val/test=0.911/0.893/0.862 | c=0.998347
[Epoch 0090] loss=9.8732 cls=0.3437 smmd=-0.0104 ct=7.1103 rec=1.1990 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0091] loss=9.8561 cls=0.3437 smmd=-0.0186 ct=7.1100 rec=1.1989 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0092] loss=9.8568 cls=0.3439 smmd=-0.0178 ct=7.1088 rec=1.1988 | train/val/test=0.911/0.893/0.862 | c=0.998347
[Epoch 0093] loss=9.8701 cls=0.3438 smmd=-0.0110 ct=7.1086 rec=1.1988 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0094] loss=9.8632 cls=0.3446 smmd=-0.0152 ct=7.1098 rec=1.1988 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0095] loss=9.8589 cls=0.3438 smmd=-0.0177 ct=7.1097 rec=1.1991 | train/val/test=0.911/0.891/0.858 | c=0.998347
[Epoch 0096] loss=9.8605 cls=0.3438 smmd=-0.0172 ct=7.1096 rec=1.1993 | train/val/test=0.910/0.891/0.860 | c=0.998347
[Epoch 0097] loss=9.8631 cls=0.3434 smmd=-0.0156 ct=7.1081 rec=1.1994 | train/val/test=0.910/0.891/0.860 | c=0.998347
[Epoch 0098] loss=9.8550 cls=0.3433 smmd=-0.0193 ct=7.1076 rec=1.1993 | train/val/test=0.910/0.891/0.860 | c=0.998347
[Epoch 0099] loss=9.8595 cls=0.3429 smmd=-0.0163 ct=7.1079 rec=1.1990 | train/val/test=0.910/0.891/0.858 | c=0.998347
[Epoch 0100] loss=9.8554 cls=0.3427 smmd=-0.0176 ct=7.1081 rec=1.1987 | train/val/test=0.910/0.891/0.860 | c=0.998347
[Epoch 0101] loss=9.8482 cls=0.3419 smmd=-0.0201 ct=7.1076 rec=1.1985 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0102] loss=9.8455 cls=0.3411 smmd=-0.0206 ct=7.1072 rec=1.1984 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0103] loss=9.8458 cls=0.3405 smmd=-0.0195 ct=7.1065 rec=1.1982 | train/val/test=0.910/0.895/0.860 | c=0.998347
[Epoch 0104] loss=9.8481 cls=0.3409 smmd=-0.0180 ct=7.1068 rec=1.1980 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0105] loss=9.8468 cls=0.3402 smmd=-0.0186 ct=7.1071 rec=1.1980 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0106] loss=9.8379 cls=0.3399 smmd=-0.0227 ct=7.1058 rec=1.1981 | train/val/test=0.910/0.891/0.860 | c=0.998347
[Epoch 0107] loss=9.8368 cls=0.3405 smmd=-0.0233 ct=7.1054 rec=1.1980 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0108] loss=9.8385 cls=0.3405 smmd=-0.0225 ct=7.1053 rec=1.1980 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0109] loss=9.8403 cls=0.3400 smmd=-0.0217 ct=7.1057 rec=1.1982 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0110] loss=9.8370 cls=0.3398 smmd=-0.0233 ct=7.1060 rec=1.1981 | train/val/test=0.911/0.891/0.858 | c=0.998347
[Epoch 0111] loss=9.8363 cls=0.3405 smmd=-0.0232 ct=7.1054 rec=1.1979 | train/val/test=0.911/0.893/0.858 | c=0.998347
[Epoch 0112] loss=9.8421 cls=0.3400 smmd=-0.0196 ct=7.1040 rec=1.1979 | train/val/test=0.909/0.893/0.858 | c=0.998347
[Epoch 0113] loss=9.8431 cls=0.3396 smmd=-0.0186 ct=7.1030 rec=1.1978 | train/val/test=0.910/0.891/0.858 | c=0.998347
[Epoch 0114] loss=9.8308 cls=0.3400 smmd=-0.0250 ct=7.1037 rec=1.1978 | train/val/test=0.910/0.891/0.858 | c=0.998347
[Epoch 0115] loss=9.8419 cls=0.3392 smmd=-0.0192 ct=7.1040 rec=1.1978 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0116] loss=9.8386 cls=0.3394 smmd=-0.0207 ct=7.1035 rec=1.1978 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0117] loss=9.8221 cls=0.3402 smmd=-0.0290 ct=7.1032 rec=1.1977 | train/val/test=0.909/0.895/0.858 | c=0.998347
[Epoch 0118] loss=9.8461 cls=0.3391 smmd=-0.0165 ct=7.1017 rec=1.1978 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0119] loss=9.8304 cls=0.3390 smmd=-0.0245 ct=7.1023 rec=1.1978 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0120] loss=9.8317 cls=0.3393 smmd=-0.0240 ct=7.1034 rec=1.1977 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0121] loss=9.8343 cls=0.3388 smmd=-0.0220 ct=7.1025 rec=1.1976 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0122] loss=9.8311 cls=0.3381 smmd=-0.0225 ct=7.1013 rec=1.1975 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0123] loss=9.8229 cls=0.3380 smmd=-0.0261 ct=7.1011 rec=1.1973 | train/val/test=0.908/0.893/0.856 | c=0.998347
[Epoch 0124] loss=9.8203 cls=0.3386 smmd=-0.0273 ct=7.1021 rec=1.1971 | train/val/test=0.910/0.895/0.856 | c=0.998347
[Epoch 0125] loss=9.8243 cls=0.3371 smmd=-0.0244 ct=7.1010 rec=1.1971 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0126] loss=9.8308 cls=0.3372 smmd=-0.0210 ct=7.1008 rec=1.1970 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0127] loss=9.8269 cls=0.3381 smmd=-0.0229 ct=7.1011 rec=1.1968 | train/val/test=0.910/0.895/0.856 | c=0.998347
[Epoch 0128] loss=9.8254 cls=0.3380 smmd=-0.0238 ct=7.1005 rec=1.1970 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0129] loss=9.8318 cls=0.3375 smmd=-0.0211 ct=7.1002 rec=1.1973 | train/val/test=0.910/0.895/0.858 | c=0.998347
[Epoch 0130] loss=9.8214 cls=0.3373 smmd=-0.0266 ct=7.1000 rec=1.1975 | train/val/test=0.911/0.889/0.856 | c=0.998347
[Epoch 0131] loss=9.8313 cls=0.3382 smmd=-0.0219 ct=7.1000 rec=1.1974 | train/val/test=0.911/0.895/0.856 | c=0.998347
[Epoch 0132] loss=9.8195 cls=0.3380 smmd=-0.0281 ct=7.1006 rec=1.1975 | train/val/test=0.909/0.895/0.854 | c=0.998347
[Epoch 0133] loss=9.8202 cls=0.3375 smmd=-0.0275 ct=7.1002 rec=1.1975 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0134] loss=9.8201 cls=0.3376 smmd=-0.0269 ct=7.0990 rec=1.1974 | train/val/test=0.909/0.889/0.856 | c=0.998347
[Epoch 0135] loss=9.8128 cls=0.3382 smmd=-0.0302 ct=7.0992 rec=1.1971 | train/val/test=0.910/0.891/0.856 | c=0.998347
[Epoch 0136] loss=9.8252 cls=0.3375 smmd=-0.0233 ct=7.0991 rec=1.1970 | train/val/test=0.909/0.895/0.854 | c=0.998347
[Epoch 0137] loss=9.8123 cls=0.3370 smmd=-0.0293 ct=7.0983 rec=1.1969 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0138] loss=9.8280 cls=0.3365 smmd=-0.0207 ct=7.0976 rec=1.1968 | train/val/test=0.908/0.891/0.856 | c=0.998347
[Epoch 0139] loss=9.8115 cls=0.3374 smmd=-0.0293 ct=7.0990 rec=1.1967 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0140] loss=9.8114 cls=0.3375 smmd=-0.0300 ct=7.0999 rec=1.1968 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0141] loss=9.8123 cls=0.3361 smmd=-0.0293 ct=7.0979 rec=1.1972 | train/val/test=0.910/0.889/0.856 | c=0.998347
[Epoch 0142] loss=9.8170 cls=0.3363 smmd=-0.0264 ct=7.0961 rec=1.1971 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0143] loss=9.8157 cls=0.3373 smmd=-0.0270 ct=7.0970 rec=1.1968 | train/val/test=0.910/0.893/0.856 | c=0.998347
[Epoch 0144] loss=9.8160 cls=0.3368 smmd=-0.0267 ct=7.0981 rec=1.1967 | train/val/test=0.910/0.893/0.854 | c=0.998347
[Epoch 0145] loss=9.8122 cls=0.3356 smmd=-0.0281 ct=7.0976 rec=1.1968 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0146] loss=9.8153 cls=0.3356 smmd=-0.0260 ct=7.0967 rec=1.1967 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0147] loss=9.8145 cls=0.3363 smmd=-0.0261 ct=7.0962 rec=1.1965 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0148] loss=9.8158 cls=0.3368 smmd=-0.0256 ct=7.0967 rec=1.1964 | train/val/test=0.909/0.891/0.854 | c=0.998347
[Epoch 0149] loss=9.8209 cls=0.3358 smmd=-0.0234 ct=7.0970 rec=1.1967 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0150] loss=9.8088 cls=0.3362 smmd=-0.0300 ct=7.0975 rec=1.1968 | train/val/test=0.909/0.891/0.854 | c=0.998347
[Epoch 0151] loss=9.8175 cls=0.3370 smmd=-0.0260 ct=7.0976 rec=1.1968 | train/val/test=0.909/0.891/0.854 | c=0.998347
[Epoch 0152] loss=9.8179 cls=0.3371 smmd=-0.0256 ct=7.0962 rec=1.1968 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0153] loss=9.8113 cls=0.3361 smmd=-0.0288 ct=7.0955 rec=1.1970 | train/val/test=0.906/0.893/0.854 | c=0.998347
[Epoch 0154] loss=9.8117 cls=0.3361 smmd=-0.0284 ct=7.0962 rec=1.1969 | train/val/test=0.906/0.891/0.854 | c=0.998347
[Epoch 0155] loss=9.8081 cls=0.3365 smmd=-0.0298 ct=7.0963 rec=1.1966 | train/val/test=0.909/0.891/0.854 | c=0.998347
[Epoch 0156] loss=9.8071 cls=0.3362 smmd=-0.0293 ct=7.0950 rec=1.1964 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0157] loss=9.8067 cls=0.3352 smmd=-0.0286 ct=7.0941 rec=1.1963 | train/val/test=0.910/0.895/0.856 | c=0.998347
[Epoch 0158] loss=9.8042 cls=0.3350 smmd=-0.0296 ct=7.0948 rec=1.1962 | train/val/test=0.906/0.893/0.856 | c=0.998347
[Epoch 0159] loss=9.8044 cls=0.3355 smmd=-0.0295 ct=7.0958 rec=1.1960 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0160] loss=9.8149 cls=0.3353 smmd=-0.0239 ct=7.0945 rec=1.1960 | train/val/test=0.909/0.897/0.856 | c=0.998347
[Epoch 0161] loss=9.8105 cls=0.3346 smmd=-0.0261 ct=7.0933 rec=1.1963 | train/val/test=0.910/0.895/0.856 | c=0.998347
[Epoch 0162] loss=9.8041 cls=0.3346 smmd=-0.0296 ct=7.0937 rec=1.1964 | train/val/test=0.906/0.893/0.856 | c=0.998347
[Epoch 0163] loss=9.8147 cls=0.3356 smmd=-0.0248 ct=7.0953 rec=1.1962 | train/val/test=0.907/0.893/0.856 | c=0.998347
[Epoch 0164] loss=9.8191 cls=0.3357 smmd=-0.0228 ct=7.0953 rec=1.1963 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0165] loss=9.8088 cls=0.3358 smmd=-0.0283 ct=7.0949 rec=1.1964 | train/val/test=0.911/0.897/0.858 | c=0.998347
[Epoch 0166] loss=9.8129 cls=0.3349 smmd=-0.0262 ct=7.0936 rec=1.1967 | train/val/test=0.910/0.897/0.858 | c=0.998347
[Epoch 0167] loss=9.8092 cls=0.3352 smmd=-0.0282 ct=7.0940 rec=1.1967 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0168] loss=9.8047 cls=0.3369 smmd=-0.0306 ct=7.0945 rec=1.1963 | train/val/test=0.909/0.893/0.858 | c=0.998347
[Epoch 0169] loss=9.8054 cls=0.3357 smmd=-0.0298 ct=7.0944 rec=1.1964 | train/val/test=0.911/0.897/0.860 | c=0.998347
[Epoch 0170] loss=9.8130 cls=0.3346 smmd=-0.0256 ct=7.0939 rec=1.1966 | train/val/test=0.910/0.893/0.856 | c=0.998347
[Epoch 0171] loss=9.8066 cls=0.3352 smmd=-0.0285 ct=7.0937 rec=1.1963 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0172] loss=9.8047 cls=0.3358 smmd=-0.0293 ct=7.0941 rec=1.1961 | train/val/test=0.910/0.893/0.856 | c=0.998347
[Epoch 0173] loss=9.8063 cls=0.3350 smmd=-0.0285 ct=7.0938 rec=1.1963 | train/val/test=0.911/0.895/0.858 | c=0.998347
[Epoch 0174] loss=9.8083 cls=0.3349 smmd=-0.0275 ct=7.0932 rec=1.1964 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0175] loss=9.8071 cls=0.3363 smmd=-0.0285 ct=7.0936 rec=1.1962 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0176] loss=9.8050 cls=0.3367 smmd=-0.0302 ct=7.0942 rec=1.1963 | train/val/test=0.911/0.895/0.856 | c=0.998347
[Epoch 0177] loss=9.7977 cls=0.3353 smmd=-0.0341 ct=7.0942 rec=1.1967 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0178] loss=9.8006 cls=0.3349 smmd=-0.0321 ct=7.0932 rec=1.1967 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0179] loss=9.8080 cls=0.3365 smmd=-0.0280 ct=7.0933 rec=1.1962 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0180] loss=9.8018 cls=0.3352 smmd=-0.0305 ct=7.0930 rec=1.1962 | train/val/test=0.910/0.895/0.858 | c=0.998347
[Epoch 0181] loss=9.8107 cls=0.3340 smmd=-0.0260 ct=7.0928 rec=1.1965 | train/val/test=0.906/0.895/0.856 | c=0.998347
[Epoch 0182] loss=9.8073 cls=0.3355 smmd=-0.0280 ct=7.0940 rec=1.1962 | train/val/test=0.906/0.893/0.854 | c=0.998347
[Epoch 0183] loss=9.8058 cls=0.3369 smmd=-0.0293 ct=7.0944 rec=1.1961 | train/val/test=0.908/0.893/0.858 | c=0.998347
[Epoch 0184] loss=9.8012 cls=0.3350 smmd=-0.0312 ct=7.0921 rec=1.1965 | train/val/test=0.909/0.893/0.858 | c=0.998347
[Epoch 0185] loss=9.8083 cls=0.3343 smmd=-0.0275 ct=7.0912 rec=1.1967 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0186] loss=9.7967 cls=0.3364 smmd=-0.0336 ct=7.0929 rec=1.1962 | train/val/test=0.906/0.895/0.856 | c=0.998347
[Epoch 0187] loss=9.8019 cls=0.3362 smmd=-0.0308 ct=7.0937 rec=1.1961 | train/val/test=0.908/0.893/0.858 | c=0.998347
[Epoch 0188] loss=9.7917 cls=0.3340 smmd=-0.0352 ct=7.0924 rec=1.1964 | train/val/test=0.909/0.893/0.858 | c=0.998347
[Epoch 0189] loss=9.8021 cls=0.3340 smmd=-0.0289 ct=7.0914 rec=1.1961 | train/val/test=0.906/0.895/0.856 | c=0.998347
[Epoch 0190] loss=9.8099 cls=0.3356 smmd=-0.0248 ct=7.0921 rec=1.1956 | train/val/test=0.906/0.895/0.858 | c=0.998347
[Epoch 0191] loss=9.7989 cls=0.3347 smmd=-0.0301 ct=7.0921 rec=1.1956 | train/val/test=0.906/0.893/0.858 | c=0.998347
[Epoch 0192] loss=9.8071 cls=0.3339 smmd=-0.0258 ct=7.0912 rec=1.1958 | train/val/test=0.905/0.893/0.856 | c=0.998347
[Epoch 0193] loss=9.7964 cls=0.3349 smmd=-0.0316 ct=7.0912 rec=1.1958 | train/val/test=0.906/0.895/0.856 | c=0.998347
[Epoch 0194] loss=9.8040 cls=0.3355 smmd=-0.0284 ct=7.0914 rec=1.1959 | train/val/test=0.908/0.893/0.858 | c=0.998347
[Epoch 0195] loss=9.8066 cls=0.3341 smmd=-0.0271 ct=7.0910 rec=1.1962 | train/val/test=0.907/0.895/0.856 | c=0.998347
[Epoch 0196] loss=9.8033 cls=0.3350 smmd=-0.0289 ct=7.0916 rec=1.1961 | train/val/test=0.906/0.893/0.856 | c=0.998347
[Epoch 0197] loss=9.7988 cls=0.3359 smmd=-0.0314 ct=7.0918 rec=1.1959 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0198] loss=9.8039 cls=0.3348 smmd=-0.0288 ct=7.0917 rec=1.1962 | train/val/test=0.908/0.893/0.860 | c=0.998347
[Epoch 0199] loss=9.8039 cls=0.3341 smmd=-0.0287 ct=7.0918 rec=1.1963 | train/val/test=0.908/0.893/0.858 | c=0.998347
=== Best @ epoch 160: val=0.8967, test=0.8561 ===

==================================================
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3 - 2025-09-21 06:28:21:
Running experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3...
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=1624, val=542, test=542 (mode=public, shot=N/A)
[Epoch 0000] loss=20.7701 cls=1.9531 smmd=4.2131 ct=6.8926 rec=1.3889 | train/val/test=0.306/0.315/0.299 | c=0.998347
[Epoch 0001] loss=20.0957 cls=1.8518 smmd=3.9232 ct=6.8849 rec=1.3910 | train/val/test=0.301/0.312/0.295 | c=0.998347
[Epoch 0002] loss=19.4651 cls=1.8096 smmd=3.6259 ct=6.8746 rec=1.3933 | train/val/test=0.301/0.312/0.295 | c=0.998347
[Epoch 0003] loss=18.7793 cls=1.7967 smmd=3.2915 ct=6.8603 rec=1.3939 | train/val/test=0.304/0.314/0.297 | c=0.998347
[Epoch 0004] loss=18.0419 cls=1.7656 smmd=2.9472 ct=6.8420 rec=1.3922 | train/val/test=0.305/0.319/0.297 | c=0.998347
[Epoch 0005] loss=17.2919 cls=1.7274 smmd=2.6013 ct=6.8211 rec=1.3903 | train/val/test=0.440/0.446/0.430 | c=0.998347
[Epoch 0006] loss=16.5580 cls=1.6896 smmd=2.2629 ct=6.7975 rec=1.3888 | train/val/test=0.548/0.565/0.535 | c=0.998347
[Epoch 0007] loss=15.8103 cls=1.6427 smmd=1.9239 ct=6.7689 rec=1.3871 | train/val/test=0.560/0.565/0.548 | c=0.998347
[Epoch 0008] loss=15.0879 cls=1.5765 smmd=1.6115 ct=6.7334 rec=1.3844 | train/val/test=0.567/0.570/0.565 | c=0.998347
[Epoch 0009] loss=14.5304 cls=1.4909 smmd=1.3969 ct=6.6925 rec=1.3799 | train/val/test=0.579/0.579/0.566 | c=0.998347
[Epoch 0010] loss=13.9694 cls=1.3940 smmd=1.1935 ct=6.6509 rec=1.3726 | train/val/test=0.599/0.598/0.590 | c=0.998347
[Epoch 0011] loss=13.6293 cls=1.2938 smmd=1.1106 ct=6.6136 rec=1.3615 | train/val/test=0.627/0.627/0.625 | c=0.998347
[Epoch 0012] loss=13.3323 cls=1.1968 smmd=1.0549 ct=6.5828 rec=1.3468 | train/val/test=0.648/0.646/0.640 | c=0.998347
[Epoch 0013] loss=13.1605 cls=1.1047 smmd=1.0612 ct=6.5588 rec=1.3308 | train/val/test=0.671/0.673/0.672 | c=0.998347
[Epoch 0014] loss=13.3113 cls=1.0141 smmd=1.0609 ct=7.2012 rec=1.3150 | train/val/test=0.706/0.716/0.697 | c=0.998347
[Epoch 0015] loss=13.2637 cls=0.9276 smmd=1.1256 ct=7.1718 rec=1.2998 | train/val/test=0.725/0.736/0.708 | c=0.998347
[Epoch 0016] loss=13.0806 cls=0.8516 smmd=1.1160 ct=7.1437 rec=1.2850 | train/val/test=0.735/0.742/0.731 | c=0.998347
[Epoch 0017] loss=12.9469 cls=0.7891 smmd=1.1240 ct=7.1213 rec=1.2698 | train/val/test=0.746/0.747/0.744 | c=0.998347
[Epoch 0018] loss=12.8107 cls=0.7406 smmd=1.1202 ct=7.1049 rec=1.2554 | train/val/test=0.754/0.749/0.747 | c=0.998347
[Epoch 0019] loss=12.5790 cls=0.6995 smmd=1.0568 ct=7.0939 rec=1.2438 | train/val/test=0.762/0.766/0.764 | c=0.998347
[Epoch 0020] loss=12.4108 cls=0.6599 smmd=1.0156 ct=7.0876 rec=1.2352 | train/val/test=0.780/0.780/0.779 | c=0.998347
[Epoch 0021] loss=12.2296 cls=0.6227 smmd=0.9590 ct=7.0868 rec=1.2291 | train/val/test=0.799/0.797/0.780 | c=0.998347
[Epoch 0022] loss=12.0296 cls=0.5910 smmd=0.8856 ct=7.0904 rec=1.2245 | train/val/test=0.812/0.812/0.786 | c=0.998347
[Epoch 0023] loss=11.8801 cls=0.5655 smmd=0.8314 ct=7.0961 rec=1.2208 | train/val/test=0.820/0.819/0.793 | c=0.998347
[Epoch 0024] loss=11.8228 cls=0.5448 smmd=0.8184 ct=7.1019 rec=1.2181 | train/val/test=0.826/0.823/0.795 | c=0.998347
[Epoch 0025] loss=11.6978 cls=0.5272 smmd=0.7676 ct=7.1067 rec=1.2164 | train/val/test=0.830/0.825/0.801 | c=0.998347
[Epoch 0026] loss=11.6433 cls=0.5128 smmd=0.7488 ct=7.1098 rec=1.2156 | train/val/test=0.837/0.828/0.810 | c=0.998347
[Epoch 0027] loss=11.4780 cls=0.5016 smmd=0.6721 ct=7.1113 rec=1.2153 | train/val/test=0.839/0.827/0.814 | c=0.998347
[Epoch 0028] loss=11.5271 cls=0.4930 smmd=0.7011 ct=7.1113 rec=1.2153 | train/val/test=0.843/0.827/0.812 | c=0.998347
[Epoch 0029] loss=11.4821 cls=0.4871 smmd=0.6816 ct=7.1107 rec=1.2153 | train/val/test=0.845/0.828/0.812 | c=0.998347
[Epoch 0030] loss=11.4429 cls=0.4839 smmd=0.6636 ct=7.1101 rec=1.2154 | train/val/test=0.847/0.828/0.817 | c=0.998347
[Epoch 0031] loss=11.4266 cls=0.4821 smmd=0.6559 ct=7.1096 rec=1.2156 | train/val/test=0.849/0.832/0.819 | c=0.998347
[Epoch 0032] loss=11.2323 cls=0.4809 smmd=0.5586 ct=7.1094 rec=1.2159 | train/val/test=0.847/0.836/0.825 | c=0.998347
[Epoch 0033] loss=11.2365 cls=0.4792 smmd=0.5605 ct=7.1086 rec=1.2164 | train/val/test=0.848/0.834/0.828 | c=0.998347
[Epoch 0034] loss=11.1910 cls=0.4769 smmd=0.5380 ct=7.1074 rec=1.2169 | train/val/test=0.847/0.834/0.832 | c=0.998347
[Epoch 0035] loss=11.0990 cls=0.4744 smmd=0.4928 ct=7.1066 rec=1.2172 | train/val/test=0.849/0.836/0.832 | c=0.998347
[Epoch 0036] loss=11.0064 cls=0.4713 smmd=0.4481 ct=7.1064 rec=1.2171 | train/val/test=0.850/0.836/0.834 | c=0.998347
[Epoch 0037] loss=10.9573 cls=0.4675 smmd=0.4264 ct=7.1071 rec=1.2167 | train/val/test=0.851/0.836/0.836 | c=0.998347
[Epoch 0038] loss=10.9179 cls=0.4625 smmd=0.4106 ct=7.1086 rec=1.2160 | train/val/test=0.852/0.838/0.834 | c=0.998347
[Epoch 0039] loss=10.8073 cls=0.4566 smmd=0.3601 ct=7.1110 rec=1.2150 | train/val/test=0.855/0.836/0.834 | c=0.998347
[Epoch 0040] loss=10.7694 cls=0.4503 smmd=0.3468 ct=7.1136 rec=1.2138 | train/val/test=0.855/0.838/0.834 | c=0.998347
[Epoch 0041] loss=10.7321 cls=0.4443 smmd=0.3340 ct=7.1155 rec=1.2124 | train/val/test=0.856/0.839/0.832 | c=0.998347
[Epoch 0042] loss=10.7012 cls=0.4392 smmd=0.3243 ct=7.1169 rec=1.2110 | train/val/test=0.858/0.845/0.832 | c=0.998347
[Epoch 0043] loss=10.5765 cls=0.4349 smmd=0.2667 ct=7.1187 rec=1.2098 | train/val/test=0.859/0.841/0.832 | c=0.998347
[Epoch 0044] loss=10.5687 cls=0.4306 smmd=0.2667 ct=7.1207 rec=1.2089 | train/val/test=0.859/0.841/0.830 | c=0.998347
[Epoch 0045] loss=10.4952 cls=0.4265 smmd=0.2328 ct=7.1226 rec=1.2084 | train/val/test=0.860/0.841/0.830 | c=0.998347
[Epoch 0046] loss=10.4507 cls=0.4230 smmd=0.2126 ct=7.1236 rec=1.2081 | train/val/test=0.860/0.839/0.830 | c=0.998347
[Epoch 0047] loss=10.3994 cls=0.4209 smmd=0.1883 ct=7.1239 rec=1.2080 | train/val/test=0.861/0.841/0.832 | c=0.998347
[Epoch 0048] loss=10.4213 cls=0.4196 smmd=0.1997 ct=7.1241 rec=1.2081 | train/val/test=0.862/0.843/0.832 | c=0.998347
[Epoch 0049] loss=10.3616 cls=0.4189 smmd=0.1691 ct=7.1254 rec=1.2083 | train/val/test=0.861/0.843/0.832 | c=0.998347
[Epoch 0050] loss=10.3050 cls=0.4187 smmd=0.1396 ct=7.1268 rec=1.2087 | train/val/test=0.861/0.845/0.832 | c=0.998347
[Epoch 0051] loss=10.2672 cls=0.4189 smmd=0.1191 ct=7.1279 rec=1.2092 | train/val/test=0.861/0.845/0.832 | c=0.998347
[Epoch 0052] loss=10.2619 cls=0.4190 smmd=0.1151 ct=7.1283 rec=1.2097 | train/val/test=0.860/0.843/0.828 | c=0.998347
[Epoch 0053] loss=10.2514 cls=0.4193 smmd=0.1085 ct=7.1289 rec=1.2101 | train/val/test=0.862/0.843/0.828 | c=0.998347
[Epoch 0054] loss=10.2362 cls=0.4197 smmd=0.0995 ct=7.1305 rec=1.2105 | train/val/test=0.863/0.847/0.827 | c=0.998347
[Epoch 0055] loss=10.2041 cls=0.4194 smmd=0.0824 ct=7.1313 rec=1.2109 | train/val/test=0.863/0.847/0.825 | c=0.998347
[Epoch 0056] loss=10.1653 cls=0.4187 smmd=0.0627 ct=7.1314 rec=1.2111 | train/val/test=0.864/0.847/0.827 | c=0.998347
[Epoch 0057] loss=10.1462 cls=0.4167 smmd=0.0538 ct=7.1307 rec=1.2113 | train/val/test=0.869/0.851/0.827 | c=0.998347
[Epoch 0058] loss=10.1391 cls=0.4138 smmd=0.0517 ct=7.1295 rec=1.2114 | train/val/test=0.869/0.852/0.830 | c=0.998347
[Epoch 0059] loss=10.1215 cls=0.4117 smmd=0.0446 ct=7.1295 rec=1.2112 | train/val/test=0.869/0.854/0.834 | c=0.998347
[Epoch 0060] loss=10.1079 cls=0.4094 smmd=0.0397 ct=7.1303 rec=1.2108 | train/val/test=0.871/0.856/0.834 | c=0.998347
[Epoch 0061] loss=10.1079 cls=0.4061 smmd=0.0420 ct=7.1306 rec=1.2105 | train/val/test=0.873/0.860/0.836 | c=0.998347
[Epoch 0062] loss=10.0830 cls=0.4032 smmd=0.0318 ct=7.1305 rec=1.2102 | train/val/test=0.878/0.856/0.836 | c=0.998347
[Epoch 0063] loss=10.0594 cls=0.4001 smmd=0.0228 ct=7.1298 rec=1.2098 | train/val/test=0.880/0.867/0.841 | c=0.998347
[Epoch 0064] loss=10.0519 cls=0.3968 smmd=0.0218 ct=7.1289 rec=1.2094 | train/val/test=0.883/0.867/0.845 | c=0.998347
[Epoch 0065] loss=10.0292 cls=0.3942 smmd=0.0131 ct=7.1284 rec=1.2089 | train/val/test=0.885/0.863/0.845 | c=0.998347
[Epoch 0066] loss=10.0327 cls=0.3916 smmd=0.0177 ct=7.1277 rec=1.2084 | train/val/test=0.887/0.863/0.845 | c=0.998347
[Epoch 0067] loss=10.0088 cls=0.3879 smmd=0.0087 ct=7.1265 rec=1.2081 | train/val/test=0.890/0.867/0.845 | c=0.998347
[Epoch 0068] loss=9.9957 cls=0.3848 smmd=0.0050 ct=7.1255 rec=1.2076 | train/val/test=0.891/0.869/0.841 | c=0.998347
[Epoch 0069] loss=10.0016 cls=0.3820 smmd=0.0109 ct=7.1247 rec=1.2071 | train/val/test=0.896/0.876/0.845 | c=0.998347
[Epoch 0070] loss=9.9867 cls=0.3786 smmd=0.0062 ct=7.1239 rec=1.2067 | train/val/test=0.898/0.878/0.845 | c=0.998347
[Epoch 0071] loss=9.9666 cls=0.3751 smmd=-0.0009 ct=7.1229 rec=1.2064 | train/val/test=0.900/0.880/0.852 | c=0.998347
[Epoch 0072] loss=9.9646 cls=0.3714 smmd=0.0014 ct=7.1214 rec=1.2060 | train/val/test=0.903/0.887/0.852 | c=0.998347
[Epoch 0073] loss=9.9569 cls=0.3685 smmd=0.0003 ct=7.1210 rec=1.2054 | train/val/test=0.907/0.889/0.856 | c=0.998347
[Epoch 0074] loss=9.9554 cls=0.3658 smmd=0.0026 ct=7.1198 rec=1.2049 | train/val/test=0.908/0.891/0.858 | c=0.998347
[Epoch 0075] loss=9.9528 cls=0.3634 smmd=0.0040 ct=7.1192 rec=1.2044 | train/val/test=0.908/0.893/0.860 | c=0.998347
[Epoch 0076] loss=9.9355 cls=0.3613 smmd=-0.0026 ct=7.1194 rec=1.2040 | train/val/test=0.909/0.893/0.862 | c=0.998347
[Epoch 0077] loss=9.9186 cls=0.3594 smmd=-0.0094 ct=7.1196 rec=1.2036 | train/val/test=0.909/0.893/0.862 | c=0.998347
[Epoch 0078] loss=9.9117 cls=0.3578 smmd=-0.0107 ct=7.1183 rec=1.2032 | train/val/test=0.909/0.893/0.862 | c=0.998347
[Epoch 0079] loss=9.9149 cls=0.3557 smmd=-0.0065 ct=7.1162 rec=1.2028 | train/val/test=0.909/0.893/0.862 | c=0.998347
[Epoch 0080] loss=9.9047 cls=0.3544 smmd=-0.0096 ct=7.1160 rec=1.2023 | train/val/test=0.910/0.893/0.862 | c=0.998347
[Epoch 0081] loss=9.8968 cls=0.3532 smmd=-0.0115 ct=7.1161 rec=1.2017 | train/val/test=0.910/0.893/0.862 | c=0.998347
[Epoch 0082] loss=9.8941 cls=0.3520 smmd=-0.0106 ct=7.1149 rec=1.2012 | train/val/test=0.909/0.895/0.862 | c=0.998347
[Epoch 0083] loss=9.8881 cls=0.3505 smmd=-0.0118 ct=7.1139 rec=1.2009 | train/val/test=0.910/0.895/0.862 | c=0.998347
[Epoch 0084] loss=9.8783 cls=0.3492 smmd=-0.0155 ct=7.1142 rec=1.2006 | train/val/test=0.909/0.895/0.862 | c=0.998347
[Epoch 0085] loss=9.8835 cls=0.3480 smmd=-0.0113 ct=7.1139 rec=1.2002 | train/val/test=0.909/0.893/0.860 | c=0.998347
[Epoch 0086] loss=9.8757 cls=0.3474 smmd=-0.0139 ct=7.1134 rec=1.1999 | train/val/test=0.910/0.893/0.862 | c=0.998347
[Epoch 0087] loss=9.8765 cls=0.3455 smmd=-0.0114 ct=7.1106 rec=1.1997 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0088] loss=9.8757 cls=0.3452 smmd=-0.0105 ct=7.1100 rec=1.1993 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0089] loss=9.8690 cls=0.3448 smmd=-0.0131 ct=7.1106 rec=1.1990 | train/val/test=0.911/0.893/0.862 | c=0.998347
[Epoch 0090] loss=9.8732 cls=0.3437 smmd=-0.0104 ct=7.1103 rec=1.1990 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0091] loss=9.8561 cls=0.3437 smmd=-0.0186 ct=7.1100 rec=1.1989 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0092] loss=9.8568 cls=0.3439 smmd=-0.0178 ct=7.1088 rec=1.1988 | train/val/test=0.911/0.893/0.862 | c=0.998347
[Epoch 0093] loss=9.8701 cls=0.3438 smmd=-0.0110 ct=7.1086 rec=1.1988 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0094] loss=9.8632 cls=0.3446 smmd=-0.0152 ct=7.1098 rec=1.1988 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0095] loss=9.8589 cls=0.3438 smmd=-0.0177 ct=7.1097 rec=1.1991 | train/val/test=0.911/0.891/0.858 | c=0.998347
[Epoch 0096] loss=9.8605 cls=0.3438 smmd=-0.0172 ct=7.1096 rec=1.1993 | train/val/test=0.910/0.891/0.860 | c=0.998347
[Epoch 0097] loss=9.8631 cls=0.3434 smmd=-0.0156 ct=7.1081 rec=1.1994 | train/val/test=0.910/0.891/0.860 | c=0.998347
[Epoch 0098] loss=9.8550 cls=0.3433 smmd=-0.0193 ct=7.1076 rec=1.1993 | train/val/test=0.910/0.891/0.860 | c=0.998347
[Epoch 0099] loss=9.8595 cls=0.3429 smmd=-0.0163 ct=7.1079 rec=1.1990 | train/val/test=0.910/0.891/0.858 | c=0.998347
[Epoch 0100] loss=9.8554 cls=0.3427 smmd=-0.0176 ct=7.1081 rec=1.1987 | train/val/test=0.910/0.891/0.860 | c=0.998347
[Epoch 0101] loss=9.8482 cls=0.3419 smmd=-0.0201 ct=7.1076 rec=1.1985 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0102] loss=9.8455 cls=0.3411 smmd=-0.0206 ct=7.1072 rec=1.1984 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0103] loss=9.8458 cls=0.3405 smmd=-0.0195 ct=7.1065 rec=1.1982 | train/val/test=0.910/0.895/0.860 | c=0.998347
[Epoch 0104] loss=9.8481 cls=0.3409 smmd=-0.0180 ct=7.1068 rec=1.1980 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0105] loss=9.8468 cls=0.3402 smmd=-0.0186 ct=7.1071 rec=1.1980 | train/val/test=0.911/0.893/0.860 | c=0.998347
[Epoch 0106] loss=9.8379 cls=0.3399 smmd=-0.0227 ct=7.1058 rec=1.1981 | train/val/test=0.910/0.891/0.860 | c=0.998347
[Epoch 0107] loss=9.8368 cls=0.3405 smmd=-0.0233 ct=7.1054 rec=1.1980 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0108] loss=9.8385 cls=0.3405 smmd=-0.0225 ct=7.1053 rec=1.1980 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0109] loss=9.8403 cls=0.3400 smmd=-0.0217 ct=7.1057 rec=1.1982 | train/val/test=0.910/0.893/0.860 | c=0.998347
[Epoch 0110] loss=9.8370 cls=0.3398 smmd=-0.0233 ct=7.1060 rec=1.1981 | train/val/test=0.911/0.891/0.858 | c=0.998347
[Epoch 0111] loss=9.8363 cls=0.3405 smmd=-0.0232 ct=7.1054 rec=1.1979 | train/val/test=0.911/0.893/0.858 | c=0.998347
[Epoch 0112] loss=9.8421 cls=0.3400 smmd=-0.0196 ct=7.1040 rec=1.1979 | train/val/test=0.909/0.893/0.858 | c=0.998347
[Epoch 0113] loss=9.8431 cls=0.3396 smmd=-0.0186 ct=7.1030 rec=1.1978 | train/val/test=0.910/0.891/0.858 | c=0.998347
[Epoch 0114] loss=9.8308 cls=0.3400 smmd=-0.0250 ct=7.1037 rec=1.1978 | train/val/test=0.910/0.891/0.858 | c=0.998347
[Epoch 0115] loss=9.8419 cls=0.3392 smmd=-0.0192 ct=7.1040 rec=1.1978 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0116] loss=9.8386 cls=0.3394 smmd=-0.0207 ct=7.1035 rec=1.1978 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0117] loss=9.8221 cls=0.3402 smmd=-0.0290 ct=7.1032 rec=1.1977 | train/val/test=0.909/0.895/0.858 | c=0.998347
[Epoch 0118] loss=9.8461 cls=0.3391 smmd=-0.0165 ct=7.1017 rec=1.1978 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0119] loss=9.8304 cls=0.3390 smmd=-0.0245 ct=7.1023 rec=1.1978 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0120] loss=9.8317 cls=0.3393 smmd=-0.0240 ct=7.1034 rec=1.1977 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0121] loss=9.8343 cls=0.3388 smmd=-0.0220 ct=7.1025 rec=1.1976 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0122] loss=9.8311 cls=0.3381 smmd=-0.0225 ct=7.1013 rec=1.1975 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0123] loss=9.8229 cls=0.3380 smmd=-0.0261 ct=7.1011 rec=1.1973 | train/val/test=0.908/0.893/0.856 | c=0.998347
[Epoch 0124] loss=9.8203 cls=0.3386 smmd=-0.0273 ct=7.1021 rec=1.1971 | train/val/test=0.910/0.895/0.856 | c=0.998347
[Epoch 0125] loss=9.8243 cls=0.3371 smmd=-0.0244 ct=7.1010 rec=1.1971 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0126] loss=9.8308 cls=0.3372 smmd=-0.0210 ct=7.1008 rec=1.1970 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0127] loss=9.8269 cls=0.3381 smmd=-0.0229 ct=7.1011 rec=1.1968 | train/val/test=0.910/0.895/0.856 | c=0.998347
[Epoch 0128] loss=9.8254 cls=0.3380 smmd=-0.0238 ct=7.1005 rec=1.1970 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0129] loss=9.8318 cls=0.3375 smmd=-0.0211 ct=7.1002 rec=1.1973 | train/val/test=0.910/0.895/0.858 | c=0.998347
[Epoch 0130] loss=9.8214 cls=0.3373 smmd=-0.0266 ct=7.1000 rec=1.1975 | train/val/test=0.911/0.889/0.856 | c=0.998347
[Epoch 0131] loss=9.8313 cls=0.3382 smmd=-0.0219 ct=7.1000 rec=1.1974 | train/val/test=0.911/0.895/0.856 | c=0.998347
[Epoch 0132] loss=9.8195 cls=0.3380 smmd=-0.0281 ct=7.1006 rec=1.1975 | train/val/test=0.909/0.895/0.854 | c=0.998347
[Epoch 0133] loss=9.8202 cls=0.3375 smmd=-0.0275 ct=7.1002 rec=1.1975 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0134] loss=9.8201 cls=0.3376 smmd=-0.0269 ct=7.0990 rec=1.1974 | train/val/test=0.909/0.889/0.856 | c=0.998347
[Epoch 0135] loss=9.8128 cls=0.3382 smmd=-0.0302 ct=7.0992 rec=1.1971 | train/val/test=0.910/0.891/0.856 | c=0.998347
[Epoch 0136] loss=9.8252 cls=0.3375 smmd=-0.0233 ct=7.0991 rec=1.1970 | train/val/test=0.909/0.895/0.854 | c=0.998347
[Epoch 0137] loss=9.8123 cls=0.3370 smmd=-0.0293 ct=7.0983 rec=1.1969 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0138] loss=9.8280 cls=0.3365 smmd=-0.0207 ct=7.0976 rec=1.1968 | train/val/test=0.908/0.891/0.856 | c=0.998347
[Epoch 0139] loss=9.8115 cls=0.3374 smmd=-0.0293 ct=7.0990 rec=1.1967 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0140] loss=9.8114 cls=0.3375 smmd=-0.0300 ct=7.0999 rec=1.1968 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0141] loss=9.8123 cls=0.3361 smmd=-0.0293 ct=7.0979 rec=1.1972 | train/val/test=0.910/0.889/0.856 | c=0.998347
[Epoch 0142] loss=9.8170 cls=0.3363 smmd=-0.0264 ct=7.0961 rec=1.1971 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0143] loss=9.8157 cls=0.3373 smmd=-0.0270 ct=7.0970 rec=1.1968 | train/val/test=0.910/0.893/0.856 | c=0.998347
[Epoch 0144] loss=9.8160 cls=0.3368 smmd=-0.0267 ct=7.0981 rec=1.1967 | train/val/test=0.910/0.893/0.854 | c=0.998347
[Epoch 0145] loss=9.8122 cls=0.3356 smmd=-0.0281 ct=7.0976 rec=1.1968 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0146] loss=9.8153 cls=0.3356 smmd=-0.0260 ct=7.0967 rec=1.1967 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0147] loss=9.8145 cls=0.3363 smmd=-0.0261 ct=7.0962 rec=1.1965 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0148] loss=9.8158 cls=0.3368 smmd=-0.0256 ct=7.0967 rec=1.1964 | train/val/test=0.909/0.891/0.854 | c=0.998347
[Epoch 0149] loss=9.8209 cls=0.3358 smmd=-0.0234 ct=7.0970 rec=1.1967 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0150] loss=9.8088 cls=0.3362 smmd=-0.0300 ct=7.0975 rec=1.1968 | train/val/test=0.909/0.891/0.854 | c=0.998347
[Epoch 0151] loss=9.8175 cls=0.3370 smmd=-0.0260 ct=7.0976 rec=1.1968 | train/val/test=0.909/0.891/0.854 | c=0.998347
[Epoch 0152] loss=9.8179 cls=0.3371 smmd=-0.0256 ct=7.0962 rec=1.1968 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0153] loss=9.8113 cls=0.3361 smmd=-0.0288 ct=7.0955 rec=1.1970 | train/val/test=0.906/0.893/0.854 | c=0.998347
[Epoch 0154] loss=9.8117 cls=0.3361 smmd=-0.0284 ct=7.0962 rec=1.1969 | train/val/test=0.906/0.891/0.854 | c=0.998347
[Epoch 0155] loss=9.8081 cls=0.3365 smmd=-0.0298 ct=7.0963 rec=1.1966 | train/val/test=0.909/0.891/0.854 | c=0.998347
[Epoch 0156] loss=9.8071 cls=0.3362 smmd=-0.0293 ct=7.0950 rec=1.1964 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0157] loss=9.8067 cls=0.3352 smmd=-0.0286 ct=7.0941 rec=1.1963 | train/val/test=0.910/0.895/0.856 | c=0.998347
[Epoch 0158] loss=9.8042 cls=0.3350 smmd=-0.0296 ct=7.0948 rec=1.1962 | train/val/test=0.906/0.893/0.856 | c=0.998347
[Epoch 0159] loss=9.8044 cls=0.3355 smmd=-0.0295 ct=7.0958 rec=1.1960 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0160] loss=9.8149 cls=0.3353 smmd=-0.0239 ct=7.0945 rec=1.1960 | train/val/test=0.909/0.897/0.856 | c=0.998347
[Epoch 0161] loss=9.8105 cls=0.3346 smmd=-0.0261 ct=7.0933 rec=1.1963 | train/val/test=0.910/0.895/0.856 | c=0.998347
[Epoch 0162] loss=9.8041 cls=0.3346 smmd=-0.0296 ct=7.0937 rec=1.1964 | train/val/test=0.906/0.893/0.856 | c=0.998347
[Epoch 0163] loss=9.8147 cls=0.3356 smmd=-0.0248 ct=7.0953 rec=1.1962 | train/val/test=0.907/0.893/0.856 | c=0.998347
[Epoch 0164] loss=9.8191 cls=0.3357 smmd=-0.0228 ct=7.0953 rec=1.1963 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0165] loss=9.8088 cls=0.3358 smmd=-0.0283 ct=7.0949 rec=1.1964 | train/val/test=0.911/0.897/0.858 | c=0.998347
[Epoch 0166] loss=9.8129 cls=0.3349 smmd=-0.0262 ct=7.0936 rec=1.1967 | train/val/test=0.910/0.897/0.858 | c=0.998347
[Epoch 0167] loss=9.8092 cls=0.3352 smmd=-0.0282 ct=7.0940 rec=1.1967 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0168] loss=9.8047 cls=0.3369 smmd=-0.0306 ct=7.0945 rec=1.1963 | train/val/test=0.909/0.893/0.858 | c=0.998347
[Epoch 0169] loss=9.8054 cls=0.3357 smmd=-0.0298 ct=7.0944 rec=1.1964 | train/val/test=0.911/0.897/0.860 | c=0.998347
[Epoch 0170] loss=9.8130 cls=0.3346 smmd=-0.0256 ct=7.0939 rec=1.1966 | train/val/test=0.910/0.893/0.856 | c=0.998347
[Epoch 0171] loss=9.8066 cls=0.3352 smmd=-0.0285 ct=7.0937 rec=1.1963 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0172] loss=9.8047 cls=0.3358 smmd=-0.0293 ct=7.0941 rec=1.1961 | train/val/test=0.910/0.893/0.856 | c=0.998347
[Epoch 0173] loss=9.8063 cls=0.3350 smmd=-0.0285 ct=7.0938 rec=1.1963 | train/val/test=0.911/0.895/0.858 | c=0.998347
[Epoch 0174] loss=9.8083 cls=0.3349 smmd=-0.0275 ct=7.0932 rec=1.1964 | train/val/test=0.909/0.893/0.856 | c=0.998347
[Epoch 0175] loss=9.8071 cls=0.3363 smmd=-0.0285 ct=7.0936 rec=1.1962 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0176] loss=9.8050 cls=0.3367 smmd=-0.0302 ct=7.0942 rec=1.1963 | train/val/test=0.911/0.895/0.856 | c=0.998347
[Epoch 0177] loss=9.7977 cls=0.3353 smmd=-0.0341 ct=7.0942 rec=1.1967 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0178] loss=9.8006 cls=0.3349 smmd=-0.0321 ct=7.0932 rec=1.1967 | train/val/test=0.909/0.893/0.854 | c=0.998347
[Epoch 0179] loss=9.8080 cls=0.3365 smmd=-0.0280 ct=7.0933 rec=1.1962 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0180] loss=9.8018 cls=0.3352 smmd=-0.0305 ct=7.0930 rec=1.1962 | train/val/test=0.910/0.895/0.858 | c=0.998347
[Epoch 0181] loss=9.8107 cls=0.3340 smmd=-0.0260 ct=7.0928 rec=1.1965 | train/val/test=0.906/0.895/0.856 | c=0.998347
[Epoch 0182] loss=9.8073 cls=0.3355 smmd=-0.0280 ct=7.0940 rec=1.1962 | train/val/test=0.906/0.893/0.854 | c=0.998347
[Epoch 0183] loss=9.8058 cls=0.3369 smmd=-0.0293 ct=7.0944 rec=1.1961 | train/val/test=0.908/0.893/0.858 | c=0.998347
[Epoch 0184] loss=9.8012 cls=0.3350 smmd=-0.0312 ct=7.0921 rec=1.1965 | train/val/test=0.909/0.893/0.858 | c=0.998347
[Epoch 0185] loss=9.8083 cls=0.3343 smmd=-0.0275 ct=7.0912 rec=1.1967 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0186] loss=9.7967 cls=0.3364 smmd=-0.0336 ct=7.0929 rec=1.1962 | train/val/test=0.906/0.895/0.856 | c=0.998347
[Epoch 0187] loss=9.8019 cls=0.3362 smmd=-0.0308 ct=7.0937 rec=1.1961 | train/val/test=0.908/0.893/0.858 | c=0.998347
[Epoch 0188] loss=9.7917 cls=0.3340 smmd=-0.0352 ct=7.0924 rec=1.1964 | train/val/test=0.909/0.893/0.858 | c=0.998347
[Epoch 0189] loss=9.8021 cls=0.3340 smmd=-0.0289 ct=7.0914 rec=1.1961 | train/val/test=0.906/0.895/0.856 | c=0.998347
[Epoch 0190] loss=9.8099 cls=0.3356 smmd=-0.0248 ct=7.0921 rec=1.1956 | train/val/test=0.906/0.895/0.858 | c=0.998347
[Epoch 0191] loss=9.7989 cls=0.3347 smmd=-0.0301 ct=7.0921 rec=1.1956 | train/val/test=0.906/0.893/0.858 | c=0.998347
[Epoch 0192] loss=9.8071 cls=0.3339 smmd=-0.0258 ct=7.0912 rec=1.1958 | train/val/test=0.905/0.893/0.856 | c=0.998347
[Epoch 0193] loss=9.7964 cls=0.3349 smmd=-0.0316 ct=7.0912 rec=1.1958 | train/val/test=0.906/0.895/0.856 | c=0.998347
[Epoch 0194] loss=9.8040 cls=0.3355 smmd=-0.0284 ct=7.0914 rec=1.1959 | train/val/test=0.908/0.893/0.858 | c=0.998347
[Epoch 0195] loss=9.8066 cls=0.3341 smmd=-0.0271 ct=7.0910 rec=1.1962 | train/val/test=0.907/0.895/0.856 | c=0.998347
[Epoch 0196] loss=9.8033 cls=0.3350 smmd=-0.0289 ct=7.0916 rec=1.1961 | train/val/test=0.906/0.893/0.856 | c=0.998347
[Epoch 0197] loss=9.7988 cls=0.3359 smmd=-0.0314 ct=7.0918 rec=1.1959 | train/val/test=0.909/0.895/0.856 | c=0.998347
[Epoch 0198] loss=9.8039 cls=0.3348 smmd=-0.0288 ct=7.0917 rec=1.1962 | train/val/test=0.908/0.893/0.860 | c=0.998347
[Epoch 0199] loss=9.8039 cls=0.3341 smmd=-0.0287 ct=7.0918 rec=1.1963 | train/val/test=0.908/0.893/0.858 | c=0.998347
=== Best @ epoch 160: val=0.8967, test=0.8561 ===

Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3 completed in 44.44 seconds.
==================================================
