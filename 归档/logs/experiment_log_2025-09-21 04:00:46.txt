Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-4 - 2025-09-21 04:00:46:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-4...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=40.3390 cls=1.0943 smmd=5.6743 ct=11.2789 rec=1.4136 | train/val/test=0.654/0.446/0.430 | c=0.998437
[Epoch 0001] loss=29.6487 cls=1.0754 smmd=3.5463 ct=11.2383 rec=1.4136 | train/val/test=0.500/0.276/0.264 | c=0.998437
[Epoch 0002] loss=36.1038 cls=1.0487 smmd=4.8379 ct=11.2485 rec=1.4136 | train/val/test=0.615/0.488/0.481 | c=0.998437
[Epoch 0003] loss=35.3997 cls=0.9932 smmd=4.7107 ct=11.2082 rec=1.4139 | train/val/test=0.808/0.614/0.606 | c=0.998437
[Epoch 0004] loss=26.3740 cls=0.8847 smmd=2.9476 ct=11.0524 rec=1.4105 | train/val/test=0.846/0.700/0.666 | c=0.998437
[Epoch 0005] loss=25.6164 cls=0.7570 smmd=2.8134 ct=11.0306 rec=1.4032 | train/val/test=0.846/0.716/0.679 | c=0.998437
[Epoch 0006] loss=27.9109 cls=0.6317 smmd=3.2935 ct=10.9885 rec=1.3910 | train/val/test=0.846/0.748/0.717 | c=0.998437
[Epoch 0007] loss=27.2634 cls=0.5029 smmd=3.0722 ct=11.5139 rec=1.3717 | train/val/test=0.885/0.804/0.743 | c=0.998437
[Epoch 0008] loss=23.2606 cls=0.3968 smmd=2.3108 ct=11.3729 rec=1.3552 | train/val/test=0.885/0.810/0.752 | c=0.998437
[Epoch 0009] loss=22.2235 cls=0.3153 smmd=2.1097 ct=11.3831 rec=1.3426 | train/val/test=1.000/0.810/0.749 | c=0.998437
[Epoch 0010] loss=24.2792 cls=0.2606 smmd=2.5094 ct=11.4685 rec=1.3363 | train/val/test=1.000/0.790/0.747 | c=0.998437
[Epoch 0011] loss=23.6201 cls=0.2146 smmd=2.3773 ct=11.4931 rec=1.3327 | train/val/test=1.000/0.796/0.764 | c=0.998437
[Epoch 0012] loss=20.2753 cls=0.1773 smmd=1.7129 ct=11.4886 rec=1.3345 | train/val/test=1.000/0.796/0.766 | c=0.998437
[Epoch 0013] loss=22.9967 cls=0.1593 smmd=2.2719 ct=11.4240 rec=1.3347 | train/val/test=1.000/0.796/0.764 | c=0.998437
[Epoch 0014] loss=22.6003 cls=0.1240 smmd=2.1979 ct=11.4161 rec=1.3257 | train/val/test=1.000/0.796/0.763 | c=0.998437
[Epoch 0015] loss=19.7360 cls=0.0851 smmd=1.6225 ct=11.4498 rec=1.3101 | train/val/test=1.000/0.804/0.764 | c=0.998437
[Epoch 0016] loss=19.9241 cls=0.0697 smmd=1.6580 ct=11.4688 rec=1.3031 | train/val/test=1.000/0.798/0.749 | c=0.998437
[Epoch 0017] loss=20.3120 cls=0.0551 smmd=1.7387 ct=11.4609 rec=1.3004 | train/val/test=1.000/0.804/0.774 | c=0.998437
[Epoch 0018] loss=18.6134 cls=0.0471 smmd=1.4072 ct=11.4246 rec=1.2914 | train/val/test=1.000/0.806/0.761 | c=0.998437
[Epoch 0019] loss=18.2712 cls=0.0546 smmd=1.3426 ct=11.4017 rec=1.2929 | train/val/test=1.000/0.808/0.776 | c=0.998437
[Epoch 0020] loss=18.3697 cls=0.0567 smmd=1.3588 ct=11.4178 rec=1.2970 | train/val/test=1.000/0.804/0.760 | c=0.998437
[Epoch 0021] loss=18.1674 cls=0.0721 smmd=1.3052 ct=11.4753 rec=1.3010 | train/val/test=1.000/0.796/0.756 | c=0.998437
[Epoch 0022] loss=17.6301 cls=0.0901 smmd=1.2012 ct=11.4481 rec=1.3085 | train/val/test=1.000/0.784/0.731 | c=0.998437
[Epoch 0023] loss=18.4420 cls=0.1103 smmd=1.3614 ct=11.4476 rec=1.3210 | train/val/test=1.000/0.800/0.754 | c=0.998437
[Epoch 0024] loss=17.4198 cls=0.0987 smmd=1.1493 ct=11.4932 rec=1.3070 | train/val/test=1.000/0.814/0.774 | c=0.998437
[Epoch 0025] loss=17.5538 cls=0.0887 smmd=1.1890 ct=11.4334 rec=1.3122 | train/val/test=1.000/0.786/0.762 | c=0.998437
[Epoch 0026] loss=16.5842 cls=0.0785 smmd=0.9936 ct=11.4468 rec=1.3020 | train/val/test=1.000/0.812/0.773 | c=0.998437
[Epoch 0027] loss=16.5772 cls=0.0709 smmd=0.9984 ct=11.4205 rec=1.2941 | train/val/test=1.000/0.812/0.784 | c=0.998437
[Epoch 0028] loss=15.9809 cls=0.0543 smmd=0.8847 ct=11.4011 rec=1.2923 | train/val/test=1.000/0.818/0.789 | c=0.998437
[Epoch 0029] loss=15.8892 cls=0.0519 smmd=0.8592 ct=11.4381 rec=1.2935 | train/val/test=1.000/0.820/0.778 | c=0.998437
[Epoch 0030] loss=15.7468 cls=0.0547 smmd=0.8290 ct=11.4447 rec=1.2952 | train/val/test=1.000/0.814/0.777 | c=0.998437
[Epoch 0031] loss=15.6567 cls=0.0634 smmd=0.8202 ct=11.3933 rec=1.3048 | train/val/test=1.000/0.790/0.755 | c=0.998437
[Epoch 0032] loss=15.9113 cls=0.0785 smmd=0.8587 ct=11.4469 rec=1.3149 | train/val/test=1.000/0.792/0.742 | c=0.998437
[Epoch 0033] loss=16.0462 cls=0.0851 smmd=0.8812 ct=11.4656 rec=1.3206 | train/val/test=1.000/0.766/0.747 | c=0.998437
[Epoch 0034] loss=15.6208 cls=0.0926 smmd=0.7979 ct=11.4527 rec=1.3238 | train/val/test=1.000/0.756/0.727 | c=0.998437
[Epoch 0035] loss=15.8817 cls=0.0843 smmd=0.8505 ct=11.4547 rec=1.3226 | train/val/test=1.000/0.770/0.753 | c=0.998437
[Epoch 0036] loss=14.6935 cls=0.0779 smmd=0.6216 ct=11.4154 rec=1.3135 | train/val/test=1.000/0.820/0.770 | c=0.998437
[Epoch 0037] loss=15.4374 cls=0.0564 smmd=0.7732 ct=11.4130 rec=1.3033 | train/val/test=1.000/0.798/0.779 | c=0.998437
[Epoch 0038] loss=14.4360 cls=0.0604 smmd=0.5686 ct=11.4325 rec=1.3019 | train/val/test=1.000/0.816/0.769 | c=0.998437
[Epoch 0039] loss=14.7734 cls=0.0586 smmd=0.6408 ct=11.4097 rec=1.3047 | train/val/test=1.000/0.798/0.775 | c=0.998437
[Epoch 0040] loss=14.6046 cls=0.0688 smmd=0.6087 ct=11.3961 rec=1.3069 | train/val/test=1.000/0.822/0.770 | c=0.998437
[Epoch 0041] loss=14.7206 cls=0.0744 smmd=0.6224 ct=11.4397 rec=1.3148 | train/val/test=1.000/0.776/0.762 | c=0.998437
[Epoch 0042] loss=14.8921 cls=0.0926 smmd=0.6533 ct=11.4468 rec=1.3233 | train/val/test=1.000/0.772/0.733 | c=0.998437
[Epoch 0043] loss=15.0689 cls=0.1029 smmd=0.6941 ct=11.4138 rec=1.3291 | train/val/test=1.000/0.758/0.732 | c=0.998437
[Epoch 0044] loss=15.2093 cls=0.1133 smmd=0.7094 ct=11.4719 rec=1.3367 | train/val/test=1.000/0.728/0.695 | c=0.998437
[Epoch 0045] loss=14.8135 cls=0.1177 smmd=0.6357 ct=11.4424 rec=1.3361 | train/val/test=1.000/0.748/0.725 | c=0.998437
[Epoch 0046] loss=14.5587 cls=0.1068 smmd=0.5871 ct=11.4365 rec=1.3325 | train/val/test=1.000/0.752/0.708 | c=0.998437
[Epoch 0047] loss=14.4617 cls=0.0967 smmd=0.5694 ct=11.4336 rec=1.3248 | train/val/test=1.000/0.786/0.760 | c=0.998437
[Epoch 0048] loss=14.1716 cls=0.0791 smmd=0.5200 ct=11.4010 rec=1.3127 | train/val/test=1.000/0.818/0.772 | c=0.998437
[Epoch 0049] loss=14.1817 cls=0.0740 smmd=0.5195 ct=11.4161 rec=1.3137 | train/val/test=1.000/0.812/0.778 | c=0.998437
[Epoch 0050] loss=14.1444 cls=0.0789 smmd=0.5114 ct=11.4166 rec=1.3132 | train/val/test=1.000/0.824/0.772 | c=0.998437
[Epoch 0051] loss=14.2942 cls=0.0868 smmd=0.5435 ct=11.4013 rec=1.3219 | train/val/test=1.000/0.780/0.769 | c=0.998437
[Epoch 0052] loss=14.5093 cls=0.0998 smmd=0.5755 ct=11.4489 rec=1.3284 | train/val/test=1.000/0.776/0.742 | c=0.998437
[Epoch 0053] loss=14.7066 cls=0.1096 smmd=0.6174 ct=11.4311 rec=1.3354 | train/val/test=1.000/0.750/0.740 | c=0.998437
[Epoch 0054] loss=14.6704 cls=0.1159 smmd=0.6090 ct=11.4335 rec=1.3402 | train/val/test=1.000/0.754/0.724 | c=0.998437
[Epoch 0055] loss=14.1861 cls=0.1054 smmd=0.5135 ct=11.4326 rec=1.3351 | train/val/test=1.000/0.766/0.740 | c=0.998437
[Epoch 0056] loss=14.1358 cls=0.0999 smmd=0.5059 ct=11.4234 rec=1.3313 | train/val/test=1.000/0.764/0.730 | c=0.998437
[Epoch 0057] loss=13.8370 cls=0.0932 smmd=0.4526 ct=11.3940 rec=1.3317 | train/val/test=1.000/0.762/0.735 | c=0.998437
[Epoch 0058] loss=13.8355 cls=0.0995 smmd=0.4451 ct=11.4269 rec=1.3316 | train/val/test=1.000/0.746/0.708 | c=0.998437
[Epoch 0059] loss=13.8640 cls=0.1019 smmd=0.4512 ct=11.4235 rec=1.3366 | train/val/test=1.000/0.752/0.739 | c=0.998437
[Epoch 0060] loss=14.1120 cls=0.1107 smmd=0.5002 ct=11.4215 rec=1.3409 | train/val/test=1.000/0.712/0.683 | c=0.998437
[Epoch 0061] loss=14.3522 cls=0.1235 smmd=0.5403 ct=11.4545 rec=1.3455 | train/val/test=1.000/0.706/0.698 | c=0.998437
[Epoch 0062] loss=14.4397 cls=0.1489 smmd=0.5500 ct=11.4791 rec=1.3629 | train/val/test=1.000/0.648/0.621 | c=0.998437
[Epoch 0063] loss=14.6154 cls=0.1529 smmd=0.5864 ct=11.4714 rec=1.3549 | train/val/test=1.000/0.704/0.692 | c=0.998437
[Epoch 0064] loss=14.4178 cls=0.1351 smmd=0.5497 ct=11.4657 rec=1.3586 | train/val/test=1.000/0.738/0.705 | c=0.998437
[Epoch 0065] loss=13.6576 cls=0.0810 smmd=0.4096 ct=11.4361 rec=1.3289 | train/val/test=1.000/0.804/0.771 | c=0.998437
[Epoch 0066] loss=13.8680 cls=0.0590 smmd=0.4652 ct=11.3816 rec=1.3095 | train/val/test=1.000/0.818/0.781 | c=0.998437
[Epoch 0067] loss=13.4893 cls=0.0559 smmd=0.3877 ct=11.3921 rec=1.3092 | train/val/test=1.000/0.812/0.762 | c=0.998437
[Epoch 0068] loss=13.3116 cls=0.0622 smmd=0.3474 ct=11.4119 rec=1.3159 | train/val/test=1.000/0.806/0.762 | c=0.998437
[Epoch 0069] loss=13.8652 cls=0.0739 smmd=0.4622 ct=11.3850 rec=1.3248 | train/val/test=1.000/0.804/0.762 | c=0.998437
[Epoch 0070] loss=14.1658 cls=0.0892 smmd=0.5099 ct=11.4382 rec=1.3346 | train/val/test=1.000/0.782/0.738 | c=0.998437
[Epoch 0071] loss=14.4393 cls=0.1021 smmd=0.5687 ct=11.4108 rec=1.3408 | train/val/test=1.000/0.778/0.733 | c=0.998437
[Epoch 0072] loss=14.5845 cls=0.1083 smmd=0.5961 ct=11.4154 rec=1.3432 | train/val/test=1.000/0.786/0.748 | c=0.998437
[Epoch 0073] loss=14.1335 cls=0.1023 smmd=0.5054 ct=11.4215 rec=1.3396 | train/val/test=1.000/0.748/0.709 | c=0.998437
[Epoch 0074] loss=13.6128 cls=0.1041 smmd=0.4089 ct=11.3823 rec=1.3385 | train/val/test=1.000/0.784/0.764 | c=0.998437
[Epoch 0075] loss=13.5264 cls=0.0946 smmd=0.3901 ct=11.3952 rec=1.3341 | train/val/test=1.000/0.744/0.706 | c=0.998437
[Epoch 0076] loss=13.4035 cls=0.1055 smmd=0.3646 ct=11.3940 rec=1.3383 | train/val/test=1.000/0.764/0.737 | c=0.998437
[Epoch 0077] loss=13.5108 cls=0.1219 smmd=0.3810 ct=11.4108 rec=1.3430 | train/val/test=1.000/0.622/0.607 | c=0.998437
[Epoch 0078] loss=14.0387 cls=0.1709 smmd=0.4696 ct=11.4685 rec=1.3661 | train/val/test=0.846/0.588/0.585 | c=0.998437
[Epoch 0079] loss=14.8786 cls=0.3252 smmd=0.6041 ct=11.5531 rec=1.4225 | train/val/test=0.808/0.544/0.534 | c=0.998437
[Epoch 0080] loss=15.3873 cls=0.3675 smmd=0.6896 ct=11.6154 rec=1.4016 | train/val/test=0.885/0.618/0.629 | c=0.998437
[Epoch 0081] loss=14.6695 cls=0.2699 smmd=0.5711 ct=11.5383 rec=1.4093 | train/val/test=1.000/0.762/0.732 | c=0.998437
[Epoch 0082] loss=13.6239 cls=0.0542 smmd=0.4063 ct=11.4340 rec=1.3157 | train/val/test=1.000/0.780/0.733 | c=0.998437
[Epoch 0083] loss=13.6337 cls=0.0453 smmd=0.4149 ct=11.4053 rec=1.3111 | train/val/test=1.000/0.764/0.738 | c=0.998437
[Epoch 0084] loss=13.4122 cls=0.0600 smmd=0.3639 ct=11.4317 rec=1.3082 | train/val/test=1.000/0.812/0.763 | c=0.998437
[Epoch 0085] loss=13.2053 cls=0.0390 smmd=0.3250 ct=11.4307 rec=1.3012 | train/val/test=1.000/0.764/0.727 | c=0.998437
[Epoch 0086] loss=13.8169 cls=0.0549 smmd=0.4486 ct=11.4145 rec=1.3209 | train/val/test=1.000/0.762/0.745 | c=0.998437
[Epoch 0087] loss=13.8261 cls=0.0692 smmd=0.4403 ct=11.4568 rec=1.3306 | train/val/test=1.000/0.744/0.695 | c=0.998437
[Epoch 0088] loss=14.0447 cls=0.0909 smmd=0.4811 ct=11.4595 rec=1.3420 | train/val/test=1.000/0.722/0.686 | c=0.998437
[Epoch 0089] loss=15.2945 cls=0.1157 smmd=0.7366 ct=11.4181 rec=1.3555 | train/val/test=0.962/0.656/0.633 | c=0.998437
[Epoch 0090] loss=14.6140 cls=0.1514 smmd=0.5762 ct=11.5213 rec=1.3595 | train/val/test=1.000/0.630/0.617 | c=0.998437
[Epoch 0091] loss=13.8101 cls=0.1575 smmd=0.4330 ct=11.4303 rec=1.3585 | train/val/test=1.000/0.728/0.698 | c=0.998437
[Epoch 0092] loss=13.7861 cls=0.1080 smmd=0.4391 ct=11.4025 rec=1.3410 | train/val/test=1.000/0.720/0.682 | c=0.998437
[Epoch 0093] loss=13.2685 cls=0.1077 smmd=0.3389 ct=11.3862 rec=1.3375 | train/val/test=1.000/0.746/0.699 | c=0.998437
[Epoch 0094] loss=13.2707 cls=0.1075 smmd=0.3373 ct=11.3966 rec=1.3370 | train/val/test=1.000/0.774/0.751 | c=0.998437
[Epoch 0095] loss=13.2513 cls=0.1109 smmd=0.3375 ct=11.3747 rec=1.3387 | train/val/test=1.000/0.684/0.653 | c=0.998437
[Epoch 0096] loss=13.5423 cls=0.1513 smmd=0.3794 ct=11.4341 rec=1.3541 | train/val/test=0.923/0.652/0.647 | c=0.998437
[Epoch 0097] loss=14.7858 cls=0.2417 smmd=0.5985 ct=11.5348 rec=1.3779 | train/val/test=0.769/0.498/0.488 | c=0.998437
[Epoch 0098] loss=15.9870 cls=0.4321 smmd=0.8008 ct=11.6215 rec=1.4544 | train/val/test=0.808/0.528/0.552 | c=0.998437
[Epoch 0099] loss=15.8259 cls=0.4878 smmd=0.7615 ct=11.6304 rec=1.4421 | train/val/test=1.000/0.604/0.599 | c=0.998437
=== Best @ epoch 50: val=0.8240, test=0.7720 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-4 - 2025-09-21 04:00:46:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-4...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=40.3390 cls=1.0943 smmd=5.6743 ct=11.2789 rec=1.4136 | train/val/test=0.654/0.446/0.430 | c=0.998437
[Epoch 0001] loss=29.6487 cls=1.0754 smmd=3.5463 ct=11.2383 rec=1.4136 | train/val/test=0.500/0.276/0.264 | c=0.998437
[Epoch 0002] loss=36.1038 cls=1.0487 smmd=4.8379 ct=11.2485 rec=1.4136 | train/val/test=0.615/0.488/0.481 | c=0.998437
[Epoch 0003] loss=35.3997 cls=0.9932 smmd=4.7107 ct=11.2082 rec=1.4139 | train/val/test=0.808/0.614/0.606 | c=0.998437
[Epoch 0004] loss=26.3740 cls=0.8847 smmd=2.9476 ct=11.0524 rec=1.4105 | train/val/test=0.846/0.700/0.666 | c=0.998437
[Epoch 0005] loss=25.6164 cls=0.7570 smmd=2.8134 ct=11.0306 rec=1.4032 | train/val/test=0.846/0.716/0.679 | c=0.998437
[Epoch 0006] loss=27.9109 cls=0.6317 smmd=3.2935 ct=10.9885 rec=1.3910 | train/val/test=0.846/0.748/0.717 | c=0.998437
[Epoch 0007] loss=27.2634 cls=0.5029 smmd=3.0722 ct=11.5139 rec=1.3717 | train/val/test=0.885/0.804/0.743 | c=0.998437
[Epoch 0008] loss=23.2606 cls=0.3968 smmd=2.3108 ct=11.3729 rec=1.3552 | train/val/test=0.885/0.810/0.752 | c=0.998437
[Epoch 0009] loss=22.2235 cls=0.3153 smmd=2.1097 ct=11.3831 rec=1.3426 | train/val/test=1.000/0.810/0.749 | c=0.998437
[Epoch 0010] loss=24.2792 cls=0.2606 smmd=2.5094 ct=11.4685 rec=1.3363 | train/val/test=1.000/0.790/0.747 | c=0.998437
[Epoch 0011] loss=23.6201 cls=0.2146 smmd=2.3773 ct=11.4931 rec=1.3327 | train/val/test=1.000/0.796/0.764 | c=0.998437
[Epoch 0012] loss=20.2753 cls=0.1773 smmd=1.7129 ct=11.4886 rec=1.3345 | train/val/test=1.000/0.796/0.766 | c=0.998437
[Epoch 0013] loss=22.9967 cls=0.1593 smmd=2.2719 ct=11.4240 rec=1.3347 | train/val/test=1.000/0.796/0.764 | c=0.998437
[Epoch 0014] loss=22.6003 cls=0.1240 smmd=2.1979 ct=11.4161 rec=1.3257 | train/val/test=1.000/0.796/0.763 | c=0.998437
[Epoch 0015] loss=19.7360 cls=0.0851 smmd=1.6225 ct=11.4498 rec=1.3101 | train/val/test=1.000/0.804/0.764 | c=0.998437
[Epoch 0016] loss=19.9241 cls=0.0697 smmd=1.6580 ct=11.4688 rec=1.3031 | train/val/test=1.000/0.798/0.749 | c=0.998437
[Epoch 0017] loss=20.3120 cls=0.0551 smmd=1.7387 ct=11.4609 rec=1.3004 | train/val/test=1.000/0.804/0.774 | c=0.998437
[Epoch 0018] loss=18.6134 cls=0.0471 smmd=1.4072 ct=11.4246 rec=1.2914 | train/val/test=1.000/0.806/0.761 | c=0.998437
[Epoch 0019] loss=18.2712 cls=0.0546 smmd=1.3426 ct=11.4017 rec=1.2929 | train/val/test=1.000/0.808/0.776 | c=0.998437
[Epoch 0020] loss=18.3697 cls=0.0567 smmd=1.3588 ct=11.4178 rec=1.2970 | train/val/test=1.000/0.804/0.760 | c=0.998437
[Epoch 0021] loss=18.1674 cls=0.0721 smmd=1.3052 ct=11.4753 rec=1.3010 | train/val/test=1.000/0.796/0.756 | c=0.998437
[Epoch 0022] loss=17.6301 cls=0.0901 smmd=1.2012 ct=11.4481 rec=1.3085 | train/val/test=1.000/0.784/0.731 | c=0.998437
[Epoch 0023] loss=18.4420 cls=0.1103 smmd=1.3614 ct=11.4476 rec=1.3210 | train/val/test=1.000/0.800/0.754 | c=0.998437
[Epoch 0024] loss=17.4198 cls=0.0987 smmd=1.1493 ct=11.4932 rec=1.3070 | train/val/test=1.000/0.814/0.774 | c=0.998437
[Epoch 0025] loss=17.5538 cls=0.0887 smmd=1.1890 ct=11.4334 rec=1.3122 | train/val/test=1.000/0.786/0.762 | c=0.998437
[Epoch 0026] loss=16.5842 cls=0.0785 smmd=0.9936 ct=11.4468 rec=1.3020 | train/val/test=1.000/0.812/0.773 | c=0.998437
[Epoch 0027] loss=16.5772 cls=0.0709 smmd=0.9984 ct=11.4205 rec=1.2941 | train/val/test=1.000/0.812/0.784 | c=0.998437
[Epoch 0028] loss=15.9809 cls=0.0543 smmd=0.8847 ct=11.4011 rec=1.2923 | train/val/test=1.000/0.818/0.789 | c=0.998437
[Epoch 0029] loss=15.8892 cls=0.0519 smmd=0.8592 ct=11.4381 rec=1.2935 | train/val/test=1.000/0.820/0.778 | c=0.998437
[Epoch 0030] loss=15.7468 cls=0.0547 smmd=0.8290 ct=11.4447 rec=1.2952 | train/val/test=1.000/0.814/0.777 | c=0.998437
[Epoch 0031] loss=15.6567 cls=0.0634 smmd=0.8202 ct=11.3933 rec=1.3048 | train/val/test=1.000/0.790/0.755 | c=0.998437
[Epoch 0032] loss=15.9113 cls=0.0785 smmd=0.8587 ct=11.4469 rec=1.3149 | train/val/test=1.000/0.792/0.742 | c=0.998437
[Epoch 0033] loss=16.0462 cls=0.0851 smmd=0.8812 ct=11.4656 rec=1.3206 | train/val/test=1.000/0.766/0.747 | c=0.998437
[Epoch 0034] loss=15.6208 cls=0.0926 smmd=0.7979 ct=11.4527 rec=1.3238 | train/val/test=1.000/0.756/0.727 | c=0.998437
[Epoch 0035] loss=15.8817 cls=0.0843 smmd=0.8505 ct=11.4547 rec=1.3226 | train/val/test=1.000/0.770/0.753 | c=0.998437
[Epoch 0036] loss=14.6935 cls=0.0779 smmd=0.6216 ct=11.4154 rec=1.3135 | train/val/test=1.000/0.820/0.770 | c=0.998437
[Epoch 0037] loss=15.4374 cls=0.0564 smmd=0.7732 ct=11.4130 rec=1.3033 | train/val/test=1.000/0.798/0.779 | c=0.998437
[Epoch 0038] loss=14.4360 cls=0.0604 smmd=0.5686 ct=11.4325 rec=1.3019 | train/val/test=1.000/0.816/0.769 | c=0.998437
[Epoch 0039] loss=14.7734 cls=0.0586 smmd=0.6408 ct=11.4097 rec=1.3047 | train/val/test=1.000/0.798/0.775 | c=0.998437
[Epoch 0040] loss=14.6046 cls=0.0688 smmd=0.6087 ct=11.3961 rec=1.3069 | train/val/test=1.000/0.822/0.770 | c=0.998437
[Epoch 0041] loss=14.7206 cls=0.0744 smmd=0.6224 ct=11.4397 rec=1.3148 | train/val/test=1.000/0.776/0.762 | c=0.998437
[Epoch 0042] loss=14.8921 cls=0.0926 smmd=0.6533 ct=11.4468 rec=1.3233 | train/val/test=1.000/0.772/0.733 | c=0.998437
[Epoch 0043] loss=15.0689 cls=0.1029 smmd=0.6941 ct=11.4138 rec=1.3291 | train/val/test=1.000/0.758/0.732 | c=0.998437
[Epoch 0044] loss=15.2093 cls=0.1133 smmd=0.7094 ct=11.4719 rec=1.3367 | train/val/test=1.000/0.728/0.695 | c=0.998437
[Epoch 0045] loss=14.8135 cls=0.1177 smmd=0.6357 ct=11.4424 rec=1.3361 | train/val/test=1.000/0.748/0.725 | c=0.998437
[Epoch 0046] loss=14.5587 cls=0.1068 smmd=0.5871 ct=11.4365 rec=1.3325 | train/val/test=1.000/0.752/0.708 | c=0.998437
[Epoch 0047] loss=14.4617 cls=0.0967 smmd=0.5694 ct=11.4336 rec=1.3248 | train/val/test=1.000/0.786/0.760 | c=0.998437
[Epoch 0048] loss=14.1716 cls=0.0791 smmd=0.5200 ct=11.4010 rec=1.3127 | train/val/test=1.000/0.818/0.772 | c=0.998437
[Epoch 0049] loss=14.1817 cls=0.0740 smmd=0.5195 ct=11.4161 rec=1.3137 | train/val/test=1.000/0.812/0.778 | c=0.998437
[Epoch 0050] loss=14.1444 cls=0.0789 smmd=0.5114 ct=11.4166 rec=1.3132 | train/val/test=1.000/0.824/0.772 | c=0.998437
[Epoch 0051] loss=14.2942 cls=0.0868 smmd=0.5435 ct=11.4013 rec=1.3219 | train/val/test=1.000/0.780/0.769 | c=0.998437
[Epoch 0052] loss=14.5093 cls=0.0998 smmd=0.5755 ct=11.4489 rec=1.3284 | train/val/test=1.000/0.776/0.742 | c=0.998437
[Epoch 0053] loss=14.7066 cls=0.1096 smmd=0.6174 ct=11.4311 rec=1.3354 | train/val/test=1.000/0.750/0.740 | c=0.998437
[Epoch 0054] loss=14.6704 cls=0.1159 smmd=0.6090 ct=11.4335 rec=1.3402 | train/val/test=1.000/0.754/0.724 | c=0.998437
[Epoch 0055] loss=14.1861 cls=0.1054 smmd=0.5135 ct=11.4326 rec=1.3351 | train/val/test=1.000/0.766/0.740 | c=0.998437
[Epoch 0056] loss=14.1358 cls=0.0999 smmd=0.5059 ct=11.4234 rec=1.3313 | train/val/test=1.000/0.764/0.730 | c=0.998437
[Epoch 0057] loss=13.8370 cls=0.0932 smmd=0.4526 ct=11.3940 rec=1.3317 | train/val/test=1.000/0.762/0.735 | c=0.998437
[Epoch 0058] loss=13.8355 cls=0.0995 smmd=0.4451 ct=11.4269 rec=1.3316 | train/val/test=1.000/0.746/0.708 | c=0.998437
[Epoch 0059] loss=13.8640 cls=0.1019 smmd=0.4512 ct=11.4235 rec=1.3366 | train/val/test=1.000/0.752/0.739 | c=0.998437
[Epoch 0060] loss=14.1120 cls=0.1107 smmd=0.5002 ct=11.4215 rec=1.3409 | train/val/test=1.000/0.712/0.683 | c=0.998437
[Epoch 0061] loss=14.3522 cls=0.1235 smmd=0.5403 ct=11.4545 rec=1.3455 | train/val/test=1.000/0.706/0.698 | c=0.998437
[Epoch 0062] loss=14.4397 cls=0.1489 smmd=0.5500 ct=11.4791 rec=1.3629 | train/val/test=1.000/0.648/0.621 | c=0.998437
[Epoch 0063] loss=14.6154 cls=0.1529 smmd=0.5864 ct=11.4714 rec=1.3549 | train/val/test=1.000/0.704/0.692 | c=0.998437
[Epoch 0064] loss=14.4178 cls=0.1351 smmd=0.5497 ct=11.4657 rec=1.3586 | train/val/test=1.000/0.738/0.705 | c=0.998437
[Epoch 0065] loss=13.6576 cls=0.0810 smmd=0.4096 ct=11.4361 rec=1.3289 | train/val/test=1.000/0.804/0.771 | c=0.998437
[Epoch 0066] loss=13.8680 cls=0.0590 smmd=0.4652 ct=11.3816 rec=1.3095 | train/val/test=1.000/0.818/0.781 | c=0.998437
[Epoch 0067] loss=13.4893 cls=0.0559 smmd=0.3877 ct=11.3921 rec=1.3092 | train/val/test=1.000/0.812/0.762 | c=0.998437
[Epoch 0068] loss=13.3116 cls=0.0622 smmd=0.3474 ct=11.4119 rec=1.3159 | train/val/test=1.000/0.806/0.762 | c=0.998437
[Epoch 0069] loss=13.8652 cls=0.0739 smmd=0.4622 ct=11.3850 rec=1.3248 | train/val/test=1.000/0.804/0.762 | c=0.998437
[Epoch 0070] loss=14.1658 cls=0.0892 smmd=0.5099 ct=11.4382 rec=1.3346 | train/val/test=1.000/0.782/0.738 | c=0.998437
[Epoch 0071] loss=14.4393 cls=0.1021 smmd=0.5687 ct=11.4108 rec=1.3408 | train/val/test=1.000/0.778/0.733 | c=0.998437
[Epoch 0072] loss=14.5845 cls=0.1083 smmd=0.5961 ct=11.4154 rec=1.3432 | train/val/test=1.000/0.786/0.748 | c=0.998437
[Epoch 0073] loss=14.1335 cls=0.1023 smmd=0.5054 ct=11.4215 rec=1.3396 | train/val/test=1.000/0.748/0.709 | c=0.998437
[Epoch 0074] loss=13.6128 cls=0.1041 smmd=0.4089 ct=11.3823 rec=1.3385 | train/val/test=1.000/0.784/0.764 | c=0.998437
[Epoch 0075] loss=13.5264 cls=0.0946 smmd=0.3901 ct=11.3952 rec=1.3341 | train/val/test=1.000/0.744/0.706 | c=0.998437
[Epoch 0076] loss=13.4035 cls=0.1055 smmd=0.3646 ct=11.3940 rec=1.3383 | train/val/test=1.000/0.764/0.737 | c=0.998437
[Epoch 0077] loss=13.5108 cls=0.1219 smmd=0.3810 ct=11.4108 rec=1.3430 | train/val/test=1.000/0.622/0.607 | c=0.998437
[Epoch 0078] loss=14.0387 cls=0.1709 smmd=0.4696 ct=11.4685 rec=1.3661 | train/val/test=0.846/0.588/0.585 | c=0.998437
[Epoch 0079] loss=14.8786 cls=0.3252 smmd=0.6041 ct=11.5531 rec=1.4225 | train/val/test=0.808/0.544/0.534 | c=0.998437
[Epoch 0080] loss=15.3873 cls=0.3675 smmd=0.6896 ct=11.6154 rec=1.4016 | train/val/test=0.885/0.618/0.629 | c=0.998437
[Epoch 0081] loss=14.6695 cls=0.2699 smmd=0.5711 ct=11.5383 rec=1.4093 | train/val/test=1.000/0.762/0.732 | c=0.998437
[Epoch 0082] loss=13.6239 cls=0.0542 smmd=0.4063 ct=11.4340 rec=1.3157 | train/val/test=1.000/0.780/0.733 | c=0.998437
[Epoch 0083] loss=13.6337 cls=0.0453 smmd=0.4149 ct=11.4053 rec=1.3111 | train/val/test=1.000/0.764/0.738 | c=0.998437
[Epoch 0084] loss=13.4122 cls=0.0600 smmd=0.3639 ct=11.4317 rec=1.3082 | train/val/test=1.000/0.812/0.763 | c=0.998437
[Epoch 0085] loss=13.2053 cls=0.0390 smmd=0.3250 ct=11.4307 rec=1.3012 | train/val/test=1.000/0.764/0.727 | c=0.998437
[Epoch 0086] loss=13.8169 cls=0.0549 smmd=0.4486 ct=11.4145 rec=1.3209 | train/val/test=1.000/0.762/0.745 | c=0.998437
[Epoch 0087] loss=13.8261 cls=0.0692 smmd=0.4403 ct=11.4568 rec=1.3306 | train/val/test=1.000/0.744/0.695 | c=0.998437
[Epoch 0088] loss=14.0447 cls=0.0909 smmd=0.4811 ct=11.4595 rec=1.3420 | train/val/test=1.000/0.722/0.686 | c=0.998437
[Epoch 0089] loss=15.2945 cls=0.1157 smmd=0.7366 ct=11.4181 rec=1.3555 | train/val/test=0.962/0.656/0.633 | c=0.998437
[Epoch 0090] loss=14.6140 cls=0.1514 smmd=0.5762 ct=11.5213 rec=1.3595 | train/val/test=1.000/0.630/0.617 | c=0.998437
[Epoch 0091] loss=13.8101 cls=0.1575 smmd=0.4330 ct=11.4303 rec=1.3585 | train/val/test=1.000/0.728/0.698 | c=0.998437
[Epoch 0092] loss=13.7861 cls=0.1080 smmd=0.4391 ct=11.4025 rec=1.3410 | train/val/test=1.000/0.720/0.682 | c=0.998437
[Epoch 0093] loss=13.2685 cls=0.1077 smmd=0.3389 ct=11.3862 rec=1.3375 | train/val/test=1.000/0.746/0.699 | c=0.998437
[Epoch 0094] loss=13.2707 cls=0.1075 smmd=0.3373 ct=11.3966 rec=1.3370 | train/val/test=1.000/0.774/0.751 | c=0.998437
[Epoch 0095] loss=13.2513 cls=0.1109 smmd=0.3375 ct=11.3747 rec=1.3387 | train/val/test=1.000/0.684/0.653 | c=0.998437
[Epoch 0096] loss=13.5423 cls=0.1513 smmd=0.3794 ct=11.4341 rec=1.3541 | train/val/test=0.923/0.652/0.647 | c=0.998437
[Epoch 0097] loss=14.7858 cls=0.2417 smmd=0.5985 ct=11.5348 rec=1.3779 | train/val/test=0.769/0.498/0.488 | c=0.998437
[Epoch 0098] loss=15.9870 cls=0.4321 smmd=0.8008 ct=11.6215 rec=1.4544 | train/val/test=0.808/0.528/0.552 | c=0.998437
[Epoch 0099] loss=15.8259 cls=0.4878 smmd=0.7615 ct=11.6304 rec=1.4421 | train/val/test=1.000/0.604/0.599 | c=0.998437
=== Best @ epoch 50: val=0.8240, test=0.7720 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-4 completed in 142.08 seconds.
==================================================
