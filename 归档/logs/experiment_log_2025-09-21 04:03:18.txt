Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-5 - 2025-09-21 04:03:18:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-5...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=40.0212 cls=1.0993 smmd=5.6109 ct=11.2759 rec=1.4136 | train/val/test=0.346/0.196/0.180 | c=0.998437
[Epoch 0001] loss=29.9059 cls=1.0796 smmd=3.6019 ct=11.2152 rec=1.4137 | train/val/test=0.808/0.700/0.683 | c=0.998437
[Epoch 0002] loss=35.5160 cls=1.0580 smmd=4.7233 ct=11.2292 rec=1.4135 | train/val/test=0.654/0.530/0.524 | c=0.998437
[Epoch 0003] loss=34.5109 cls=1.0150 smmd=4.5444 ct=11.1400 rec=1.4141 | train/val/test=0.615/0.546/0.525 | c=0.998437
[Epoch 0004] loss=25.4049 cls=0.9390 smmd=2.7564 ct=11.0120 rec=1.4124 | train/val/test=0.692/0.578/0.566 | c=0.998437
[Epoch 0005] loss=25.9032 cls=0.8461 smmd=2.8741 ct=10.9688 rec=1.4060 | train/val/test=0.731/0.622/0.614 | c=0.998437
[Epoch 0006] loss=28.0740 cls=0.7501 smmd=3.3223 ct=10.9476 rec=1.3965 | train/val/test=0.731/0.634/0.624 | c=0.998437
[Epoch 0007] loss=26.2975 cls=0.6583 smmd=2.9818 ct=10.9207 rec=1.3853 | train/val/test=0.769/0.640/0.629 | c=0.998437
[Epoch 0008] loss=21.9668 cls=0.5828 smmd=2.1299 ct=10.8880 rec=1.3776 | train/val/test=0.923/0.686/0.683 | c=0.998437
[Epoch 0009] loss=22.0682 cls=0.4894 smmd=2.1594 ct=10.8896 rec=1.3713 | train/val/test=0.923/0.776/0.741 | c=0.998437
[Epoch 0010] loss=23.9684 cls=0.4066 smmd=2.5393 ct=10.9320 rec=1.3686 | train/val/test=0.923/0.780/0.737 | c=0.998437
[Epoch 0011] loss=22.4512 cls=0.3503 smmd=2.2436 ct=10.9213 rec=1.3668 | train/val/test=1.000/0.778/0.730 | c=0.998437
[Epoch 0012] loss=19.4791 cls=0.2861 smmd=1.6668 ct=10.8659 rec=1.3618 | train/val/test=1.000/0.754/0.707 | c=0.998437
[Epoch 0013] loss=22.4529 cls=0.2502 smmd=2.2569 ct=10.9075 rec=1.3596 | train/val/test=1.000/0.772/0.723 | c=0.998437
[Epoch 0014] loss=21.5322 cls=0.1953 smmd=2.0822 ct=10.8889 rec=1.3453 | train/val/test=1.000/0.774/0.724 | c=0.998437
[Epoch 0015] loss=18.7894 cls=0.1411 smmd=1.5455 ct=10.8588 rec=1.3280 | train/val/test=1.000/0.762/0.718 | c=0.998437
[Epoch 0016] loss=18.9933 cls=0.1131 smmd=1.5925 ct=10.8421 rec=1.3199 | train/val/test=1.000/0.784/0.740 | c=0.998437
[Epoch 0017] loss=19.4949 cls=0.0972 smmd=1.6904 ct=10.8631 rec=1.3138 | train/val/test=1.000/0.790/0.739 | c=0.998437
[Epoch 0018] loss=18.1451 cls=0.0811 smmd=1.4258 ct=10.8448 rec=1.3082 | train/val/test=1.000/0.760/0.731 | c=0.998437
[Epoch 0019] loss=17.2477 cls=0.0798 smmd=1.2451 ct=10.8512 rec=1.3094 | train/val/test=1.000/0.804/0.749 | c=0.998437
[Epoch 0020] loss=17.8112 cls=0.0841 smmd=1.3589 ct=10.8435 rec=1.3118 | train/val/test=1.000/0.800/0.751 | c=0.998437
[Epoch 0021] loss=17.6017 cls=0.0915 smmd=1.3118 ct=10.8654 rec=1.3138 | train/val/test=1.000/0.804/0.751 | c=0.998437
[Epoch 0022] loss=16.5803 cls=0.0974 smmd=1.1057 ct=10.8718 rec=1.3141 | train/val/test=1.000/0.808/0.756 | c=0.998437
[Epoch 0023] loss=17.4242 cls=0.1024 smmd=1.2756 ct=10.8637 rec=1.3119 | train/val/test=1.000/0.814/0.751 | c=0.998437
[Epoch 0024] loss=16.5970 cls=0.1005 smmd=1.1091 ct=10.8705 rec=1.3098 | train/val/test=1.000/0.788/0.738 | c=0.998437
[Epoch 0025] loss=16.2700 cls=0.0993 smmd=1.0486 ct=10.8459 rec=1.3131 | train/val/test=1.000/0.814/0.742 | c=0.998437
[Epoch 0026] loss=15.8214 cls=0.0925 smmd=0.9620 ct=10.8349 rec=1.3019 | train/val/test=1.000/0.818/0.750 | c=0.998437
[Epoch 0027] loss=15.9069 cls=0.0817 smmd=0.9800 ct=10.8360 rec=1.3009 | train/val/test=1.000/0.816/0.751 | c=0.998437
[Epoch 0028] loss=15.0850 cls=0.0763 smmd=0.8171 ct=10.8313 rec=1.3008 | train/val/test=1.000/0.818/0.745 | c=0.998437
[Epoch 0029] loss=15.3342 cls=0.0777 smmd=0.8660 ct=10.8358 rec=1.2978 | train/val/test=1.000/0.822/0.748 | c=0.998437
[Epoch 0030] loss=15.1759 cls=0.0776 smmd=0.8326 ct=10.8439 rec=1.3003 | train/val/test=1.000/0.796/0.736 | c=0.998437
[Epoch 0031] loss=15.0134 cls=0.0836 smmd=0.7973 ct=10.8540 rec=1.3094 | train/val/test=1.000/0.812/0.742 | c=0.998437
[Epoch 0032] loss=15.2564 cls=0.0821 smmd=0.8448 ct=10.8611 rec=1.3035 | train/val/test=1.000/0.808/0.747 | c=0.998437
[Epoch 0033] loss=15.2965 cls=0.0782 smmd=0.8545 ct=10.8545 rec=1.3035 | train/val/test=1.000/0.814/0.750 | c=0.998437
[Epoch 0034] loss=14.6653 cls=0.0689 smmd=0.7319 ct=10.8412 rec=1.2999 | train/val/test=1.000/0.802/0.750 | c=0.998437
[Epoch 0035] loss=14.4649 cls=0.0674 smmd=0.6934 ct=10.8351 rec=1.2935 | train/val/test=1.000/0.816/0.750 | c=0.998437
[Epoch 0036] loss=14.4855 cls=0.0632 smmd=0.6975 ct=10.8366 rec=1.2976 | train/val/test=1.000/0.820/0.751 | c=0.998437
[Epoch 0037] loss=14.0124 cls=0.0652 smmd=0.6030 ct=10.8349 rec=1.2982 | train/val/test=1.000/0.818/0.757 | c=0.998437
[Epoch 0038] loss=14.1245 cls=0.0722 smmd=0.6241 ct=10.8379 rec=1.2981 | train/val/test=1.000/0.824/0.754 | c=0.998437
[Epoch 0039] loss=14.2680 cls=0.0776 smmd=0.6506 ct=10.8458 rec=1.3035 | train/val/test=1.000/0.812/0.753 | c=0.998437
[Epoch 0040] loss=14.2092 cls=0.0905 smmd=0.6342 ct=10.8619 rec=1.3096 | train/val/test=1.000/0.796/0.739 | c=0.998437
[Epoch 0041] loss=14.4888 cls=0.0978 smmd=0.6884 ct=10.8662 rec=1.3148 | train/val/test=1.000/0.788/0.757 | c=0.998437
[Epoch 0042] loss=14.3730 cls=0.0993 smmd=0.6638 ct=10.8732 rec=1.3097 | train/val/test=1.000/0.774/0.734 | c=0.998437
[Epoch 0043] loss=14.0316 cls=0.0986 smmd=0.5993 ct=10.8535 rec=1.3212 | train/val/test=1.000/0.798/0.760 | c=0.998437
[Epoch 0044] loss=13.9108 cls=0.0892 smmd=0.5780 ct=10.8460 rec=1.3034 | train/val/test=1.000/0.822/0.760 | c=0.998437
[Epoch 0045] loss=13.5889 cls=0.0808 smmd=0.5153 ct=10.8411 rec=1.3083 | train/val/test=1.000/0.824/0.765 | c=0.998437
[Epoch 0046] loss=13.4699 cls=0.0794 smmd=0.4928 ct=10.8358 rec=1.3044 | train/val/test=1.000/0.810/0.763 | c=0.998437
[Epoch 0047] loss=13.5533 cls=0.0831 smmd=0.5077 ct=10.8429 rec=1.3055 | train/val/test=1.000/0.828/0.763 | c=0.998437
[Epoch 0048] loss=13.5086 cls=0.0882 smmd=0.4970 ct=10.8483 rec=1.3107 | train/val/test=1.000/0.806/0.754 | c=0.998437
[Epoch 0049] loss=13.8580 cls=0.0962 smmd=0.5633 ct=10.8619 rec=1.3166 | train/val/test=1.000/0.800/0.757 | c=0.998437
[Epoch 0050] loss=14.1458 cls=0.1059 smmd=0.6191 ct=10.8658 rec=1.3152 | train/val/test=1.000/0.774/0.731 | c=0.998437
[Epoch 0051] loss=13.9661 cls=0.1041 smmd=0.5829 ct=10.8675 rec=1.3229 | train/val/test=1.000/0.796/0.756 | c=0.998437
[Epoch 0052] loss=13.9013 cls=0.0971 smmd=0.5750 ct=10.8467 rec=1.3099 | train/val/test=1.000/0.798/0.744 | c=0.998437
[Epoch 0053] loss=13.3861 cls=0.0874 smmd=0.4726 ct=10.8483 rec=1.3133 | train/val/test=1.000/0.814/0.755 | c=0.998437
[Epoch 0054] loss=13.2954 cls=0.0830 smmd=0.4583 ct=10.8320 rec=1.3042 | train/val/test=1.000/0.824/0.757 | c=0.998437
[Epoch 0055] loss=13.3386 cls=0.0832 smmd=0.4662 ct=10.8352 rec=1.3102 | train/val/test=1.000/0.788/0.745 | c=0.998437
[Epoch 0056] loss=13.1747 cls=0.0897 smmd=0.4311 ct=10.8435 rec=1.3089 | train/val/test=1.000/0.808/0.749 | c=0.998437
[Epoch 0057] loss=13.4540 cls=0.0953 smmd=0.4854 ct=10.8476 rec=1.3174 | train/val/test=1.000/0.798/0.752 | c=0.998437
[Epoch 0058] loss=13.7399 cls=0.1080 smmd=0.5383 ct=10.8625 rec=1.3168 | train/val/test=1.000/0.756/0.710 | c=0.998437
[Epoch 0059] loss=14.0892 cls=0.1181 smmd=0.6046 ct=10.8744 rec=1.3282 | train/val/test=1.000/0.786/0.755 | c=0.998437
[Epoch 0060] loss=14.0447 cls=0.1198 smmd=0.5968 ct=10.8691 rec=1.3200 | train/val/test=1.000/0.760/0.716 | c=0.998437
[Epoch 0061] loss=13.4459 cls=0.1055 smmd=0.4807 ct=10.8569 rec=1.3254 | train/val/test=1.000/0.796/0.747 | c=0.998437
[Epoch 0062] loss=13.2727 cls=0.0964 smmd=0.4498 ct=10.8446 rec=1.3077 | train/val/test=1.000/0.794/0.745 | c=0.998437
[Epoch 0063] loss=13.0706 cls=0.0862 smmd=0.4121 ct=10.8357 rec=1.3156 | train/val/test=1.000/0.806/0.760 | c=0.998437
[Epoch 0064] loss=13.0384 cls=0.0856 smmd=0.4064 ct=10.8328 rec=1.3071 | train/val/test=1.000/0.792/0.746 | c=0.998437
[Epoch 0065] loss=13.2531 cls=0.0915 smmd=0.4458 ct=10.8467 rec=1.3146 | train/val/test=1.000/0.800/0.755 | c=0.998437
[Epoch 0066] loss=13.2618 cls=0.1038 smmd=0.4439 ct=10.8585 rec=1.3170 | train/val/test=1.000/0.756/0.717 | c=0.998437
[Epoch 0067] loss=13.6166 cls=0.1122 smmd=0.5115 ct=10.8701 rec=1.3271 | train/val/test=1.000/0.782/0.752 | c=0.998437
[Epoch 0068] loss=14.0447 cls=0.1200 smmd=0.5948 ct=10.8783 rec=1.3219 | train/val/test=1.000/0.748/0.711 | c=0.998437
[Epoch 0069] loss=13.6472 cls=0.1097 smmd=0.5182 ct=10.8681 rec=1.3296 | train/val/test=1.000/0.778/0.745 | c=0.998437
[Epoch 0070] loss=13.3691 cls=0.0993 smmd=0.4674 ct=10.8514 rec=1.3097 | train/val/test=1.000/0.772/0.723 | c=0.998437
[Epoch 0071] loss=13.2058 cls=0.0863 smmd=0.4375 ct=10.8431 rec=1.3200 | train/val/test=1.000/0.794/0.761 | c=0.998437
[Epoch 0072] loss=12.8912 cls=0.0786 smmd=0.3780 ct=10.8316 rec=1.3014 | train/val/test=1.000/0.800/0.748 | c=0.998437
[Epoch 0073] loss=12.8126 cls=0.0774 smmd=0.3614 ct=10.8360 rec=1.3092 | train/val/test=1.000/0.814/0.758 | c=0.998437
[Epoch 0074] loss=13.0460 cls=0.0835 smmd=0.4054 ct=10.8461 rec=1.3103 | train/val/test=1.000/0.790/0.749 | c=0.998437
[Epoch 0075] loss=13.2447 cls=0.0934 smmd=0.4409 ct=10.8619 rec=1.3171 | train/val/test=1.000/0.800/0.757 | c=0.998437
[Epoch 0076] loss=13.6928 cls=0.1011 smmd=0.5278 ct=10.8713 rec=1.3182 | train/val/test=1.000/0.772/0.733 | c=0.998437
[Epoch 0077] loss=14.1249 cls=0.1062 smmd=0.6124 ct=10.8772 rec=1.3283 | train/val/test=1.000/0.778/0.742 | c=0.998437
[Epoch 0078] loss=13.8895 cls=0.1110 smmd=0.5678 ct=10.8631 rec=1.3167 | train/val/test=1.000/0.730/0.699 | c=0.998437
[Epoch 0079] loss=13.1586 cls=0.1045 smmd=0.4211 ct=10.8676 rec=1.3344 | train/val/test=1.000/0.782/0.744 | c=0.998437
[Epoch 0080] loss=13.1066 cls=0.0985 smmd=0.4174 ct=10.8395 rec=1.3069 | train/val/test=1.000/0.772/0.718 | c=0.998437
[Epoch 0081] loss=12.8313 cls=0.0818 smmd=0.3640 ct=10.8386 rec=1.3179 | train/val/test=1.000/0.804/0.756 | c=0.998437
[Epoch 0082] loss=12.7747 cls=0.0773 smmd=0.3534 ct=10.8388 rec=1.3033 | train/val/test=1.000/0.810/0.765 | c=0.998437
[Epoch 0083] loss=12.8843 cls=0.0815 smmd=0.3745 ct=10.8398 rec=1.3099 | train/val/test=1.000/0.820/0.755 | c=0.998437
[Epoch 0084] loss=13.0895 cls=0.0914 smmd=0.4088 ct=10.8680 rec=1.3166 | train/val/test=1.000/0.814/0.755 | c=0.998437
[Epoch 0085] loss=13.9856 cls=0.1003 smmd=0.5854 ct=10.8764 rec=1.3202 | train/val/test=1.000/0.804/0.761 | c=0.998437
[Epoch 0086] loss=14.4174 cls=0.1031 smmd=0.6718 ct=10.8750 rec=1.3176 | train/val/test=1.000/0.766/0.727 | c=0.998437
[Epoch 0087] loss=13.7337 cls=0.1011 smmd=0.5349 ct=10.8757 rec=1.3289 | train/val/test=1.000/0.764/0.737 | c=0.998437
[Epoch 0088] loss=13.1896 cls=0.1051 smmd=0.4314 ct=10.8492 rec=1.3089 | train/val/test=1.000/0.746/0.710 | c=0.998437
[Epoch 0089] loss=12.9001 cls=0.0899 smmd=0.3744 ct=10.8504 rec=1.3257 | train/val/test=1.000/0.800/0.759 | c=0.998437
[Epoch 0090] loss=12.7433 cls=0.0743 smmd=0.3506 ct=10.8235 rec=1.2972 | train/val/test=1.000/0.796/0.757 | c=0.998437
[Epoch 0091] loss=12.7350 cls=0.0731 smmd=0.3484 ct=10.8262 rec=1.3031 | train/val/test=1.000/0.810/0.761 | c=0.998437
[Epoch 0092] loss=12.8062 cls=0.0838 smmd=0.3558 ct=10.8536 rec=1.3144 | train/val/test=1.000/0.802/0.759 | c=0.998437
[Epoch 0093] loss=13.1966 cls=0.0980 smmd=0.4303 ct=10.8644 rec=1.3150 | train/val/test=1.000/0.808/0.757 | c=0.998437
[Epoch 0094] loss=14.0932 cls=0.1082 smmd=0.6046 ct=10.8838 rec=1.3243 | train/val/test=1.000/0.810/0.756 | c=0.998437
[Epoch 0095] loss=14.4910 cls=0.1049 smmd=0.6849 ct=10.8820 rec=1.3208 | train/val/test=1.000/0.806/0.761 | c=0.998437
[Epoch 0096] loss=13.8125 cls=0.0936 smmd=0.5552 ct=10.8585 rec=1.3116 | train/val/test=1.000/0.798/0.752 | c=0.998437
[Epoch 0097] loss=13.1411 cls=0.0810 smmd=0.4255 ct=10.8416 rec=1.3127 | train/val/test=1.000/0.800/0.760 | c=0.998437
[Epoch 0098] loss=12.7834 cls=0.0759 smmd=0.3582 ct=10.8247 rec=1.2983 | train/val/test=1.000/0.806/0.762 | c=0.998437
[Epoch 0099] loss=12.6998 cls=0.0716 smmd=0.3425 ct=10.8214 rec=1.3027 | train/val/test=1.000/0.814/0.769 | c=0.998437
=== Best @ epoch 47: val=0.8280, test=0.7630 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-5 - 2025-09-21 04:03:18:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-5...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=40.0212 cls=1.0993 smmd=5.6109 ct=11.2759 rec=1.4136 | train/val/test=0.346/0.196/0.180 | c=0.998437
[Epoch 0001] loss=29.9059 cls=1.0796 smmd=3.6019 ct=11.2152 rec=1.4137 | train/val/test=0.808/0.700/0.683 | c=0.998437
[Epoch 0002] loss=35.5160 cls=1.0580 smmd=4.7233 ct=11.2292 rec=1.4135 | train/val/test=0.654/0.530/0.524 | c=0.998437
[Epoch 0003] loss=34.5109 cls=1.0150 smmd=4.5444 ct=11.1400 rec=1.4141 | train/val/test=0.615/0.546/0.525 | c=0.998437
[Epoch 0004] loss=25.4049 cls=0.9390 smmd=2.7564 ct=11.0120 rec=1.4124 | train/val/test=0.692/0.578/0.566 | c=0.998437
[Epoch 0005] loss=25.9032 cls=0.8461 smmd=2.8741 ct=10.9688 rec=1.4060 | train/val/test=0.731/0.622/0.614 | c=0.998437
[Epoch 0006] loss=28.0740 cls=0.7501 smmd=3.3223 ct=10.9476 rec=1.3965 | train/val/test=0.731/0.634/0.624 | c=0.998437
[Epoch 0007] loss=26.2975 cls=0.6583 smmd=2.9818 ct=10.9207 rec=1.3853 | train/val/test=0.769/0.640/0.629 | c=0.998437
[Epoch 0008] loss=21.9668 cls=0.5828 smmd=2.1299 ct=10.8880 rec=1.3776 | train/val/test=0.923/0.686/0.683 | c=0.998437
[Epoch 0009] loss=22.0682 cls=0.4894 smmd=2.1594 ct=10.8896 rec=1.3713 | train/val/test=0.923/0.776/0.741 | c=0.998437
[Epoch 0010] loss=23.9684 cls=0.4066 smmd=2.5393 ct=10.9320 rec=1.3686 | train/val/test=0.923/0.780/0.737 | c=0.998437
[Epoch 0011] loss=22.4512 cls=0.3503 smmd=2.2436 ct=10.9213 rec=1.3668 | train/val/test=1.000/0.778/0.730 | c=0.998437
[Epoch 0012] loss=19.4791 cls=0.2861 smmd=1.6668 ct=10.8659 rec=1.3618 | train/val/test=1.000/0.754/0.707 | c=0.998437
[Epoch 0013] loss=22.4529 cls=0.2502 smmd=2.2569 ct=10.9075 rec=1.3596 | train/val/test=1.000/0.772/0.723 | c=0.998437
[Epoch 0014] loss=21.5322 cls=0.1953 smmd=2.0822 ct=10.8889 rec=1.3453 | train/val/test=1.000/0.774/0.724 | c=0.998437
[Epoch 0015] loss=18.7894 cls=0.1411 smmd=1.5455 ct=10.8588 rec=1.3280 | train/val/test=1.000/0.762/0.718 | c=0.998437
[Epoch 0016] loss=18.9933 cls=0.1131 smmd=1.5925 ct=10.8421 rec=1.3199 | train/val/test=1.000/0.784/0.740 | c=0.998437
[Epoch 0017] loss=19.4949 cls=0.0972 smmd=1.6904 ct=10.8631 rec=1.3138 | train/val/test=1.000/0.790/0.739 | c=0.998437
[Epoch 0018] loss=18.1451 cls=0.0811 smmd=1.4258 ct=10.8448 rec=1.3082 | train/val/test=1.000/0.760/0.731 | c=0.998437
[Epoch 0019] loss=17.2477 cls=0.0798 smmd=1.2451 ct=10.8512 rec=1.3094 | train/val/test=1.000/0.804/0.749 | c=0.998437
[Epoch 0020] loss=17.8112 cls=0.0841 smmd=1.3589 ct=10.8435 rec=1.3118 | train/val/test=1.000/0.800/0.751 | c=0.998437
[Epoch 0021] loss=17.6017 cls=0.0915 smmd=1.3118 ct=10.8654 rec=1.3138 | train/val/test=1.000/0.804/0.751 | c=0.998437
[Epoch 0022] loss=16.5803 cls=0.0974 smmd=1.1057 ct=10.8718 rec=1.3141 | train/val/test=1.000/0.808/0.756 | c=0.998437
[Epoch 0023] loss=17.4242 cls=0.1024 smmd=1.2756 ct=10.8637 rec=1.3119 | train/val/test=1.000/0.814/0.751 | c=0.998437
[Epoch 0024] loss=16.5970 cls=0.1005 smmd=1.1091 ct=10.8705 rec=1.3098 | train/val/test=1.000/0.788/0.738 | c=0.998437
[Epoch 0025] loss=16.2700 cls=0.0993 smmd=1.0486 ct=10.8459 rec=1.3131 | train/val/test=1.000/0.814/0.742 | c=0.998437
[Epoch 0026] loss=15.8214 cls=0.0925 smmd=0.9620 ct=10.8349 rec=1.3019 | train/val/test=1.000/0.818/0.750 | c=0.998437
[Epoch 0027] loss=15.9069 cls=0.0817 smmd=0.9800 ct=10.8360 rec=1.3009 | train/val/test=1.000/0.816/0.751 | c=0.998437
[Epoch 0028] loss=15.0850 cls=0.0763 smmd=0.8171 ct=10.8313 rec=1.3008 | train/val/test=1.000/0.818/0.745 | c=0.998437
[Epoch 0029] loss=15.3342 cls=0.0777 smmd=0.8660 ct=10.8358 rec=1.2978 | train/val/test=1.000/0.822/0.748 | c=0.998437
[Epoch 0030] loss=15.1759 cls=0.0776 smmd=0.8326 ct=10.8439 rec=1.3003 | train/val/test=1.000/0.796/0.736 | c=0.998437
[Epoch 0031] loss=15.0134 cls=0.0836 smmd=0.7973 ct=10.8540 rec=1.3094 | train/val/test=1.000/0.812/0.742 | c=0.998437
[Epoch 0032] loss=15.2564 cls=0.0821 smmd=0.8448 ct=10.8611 rec=1.3035 | train/val/test=1.000/0.808/0.747 | c=0.998437
[Epoch 0033] loss=15.2965 cls=0.0782 smmd=0.8545 ct=10.8545 rec=1.3035 | train/val/test=1.000/0.814/0.750 | c=0.998437
[Epoch 0034] loss=14.6653 cls=0.0689 smmd=0.7319 ct=10.8412 rec=1.2999 | train/val/test=1.000/0.802/0.750 | c=0.998437
[Epoch 0035] loss=14.4649 cls=0.0674 smmd=0.6934 ct=10.8351 rec=1.2935 | train/val/test=1.000/0.816/0.750 | c=0.998437
[Epoch 0036] loss=14.4855 cls=0.0632 smmd=0.6975 ct=10.8366 rec=1.2976 | train/val/test=1.000/0.820/0.751 | c=0.998437
[Epoch 0037] loss=14.0124 cls=0.0652 smmd=0.6030 ct=10.8349 rec=1.2982 | train/val/test=1.000/0.818/0.757 | c=0.998437
[Epoch 0038] loss=14.1245 cls=0.0722 smmd=0.6241 ct=10.8379 rec=1.2981 | train/val/test=1.000/0.824/0.754 | c=0.998437
[Epoch 0039] loss=14.2680 cls=0.0776 smmd=0.6506 ct=10.8458 rec=1.3035 | train/val/test=1.000/0.812/0.753 | c=0.998437
[Epoch 0040] loss=14.2092 cls=0.0905 smmd=0.6342 ct=10.8619 rec=1.3096 | train/val/test=1.000/0.796/0.739 | c=0.998437
[Epoch 0041] loss=14.4888 cls=0.0978 smmd=0.6884 ct=10.8662 rec=1.3148 | train/val/test=1.000/0.788/0.757 | c=0.998437
[Epoch 0042] loss=14.3730 cls=0.0993 smmd=0.6638 ct=10.8732 rec=1.3097 | train/val/test=1.000/0.774/0.734 | c=0.998437
[Epoch 0043] loss=14.0316 cls=0.0986 smmd=0.5993 ct=10.8535 rec=1.3212 | train/val/test=1.000/0.798/0.760 | c=0.998437
[Epoch 0044] loss=13.9108 cls=0.0892 smmd=0.5780 ct=10.8460 rec=1.3034 | train/val/test=1.000/0.822/0.760 | c=0.998437
[Epoch 0045] loss=13.5889 cls=0.0808 smmd=0.5153 ct=10.8411 rec=1.3083 | train/val/test=1.000/0.824/0.765 | c=0.998437
[Epoch 0046] loss=13.4699 cls=0.0794 smmd=0.4928 ct=10.8358 rec=1.3044 | train/val/test=1.000/0.810/0.763 | c=0.998437
[Epoch 0047] loss=13.5533 cls=0.0831 smmd=0.5077 ct=10.8429 rec=1.3055 | train/val/test=1.000/0.828/0.763 | c=0.998437
[Epoch 0048] loss=13.5086 cls=0.0882 smmd=0.4970 ct=10.8483 rec=1.3107 | train/val/test=1.000/0.806/0.754 | c=0.998437
[Epoch 0049] loss=13.8580 cls=0.0962 smmd=0.5633 ct=10.8619 rec=1.3166 | train/val/test=1.000/0.800/0.757 | c=0.998437
[Epoch 0050] loss=14.1458 cls=0.1059 smmd=0.6191 ct=10.8658 rec=1.3152 | train/val/test=1.000/0.774/0.731 | c=0.998437
[Epoch 0051] loss=13.9661 cls=0.1041 smmd=0.5829 ct=10.8675 rec=1.3229 | train/val/test=1.000/0.796/0.756 | c=0.998437
[Epoch 0052] loss=13.9013 cls=0.0971 smmd=0.5750 ct=10.8467 rec=1.3099 | train/val/test=1.000/0.798/0.744 | c=0.998437
[Epoch 0053] loss=13.3861 cls=0.0874 smmd=0.4726 ct=10.8483 rec=1.3133 | train/val/test=1.000/0.814/0.755 | c=0.998437
[Epoch 0054] loss=13.2954 cls=0.0830 smmd=0.4583 ct=10.8320 rec=1.3042 | train/val/test=1.000/0.824/0.757 | c=0.998437
[Epoch 0055] loss=13.3386 cls=0.0832 smmd=0.4662 ct=10.8352 rec=1.3102 | train/val/test=1.000/0.788/0.745 | c=0.998437
[Epoch 0056] loss=13.1747 cls=0.0897 smmd=0.4311 ct=10.8435 rec=1.3089 | train/val/test=1.000/0.808/0.749 | c=0.998437
[Epoch 0057] loss=13.4540 cls=0.0953 smmd=0.4854 ct=10.8476 rec=1.3174 | train/val/test=1.000/0.798/0.752 | c=0.998437
[Epoch 0058] loss=13.7399 cls=0.1080 smmd=0.5383 ct=10.8625 rec=1.3168 | train/val/test=1.000/0.756/0.710 | c=0.998437
[Epoch 0059] loss=14.0892 cls=0.1181 smmd=0.6046 ct=10.8744 rec=1.3282 | train/val/test=1.000/0.786/0.755 | c=0.998437
[Epoch 0060] loss=14.0447 cls=0.1198 smmd=0.5968 ct=10.8691 rec=1.3200 | train/val/test=1.000/0.760/0.716 | c=0.998437
[Epoch 0061] loss=13.4459 cls=0.1055 smmd=0.4807 ct=10.8569 rec=1.3254 | train/val/test=1.000/0.796/0.747 | c=0.998437
[Epoch 0062] loss=13.2727 cls=0.0964 smmd=0.4498 ct=10.8446 rec=1.3077 | train/val/test=1.000/0.794/0.745 | c=0.998437
[Epoch 0063] loss=13.0706 cls=0.0862 smmd=0.4121 ct=10.8357 rec=1.3156 | train/val/test=1.000/0.806/0.760 | c=0.998437
[Epoch 0064] loss=13.0384 cls=0.0856 smmd=0.4064 ct=10.8328 rec=1.3071 | train/val/test=1.000/0.792/0.746 | c=0.998437
[Epoch 0065] loss=13.2531 cls=0.0915 smmd=0.4458 ct=10.8467 rec=1.3146 | train/val/test=1.000/0.800/0.755 | c=0.998437
[Epoch 0066] loss=13.2618 cls=0.1038 smmd=0.4439 ct=10.8585 rec=1.3170 | train/val/test=1.000/0.756/0.717 | c=0.998437
[Epoch 0067] loss=13.6166 cls=0.1122 smmd=0.5115 ct=10.8701 rec=1.3271 | train/val/test=1.000/0.782/0.752 | c=0.998437
[Epoch 0068] loss=14.0447 cls=0.1200 smmd=0.5948 ct=10.8783 rec=1.3219 | train/val/test=1.000/0.748/0.711 | c=0.998437
[Epoch 0069] loss=13.6472 cls=0.1097 smmd=0.5182 ct=10.8681 rec=1.3296 | train/val/test=1.000/0.778/0.745 | c=0.998437
[Epoch 0070] loss=13.3691 cls=0.0993 smmd=0.4674 ct=10.8514 rec=1.3097 | train/val/test=1.000/0.772/0.723 | c=0.998437
[Epoch 0071] loss=13.2058 cls=0.0863 smmd=0.4375 ct=10.8431 rec=1.3200 | train/val/test=1.000/0.794/0.761 | c=0.998437
[Epoch 0072] loss=12.8912 cls=0.0786 smmd=0.3780 ct=10.8316 rec=1.3014 | train/val/test=1.000/0.800/0.748 | c=0.998437
[Epoch 0073] loss=12.8126 cls=0.0774 smmd=0.3614 ct=10.8360 rec=1.3092 | train/val/test=1.000/0.814/0.758 | c=0.998437
[Epoch 0074] loss=13.0460 cls=0.0835 smmd=0.4054 ct=10.8461 rec=1.3103 | train/val/test=1.000/0.790/0.749 | c=0.998437
[Epoch 0075] loss=13.2447 cls=0.0934 smmd=0.4409 ct=10.8619 rec=1.3171 | train/val/test=1.000/0.800/0.757 | c=0.998437
[Epoch 0076] loss=13.6928 cls=0.1011 smmd=0.5278 ct=10.8713 rec=1.3182 | train/val/test=1.000/0.772/0.733 | c=0.998437
[Epoch 0077] loss=14.1249 cls=0.1062 smmd=0.6124 ct=10.8772 rec=1.3283 | train/val/test=1.000/0.778/0.742 | c=0.998437
[Epoch 0078] loss=13.8895 cls=0.1110 smmd=0.5678 ct=10.8631 rec=1.3167 | train/val/test=1.000/0.730/0.699 | c=0.998437
[Epoch 0079] loss=13.1586 cls=0.1045 smmd=0.4211 ct=10.8676 rec=1.3344 | train/val/test=1.000/0.782/0.744 | c=0.998437
[Epoch 0080] loss=13.1066 cls=0.0985 smmd=0.4174 ct=10.8395 rec=1.3069 | train/val/test=1.000/0.772/0.718 | c=0.998437
[Epoch 0081] loss=12.8313 cls=0.0818 smmd=0.3640 ct=10.8386 rec=1.3179 | train/val/test=1.000/0.804/0.756 | c=0.998437
[Epoch 0082] loss=12.7747 cls=0.0773 smmd=0.3534 ct=10.8388 rec=1.3033 | train/val/test=1.000/0.810/0.765 | c=0.998437
[Epoch 0083] loss=12.8843 cls=0.0815 smmd=0.3745 ct=10.8398 rec=1.3099 | train/val/test=1.000/0.820/0.755 | c=0.998437
[Epoch 0084] loss=13.0895 cls=0.0914 smmd=0.4088 ct=10.8680 rec=1.3166 | train/val/test=1.000/0.814/0.755 | c=0.998437
[Epoch 0085] loss=13.9856 cls=0.1003 smmd=0.5854 ct=10.8764 rec=1.3202 | train/val/test=1.000/0.804/0.761 | c=0.998437
[Epoch 0086] loss=14.4174 cls=0.1031 smmd=0.6718 ct=10.8750 rec=1.3176 | train/val/test=1.000/0.766/0.727 | c=0.998437
[Epoch 0087] loss=13.7337 cls=0.1011 smmd=0.5349 ct=10.8757 rec=1.3289 | train/val/test=1.000/0.764/0.737 | c=0.998437
[Epoch 0088] loss=13.1896 cls=0.1051 smmd=0.4314 ct=10.8492 rec=1.3089 | train/val/test=1.000/0.746/0.710 | c=0.998437
[Epoch 0089] loss=12.9001 cls=0.0899 smmd=0.3744 ct=10.8504 rec=1.3257 | train/val/test=1.000/0.800/0.759 | c=0.998437
[Epoch 0090] loss=12.7433 cls=0.0743 smmd=0.3506 ct=10.8235 rec=1.2972 | train/val/test=1.000/0.796/0.757 | c=0.998437
[Epoch 0091] loss=12.7350 cls=0.0731 smmd=0.3484 ct=10.8262 rec=1.3031 | train/val/test=1.000/0.810/0.761 | c=0.998437
[Epoch 0092] loss=12.8062 cls=0.0838 smmd=0.3558 ct=10.8536 rec=1.3144 | train/val/test=1.000/0.802/0.759 | c=0.998437
[Epoch 0093] loss=13.1966 cls=0.0980 smmd=0.4303 ct=10.8644 rec=1.3150 | train/val/test=1.000/0.808/0.757 | c=0.998437
[Epoch 0094] loss=14.0932 cls=0.1082 smmd=0.6046 ct=10.8838 rec=1.3243 | train/val/test=1.000/0.810/0.756 | c=0.998437
[Epoch 0095] loss=14.4910 cls=0.1049 smmd=0.6849 ct=10.8820 rec=1.3208 | train/val/test=1.000/0.806/0.761 | c=0.998437
[Epoch 0096] loss=13.8125 cls=0.0936 smmd=0.5552 ct=10.8585 rec=1.3116 | train/val/test=1.000/0.798/0.752 | c=0.998437
[Epoch 0097] loss=13.1411 cls=0.0810 smmd=0.4255 ct=10.8416 rec=1.3127 | train/val/test=1.000/0.800/0.760 | c=0.998437
[Epoch 0098] loss=12.7834 cls=0.0759 smmd=0.3582 ct=10.8247 rec=1.2983 | train/val/test=1.000/0.806/0.762 | c=0.998437
[Epoch 0099] loss=12.6998 cls=0.0716 smmd=0.3425 ct=10.8214 rec=1.3027 | train/val/test=1.000/0.814/0.769 | c=0.998437
=== Best @ epoch 47: val=0.8280, test=0.7630 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-5 completed in 151.75 seconds.
==================================================
