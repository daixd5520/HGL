Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3 - 2025-09-21 05:18:41:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.6926 cls=1.1081 smmd=5.6917 ct=7.2575 rec=1.4136 | train/val/test=0.395/0.406/0.400 | c=0.998347
[Epoch 0001] loss=53.7735 cls=1.0679 smmd=3.8120 ct=7.2059 rec=1.4149 | train/val/test=0.398/0.408/0.403 | c=0.998347
[Epoch 0002] loss=38.0295 cls=1.0774 smmd=2.2502 ct=7.1410 rec=1.4137 | train/val/test=0.494/0.501/0.504 | c=0.998347
[Epoch 0003] loss=41.2487 cls=1.0559 smmd=2.5779 ct=7.1175 rec=1.4138 | train/val/test=0.528/0.517/0.535 | c=0.998347
[Epoch 0004] loss=40.9552 cls=1.0160 smmd=2.5640 ct=7.0501 rec=1.4146 | train/val/test=0.532/0.522/0.531 | c=0.998347
[Epoch 0005] loss=36.2261 cls=0.9702 smmd=2.1077 ct=6.9780 rec=1.4163 | train/val/test=0.554/0.555/0.555 | c=0.998347
[Epoch 0006] loss=30.5912 cls=0.9278 smmd=1.5544 ct=6.9377 rec=1.4165 | train/val/test=0.576/0.577/0.575 | c=0.998347
[Epoch 0007] loss=34.1195 cls=0.8750 smmd=1.9121 ct=6.9277 rec=1.4103 | train/val/test=0.670/0.663/0.661 | c=0.998347
[Epoch 0008] loss=36.6471 cls=0.8188 smmd=2.0257 ct=7.6404 rec=1.4001 | train/val/test=0.709/0.697/0.707 | c=0.998347
[Epoch 0009] loss=30.0591 cls=0.7698 smmd=1.3954 ct=7.5130 rec=1.3886 | train/val/test=0.710/0.696/0.710 | c=0.998347
[Epoch 0010] loss=28.5107 cls=0.7329 smmd=1.2435 ct=7.5095 rec=1.3801 | train/val/test=0.731/0.720/0.733 | c=0.998347
[Epoch 0011] loss=30.7847 cls=0.6985 smmd=1.4724 ct=7.5134 rec=1.3691 | train/val/test=0.740/0.735/0.734 | c=0.998347
[Epoch 0012] loss=28.0185 cls=0.6796 smmd=1.1917 ct=7.5411 rec=1.3593 | train/val/test=0.752/0.742/0.745 | c=0.998347
[Epoch 0013] loss=26.9314 cls=0.6564 smmd=1.0745 ct=7.5906 rec=1.3539 | train/val/test=0.752/0.741/0.753 | c=0.998347
[Epoch 0014] loss=26.0687 cls=0.6301 smmd=0.9890 ct=7.5941 rec=1.3504 | train/val/test=0.742/0.727/0.747 | c=0.998347
[Epoch 0015] loss=25.9452 cls=0.6224 smmd=0.9853 ct=7.5541 rec=1.3460 | train/val/test=0.768/0.756/0.769 | c=0.998347
[Epoch 0016] loss=25.3283 cls=0.5994 smmd=0.9355 ct=7.5031 rec=1.3355 | train/val/test=0.790/0.783/0.792 | c=0.998347
[Epoch 0017] loss=23.9139 cls=0.5924 smmd=0.7862 ct=7.5445 rec=1.3344 | train/val/test=0.797/0.791/0.799 | c=0.998347
[Epoch 0018] loss=23.6296 cls=0.5719 smmd=0.7493 ct=7.5925 rec=1.3312 | train/val/test=0.800/0.786/0.804 | c=0.998347
[Epoch 0019] loss=23.2251 cls=0.5480 smmd=0.7103 ct=7.5923 rec=1.3275 | train/val/test=0.798/0.792/0.802 | c=0.998347
[Epoch 0020] loss=22.7140 cls=0.5358 smmd=0.6670 ct=7.5566 rec=1.3250 | train/val/test=0.807/0.798/0.812 | c=0.998347
[Epoch 0021] loss=21.8989 cls=0.5230 smmd=0.5953 ct=7.5128 rec=1.3183 | train/val/test=0.813/0.809/0.812 | c=0.998347
[Epoch 0022] loss=21.8837 cls=0.5127 smmd=0.5903 ct=7.5328 rec=1.3172 | train/val/test=0.815/0.818/0.819 | c=0.998347
[Epoch 0023] loss=21.3415 cls=0.4985 smmd=0.5271 ct=7.5813 rec=1.3176 | train/val/test=0.819/0.815/0.824 | c=0.998347
[Epoch 0024] loss=20.7673 cls=0.4863 smmd=0.4738 ct=7.5643 rec=1.3154 | train/val/test=0.817/0.814/0.820 | c=0.998347
[Epoch 0025] loss=20.7846 cls=0.4840 smmd=0.4788 ct=7.5480 rec=1.3170 | train/val/test=0.826/0.819/0.827 | c=0.998347
[Epoch 0026] loss=20.1885 cls=0.4776 smmd=0.4234 ct=7.5293 rec=1.3143 | train/val/test=0.827/0.826/0.830 | c=0.998347
[Epoch 0027] loss=20.1600 cls=0.4780 smmd=0.4199 ct=7.5326 rec=1.3146 | train/val/test=0.830/0.828/0.831 | c=0.998347
[Epoch 0028] loss=19.8125 cls=0.4657 smmd=0.3796 ct=7.5634 rec=1.3144 | train/val/test=0.830/0.825/0.833 | c=0.998347
[Epoch 0029] loss=19.8104 cls=0.4651 smmd=0.3797 ct=7.5620 rec=1.3133 | train/val/test=0.831/0.829/0.834 | c=0.998347
[Epoch 0030] loss=19.2493 cls=0.4591 smmd=0.3289 ct=7.5372 rec=1.3129 | train/val/test=0.833/0.833/0.835 | c=0.998347
[Epoch 0031] loss=19.2229 cls=0.4544 smmd=0.3277 ct=7.5308 rec=1.3132 | train/val/test=0.832/0.833/0.834 | c=0.998347
[Epoch 0032] loss=19.0970 cls=0.4633 smmd=0.3123 ct=7.5435 rec=1.3114 | train/val/test=0.835/0.834/0.837 | c=0.998347
[Epoch 0033] loss=18.8082 cls=0.4514 smmd=0.2830 ct=7.5487 rec=1.3096 | train/val/test=0.829/0.830/0.831 | c=0.998347
[Epoch 0034] loss=18.6899 cls=0.4540 smmd=0.2735 ct=7.5365 rec=1.3105 | train/val/test=0.835/0.837/0.840 | c=0.998347
[Epoch 0035] loss=18.5504 cls=0.4524 smmd=0.2605 ct=7.5318 rec=1.3117 | train/val/test=0.838/0.836/0.840 | c=0.998347
[Epoch 0036] loss=18.3553 cls=0.4476 smmd=0.2416 ct=7.5303 rec=1.3091 | train/val/test=0.836/0.833/0.837 | c=0.998347
[Epoch 0037] loss=18.3083 cls=0.4497 smmd=0.2370 ct=7.5298 rec=1.3077 | train/val/test=0.839/0.840/0.842 | c=0.998347
[Epoch 0038] loss=18.1680 cls=0.4492 smmd=0.2212 ct=7.5378 rec=1.3114 | train/val/test=0.832/0.832/0.835 | c=0.998347
[Epoch 0039] loss=18.0580 cls=0.4519 smmd=0.2123 ct=7.5263 rec=1.3117 | train/val/test=0.839/0.839/0.844 | c=0.998347
[Epoch 0040] loss=17.9254 cls=0.4495 smmd=0.1989 ct=7.5275 rec=1.3128 | train/val/test=0.839/0.838/0.841 | c=0.998347
[Epoch 0041] loss=17.7947 cls=0.4496 smmd=0.1843 ct=7.5354 rec=1.3126 | train/val/test=0.836/0.833/0.835 | c=0.998347
[Epoch 0042] loss=17.8427 cls=0.4557 smmd=0.1919 ct=7.5198 rec=1.3114 | train/val/test=0.841/0.839/0.841 | c=0.998347
[Epoch 0043] loss=17.6826 cls=0.4501 smmd=0.1752 ct=7.5241 rec=1.3152 | train/val/test=0.838/0.834/0.840 | c=0.998347
[Epoch 0044] loss=17.6403 cls=0.4523 smmd=0.1694 ct=7.5316 rec=1.3144 | train/val/test=0.840/0.838/0.841 | c=0.998347
[Epoch 0045] loss=17.5679 cls=0.4538 smmd=0.1646 ct=7.5190 rec=1.3143 | train/val/test=0.838/0.835/0.839 | c=0.998347
[Epoch 0046] loss=17.5639 cls=0.4546 smmd=0.1643 ct=7.5181 rec=1.3149 | train/val/test=0.840/0.841/0.840 | c=0.998347
[Epoch 0047] loss=17.5212 cls=0.4558 smmd=0.1591 ct=7.5223 rec=1.3150 | train/val/test=0.840/0.839/0.839 | c=0.998347
[Epoch 0048] loss=17.3764 cls=0.4549 smmd=0.1455 ct=7.5178 rec=1.3171 | train/val/test=0.839/0.838/0.838 | c=0.998347
[Epoch 0049] loss=17.3974 cls=0.4580 smmd=0.1476 ct=7.5174 rec=1.3156 | train/val/test=0.841/0.841/0.843 | c=0.998347
[Epoch 0050] loss=17.2962 cls=0.4572 smmd=0.1369 ct=7.5199 rec=1.3168 | train/val/test=0.839/0.838/0.840 | c=0.998347
[Epoch 0051] loss=17.3038 cls=0.4589 smmd=0.1406 ct=7.5050 rec=1.3164 | train/val/test=0.840/0.841/0.843 | c=0.998347
[Epoch 0052] loss=17.2619 cls=0.4595 smmd=0.1331 ct=7.5214 rec=1.3171 | train/val/test=0.840/0.840/0.841 | c=0.998347
[Epoch 0053] loss=17.2592 cls=0.4598 smmd=0.1354 ct=7.5081 rec=1.3175 | train/val/test=0.841/0.842/0.844 | c=0.998347
[Epoch 0054] loss=17.2332 cls=0.4607 smmd=0.1324 ct=7.5097 rec=1.3183 | train/val/test=0.839/0.839/0.839 | c=0.998347
[Epoch 0055] loss=17.2099 cls=0.4637 smmd=0.1290 ct=7.5146 rec=1.3176 | train/val/test=0.841/0.840/0.844 | c=0.998347
[Epoch 0056] loss=17.1420 cls=0.4619 smmd=0.1239 ct=7.5062 rec=1.3194 | train/val/test=0.840/0.841/0.844 | c=0.998347
[Epoch 0057] loss=17.1773 cls=0.4634 smmd=0.1270 ct=7.5083 rec=1.3190 | train/val/test=0.841/0.841/0.843 | c=0.998347
[Epoch 0058] loss=17.2136 cls=0.4635 smmd=0.1309 ct=7.5066 rec=1.3198 | train/val/test=0.839/0.838/0.840 | c=0.998347
[Epoch 0059] loss=17.2085 cls=0.4647 smmd=0.1300 ct=7.5084 rec=1.3194 | train/val/test=0.841/0.841/0.843 | c=0.998347
[Epoch 0060] loss=17.1838 cls=0.4625 smmd=0.1284 ct=7.5044 rec=1.3198 | train/val/test=0.839/0.837/0.841 | c=0.998347
[Epoch 0061] loss=17.1738 cls=0.4630 smmd=0.1290 ct=7.4962 rec=1.3190 | train/val/test=0.839/0.839/0.841 | c=0.998347
[Epoch 0062] loss=17.1352 cls=0.4612 smmd=0.1242 ct=7.5017 rec=1.3191 | train/val/test=0.840/0.839/0.841 | c=0.998347
[Epoch 0063] loss=17.1539 cls=0.4618 smmd=0.1277 ct=7.4936 rec=1.3186 | train/val/test=0.838/0.837/0.840 | c=0.998347
[Epoch 0064] loss=17.0888 cls=0.4620 smmd=0.1206 ct=7.4962 rec=1.3195 | train/val/test=0.841/0.842/0.846 | c=0.998347
[Epoch 0065] loss=17.0815 cls=0.4630 smmd=0.1201 ct=7.4945 rec=1.3206 | train/val/test=0.835/0.830/0.837 | c=0.998347
[Epoch 0066] loss=17.1178 cls=0.4676 smmd=0.1250 ct=7.4870 rec=1.3206 | train/val/test=0.840/0.841/0.844 | c=0.998347
[Epoch 0067] loss=17.0903 cls=0.4680 smmd=0.1192 ct=7.5015 rec=1.3233 | train/val/test=0.828/0.822/0.829 | c=0.998347
[Epoch 0068] loss=17.0327 cls=0.4755 smmd=0.1170 ct=7.4813 rec=1.3241 | train/val/test=0.833/0.835/0.836 | c=0.998347
[Epoch 0069] loss=17.1065 cls=0.4803 smmd=0.1196 ct=7.5033 rec=1.3266 | train/val/test=0.814/0.807/0.817 | c=0.998347
[Epoch 0070] loss=17.2458 cls=0.4929 smmd=0.1375 ct=7.4799 rec=1.3297 | train/val/test=0.821/0.811/0.821 | c=0.998347
[Epoch 0071] loss=17.3191 cls=0.4983 smmd=0.1399 ct=7.5026 rec=1.3319 | train/val/test=0.802/0.792/0.802 | c=0.998347
[Epoch 0072] loss=17.4274 cls=0.5146 smmd=0.1547 ct=7.4780 rec=1.3346 | train/val/test=0.812/0.800/0.813 | c=0.998347
[Epoch 0073] loss=17.4064 cls=0.5038 smmd=0.1494 ct=7.4969 rec=1.3331 | train/val/test=0.813/0.808/0.817 | c=0.998347
[Epoch 0074] loss=17.2728 cls=0.4932 smmd=0.1424 ct=7.4693 rec=1.3264 | train/val/test=0.837/0.834/0.842 | c=0.998347
[Epoch 0075] loss=17.1315 cls=0.4662 smmd=0.1294 ct=7.4719 rec=1.3206 | train/val/test=0.836/0.832/0.838 | c=0.998347
[Epoch 0076] loss=17.0708 cls=0.4601 smmd=0.1261 ct=7.4605 rec=1.3181 | train/val/test=0.839/0.835/0.839 | c=0.998347
[Epoch 0077] loss=17.0188 cls=0.4619 smmd=0.1208 ct=7.4600 rec=1.3197 | train/val/test=0.842/0.841/0.845 | c=0.998347
[Epoch 0078] loss=17.0299 cls=0.4662 smmd=0.1215 ct=7.4602 rec=1.3236 | train/val/test=0.837/0.831/0.838 | c=0.998347
[Epoch 0079] loss=16.9935 cls=0.4766 smmd=0.1173 ct=7.4590 rec=1.3280 | train/val/test=0.840/0.842/0.846 | c=0.998347
[Epoch 0080] loss=17.0233 cls=0.4821 smmd=0.1193 ct=7.4620 rec=1.3313 | train/val/test=0.832/0.829/0.835 | c=0.998347
[Epoch 0081] loss=17.1033 cls=0.4933 smmd=0.1273 ct=7.4578 rec=1.3359 | train/val/test=0.838/0.837/0.842 | c=0.998347
[Epoch 0082] loss=17.1929 cls=0.4928 smmd=0.1359 ct=7.4598 rec=1.3355 | train/val/test=0.825/0.817/0.829 | c=0.998347
[Epoch 0083] loss=17.2489 cls=0.4996 smmd=0.1424 ct=7.4531 rec=1.3383 | train/val/test=0.830/0.828/0.831 | c=0.998347
[Epoch 0084] loss=17.2538 cls=0.4982 smmd=0.1425 ct=7.4561 rec=1.3355 | train/val/test=0.820/0.812/0.822 | c=0.998347
[Epoch 0085] loss=17.1766 cls=0.4996 smmd=0.1379 ct=7.4402 rec=1.3358 | train/val/test=0.829/0.825/0.828 | c=0.998347
[Epoch 0086] loss=17.1461 cls=0.4949 smmd=0.1314 ct=7.4592 rec=1.3329 | train/val/test=0.821/0.816/0.825 | c=0.998347
[Epoch 0087] loss=17.1481 cls=0.4899 smmd=0.1389 ct=7.4249 rec=1.3293 | train/val/test=0.834/0.834/0.837 | c=0.998347
[Epoch 0088] loss=17.0320 cls=0.4797 smmd=0.1219 ct=7.4545 rec=1.3280 | train/val/test=0.830/0.823/0.834 | c=0.998347
[Epoch 0089] loss=16.9706 cls=0.4776 smmd=0.1213 ct=7.4283 rec=1.3248 | train/val/test=0.842/0.841/0.846 | c=0.998347
[Epoch 0090] loss=16.9496 cls=0.4716 smmd=0.1176 ct=7.4372 rec=1.3267 | train/val/test=0.838/0.835/0.838 | c=0.998347
[Epoch 0091] loss=16.8764 cls=0.4769 smmd=0.1105 ct=7.4345 rec=1.3270 | train/val/test=0.841/0.836/0.843 | c=0.998347
[Epoch 0092] loss=16.8665 cls=0.4788 smmd=0.1084 ct=7.4390 rec=1.3313 | train/val/test=0.843/0.838/0.843 | c=0.998347
[Epoch 0093] loss=16.9289 cls=0.4831 smmd=0.1156 ct=7.4327 rec=1.3316 | train/val/test=0.838/0.835/0.840 | c=0.998347
[Epoch 0094] loss=17.0254 cls=0.4855 smmd=0.1230 ct=7.4425 rec=1.3351 | train/val/test=0.842/0.841/0.845 | c=0.998347
[Epoch 0095] loss=17.0756 cls=0.4837 smmd=0.1302 ct=7.4329 rec=1.3316 | train/val/test=0.836/0.833/0.836 | c=0.998347
[Epoch 0096] loss=17.0773 cls=0.4813 smmd=0.1294 ct=7.4382 rec=1.3333 | train/val/test=0.839/0.840/0.846 | c=0.998347
[Epoch 0097] loss=16.9813 cls=0.4785 smmd=0.1215 ct=7.4317 rec=1.3265 | train/val/test=0.833/0.831/0.835 | c=0.998347
[Epoch 0098] loss=16.9214 cls=0.4722 smmd=0.1160 ct=7.4308 rec=1.3277 | train/val/test=0.837/0.841/0.840 | c=0.998347
[Epoch 0099] loss=16.9132 cls=0.4758 smmd=0.1156 ct=7.4291 rec=1.3228 | train/val/test=0.828/0.824/0.830 | c=0.998347
=== Best @ epoch 79: val=0.8423, test=0.8463 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3 - 2025-09-21 05:18:41:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.6926 cls=1.1081 smmd=5.6917 ct=7.2575 rec=1.4136 | train/val/test=0.395/0.406/0.400 | c=0.998347
[Epoch 0001] loss=53.7735 cls=1.0679 smmd=3.8120 ct=7.2059 rec=1.4149 | train/val/test=0.398/0.408/0.403 | c=0.998347
[Epoch 0002] loss=38.0295 cls=1.0774 smmd=2.2502 ct=7.1410 rec=1.4137 | train/val/test=0.494/0.501/0.504 | c=0.998347
[Epoch 0003] loss=41.2487 cls=1.0559 smmd=2.5779 ct=7.1175 rec=1.4138 | train/val/test=0.528/0.517/0.535 | c=0.998347
[Epoch 0004] loss=40.9552 cls=1.0160 smmd=2.5640 ct=7.0501 rec=1.4146 | train/val/test=0.532/0.522/0.531 | c=0.998347
[Epoch 0005] loss=36.2261 cls=0.9702 smmd=2.1077 ct=6.9780 rec=1.4163 | train/val/test=0.554/0.555/0.555 | c=0.998347
[Epoch 0006] loss=30.5912 cls=0.9278 smmd=1.5544 ct=6.9377 rec=1.4165 | train/val/test=0.576/0.577/0.575 | c=0.998347
[Epoch 0007] loss=34.1195 cls=0.8750 smmd=1.9121 ct=6.9277 rec=1.4103 | train/val/test=0.670/0.663/0.661 | c=0.998347
[Epoch 0008] loss=36.6471 cls=0.8188 smmd=2.0257 ct=7.6404 rec=1.4001 | train/val/test=0.709/0.697/0.707 | c=0.998347
[Epoch 0009] loss=30.0591 cls=0.7698 smmd=1.3954 ct=7.5130 rec=1.3886 | train/val/test=0.710/0.696/0.710 | c=0.998347
[Epoch 0010] loss=28.5107 cls=0.7329 smmd=1.2435 ct=7.5095 rec=1.3801 | train/val/test=0.731/0.720/0.733 | c=0.998347
[Epoch 0011] loss=30.7847 cls=0.6985 smmd=1.4724 ct=7.5134 rec=1.3691 | train/val/test=0.740/0.735/0.734 | c=0.998347
[Epoch 0012] loss=28.0185 cls=0.6796 smmd=1.1917 ct=7.5411 rec=1.3593 | train/val/test=0.752/0.742/0.745 | c=0.998347
[Epoch 0013] loss=26.9314 cls=0.6564 smmd=1.0745 ct=7.5906 rec=1.3539 | train/val/test=0.752/0.741/0.753 | c=0.998347
[Epoch 0014] loss=26.0687 cls=0.6301 smmd=0.9890 ct=7.5941 rec=1.3504 | train/val/test=0.742/0.727/0.747 | c=0.998347
[Epoch 0015] loss=25.9452 cls=0.6224 smmd=0.9853 ct=7.5541 rec=1.3460 | train/val/test=0.768/0.756/0.769 | c=0.998347
[Epoch 0016] loss=25.3283 cls=0.5994 smmd=0.9355 ct=7.5031 rec=1.3355 | train/val/test=0.790/0.783/0.792 | c=0.998347
[Epoch 0017] loss=23.9139 cls=0.5924 smmd=0.7862 ct=7.5445 rec=1.3344 | train/val/test=0.797/0.791/0.799 | c=0.998347
[Epoch 0018] loss=23.6296 cls=0.5719 smmd=0.7493 ct=7.5925 rec=1.3312 | train/val/test=0.800/0.786/0.804 | c=0.998347
[Epoch 0019] loss=23.2251 cls=0.5480 smmd=0.7103 ct=7.5923 rec=1.3275 | train/val/test=0.798/0.792/0.802 | c=0.998347
[Epoch 0020] loss=22.7140 cls=0.5358 smmd=0.6670 ct=7.5566 rec=1.3250 | train/val/test=0.807/0.798/0.812 | c=0.998347
[Epoch 0021] loss=21.8989 cls=0.5230 smmd=0.5953 ct=7.5128 rec=1.3183 | train/val/test=0.813/0.809/0.812 | c=0.998347
[Epoch 0022] loss=21.8837 cls=0.5127 smmd=0.5903 ct=7.5328 rec=1.3172 | train/val/test=0.815/0.818/0.819 | c=0.998347
[Epoch 0023] loss=21.3415 cls=0.4985 smmd=0.5271 ct=7.5813 rec=1.3176 | train/val/test=0.819/0.815/0.824 | c=0.998347
[Epoch 0024] loss=20.7673 cls=0.4863 smmd=0.4738 ct=7.5643 rec=1.3154 | train/val/test=0.817/0.814/0.820 | c=0.998347
[Epoch 0025] loss=20.7846 cls=0.4840 smmd=0.4788 ct=7.5480 rec=1.3170 | train/val/test=0.826/0.819/0.827 | c=0.998347
[Epoch 0026] loss=20.1885 cls=0.4776 smmd=0.4234 ct=7.5293 rec=1.3143 | train/val/test=0.827/0.826/0.830 | c=0.998347
[Epoch 0027] loss=20.1600 cls=0.4780 smmd=0.4199 ct=7.5326 rec=1.3146 | train/val/test=0.830/0.828/0.831 | c=0.998347
[Epoch 0028] loss=19.8125 cls=0.4657 smmd=0.3796 ct=7.5634 rec=1.3144 | train/val/test=0.830/0.825/0.833 | c=0.998347
[Epoch 0029] loss=19.8104 cls=0.4651 smmd=0.3797 ct=7.5620 rec=1.3133 | train/val/test=0.831/0.829/0.834 | c=0.998347
[Epoch 0030] loss=19.2493 cls=0.4591 smmd=0.3289 ct=7.5372 rec=1.3129 | train/val/test=0.833/0.833/0.835 | c=0.998347
[Epoch 0031] loss=19.2229 cls=0.4544 smmd=0.3277 ct=7.5308 rec=1.3132 | train/val/test=0.832/0.833/0.834 | c=0.998347
[Epoch 0032] loss=19.0970 cls=0.4633 smmd=0.3123 ct=7.5435 rec=1.3114 | train/val/test=0.835/0.834/0.837 | c=0.998347
[Epoch 0033] loss=18.8082 cls=0.4514 smmd=0.2830 ct=7.5487 rec=1.3096 | train/val/test=0.829/0.830/0.831 | c=0.998347
[Epoch 0034] loss=18.6899 cls=0.4540 smmd=0.2735 ct=7.5365 rec=1.3105 | train/val/test=0.835/0.837/0.840 | c=0.998347
[Epoch 0035] loss=18.5504 cls=0.4524 smmd=0.2605 ct=7.5318 rec=1.3117 | train/val/test=0.838/0.836/0.840 | c=0.998347
[Epoch 0036] loss=18.3553 cls=0.4476 smmd=0.2416 ct=7.5303 rec=1.3091 | train/val/test=0.836/0.833/0.837 | c=0.998347
[Epoch 0037] loss=18.3083 cls=0.4497 smmd=0.2370 ct=7.5298 rec=1.3077 | train/val/test=0.839/0.840/0.842 | c=0.998347
[Epoch 0038] loss=18.1680 cls=0.4492 smmd=0.2212 ct=7.5378 rec=1.3114 | train/val/test=0.832/0.832/0.835 | c=0.998347
[Epoch 0039] loss=18.0580 cls=0.4519 smmd=0.2123 ct=7.5263 rec=1.3117 | train/val/test=0.839/0.839/0.844 | c=0.998347
[Epoch 0040] loss=17.9254 cls=0.4495 smmd=0.1989 ct=7.5275 rec=1.3128 | train/val/test=0.839/0.838/0.841 | c=0.998347
[Epoch 0041] loss=17.7947 cls=0.4496 smmd=0.1843 ct=7.5354 rec=1.3126 | train/val/test=0.836/0.833/0.835 | c=0.998347
[Epoch 0042] loss=17.8427 cls=0.4557 smmd=0.1919 ct=7.5198 rec=1.3114 | train/val/test=0.841/0.839/0.841 | c=0.998347
[Epoch 0043] loss=17.6826 cls=0.4501 smmd=0.1752 ct=7.5241 rec=1.3152 | train/val/test=0.838/0.834/0.840 | c=0.998347
[Epoch 0044] loss=17.6403 cls=0.4523 smmd=0.1694 ct=7.5316 rec=1.3144 | train/val/test=0.840/0.838/0.841 | c=0.998347
[Epoch 0045] loss=17.5679 cls=0.4538 smmd=0.1646 ct=7.5190 rec=1.3143 | train/val/test=0.838/0.835/0.839 | c=0.998347
[Epoch 0046] loss=17.5639 cls=0.4546 smmd=0.1643 ct=7.5181 rec=1.3149 | train/val/test=0.840/0.841/0.840 | c=0.998347
[Epoch 0047] loss=17.5212 cls=0.4558 smmd=0.1591 ct=7.5223 rec=1.3150 | train/val/test=0.840/0.839/0.839 | c=0.998347
[Epoch 0048] loss=17.3764 cls=0.4549 smmd=0.1455 ct=7.5178 rec=1.3171 | train/val/test=0.839/0.838/0.838 | c=0.998347
[Epoch 0049] loss=17.3974 cls=0.4580 smmd=0.1476 ct=7.5174 rec=1.3156 | train/val/test=0.841/0.841/0.843 | c=0.998347
[Epoch 0050] loss=17.2962 cls=0.4572 smmd=0.1369 ct=7.5199 rec=1.3168 | train/val/test=0.839/0.838/0.840 | c=0.998347
[Epoch 0051] loss=17.3038 cls=0.4589 smmd=0.1406 ct=7.5050 rec=1.3164 | train/val/test=0.840/0.841/0.843 | c=0.998347
[Epoch 0052] loss=17.2619 cls=0.4595 smmd=0.1331 ct=7.5214 rec=1.3171 | train/val/test=0.840/0.840/0.841 | c=0.998347
[Epoch 0053] loss=17.2592 cls=0.4598 smmd=0.1354 ct=7.5081 rec=1.3175 | train/val/test=0.841/0.842/0.844 | c=0.998347
[Epoch 0054] loss=17.2332 cls=0.4607 smmd=0.1324 ct=7.5097 rec=1.3183 | train/val/test=0.839/0.839/0.839 | c=0.998347
[Epoch 0055] loss=17.2099 cls=0.4637 smmd=0.1290 ct=7.5146 rec=1.3176 | train/val/test=0.841/0.840/0.844 | c=0.998347
[Epoch 0056] loss=17.1420 cls=0.4619 smmd=0.1239 ct=7.5062 rec=1.3194 | train/val/test=0.840/0.841/0.844 | c=0.998347
[Epoch 0057] loss=17.1773 cls=0.4634 smmd=0.1270 ct=7.5083 rec=1.3190 | train/val/test=0.841/0.841/0.843 | c=0.998347
[Epoch 0058] loss=17.2136 cls=0.4635 smmd=0.1309 ct=7.5066 rec=1.3198 | train/val/test=0.839/0.838/0.840 | c=0.998347
[Epoch 0059] loss=17.2085 cls=0.4647 smmd=0.1300 ct=7.5084 rec=1.3194 | train/val/test=0.841/0.841/0.843 | c=0.998347
[Epoch 0060] loss=17.1838 cls=0.4625 smmd=0.1284 ct=7.5044 rec=1.3198 | train/val/test=0.839/0.837/0.841 | c=0.998347
[Epoch 0061] loss=17.1738 cls=0.4630 smmd=0.1290 ct=7.4962 rec=1.3190 | train/val/test=0.839/0.839/0.841 | c=0.998347
[Epoch 0062] loss=17.1352 cls=0.4612 smmd=0.1242 ct=7.5017 rec=1.3191 | train/val/test=0.840/0.839/0.841 | c=0.998347
[Epoch 0063] loss=17.1539 cls=0.4618 smmd=0.1277 ct=7.4936 rec=1.3186 | train/val/test=0.838/0.837/0.840 | c=0.998347
[Epoch 0064] loss=17.0888 cls=0.4620 smmd=0.1206 ct=7.4962 rec=1.3195 | train/val/test=0.841/0.842/0.846 | c=0.998347
[Epoch 0065] loss=17.0815 cls=0.4630 smmd=0.1201 ct=7.4945 rec=1.3206 | train/val/test=0.835/0.830/0.837 | c=0.998347
[Epoch 0066] loss=17.1178 cls=0.4676 smmd=0.1250 ct=7.4870 rec=1.3206 | train/val/test=0.840/0.841/0.844 | c=0.998347
[Epoch 0067] loss=17.0903 cls=0.4680 smmd=0.1192 ct=7.5015 rec=1.3233 | train/val/test=0.828/0.822/0.829 | c=0.998347
[Epoch 0068] loss=17.0327 cls=0.4755 smmd=0.1170 ct=7.4813 rec=1.3241 | train/val/test=0.833/0.835/0.836 | c=0.998347
[Epoch 0069] loss=17.1065 cls=0.4803 smmd=0.1196 ct=7.5033 rec=1.3266 | train/val/test=0.814/0.807/0.817 | c=0.998347
[Epoch 0070] loss=17.2458 cls=0.4929 smmd=0.1375 ct=7.4799 rec=1.3297 | train/val/test=0.821/0.811/0.821 | c=0.998347
[Epoch 0071] loss=17.3191 cls=0.4983 smmd=0.1399 ct=7.5026 rec=1.3319 | train/val/test=0.802/0.792/0.802 | c=0.998347
[Epoch 0072] loss=17.4274 cls=0.5146 smmd=0.1547 ct=7.4780 rec=1.3346 | train/val/test=0.812/0.800/0.813 | c=0.998347
[Epoch 0073] loss=17.4064 cls=0.5038 smmd=0.1494 ct=7.4969 rec=1.3331 | train/val/test=0.813/0.808/0.817 | c=0.998347
[Epoch 0074] loss=17.2728 cls=0.4932 smmd=0.1424 ct=7.4693 rec=1.3264 | train/val/test=0.837/0.834/0.842 | c=0.998347
[Epoch 0075] loss=17.1315 cls=0.4662 smmd=0.1294 ct=7.4719 rec=1.3206 | train/val/test=0.836/0.832/0.838 | c=0.998347
[Epoch 0076] loss=17.0708 cls=0.4601 smmd=0.1261 ct=7.4605 rec=1.3181 | train/val/test=0.839/0.835/0.839 | c=0.998347
[Epoch 0077] loss=17.0188 cls=0.4619 smmd=0.1208 ct=7.4600 rec=1.3197 | train/val/test=0.842/0.841/0.845 | c=0.998347
[Epoch 0078] loss=17.0299 cls=0.4662 smmd=0.1215 ct=7.4602 rec=1.3236 | train/val/test=0.837/0.831/0.838 | c=0.998347
[Epoch 0079] loss=16.9935 cls=0.4766 smmd=0.1173 ct=7.4590 rec=1.3280 | train/val/test=0.840/0.842/0.846 | c=0.998347
[Epoch 0080] loss=17.0233 cls=0.4821 smmd=0.1193 ct=7.4620 rec=1.3313 | train/val/test=0.832/0.829/0.835 | c=0.998347
[Epoch 0081] loss=17.1033 cls=0.4933 smmd=0.1273 ct=7.4578 rec=1.3359 | train/val/test=0.838/0.837/0.842 | c=0.998347
[Epoch 0082] loss=17.1929 cls=0.4928 smmd=0.1359 ct=7.4598 rec=1.3355 | train/val/test=0.825/0.817/0.829 | c=0.998347
[Epoch 0083] loss=17.2489 cls=0.4996 smmd=0.1424 ct=7.4531 rec=1.3383 | train/val/test=0.830/0.828/0.831 | c=0.998347
[Epoch 0084] loss=17.2538 cls=0.4982 smmd=0.1425 ct=7.4561 rec=1.3355 | train/val/test=0.820/0.812/0.822 | c=0.998347
[Epoch 0085] loss=17.1766 cls=0.4996 smmd=0.1379 ct=7.4402 rec=1.3358 | train/val/test=0.829/0.825/0.828 | c=0.998347
[Epoch 0086] loss=17.1461 cls=0.4949 smmd=0.1314 ct=7.4592 rec=1.3329 | train/val/test=0.821/0.816/0.825 | c=0.998347
[Epoch 0087] loss=17.1481 cls=0.4899 smmd=0.1389 ct=7.4249 rec=1.3293 | train/val/test=0.834/0.834/0.837 | c=0.998347
[Epoch 0088] loss=17.0320 cls=0.4797 smmd=0.1219 ct=7.4545 rec=1.3280 | train/val/test=0.830/0.823/0.834 | c=0.998347
[Epoch 0089] loss=16.9706 cls=0.4776 smmd=0.1213 ct=7.4283 rec=1.3248 | train/val/test=0.842/0.841/0.846 | c=0.998347
[Epoch 0090] loss=16.9496 cls=0.4716 smmd=0.1176 ct=7.4372 rec=1.3267 | train/val/test=0.838/0.835/0.838 | c=0.998347
[Epoch 0091] loss=16.8764 cls=0.4769 smmd=0.1105 ct=7.4345 rec=1.3270 | train/val/test=0.841/0.836/0.843 | c=0.998347
[Epoch 0092] loss=16.8665 cls=0.4788 smmd=0.1084 ct=7.4390 rec=1.3313 | train/val/test=0.843/0.838/0.843 | c=0.998347
[Epoch 0093] loss=16.9289 cls=0.4831 smmd=0.1156 ct=7.4327 rec=1.3316 | train/val/test=0.838/0.835/0.840 | c=0.998347
[Epoch 0094] loss=17.0254 cls=0.4855 smmd=0.1230 ct=7.4425 rec=1.3351 | train/val/test=0.842/0.841/0.845 | c=0.998347
[Epoch 0095] loss=17.0756 cls=0.4837 smmd=0.1302 ct=7.4329 rec=1.3316 | train/val/test=0.836/0.833/0.836 | c=0.998347
[Epoch 0096] loss=17.0773 cls=0.4813 smmd=0.1294 ct=7.4382 rec=1.3333 | train/val/test=0.839/0.840/0.846 | c=0.998347
[Epoch 0097] loss=16.9813 cls=0.4785 smmd=0.1215 ct=7.4317 rec=1.3265 | train/val/test=0.833/0.831/0.835 | c=0.998347
[Epoch 0098] loss=16.9214 cls=0.4722 smmd=0.1160 ct=7.4308 rec=1.3277 | train/val/test=0.837/0.841/0.840 | c=0.998347
[Epoch 0099] loss=16.9132 cls=0.4758 smmd=0.1156 ct=7.4291 rec=1.3228 | train/val/test=0.828/0.824/0.830 | c=0.998347
=== Best @ epoch 79: val=0.8423, test=0.8463 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-3 completed in 192.16 seconds.
==================================================
