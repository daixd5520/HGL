Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-3 - 2025-09-21 03:35:02:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.4865 cls=1.0939 smmd=5.6732 ct=7.2503 rec=1.4136 | train/val/test=0.449/0.446/0.440 | c=0.998437
[Epoch 0001] loss=53.3130 cls=1.0605 smmd=3.7689 ct=7.1931 rec=1.4152 | train/val/test=0.527/0.528/0.522 | c=0.998437
[Epoch 0002] loss=37.7338 cls=1.0671 smmd=2.2206 ct=7.1437 rec=1.4138 | train/val/test=0.574/0.574/0.570 | c=0.998437
[Epoch 0003] loss=40.7575 cls=1.0538 smmd=2.5314 ct=7.1048 rec=1.4136 | train/val/test=0.571/0.574/0.570 | c=0.998437
[Epoch 0004] loss=40.4483 cls=1.0183 smmd=2.5080 ct=7.0760 rec=1.4142 | train/val/test=0.566/0.563/0.562 | c=0.998437
[Epoch 0005] loss=36.0122 cls=0.9853 smmd=2.0823 ct=6.9943 rec=1.4151 | train/val/test=0.565/0.563/0.561 | c=0.998437
[Epoch 0006] loss=30.2085 cls=0.9595 smmd=1.5133 ct=6.9446 rec=1.4137 | train/val/test=0.562/0.561/0.559 | c=0.998437
[Epoch 0007] loss=33.3277 cls=0.9248 smmd=1.8250 ct=6.9557 rec=1.4081 | train/val/test=0.567/0.566/0.567 | c=0.998437
[Epoch 0008] loss=35.8331 cls=0.8815 smmd=1.9515 ct=7.5886 rec=1.4000 | train/val/test=0.583/0.585/0.584 | c=0.998437
[Epoch 0009] loss=29.7630 cls=0.8380 smmd=1.3625 ct=7.5116 rec=1.3918 | train/val/test=0.600/0.609/0.600 | c=0.998437
[Epoch 0010] loss=28.0132 cls=0.8040 smmd=1.1852 ct=7.5330 rec=1.3863 | train/val/test=0.647/0.652/0.652 | c=0.998437
[Epoch 0011] loss=30.0139 cls=0.7696 smmd=1.3867 ct=7.5363 rec=1.3795 | train/val/test=0.695/0.699/0.698 | c=0.998437
[Epoch 0012] loss=27.5967 cls=0.7381 smmd=1.1499 ct=7.5214 rec=1.3711 | train/val/test=0.718/0.727/0.727 | c=0.998437
[Epoch 0013] loss=26.7532 cls=0.7221 smmd=1.0613 ct=7.5487 rec=1.3625 | train/val/test=0.725/0.736/0.729 | c=0.998437
[Epoch 0014] loss=25.1323 cls=0.6997 smmd=0.8975 ct=7.5640 rec=1.3595 | train/val/test=0.733/0.742/0.735 | c=0.998437
[Epoch 0015] loss=25.7201 cls=0.6570 smmd=0.9622 ct=7.5460 rec=1.3558 | train/val/test=0.720/0.729/0.729 | c=0.998437
[Epoch 0016] loss=24.9679 cls=0.6547 smmd=0.8892 ct=7.5357 rec=1.3536 | train/val/test=0.758/0.763/0.767 | c=0.998437
[Epoch 0017] loss=23.0414 cls=0.6239 smmd=0.7026 ct=7.5176 rec=1.3370 | train/val/test=0.766/0.767/0.768 | c=0.998437
[Epoch 0018] loss=23.4521 cls=0.6296 smmd=0.7403 ct=7.5339 rec=1.3332 | train/val/test=0.781/0.785/0.780 | c=0.998437
[Epoch 0019] loss=22.6232 cls=0.5942 smmd=0.6584 ct=7.5388 rec=1.3286 | train/val/test=0.790/0.793/0.795 | c=0.998437
[Epoch 0020] loss=22.2026 cls=0.5654 smmd=0.6183 ct=7.5375 rec=1.3245 | train/val/test=0.788/0.788/0.795 | c=0.998437
[Epoch 0021] loss=21.8058 cls=0.5519 smmd=0.5824 ct=7.5227 rec=1.3215 | train/val/test=0.793/0.792/0.799 | c=0.998437
[Epoch 0022] loss=21.2616 cls=0.5415 smmd=0.5320 ct=7.5059 rec=1.3182 | train/val/test=0.802/0.801/0.807 | c=0.998437
[Epoch 0023] loss=21.2234 cls=0.5396 smmd=0.5250 ct=7.5225 rec=1.3167 | train/val/test=0.808/0.808/0.814 | c=0.998437
[Epoch 0024] loss=20.5411 cls=0.5243 smmd=0.4543 ct=7.5389 rec=1.3160 | train/val/test=0.813/0.813/0.820 | c=0.998437
[Epoch 0025] loss=20.2716 cls=0.5046 smmd=0.4323 ct=7.5183 rec=1.3191 | train/val/test=0.812/0.816/0.820 | c=0.998437
[Epoch 0026] loss=20.1158 cls=0.4996 smmd=0.4185 ct=7.5108 rec=1.3193 | train/val/test=0.817/0.816/0.825 | c=0.998437
[Epoch 0027] loss=19.7570 cls=0.4984 smmd=0.3795 ct=7.5276 rec=1.3158 | train/val/test=0.822/0.823/0.829 | c=0.998437
[Epoch 0028] loss=19.6223 cls=0.4888 smmd=0.3677 ct=7.5213 rec=1.3166 | train/val/test=0.823/0.823/0.829 | c=0.998437
[Epoch 0029] loss=19.2810 cls=0.4797 smmd=0.3352 ct=7.5152 rec=1.3179 | train/val/test=0.825/0.825/0.832 | c=0.998437
[Epoch 0030] loss=19.1299 cls=0.4743 smmd=0.3211 ct=7.5112 rec=1.3180 | train/val/test=0.828/0.828/0.832 | c=0.998437
[Epoch 0031] loss=18.9679 cls=0.4691 smmd=0.3056 ct=7.5094 rec=1.3173 | train/val/test=0.831/0.828/0.832 | c=0.998437
[Epoch 0032] loss=18.6844 cls=0.4665 smmd=0.2770 ct=7.5120 rec=1.3143 | train/val/test=0.832/0.833/0.835 | c=0.998437
[Epoch 0033] loss=18.7044 cls=0.4665 smmd=0.2801 ct=7.5069 rec=1.3133 | train/val/test=0.833/0.830/0.836 | c=0.998437
[Epoch 0034] loss=18.3412 cls=0.4603 smmd=0.2462 ct=7.4962 rec=1.3136 | train/val/test=0.837/0.835/0.838 | c=0.998437
[Epoch 0035] loss=18.3700 cls=0.4582 smmd=0.2482 ct=7.5007 rec=1.3150 | train/val/test=0.839/0.835/0.839 | c=0.998437
[Epoch 0036] loss=18.1125 cls=0.4581 smmd=0.2221 ct=7.5028 rec=1.3137 | train/val/test=0.838/0.838/0.838 | c=0.998437
[Epoch 0037] loss=18.0720 cls=0.4596 smmd=0.2193 ct=7.4969 rec=1.3114 | train/val/test=0.839/0.837/0.837 | c=0.998437
[Epoch 0038] loss=18.0151 cls=0.4583 smmd=0.2146 ct=7.4921 rec=1.3120 | train/val/test=0.839/0.836/0.840 | c=0.998437
[Epoch 0039] loss=17.8614 cls=0.4570 smmd=0.1988 ct=7.4941 rec=1.3139 | train/val/test=0.839/0.838/0.839 | c=0.998437
[Epoch 0040] loss=17.7607 cls=0.4602 smmd=0.1883 ct=7.4956 rec=1.3128 | train/val/test=0.838/0.838/0.839 | c=0.998437
[Epoch 0041] loss=17.7681 cls=0.4602 smmd=0.1894 ct=7.4936 rec=1.3132 | train/val/test=0.839/0.836/0.839 | c=0.998437
[Epoch 0042] loss=17.6211 cls=0.4586 smmd=0.1752 ct=7.4915 rec=1.3147 | train/val/test=0.836/0.832/0.839 | c=0.998437
[Epoch 0043] loss=17.5527 cls=0.4610 smmd=0.1695 ct=7.4851 rec=1.3136 | train/val/test=0.838/0.835/0.841 | c=0.998437
[Epoch 0044] loss=17.4752 cls=0.4594 smmd=0.1613 ct=7.4876 rec=1.3144 | train/val/test=0.840/0.841/0.840 | c=0.998437
[Epoch 0045] loss=17.4436 cls=0.4610 smmd=0.1598 ct=7.4790 rec=1.3144 | train/val/test=0.835/0.830/0.840 | c=0.998437
[Epoch 0046] loss=17.3720 cls=0.4605 smmd=0.1524 ct=7.4800 rec=1.3161 | train/val/test=0.841/0.838/0.842 | c=0.998437
[Epoch 0047] loss=17.2977 cls=0.4598 smmd=0.1454 ct=7.4778 rec=1.3165 | train/val/test=0.838/0.836/0.842 | c=0.998437
[Epoch 0048] loss=17.2892 cls=0.4631 smmd=0.1448 ct=7.4754 rec=1.3172 | train/val/test=0.840/0.839/0.840 | c=0.998437
[Epoch 0049] loss=17.1949 cls=0.4633 smmd=0.1366 ct=7.4686 rec=1.3192 | train/val/test=0.840/0.839/0.840 | c=0.998437
[Epoch 0050] loss=17.1399 cls=0.4652 smmd=0.1316 ct=7.4657 rec=1.3206 | train/val/test=0.838/0.838/0.841 | c=0.998437
[Epoch 0051] loss=17.1069 cls=0.4676 smmd=0.1261 ct=7.4753 rec=1.3227 | train/val/test=0.843/0.840/0.840 | c=0.998437
[Epoch 0052] loss=17.1073 cls=0.4710 smmd=0.1289 ct=7.4606 rec=1.3230 | train/val/test=0.838/0.837/0.839 | c=0.998437
[Epoch 0053] loss=17.0848 cls=0.4713 smmd=0.1265 ct=7.4608 rec=1.3251 | train/val/test=0.841/0.839/0.839 | c=0.998437
[Epoch 0054] loss=17.0877 cls=0.4738 smmd=0.1261 ct=7.4633 rec=1.3256 | train/val/test=0.840/0.839/0.840 | c=0.998437
[Epoch 0055] loss=17.0320 cls=0.4735 smmd=0.1234 ct=7.4495 rec=1.3253 | train/val/test=0.841/0.839/0.840 | c=0.998437
[Epoch 0056] loss=17.0401 cls=0.4736 smmd=0.1219 ct=7.4604 rec=1.3262 | train/val/test=0.839/0.839/0.840 | c=0.998437
[Epoch 0057] loss=16.9990 cls=0.4734 smmd=0.1206 ct=7.4468 rec=1.3249 | train/val/test=0.840/0.836/0.838 | c=0.998437
[Epoch 0058] loss=16.9799 cls=0.4731 smmd=0.1181 ct=7.4499 rec=1.3255 | train/val/test=0.837/0.834/0.838 | c=0.998437
[Epoch 0059] loss=16.9718 cls=0.4728 smmd=0.1190 ct=7.4417 rec=1.3247 | train/val/test=0.840/0.838/0.841 | c=0.998437
[Epoch 0060] loss=16.9251 cls=0.4733 smmd=0.1142 ct=7.4422 rec=1.3244 | train/val/test=0.836/0.833/0.837 | c=0.998437
[Epoch 0061] loss=16.8963 cls=0.4731 smmd=0.1108 ct=7.4446 rec=1.3243 | train/val/test=0.840/0.837/0.839 | c=0.998437
[Epoch 0062] loss=16.9432 cls=0.4735 smmd=0.1166 ct=7.4393 rec=1.3243 | train/val/test=0.832/0.831/0.833 | c=0.998437
[Epoch 0063] loss=16.9920 cls=0.4767 smmd=0.1219 ct=7.4357 rec=1.3258 | train/val/test=0.837/0.835/0.835 | c=0.998437
[Epoch 0064] loss=16.9826 cls=0.4798 smmd=0.1194 ct=7.4433 rec=1.3249 | train/val/test=0.825/0.822/0.829 | c=0.998437
[Epoch 0065] loss=17.0242 cls=0.4842 smmd=0.1248 ct=7.4348 rec=1.3289 | train/val/test=0.836/0.834/0.833 | c=0.998437
[Epoch 0066] loss=16.9916 cls=0.4831 smmd=0.1200 ct=7.4437 rec=1.3250 | train/val/test=0.824/0.821/0.829 | c=0.998437
[Epoch 0067] loss=17.0702 cls=0.4835 smmd=0.1308 ct=7.4278 rec=1.3287 | train/val/test=0.836/0.834/0.832 | c=0.998437
[Epoch 0068] loss=17.0945 cls=0.4838 smmd=0.1312 ct=7.4393 rec=1.3232 | train/val/test=0.828/0.823/0.831 | c=0.998437
[Epoch 0069] loss=17.0120 cls=0.4764 smmd=0.1260 ct=7.4253 rec=1.3271 | train/val/test=0.838/0.834/0.834 | c=0.998437
[Epoch 0070] loss=16.9519 cls=0.4794 smmd=0.1189 ct=7.4315 rec=1.3201 | train/val/test=0.834/0.833/0.838 | c=0.998437
[Epoch 0071] loss=16.9796 cls=0.4684 smmd=0.1236 ct=7.4233 rec=1.3251 | train/val/test=0.839/0.839/0.836 | c=0.998437
[Epoch 0072] loss=16.9082 cls=0.4756 smmd=0.1169 ct=7.4207 rec=1.3207 | train/val/test=0.835/0.835/0.838 | c=0.998437
[Epoch 0073] loss=16.9007 cls=0.4721 smmd=0.1146 ct=7.4274 rec=1.3268 | train/val/test=0.840/0.839/0.837 | c=0.998437
[Epoch 0074] loss=16.9201 cls=0.4792 smmd=0.1172 ct=7.4233 rec=1.3230 | train/val/test=0.837/0.837/0.836 | c=0.998437
[Epoch 0075] loss=16.8902 cls=0.4763 smmd=0.1143 ct=7.4223 rec=1.3294 | train/val/test=0.841/0.839/0.839 | c=0.998437
[Epoch 0076] loss=16.9293 cls=0.4827 smmd=0.1163 ct=7.4315 rec=1.3245 | train/val/test=0.835/0.838/0.837 | c=0.998437
[Epoch 0077] loss=17.0063 cls=0.4809 smmd=0.1251 ct=7.4243 rec=1.3323 | train/val/test=0.838/0.840/0.838 | c=0.998437
[Epoch 0078] loss=17.0538 cls=0.4903 smmd=0.1280 ct=7.4333 rec=1.3242 | train/val/test=0.833/0.834/0.835 | c=0.998437
[Epoch 0079] loss=17.0546 cls=0.4819 smmd=0.1281 ct=7.4334 rec=1.3328 | train/val/test=0.836/0.837/0.833 | c=0.998437
[Epoch 0080] loss=17.0798 cls=0.4928 smmd=0.1325 ct=7.4237 rec=1.3225 | train/val/test=0.832/0.830/0.835 | c=0.998437
[Epoch 0081] loss=17.0723 cls=0.4782 smmd=0.1304 ct=7.4321 rec=1.3304 | train/val/test=0.835/0.835/0.831 | c=0.998437
[Epoch 0082] loss=17.0055 cls=0.4899 smmd=0.1242 ct=7.4291 rec=1.3204 | train/val/test=0.832/0.832/0.834 | c=0.998437
[Epoch 0083] loss=16.9695 cls=0.4731 smmd=0.1250 ct=7.4096 rec=1.3268 | train/val/test=0.840/0.840/0.836 | c=0.998437
[Epoch 0084] loss=16.8702 cls=0.4763 smmd=0.1110 ct=7.4306 rec=1.3207 | train/val/test=0.834/0.833/0.838 | c=0.998437
[Epoch 0085] loss=16.7958 cls=0.4725 smmd=0.1088 ct=7.4046 rec=1.3244 | train/val/test=0.841/0.840/0.839 | c=0.998437
[Epoch 0086] loss=16.7928 cls=0.4752 smmd=0.1062 ct=7.4152 rec=1.3264 | train/val/test=0.835/0.833/0.838 | c=0.998437
[Epoch 0087] loss=16.8294 cls=0.4826 smmd=0.1075 ct=7.4246 rec=1.3274 | train/val/test=0.838/0.838/0.841 | c=0.998437
[Epoch 0088] loss=16.8776 cls=0.4856 smmd=0.1147 ct=7.4108 rec=1.3329 | train/val/test=0.829/0.828/0.833 | c=0.998437
[Epoch 0089] loss=16.9690 cls=0.4922 smmd=0.1194 ct=7.4316 rec=1.3310 | train/val/test=0.837/0.837/0.838 | c=0.998437
[Epoch 0090] loss=17.0884 cls=0.4917 smmd=0.1337 ct=7.4187 rec=1.3363 | train/val/test=0.821/0.821/0.829 | c=0.998437
[Epoch 0091] loss=17.1483 cls=0.5011 smmd=0.1375 ct=7.4285 rec=1.3315 | train/val/test=0.827/0.827/0.832 | c=0.998437
[Epoch 0092] loss=17.1214 cls=0.4967 smmd=0.1354 ct=7.4250 rec=1.3371 | train/val/test=0.810/0.808/0.822 | c=0.998437
[Epoch 0093] loss=17.1409 cls=0.5120 smmd=0.1375 ct=7.4224 rec=1.3305 | train/val/test=0.820/0.818/0.824 | c=0.998437
[Epoch 0094] loss=17.1675 cls=0.4988 smmd=0.1397 ct=7.4274 rec=1.3325 | train/val/test=0.813/0.810/0.822 | c=0.998437
[Epoch 0095] loss=17.0635 cls=0.4977 smmd=0.1336 ct=7.4075 rec=1.3264 | train/val/test=0.833/0.831/0.829 | c=0.998437
[Epoch 0096] loss=16.9424 cls=0.4894 smmd=0.1194 ct=7.4214 rec=1.3218 | train/val/test=0.825/0.826/0.830 | c=0.998437
[Epoch 0097] loss=16.9514 cls=0.4793 smmd=0.1233 ct=7.4082 rec=1.3249 | train/val/test=0.834/0.833/0.829 | c=0.998437
[Epoch 0098] loss=16.9261 cls=0.4976 smmd=0.1179 ct=7.4188 rec=1.3209 | train/val/test=0.828/0.828/0.830 | c=0.998437
[Epoch 0099] loss=16.9939 cls=0.4891 smmd=0.1232 ct=7.4253 rec=1.3332 | train/val/test=0.830/0.827/0.828 | c=0.998437
=== Best @ epoch 44: val=0.8412, test=0.8398 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-3 - 2025-09-21 03:35:02:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.4865 cls=1.0939 smmd=5.6732 ct=7.2503 rec=1.4136 | train/val/test=0.449/0.446/0.440 | c=0.998437
[Epoch 0001] loss=53.3130 cls=1.0605 smmd=3.7689 ct=7.1931 rec=1.4152 | train/val/test=0.527/0.528/0.522 | c=0.998437
[Epoch 0002] loss=37.7338 cls=1.0671 smmd=2.2206 ct=7.1437 rec=1.4138 | train/val/test=0.574/0.574/0.570 | c=0.998437
[Epoch 0003] loss=40.7575 cls=1.0538 smmd=2.5314 ct=7.1048 rec=1.4136 | train/val/test=0.571/0.574/0.570 | c=0.998437
[Epoch 0004] loss=40.4483 cls=1.0183 smmd=2.5080 ct=7.0760 rec=1.4142 | train/val/test=0.566/0.563/0.562 | c=0.998437
[Epoch 0005] loss=36.0122 cls=0.9853 smmd=2.0823 ct=6.9943 rec=1.4151 | train/val/test=0.565/0.563/0.561 | c=0.998437
[Epoch 0006] loss=30.2085 cls=0.9595 smmd=1.5133 ct=6.9446 rec=1.4137 | train/val/test=0.562/0.561/0.559 | c=0.998437
[Epoch 0007] loss=33.3277 cls=0.9248 smmd=1.8250 ct=6.9557 rec=1.4081 | train/val/test=0.567/0.566/0.567 | c=0.998437
[Epoch 0008] loss=35.8331 cls=0.8815 smmd=1.9515 ct=7.5886 rec=1.4000 | train/val/test=0.583/0.585/0.584 | c=0.998437
[Epoch 0009] loss=29.7630 cls=0.8380 smmd=1.3625 ct=7.5116 rec=1.3918 | train/val/test=0.600/0.609/0.600 | c=0.998437
[Epoch 0010] loss=28.0132 cls=0.8040 smmd=1.1852 ct=7.5330 rec=1.3863 | train/val/test=0.647/0.652/0.652 | c=0.998437
[Epoch 0011] loss=30.0139 cls=0.7696 smmd=1.3867 ct=7.5363 rec=1.3795 | train/val/test=0.695/0.699/0.698 | c=0.998437
[Epoch 0012] loss=27.5967 cls=0.7381 smmd=1.1499 ct=7.5214 rec=1.3711 | train/val/test=0.718/0.727/0.727 | c=0.998437
[Epoch 0013] loss=26.7532 cls=0.7221 smmd=1.0613 ct=7.5487 rec=1.3625 | train/val/test=0.725/0.736/0.729 | c=0.998437
[Epoch 0014] loss=25.1323 cls=0.6997 smmd=0.8975 ct=7.5640 rec=1.3595 | train/val/test=0.733/0.742/0.735 | c=0.998437
[Epoch 0015] loss=25.7201 cls=0.6570 smmd=0.9622 ct=7.5460 rec=1.3558 | train/val/test=0.720/0.729/0.729 | c=0.998437
[Epoch 0016] loss=24.9679 cls=0.6547 smmd=0.8892 ct=7.5357 rec=1.3536 | train/val/test=0.758/0.763/0.767 | c=0.998437
[Epoch 0017] loss=23.0414 cls=0.6239 smmd=0.7026 ct=7.5176 rec=1.3370 | train/val/test=0.766/0.767/0.768 | c=0.998437
[Epoch 0018] loss=23.4521 cls=0.6296 smmd=0.7403 ct=7.5339 rec=1.3332 | train/val/test=0.781/0.785/0.780 | c=0.998437
[Epoch 0019] loss=22.6232 cls=0.5942 smmd=0.6584 ct=7.5388 rec=1.3286 | train/val/test=0.790/0.793/0.795 | c=0.998437
[Epoch 0020] loss=22.2026 cls=0.5654 smmd=0.6183 ct=7.5375 rec=1.3245 | train/val/test=0.788/0.788/0.795 | c=0.998437
[Epoch 0021] loss=21.8058 cls=0.5519 smmd=0.5824 ct=7.5227 rec=1.3215 | train/val/test=0.793/0.792/0.799 | c=0.998437
[Epoch 0022] loss=21.2616 cls=0.5415 smmd=0.5320 ct=7.5059 rec=1.3182 | train/val/test=0.802/0.801/0.807 | c=0.998437
[Epoch 0023] loss=21.2234 cls=0.5396 smmd=0.5250 ct=7.5225 rec=1.3167 | train/val/test=0.808/0.808/0.814 | c=0.998437
[Epoch 0024] loss=20.5411 cls=0.5243 smmd=0.4543 ct=7.5389 rec=1.3160 | train/val/test=0.813/0.813/0.820 | c=0.998437
[Epoch 0025] loss=20.2716 cls=0.5046 smmd=0.4323 ct=7.5183 rec=1.3191 | train/val/test=0.812/0.816/0.820 | c=0.998437
[Epoch 0026] loss=20.1158 cls=0.4996 smmd=0.4185 ct=7.5108 rec=1.3193 | train/val/test=0.817/0.816/0.825 | c=0.998437
[Epoch 0027] loss=19.7570 cls=0.4984 smmd=0.3795 ct=7.5276 rec=1.3158 | train/val/test=0.822/0.823/0.829 | c=0.998437
[Epoch 0028] loss=19.6223 cls=0.4888 smmd=0.3677 ct=7.5213 rec=1.3166 | train/val/test=0.823/0.823/0.829 | c=0.998437
[Epoch 0029] loss=19.2810 cls=0.4797 smmd=0.3352 ct=7.5152 rec=1.3179 | train/val/test=0.825/0.825/0.832 | c=0.998437
[Epoch 0030] loss=19.1299 cls=0.4743 smmd=0.3211 ct=7.5112 rec=1.3180 | train/val/test=0.828/0.828/0.832 | c=0.998437
[Epoch 0031] loss=18.9679 cls=0.4691 smmd=0.3056 ct=7.5094 rec=1.3173 | train/val/test=0.831/0.828/0.832 | c=0.998437
[Epoch 0032] loss=18.6844 cls=0.4665 smmd=0.2770 ct=7.5120 rec=1.3143 | train/val/test=0.832/0.833/0.835 | c=0.998437
[Epoch 0033] loss=18.7044 cls=0.4665 smmd=0.2801 ct=7.5069 rec=1.3133 | train/val/test=0.833/0.830/0.836 | c=0.998437
[Epoch 0034] loss=18.3412 cls=0.4603 smmd=0.2462 ct=7.4962 rec=1.3136 | train/val/test=0.837/0.835/0.838 | c=0.998437
[Epoch 0035] loss=18.3700 cls=0.4582 smmd=0.2482 ct=7.5007 rec=1.3150 | train/val/test=0.839/0.835/0.839 | c=0.998437
[Epoch 0036] loss=18.1125 cls=0.4581 smmd=0.2221 ct=7.5028 rec=1.3137 | train/val/test=0.838/0.838/0.838 | c=0.998437
[Epoch 0037] loss=18.0720 cls=0.4596 smmd=0.2193 ct=7.4969 rec=1.3114 | train/val/test=0.839/0.837/0.837 | c=0.998437
[Epoch 0038] loss=18.0151 cls=0.4583 smmd=0.2146 ct=7.4921 rec=1.3120 | train/val/test=0.839/0.836/0.840 | c=0.998437
[Epoch 0039] loss=17.8614 cls=0.4570 smmd=0.1988 ct=7.4941 rec=1.3139 | train/val/test=0.839/0.838/0.839 | c=0.998437
[Epoch 0040] loss=17.7607 cls=0.4602 smmd=0.1883 ct=7.4956 rec=1.3128 | train/val/test=0.838/0.838/0.839 | c=0.998437
[Epoch 0041] loss=17.7681 cls=0.4602 smmd=0.1894 ct=7.4936 rec=1.3132 | train/val/test=0.839/0.836/0.839 | c=0.998437
[Epoch 0042] loss=17.6211 cls=0.4586 smmd=0.1752 ct=7.4915 rec=1.3147 | train/val/test=0.836/0.832/0.839 | c=0.998437
[Epoch 0043] loss=17.5527 cls=0.4610 smmd=0.1695 ct=7.4851 rec=1.3136 | train/val/test=0.838/0.835/0.841 | c=0.998437
[Epoch 0044] loss=17.4752 cls=0.4594 smmd=0.1613 ct=7.4876 rec=1.3144 | train/val/test=0.840/0.841/0.840 | c=0.998437
[Epoch 0045] loss=17.4436 cls=0.4610 smmd=0.1598 ct=7.4790 rec=1.3144 | train/val/test=0.835/0.830/0.840 | c=0.998437
[Epoch 0046] loss=17.3720 cls=0.4605 smmd=0.1524 ct=7.4800 rec=1.3161 | train/val/test=0.841/0.838/0.842 | c=0.998437
[Epoch 0047] loss=17.2977 cls=0.4598 smmd=0.1454 ct=7.4778 rec=1.3165 | train/val/test=0.838/0.836/0.842 | c=0.998437
[Epoch 0048] loss=17.2892 cls=0.4631 smmd=0.1448 ct=7.4754 rec=1.3172 | train/val/test=0.840/0.839/0.840 | c=0.998437
[Epoch 0049] loss=17.1949 cls=0.4633 smmd=0.1366 ct=7.4686 rec=1.3192 | train/val/test=0.840/0.839/0.840 | c=0.998437
[Epoch 0050] loss=17.1399 cls=0.4652 smmd=0.1316 ct=7.4657 rec=1.3206 | train/val/test=0.838/0.838/0.841 | c=0.998437
[Epoch 0051] loss=17.1069 cls=0.4676 smmd=0.1261 ct=7.4753 rec=1.3227 | train/val/test=0.843/0.840/0.840 | c=0.998437
[Epoch 0052] loss=17.1073 cls=0.4710 smmd=0.1289 ct=7.4606 rec=1.3230 | train/val/test=0.838/0.837/0.839 | c=0.998437
[Epoch 0053] loss=17.0848 cls=0.4713 smmd=0.1265 ct=7.4608 rec=1.3251 | train/val/test=0.841/0.839/0.839 | c=0.998437
[Epoch 0054] loss=17.0877 cls=0.4738 smmd=0.1261 ct=7.4633 rec=1.3256 | train/val/test=0.840/0.839/0.840 | c=0.998437
[Epoch 0055] loss=17.0320 cls=0.4735 smmd=0.1234 ct=7.4495 rec=1.3253 | train/val/test=0.841/0.839/0.840 | c=0.998437
[Epoch 0056] loss=17.0401 cls=0.4736 smmd=0.1219 ct=7.4604 rec=1.3262 | train/val/test=0.839/0.839/0.840 | c=0.998437
[Epoch 0057] loss=16.9990 cls=0.4734 smmd=0.1206 ct=7.4468 rec=1.3249 | train/val/test=0.840/0.836/0.838 | c=0.998437
[Epoch 0058] loss=16.9799 cls=0.4731 smmd=0.1181 ct=7.4499 rec=1.3255 | train/val/test=0.837/0.834/0.838 | c=0.998437
[Epoch 0059] loss=16.9718 cls=0.4728 smmd=0.1190 ct=7.4417 rec=1.3247 | train/val/test=0.840/0.838/0.841 | c=0.998437
[Epoch 0060] loss=16.9251 cls=0.4733 smmd=0.1142 ct=7.4422 rec=1.3244 | train/val/test=0.836/0.833/0.837 | c=0.998437
[Epoch 0061] loss=16.8963 cls=0.4731 smmd=0.1108 ct=7.4446 rec=1.3243 | train/val/test=0.840/0.837/0.839 | c=0.998437
[Epoch 0062] loss=16.9432 cls=0.4735 smmd=0.1166 ct=7.4393 rec=1.3243 | train/val/test=0.832/0.831/0.833 | c=0.998437
[Epoch 0063] loss=16.9920 cls=0.4767 smmd=0.1219 ct=7.4357 rec=1.3258 | train/val/test=0.837/0.835/0.835 | c=0.998437
[Epoch 0064] loss=16.9826 cls=0.4798 smmd=0.1194 ct=7.4433 rec=1.3249 | train/val/test=0.825/0.822/0.829 | c=0.998437
[Epoch 0065] loss=17.0242 cls=0.4842 smmd=0.1248 ct=7.4348 rec=1.3289 | train/val/test=0.836/0.834/0.833 | c=0.998437
[Epoch 0066] loss=16.9916 cls=0.4831 smmd=0.1200 ct=7.4437 rec=1.3250 | train/val/test=0.824/0.821/0.829 | c=0.998437
[Epoch 0067] loss=17.0702 cls=0.4835 smmd=0.1308 ct=7.4278 rec=1.3287 | train/val/test=0.836/0.834/0.832 | c=0.998437
[Epoch 0068] loss=17.0945 cls=0.4838 smmd=0.1312 ct=7.4393 rec=1.3232 | train/val/test=0.828/0.823/0.831 | c=0.998437
[Epoch 0069] loss=17.0120 cls=0.4764 smmd=0.1260 ct=7.4253 rec=1.3271 | train/val/test=0.838/0.834/0.834 | c=0.998437
[Epoch 0070] loss=16.9519 cls=0.4794 smmd=0.1189 ct=7.4315 rec=1.3201 | train/val/test=0.834/0.833/0.838 | c=0.998437
[Epoch 0071] loss=16.9796 cls=0.4684 smmd=0.1236 ct=7.4233 rec=1.3251 | train/val/test=0.839/0.839/0.836 | c=0.998437
[Epoch 0072] loss=16.9082 cls=0.4756 smmd=0.1169 ct=7.4207 rec=1.3207 | train/val/test=0.835/0.835/0.838 | c=0.998437
[Epoch 0073] loss=16.9007 cls=0.4721 smmd=0.1146 ct=7.4274 rec=1.3268 | train/val/test=0.840/0.839/0.837 | c=0.998437
[Epoch 0074] loss=16.9201 cls=0.4792 smmd=0.1172 ct=7.4233 rec=1.3230 | train/val/test=0.837/0.837/0.836 | c=0.998437
[Epoch 0075] loss=16.8902 cls=0.4763 smmd=0.1143 ct=7.4223 rec=1.3294 | train/val/test=0.841/0.839/0.839 | c=0.998437
[Epoch 0076] loss=16.9293 cls=0.4827 smmd=0.1163 ct=7.4315 rec=1.3245 | train/val/test=0.835/0.838/0.837 | c=0.998437
[Epoch 0077] loss=17.0063 cls=0.4809 smmd=0.1251 ct=7.4243 rec=1.3323 | train/val/test=0.838/0.840/0.838 | c=0.998437
[Epoch 0078] loss=17.0538 cls=0.4903 smmd=0.1280 ct=7.4333 rec=1.3242 | train/val/test=0.833/0.834/0.835 | c=0.998437
[Epoch 0079] loss=17.0546 cls=0.4819 smmd=0.1281 ct=7.4334 rec=1.3328 | train/val/test=0.836/0.837/0.833 | c=0.998437
[Epoch 0080] loss=17.0798 cls=0.4928 smmd=0.1325 ct=7.4237 rec=1.3225 | train/val/test=0.832/0.830/0.835 | c=0.998437
[Epoch 0081] loss=17.0723 cls=0.4782 smmd=0.1304 ct=7.4321 rec=1.3304 | train/val/test=0.835/0.835/0.831 | c=0.998437
[Epoch 0082] loss=17.0055 cls=0.4899 smmd=0.1242 ct=7.4291 rec=1.3204 | train/val/test=0.832/0.832/0.834 | c=0.998437
[Epoch 0083] loss=16.9695 cls=0.4731 smmd=0.1250 ct=7.4096 rec=1.3268 | train/val/test=0.840/0.840/0.836 | c=0.998437
[Epoch 0084] loss=16.8702 cls=0.4763 smmd=0.1110 ct=7.4306 rec=1.3207 | train/val/test=0.834/0.833/0.838 | c=0.998437
[Epoch 0085] loss=16.7958 cls=0.4725 smmd=0.1088 ct=7.4046 rec=1.3244 | train/val/test=0.841/0.840/0.839 | c=0.998437
[Epoch 0086] loss=16.7928 cls=0.4752 smmd=0.1062 ct=7.4152 rec=1.3264 | train/val/test=0.835/0.833/0.838 | c=0.998437
[Epoch 0087] loss=16.8294 cls=0.4826 smmd=0.1075 ct=7.4246 rec=1.3274 | train/val/test=0.838/0.838/0.841 | c=0.998437
[Epoch 0088] loss=16.8776 cls=0.4856 smmd=0.1147 ct=7.4108 rec=1.3329 | train/val/test=0.829/0.828/0.833 | c=0.998437
[Epoch 0089] loss=16.9690 cls=0.4922 smmd=0.1194 ct=7.4316 rec=1.3310 | train/val/test=0.837/0.837/0.838 | c=0.998437
[Epoch 0090] loss=17.0884 cls=0.4917 smmd=0.1337 ct=7.4187 rec=1.3363 | train/val/test=0.821/0.821/0.829 | c=0.998437
[Epoch 0091] loss=17.1483 cls=0.5011 smmd=0.1375 ct=7.4285 rec=1.3315 | train/val/test=0.827/0.827/0.832 | c=0.998437
[Epoch 0092] loss=17.1214 cls=0.4967 smmd=0.1354 ct=7.4250 rec=1.3371 | train/val/test=0.810/0.808/0.822 | c=0.998437
[Epoch 0093] loss=17.1409 cls=0.5120 smmd=0.1375 ct=7.4224 rec=1.3305 | train/val/test=0.820/0.818/0.824 | c=0.998437
[Epoch 0094] loss=17.1675 cls=0.4988 smmd=0.1397 ct=7.4274 rec=1.3325 | train/val/test=0.813/0.810/0.822 | c=0.998437
[Epoch 0095] loss=17.0635 cls=0.4977 smmd=0.1336 ct=7.4075 rec=1.3264 | train/val/test=0.833/0.831/0.829 | c=0.998437
[Epoch 0096] loss=16.9424 cls=0.4894 smmd=0.1194 ct=7.4214 rec=1.3218 | train/val/test=0.825/0.826/0.830 | c=0.998437
[Epoch 0097] loss=16.9514 cls=0.4793 smmd=0.1233 ct=7.4082 rec=1.3249 | train/val/test=0.834/0.833/0.829 | c=0.998437
[Epoch 0098] loss=16.9261 cls=0.4976 smmd=0.1179 ct=7.4188 rec=1.3209 | train/val/test=0.828/0.828/0.830 | c=0.998437
[Epoch 0099] loss=16.9939 cls=0.4891 smmd=0.1232 ct=7.4253 rec=1.3332 | train/val/test=0.830/0.827/0.828 | c=0.998437
=== Best @ epoch 44: val=0.8412, test=0.8398 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-3 completed in 169.36 seconds.
==================================================
