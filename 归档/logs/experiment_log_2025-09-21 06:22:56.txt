Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-1 - 2025-09-21 06:22:56:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-1...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.8645 cls=1.7936 smmd=4.0950 ct=9.4780 rec=1.3917 | train/val/test=0.260/0.068/0.084 | c=0.998347
[Epoch 0001] loss=37.6575 cls=1.7858 smmd=3.9037 ct=9.4721 rec=1.3917 | train/val/test=0.180/0.058/0.077 | c=0.998347
[Epoch 0002] loss=36.4561 cls=1.7764 smmd=2.9612 ct=9.3450 rec=1.3917 | train/val/test=0.200/0.192/0.174 | c=0.998347
[Epoch 0003] loss=35.9461 cls=1.7598 smmd=2.5089 ct=9.3204 rec=1.3917 | train/val/test=0.500/0.206/0.252 | c=0.998347
[Epoch 0004] loss=35.2049 cls=1.7297 smmd=2.2354 ct=9.0947 rec=1.3915 | train/val/test=0.640/0.378/0.412 | c=0.998347
[Epoch 0005] loss=34.6145 cls=1.6928 smmd=1.7564 ct=9.0502 rec=1.3911 | train/val/test=0.640/0.496/0.499 | c=0.998347
[Epoch 0006] loss=34.5121 cls=1.6506 smmd=1.7406 ct=9.0217 rec=1.3903 | train/val/test=0.640/0.500/0.506 | c=0.998347
[Epoch 0007] loss=34.4067 cls=1.6069 smmd=1.6847 ct=9.0132 rec=1.3892 | train/val/test=0.680/0.492/0.500 | c=0.998347
[Epoch 0008] loss=34.0718 cls=1.5630 smmd=1.4061 ct=9.0021 rec=1.3880 | train/val/test=0.740/0.502/0.501 | c=0.998347
[Epoch 0009] loss=33.9125 cls=1.5223 smmd=1.2931 ct=8.9958 rec=1.3867 | train/val/test=0.700/0.500/0.506 | c=0.998347
[Epoch 0010] loss=35.2152 cls=1.4862 smmd=1.2787 ct=9.6704 rec=1.3853 | train/val/test=0.700/0.550/0.564 | c=0.998347
[Epoch 0011] loss=34.9304 cls=1.4459 smmd=1.2796 ct=9.5383 rec=1.3851 | train/val/test=0.720/0.548/0.565 | c=0.998347
[Epoch 0012] loss=34.8105 cls=1.4062 smmd=1.3812 ct=9.4398 rec=1.3847 | train/val/test=0.800/0.542/0.530 | c=0.998347
[Epoch 0013] loss=34.8188 cls=1.3710 smmd=1.3813 ct=9.4619 rec=1.3828 | train/val/test=0.740/0.584/0.573 | c=0.998347
[Epoch 0014] loss=34.5629 cls=1.3270 smmd=1.1162 ct=9.4813 rec=1.3821 | train/val/test=0.780/0.574/0.568 | c=0.998347
[Epoch 0015] loss=34.4373 cls=1.2792 smmd=0.8948 ct=9.5467 rec=1.3810 | train/val/test=0.840/0.554/0.545 | c=0.998347
[Epoch 0016] loss=34.3990 cls=1.2385 smmd=0.7862 ct=9.6091 rec=1.3775 | train/val/test=0.800/0.594/0.584 | c=0.998347
[Epoch 0017] loss=34.3274 cls=1.1845 smmd=0.9129 ct=9.5345 rec=1.3753 | train/val/test=0.880/0.626/0.595 | c=0.998347
[Epoch 0018] loss=34.1240 cls=1.1317 smmd=0.8583 ct=9.5070 rec=1.3686 | train/val/test=0.900/0.628/0.622 | c=0.998347
[Epoch 0019] loss=33.9812 cls=1.0762 smmd=0.7990 ct=9.5079 rec=1.3628 | train/val/test=0.820/0.626/0.617 | c=0.998347
[Epoch 0020] loss=33.9213 cls=1.0375 smmd=0.8183 ct=9.5134 rec=1.3557 | train/val/test=0.880/0.630/0.617 | c=0.998347
[Epoch 0021] loss=33.7030 cls=0.9905 smmd=0.6420 ct=9.5416 rec=1.3483 | train/val/test=0.900/0.626/0.624 | c=0.998347
[Epoch 0022] loss=33.5738 cls=0.9403 smmd=0.5572 ct=9.5650 rec=1.3416 | train/val/test=0.880/0.642/0.627 | c=0.998347
[Epoch 0023] loss=33.5226 cls=0.9164 smmd=0.6092 ct=9.5533 rec=1.3349 | train/val/test=0.900/0.642/0.634 | c=0.998347
[Epoch 0024] loss=33.3616 cls=0.8790 smmd=0.5464 ct=9.5456 rec=1.3285 | train/val/test=0.900/0.634/0.637 | c=0.998347
[Epoch 0025] loss=33.2980 cls=0.8354 smmd=0.5538 ct=9.5488 rec=1.3229 | train/val/test=0.900/0.638/0.642 | c=0.998347
[Epoch 0026] loss=33.2053 cls=0.8108 smmd=0.5471 ct=9.5345 rec=1.3184 | train/val/test=0.920/0.644/0.645 | c=0.998347
[Epoch 0027] loss=33.1189 cls=0.7758 smmd=0.5038 ct=9.5456 rec=1.3136 | train/val/test=0.960/0.642/0.644 | c=0.998347
[Epoch 0028] loss=33.0563 cls=0.7309 smmd=0.4588 ct=9.5694 rec=1.3093 | train/val/test=0.940/0.648/0.657 | c=0.998347
[Epoch 0029] loss=32.9468 cls=0.7006 smmd=0.4127 ct=9.5617 rec=1.3060 | train/val/test=0.940/0.658/0.655 | c=0.998347
[Epoch 0030] loss=32.8898 cls=0.6642 smmd=0.4337 ct=9.5521 rec=1.3020 | train/val/test=0.960/0.640/0.656 | c=0.998347
[Epoch 0031] loss=32.8071 cls=0.6247 smmd=0.4033 ct=9.5546 rec=1.2982 | train/val/test=0.940/0.650/0.661 | c=0.998347
[Epoch 0032] loss=32.7319 cls=0.5890 smmd=0.4089 ct=9.5461 rec=1.2936 | train/val/test=0.940/0.658/0.666 | c=0.998347
[Epoch 0033] loss=32.6517 cls=0.5594 smmd=0.3777 ct=9.5556 rec=1.2883 | train/val/test=0.940/0.648/0.666 | c=0.998347
[Epoch 0034] loss=32.5753 cls=0.5190 smmd=0.3562 ct=9.5658 rec=1.2828 | train/val/test=0.940/0.652/0.665 | c=0.998347
[Epoch 0035] loss=32.4864 cls=0.4965 smmd=0.3571 ct=9.5602 rec=1.2761 | train/val/test=0.940/0.658/0.676 | c=0.998347
[Epoch 0036] loss=32.3883 cls=0.4672 smmd=0.3534 ct=9.5546 rec=1.2692 | train/val/test=0.940/0.660/0.678 | c=0.998347
[Epoch 0037] loss=32.3213 cls=0.4412 smmd=0.3628 ct=9.5559 rec=1.2626 | train/val/test=0.940/0.666/0.675 | c=0.998347
[Epoch 0038] loss=32.2476 cls=0.4214 smmd=0.3612 ct=9.5547 rec=1.2566 | train/val/test=0.940/0.670/0.685 | c=0.998347
[Epoch 0039] loss=32.1641 cls=0.4018 smmd=0.3179 ct=9.5690 rec=1.2507 | train/val/test=0.940/0.676/0.683 | c=0.998347
[Epoch 0040] loss=32.1111 cls=0.3784 smmd=0.3426 ct=9.5566 rec=1.2466 | train/val/test=0.960/0.664/0.684 | c=0.998347
[Epoch 0041] loss=32.0496 cls=0.3697 smmd=0.3171 ct=9.5651 rec=1.2417 | train/val/test=0.940/0.684/0.698 | c=0.998347
[Epoch 0042] loss=32.0402 cls=0.3421 smmd=0.3614 ct=9.5528 rec=1.2402 | train/val/test=0.960/0.658/0.686 | c=0.998347
[Epoch 0043] loss=32.0322 cls=0.3509 smmd=0.3237 ct=9.5907 rec=1.2352 | train/val/test=0.960/0.678/0.691 | c=0.998347
[Epoch 0044] loss=32.0868 cls=0.3222 smmd=0.4081 ct=9.5590 rec=1.2400 | train/val/test=0.940/0.674/0.681 | c=0.998347
[Epoch 0045] loss=32.1044 cls=0.3484 smmd=0.3691 ct=9.6280 rec=1.2305 | train/val/test=0.960/0.694/0.699 | c=0.998347
[Epoch 0046] loss=31.9769 cls=0.3042 smmd=0.4306 ct=9.5563 rec=1.2281 | train/val/test=0.960/0.700/0.720 | c=0.998347
[Epoch 0047] loss=31.7803 cls=0.2881 smmd=0.3367 ct=9.5751 rec=1.2149 | train/val/test=0.960/0.684/0.713 | c=0.998347
[Epoch 0048] loss=31.8032 cls=0.2965 smmd=0.3333 ct=9.5964 rec=1.2129 | train/val/test=0.960/0.694/0.715 | c=0.998347
[Epoch 0049] loss=31.8335 cls=0.2710 smmd=0.4137 ct=9.5591 rec=1.2166 | train/val/test=0.960/0.698/0.723 | c=0.998347
[Epoch 0050] loss=31.7036 cls=0.2602 smmd=0.3329 ct=9.5838 rec=1.2073 | train/val/test=0.960/0.694/0.723 | c=0.998347
[Epoch 0051] loss=31.6682 cls=0.2616 smmd=0.3088 ct=9.5826 rec=1.2063 | train/val/test=0.960/0.688/0.721 | c=0.998347
[Epoch 0052] loss=31.7866 cls=0.2468 smmd=0.3978 ct=9.5559 rec=1.2154 | train/val/test=0.940/0.704/0.725 | c=0.998347
[Epoch 0053] loss=31.8121 cls=0.2674 smmd=0.3336 ct=9.6276 rec=1.2090 | train/val/test=0.960/0.696/0.727 | c=0.998347
[Epoch 0054] loss=31.6896 cls=0.2430 smmd=0.3770 ct=9.5568 rec=1.2078 | train/val/test=0.980/0.700/0.729 | c=0.998347
[Epoch 0055] loss=31.5394 cls=0.2310 smmd=0.2958 ct=9.5802 rec=1.1968 | train/val/test=0.980/0.700/0.726 | c=0.998347
[Epoch 0056] loss=31.5428 cls=0.2332 smmd=0.3016 ct=9.5881 rec=1.1948 | train/val/test=0.960/0.706/0.729 | c=0.998347
[Epoch 0057] loss=31.5999 cls=0.2255 smmd=0.3856 ct=9.5581 rec=1.1985 | train/val/test=0.960/0.702/0.725 | c=0.998347
[Epoch 0058] loss=31.5389 cls=0.2302 smmd=0.3107 ct=9.5958 rec=1.1921 | train/val/test=0.980/0.712/0.727 | c=0.998347
[Epoch 0059] loss=31.4345 cls=0.2134 smmd=0.2749 ct=9.5693 rec=1.1914 | train/val/test=0.980/0.710/0.728 | c=0.998347
[Epoch 0060] loss=31.4590 cls=0.2063 smmd=0.3027 ct=9.5622 rec=1.1929 | train/val/test=0.960/0.706/0.726 | c=0.998347
[Epoch 0061] loss=31.5109 cls=0.2208 smmd=0.2774 ct=9.5997 rec=1.1924 | train/val/test=0.980/0.704/0.728 | c=0.998347
[Epoch 0062] loss=31.5674 cls=0.2008 smmd=0.3598 ct=9.5566 rec=1.1994 | train/val/test=0.960/0.714/0.726 | c=0.998347
[Epoch 0063] loss=31.5663 cls=0.2254 smmd=0.3098 ct=9.6188 rec=1.1906 | train/val/test=0.960/0.708/0.730 | c=0.998347
[Epoch 0064] loss=31.4682 cls=0.1936 smmd=0.3594 ct=9.5596 rec=1.1893 | train/val/test=0.980/0.710/0.727 | c=0.998347
[Epoch 0065] loss=31.3325 cls=0.1930 smmd=0.2750 ct=9.5796 rec=1.1802 | train/val/test=0.980/0.718/0.725 | c=0.998347
[Epoch 0066] loss=31.3481 cls=0.2031 smmd=0.2778 ct=9.5866 rec=1.1796 | train/val/test=0.980/0.716/0.730 | c=0.998347
[Epoch 0067] loss=31.4195 cls=0.1785 smmd=0.3624 ct=9.5606 rec=1.1847 | train/val/test=0.960/0.708/0.724 | c=0.998347
[Epoch 0068] loss=31.3637 cls=0.1953 smmd=0.2804 ct=9.5916 rec=1.1802 | train/val/test=0.980/0.714/0.726 | c=0.998347
[Epoch 0069] loss=31.3155 cls=0.1799 smmd=0.2834 ct=9.5672 rec=1.1808 | train/val/test=0.980/0.704/0.719 | c=0.998347
[Epoch 0070] loss=31.3260 cls=0.1683 smmd=0.2732 ct=9.5640 rec=1.1841 | train/val/test=0.980/0.712/0.720 | c=0.998347
[Epoch 0071] loss=31.3847 cls=0.1935 smmd=0.2510 ct=9.5986 rec=1.1840 | train/val/test=0.980/0.712/0.724 | c=0.998347
[Epoch 0072] loss=31.5588 cls=0.1776 smmd=0.3920 ct=9.5569 rec=1.1964 | train/val/test=0.960/0.690/0.721 | c=0.998347
[Epoch 0073] loss=31.7758 cls=0.2443 smmd=0.3916 ct=9.6651 rec=1.1932 | train/val/test=0.940/0.716/0.725 | c=0.998347
[Epoch 0074] loss=31.6239 cls=0.1935 smmd=0.5113 ct=9.5703 rec=1.1875 | train/val/test=0.980/0.704/0.720 | c=0.998347
[Epoch 0075] loss=31.2410 cls=0.1651 smmd=0.3440 ct=9.5783 rec=1.1658 | train/val/test=0.960/0.702/0.724 | c=0.998347
[Epoch 0076] loss=31.5157 cls=0.2284 smmd=0.4156 ct=9.6364 rec=1.1713 | train/val/test=0.980/0.708/0.724 | c=0.998347
[Epoch 0077] loss=31.2796 cls=0.1599 smmd=0.4020 ct=9.5698 rec=1.1658 | train/val/test=0.980/0.708/0.724 | c=0.998347
[Epoch 0078] loss=31.3634 cls=0.1489 smmd=0.4403 ct=9.5641 rec=1.1720 | train/val/test=0.960/0.708/0.721 | c=0.998347
[Epoch 0079] loss=31.3800 cls=0.1877 smmd=0.3440 ct=9.6126 rec=1.1717 | train/val/test=0.980/0.704/0.722 | c=0.998347
[Epoch 0080] loss=31.2113 cls=0.1526 smmd=0.2675 ct=9.5739 rec=1.1720 | train/val/test=0.980/0.708/0.723 | c=0.998347
[Epoch 0081] loss=31.4412 cls=0.1545 smmd=0.3682 ct=9.5562 rec=1.1883 | train/val/test=0.960/0.694/0.718 | c=0.998347
[Epoch 0082] loss=31.7724 cls=0.2220 smmd=0.3812 ct=9.6679 rec=1.1944 | train/val/test=0.940/0.704/0.721 | c=0.998347
[Epoch 0083] loss=31.8099 cls=0.2107 smmd=0.5502 ct=9.5710 rec=1.2012 | train/val/test=0.960/0.716/0.720 | c=0.998347
[Epoch 0084] loss=31.3676 cls=0.1638 smmd=0.3502 ct=9.6163 rec=1.1703 | train/val/test=0.980/0.700/0.726 | c=0.998347
[Epoch 0085] loss=31.4585 cls=0.2205 smmd=0.4256 ct=9.6226 rec=1.1678 | train/val/test=0.980/0.706/0.722 | c=0.998347
[Epoch 0086] loss=31.3541 cls=0.1557 smmd=0.4992 ct=9.5678 rec=1.1641 | train/val/test=0.980/0.706/0.723 | c=0.998347
[Epoch 0087] loss=31.3933 cls=0.1306 smmd=0.5085 ct=9.5817 rec=1.1656 | train/val/test=0.960/0.700/0.723 | c=0.998347
[Epoch 0088] loss=31.3181 cls=0.1834 smmd=0.3976 ct=9.6033 rec=1.1622 | train/val/test=0.960/0.700/0.724 | c=0.998347
[Epoch 0089] loss=31.2767 cls=0.1808 smmd=0.3394 ct=9.5985 rec=1.1650 | train/val/test=0.980/0.710/0.723 | c=0.998347
[Epoch 0090] loss=31.4635 cls=0.1279 smmd=0.4650 ct=9.5676 rec=1.1799 | train/val/test=0.980/0.700/0.723 | c=0.998347
[Epoch 0091] loss=31.2566 cls=0.1573 smmd=0.3009 ct=9.5674 rec=1.1742 | train/val/test=0.960/0.708/0.720 | c=0.998347
[Epoch 0092] loss=31.5602 cls=0.1922 smmd=0.3513 ct=9.6307 rec=1.1851 | train/val/test=0.960/0.710/0.713 | c=0.998347
[Epoch 0093] loss=31.9082 cls=0.1966 smmd=0.5875 ct=9.5749 rec=1.2073 | train/val/test=0.960/0.708/0.719 | c=0.998347
[Epoch 0094] loss=31.5174 cls=0.1808 smmd=0.3578 ct=9.6422 rec=1.1785 | train/val/test=0.960/0.704/0.719 | c=0.998347
[Epoch 0095] loss=31.3873 cls=0.2183 smmd=0.4244 ct=9.5960 rec=1.1662 | train/val/test=0.980/0.714/0.722 | c=0.998347
[Epoch 0096] loss=31.4253 cls=0.1430 smmd=0.5531 ct=9.5677 rec=1.1665 | train/val/test=0.960/0.706/0.722 | c=0.998347
[Epoch 0097] loss=31.3804 cls=0.1242 smmd=0.5013 ct=9.5927 rec=1.1632 | train/val/test=0.960/0.702/0.723 | c=0.998347
[Epoch 0098] loss=31.3168 cls=0.1864 smmd=0.3995 ct=9.6097 rec=1.1605 | train/val/test=0.980/0.710/0.724 | c=0.998347
[Epoch 0099] loss=31.3132 cls=0.1781 smmd=0.4224 ct=9.5892 rec=1.1623 | train/val/test=0.980/0.706/0.721 | c=0.998347
[Epoch 0100] loss=31.3182 cls=0.1192 smmd=0.4413 ct=9.5650 rec=1.1687 | train/val/test=0.980/0.700/0.724 | c=0.998347
[Epoch 0101] loss=31.2810 cls=0.1390 smmd=0.3508 ct=9.5709 rec=1.1719 | train/val/test=0.980/0.708/0.721 | c=0.998347
[Epoch 0102] loss=31.5059 cls=0.1857 smmd=0.3868 ct=9.6144 rec=1.1797 | train/val/test=0.980/0.710/0.719 | c=0.998347
[Epoch 0103] loss=31.3724 cls=0.1383 smmd=0.3518 ct=9.5562 rec=1.1839 | train/val/test=0.980/0.700/0.723 | c=0.998347
[Epoch 0104] loss=31.4064 cls=0.1594 smmd=0.3463 ct=9.5887 rec=1.1803 | train/val/test=0.960/0.710/0.725 | c=0.998347
[Epoch 0105] loss=31.3760 cls=0.1819 smmd=0.3966 ct=9.5857 rec=1.1717 | train/val/test=0.980/0.706/0.725 | c=0.998347
[Epoch 0106] loss=31.1600 cls=0.1366 smmd=0.3018 ct=9.5643 rec=1.1661 | train/val/test=0.960/0.698/0.722 | c=0.998347
[Epoch 0107] loss=31.3246 cls=0.1486 smmd=0.3870 ct=9.5835 rec=1.1696 | train/val/test=0.960/0.708/0.721 | c=0.998347
[Epoch 0108] loss=31.1495 cls=0.1490 smmd=0.3133 ct=9.5724 rec=1.1617 | train/val/test=0.980/0.706/0.723 | c=0.998347
[Epoch 0109] loss=31.2394 cls=0.1470 smmd=0.3655 ct=9.5729 rec=1.1655 | train/val/test=0.980/0.702/0.719 | c=0.998347
[Epoch 0110] loss=31.2073 cls=0.1364 smmd=0.3159 ct=9.5747 rec=1.1674 | train/val/test=0.980/0.706/0.724 | c=0.998347
[Epoch 0111] loss=31.1967 cls=0.1309 smmd=0.2853 ct=9.5736 rec=1.1699 | train/val/test=0.980/0.704/0.720 | c=0.998347
[Epoch 0112] loss=31.3478 cls=0.1597 smmd=0.3654 ct=9.5737 rec=1.1755 | train/val/test=0.980/0.704/0.724 | c=0.998347
[Epoch 0113] loss=31.2096 cls=0.1364 smmd=0.2497 ct=9.5771 rec=1.1737 | train/val/test=0.980/0.700/0.724 | c=0.998347
[Epoch 0114] loss=31.2041 cls=0.1368 smmd=0.2779 ct=9.5576 rec=1.1743 | train/val/test=0.980/0.710/0.723 | c=0.998347
[Epoch 0115] loss=31.2711 cls=0.1519 smmd=0.3017 ct=9.5802 rec=1.1733 | train/val/test=0.980/0.702/0.722 | c=0.998347
[Epoch 0116] loss=31.1583 cls=0.1505 smmd=0.2672 ct=9.5655 rec=1.1685 | train/val/test=0.980/0.702/0.726 | c=0.998347
[Epoch 0117] loss=31.1766 cls=0.1327 smmd=0.2941 ct=9.5657 rec=1.1685 | train/val/test=0.980/0.710/0.720 | c=0.998347
[Epoch 0118] loss=31.1554 cls=0.1507 smmd=0.2780 ct=9.5715 rec=1.1659 | train/val/test=0.980/0.704/0.722 | c=0.998347
[Epoch 0119] loss=31.1157 cls=0.1482 smmd=0.2566 ct=9.5654 rec=1.1654 | train/val/test=0.980/0.704/0.725 | c=0.998347
[Epoch 0120] loss=31.1779 cls=0.1272 smmd=0.2763 ct=9.5687 rec=1.1700 | train/val/test=0.980/0.702/0.720 | c=0.998347
[Epoch 0121] loss=31.1509 cls=0.1483 smmd=0.2602 ct=9.5664 rec=1.1684 | train/val/test=0.980/0.704/0.722 | c=0.998347
[Epoch 0122] loss=31.1189 cls=0.1385 smmd=0.2231 ct=9.5657 rec=1.1695 | train/val/test=0.980/0.702/0.724 | c=0.998347
[Epoch 0123] loss=31.1787 cls=0.1307 smmd=0.2551 ct=9.5624 rec=1.1733 | train/val/test=0.980/0.708/0.721 | c=0.998347
[Epoch 0124] loss=31.1737 cls=0.1536 smmd=0.2356 ct=9.5738 rec=1.1714 | train/val/test=0.980/0.702/0.721 | c=0.998347
[Epoch 0125] loss=31.1410 cls=0.1390 smmd=0.2544 ct=9.5575 rec=1.1702 | train/val/test=0.980/0.704/0.725 | c=0.998347
[Epoch 0126] loss=31.1595 cls=0.1367 smmd=0.2417 ct=9.5746 rec=1.1700 | train/val/test=0.980/0.706/0.722 | c=0.998347
[Epoch 0127] loss=31.1987 cls=0.1637 smmd=0.3007 ct=9.5643 rec=1.1688 | train/val/test=0.960/0.710/0.725 | c=0.998347
[Epoch 0128] loss=31.1903 cls=0.1358 smmd=0.2709 ct=9.5830 rec=1.1686 | train/val/test=0.980/0.702/0.724 | c=0.998347
[Epoch 0129] loss=31.1745 cls=0.1491 smmd=0.2946 ct=9.5625 rec=1.1680 | train/val/test=0.960/0.708/0.722 | c=0.998347
[Epoch 0130] loss=31.1591 cls=0.1338 smmd=0.2713 ct=9.5783 rec=1.1664 | train/val/test=0.980/0.702/0.723 | c=0.998347
[Epoch 0131] loss=31.0848 cls=0.1323 smmd=0.2436 ct=9.5635 rec=1.1648 | train/val/test=0.980/0.702/0.724 | c=0.998347
[Epoch 0132] loss=31.1088 cls=0.1264 smmd=0.2542 ct=9.5588 rec=1.1674 | train/val/test=0.980/0.708/0.722 | c=0.998347
[Epoch 0133] loss=31.1647 cls=0.1345 smmd=0.2411 ct=9.5818 rec=1.1693 | train/val/test=0.980/0.700/0.723 | c=0.998347
[Epoch 0134] loss=31.1954 cls=0.1496 smmd=0.2860 ct=9.5550 rec=1.1725 | train/val/test=0.960/0.710/0.720 | c=0.998347
[Epoch 0135] loss=31.3130 cls=0.1487 smmd=0.2604 ct=9.6092 rec=1.1760 | train/val/test=0.940/0.702/0.723 | c=0.998347
[Epoch 0136] loss=31.4648 cls=0.2025 smmd=0.4296 ct=9.5709 rec=1.1792 | train/val/test=0.960/0.708/0.719 | c=0.998347
[Epoch 0137] loss=31.3035 cls=0.1558 smmd=0.3081 ct=9.6148 rec=1.1688 | train/val/test=0.980/0.702/0.722 | c=0.998347
[Epoch 0138] loss=31.0826 cls=0.1190 smmd=0.3050 ct=9.5609 rec=1.1596 | train/val/test=0.980/0.700/0.724 | c=0.998347
[Epoch 0139] loss=31.1675 cls=0.1400 smmd=0.3549 ct=9.5626 rec=1.1617 | train/val/test=0.960/0.710/0.720 | c=0.998347
[Epoch 0140] loss=31.1901 cls=0.1360 smmd=0.2950 ct=9.6028 rec=1.1621 | train/val/test=0.980/0.702/0.723 | c=0.998347
[Epoch 0141] loss=31.0837 cls=0.1089 smmd=0.2800 ct=9.5617 rec=1.1626 | train/val/test=0.980/0.702/0.725 | c=0.998347
[Epoch 0142] loss=31.2019 cls=0.1397 smmd=0.3237 ct=9.5570 rec=1.1694 | train/val/test=0.960/0.716/0.716 | c=0.998347
[Epoch 0143] loss=31.3759 cls=0.1506 smmd=0.2838 ct=9.6211 rec=1.1775 | train/val/test=0.960/0.700/0.724 | c=0.998347
[Epoch 0144] loss=31.3983 cls=0.1590 smmd=0.3852 ct=9.5567 rec=1.1820 | train/val/test=0.960/0.714/0.719 | c=0.998347
[Epoch 0145] loss=31.4685 cls=0.1890 smmd=0.3185 ct=9.6415 rec=1.1773 | train/val/test=0.980/0.704/0.724 | c=0.998347
[Epoch 0146] loss=31.4195 cls=0.1431 smmd=0.4515 ct=9.5686 rec=1.1759 | train/val/test=0.980/0.700/0.723 | c=0.998347
[Epoch 0147] loss=31.2617 cls=0.1818 smmd=0.3788 ct=9.5805 rec=1.1631 | train/val/test=0.960/0.714/0.721 | c=0.998347
[Epoch 0148] loss=31.2636 cls=0.1791 smmd=0.3627 ct=9.6147 rec=1.1582 | train/val/test=0.980/0.708/0.725 | c=0.998347
[Epoch 0149] loss=31.2349 cls=0.1236 smmd=0.4100 ct=9.5788 rec=1.1605 | train/val/test=0.980/0.704/0.725 | c=0.998347
[Epoch 0150] loss=31.2339 cls=0.1508 smmd=0.4122 ct=9.5643 rec=1.1618 | train/val/test=0.960/0.708/0.725 | c=0.998347
[Epoch 0151] loss=31.2357 cls=0.1564 smmd=0.3109 ct=9.6058 rec=1.1635 | train/val/test=0.980/0.704/0.723 | c=0.998347
[Epoch 0152] loss=31.2146 cls=0.1087 smmd=0.3245 ct=9.5686 rec=1.1699 | train/val/test=0.960/0.706/0.725 | c=0.998347
[Epoch 0153] loss=31.2937 cls=0.1554 smmd=0.3510 ct=9.5697 rec=1.1726 | train/val/test=0.960/0.708/0.715 | c=0.998347
[Epoch 0154] loss=31.3958 cls=0.1477 smmd=0.2824 ct=9.6224 rec=1.1795 | train/val/test=0.940/0.694/0.727 | c=0.998347
[Epoch 0155] loss=31.5635 cls=0.1755 smmd=0.4868 ct=9.5710 rec=1.1847 | train/val/test=0.980/0.700/0.725 | c=0.998347
[Epoch 0156] loss=31.3595 cls=0.2011 smmd=0.3481 ct=9.6095 rec=1.1692 | train/val/test=0.940/0.700/0.725 | c=0.998347
[Epoch 0157] loss=31.3583 cls=0.1324 smmd=0.4361 ct=9.5978 rec=1.1660 | train/val/test=0.980/0.700/0.724 | c=0.998347
[Epoch 0158] loss=31.3625 cls=0.1421 smmd=0.4981 ct=9.5786 rec=1.1636 | train/val/test=0.980/0.714/0.724 | c=0.998347
[Epoch 0159] loss=31.2936 cls=0.1877 smmd=0.4355 ct=9.5852 rec=1.1594 | train/val/test=0.940/0.702/0.723 | c=0.998347
[Epoch 0160] loss=31.4368 cls=0.1779 smmd=0.4699 ct=9.6136 rec=1.1651 | train/val/test=0.980/0.698/0.721 | c=0.998347
[Epoch 0161] loss=31.2506 cls=0.1106 smmd=0.4244 ct=9.5735 rec=1.1624 | train/val/test=0.980/0.710/0.719 | c=0.998347
[Epoch 0162] loss=31.2536 cls=0.1346 smmd=0.4104 ct=9.5731 rec=1.1630 | train/val/test=0.980/0.712/0.725 | c=0.998347
[Epoch 0163] loss=31.3301 cls=0.1401 smmd=0.3681 ct=9.5932 rec=1.1705 | train/val/test=0.980/0.700/0.720 | c=0.998347
[Epoch 0164] loss=31.2282 cls=0.1046 smmd=0.3166 ct=9.5730 rec=1.1713 | train/val/test=0.960/0.704/0.716 | c=0.998347
[Epoch 0165] loss=31.2378 cls=0.1356 smmd=0.3295 ct=9.5619 rec=1.1717 | train/val/test=0.980/0.710/0.721 | c=0.998347
[Epoch 0166] loss=31.3403 cls=0.1458 smmd=0.3206 ct=9.6036 rec=1.1739 | train/val/test=0.980/0.700/0.721 | c=0.998347
[Epoch 0167] loss=31.1656 cls=0.1252 smmd=0.3084 ct=9.5606 rec=1.1673 | train/val/test=0.980/0.704/0.719 | c=0.998347
[Epoch 0168] loss=31.1075 cls=0.1396 smmd=0.2889 ct=9.5579 rec=1.1633 | train/val/test=0.960/0.712/0.721 | c=0.998347
[Epoch 0169] loss=31.2386 cls=0.1602 smmd=0.3109 ct=9.5969 rec=1.1654 | train/val/test=0.980/0.702/0.719 | c=0.998347
[Epoch 0170] loss=31.1225 cls=0.1351 smmd=0.2991 ct=9.5642 rec=1.1627 | train/val/test=0.980/0.700/0.720 | c=0.998347
[Epoch 0171] loss=31.1250 cls=0.1233 smmd=0.3038 ct=9.5549 rec=1.1650 | train/val/test=0.960/0.708/0.723 | c=0.998347
[Epoch 0172] loss=31.2582 cls=0.1424 smmd=0.2948 ct=9.6010 rec=1.1690 | train/val/test=0.980/0.702/0.717 | c=0.998347
[Epoch 0173] loss=31.1607 cls=0.1230 smmd=0.2900 ct=9.5609 rec=1.1688 | train/val/test=0.980/0.700/0.719 | c=0.998347
[Epoch 0174] loss=31.1111 cls=0.1134 smmd=0.2521 ct=9.5572 rec=1.1688 | train/val/test=0.980/0.708/0.720 | c=0.998347
[Epoch 0175] loss=31.2361 cls=0.1396 smmd=0.2648 ct=9.5949 rec=1.1712 | train/val/test=0.980/0.702/0.715 | c=0.998347
[Epoch 0176] loss=31.2770 cls=0.1429 smmd=0.3479 ct=9.5582 rec=1.1741 | train/val/test=0.960/0.706/0.717 | c=0.998347
[Epoch 0177] loss=31.2060 cls=0.1518 smmd=0.2626 ct=9.5932 rec=1.1681 | train/val/test=0.980/0.706/0.722 | c=0.998347
[Epoch 0178] loss=31.2132 cls=0.1435 smmd=0.3324 ct=9.5661 rec=1.1677 | train/val/test=0.980/0.700/0.720 | c=0.998347
[Epoch 0179] loss=31.2487 cls=0.1634 smmd=0.3360 ct=9.5826 rec=1.1666 | train/val/test=0.980/0.702/0.725 | c=0.998347
[Epoch 0180] loss=31.1138 cls=0.1191 smmd=0.2931 ct=9.5682 rec=1.1625 | train/val/test=0.980/0.708/0.724 | c=0.998347
[Epoch 0181] loss=31.1050 cls=0.1367 smmd=0.2808 ct=9.5667 rec=1.1622 | train/val/test=0.980/0.700/0.720 | c=0.998347
[Epoch 0182] loss=31.1805 cls=0.1336 smmd=0.2916 ct=9.5774 rec=1.1667 | train/val/test=0.980/0.698/0.722 | c=0.998347
[Epoch 0183] loss=31.2154 cls=0.1096 smmd=0.3013 ct=9.5594 rec=1.1740 | train/val/test=0.980/0.702/0.724 | c=0.998347
[Epoch 0184] loss=31.3342 cls=0.1766 smmd=0.2880 ct=9.6045 rec=1.1749 | train/val/test=1.000/0.704/0.715 | c=0.998347
[Epoch 0185] loss=31.5379 cls=0.1383 smmd=0.4671 ct=9.5686 rec=1.1864 | train/val/test=0.960/0.702/0.720 | c=0.998347
[Epoch 0186] loss=31.4493 cls=0.2122 smmd=0.3281 ct=9.6357 rec=1.1744 | train/val/test=0.980/0.712/0.726 | c=0.998347
[Epoch 0187] loss=31.2147 cls=0.1808 smmd=0.3867 ct=9.5616 rec=1.1614 | train/val/test=0.980/0.704/0.724 | c=0.998347
[Epoch 0188] loss=31.1668 cls=0.1324 smmd=0.3787 ct=9.5692 rec=1.1583 | train/val/test=0.960/0.706/0.721 | c=0.998347
[Epoch 0189] loss=31.1809 cls=0.1628 smmd=0.3260 ct=9.5983 rec=1.1577 | train/val/test=0.980/0.704/0.726 | c=0.998347
[Epoch 0190] loss=31.1578 cls=0.1640 smmd=0.3318 ct=9.5774 rec=1.1589 | train/val/test=0.980/0.704/0.724 | c=0.998347
[Epoch 0191] loss=31.1573 cls=0.1145 smmd=0.3328 ct=9.5559 rec=1.1655 | train/val/test=0.960/0.700/0.718 | c=0.998347
[Epoch 0192] loss=31.2133 cls=0.1246 smmd=0.2715 ct=9.5897 rec=1.1700 | train/val/test=0.980/0.712/0.730 | c=0.998347
[Epoch 0193] loss=31.2529 cls=0.1472 smmd=0.2992 ct=9.5679 rec=1.1744 | train/val/test=0.980/0.704/0.718 | c=0.998347
[Epoch 0194] loss=31.1948 cls=0.1174 smmd=0.2573 ct=9.5703 rec=1.1738 | train/val/test=0.980/0.702/0.725 | c=0.998347
[Epoch 0195] loss=31.1138 cls=0.1209 smmd=0.2401 ct=9.5597 rec=1.1694 | train/val/test=0.980/0.712/0.722 | c=0.998347
[Epoch 0196] loss=31.1210 cls=0.1538 smmd=0.2487 ct=9.5660 rec=1.1663 | train/val/test=0.980/0.700/0.718 | c=0.998347
[Epoch 0197] loss=31.1318 cls=0.1306 smmd=0.2784 ct=9.5670 rec=1.1654 | train/val/test=0.980/0.704/0.722 | c=0.998347
[Epoch 0198] loss=31.0868 cls=0.1492 smmd=0.2604 ct=9.5637 rec=1.1624 | train/val/test=0.980/0.710/0.720 | c=0.998347
[Epoch 0199] loss=31.0871 cls=0.1485 smmd=0.2579 ct=9.5664 rec=1.1622 | train/val/test=0.980/0.700/0.720 | c=0.998347
=== Best @ epoch 65: val=0.7180, test=0.7250 ===

==================================================
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-1 - 2025-09-21 06:22:56:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-1...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.8645 cls=1.7936 smmd=4.0950 ct=9.4780 rec=1.3917 | train/val/test=0.260/0.068/0.084 | c=0.998347
[Epoch 0001] loss=37.6575 cls=1.7858 smmd=3.9037 ct=9.4721 rec=1.3917 | train/val/test=0.180/0.058/0.077 | c=0.998347
[Epoch 0002] loss=36.4561 cls=1.7764 smmd=2.9612 ct=9.3450 rec=1.3917 | train/val/test=0.200/0.192/0.174 | c=0.998347
[Epoch 0003] loss=35.9461 cls=1.7598 smmd=2.5089 ct=9.3204 rec=1.3917 | train/val/test=0.500/0.206/0.252 | c=0.998347
[Epoch 0004] loss=35.2049 cls=1.7297 smmd=2.2354 ct=9.0947 rec=1.3915 | train/val/test=0.640/0.378/0.412 | c=0.998347
[Epoch 0005] loss=34.6145 cls=1.6928 smmd=1.7564 ct=9.0502 rec=1.3911 | train/val/test=0.640/0.496/0.499 | c=0.998347
[Epoch 0006] loss=34.5121 cls=1.6506 smmd=1.7406 ct=9.0217 rec=1.3903 | train/val/test=0.640/0.500/0.506 | c=0.998347
[Epoch 0007] loss=34.4067 cls=1.6069 smmd=1.6847 ct=9.0132 rec=1.3892 | train/val/test=0.680/0.492/0.500 | c=0.998347
[Epoch 0008] loss=34.0718 cls=1.5630 smmd=1.4061 ct=9.0021 rec=1.3880 | train/val/test=0.740/0.502/0.501 | c=0.998347
[Epoch 0009] loss=33.9125 cls=1.5223 smmd=1.2931 ct=8.9958 rec=1.3867 | train/val/test=0.700/0.500/0.506 | c=0.998347
[Epoch 0010] loss=35.2152 cls=1.4862 smmd=1.2787 ct=9.6704 rec=1.3853 | train/val/test=0.700/0.550/0.564 | c=0.998347
[Epoch 0011] loss=34.9304 cls=1.4459 smmd=1.2796 ct=9.5383 rec=1.3851 | train/val/test=0.720/0.548/0.565 | c=0.998347
[Epoch 0012] loss=34.8105 cls=1.4062 smmd=1.3812 ct=9.4398 rec=1.3847 | train/val/test=0.800/0.542/0.530 | c=0.998347
[Epoch 0013] loss=34.8188 cls=1.3710 smmd=1.3813 ct=9.4619 rec=1.3828 | train/val/test=0.740/0.584/0.573 | c=0.998347
[Epoch 0014] loss=34.5629 cls=1.3270 smmd=1.1162 ct=9.4813 rec=1.3821 | train/val/test=0.780/0.574/0.568 | c=0.998347
[Epoch 0015] loss=34.4373 cls=1.2792 smmd=0.8948 ct=9.5467 rec=1.3810 | train/val/test=0.840/0.554/0.545 | c=0.998347
[Epoch 0016] loss=34.3990 cls=1.2385 smmd=0.7862 ct=9.6091 rec=1.3775 | train/val/test=0.800/0.594/0.584 | c=0.998347
[Epoch 0017] loss=34.3274 cls=1.1845 smmd=0.9129 ct=9.5345 rec=1.3753 | train/val/test=0.880/0.626/0.595 | c=0.998347
[Epoch 0018] loss=34.1240 cls=1.1317 smmd=0.8583 ct=9.5070 rec=1.3686 | train/val/test=0.900/0.628/0.622 | c=0.998347
[Epoch 0019] loss=33.9812 cls=1.0762 smmd=0.7990 ct=9.5079 rec=1.3628 | train/val/test=0.820/0.626/0.617 | c=0.998347
[Epoch 0020] loss=33.9213 cls=1.0375 smmd=0.8183 ct=9.5134 rec=1.3557 | train/val/test=0.880/0.630/0.617 | c=0.998347
[Epoch 0021] loss=33.7030 cls=0.9905 smmd=0.6420 ct=9.5416 rec=1.3483 | train/val/test=0.900/0.626/0.624 | c=0.998347
[Epoch 0022] loss=33.5738 cls=0.9403 smmd=0.5572 ct=9.5650 rec=1.3416 | train/val/test=0.880/0.642/0.627 | c=0.998347
[Epoch 0023] loss=33.5226 cls=0.9164 smmd=0.6092 ct=9.5533 rec=1.3349 | train/val/test=0.900/0.642/0.634 | c=0.998347
[Epoch 0024] loss=33.3616 cls=0.8790 smmd=0.5464 ct=9.5456 rec=1.3285 | train/val/test=0.900/0.634/0.637 | c=0.998347
[Epoch 0025] loss=33.2980 cls=0.8354 smmd=0.5538 ct=9.5488 rec=1.3229 | train/val/test=0.900/0.638/0.642 | c=0.998347
[Epoch 0026] loss=33.2053 cls=0.8108 smmd=0.5471 ct=9.5345 rec=1.3184 | train/val/test=0.920/0.644/0.645 | c=0.998347
[Epoch 0027] loss=33.1189 cls=0.7758 smmd=0.5038 ct=9.5456 rec=1.3136 | train/val/test=0.960/0.642/0.644 | c=0.998347
[Epoch 0028] loss=33.0563 cls=0.7309 smmd=0.4588 ct=9.5694 rec=1.3093 | train/val/test=0.940/0.648/0.657 | c=0.998347
[Epoch 0029] loss=32.9468 cls=0.7006 smmd=0.4127 ct=9.5617 rec=1.3060 | train/val/test=0.940/0.658/0.655 | c=0.998347
[Epoch 0030] loss=32.8898 cls=0.6642 smmd=0.4337 ct=9.5521 rec=1.3020 | train/val/test=0.960/0.640/0.656 | c=0.998347
[Epoch 0031] loss=32.8071 cls=0.6247 smmd=0.4033 ct=9.5546 rec=1.2982 | train/val/test=0.940/0.650/0.661 | c=0.998347
[Epoch 0032] loss=32.7319 cls=0.5890 smmd=0.4089 ct=9.5461 rec=1.2936 | train/val/test=0.940/0.658/0.666 | c=0.998347
[Epoch 0033] loss=32.6517 cls=0.5594 smmd=0.3777 ct=9.5556 rec=1.2883 | train/val/test=0.940/0.648/0.666 | c=0.998347
[Epoch 0034] loss=32.5753 cls=0.5190 smmd=0.3562 ct=9.5658 rec=1.2828 | train/val/test=0.940/0.652/0.665 | c=0.998347
[Epoch 0035] loss=32.4864 cls=0.4965 smmd=0.3571 ct=9.5602 rec=1.2761 | train/val/test=0.940/0.658/0.676 | c=0.998347
[Epoch 0036] loss=32.3883 cls=0.4672 smmd=0.3534 ct=9.5546 rec=1.2692 | train/val/test=0.940/0.660/0.678 | c=0.998347
[Epoch 0037] loss=32.3213 cls=0.4412 smmd=0.3628 ct=9.5559 rec=1.2626 | train/val/test=0.940/0.666/0.675 | c=0.998347
[Epoch 0038] loss=32.2476 cls=0.4214 smmd=0.3612 ct=9.5547 rec=1.2566 | train/val/test=0.940/0.670/0.685 | c=0.998347
[Epoch 0039] loss=32.1641 cls=0.4018 smmd=0.3179 ct=9.5690 rec=1.2507 | train/val/test=0.940/0.676/0.683 | c=0.998347
[Epoch 0040] loss=32.1111 cls=0.3784 smmd=0.3426 ct=9.5566 rec=1.2466 | train/val/test=0.960/0.664/0.684 | c=0.998347
[Epoch 0041] loss=32.0496 cls=0.3697 smmd=0.3171 ct=9.5651 rec=1.2417 | train/val/test=0.940/0.684/0.698 | c=0.998347
[Epoch 0042] loss=32.0402 cls=0.3421 smmd=0.3614 ct=9.5528 rec=1.2402 | train/val/test=0.960/0.658/0.686 | c=0.998347
[Epoch 0043] loss=32.0322 cls=0.3509 smmd=0.3237 ct=9.5907 rec=1.2352 | train/val/test=0.960/0.678/0.691 | c=0.998347
[Epoch 0044] loss=32.0868 cls=0.3222 smmd=0.4081 ct=9.5590 rec=1.2400 | train/val/test=0.940/0.674/0.681 | c=0.998347
[Epoch 0045] loss=32.1044 cls=0.3484 smmd=0.3691 ct=9.6280 rec=1.2305 | train/val/test=0.960/0.694/0.699 | c=0.998347
[Epoch 0046] loss=31.9769 cls=0.3042 smmd=0.4306 ct=9.5563 rec=1.2281 | train/val/test=0.960/0.700/0.720 | c=0.998347
[Epoch 0047] loss=31.7803 cls=0.2881 smmd=0.3367 ct=9.5751 rec=1.2149 | train/val/test=0.960/0.684/0.713 | c=0.998347
[Epoch 0048] loss=31.8032 cls=0.2965 smmd=0.3333 ct=9.5964 rec=1.2129 | train/val/test=0.960/0.694/0.715 | c=0.998347
[Epoch 0049] loss=31.8335 cls=0.2710 smmd=0.4137 ct=9.5591 rec=1.2166 | train/val/test=0.960/0.698/0.723 | c=0.998347
[Epoch 0050] loss=31.7036 cls=0.2602 smmd=0.3329 ct=9.5838 rec=1.2073 | train/val/test=0.960/0.694/0.723 | c=0.998347
[Epoch 0051] loss=31.6682 cls=0.2616 smmd=0.3088 ct=9.5826 rec=1.2063 | train/val/test=0.960/0.688/0.721 | c=0.998347
[Epoch 0052] loss=31.7866 cls=0.2468 smmd=0.3978 ct=9.5559 rec=1.2154 | train/val/test=0.940/0.704/0.725 | c=0.998347
[Epoch 0053] loss=31.8121 cls=0.2674 smmd=0.3336 ct=9.6276 rec=1.2090 | train/val/test=0.960/0.696/0.727 | c=0.998347
[Epoch 0054] loss=31.6896 cls=0.2430 smmd=0.3770 ct=9.5568 rec=1.2078 | train/val/test=0.980/0.700/0.729 | c=0.998347
[Epoch 0055] loss=31.5394 cls=0.2310 smmd=0.2958 ct=9.5802 rec=1.1968 | train/val/test=0.980/0.700/0.726 | c=0.998347
[Epoch 0056] loss=31.5428 cls=0.2332 smmd=0.3016 ct=9.5881 rec=1.1948 | train/val/test=0.960/0.706/0.729 | c=0.998347
[Epoch 0057] loss=31.5999 cls=0.2255 smmd=0.3856 ct=9.5581 rec=1.1985 | train/val/test=0.960/0.702/0.725 | c=0.998347
[Epoch 0058] loss=31.5389 cls=0.2302 smmd=0.3107 ct=9.5958 rec=1.1921 | train/val/test=0.980/0.712/0.727 | c=0.998347
[Epoch 0059] loss=31.4345 cls=0.2134 smmd=0.2749 ct=9.5693 rec=1.1914 | train/val/test=0.980/0.710/0.728 | c=0.998347
[Epoch 0060] loss=31.4590 cls=0.2063 smmd=0.3027 ct=9.5622 rec=1.1929 | train/val/test=0.960/0.706/0.726 | c=0.998347
[Epoch 0061] loss=31.5109 cls=0.2208 smmd=0.2774 ct=9.5997 rec=1.1924 | train/val/test=0.980/0.704/0.728 | c=0.998347
[Epoch 0062] loss=31.5674 cls=0.2008 smmd=0.3598 ct=9.5566 rec=1.1994 | train/val/test=0.960/0.714/0.726 | c=0.998347
[Epoch 0063] loss=31.5663 cls=0.2254 smmd=0.3098 ct=9.6188 rec=1.1906 | train/val/test=0.960/0.708/0.730 | c=0.998347
[Epoch 0064] loss=31.4682 cls=0.1936 smmd=0.3594 ct=9.5596 rec=1.1893 | train/val/test=0.980/0.710/0.727 | c=0.998347
[Epoch 0065] loss=31.3325 cls=0.1930 smmd=0.2750 ct=9.5796 rec=1.1802 | train/val/test=0.980/0.718/0.725 | c=0.998347
[Epoch 0066] loss=31.3481 cls=0.2031 smmd=0.2778 ct=9.5866 rec=1.1796 | train/val/test=0.980/0.716/0.730 | c=0.998347
[Epoch 0067] loss=31.4195 cls=0.1785 smmd=0.3624 ct=9.5606 rec=1.1847 | train/val/test=0.960/0.708/0.724 | c=0.998347
[Epoch 0068] loss=31.3637 cls=0.1953 smmd=0.2804 ct=9.5916 rec=1.1802 | train/val/test=0.980/0.714/0.726 | c=0.998347
[Epoch 0069] loss=31.3155 cls=0.1799 smmd=0.2834 ct=9.5672 rec=1.1808 | train/val/test=0.980/0.704/0.719 | c=0.998347
[Epoch 0070] loss=31.3260 cls=0.1683 smmd=0.2732 ct=9.5640 rec=1.1841 | train/val/test=0.980/0.712/0.720 | c=0.998347
[Epoch 0071] loss=31.3847 cls=0.1935 smmd=0.2510 ct=9.5986 rec=1.1840 | train/val/test=0.980/0.712/0.724 | c=0.998347
[Epoch 0072] loss=31.5588 cls=0.1776 smmd=0.3920 ct=9.5569 rec=1.1964 | train/val/test=0.960/0.690/0.721 | c=0.998347
[Epoch 0073] loss=31.7758 cls=0.2443 smmd=0.3916 ct=9.6651 rec=1.1932 | train/val/test=0.940/0.716/0.725 | c=0.998347
[Epoch 0074] loss=31.6239 cls=0.1935 smmd=0.5113 ct=9.5703 rec=1.1875 | train/val/test=0.980/0.704/0.720 | c=0.998347
[Epoch 0075] loss=31.2410 cls=0.1651 smmd=0.3440 ct=9.5783 rec=1.1658 | train/val/test=0.960/0.702/0.724 | c=0.998347
[Epoch 0076] loss=31.5157 cls=0.2284 smmd=0.4156 ct=9.6364 rec=1.1713 | train/val/test=0.980/0.708/0.724 | c=0.998347
[Epoch 0077] loss=31.2796 cls=0.1599 smmd=0.4020 ct=9.5698 rec=1.1658 | train/val/test=0.980/0.708/0.724 | c=0.998347
[Epoch 0078] loss=31.3634 cls=0.1489 smmd=0.4403 ct=9.5641 rec=1.1720 | train/val/test=0.960/0.708/0.721 | c=0.998347
[Epoch 0079] loss=31.3800 cls=0.1877 smmd=0.3440 ct=9.6126 rec=1.1717 | train/val/test=0.980/0.704/0.722 | c=0.998347
[Epoch 0080] loss=31.2113 cls=0.1526 smmd=0.2675 ct=9.5739 rec=1.1720 | train/val/test=0.980/0.708/0.723 | c=0.998347
[Epoch 0081] loss=31.4412 cls=0.1545 smmd=0.3682 ct=9.5562 rec=1.1883 | train/val/test=0.960/0.694/0.718 | c=0.998347
[Epoch 0082] loss=31.7724 cls=0.2220 smmd=0.3812 ct=9.6679 rec=1.1944 | train/val/test=0.940/0.704/0.721 | c=0.998347
[Epoch 0083] loss=31.8099 cls=0.2107 smmd=0.5502 ct=9.5710 rec=1.2012 | train/val/test=0.960/0.716/0.720 | c=0.998347
[Epoch 0084] loss=31.3676 cls=0.1638 smmd=0.3502 ct=9.6163 rec=1.1703 | train/val/test=0.980/0.700/0.726 | c=0.998347
[Epoch 0085] loss=31.4585 cls=0.2205 smmd=0.4256 ct=9.6226 rec=1.1678 | train/val/test=0.980/0.706/0.722 | c=0.998347
[Epoch 0086] loss=31.3541 cls=0.1557 smmd=0.4992 ct=9.5678 rec=1.1641 | train/val/test=0.980/0.706/0.723 | c=0.998347
[Epoch 0087] loss=31.3933 cls=0.1306 smmd=0.5085 ct=9.5817 rec=1.1656 | train/val/test=0.960/0.700/0.723 | c=0.998347
[Epoch 0088] loss=31.3181 cls=0.1834 smmd=0.3976 ct=9.6033 rec=1.1622 | train/val/test=0.960/0.700/0.724 | c=0.998347
[Epoch 0089] loss=31.2767 cls=0.1808 smmd=0.3394 ct=9.5985 rec=1.1650 | train/val/test=0.980/0.710/0.723 | c=0.998347
[Epoch 0090] loss=31.4635 cls=0.1279 smmd=0.4650 ct=9.5676 rec=1.1799 | train/val/test=0.980/0.700/0.723 | c=0.998347
[Epoch 0091] loss=31.2566 cls=0.1573 smmd=0.3009 ct=9.5674 rec=1.1742 | train/val/test=0.960/0.708/0.720 | c=0.998347
[Epoch 0092] loss=31.5602 cls=0.1922 smmd=0.3513 ct=9.6307 rec=1.1851 | train/val/test=0.960/0.710/0.713 | c=0.998347
[Epoch 0093] loss=31.9082 cls=0.1966 smmd=0.5875 ct=9.5749 rec=1.2073 | train/val/test=0.960/0.708/0.719 | c=0.998347
[Epoch 0094] loss=31.5174 cls=0.1808 smmd=0.3578 ct=9.6422 rec=1.1785 | train/val/test=0.960/0.704/0.719 | c=0.998347
[Epoch 0095] loss=31.3873 cls=0.2183 smmd=0.4244 ct=9.5960 rec=1.1662 | train/val/test=0.980/0.714/0.722 | c=0.998347
[Epoch 0096] loss=31.4253 cls=0.1430 smmd=0.5531 ct=9.5677 rec=1.1665 | train/val/test=0.960/0.706/0.722 | c=0.998347
[Epoch 0097] loss=31.3804 cls=0.1242 smmd=0.5013 ct=9.5927 rec=1.1632 | train/val/test=0.960/0.702/0.723 | c=0.998347
[Epoch 0098] loss=31.3168 cls=0.1864 smmd=0.3995 ct=9.6097 rec=1.1605 | train/val/test=0.980/0.710/0.724 | c=0.998347
[Epoch 0099] loss=31.3132 cls=0.1781 smmd=0.4224 ct=9.5892 rec=1.1623 | train/val/test=0.980/0.706/0.721 | c=0.998347
[Epoch 0100] loss=31.3182 cls=0.1192 smmd=0.4413 ct=9.5650 rec=1.1687 | train/val/test=0.980/0.700/0.724 | c=0.998347
[Epoch 0101] loss=31.2810 cls=0.1390 smmd=0.3508 ct=9.5709 rec=1.1719 | train/val/test=0.980/0.708/0.721 | c=0.998347
[Epoch 0102] loss=31.5059 cls=0.1857 smmd=0.3868 ct=9.6144 rec=1.1797 | train/val/test=0.980/0.710/0.719 | c=0.998347
[Epoch 0103] loss=31.3724 cls=0.1383 smmd=0.3518 ct=9.5562 rec=1.1839 | train/val/test=0.980/0.700/0.723 | c=0.998347
[Epoch 0104] loss=31.4064 cls=0.1594 smmd=0.3463 ct=9.5887 rec=1.1803 | train/val/test=0.960/0.710/0.725 | c=0.998347
[Epoch 0105] loss=31.3760 cls=0.1819 smmd=0.3966 ct=9.5857 rec=1.1717 | train/val/test=0.980/0.706/0.725 | c=0.998347
[Epoch 0106] loss=31.1600 cls=0.1366 smmd=0.3018 ct=9.5643 rec=1.1661 | train/val/test=0.960/0.698/0.722 | c=0.998347
[Epoch 0107] loss=31.3246 cls=0.1486 smmd=0.3870 ct=9.5835 rec=1.1696 | train/val/test=0.960/0.708/0.721 | c=0.998347
[Epoch 0108] loss=31.1495 cls=0.1490 smmd=0.3133 ct=9.5724 rec=1.1617 | train/val/test=0.980/0.706/0.723 | c=0.998347
[Epoch 0109] loss=31.2394 cls=0.1470 smmd=0.3655 ct=9.5729 rec=1.1655 | train/val/test=0.980/0.702/0.719 | c=0.998347
[Epoch 0110] loss=31.2073 cls=0.1364 smmd=0.3159 ct=9.5747 rec=1.1674 | train/val/test=0.980/0.706/0.724 | c=0.998347
[Epoch 0111] loss=31.1967 cls=0.1309 smmd=0.2853 ct=9.5736 rec=1.1699 | train/val/test=0.980/0.704/0.720 | c=0.998347
[Epoch 0112] loss=31.3478 cls=0.1597 smmd=0.3654 ct=9.5737 rec=1.1755 | train/val/test=0.980/0.704/0.724 | c=0.998347
[Epoch 0113] loss=31.2096 cls=0.1364 smmd=0.2497 ct=9.5771 rec=1.1737 | train/val/test=0.980/0.700/0.724 | c=0.998347
[Epoch 0114] loss=31.2041 cls=0.1368 smmd=0.2779 ct=9.5576 rec=1.1743 | train/val/test=0.980/0.710/0.723 | c=0.998347
[Epoch 0115] loss=31.2711 cls=0.1519 smmd=0.3017 ct=9.5802 rec=1.1733 | train/val/test=0.980/0.702/0.722 | c=0.998347
[Epoch 0116] loss=31.1583 cls=0.1505 smmd=0.2672 ct=9.5655 rec=1.1685 | train/val/test=0.980/0.702/0.726 | c=0.998347
[Epoch 0117] loss=31.1766 cls=0.1327 smmd=0.2941 ct=9.5657 rec=1.1685 | train/val/test=0.980/0.710/0.720 | c=0.998347
[Epoch 0118] loss=31.1554 cls=0.1507 smmd=0.2780 ct=9.5715 rec=1.1659 | train/val/test=0.980/0.704/0.722 | c=0.998347
[Epoch 0119] loss=31.1157 cls=0.1482 smmd=0.2566 ct=9.5654 rec=1.1654 | train/val/test=0.980/0.704/0.725 | c=0.998347
[Epoch 0120] loss=31.1779 cls=0.1272 smmd=0.2763 ct=9.5687 rec=1.1700 | train/val/test=0.980/0.702/0.720 | c=0.998347
[Epoch 0121] loss=31.1509 cls=0.1483 smmd=0.2602 ct=9.5664 rec=1.1684 | train/val/test=0.980/0.704/0.722 | c=0.998347
[Epoch 0122] loss=31.1189 cls=0.1385 smmd=0.2231 ct=9.5657 rec=1.1695 | train/val/test=0.980/0.702/0.724 | c=0.998347
[Epoch 0123] loss=31.1787 cls=0.1307 smmd=0.2551 ct=9.5624 rec=1.1733 | train/val/test=0.980/0.708/0.721 | c=0.998347
[Epoch 0124] loss=31.1737 cls=0.1536 smmd=0.2356 ct=9.5738 rec=1.1714 | train/val/test=0.980/0.702/0.721 | c=0.998347
[Epoch 0125] loss=31.1410 cls=0.1390 smmd=0.2544 ct=9.5575 rec=1.1702 | train/val/test=0.980/0.704/0.725 | c=0.998347
[Epoch 0126] loss=31.1595 cls=0.1367 smmd=0.2417 ct=9.5746 rec=1.1700 | train/val/test=0.980/0.706/0.722 | c=0.998347
[Epoch 0127] loss=31.1987 cls=0.1637 smmd=0.3007 ct=9.5643 rec=1.1688 | train/val/test=0.960/0.710/0.725 | c=0.998347
[Epoch 0128] loss=31.1903 cls=0.1358 smmd=0.2709 ct=9.5830 rec=1.1686 | train/val/test=0.980/0.702/0.724 | c=0.998347
[Epoch 0129] loss=31.1745 cls=0.1491 smmd=0.2946 ct=9.5625 rec=1.1680 | train/val/test=0.960/0.708/0.722 | c=0.998347
[Epoch 0130] loss=31.1591 cls=0.1338 smmd=0.2713 ct=9.5783 rec=1.1664 | train/val/test=0.980/0.702/0.723 | c=0.998347
[Epoch 0131] loss=31.0848 cls=0.1323 smmd=0.2436 ct=9.5635 rec=1.1648 | train/val/test=0.980/0.702/0.724 | c=0.998347
[Epoch 0132] loss=31.1088 cls=0.1264 smmd=0.2542 ct=9.5588 rec=1.1674 | train/val/test=0.980/0.708/0.722 | c=0.998347
[Epoch 0133] loss=31.1647 cls=0.1345 smmd=0.2411 ct=9.5818 rec=1.1693 | train/val/test=0.980/0.700/0.723 | c=0.998347
[Epoch 0134] loss=31.1954 cls=0.1496 smmd=0.2860 ct=9.5550 rec=1.1725 | train/val/test=0.960/0.710/0.720 | c=0.998347
[Epoch 0135] loss=31.3130 cls=0.1487 smmd=0.2604 ct=9.6092 rec=1.1760 | train/val/test=0.940/0.702/0.723 | c=0.998347
[Epoch 0136] loss=31.4648 cls=0.2025 smmd=0.4296 ct=9.5709 rec=1.1792 | train/val/test=0.960/0.708/0.719 | c=0.998347
[Epoch 0137] loss=31.3035 cls=0.1558 smmd=0.3081 ct=9.6148 rec=1.1688 | train/val/test=0.980/0.702/0.722 | c=0.998347
[Epoch 0138] loss=31.0826 cls=0.1190 smmd=0.3050 ct=9.5609 rec=1.1596 | train/val/test=0.980/0.700/0.724 | c=0.998347
[Epoch 0139] loss=31.1675 cls=0.1400 smmd=0.3549 ct=9.5626 rec=1.1617 | train/val/test=0.960/0.710/0.720 | c=0.998347
[Epoch 0140] loss=31.1901 cls=0.1360 smmd=0.2950 ct=9.6028 rec=1.1621 | train/val/test=0.980/0.702/0.723 | c=0.998347
[Epoch 0141] loss=31.0837 cls=0.1089 smmd=0.2800 ct=9.5617 rec=1.1626 | train/val/test=0.980/0.702/0.725 | c=0.998347
[Epoch 0142] loss=31.2019 cls=0.1397 smmd=0.3237 ct=9.5570 rec=1.1694 | train/val/test=0.960/0.716/0.716 | c=0.998347
[Epoch 0143] loss=31.3759 cls=0.1506 smmd=0.2838 ct=9.6211 rec=1.1775 | train/val/test=0.960/0.700/0.724 | c=0.998347
[Epoch 0144] loss=31.3983 cls=0.1590 smmd=0.3852 ct=9.5567 rec=1.1820 | train/val/test=0.960/0.714/0.719 | c=0.998347
[Epoch 0145] loss=31.4685 cls=0.1890 smmd=0.3185 ct=9.6415 rec=1.1773 | train/val/test=0.980/0.704/0.724 | c=0.998347
[Epoch 0146] loss=31.4195 cls=0.1431 smmd=0.4515 ct=9.5686 rec=1.1759 | train/val/test=0.980/0.700/0.723 | c=0.998347
[Epoch 0147] loss=31.2617 cls=0.1818 smmd=0.3788 ct=9.5805 rec=1.1631 | train/val/test=0.960/0.714/0.721 | c=0.998347
[Epoch 0148] loss=31.2636 cls=0.1791 smmd=0.3627 ct=9.6147 rec=1.1582 | train/val/test=0.980/0.708/0.725 | c=0.998347
[Epoch 0149] loss=31.2349 cls=0.1236 smmd=0.4100 ct=9.5788 rec=1.1605 | train/val/test=0.980/0.704/0.725 | c=0.998347
[Epoch 0150] loss=31.2339 cls=0.1508 smmd=0.4122 ct=9.5643 rec=1.1618 | train/val/test=0.960/0.708/0.725 | c=0.998347
[Epoch 0151] loss=31.2357 cls=0.1564 smmd=0.3109 ct=9.6058 rec=1.1635 | train/val/test=0.980/0.704/0.723 | c=0.998347
[Epoch 0152] loss=31.2146 cls=0.1087 smmd=0.3245 ct=9.5686 rec=1.1699 | train/val/test=0.960/0.706/0.725 | c=0.998347
[Epoch 0153] loss=31.2937 cls=0.1554 smmd=0.3510 ct=9.5697 rec=1.1726 | train/val/test=0.960/0.708/0.715 | c=0.998347
[Epoch 0154] loss=31.3958 cls=0.1477 smmd=0.2824 ct=9.6224 rec=1.1795 | train/val/test=0.940/0.694/0.727 | c=0.998347
[Epoch 0155] loss=31.5635 cls=0.1755 smmd=0.4868 ct=9.5710 rec=1.1847 | train/val/test=0.980/0.700/0.725 | c=0.998347
[Epoch 0156] loss=31.3595 cls=0.2011 smmd=0.3481 ct=9.6095 rec=1.1692 | train/val/test=0.940/0.700/0.725 | c=0.998347
[Epoch 0157] loss=31.3583 cls=0.1324 smmd=0.4361 ct=9.5978 rec=1.1660 | train/val/test=0.980/0.700/0.724 | c=0.998347
[Epoch 0158] loss=31.3625 cls=0.1421 smmd=0.4981 ct=9.5786 rec=1.1636 | train/val/test=0.980/0.714/0.724 | c=0.998347
[Epoch 0159] loss=31.2936 cls=0.1877 smmd=0.4355 ct=9.5852 rec=1.1594 | train/val/test=0.940/0.702/0.723 | c=0.998347
[Epoch 0160] loss=31.4368 cls=0.1779 smmd=0.4699 ct=9.6136 rec=1.1651 | train/val/test=0.980/0.698/0.721 | c=0.998347
[Epoch 0161] loss=31.2506 cls=0.1106 smmd=0.4244 ct=9.5735 rec=1.1624 | train/val/test=0.980/0.710/0.719 | c=0.998347
[Epoch 0162] loss=31.2536 cls=0.1346 smmd=0.4104 ct=9.5731 rec=1.1630 | train/val/test=0.980/0.712/0.725 | c=0.998347
[Epoch 0163] loss=31.3301 cls=0.1401 smmd=0.3681 ct=9.5932 rec=1.1705 | train/val/test=0.980/0.700/0.720 | c=0.998347
[Epoch 0164] loss=31.2282 cls=0.1046 smmd=0.3166 ct=9.5730 rec=1.1713 | train/val/test=0.960/0.704/0.716 | c=0.998347
[Epoch 0165] loss=31.2378 cls=0.1356 smmd=0.3295 ct=9.5619 rec=1.1717 | train/val/test=0.980/0.710/0.721 | c=0.998347
[Epoch 0166] loss=31.3403 cls=0.1458 smmd=0.3206 ct=9.6036 rec=1.1739 | train/val/test=0.980/0.700/0.721 | c=0.998347
[Epoch 0167] loss=31.1656 cls=0.1252 smmd=0.3084 ct=9.5606 rec=1.1673 | train/val/test=0.980/0.704/0.719 | c=0.998347
[Epoch 0168] loss=31.1075 cls=0.1396 smmd=0.2889 ct=9.5579 rec=1.1633 | train/val/test=0.960/0.712/0.721 | c=0.998347
[Epoch 0169] loss=31.2386 cls=0.1602 smmd=0.3109 ct=9.5969 rec=1.1654 | train/val/test=0.980/0.702/0.719 | c=0.998347
[Epoch 0170] loss=31.1225 cls=0.1351 smmd=0.2991 ct=9.5642 rec=1.1627 | train/val/test=0.980/0.700/0.720 | c=0.998347
[Epoch 0171] loss=31.1250 cls=0.1233 smmd=0.3038 ct=9.5549 rec=1.1650 | train/val/test=0.960/0.708/0.723 | c=0.998347
[Epoch 0172] loss=31.2582 cls=0.1424 smmd=0.2948 ct=9.6010 rec=1.1690 | train/val/test=0.980/0.702/0.717 | c=0.998347
[Epoch 0173] loss=31.1607 cls=0.1230 smmd=0.2900 ct=9.5609 rec=1.1688 | train/val/test=0.980/0.700/0.719 | c=0.998347
[Epoch 0174] loss=31.1111 cls=0.1134 smmd=0.2521 ct=9.5572 rec=1.1688 | train/val/test=0.980/0.708/0.720 | c=0.998347
[Epoch 0175] loss=31.2361 cls=0.1396 smmd=0.2648 ct=9.5949 rec=1.1712 | train/val/test=0.980/0.702/0.715 | c=0.998347
[Epoch 0176] loss=31.2770 cls=0.1429 smmd=0.3479 ct=9.5582 rec=1.1741 | train/val/test=0.960/0.706/0.717 | c=0.998347
[Epoch 0177] loss=31.2060 cls=0.1518 smmd=0.2626 ct=9.5932 rec=1.1681 | train/val/test=0.980/0.706/0.722 | c=0.998347
[Epoch 0178] loss=31.2132 cls=0.1435 smmd=0.3324 ct=9.5661 rec=1.1677 | train/val/test=0.980/0.700/0.720 | c=0.998347
[Epoch 0179] loss=31.2487 cls=0.1634 smmd=0.3360 ct=9.5826 rec=1.1666 | train/val/test=0.980/0.702/0.725 | c=0.998347
[Epoch 0180] loss=31.1138 cls=0.1191 smmd=0.2931 ct=9.5682 rec=1.1625 | train/val/test=0.980/0.708/0.724 | c=0.998347
[Epoch 0181] loss=31.1050 cls=0.1367 smmd=0.2808 ct=9.5667 rec=1.1622 | train/val/test=0.980/0.700/0.720 | c=0.998347
[Epoch 0182] loss=31.1805 cls=0.1336 smmd=0.2916 ct=9.5774 rec=1.1667 | train/val/test=0.980/0.698/0.722 | c=0.998347
[Epoch 0183] loss=31.2154 cls=0.1096 smmd=0.3013 ct=9.5594 rec=1.1740 | train/val/test=0.980/0.702/0.724 | c=0.998347
[Epoch 0184] loss=31.3342 cls=0.1766 smmd=0.2880 ct=9.6045 rec=1.1749 | train/val/test=1.000/0.704/0.715 | c=0.998347
[Epoch 0185] loss=31.5379 cls=0.1383 smmd=0.4671 ct=9.5686 rec=1.1864 | train/val/test=0.960/0.702/0.720 | c=0.998347
[Epoch 0186] loss=31.4493 cls=0.2122 smmd=0.3281 ct=9.6357 rec=1.1744 | train/val/test=0.980/0.712/0.726 | c=0.998347
[Epoch 0187] loss=31.2147 cls=0.1808 smmd=0.3867 ct=9.5616 rec=1.1614 | train/val/test=0.980/0.704/0.724 | c=0.998347
[Epoch 0188] loss=31.1668 cls=0.1324 smmd=0.3787 ct=9.5692 rec=1.1583 | train/val/test=0.960/0.706/0.721 | c=0.998347
[Epoch 0189] loss=31.1809 cls=0.1628 smmd=0.3260 ct=9.5983 rec=1.1577 | train/val/test=0.980/0.704/0.726 | c=0.998347
[Epoch 0190] loss=31.1578 cls=0.1640 smmd=0.3318 ct=9.5774 rec=1.1589 | train/val/test=0.980/0.704/0.724 | c=0.998347
[Epoch 0191] loss=31.1573 cls=0.1145 smmd=0.3328 ct=9.5559 rec=1.1655 | train/val/test=0.960/0.700/0.718 | c=0.998347
[Epoch 0192] loss=31.2133 cls=0.1246 smmd=0.2715 ct=9.5897 rec=1.1700 | train/val/test=0.980/0.712/0.730 | c=0.998347
[Epoch 0193] loss=31.2529 cls=0.1472 smmd=0.2992 ct=9.5679 rec=1.1744 | train/val/test=0.980/0.704/0.718 | c=0.998347
[Epoch 0194] loss=31.1948 cls=0.1174 smmd=0.2573 ct=9.5703 rec=1.1738 | train/val/test=0.980/0.702/0.725 | c=0.998347
[Epoch 0195] loss=31.1138 cls=0.1209 smmd=0.2401 ct=9.5597 rec=1.1694 | train/val/test=0.980/0.712/0.722 | c=0.998347
[Epoch 0196] loss=31.1210 cls=0.1538 smmd=0.2487 ct=9.5660 rec=1.1663 | train/val/test=0.980/0.700/0.718 | c=0.998347
[Epoch 0197] loss=31.1318 cls=0.1306 smmd=0.2784 ct=9.5670 rec=1.1654 | train/val/test=0.980/0.704/0.722 | c=0.998347
[Epoch 0198] loss=31.0868 cls=0.1492 smmd=0.2604 ct=9.5637 rec=1.1624 | train/val/test=0.980/0.710/0.720 | c=0.998347
[Epoch 0199] loss=31.0871 cls=0.1485 smmd=0.2579 ct=9.5664 rec=1.1622 | train/val/test=0.980/0.700/0.720 | c=0.998347
=== Best @ epoch 65: val=0.7180, test=0.7250 ===

Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-1 completed in 50.78 seconds.
==================================================
