Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-5-5 - 2025-09-21 06:22:05:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-5-5...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-5-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=19.7767 cls=1.7909 smmd=4.1588 ct=9.4852 rec=1.3917 | train/val/test=0.192/0.058/0.077 | c=0.998347
[Epoch 0001] loss=19.4683 cls=1.7653 smmd=3.6068 ct=9.4707 rec=1.3917 | train/val/test=0.577/0.212/0.258 | c=0.998347
[Epoch 0002] loss=18.8795 cls=1.7275 smmd=2.6185 ct=9.4026 rec=1.3917 | train/val/test=0.500/0.210/0.229 | c=0.998347
[Epoch 0003] loss=18.7508 cls=1.6750 smmd=2.5629 ct=9.3386 rec=1.3917 | train/val/test=0.615/0.312/0.349 | c=0.998347
[Epoch 0004] loss=18.2597 cls=1.5979 smmd=2.1004 ct=9.1342 rec=1.3914 | train/val/test=0.692/0.364/0.411 | c=0.998347
[Epoch 0005] loss=17.8032 cls=1.5114 smmd=1.5407 ct=9.0218 rec=1.3906 | train/val/test=0.769/0.398/0.432 | c=0.998347
[Epoch 0006] loss=17.7934 cls=1.4250 smmd=1.6787 ct=9.0085 rec=1.3896 | train/val/test=0.808/0.452/0.477 | c=0.998347
[Epoch 0007] loss=17.6265 cls=1.3378 smmd=1.5122 ct=8.9917 rec=1.3885 | train/val/test=0.808/0.464/0.497 | c=0.998347
[Epoch 0008] loss=18.1029 cls=1.2584 smmd=1.1609 ct=9.7050 rec=1.3873 | train/val/test=0.846/0.460/0.489 | c=0.998347
[Epoch 0009] loss=17.9569 cls=1.1868 smmd=1.2381 ct=9.5775 rec=1.3859 | train/val/test=0.885/0.414/0.448 | c=0.998347
[Epoch 0010] loss=17.9877 cls=1.1286 smmd=1.5022 ct=9.5203 rec=1.3852 | train/val/test=0.885/0.464/0.489 | c=0.998347
[Epoch 0011] loss=17.8622 cls=1.0594 smmd=1.4056 ct=9.4968 rec=1.3842 | train/val/test=0.885/0.518/0.539 | c=0.998347
[Epoch 0012] loss=17.7213 cls=0.9967 smmd=1.1201 ct=9.5463 rec=1.3834 | train/val/test=0.923/0.528/0.543 | c=0.998347
[Epoch 0013] loss=17.6487 cls=0.9420 smmd=0.9266 ct=9.6118 rec=1.3828 | train/val/test=0.923/0.508/0.530 | c=0.998347
[Epoch 0014] loss=17.5974 cls=0.8891 smmd=0.8693 ct=9.6282 rec=1.3824 | train/val/test=0.962/0.578/0.586 | c=0.998347
[Epoch 0015] loss=17.4914 cls=0.8305 smmd=0.8145 ct=9.5950 rec=1.3816 | train/val/test=1.000/0.610/0.603 | c=0.998347
[Epoch 0016] loss=17.4382 cls=0.7738 smmd=0.8705 ct=9.5590 rec=1.3805 | train/val/test=1.000/0.596/0.610 | c=0.998347
[Epoch 0017] loss=17.3849 cls=0.7175 smmd=0.8541 ct=9.5590 rec=1.3793 | train/val/test=1.000/0.626/0.625 | c=0.998347
[Epoch 0018] loss=17.2912 cls=0.6557 smmd=0.7369 ct=9.5768 rec=1.3774 | train/val/test=1.000/0.640/0.642 | c=0.998347
[Epoch 0019] loss=17.2110 cls=0.5994 smmd=0.6421 ct=9.5940 rec=1.3753 | train/val/test=1.000/0.646/0.656 | c=0.998347
[Epoch 0020] loss=17.1507 cls=0.5465 smmd=0.6196 ct=9.5936 rec=1.3729 | train/val/test=1.000/0.648/0.649 | c=0.998347
[Epoch 0021] loss=17.0762 cls=0.4950 smmd=0.5743 ct=9.5922 rec=1.3701 | train/val/test=1.000/0.672/0.662 | c=0.998347
[Epoch 0022] loss=17.0159 cls=0.4504 smmd=0.5534 ct=9.5896 rec=1.3669 | train/val/test=1.000/0.676/0.672 | c=0.998347
[Epoch 0023] loss=16.9549 cls=0.4108 smmd=0.5234 ct=9.5890 rec=1.3633 | train/val/test=1.000/0.664/0.675 | c=0.998347
[Epoch 0024] loss=16.9075 cls=0.3730 smmd=0.5179 ct=9.5915 rec=1.3592 | train/val/test=1.000/0.678/0.680 | c=0.998347
[Epoch 0025] loss=16.8478 cls=0.3420 smmd=0.4778 ct=9.5968 rec=1.3545 | train/val/test=1.000/0.680/0.681 | c=0.998347
[Epoch 0026] loss=16.7887 cls=0.3152 smmd=0.4461 ct=9.5991 rec=1.3492 | train/val/test=1.000/0.690/0.686 | c=0.998347
[Epoch 0027] loss=16.7384 cls=0.2888 smmd=0.4399 ct=9.6034 rec=1.3426 | train/val/test=1.000/0.676/0.687 | c=0.998347
[Epoch 0028] loss=16.6688 cls=0.2668 smmd=0.4045 ct=9.6061 rec=1.3347 | train/val/test=1.000/0.682/0.690 | c=0.998347
[Epoch 0029] loss=16.6163 cls=0.2470 smmd=0.4096 ct=9.6082 rec=1.3261 | train/val/test=1.000/0.672/0.693 | c=0.998347
[Epoch 0030] loss=16.5548 cls=0.2271 smmd=0.4020 ct=9.6083 rec=1.3173 | train/val/test=1.000/0.672/0.687 | c=0.998347
[Epoch 0031] loss=16.4959 cls=0.2116 smmd=0.3935 ct=9.6065 rec=1.3089 | train/val/test=1.000/0.676/0.696 | c=0.998347
[Epoch 0032] loss=16.4411 cls=0.1968 smmd=0.3719 ct=9.6148 rec=1.3005 | train/val/test=1.000/0.676/0.699 | c=0.998347
[Epoch 0033] loss=16.3958 cls=0.1833 smmd=0.3676 ct=9.6191 rec=1.2929 | train/val/test=1.000/0.676/0.695 | c=0.998347
[Epoch 0034] loss=16.3431 cls=0.1740 smmd=0.3439 ct=9.6171 rec=1.2864 | train/val/test=1.000/0.680/0.696 | c=0.998347
[Epoch 0035] loss=16.3105 cls=0.1633 smmd=0.3595 ct=9.6173 rec=1.2798 | train/val/test=1.000/0.670/0.699 | c=0.998347
[Epoch 0036] loss=16.2791 cls=0.1556 smmd=0.3659 ct=9.6144 rec=1.2746 | train/val/test=1.000/0.664/0.700 | c=0.998347
[Epoch 0037] loss=16.2464 cls=0.1491 smmd=0.3471 ct=9.6184 rec=1.2700 | train/val/test=1.000/0.672/0.708 | c=0.998347
[Epoch 0038] loss=16.2208 cls=0.1427 smmd=0.3381 ct=9.6228 rec=1.2658 | train/val/test=1.000/0.670/0.699 | c=0.998347
[Epoch 0039] loss=16.1919 cls=0.1384 smmd=0.3243 ct=9.6199 rec=1.2626 | train/val/test=1.000/0.678/0.707 | c=0.998347
[Epoch 0040] loss=16.1699 cls=0.1322 smmd=0.3293 ct=9.6184 rec=1.2589 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0041] loss=16.1502 cls=0.1279 smmd=0.3278 ct=9.6192 rec=1.2555 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0042] loss=16.1213 cls=0.1220 smmd=0.3095 ct=9.6214 rec=1.2520 | train/val/test=1.000/0.684/0.706 | c=0.998347
[Epoch 0043] loss=16.1037 cls=0.1171 smmd=0.3179 ct=9.6200 rec=1.2486 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0044] loss=16.0828 cls=0.1122 smmd=0.3125 ct=9.6226 rec=1.2451 | train/val/test=1.000/0.678/0.707 | c=0.998347
[Epoch 0045] loss=16.0640 cls=0.1079 smmd=0.3107 ct=9.6226 rec=1.2421 | train/val/test=1.000/0.684/0.706 | c=0.998347
[Epoch 0046] loss=16.0485 cls=0.1043 smmd=0.3108 ct=9.6229 rec=1.2394 | train/val/test=1.000/0.680/0.707 | c=0.998347
[Epoch 0047] loss=16.0332 cls=0.1013 smmd=0.3112 ct=9.6202 rec=1.2373 | train/val/test=1.000/0.684/0.709 | c=0.998347
[Epoch 0048] loss=16.0150 cls=0.0991 smmd=0.2911 ct=9.6229 rec=1.2354 | train/val/test=1.000/0.682/0.711 | c=0.998347
[Epoch 0049] loss=16.0070 cls=0.0965 smmd=0.2935 ct=9.6240 rec=1.2337 | train/val/test=1.000/0.682/0.708 | c=0.998347
[Epoch 0050] loss=15.9982 cls=0.0950 smmd=0.2955 ct=9.6224 rec=1.2323 | train/val/test=1.000/0.680/0.710 | c=0.998347
[Epoch 0051] loss=15.9826 cls=0.0916 smmd=0.2870 ct=9.6221 rec=1.2306 | train/val/test=1.000/0.682/0.708 | c=0.998347
[Epoch 0052] loss=15.9738 cls=0.0912 smmd=0.2858 ct=9.6196 rec=1.2295 | train/val/test=1.000/0.672/0.711 | c=0.998347
[Epoch 0053] loss=15.9740 cls=0.0861 smmd=0.2892 ct=9.6313 rec=1.2276 | train/val/test=1.000/0.686/0.705 | c=0.998347
[Epoch 0054] loss=16.0180 cls=0.0966 smmd=0.3453 ct=9.6251 rec=1.2305 | train/val/test=1.000/0.670/0.693 | c=0.998347
[Epoch 0055] loss=16.1664 cls=0.0958 smmd=0.4667 ct=9.6846 rec=1.2363 | train/val/test=1.000/0.654/0.657 | c=0.998347
[Epoch 0056] loss=16.2797 cls=0.1361 smmd=0.5586 ct=9.6716 rec=1.2467 | train/val/test=1.000/0.668/0.705 | c=0.998347
[Epoch 0057] loss=16.0324 cls=0.0667 smmd=0.4603 ct=9.6600 rec=1.2191 | train/val/test=1.000/0.676/0.718 | c=0.998347
[Epoch 0058] loss=15.9240 cls=0.0550 smmd=0.3923 ct=9.6446 rec=1.2090 | train/val/test=1.000/0.678/0.696 | c=0.998347
[Epoch 0059] loss=16.0643 cls=0.0744 smmd=0.5205 ct=9.6501 rec=1.2204 | train/val/test=1.000/0.686/0.715 | c=0.998347
[Epoch 0060] loss=15.8997 cls=0.0542 smmd=0.4135 ct=9.6320 rec=1.2046 | train/val/test=1.000/0.672/0.716 | c=0.998347
[Epoch 0061] loss=16.0326 cls=0.0672 smmd=0.5024 ct=9.6628 rec=1.2143 | train/val/test=1.000/0.688/0.714 | c=0.998347
[Epoch 0062] loss=15.9847 cls=0.0788 smmd=0.4414 ct=9.6353 rec=1.2147 | train/val/test=1.000/0.684/0.717 | c=0.998347
[Epoch 0063] loss=15.8950 cls=0.0731 smmd=0.3326 ct=9.6242 rec=1.2107 | train/val/test=1.000/0.664/0.705 | c=0.998347
[Epoch 0064] loss=16.0701 cls=0.0834 smmd=0.4598 ct=9.6667 rec=1.2230 | train/val/test=1.000/0.688/0.708 | c=0.998347
[Epoch 0065] loss=16.0340 cls=0.1049 smmd=0.4035 ct=9.6440 rec=1.2229 | train/val/test=1.000/0.676/0.720 | c=0.998347
[Epoch 0066] loss=15.8610 cls=0.0630 smmd=0.3196 ct=9.6181 rec=1.2078 | train/val/test=1.000/0.670/0.713 | c=0.998347
[Epoch 0067] loss=15.9542 cls=0.0621 smmd=0.3891 ct=9.6558 rec=1.2121 | train/val/test=1.000/0.690/0.719 | c=0.998347
[Epoch 0068] loss=15.9260 cls=0.0661 smmd=0.3714 ct=9.6389 rec=1.2110 | train/val/test=1.000/0.678/0.717 | c=0.998347
[Epoch 0069] loss=15.8489 cls=0.0548 smmd=0.3583 ct=9.6142 rec=1.2034 | train/val/test=1.000/0.672/0.712 | c=0.998347
[Epoch 0070] loss=15.9330 cls=0.0602 smmd=0.3931 ct=9.6542 rec=1.2080 | train/val/test=1.000/0.684/0.719 | c=0.998347
[Epoch 0071] loss=15.8706 cls=0.0627 smmd=0.3317 ct=9.6328 rec=1.2056 | train/val/test=1.000/0.682/0.713 | c=0.998347
[Epoch 0072] loss=15.8709 cls=0.0640 smmd=0.3627 ct=9.6136 rec=1.2062 | train/val/test=1.000/0.674/0.711 | c=0.998347
[Epoch 0073] loss=15.9505 cls=0.0705 smmd=0.3813 ct=9.6587 rec=1.2104 | train/val/test=1.000/0.684/0.717 | c=0.998347
[Epoch 0074] loss=15.9053 cls=0.0776 smmd=0.3414 ct=9.6355 rec=1.2090 | train/val/test=1.000/0.682/0.718 | c=0.998347
[Epoch 0075] loss=15.8780 cls=0.0647 smmd=0.3711 ct=9.6130 rec=1.2068 | train/val/test=1.000/0.682/0.719 | c=0.998347
[Epoch 0076] loss=15.9027 cls=0.0607 smmd=0.3581 ct=9.6509 rec=1.2060 | train/val/test=1.000/0.684/0.715 | c=0.998347
[Epoch 0077] loss=15.8865 cls=0.0680 smmd=0.3397 ct=9.6385 rec=1.2061 | train/val/test=1.000/0.684/0.722 | c=0.998347
[Epoch 0078] loss=15.8872 cls=0.0559 smmd=0.4229 ct=9.6144 rec=1.2044 | train/val/test=1.000/0.684/0.720 | c=0.998347
[Epoch 0079] loss=15.8424 cls=0.0541 smmd=0.3214 ct=9.6410 rec=1.2006 | train/val/test=1.000/0.676/0.711 | c=0.998347
[Epoch 0080] loss=15.8827 cls=0.0644 smmd=0.3382 ct=9.6448 rec=1.2047 | train/val/test=1.000/0.688/0.720 | c=0.998347
[Epoch 0081] loss=15.8999 cls=0.0571 smmd=0.4458 ct=9.6135 rec=1.2047 | train/val/test=1.000/0.686/0.719 | c=0.998347
[Epoch 0082] loss=15.8155 cls=0.0558 smmd=0.3100 ct=9.6276 rec=1.1988 | train/val/test=1.000/0.676/0.710 | c=0.998347
[Epoch 0083] loss=15.9260 cls=0.0729 smmd=0.3576 ct=9.6586 rec=1.2075 | train/val/test=1.000/0.690/0.721 | c=0.998347
[Epoch 0084] loss=15.9211 cls=0.0588 smmd=0.4497 ct=9.6235 rec=1.2063 | train/val/test=1.000/0.688/0.716 | c=0.998347
[Epoch 0085] loss=15.7933 cls=0.0532 smmd=0.3195 ct=9.6124 rec=1.1968 | train/val/test=1.000/0.678/0.708 | c=0.998347
[Epoch 0086] loss=15.9475 cls=0.0698 smmd=0.3913 ct=9.6687 rec=1.2069 | train/val/test=1.000/0.688/0.718 | c=0.998347
[Epoch 0087] loss=15.8804 cls=0.0525 smmd=0.4189 ct=9.6271 rec=1.2014 | train/val/test=1.000/0.690/0.715 | c=0.998347
[Epoch 0088] loss=15.8142 cls=0.0517 smmd=0.3665 ct=9.6101 rec=1.1969 | train/val/test=1.000/0.680/0.709 | c=0.998347
[Epoch 0089] loss=15.9120 cls=0.0613 smmd=0.3940 ct=9.6641 rec=1.2016 | train/val/test=1.000/0.686/0.722 | c=0.998347
[Epoch 0090] loss=15.7901 cls=0.0490 smmd=0.3287 ct=9.6233 rec=1.1936 | train/val/test=1.000/0.688/0.715 | c=0.998347
[Epoch 0091] loss=15.8629 cls=0.0565 smmd=0.4264 ct=9.6118 rec=1.1997 | train/val/test=1.000/0.686/0.717 | c=0.998347
[Epoch 0092] loss=15.8166 cls=0.0552 smmd=0.3176 ct=9.6414 rec=1.1956 | train/val/test=1.000/0.688/0.720 | c=0.998347
[Epoch 0093] loss=15.7979 cls=0.0549 smmd=0.2900 ct=9.6349 rec=1.1959 | train/val/test=1.000/0.684/0.715 | c=0.998347
[Epoch 0094] loss=15.8719 cls=0.0603 smmd=0.4152 ct=9.6086 rec=1.2027 | train/val/test=1.000/0.680/0.720 | c=0.998347
[Epoch 0095] loss=15.8024 cls=0.0544 smmd=0.2898 ct=9.6321 rec=1.1975 | train/val/test=1.000/0.680/0.712 | c=0.998347
[Epoch 0096] loss=15.8508 cls=0.0628 smmd=0.3022 ct=9.6483 rec=1.2015 | train/val/test=1.000/0.690/0.715 | c=0.998347
[Epoch 0097] loss=15.8606 cls=0.0551 smmd=0.3905 ct=9.6138 rec=1.2026 | train/val/test=1.000/0.686/0.718 | c=0.998347
[Epoch 0098] loss=15.7693 cls=0.0511 smmd=0.2873 ct=9.6144 rec=1.1951 | train/val/test=1.000/0.678/0.715 | c=0.998347
[Epoch 0099] loss=15.8541 cls=0.0589 smmd=0.3160 ct=9.6590 rec=1.1992 | train/val/test=1.000/0.684/0.715 | c=0.998347
[Epoch 0100] loss=15.8082 cls=0.0497 smmd=0.3443 ct=9.6175 rec=1.1967 | train/val/test=1.000/0.678/0.711 | c=0.998347
[Epoch 0101] loss=15.7923 cls=0.0523 smmd=0.3433 ct=9.6073 rec=1.1953 | train/val/test=1.000/0.678/0.717 | c=0.998347
[Epoch 0102] loss=15.8610 cls=0.0565 smmd=0.3431 ct=9.6620 rec=1.1976 | train/val/test=1.000/0.686/0.714 | c=0.998347
[Epoch 0103] loss=15.7608 cls=0.0490 smmd=0.2919 ct=9.6176 rec=1.1926 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0104] loss=15.8160 cls=0.0557 smmd=0.3565 ct=9.6088 rec=1.1980 | train/val/test=1.000/0.668/0.715 | c=0.998347
[Epoch 0105] loss=15.8305 cls=0.0544 smmd=0.3094 ct=9.6525 rec=1.1970 | train/val/test=1.000/0.676/0.713 | c=0.998347
[Epoch 0106] loss=15.7767 cls=0.0554 smmd=0.2746 ct=9.6247 rec=1.1952 | train/val/test=1.000/0.684/0.711 | c=0.998347
[Epoch 0107] loss=15.8253 cls=0.0518 smmd=0.3678 ct=9.6137 rec=1.1983 | train/val/test=1.000/0.674/0.715 | c=0.998347
[Epoch 0108] loss=15.7573 cls=0.0505 smmd=0.2612 ct=9.6292 rec=1.1924 | train/val/test=1.000/0.674/0.715 | c=0.998347
[Epoch 0109] loss=15.7877 cls=0.0539 smmd=0.2812 ct=9.6365 rec=1.1946 | train/val/test=1.000/0.684/0.709 | c=0.998347
[Epoch 0110] loss=15.8188 cls=0.0509 smmd=0.3581 ct=9.6165 rec=1.1975 | train/val/test=1.000/0.674/0.711 | c=0.998347
[Epoch 0111] loss=15.7682 cls=0.0538 smmd=0.2875 ct=9.6162 rec=1.1941 | train/val/test=1.000/0.662/0.708 | c=0.998347
[Epoch 0112] loss=15.8243 cls=0.0551 smmd=0.3001 ct=9.6529 rec=1.1965 | train/val/test=1.000/0.680/0.709 | c=0.998347
[Epoch 0113] loss=15.7798 cls=0.0513 smmd=0.3181 ct=9.6117 rec=1.1946 | train/val/test=1.000/0.680/0.712 | c=0.998347
[Epoch 0114] loss=15.7559 cls=0.0484 smmd=0.2896 ct=9.6156 rec=1.1923 | train/val/test=1.000/0.674/0.707 | c=0.998347
[Epoch 0115] loss=15.8004 cls=0.0527 smmd=0.2924 ct=9.6459 rec=1.1943 | train/val/test=1.000/0.676/0.711 | c=0.998347
[Epoch 0116] loss=15.7631 cls=0.0493 smmd=0.3025 ct=9.6124 rec=1.1930 | train/val/test=1.000/0.682/0.713 | c=0.998347
[Epoch 0117] loss=15.7648 cls=0.0501 smmd=0.2970 ct=9.6148 rec=1.1933 | train/val/test=1.000/0.662/0.711 | c=0.998347
[Epoch 0118] loss=15.7928 cls=0.0532 smmd=0.2836 ct=9.6420 rec=1.1944 | train/val/test=1.000/0.676/0.711 | c=0.998347
[Epoch 0119] loss=15.7559 cls=0.0507 smmd=0.2821 ct=9.6151 rec=1.1929 | train/val/test=1.000/0.680/0.713 | c=0.998347
[Epoch 0120] loss=15.7553 cls=0.0503 smmd=0.2756 ct=9.6151 rec=1.1934 | train/val/test=1.000/0.670/0.713 | c=0.998347
[Epoch 0121] loss=15.7753 cls=0.0537 smmd=0.2703 ct=9.6327 rec=1.1940 | train/val/test=1.000/0.678/0.711 | c=0.998347
[Epoch 0122] loss=15.7572 cls=0.0491 smmd=0.2751 ct=9.6186 rec=1.1933 | train/val/test=1.000/0.674/0.705 | c=0.998347
[Epoch 0123] loss=15.7575 cls=0.0534 smmd=0.2675 ct=9.6160 rec=1.1941 | train/val/test=1.000/0.662/0.711 | c=0.998347
[Epoch 0124] loss=15.8082 cls=0.0515 smmd=0.2972 ct=9.6456 rec=1.1956 | train/val/test=1.000/0.684/0.706 | c=0.998347
[Epoch 0125] loss=15.8145 cls=0.0592 smmd=0.3278 ct=9.6236 rec=1.1971 | train/val/test=1.000/0.660/0.712 | c=0.998347
[Epoch 0126] loss=15.8610 cls=0.0517 smmd=0.3531 ct=9.6475 rec=1.2001 | train/val/test=1.000/0.680/0.695 | c=0.998347
[Epoch 0127] loss=15.9040 cls=0.0677 smmd=0.3898 ct=9.6527 rec=1.2018 | train/val/test=1.000/0.652/0.708 | c=0.998347
[Epoch 0128] loss=15.8205 cls=0.0448 smmd=0.3673 ct=9.6401 rec=1.1931 | train/val/test=1.000/0.680/0.707 | c=0.998347
[Epoch 0129] loss=15.7379 cls=0.0383 smmd=0.3271 ct=9.6206 rec=1.1854 | train/val/test=1.000/0.676/0.709 | c=0.998347
[Epoch 0130] loss=15.7594 cls=0.0430 smmd=0.3165 ct=9.6341 rec=1.1874 | train/val/test=1.000/0.666/0.715 | c=0.998347
[Epoch 0131] loss=15.7933 cls=0.0449 smmd=0.3407 ct=9.6362 rec=1.1911 | train/val/test=1.000/0.680/0.706 | c=0.998347
[Epoch 0132] loss=15.7880 cls=0.0543 smmd=0.3248 ct=9.6201 rec=1.1935 | train/val/test=1.000/0.656/0.711 | c=0.998347
[Epoch 0133] loss=15.7827 cls=0.0524 smmd=0.2794 ct=9.6378 rec=1.1937 | train/val/test=1.000/0.680/0.707 | c=0.998347
[Epoch 0134] loss=15.7728 cls=0.0519 smmd=0.2822 ct=9.6269 rec=1.1937 | train/val/test=1.000/0.676/0.704 | c=0.998347
[Epoch 0135] loss=15.8102 cls=0.0611 smmd=0.3232 ct=9.6192 rec=1.1973 | train/val/test=1.000/0.668/0.714 | c=0.998347
[Epoch 0136] loss=15.8618 cls=0.0531 smmd=0.3311 ct=9.6612 rec=1.1996 | train/val/test=1.000/0.678/0.694 | c=0.998347
[Epoch 0137] loss=15.8737 cls=0.0639 smmd=0.3778 ct=9.6423 rec=1.1996 | train/val/test=1.000/0.660/0.712 | c=0.998347
[Epoch 0138] loss=15.7826 cls=0.0397 smmd=0.3638 ct=9.6285 rec=1.1889 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0139] loss=15.7357 cls=0.0396 smmd=0.3063 ct=9.6336 rec=1.1842 | train/val/test=1.000/0.674/0.703 | c=0.998347
[Epoch 0140] loss=15.7951 cls=0.0452 smmd=0.3568 ct=9.6402 rec=1.1890 | train/val/test=1.000/0.668/0.709 | c=0.998347
[Epoch 0141] loss=15.7504 cls=0.0410 smmd=0.3497 ct=9.6166 rec=1.1861 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0142] loss=15.7488 cls=0.0466 smmd=0.2926 ct=9.6293 rec=1.1881 | train/val/test=1.000/0.662/0.700 | c=0.998347
[Epoch 0143] loss=15.8690 cls=0.0658 smmd=0.3635 ct=9.6427 rec=1.1997 | train/val/test=1.000/0.676/0.703 | c=0.998347
[Epoch 0144] loss=15.8790 cls=0.0557 smmd=0.3693 ct=9.6447 rec=1.2021 | train/val/test=1.000/0.678/0.697 | c=0.998347
[Epoch 0145] loss=15.8633 cls=0.0680 smmd=0.3733 ct=9.6343 rec=1.1989 | train/val/test=1.000/0.652/0.712 | c=0.998347
[Epoch 0146] loss=15.7991 cls=0.0436 smmd=0.3410 ct=9.6478 rec=1.1901 | train/val/test=1.000/0.678/0.707 | c=0.998347
[Epoch 0147] loss=15.7553 cls=0.0431 smmd=0.3239 ct=9.6310 rec=1.1864 | train/val/test=1.000/0.664/0.705 | c=0.998347
[Epoch 0148] loss=15.8013 cls=0.0442 smmd=0.4028 ct=9.6292 rec=1.1880 | train/val/test=1.000/0.662/0.706 | c=0.998347
[Epoch 0149] loss=15.7389 cls=0.0388 smmd=0.3269 ct=9.6325 rec=1.1832 | train/val/test=1.000/0.674/0.706 | c=0.998347
[Epoch 0150] loss=15.7623 cls=0.0435 smmd=0.3193 ct=9.6341 rec=1.1876 | train/val/test=1.000/0.664/0.699 | c=0.998347
[Epoch 0151] loss=15.8859 cls=0.0627 smmd=0.4280 ct=9.6325 rec=1.1991 | train/val/test=1.000/0.662/0.705 | c=0.998347
[Epoch 0152] loss=15.8070 cls=0.0522 smmd=0.3297 ct=9.6428 rec=1.1926 | train/val/test=1.000/0.672/0.709 | c=0.998347
[Epoch 0153] loss=15.7301 cls=0.0481 smmd=0.2666 ct=9.6224 rec=1.1881 | train/val/test=1.000/0.658/0.708 | c=0.998347
[Epoch 0154] loss=15.8204 cls=0.0538 smmd=0.3651 ct=9.6234 rec=1.1954 | train/val/test=1.000/0.664/0.700 | c=0.998347
[Epoch 0155] loss=15.8084 cls=0.0515 smmd=0.3377 ct=9.6437 rec=1.1920 | train/val/test=1.000/0.660/0.709 | c=0.998347
[Epoch 0156] loss=15.7227 cls=0.0426 smmd=0.2799 ct=9.6253 rec=1.1855 | train/val/test=1.000/0.668/0.711 | c=0.998347
[Epoch 0157] loss=15.7726 cls=0.0461 smmd=0.3543 ct=9.6184 rec=1.1889 | train/val/test=1.000/0.670/0.706 | c=0.998347
[Epoch 0158] loss=15.7867 cls=0.0483 smmd=0.3357 ct=9.6357 rec=1.1899 | train/val/test=1.000/0.656/0.707 | c=0.998347
[Epoch 0159] loss=15.7819 cls=0.0508 smmd=0.3084 ct=9.6388 rec=1.1907 | train/val/test=1.000/0.678/0.711 | c=0.998347
[Epoch 0160] loss=15.7822 cls=0.0488 smmd=0.3595 ct=9.6155 rec=1.1906 | train/val/test=1.000/0.674/0.706 | c=0.998347
[Epoch 0161] loss=15.7561 cls=0.0474 smmd=0.3008 ct=9.6252 rec=1.1895 | train/val/test=1.000/0.652/0.701 | c=0.998347
[Epoch 0162] loss=15.8277 cls=0.0561 smmd=0.3297 ct=9.6471 rec=1.1953 | train/val/test=1.000/0.678/0.709 | c=0.998347
[Epoch 0163] loss=15.8162 cls=0.0474 smmd=0.3960 ct=9.6244 rec=1.1921 | train/val/test=1.000/0.672/0.708 | c=0.998347
[Epoch 0164] loss=15.7446 cls=0.0490 smmd=0.3200 ct=9.6142 rec=1.1872 | train/val/test=1.000/0.646/0.705 | c=0.998347
[Epoch 0165] loss=15.8633 cls=0.0538 smmd=0.3725 ct=9.6643 rec=1.1950 | train/val/test=1.000/0.674/0.706 | c=0.998347
[Epoch 0166] loss=15.7587 cls=0.0448 smmd=0.3575 ct=9.6169 rec=1.1863 | train/val/test=1.000/0.666/0.707 | c=0.998347
[Epoch 0167] loss=15.7350 cls=0.0422 smmd=0.3408 ct=9.6101 rec=1.1850 | train/val/test=1.000/0.656/0.706 | c=0.998347
[Epoch 0168] loss=15.8004 cls=0.0489 smmd=0.3333 ct=9.6510 rec=1.1897 | train/val/test=1.000/0.668/0.709 | c=0.998347
[Epoch 0169] loss=15.7307 cls=0.0465 smmd=0.3024 ct=9.6169 rec=1.1860 | train/val/test=1.000/0.668/0.708 | c=0.998347
[Epoch 0170] loss=15.7704 cls=0.0481 smmd=0.3423 ct=9.6133 rec=1.1905 | train/val/test=1.000/0.664/0.709 | c=0.998347
[Epoch 0171] loss=15.7655 cls=0.0526 smmd=0.2782 ct=9.6395 rec=1.1900 | train/val/test=1.000/0.664/0.704 | c=0.998347
[Epoch 0172] loss=15.7319 cls=0.0479 smmd=0.2686 ct=9.6201 rec=1.1888 | train/val/test=1.000/0.664/0.704 | c=0.998347
[Epoch 0173] loss=15.7583 cls=0.0520 smmd=0.3073 ct=9.6116 rec=1.1913 | train/val/test=1.000/0.660/0.712 | c=0.998347
[Epoch 0174] loss=15.7672 cls=0.0493 smmd=0.2753 ct=9.6424 rec=1.1905 | train/val/test=1.000/0.668/0.705 | c=0.998347
[Epoch 0175] loss=15.7555 cls=0.0525 smmd=0.2934 ct=9.6217 rec=1.1901 | train/val/test=1.000/0.660/0.712 | c=0.998347
[Epoch 0176] loss=15.8001 cls=0.0477 smmd=0.3405 ct=9.6314 rec=1.1930 | train/val/test=1.000/0.676/0.703 | c=0.998347
[Epoch 0177] loss=15.8222 cls=0.0602 smmd=0.3365 ct=9.6412 rec=1.1941 | train/val/test=1.000/0.656/0.708 | c=0.998347
[Epoch 0178] loss=15.8376 cls=0.0495 smmd=0.3652 ct=9.6471 rec=1.1947 | train/val/test=1.000/0.680/0.707 | c=0.998347
[Epoch 0179] loss=15.7922 cls=0.0508 smmd=0.3481 ct=9.6311 rec=1.1903 | train/val/test=1.000/0.656/0.712 | c=0.998347
[Epoch 0180] loss=15.7190 cls=0.0369 smmd=0.2968 ct=9.6304 rec=1.1829 | train/val/test=1.000/0.654/0.707 | c=0.998347
[Epoch 0181] loss=15.7112 cls=0.0393 smmd=0.2963 ct=9.6209 rec=1.1829 | train/val/test=1.000/0.672/0.707 | c=0.998347
[Epoch 0182] loss=15.7615 cls=0.0504 smmd=0.3190 ct=9.6256 rec=1.1882 | train/val/test=1.000/0.662/0.712 | c=0.998347
[Epoch 0183] loss=15.7985 cls=0.0506 smmd=0.3025 ct=9.6424 rec=1.1939 | train/val/test=1.000/0.676/0.699 | c=0.998347
[Epoch 0184] loss=15.8496 cls=0.0698 smmd=0.3534 ct=9.6352 rec=1.1978 | train/val/test=1.000/0.664/0.713 | c=0.998347
[Epoch 0185] loss=15.8513 cls=0.0516 smmd=0.3648 ct=9.6502 rec=1.1965 | train/val/test=1.000/0.674/0.704 | c=0.998347
[Epoch 0186] loss=15.7611 cls=0.0486 smmd=0.3301 ct=9.6239 rec=1.1876 | train/val/test=1.000/0.660/0.704 | c=0.998347
[Epoch 0187] loss=15.7087 cls=0.0379 smmd=0.2920 ct=9.6259 rec=1.1820 | train/val/test=1.000/0.670/0.710 | c=0.998347
[Epoch 0188] loss=15.7338 cls=0.0384 smmd=0.3116 ct=9.6316 rec=1.1839 | train/val/test=1.000/0.678/0.705 | c=0.998347
[Epoch 0189] loss=15.7573 cls=0.0478 smmd=0.3287 ct=9.6195 rec=1.1880 | train/val/test=1.000/0.652/0.713 | c=0.998347
[Epoch 0190] loss=15.7573 cls=0.0463 smmd=0.2908 ct=9.6356 rec=1.1888 | train/val/test=1.000/0.672/0.708 | c=0.998347
[Epoch 0191] loss=15.7406 cls=0.0501 smmd=0.2801 ct=9.6261 rec=1.1879 | train/val/test=1.000/0.660/0.708 | c=0.998347
[Epoch 0192] loss=15.7491 cls=0.0518 smmd=0.2893 ct=9.6150 rec=1.1906 | train/val/test=1.000/0.662/0.709 | c=0.998347
[Epoch 0193] loss=15.7684 cls=0.0498 smmd=0.2718 ct=9.6413 rec=1.1913 | train/val/test=1.000/0.672/0.704 | c=0.998347
[Epoch 0194] loss=15.7754 cls=0.0569 smmd=0.3140 ct=9.6218 rec=1.1914 | train/val/test=1.000/0.662/0.715 | c=0.998347
[Epoch 0195] loss=15.7910 cls=0.0464 smmd=0.3263 ct=9.6352 rec=1.1920 | train/val/test=1.000/0.668/0.709 | c=0.998347
[Epoch 0196] loss=15.7970 cls=0.0561 smmd=0.3319 ct=9.6404 rec=1.1903 | train/val/test=1.000/0.660/0.710 | c=0.998347
[Epoch 0197] loss=15.7387 cls=0.0415 smmd=0.3039 ct=9.6287 rec=1.1858 | train/val/test=1.000/0.674/0.705 | c=0.998347
[Epoch 0198] loss=15.7056 cls=0.0388 smmd=0.2998 ct=9.6158 rec=1.1825 | train/val/test=1.000/0.666/0.704 | c=0.998347
[Epoch 0199] loss=15.7213 cls=0.0441 smmd=0.2770 ct=9.6271 rec=1.1850 | train/val/test=1.000/0.656/0.713 | c=0.998347
=== Best @ epoch 26: val=0.6900, test=0.6860 ===

==================================================
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-5-5 - 2025-09-21 06:22:05:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-5-5...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-5-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=26, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=19.7767 cls=1.7909 smmd=4.1588 ct=9.4852 rec=1.3917 | train/val/test=0.192/0.058/0.077 | c=0.998347
[Epoch 0001] loss=19.4683 cls=1.7653 smmd=3.6068 ct=9.4707 rec=1.3917 | train/val/test=0.577/0.212/0.258 | c=0.998347
[Epoch 0002] loss=18.8795 cls=1.7275 smmd=2.6185 ct=9.4026 rec=1.3917 | train/val/test=0.500/0.210/0.229 | c=0.998347
[Epoch 0003] loss=18.7508 cls=1.6750 smmd=2.5629 ct=9.3386 rec=1.3917 | train/val/test=0.615/0.312/0.349 | c=0.998347
[Epoch 0004] loss=18.2597 cls=1.5979 smmd=2.1004 ct=9.1342 rec=1.3914 | train/val/test=0.692/0.364/0.411 | c=0.998347
[Epoch 0005] loss=17.8032 cls=1.5114 smmd=1.5407 ct=9.0218 rec=1.3906 | train/val/test=0.769/0.398/0.432 | c=0.998347
[Epoch 0006] loss=17.7934 cls=1.4250 smmd=1.6787 ct=9.0085 rec=1.3896 | train/val/test=0.808/0.452/0.477 | c=0.998347
[Epoch 0007] loss=17.6265 cls=1.3378 smmd=1.5122 ct=8.9917 rec=1.3885 | train/val/test=0.808/0.464/0.497 | c=0.998347
[Epoch 0008] loss=18.1029 cls=1.2584 smmd=1.1609 ct=9.7050 rec=1.3873 | train/val/test=0.846/0.460/0.489 | c=0.998347
[Epoch 0009] loss=17.9569 cls=1.1868 smmd=1.2381 ct=9.5775 rec=1.3859 | train/val/test=0.885/0.414/0.448 | c=0.998347
[Epoch 0010] loss=17.9877 cls=1.1286 smmd=1.5022 ct=9.5203 rec=1.3852 | train/val/test=0.885/0.464/0.489 | c=0.998347
[Epoch 0011] loss=17.8622 cls=1.0594 smmd=1.4056 ct=9.4968 rec=1.3842 | train/val/test=0.885/0.518/0.539 | c=0.998347
[Epoch 0012] loss=17.7213 cls=0.9967 smmd=1.1201 ct=9.5463 rec=1.3834 | train/val/test=0.923/0.528/0.543 | c=0.998347
[Epoch 0013] loss=17.6487 cls=0.9420 smmd=0.9266 ct=9.6118 rec=1.3828 | train/val/test=0.923/0.508/0.530 | c=0.998347
[Epoch 0014] loss=17.5974 cls=0.8891 smmd=0.8693 ct=9.6282 rec=1.3824 | train/val/test=0.962/0.578/0.586 | c=0.998347
[Epoch 0015] loss=17.4914 cls=0.8305 smmd=0.8145 ct=9.5950 rec=1.3816 | train/val/test=1.000/0.610/0.603 | c=0.998347
[Epoch 0016] loss=17.4382 cls=0.7738 smmd=0.8705 ct=9.5590 rec=1.3805 | train/val/test=1.000/0.596/0.610 | c=0.998347
[Epoch 0017] loss=17.3849 cls=0.7175 smmd=0.8541 ct=9.5590 rec=1.3793 | train/val/test=1.000/0.626/0.625 | c=0.998347
[Epoch 0018] loss=17.2912 cls=0.6557 smmd=0.7369 ct=9.5768 rec=1.3774 | train/val/test=1.000/0.640/0.642 | c=0.998347
[Epoch 0019] loss=17.2110 cls=0.5994 smmd=0.6421 ct=9.5940 rec=1.3753 | train/val/test=1.000/0.646/0.656 | c=0.998347
[Epoch 0020] loss=17.1507 cls=0.5465 smmd=0.6196 ct=9.5936 rec=1.3729 | train/val/test=1.000/0.648/0.649 | c=0.998347
[Epoch 0021] loss=17.0762 cls=0.4950 smmd=0.5743 ct=9.5922 rec=1.3701 | train/val/test=1.000/0.672/0.662 | c=0.998347
[Epoch 0022] loss=17.0159 cls=0.4504 smmd=0.5534 ct=9.5896 rec=1.3669 | train/val/test=1.000/0.676/0.672 | c=0.998347
[Epoch 0023] loss=16.9549 cls=0.4108 smmd=0.5234 ct=9.5890 rec=1.3633 | train/val/test=1.000/0.664/0.675 | c=0.998347
[Epoch 0024] loss=16.9075 cls=0.3730 smmd=0.5179 ct=9.5915 rec=1.3592 | train/val/test=1.000/0.678/0.680 | c=0.998347
[Epoch 0025] loss=16.8478 cls=0.3420 smmd=0.4778 ct=9.5968 rec=1.3545 | train/val/test=1.000/0.680/0.681 | c=0.998347
[Epoch 0026] loss=16.7887 cls=0.3152 smmd=0.4461 ct=9.5991 rec=1.3492 | train/val/test=1.000/0.690/0.686 | c=0.998347
[Epoch 0027] loss=16.7384 cls=0.2888 smmd=0.4399 ct=9.6034 rec=1.3426 | train/val/test=1.000/0.676/0.687 | c=0.998347
[Epoch 0028] loss=16.6688 cls=0.2668 smmd=0.4045 ct=9.6061 rec=1.3347 | train/val/test=1.000/0.682/0.690 | c=0.998347
[Epoch 0029] loss=16.6163 cls=0.2470 smmd=0.4096 ct=9.6082 rec=1.3261 | train/val/test=1.000/0.672/0.693 | c=0.998347
[Epoch 0030] loss=16.5548 cls=0.2271 smmd=0.4020 ct=9.6083 rec=1.3173 | train/val/test=1.000/0.672/0.687 | c=0.998347
[Epoch 0031] loss=16.4959 cls=0.2116 smmd=0.3935 ct=9.6065 rec=1.3089 | train/val/test=1.000/0.676/0.696 | c=0.998347
[Epoch 0032] loss=16.4411 cls=0.1968 smmd=0.3719 ct=9.6148 rec=1.3005 | train/val/test=1.000/0.676/0.699 | c=0.998347
[Epoch 0033] loss=16.3958 cls=0.1833 smmd=0.3676 ct=9.6191 rec=1.2929 | train/val/test=1.000/0.676/0.695 | c=0.998347
[Epoch 0034] loss=16.3431 cls=0.1740 smmd=0.3439 ct=9.6171 rec=1.2864 | train/val/test=1.000/0.680/0.696 | c=0.998347
[Epoch 0035] loss=16.3105 cls=0.1633 smmd=0.3595 ct=9.6173 rec=1.2798 | train/val/test=1.000/0.670/0.699 | c=0.998347
[Epoch 0036] loss=16.2791 cls=0.1556 smmd=0.3659 ct=9.6144 rec=1.2746 | train/val/test=1.000/0.664/0.700 | c=0.998347
[Epoch 0037] loss=16.2464 cls=0.1491 smmd=0.3471 ct=9.6184 rec=1.2700 | train/val/test=1.000/0.672/0.708 | c=0.998347
[Epoch 0038] loss=16.2208 cls=0.1427 smmd=0.3381 ct=9.6228 rec=1.2658 | train/val/test=1.000/0.670/0.699 | c=0.998347
[Epoch 0039] loss=16.1919 cls=0.1384 smmd=0.3243 ct=9.6199 rec=1.2626 | train/val/test=1.000/0.678/0.707 | c=0.998347
[Epoch 0040] loss=16.1699 cls=0.1322 smmd=0.3293 ct=9.6184 rec=1.2589 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0041] loss=16.1502 cls=0.1279 smmd=0.3278 ct=9.6192 rec=1.2555 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0042] loss=16.1213 cls=0.1220 smmd=0.3095 ct=9.6214 rec=1.2520 | train/val/test=1.000/0.684/0.706 | c=0.998347
[Epoch 0043] loss=16.1037 cls=0.1171 smmd=0.3179 ct=9.6200 rec=1.2486 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0044] loss=16.0828 cls=0.1122 smmd=0.3125 ct=9.6226 rec=1.2451 | train/val/test=1.000/0.678/0.707 | c=0.998347
[Epoch 0045] loss=16.0640 cls=0.1079 smmd=0.3107 ct=9.6226 rec=1.2421 | train/val/test=1.000/0.684/0.706 | c=0.998347
[Epoch 0046] loss=16.0485 cls=0.1043 smmd=0.3108 ct=9.6229 rec=1.2394 | train/val/test=1.000/0.680/0.707 | c=0.998347
[Epoch 0047] loss=16.0332 cls=0.1013 smmd=0.3112 ct=9.6202 rec=1.2373 | train/val/test=1.000/0.684/0.709 | c=0.998347
[Epoch 0048] loss=16.0150 cls=0.0991 smmd=0.2911 ct=9.6229 rec=1.2354 | train/val/test=1.000/0.682/0.711 | c=0.998347
[Epoch 0049] loss=16.0070 cls=0.0965 smmd=0.2935 ct=9.6240 rec=1.2337 | train/val/test=1.000/0.682/0.708 | c=0.998347
[Epoch 0050] loss=15.9982 cls=0.0950 smmd=0.2955 ct=9.6224 rec=1.2323 | train/val/test=1.000/0.680/0.710 | c=0.998347
[Epoch 0051] loss=15.9826 cls=0.0916 smmd=0.2870 ct=9.6221 rec=1.2306 | train/val/test=1.000/0.682/0.708 | c=0.998347
[Epoch 0052] loss=15.9738 cls=0.0912 smmd=0.2858 ct=9.6196 rec=1.2295 | train/val/test=1.000/0.672/0.711 | c=0.998347
[Epoch 0053] loss=15.9740 cls=0.0861 smmd=0.2892 ct=9.6313 rec=1.2276 | train/val/test=1.000/0.686/0.705 | c=0.998347
[Epoch 0054] loss=16.0180 cls=0.0966 smmd=0.3453 ct=9.6251 rec=1.2305 | train/val/test=1.000/0.670/0.693 | c=0.998347
[Epoch 0055] loss=16.1664 cls=0.0958 smmd=0.4667 ct=9.6846 rec=1.2363 | train/val/test=1.000/0.654/0.657 | c=0.998347
[Epoch 0056] loss=16.2797 cls=0.1361 smmd=0.5586 ct=9.6716 rec=1.2467 | train/val/test=1.000/0.668/0.705 | c=0.998347
[Epoch 0057] loss=16.0324 cls=0.0667 smmd=0.4603 ct=9.6600 rec=1.2191 | train/val/test=1.000/0.676/0.718 | c=0.998347
[Epoch 0058] loss=15.9240 cls=0.0550 smmd=0.3923 ct=9.6446 rec=1.2090 | train/val/test=1.000/0.678/0.696 | c=0.998347
[Epoch 0059] loss=16.0643 cls=0.0744 smmd=0.5205 ct=9.6501 rec=1.2204 | train/val/test=1.000/0.686/0.715 | c=0.998347
[Epoch 0060] loss=15.8997 cls=0.0542 smmd=0.4135 ct=9.6320 rec=1.2046 | train/val/test=1.000/0.672/0.716 | c=0.998347
[Epoch 0061] loss=16.0326 cls=0.0672 smmd=0.5024 ct=9.6628 rec=1.2143 | train/val/test=1.000/0.688/0.714 | c=0.998347
[Epoch 0062] loss=15.9847 cls=0.0788 smmd=0.4414 ct=9.6353 rec=1.2147 | train/val/test=1.000/0.684/0.717 | c=0.998347
[Epoch 0063] loss=15.8950 cls=0.0731 smmd=0.3326 ct=9.6242 rec=1.2107 | train/val/test=1.000/0.664/0.705 | c=0.998347
[Epoch 0064] loss=16.0701 cls=0.0834 smmd=0.4598 ct=9.6667 rec=1.2230 | train/val/test=1.000/0.688/0.708 | c=0.998347
[Epoch 0065] loss=16.0340 cls=0.1049 smmd=0.4035 ct=9.6440 rec=1.2229 | train/val/test=1.000/0.676/0.720 | c=0.998347
[Epoch 0066] loss=15.8610 cls=0.0630 smmd=0.3196 ct=9.6181 rec=1.2078 | train/val/test=1.000/0.670/0.713 | c=0.998347
[Epoch 0067] loss=15.9542 cls=0.0621 smmd=0.3891 ct=9.6558 rec=1.2121 | train/val/test=1.000/0.690/0.719 | c=0.998347
[Epoch 0068] loss=15.9260 cls=0.0661 smmd=0.3714 ct=9.6389 rec=1.2110 | train/val/test=1.000/0.678/0.717 | c=0.998347
[Epoch 0069] loss=15.8489 cls=0.0548 smmd=0.3583 ct=9.6142 rec=1.2034 | train/val/test=1.000/0.672/0.712 | c=0.998347
[Epoch 0070] loss=15.9330 cls=0.0602 smmd=0.3931 ct=9.6542 rec=1.2080 | train/val/test=1.000/0.684/0.719 | c=0.998347
[Epoch 0071] loss=15.8706 cls=0.0627 smmd=0.3317 ct=9.6328 rec=1.2056 | train/val/test=1.000/0.682/0.713 | c=0.998347
[Epoch 0072] loss=15.8709 cls=0.0640 smmd=0.3627 ct=9.6136 rec=1.2062 | train/val/test=1.000/0.674/0.711 | c=0.998347
[Epoch 0073] loss=15.9505 cls=0.0705 smmd=0.3813 ct=9.6587 rec=1.2104 | train/val/test=1.000/0.684/0.717 | c=0.998347
[Epoch 0074] loss=15.9053 cls=0.0776 smmd=0.3414 ct=9.6355 rec=1.2090 | train/val/test=1.000/0.682/0.718 | c=0.998347
[Epoch 0075] loss=15.8780 cls=0.0647 smmd=0.3711 ct=9.6130 rec=1.2068 | train/val/test=1.000/0.682/0.719 | c=0.998347
[Epoch 0076] loss=15.9027 cls=0.0607 smmd=0.3581 ct=9.6509 rec=1.2060 | train/val/test=1.000/0.684/0.715 | c=0.998347
[Epoch 0077] loss=15.8865 cls=0.0680 smmd=0.3397 ct=9.6385 rec=1.2061 | train/val/test=1.000/0.684/0.722 | c=0.998347
[Epoch 0078] loss=15.8872 cls=0.0559 smmd=0.4229 ct=9.6144 rec=1.2044 | train/val/test=1.000/0.684/0.720 | c=0.998347
[Epoch 0079] loss=15.8424 cls=0.0541 smmd=0.3214 ct=9.6410 rec=1.2006 | train/val/test=1.000/0.676/0.711 | c=0.998347
[Epoch 0080] loss=15.8827 cls=0.0644 smmd=0.3382 ct=9.6448 rec=1.2047 | train/val/test=1.000/0.688/0.720 | c=0.998347
[Epoch 0081] loss=15.8999 cls=0.0571 smmd=0.4458 ct=9.6135 rec=1.2047 | train/val/test=1.000/0.686/0.719 | c=0.998347
[Epoch 0082] loss=15.8155 cls=0.0558 smmd=0.3100 ct=9.6276 rec=1.1988 | train/val/test=1.000/0.676/0.710 | c=0.998347
[Epoch 0083] loss=15.9260 cls=0.0729 smmd=0.3576 ct=9.6586 rec=1.2075 | train/val/test=1.000/0.690/0.721 | c=0.998347
[Epoch 0084] loss=15.9211 cls=0.0588 smmd=0.4497 ct=9.6235 rec=1.2063 | train/val/test=1.000/0.688/0.716 | c=0.998347
[Epoch 0085] loss=15.7933 cls=0.0532 smmd=0.3195 ct=9.6124 rec=1.1968 | train/val/test=1.000/0.678/0.708 | c=0.998347
[Epoch 0086] loss=15.9475 cls=0.0698 smmd=0.3913 ct=9.6687 rec=1.2069 | train/val/test=1.000/0.688/0.718 | c=0.998347
[Epoch 0087] loss=15.8804 cls=0.0525 smmd=0.4189 ct=9.6271 rec=1.2014 | train/val/test=1.000/0.690/0.715 | c=0.998347
[Epoch 0088] loss=15.8142 cls=0.0517 smmd=0.3665 ct=9.6101 rec=1.1969 | train/val/test=1.000/0.680/0.709 | c=0.998347
[Epoch 0089] loss=15.9120 cls=0.0613 smmd=0.3940 ct=9.6641 rec=1.2016 | train/val/test=1.000/0.686/0.722 | c=0.998347
[Epoch 0090] loss=15.7901 cls=0.0490 smmd=0.3287 ct=9.6233 rec=1.1936 | train/val/test=1.000/0.688/0.715 | c=0.998347
[Epoch 0091] loss=15.8629 cls=0.0565 smmd=0.4264 ct=9.6118 rec=1.1997 | train/val/test=1.000/0.686/0.717 | c=0.998347
[Epoch 0092] loss=15.8166 cls=0.0552 smmd=0.3176 ct=9.6414 rec=1.1956 | train/val/test=1.000/0.688/0.720 | c=0.998347
[Epoch 0093] loss=15.7979 cls=0.0549 smmd=0.2900 ct=9.6349 rec=1.1959 | train/val/test=1.000/0.684/0.715 | c=0.998347
[Epoch 0094] loss=15.8719 cls=0.0603 smmd=0.4152 ct=9.6086 rec=1.2027 | train/val/test=1.000/0.680/0.720 | c=0.998347
[Epoch 0095] loss=15.8024 cls=0.0544 smmd=0.2898 ct=9.6321 rec=1.1975 | train/val/test=1.000/0.680/0.712 | c=0.998347
[Epoch 0096] loss=15.8508 cls=0.0628 smmd=0.3022 ct=9.6483 rec=1.2015 | train/val/test=1.000/0.690/0.715 | c=0.998347
[Epoch 0097] loss=15.8606 cls=0.0551 smmd=0.3905 ct=9.6138 rec=1.2026 | train/val/test=1.000/0.686/0.718 | c=0.998347
[Epoch 0098] loss=15.7693 cls=0.0511 smmd=0.2873 ct=9.6144 rec=1.1951 | train/val/test=1.000/0.678/0.715 | c=0.998347
[Epoch 0099] loss=15.8541 cls=0.0589 smmd=0.3160 ct=9.6590 rec=1.1992 | train/val/test=1.000/0.684/0.715 | c=0.998347
[Epoch 0100] loss=15.8082 cls=0.0497 smmd=0.3443 ct=9.6175 rec=1.1967 | train/val/test=1.000/0.678/0.711 | c=0.998347
[Epoch 0101] loss=15.7923 cls=0.0523 smmd=0.3433 ct=9.6073 rec=1.1953 | train/val/test=1.000/0.678/0.717 | c=0.998347
[Epoch 0102] loss=15.8610 cls=0.0565 smmd=0.3431 ct=9.6620 rec=1.1976 | train/val/test=1.000/0.686/0.714 | c=0.998347
[Epoch 0103] loss=15.7608 cls=0.0490 smmd=0.2919 ct=9.6176 rec=1.1926 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0104] loss=15.8160 cls=0.0557 smmd=0.3565 ct=9.6088 rec=1.1980 | train/val/test=1.000/0.668/0.715 | c=0.998347
[Epoch 0105] loss=15.8305 cls=0.0544 smmd=0.3094 ct=9.6525 rec=1.1970 | train/val/test=1.000/0.676/0.713 | c=0.998347
[Epoch 0106] loss=15.7767 cls=0.0554 smmd=0.2746 ct=9.6247 rec=1.1952 | train/val/test=1.000/0.684/0.711 | c=0.998347
[Epoch 0107] loss=15.8253 cls=0.0518 smmd=0.3678 ct=9.6137 rec=1.1983 | train/val/test=1.000/0.674/0.715 | c=0.998347
[Epoch 0108] loss=15.7573 cls=0.0505 smmd=0.2612 ct=9.6292 rec=1.1924 | train/val/test=1.000/0.674/0.715 | c=0.998347
[Epoch 0109] loss=15.7877 cls=0.0539 smmd=0.2812 ct=9.6365 rec=1.1946 | train/val/test=1.000/0.684/0.709 | c=0.998347
[Epoch 0110] loss=15.8188 cls=0.0509 smmd=0.3581 ct=9.6165 rec=1.1975 | train/val/test=1.000/0.674/0.711 | c=0.998347
[Epoch 0111] loss=15.7682 cls=0.0538 smmd=0.2875 ct=9.6162 rec=1.1941 | train/val/test=1.000/0.662/0.708 | c=0.998347
[Epoch 0112] loss=15.8243 cls=0.0551 smmd=0.3001 ct=9.6529 rec=1.1965 | train/val/test=1.000/0.680/0.709 | c=0.998347
[Epoch 0113] loss=15.7798 cls=0.0513 smmd=0.3181 ct=9.6117 rec=1.1946 | train/val/test=1.000/0.680/0.712 | c=0.998347
[Epoch 0114] loss=15.7559 cls=0.0484 smmd=0.2896 ct=9.6156 rec=1.1923 | train/val/test=1.000/0.674/0.707 | c=0.998347
[Epoch 0115] loss=15.8004 cls=0.0527 smmd=0.2924 ct=9.6459 rec=1.1943 | train/val/test=1.000/0.676/0.711 | c=0.998347
[Epoch 0116] loss=15.7631 cls=0.0493 smmd=0.3025 ct=9.6124 rec=1.1930 | train/val/test=1.000/0.682/0.713 | c=0.998347
[Epoch 0117] loss=15.7648 cls=0.0501 smmd=0.2970 ct=9.6148 rec=1.1933 | train/val/test=1.000/0.662/0.711 | c=0.998347
[Epoch 0118] loss=15.7928 cls=0.0532 smmd=0.2836 ct=9.6420 rec=1.1944 | train/val/test=1.000/0.676/0.711 | c=0.998347
[Epoch 0119] loss=15.7559 cls=0.0507 smmd=0.2821 ct=9.6151 rec=1.1929 | train/val/test=1.000/0.680/0.713 | c=0.998347
[Epoch 0120] loss=15.7553 cls=0.0503 smmd=0.2756 ct=9.6151 rec=1.1934 | train/val/test=1.000/0.670/0.713 | c=0.998347
[Epoch 0121] loss=15.7753 cls=0.0537 smmd=0.2703 ct=9.6327 rec=1.1940 | train/val/test=1.000/0.678/0.711 | c=0.998347
[Epoch 0122] loss=15.7572 cls=0.0491 smmd=0.2751 ct=9.6186 rec=1.1933 | train/val/test=1.000/0.674/0.705 | c=0.998347
[Epoch 0123] loss=15.7575 cls=0.0534 smmd=0.2675 ct=9.6160 rec=1.1941 | train/val/test=1.000/0.662/0.711 | c=0.998347
[Epoch 0124] loss=15.8082 cls=0.0515 smmd=0.2972 ct=9.6456 rec=1.1956 | train/val/test=1.000/0.684/0.706 | c=0.998347
[Epoch 0125] loss=15.8145 cls=0.0592 smmd=0.3278 ct=9.6236 rec=1.1971 | train/val/test=1.000/0.660/0.712 | c=0.998347
[Epoch 0126] loss=15.8610 cls=0.0517 smmd=0.3531 ct=9.6475 rec=1.2001 | train/val/test=1.000/0.680/0.695 | c=0.998347
[Epoch 0127] loss=15.9040 cls=0.0677 smmd=0.3898 ct=9.6527 rec=1.2018 | train/val/test=1.000/0.652/0.708 | c=0.998347
[Epoch 0128] loss=15.8205 cls=0.0448 smmd=0.3673 ct=9.6401 rec=1.1931 | train/val/test=1.000/0.680/0.707 | c=0.998347
[Epoch 0129] loss=15.7379 cls=0.0383 smmd=0.3271 ct=9.6206 rec=1.1854 | train/val/test=1.000/0.676/0.709 | c=0.998347
[Epoch 0130] loss=15.7594 cls=0.0430 smmd=0.3165 ct=9.6341 rec=1.1874 | train/val/test=1.000/0.666/0.715 | c=0.998347
[Epoch 0131] loss=15.7933 cls=0.0449 smmd=0.3407 ct=9.6362 rec=1.1911 | train/val/test=1.000/0.680/0.706 | c=0.998347
[Epoch 0132] loss=15.7880 cls=0.0543 smmd=0.3248 ct=9.6201 rec=1.1935 | train/val/test=1.000/0.656/0.711 | c=0.998347
[Epoch 0133] loss=15.7827 cls=0.0524 smmd=0.2794 ct=9.6378 rec=1.1937 | train/val/test=1.000/0.680/0.707 | c=0.998347
[Epoch 0134] loss=15.7728 cls=0.0519 smmd=0.2822 ct=9.6269 rec=1.1937 | train/val/test=1.000/0.676/0.704 | c=0.998347
[Epoch 0135] loss=15.8102 cls=0.0611 smmd=0.3232 ct=9.6192 rec=1.1973 | train/val/test=1.000/0.668/0.714 | c=0.998347
[Epoch 0136] loss=15.8618 cls=0.0531 smmd=0.3311 ct=9.6612 rec=1.1996 | train/val/test=1.000/0.678/0.694 | c=0.998347
[Epoch 0137] loss=15.8737 cls=0.0639 smmd=0.3778 ct=9.6423 rec=1.1996 | train/val/test=1.000/0.660/0.712 | c=0.998347
[Epoch 0138] loss=15.7826 cls=0.0397 smmd=0.3638 ct=9.6285 rec=1.1889 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0139] loss=15.7357 cls=0.0396 smmd=0.3063 ct=9.6336 rec=1.1842 | train/val/test=1.000/0.674/0.703 | c=0.998347
[Epoch 0140] loss=15.7951 cls=0.0452 smmd=0.3568 ct=9.6402 rec=1.1890 | train/val/test=1.000/0.668/0.709 | c=0.998347
[Epoch 0141] loss=15.7504 cls=0.0410 smmd=0.3497 ct=9.6166 rec=1.1861 | train/val/test=1.000/0.680/0.708 | c=0.998347
[Epoch 0142] loss=15.7488 cls=0.0466 smmd=0.2926 ct=9.6293 rec=1.1881 | train/val/test=1.000/0.662/0.700 | c=0.998347
[Epoch 0143] loss=15.8690 cls=0.0658 smmd=0.3635 ct=9.6427 rec=1.1997 | train/val/test=1.000/0.676/0.703 | c=0.998347
[Epoch 0144] loss=15.8790 cls=0.0557 smmd=0.3693 ct=9.6447 rec=1.2021 | train/val/test=1.000/0.678/0.697 | c=0.998347
[Epoch 0145] loss=15.8633 cls=0.0680 smmd=0.3733 ct=9.6343 rec=1.1989 | train/val/test=1.000/0.652/0.712 | c=0.998347
[Epoch 0146] loss=15.7991 cls=0.0436 smmd=0.3410 ct=9.6478 rec=1.1901 | train/val/test=1.000/0.678/0.707 | c=0.998347
[Epoch 0147] loss=15.7553 cls=0.0431 smmd=0.3239 ct=9.6310 rec=1.1864 | train/val/test=1.000/0.664/0.705 | c=0.998347
[Epoch 0148] loss=15.8013 cls=0.0442 smmd=0.4028 ct=9.6292 rec=1.1880 | train/val/test=1.000/0.662/0.706 | c=0.998347
[Epoch 0149] loss=15.7389 cls=0.0388 smmd=0.3269 ct=9.6325 rec=1.1832 | train/val/test=1.000/0.674/0.706 | c=0.998347
[Epoch 0150] loss=15.7623 cls=0.0435 smmd=0.3193 ct=9.6341 rec=1.1876 | train/val/test=1.000/0.664/0.699 | c=0.998347
[Epoch 0151] loss=15.8859 cls=0.0627 smmd=0.4280 ct=9.6325 rec=1.1991 | train/val/test=1.000/0.662/0.705 | c=0.998347
[Epoch 0152] loss=15.8070 cls=0.0522 smmd=0.3297 ct=9.6428 rec=1.1926 | train/val/test=1.000/0.672/0.709 | c=0.998347
[Epoch 0153] loss=15.7301 cls=0.0481 smmd=0.2666 ct=9.6224 rec=1.1881 | train/val/test=1.000/0.658/0.708 | c=0.998347
[Epoch 0154] loss=15.8204 cls=0.0538 smmd=0.3651 ct=9.6234 rec=1.1954 | train/val/test=1.000/0.664/0.700 | c=0.998347
[Epoch 0155] loss=15.8084 cls=0.0515 smmd=0.3377 ct=9.6437 rec=1.1920 | train/val/test=1.000/0.660/0.709 | c=0.998347
[Epoch 0156] loss=15.7227 cls=0.0426 smmd=0.2799 ct=9.6253 rec=1.1855 | train/val/test=1.000/0.668/0.711 | c=0.998347
[Epoch 0157] loss=15.7726 cls=0.0461 smmd=0.3543 ct=9.6184 rec=1.1889 | train/val/test=1.000/0.670/0.706 | c=0.998347
[Epoch 0158] loss=15.7867 cls=0.0483 smmd=0.3357 ct=9.6357 rec=1.1899 | train/val/test=1.000/0.656/0.707 | c=0.998347
[Epoch 0159] loss=15.7819 cls=0.0508 smmd=0.3084 ct=9.6388 rec=1.1907 | train/val/test=1.000/0.678/0.711 | c=0.998347
[Epoch 0160] loss=15.7822 cls=0.0488 smmd=0.3595 ct=9.6155 rec=1.1906 | train/val/test=1.000/0.674/0.706 | c=0.998347
[Epoch 0161] loss=15.7561 cls=0.0474 smmd=0.3008 ct=9.6252 rec=1.1895 | train/val/test=1.000/0.652/0.701 | c=0.998347
[Epoch 0162] loss=15.8277 cls=0.0561 smmd=0.3297 ct=9.6471 rec=1.1953 | train/val/test=1.000/0.678/0.709 | c=0.998347
[Epoch 0163] loss=15.8162 cls=0.0474 smmd=0.3960 ct=9.6244 rec=1.1921 | train/val/test=1.000/0.672/0.708 | c=0.998347
[Epoch 0164] loss=15.7446 cls=0.0490 smmd=0.3200 ct=9.6142 rec=1.1872 | train/val/test=1.000/0.646/0.705 | c=0.998347
[Epoch 0165] loss=15.8633 cls=0.0538 smmd=0.3725 ct=9.6643 rec=1.1950 | train/val/test=1.000/0.674/0.706 | c=0.998347
[Epoch 0166] loss=15.7587 cls=0.0448 smmd=0.3575 ct=9.6169 rec=1.1863 | train/val/test=1.000/0.666/0.707 | c=0.998347
[Epoch 0167] loss=15.7350 cls=0.0422 smmd=0.3408 ct=9.6101 rec=1.1850 | train/val/test=1.000/0.656/0.706 | c=0.998347
[Epoch 0168] loss=15.8004 cls=0.0489 smmd=0.3333 ct=9.6510 rec=1.1897 | train/val/test=1.000/0.668/0.709 | c=0.998347
[Epoch 0169] loss=15.7307 cls=0.0465 smmd=0.3024 ct=9.6169 rec=1.1860 | train/val/test=1.000/0.668/0.708 | c=0.998347
[Epoch 0170] loss=15.7704 cls=0.0481 smmd=0.3423 ct=9.6133 rec=1.1905 | train/val/test=1.000/0.664/0.709 | c=0.998347
[Epoch 0171] loss=15.7655 cls=0.0526 smmd=0.2782 ct=9.6395 rec=1.1900 | train/val/test=1.000/0.664/0.704 | c=0.998347
[Epoch 0172] loss=15.7319 cls=0.0479 smmd=0.2686 ct=9.6201 rec=1.1888 | train/val/test=1.000/0.664/0.704 | c=0.998347
[Epoch 0173] loss=15.7583 cls=0.0520 smmd=0.3073 ct=9.6116 rec=1.1913 | train/val/test=1.000/0.660/0.712 | c=0.998347
[Epoch 0174] loss=15.7672 cls=0.0493 smmd=0.2753 ct=9.6424 rec=1.1905 | train/val/test=1.000/0.668/0.705 | c=0.998347
[Epoch 0175] loss=15.7555 cls=0.0525 smmd=0.2934 ct=9.6217 rec=1.1901 | train/val/test=1.000/0.660/0.712 | c=0.998347
[Epoch 0176] loss=15.8001 cls=0.0477 smmd=0.3405 ct=9.6314 rec=1.1930 | train/val/test=1.000/0.676/0.703 | c=0.998347
[Epoch 0177] loss=15.8222 cls=0.0602 smmd=0.3365 ct=9.6412 rec=1.1941 | train/val/test=1.000/0.656/0.708 | c=0.998347
[Epoch 0178] loss=15.8376 cls=0.0495 smmd=0.3652 ct=9.6471 rec=1.1947 | train/val/test=1.000/0.680/0.707 | c=0.998347
[Epoch 0179] loss=15.7922 cls=0.0508 smmd=0.3481 ct=9.6311 rec=1.1903 | train/val/test=1.000/0.656/0.712 | c=0.998347
[Epoch 0180] loss=15.7190 cls=0.0369 smmd=0.2968 ct=9.6304 rec=1.1829 | train/val/test=1.000/0.654/0.707 | c=0.998347
[Epoch 0181] loss=15.7112 cls=0.0393 smmd=0.2963 ct=9.6209 rec=1.1829 | train/val/test=1.000/0.672/0.707 | c=0.998347
[Epoch 0182] loss=15.7615 cls=0.0504 smmd=0.3190 ct=9.6256 rec=1.1882 | train/val/test=1.000/0.662/0.712 | c=0.998347
[Epoch 0183] loss=15.7985 cls=0.0506 smmd=0.3025 ct=9.6424 rec=1.1939 | train/val/test=1.000/0.676/0.699 | c=0.998347
[Epoch 0184] loss=15.8496 cls=0.0698 smmd=0.3534 ct=9.6352 rec=1.1978 | train/val/test=1.000/0.664/0.713 | c=0.998347
[Epoch 0185] loss=15.8513 cls=0.0516 smmd=0.3648 ct=9.6502 rec=1.1965 | train/val/test=1.000/0.674/0.704 | c=0.998347
[Epoch 0186] loss=15.7611 cls=0.0486 smmd=0.3301 ct=9.6239 rec=1.1876 | train/val/test=1.000/0.660/0.704 | c=0.998347
[Epoch 0187] loss=15.7087 cls=0.0379 smmd=0.2920 ct=9.6259 rec=1.1820 | train/val/test=1.000/0.670/0.710 | c=0.998347
[Epoch 0188] loss=15.7338 cls=0.0384 smmd=0.3116 ct=9.6316 rec=1.1839 | train/val/test=1.000/0.678/0.705 | c=0.998347
[Epoch 0189] loss=15.7573 cls=0.0478 smmd=0.3287 ct=9.6195 rec=1.1880 | train/val/test=1.000/0.652/0.713 | c=0.998347
[Epoch 0190] loss=15.7573 cls=0.0463 smmd=0.2908 ct=9.6356 rec=1.1888 | train/val/test=1.000/0.672/0.708 | c=0.998347
[Epoch 0191] loss=15.7406 cls=0.0501 smmd=0.2801 ct=9.6261 rec=1.1879 | train/val/test=1.000/0.660/0.708 | c=0.998347
[Epoch 0192] loss=15.7491 cls=0.0518 smmd=0.2893 ct=9.6150 rec=1.1906 | train/val/test=1.000/0.662/0.709 | c=0.998347
[Epoch 0193] loss=15.7684 cls=0.0498 smmd=0.2718 ct=9.6413 rec=1.1913 | train/val/test=1.000/0.672/0.704 | c=0.998347
[Epoch 0194] loss=15.7754 cls=0.0569 smmd=0.3140 ct=9.6218 rec=1.1914 | train/val/test=1.000/0.662/0.715 | c=0.998347
[Epoch 0195] loss=15.7910 cls=0.0464 smmd=0.3263 ct=9.6352 rec=1.1920 | train/val/test=1.000/0.668/0.709 | c=0.998347
[Epoch 0196] loss=15.7970 cls=0.0561 smmd=0.3319 ct=9.6404 rec=1.1903 | train/val/test=1.000/0.660/0.710 | c=0.998347
[Epoch 0197] loss=15.7387 cls=0.0415 smmd=0.3039 ct=9.6287 rec=1.1858 | train/val/test=1.000/0.674/0.705 | c=0.998347
[Epoch 0198] loss=15.7056 cls=0.0388 smmd=0.2998 ct=9.6158 rec=1.1825 | train/val/test=1.000/0.666/0.704 | c=0.998347
[Epoch 0199] loss=15.7213 cls=0.0441 smmd=0.2770 ct=9.6271 rec=1.1850 | train/val/test=1.000/0.656/0.713 | c=0.998347
=== Best @ epoch 26: val=0.6900, test=0.6860 ===

Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-5-5 completed in 47.03 seconds.
==================================================
