Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5 - 2025-09-21 03:51:26:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.6320 cls=1.0981 smmd=5.6358 ct=11.2866 rec=1.4137 | train/val/test=0.385/0.388/0.413 | c=0.998437
[Epoch 0001] loss=22.4826 cls=1.0886 smmd=3.9960 ct=11.2414 rec=1.4138 | train/val/test=0.692/0.424/0.410 | c=0.998437
[Epoch 0002] loss=24.5196 cls=1.0859 smmd=4.8090 ct=11.2473 rec=1.4135 | train/val/test=0.615/0.486/0.534 | c=0.998437
[Epoch 0003] loss=23.3417 cls=1.0654 smmd=4.3847 ct=11.1405 rec=1.4135 | train/val/test=0.615/0.502/0.516 | c=0.998437
[Epoch 0004] loss=18.1368 cls=1.0340 smmd=2.3769 ct=10.9707 rec=1.4135 | train/val/test=0.615/0.554/0.589 | c=0.998437
[Epoch 0005] loss=19.7190 cls=1.0039 smmd=3.0344 ct=10.9247 rec=1.4126 | train/val/test=0.692/0.596/0.625 | c=0.998437
[Epoch 0006] loss=20.1885 cls=0.9721 smmd=3.2366 ct=10.9054 rec=1.4112 | train/val/test=0.769/0.644/0.661 | c=0.998437
[Epoch 0007] loss=18.1413 cls=0.9389 smmd=2.4346 ct=10.8806 rec=1.4093 | train/val/test=0.769/0.656/0.668 | c=0.998437
[Epoch 0008] loss=16.5775 cls=0.9126 smmd=1.8156 ct=10.8783 rec=1.4078 | train/val/test=0.846/0.666/0.660 | c=0.998437
[Epoch 0009] loss=18.1752 cls=0.8945 smmd=2.4480 ct=10.9041 rec=1.4078 | train/val/test=0.846/0.654/0.662 | c=0.998437
[Epoch 0010] loss=17.9295 cls=0.8702 smmd=2.3569 ct=10.8977 rec=1.4090 | train/val/test=0.846/0.648/0.659 | c=0.998437
[Epoch 0011] loss=15.8303 cls=0.8414 smmd=1.5305 ct=10.8788 rec=1.4089 | train/val/test=0.923/0.680/0.685 | c=0.998437
[Epoch 0012] loss=17.6152 cls=0.8134 smmd=2.2463 ct=10.8891 rec=1.4075 | train/val/test=0.923/0.672/0.679 | c=0.998437
[Epoch 0013] loss=16.8940 cls=0.7598 smmd=1.9732 ct=10.8784 rec=1.4053 | train/val/test=0.923/0.688/0.694 | c=0.998437
[Epoch 0014] loss=15.7238 cls=0.6922 smmd=1.5298 ct=10.8532 rec=1.4002 | train/val/test=0.923/0.706/0.692 | c=0.998437
[Epoch 0015] loss=15.7495 cls=0.6308 smmd=1.5600 ct=10.8367 rec=1.3946 | train/val/test=0.923/0.704/0.699 | c=0.998437
[Epoch 0016] loss=15.5007 cls=0.5786 smmd=1.4740 ct=10.8321 rec=1.3887 | train/val/test=0.923/0.712/0.703 | c=0.998437
[Epoch 0017] loss=15.0439 cls=0.5437 smmd=1.2996 ct=10.8305 rec=1.3851 | train/val/test=0.923/0.712/0.707 | c=0.998437
[Epoch 0018] loss=14.8732 cls=0.5222 smmd=1.2354 ct=10.8312 rec=1.3850 | train/val/test=1.000/0.718/0.716 | c=0.998437
[Epoch 0019] loss=14.7270 cls=0.5123 smmd=1.1762 ct=10.8371 rec=1.3863 | train/val/test=1.000/0.720/0.724 | c=0.998437
[Epoch 0020] loss=14.9632 cls=0.5061 smmd=1.2666 ct=10.8495 rec=1.3881 | train/val/test=1.000/0.706/0.713 | c=0.998437
[Epoch 0021] loss=14.6125 cls=0.4961 smmd=1.1235 ct=10.8601 rec=1.3913 | train/val/test=1.000/0.728/0.721 | c=0.998437
[Epoch 0022] loss=14.9888 cls=0.4750 smmd=1.2668 ct=10.8900 rec=1.3885 | train/val/test=1.000/0.716/0.720 | c=0.998437
[Epoch 0023] loss=14.4601 cls=0.4247 smmd=1.0805 ct=10.8545 rec=1.3841 | train/val/test=1.000/0.728/0.724 | c=0.998437
[Epoch 0024] loss=14.1279 cls=0.3780 smmd=0.9650 ct=10.8387 rec=1.3753 | train/val/test=1.000/0.730/0.728 | c=0.998437
[Epoch 0025] loss=14.0604 cls=0.3393 smmd=0.9483 ct=10.8355 rec=1.3688 | train/val/test=1.000/0.724/0.723 | c=0.998437
[Epoch 0026] loss=13.7795 cls=0.3123 smmd=0.8490 ct=10.8192 rec=1.3633 | train/val/test=1.000/0.718/0.725 | c=0.998437
[Epoch 0027] loss=13.6911 cls=0.2983 smmd=0.8153 ct=10.8232 rec=1.3611 | train/val/test=1.000/0.736/0.724 | c=0.998437
[Epoch 0028] loss=13.6315 cls=0.2918 smmd=0.7843 ct=10.8434 rec=1.3632 | train/val/test=1.000/0.736/0.727 | c=0.998437
[Epoch 0029] loss=13.6583 cls=0.2965 smmd=0.7927 ct=10.8451 rec=1.3662 | train/val/test=1.000/0.732/0.727 | c=0.998437
[Epoch 0030] loss=13.9472 cls=0.3050 smmd=0.9013 ct=10.8573 rec=1.3683 | train/val/test=1.000/0.708/0.726 | c=0.998437
[Epoch 0031] loss=14.0517 cls=0.2946 smmd=0.9373 ct=10.8769 rec=1.3683 | train/val/test=1.000/0.724/0.725 | c=0.998437
[Epoch 0032] loss=13.6894 cls=0.2673 smmd=0.8060 ct=10.8604 rec=1.3608 | train/val/test=1.000/0.726/0.723 | c=0.998437
[Epoch 0033] loss=13.4538 cls=0.2326 smmd=0.7293 ct=10.8382 rec=1.3521 | train/val/test=1.000/0.726/0.720 | c=0.998437
[Epoch 0034] loss=13.3574 cls=0.2111 smmd=0.7011 ct=10.8271 rec=1.3442 | train/val/test=1.000/0.728/0.726 | c=0.998437
[Epoch 0035] loss=13.1513 cls=0.1921 smmd=0.6232 ct=10.8277 rec=1.3392 | train/val/test=1.000/0.728/0.726 | c=0.998437
[Epoch 0036] loss=13.1308 cls=0.1883 smmd=0.6153 ct=10.8290 rec=1.3391 | train/val/test=1.000/0.732/0.720 | c=0.998437
[Epoch 0037] loss=13.1029 cls=0.1946 smmd=0.6006 ct=10.8329 rec=1.3423 | train/val/test=1.000/0.734/0.731 | c=0.998437
[Epoch 0038] loss=13.2783 cls=0.2029 smmd=0.6615 ct=10.8498 rec=1.3466 | train/val/test=1.000/0.738/0.725 | c=0.998437
[Epoch 0039] loss=13.4284 cls=0.2077 smmd=0.7176 ct=10.8553 rec=1.3502 | train/val/test=1.000/0.734/0.728 | c=0.998437
[Epoch 0040] loss=13.5833 cls=0.2035 smmd=0.7770 ct=10.8651 rec=1.3481 | train/val/test=1.000/0.722/0.727 | c=0.998437
[Epoch 0041] loss=13.3847 cls=0.1834 smmd=0.7092 ct=10.8485 rec=1.3432 | train/val/test=1.000/0.736/0.726 | c=0.998437
[Epoch 0042] loss=13.0518 cls=0.1654 smmd=0.5848 ct=10.8397 rec=1.3347 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0043] loss=13.0227 cls=0.1440 smmd=0.5827 ct=10.8303 rec=1.3272 | train/val/test=1.000/0.730/0.719 | c=0.998437
[Epoch 0044] loss=12.7611 cls=0.1372 smmd=0.4829 ct=10.8232 rec=1.3242 | train/val/test=1.000/0.728/0.732 | c=0.998437
[Epoch 0045] loss=12.8407 cls=0.1377 smmd=0.5117 ct=10.8300 rec=1.3250 | train/val/test=1.000/0.738/0.734 | c=0.998437
[Epoch 0046] loss=12.8918 cls=0.1485 smmd=0.5243 ct=10.8417 rec=1.3302 | train/val/test=1.000/0.738/0.732 | c=0.998437
[Epoch 0047] loss=13.1262 cls=0.1599 smmd=0.6111 ct=10.8503 rec=1.3365 | train/val/test=1.000/0.748/0.743 | c=0.998437
[Epoch 0048] loss=13.2962 cls=0.1702 smmd=0.6697 ct=10.8673 rec=1.3392 | train/val/test=1.000/0.710/0.704 | c=0.998437
[Epoch 0049] loss=13.6033 cls=0.1700 smmd=0.7918 ct=10.8665 rec=1.3446 | train/val/test=1.000/0.698/0.705 | c=0.998437
[Epoch 0050] loss=13.0157 cls=0.1656 smmd=0.5578 ct=10.8700 rec=1.3366 | train/val/test=1.000/0.706/0.712 | c=0.998437
[Epoch 0051] loss=13.0350 cls=0.1434 smmd=0.5765 ct=10.8559 rec=1.3324 | train/val/test=1.000/0.722/0.717 | c=0.998437
[Epoch 0052] loss=12.7705 cls=0.1121 smmd=0.4891 ct=10.8331 rec=1.3172 | train/val/test=1.000/0.732/0.734 | c=0.998437
[Epoch 0053] loss=12.8191 cls=0.0912 smmd=0.5182 ct=10.8235 rec=1.3089 | train/val/test=1.000/0.740/0.735 | c=0.998437
[Epoch 0054] loss=12.6482 cls=0.0952 smmd=0.4463 ct=10.8290 rec=1.3116 | train/val/test=1.000/0.742/0.734 | c=0.998437
[Epoch 0055] loss=12.8012 cls=0.1072 smmd=0.4992 ct=10.8403 rec=1.3185 | train/val/test=1.000/0.744/0.737 | c=0.998437
[Epoch 0056] loss=13.1260 cls=0.1243 smmd=0.6172 ct=10.8575 rec=1.3266 | train/val/test=1.000/0.750/0.743 | c=0.998437
[Epoch 0057] loss=13.3074 cls=0.1349 smmd=0.6847 ct=10.8634 rec=1.3296 | train/val/test=1.000/0.726/0.732 | c=0.998437
[Epoch 0058] loss=13.2977 cls=0.1311 smmd=0.6826 ct=10.8604 rec=1.3305 | train/val/test=1.000/0.724/0.722 | c=0.998437
[Epoch 0059] loss=12.9983 cls=0.1406 smmd=0.5633 ct=10.8561 rec=1.3275 | train/val/test=1.000/0.704/0.709 | c=0.998437
[Epoch 0060] loss=12.8970 cls=0.1356 smmd=0.5233 ct=10.8559 rec=1.3299 | train/val/test=1.000/0.702/0.707 | c=0.998437
[Epoch 0061] loss=12.6987 cls=0.1155 smmd=0.4553 ct=10.8442 rec=1.3170 | train/val/test=1.000/0.730/0.736 | c=0.998437
[Epoch 0062] loss=12.6959 cls=0.0863 smmd=0.4728 ct=10.8186 rec=1.3043 | train/val/test=1.000/0.738/0.729 | c=0.998437
[Epoch 0063] loss=12.5585 cls=0.0822 smmd=0.4154 ct=10.8263 rec=1.3051 | train/val/test=1.000/0.740/0.736 | c=0.998437
[Epoch 0064] loss=12.6241 cls=0.0922 smmd=0.4308 ct=10.8451 rec=1.3117 | train/val/test=1.000/0.736/0.743 | c=0.998437
[Epoch 0065] loss=12.9897 cls=0.1070 smmd=0.5704 ct=10.8500 rec=1.3203 | train/val/test=1.000/0.748/0.732 | c=0.998437
[Epoch 0066] loss=13.3501 cls=0.1169 smmd=0.7002 ct=10.8785 rec=1.3250 | train/val/test=1.000/0.736/0.735 | c=0.998437
[Epoch 0067] loss=13.4151 cls=0.1086 smmd=0.7354 ct=10.8608 rec=1.3231 | train/val/test=1.000/0.738/0.738 | c=0.998437
[Epoch 0068] loss=12.8198 cls=0.0971 smmd=0.5074 ct=10.8460 rec=1.3134 | train/val/test=1.000/0.728/0.737 | c=0.998437
[Epoch 0069] loss=12.6712 cls=0.0788 smmd=0.4580 ct=10.8340 rec=1.3056 | train/val/test=1.000/0.734/0.728 | c=0.998437
[Epoch 0070] loss=12.5724 cls=0.0807 smmd=0.4245 ct=10.8191 rec=1.3033 | train/val/test=1.000/0.740/0.744 | c=0.998437
[Epoch 0071] loss=12.5113 cls=0.0752 smmd=0.4003 ct=10.8226 rec=1.3008 | train/val/test=1.000/0.736/0.720 | c=0.998437
[Epoch 0072] loss=12.5767 cls=0.0897 smmd=0.4155 ct=10.8393 rec=1.3079 | train/val/test=1.000/0.730/0.737 | c=0.998437
[Epoch 0073] loss=12.7412 cls=0.1084 smmd=0.4705 ct=10.8516 rec=1.3183 | train/val/test=1.000/0.710/0.690 | c=0.998437
[Epoch 0074] loss=13.1455 cls=0.1446 smmd=0.6048 ct=10.8951 rec=1.3322 | train/val/test=0.923/0.638/0.653 | c=0.998437
[Epoch 0075] loss=13.9036 cls=0.2529 smmd=0.8546 ct=10.9446 rec=1.3924 | train/val/test=1.000/0.548/0.532 | c=0.998437
[Epoch 0076] loss=13.4796 cls=0.2773 smmd=0.6691 ct=10.9894 rec=1.3575 | train/val/test=0.923/0.688/0.697 | c=0.998437
[Epoch 0077] loss=13.2674 cls=0.1328 smmd=0.6633 ct=10.8761 rec=1.3332 | train/val/test=1.000/0.722/0.723 | c=0.998437
[Epoch 0078] loss=12.6631 cls=0.0304 smmd=0.4749 ct=10.8195 rec=1.2824 | train/val/test=1.000/0.704/0.703 | c=0.998437
[Epoch 0079] loss=12.7520 cls=0.0418 smmd=0.4905 ct=10.8569 rec=1.2959 | train/val/test=1.000/0.728/0.720 | c=0.998437
[Epoch 0080] loss=12.7927 cls=0.0242 smmd=0.5253 ct=10.8268 rec=1.2811 | train/val/test=1.000/0.718/0.719 | c=0.998437
[Epoch 0081] loss=12.5511 cls=0.0354 smmd=0.4164 ct=10.8441 rec=1.2965 | train/val/test=1.000/0.738/0.735 | c=0.998437
[Epoch 0082] loss=12.7335 cls=0.0460 smmd=0.4776 ct=10.8665 rec=1.2999 | train/val/test=1.000/0.728/0.730 | c=0.998437
[Epoch 0083] loss=13.5228 cls=0.0895 smmd=0.7650 ct=10.9042 rec=1.3228 | train/val/test=1.000/0.642/0.649 | c=0.998437
[Epoch 0084] loss=13.6421 cls=0.1520 smmd=0.7648 ct=10.9648 rec=1.3787 | train/val/test=0.846/0.522/0.527 | c=0.998437
[Epoch 0085] loss=13.8747 cls=0.3116 smmd=0.8209 ct=10.9886 rec=1.3564 | train/val/test=0.846/0.582/0.592 | c=0.998437
[Epoch 0086] loss=13.7646 cls=0.2659 smmd=0.7826 ct=10.9630 rec=1.4243 | train/val/test=1.000/0.614/0.593 | c=0.998437
[Epoch 0087] loss=12.9308 cls=0.1087 smmd=0.5501 ct=10.8433 rec=1.3160 | train/val/test=1.000/0.716/0.713 | c=0.998437
[Epoch 0088] loss=12.7268 cls=0.0463 smmd=0.4990 ct=10.8068 rec=1.2986 | train/val/test=1.000/0.702/0.709 | c=0.998437
[Epoch 0089] loss=12.9590 cls=0.0851 smmd=0.5562 ct=10.8656 rec=1.3203 | train/val/test=1.000/0.698/0.699 | c=0.998437
[Epoch 0090] loss=13.2862 cls=0.0385 smmd=0.4332 ct=11.5370 rec=1.2941 | train/val/test=1.000/0.706/0.707 | c=0.998437
[Epoch 0091] loss=13.2837 cls=0.0452 smmd=0.4519 ct=11.4820 rec=1.2987 | train/val/test=1.000/0.658/0.679 | c=0.998437
[Epoch 0092] loss=13.9565 cls=0.1055 smmd=0.6456 ct=11.6158 rec=1.3479 | train/val/test=1.000/0.630/0.611 | c=0.998437
[Epoch 0093] loss=14.3043 cls=0.1277 smmd=0.7663 ct=11.6539 rec=1.3418 | train/val/test=1.000/0.660/0.675 | c=0.998437
[Epoch 0094] loss=14.4964 cls=0.0970 smmd=0.8884 ct=11.5567 rec=1.3401 | train/val/test=1.000/0.730/0.721 | c=0.998437
[Epoch 0095] loss=13.3725 cls=0.0460 smmd=0.4668 ct=11.5353 rec=1.2941 | train/val/test=1.000/0.710/0.693 | c=0.998437
[Epoch 0096] loss=13.5927 cls=0.0670 smmd=0.5446 ct=11.5470 rec=1.3013 | train/val/test=1.000/0.724/0.723 | c=0.998437
[Epoch 0097] loss=13.1158 cls=0.0324 smmd=0.3928 ct=11.4745 rec=1.2861 | train/val/test=1.000/0.722/0.719 | c=0.998437
[Epoch 0098] loss=13.3352 cls=0.0364 smmd=0.4681 ct=11.5019 rec=1.2900 | train/val/test=1.000/0.730/0.724 | c=0.998437
[Epoch 0099] loss=12.9720 cls=0.0630 smmd=0.3167 ct=11.5009 rec=1.2958 | train/val/test=1.000/0.718/0.726 | c=0.998437
=== Best @ epoch 56: val=0.7500, test=0.7430 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5 - 2025-09-21 03:51:26:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.6320 cls=1.0981 smmd=5.6358 ct=11.2866 rec=1.4137 | train/val/test=0.385/0.388/0.413 | c=0.998437
[Epoch 0001] loss=22.4826 cls=1.0886 smmd=3.9960 ct=11.2414 rec=1.4138 | train/val/test=0.692/0.424/0.410 | c=0.998437
[Epoch 0002] loss=24.5196 cls=1.0859 smmd=4.8090 ct=11.2473 rec=1.4135 | train/val/test=0.615/0.486/0.534 | c=0.998437
[Epoch 0003] loss=23.3417 cls=1.0654 smmd=4.3847 ct=11.1405 rec=1.4135 | train/val/test=0.615/0.502/0.516 | c=0.998437
[Epoch 0004] loss=18.1368 cls=1.0340 smmd=2.3769 ct=10.9707 rec=1.4135 | train/val/test=0.615/0.554/0.589 | c=0.998437
[Epoch 0005] loss=19.7190 cls=1.0039 smmd=3.0344 ct=10.9247 rec=1.4126 | train/val/test=0.692/0.596/0.625 | c=0.998437
[Epoch 0006] loss=20.1885 cls=0.9721 smmd=3.2366 ct=10.9054 rec=1.4112 | train/val/test=0.769/0.644/0.661 | c=0.998437
[Epoch 0007] loss=18.1413 cls=0.9389 smmd=2.4346 ct=10.8806 rec=1.4093 | train/val/test=0.769/0.656/0.668 | c=0.998437
[Epoch 0008] loss=16.5775 cls=0.9126 smmd=1.8156 ct=10.8783 rec=1.4078 | train/val/test=0.846/0.666/0.660 | c=0.998437
[Epoch 0009] loss=18.1752 cls=0.8945 smmd=2.4480 ct=10.9041 rec=1.4078 | train/val/test=0.846/0.654/0.662 | c=0.998437
[Epoch 0010] loss=17.9295 cls=0.8702 smmd=2.3569 ct=10.8977 rec=1.4090 | train/val/test=0.846/0.648/0.659 | c=0.998437
[Epoch 0011] loss=15.8303 cls=0.8414 smmd=1.5305 ct=10.8788 rec=1.4089 | train/val/test=0.923/0.680/0.685 | c=0.998437
[Epoch 0012] loss=17.6152 cls=0.8134 smmd=2.2463 ct=10.8891 rec=1.4075 | train/val/test=0.923/0.672/0.679 | c=0.998437
[Epoch 0013] loss=16.8940 cls=0.7598 smmd=1.9732 ct=10.8784 rec=1.4053 | train/val/test=0.923/0.688/0.694 | c=0.998437
[Epoch 0014] loss=15.7238 cls=0.6922 smmd=1.5298 ct=10.8532 rec=1.4002 | train/val/test=0.923/0.706/0.692 | c=0.998437
[Epoch 0015] loss=15.7495 cls=0.6308 smmd=1.5600 ct=10.8367 rec=1.3946 | train/val/test=0.923/0.704/0.699 | c=0.998437
[Epoch 0016] loss=15.5007 cls=0.5786 smmd=1.4740 ct=10.8321 rec=1.3887 | train/val/test=0.923/0.712/0.703 | c=0.998437
[Epoch 0017] loss=15.0439 cls=0.5437 smmd=1.2996 ct=10.8305 rec=1.3851 | train/val/test=0.923/0.712/0.707 | c=0.998437
[Epoch 0018] loss=14.8732 cls=0.5222 smmd=1.2354 ct=10.8312 rec=1.3850 | train/val/test=1.000/0.718/0.716 | c=0.998437
[Epoch 0019] loss=14.7270 cls=0.5123 smmd=1.1762 ct=10.8371 rec=1.3863 | train/val/test=1.000/0.720/0.724 | c=0.998437
[Epoch 0020] loss=14.9632 cls=0.5061 smmd=1.2666 ct=10.8495 rec=1.3881 | train/val/test=1.000/0.706/0.713 | c=0.998437
[Epoch 0021] loss=14.6125 cls=0.4961 smmd=1.1235 ct=10.8601 rec=1.3913 | train/val/test=1.000/0.728/0.721 | c=0.998437
[Epoch 0022] loss=14.9888 cls=0.4750 smmd=1.2668 ct=10.8900 rec=1.3885 | train/val/test=1.000/0.716/0.720 | c=0.998437
[Epoch 0023] loss=14.4601 cls=0.4247 smmd=1.0805 ct=10.8545 rec=1.3841 | train/val/test=1.000/0.728/0.724 | c=0.998437
[Epoch 0024] loss=14.1279 cls=0.3780 smmd=0.9650 ct=10.8387 rec=1.3753 | train/val/test=1.000/0.730/0.728 | c=0.998437
[Epoch 0025] loss=14.0604 cls=0.3393 smmd=0.9483 ct=10.8355 rec=1.3688 | train/val/test=1.000/0.724/0.723 | c=0.998437
[Epoch 0026] loss=13.7795 cls=0.3123 smmd=0.8490 ct=10.8192 rec=1.3633 | train/val/test=1.000/0.718/0.725 | c=0.998437
[Epoch 0027] loss=13.6911 cls=0.2983 smmd=0.8153 ct=10.8232 rec=1.3611 | train/val/test=1.000/0.736/0.724 | c=0.998437
[Epoch 0028] loss=13.6315 cls=0.2918 smmd=0.7843 ct=10.8434 rec=1.3632 | train/val/test=1.000/0.736/0.727 | c=0.998437
[Epoch 0029] loss=13.6583 cls=0.2965 smmd=0.7927 ct=10.8451 rec=1.3662 | train/val/test=1.000/0.732/0.727 | c=0.998437
[Epoch 0030] loss=13.9472 cls=0.3050 smmd=0.9013 ct=10.8573 rec=1.3683 | train/val/test=1.000/0.708/0.726 | c=0.998437
[Epoch 0031] loss=14.0517 cls=0.2946 smmd=0.9373 ct=10.8769 rec=1.3683 | train/val/test=1.000/0.724/0.725 | c=0.998437
[Epoch 0032] loss=13.6894 cls=0.2673 smmd=0.8060 ct=10.8604 rec=1.3608 | train/val/test=1.000/0.726/0.723 | c=0.998437
[Epoch 0033] loss=13.4538 cls=0.2326 smmd=0.7293 ct=10.8382 rec=1.3521 | train/val/test=1.000/0.726/0.720 | c=0.998437
[Epoch 0034] loss=13.3574 cls=0.2111 smmd=0.7011 ct=10.8271 rec=1.3442 | train/val/test=1.000/0.728/0.726 | c=0.998437
[Epoch 0035] loss=13.1513 cls=0.1921 smmd=0.6232 ct=10.8277 rec=1.3392 | train/val/test=1.000/0.728/0.726 | c=0.998437
[Epoch 0036] loss=13.1308 cls=0.1883 smmd=0.6153 ct=10.8290 rec=1.3391 | train/val/test=1.000/0.732/0.720 | c=0.998437
[Epoch 0037] loss=13.1029 cls=0.1946 smmd=0.6006 ct=10.8329 rec=1.3423 | train/val/test=1.000/0.734/0.731 | c=0.998437
[Epoch 0038] loss=13.2783 cls=0.2029 smmd=0.6615 ct=10.8498 rec=1.3466 | train/val/test=1.000/0.738/0.725 | c=0.998437
[Epoch 0039] loss=13.4284 cls=0.2077 smmd=0.7176 ct=10.8553 rec=1.3502 | train/val/test=1.000/0.734/0.728 | c=0.998437
[Epoch 0040] loss=13.5833 cls=0.2035 smmd=0.7770 ct=10.8651 rec=1.3481 | train/val/test=1.000/0.722/0.727 | c=0.998437
[Epoch 0041] loss=13.3847 cls=0.1834 smmd=0.7092 ct=10.8485 rec=1.3432 | train/val/test=1.000/0.736/0.726 | c=0.998437
[Epoch 0042] loss=13.0518 cls=0.1654 smmd=0.5848 ct=10.8397 rec=1.3347 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0043] loss=13.0227 cls=0.1440 smmd=0.5827 ct=10.8303 rec=1.3272 | train/val/test=1.000/0.730/0.719 | c=0.998437
[Epoch 0044] loss=12.7611 cls=0.1372 smmd=0.4829 ct=10.8232 rec=1.3242 | train/val/test=1.000/0.728/0.732 | c=0.998437
[Epoch 0045] loss=12.8407 cls=0.1377 smmd=0.5117 ct=10.8300 rec=1.3250 | train/val/test=1.000/0.738/0.734 | c=0.998437
[Epoch 0046] loss=12.8918 cls=0.1485 smmd=0.5243 ct=10.8417 rec=1.3302 | train/val/test=1.000/0.738/0.732 | c=0.998437
[Epoch 0047] loss=13.1262 cls=0.1599 smmd=0.6111 ct=10.8503 rec=1.3365 | train/val/test=1.000/0.748/0.743 | c=0.998437
[Epoch 0048] loss=13.2962 cls=0.1702 smmd=0.6697 ct=10.8673 rec=1.3392 | train/val/test=1.000/0.710/0.704 | c=0.998437
[Epoch 0049] loss=13.6033 cls=0.1700 smmd=0.7918 ct=10.8665 rec=1.3446 | train/val/test=1.000/0.698/0.705 | c=0.998437
[Epoch 0050] loss=13.0157 cls=0.1656 smmd=0.5578 ct=10.8700 rec=1.3366 | train/val/test=1.000/0.706/0.712 | c=0.998437
[Epoch 0051] loss=13.0350 cls=0.1434 smmd=0.5765 ct=10.8559 rec=1.3324 | train/val/test=1.000/0.722/0.717 | c=0.998437
[Epoch 0052] loss=12.7705 cls=0.1121 smmd=0.4891 ct=10.8331 rec=1.3172 | train/val/test=1.000/0.732/0.734 | c=0.998437
[Epoch 0053] loss=12.8191 cls=0.0912 smmd=0.5182 ct=10.8235 rec=1.3089 | train/val/test=1.000/0.740/0.735 | c=0.998437
[Epoch 0054] loss=12.6482 cls=0.0952 smmd=0.4463 ct=10.8290 rec=1.3116 | train/val/test=1.000/0.742/0.734 | c=0.998437
[Epoch 0055] loss=12.8012 cls=0.1072 smmd=0.4992 ct=10.8403 rec=1.3185 | train/val/test=1.000/0.744/0.737 | c=0.998437
[Epoch 0056] loss=13.1260 cls=0.1243 smmd=0.6172 ct=10.8575 rec=1.3266 | train/val/test=1.000/0.750/0.743 | c=0.998437
[Epoch 0057] loss=13.3074 cls=0.1349 smmd=0.6847 ct=10.8634 rec=1.3296 | train/val/test=1.000/0.726/0.732 | c=0.998437
[Epoch 0058] loss=13.2977 cls=0.1311 smmd=0.6826 ct=10.8604 rec=1.3305 | train/val/test=1.000/0.724/0.722 | c=0.998437
[Epoch 0059] loss=12.9983 cls=0.1406 smmd=0.5633 ct=10.8561 rec=1.3275 | train/val/test=1.000/0.704/0.709 | c=0.998437
[Epoch 0060] loss=12.8970 cls=0.1356 smmd=0.5233 ct=10.8559 rec=1.3299 | train/val/test=1.000/0.702/0.707 | c=0.998437
[Epoch 0061] loss=12.6987 cls=0.1155 smmd=0.4553 ct=10.8442 rec=1.3170 | train/val/test=1.000/0.730/0.736 | c=0.998437
[Epoch 0062] loss=12.6959 cls=0.0863 smmd=0.4728 ct=10.8186 rec=1.3043 | train/val/test=1.000/0.738/0.729 | c=0.998437
[Epoch 0063] loss=12.5585 cls=0.0822 smmd=0.4154 ct=10.8263 rec=1.3051 | train/val/test=1.000/0.740/0.736 | c=0.998437
[Epoch 0064] loss=12.6241 cls=0.0922 smmd=0.4308 ct=10.8451 rec=1.3117 | train/val/test=1.000/0.736/0.743 | c=0.998437
[Epoch 0065] loss=12.9897 cls=0.1070 smmd=0.5704 ct=10.8500 rec=1.3203 | train/val/test=1.000/0.748/0.732 | c=0.998437
[Epoch 0066] loss=13.3501 cls=0.1169 smmd=0.7002 ct=10.8785 rec=1.3250 | train/val/test=1.000/0.736/0.735 | c=0.998437
[Epoch 0067] loss=13.4151 cls=0.1086 smmd=0.7354 ct=10.8608 rec=1.3231 | train/val/test=1.000/0.738/0.738 | c=0.998437
[Epoch 0068] loss=12.8198 cls=0.0971 smmd=0.5074 ct=10.8460 rec=1.3134 | train/val/test=1.000/0.728/0.737 | c=0.998437
[Epoch 0069] loss=12.6712 cls=0.0788 smmd=0.4580 ct=10.8340 rec=1.3056 | train/val/test=1.000/0.734/0.728 | c=0.998437
[Epoch 0070] loss=12.5724 cls=0.0807 smmd=0.4245 ct=10.8191 rec=1.3033 | train/val/test=1.000/0.740/0.744 | c=0.998437
[Epoch 0071] loss=12.5113 cls=0.0752 smmd=0.4003 ct=10.8226 rec=1.3008 | train/val/test=1.000/0.736/0.720 | c=0.998437
[Epoch 0072] loss=12.5767 cls=0.0897 smmd=0.4155 ct=10.8393 rec=1.3079 | train/val/test=1.000/0.730/0.737 | c=0.998437
[Epoch 0073] loss=12.7412 cls=0.1084 smmd=0.4705 ct=10.8516 rec=1.3183 | train/val/test=1.000/0.710/0.690 | c=0.998437
[Epoch 0074] loss=13.1455 cls=0.1446 smmd=0.6048 ct=10.8951 rec=1.3322 | train/val/test=0.923/0.638/0.653 | c=0.998437
[Epoch 0075] loss=13.9036 cls=0.2529 smmd=0.8546 ct=10.9446 rec=1.3924 | train/val/test=1.000/0.548/0.532 | c=0.998437
[Epoch 0076] loss=13.4796 cls=0.2773 smmd=0.6691 ct=10.9894 rec=1.3575 | train/val/test=0.923/0.688/0.697 | c=0.998437
[Epoch 0077] loss=13.2674 cls=0.1328 smmd=0.6633 ct=10.8761 rec=1.3332 | train/val/test=1.000/0.722/0.723 | c=0.998437
[Epoch 0078] loss=12.6631 cls=0.0304 smmd=0.4749 ct=10.8195 rec=1.2824 | train/val/test=1.000/0.704/0.703 | c=0.998437
[Epoch 0079] loss=12.7520 cls=0.0418 smmd=0.4905 ct=10.8569 rec=1.2959 | train/val/test=1.000/0.728/0.720 | c=0.998437
[Epoch 0080] loss=12.7927 cls=0.0242 smmd=0.5253 ct=10.8268 rec=1.2811 | train/val/test=1.000/0.718/0.719 | c=0.998437
[Epoch 0081] loss=12.5511 cls=0.0354 smmd=0.4164 ct=10.8441 rec=1.2965 | train/val/test=1.000/0.738/0.735 | c=0.998437
[Epoch 0082] loss=12.7335 cls=0.0460 smmd=0.4776 ct=10.8665 rec=1.2999 | train/val/test=1.000/0.728/0.730 | c=0.998437
[Epoch 0083] loss=13.5228 cls=0.0895 smmd=0.7650 ct=10.9042 rec=1.3228 | train/val/test=1.000/0.642/0.649 | c=0.998437
[Epoch 0084] loss=13.6421 cls=0.1520 smmd=0.7648 ct=10.9648 rec=1.3787 | train/val/test=0.846/0.522/0.527 | c=0.998437
[Epoch 0085] loss=13.8747 cls=0.3116 smmd=0.8209 ct=10.9886 rec=1.3564 | train/val/test=0.846/0.582/0.592 | c=0.998437
[Epoch 0086] loss=13.7646 cls=0.2659 smmd=0.7826 ct=10.9630 rec=1.4243 | train/val/test=1.000/0.614/0.593 | c=0.998437
[Epoch 0087] loss=12.9308 cls=0.1087 smmd=0.5501 ct=10.8433 rec=1.3160 | train/val/test=1.000/0.716/0.713 | c=0.998437
[Epoch 0088] loss=12.7268 cls=0.0463 smmd=0.4990 ct=10.8068 rec=1.2986 | train/val/test=1.000/0.702/0.709 | c=0.998437
[Epoch 0089] loss=12.9590 cls=0.0851 smmd=0.5562 ct=10.8656 rec=1.3203 | train/val/test=1.000/0.698/0.699 | c=0.998437
[Epoch 0090] loss=13.2862 cls=0.0385 smmd=0.4332 ct=11.5370 rec=1.2941 | train/val/test=1.000/0.706/0.707 | c=0.998437
[Epoch 0091] loss=13.2837 cls=0.0452 smmd=0.4519 ct=11.4820 rec=1.2987 | train/val/test=1.000/0.658/0.679 | c=0.998437
[Epoch 0092] loss=13.9565 cls=0.1055 smmd=0.6456 ct=11.6158 rec=1.3479 | train/val/test=1.000/0.630/0.611 | c=0.998437
[Epoch 0093] loss=14.3043 cls=0.1277 smmd=0.7663 ct=11.6539 rec=1.3418 | train/val/test=1.000/0.660/0.675 | c=0.998437
[Epoch 0094] loss=14.4964 cls=0.0970 smmd=0.8884 ct=11.5567 rec=1.3401 | train/val/test=1.000/0.730/0.721 | c=0.998437
[Epoch 0095] loss=13.3725 cls=0.0460 smmd=0.4668 ct=11.5353 rec=1.2941 | train/val/test=1.000/0.710/0.693 | c=0.998437
[Epoch 0096] loss=13.5927 cls=0.0670 smmd=0.5446 ct=11.5470 rec=1.3013 | train/val/test=1.000/0.724/0.723 | c=0.998437
[Epoch 0097] loss=13.1158 cls=0.0324 smmd=0.3928 ct=11.4745 rec=1.2861 | train/val/test=1.000/0.722/0.719 | c=0.998437
[Epoch 0098] loss=13.3352 cls=0.0364 smmd=0.4681 ct=11.5019 rec=1.2900 | train/val/test=1.000/0.730/0.724 | c=0.998437
[Epoch 0099] loss=12.9720 cls=0.0630 smmd=0.3167 ct=11.5009 rec=1.2958 | train/val/test=1.000/0.718/0.726 | c=0.998437
=== Best @ epoch 56: val=0.7500, test=0.7430 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5 completed in 139.02 seconds.
==================================================
