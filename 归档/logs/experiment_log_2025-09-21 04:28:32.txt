Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5 - 2025-09-21 04:28:32:
Running experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5...
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.0882 cls=1.9497 smmd=4.0956 ct=9.2651 rec=1.3889 | train/val/test=0.207/0.316/0.319 | c=0.998437
[Epoch 0001] loss=16.5374 cls=1.8929 smmd=2.6756 ct=9.1901 rec=1.3894 | train/val/test=0.655/0.440/0.441 | c=0.998437
[Epoch 0002] loss=15.0595 cls=1.7724 smmd=1.4267 ct=9.0828 rec=1.3888 | train/val/test=0.828/0.336/0.351 | c=0.998437
[Epoch 0003] loss=14.8048 cls=1.5349 smmd=1.4570 ct=9.0376 rec=1.3876 | train/val/test=0.828/0.544/0.509 | c=0.998437
[Epoch 0004] loss=14.5448 cls=1.2025 smmd=1.6546 ct=8.9259 rec=1.3809 | train/val/test=0.931/0.628/0.607 | c=0.998437
[Epoch 0005] loss=13.9990 cls=0.8331 smmd=1.5739 ct=8.8647 rec=1.3636 | train/val/test=0.931/0.622/0.606 | c=0.998437
[Epoch 0006] loss=14.0439 cls=0.5274 smmd=1.3509 ct=9.4930 rec=1.3364 | train/val/test=0.966/0.678/0.653 | c=0.998437
[Epoch 0007] loss=13.3980 cls=0.3205 smmd=1.1189 ct=9.3475 rec=1.3055 | train/val/test=1.000/0.698/0.679 | c=0.998437
[Epoch 0008] loss=13.1537 cls=0.1956 smmd=1.1341 ct=9.2711 rec=1.2764 | train/val/test=1.000/0.688/0.673 | c=0.998437
[Epoch 0009] loss=13.1336 cls=0.1168 smmd=1.2479 ct=9.2668 rec=1.2510 | train/val/test=1.000/0.674/0.677 | c=0.998437
[Epoch 0010] loss=13.0673 cls=0.0686 smmd=1.2317 ct=9.3041 rec=1.2315 | train/val/test=1.000/0.670/0.682 | c=0.998437
[Epoch 0011] loss=12.9038 cls=0.0411 smmd=1.0722 ct=9.3549 rec=1.2178 | train/val/test=1.000/0.672/0.685 | c=0.998437
[Epoch 0012] loss=12.7082 cls=0.0251 smmd=0.8877 ct=9.3822 rec=1.2066 | train/val/test=1.000/0.674/0.694 | c=0.998437
[Epoch 0013] loss=12.5454 cls=0.0175 smmd=0.7454 ct=9.3850 rec=1.1988 | train/val/test=1.000/0.686/0.693 | c=0.998437
[Epoch 0014] loss=12.4895 cls=0.0120 smmd=0.7133 ct=9.3751 rec=1.1946 | train/val/test=1.000/0.700/0.702 | c=0.998437
[Epoch 0015] loss=12.4676 cls=0.0084 smmd=0.7115 ct=9.3634 rec=1.1921 | train/val/test=1.000/0.698/0.705 | c=0.998437
[Epoch 0016] loss=12.3993 cls=0.0069 smmd=0.6525 ct=9.3565 rec=1.1917 | train/val/test=1.000/0.696/0.702 | c=0.998437
[Epoch 0017] loss=12.3025 cls=0.0068 smmd=0.5619 ct=9.3491 rec=1.1923 | train/val/test=1.000/0.696/0.704 | c=0.998437
[Epoch 0018] loss=12.2059 cls=0.0073 smmd=0.4669 ct=9.3447 rec=1.1935 | train/val/test=1.000/0.706/0.707 | c=0.998437
[Epoch 0019] loss=12.1715 cls=0.0087 smmd=0.4220 ct=9.3500 rec=1.1954 | train/val/test=1.000/0.702/0.707 | c=0.998437
[Epoch 0020] loss=12.1561 cls=0.0109 smmd=0.3901 ct=9.3580 rec=1.1986 | train/val/test=1.000/0.704/0.710 | c=0.998437
[Epoch 0021] loss=12.1073 cls=0.0145 smmd=0.3380 ct=9.3534 rec=1.2007 | train/val/test=1.000/0.706/0.712 | c=0.998437
[Epoch 0022] loss=12.0454 cls=0.0189 smmd=0.2790 ct=9.3435 rec=1.2020 | train/val/test=1.000/0.706/0.709 | c=0.998437
[Epoch 0023] loss=12.0289 cls=0.0231 smmd=0.2588 ct=9.3447 rec=1.2011 | train/val/test=1.000/0.716/0.719 | c=0.998437
[Epoch 0024] loss=12.0092 cls=0.0274 smmd=0.2348 ct=9.3509 rec=1.1981 | train/val/test=1.000/0.720/0.720 | c=0.998437
[Epoch 0025] loss=11.9699 cls=0.0315 smmd=0.1956 ct=9.3532 rec=1.1948 | train/val/test=1.000/0.720/0.738 | c=0.998437
[Epoch 0026] loss=11.9586 cls=0.0353 smmd=0.1860 ct=9.3563 rec=1.1905 | train/val/test=1.000/0.716/0.716 | c=0.998437
[Epoch 0027] loss=11.9381 cls=0.0424 smmd=0.1680 ct=9.3526 rec=1.1875 | train/val/test=1.000/0.718/0.736 | c=0.998437
[Epoch 0028] loss=11.9513 cls=0.0431 smmd=0.1850 ct=9.3496 rec=1.1868 | train/val/test=1.000/0.706/0.720 | c=0.998437
[Epoch 0029] loss=11.9241 cls=0.0440 smmd=0.1817 ct=9.3383 rec=1.1801 | train/val/test=1.000/0.728/0.742 | c=0.998437
[Epoch 0030] loss=11.8369 cls=0.0231 smmd=0.1377 ct=9.3308 rec=1.1726 | train/val/test=1.000/0.730/0.738 | c=0.998437
[Epoch 0031] loss=11.8270 cls=0.0226 smmd=0.1243 ct=9.3358 rec=1.1722 | train/val/test=1.000/0.716/0.721 | c=0.998437
[Epoch 0032] loss=11.8266 cls=0.0157 smmd=0.1397 ct=9.3331 rec=1.1691 | train/val/test=1.000/0.728/0.740 | c=0.998437
[Epoch 0033] loss=11.7820 cls=0.0124 smmd=0.1143 ct=9.3194 rec=1.1680 | train/val/test=1.000/0.726/0.733 | c=0.998437
[Epoch 0034] loss=11.7856 cls=0.0152 smmd=0.1069 ct=9.3234 rec=1.1700 | train/val/test=1.000/0.718/0.725 | c=0.998437
[Epoch 0035] loss=11.7634 cls=0.0117 smmd=0.0921 ct=9.3207 rec=1.1694 | train/val/test=1.000/0.722/0.739 | c=0.998437
[Epoch 0036] loss=11.7544 cls=0.0122 smmd=0.0890 ct=9.3099 rec=1.1716 | train/val/test=1.000/0.722/0.723 | c=0.998437
[Epoch 0037] loss=11.7383 cls=0.0136 smmd=0.0704 ct=9.3096 rec=1.1724 | train/val/test=1.000/0.720/0.724 | c=0.998437
[Epoch 0038] loss=11.7357 cls=0.0141 smmd=0.0615 ct=9.3123 rec=1.1739 | train/val/test=1.000/0.728/0.740 | c=0.998437
[Epoch 0039] loss=11.7453 cls=0.0158 smmd=0.0672 ct=9.3076 rec=1.1774 | train/val/test=1.000/0.722/0.716 | c=0.998437
[Epoch 0040] loss=11.7254 cls=0.0165 smmd=0.0530 ct=9.3055 rec=1.1752 | train/val/test=1.000/0.722/0.733 | c=0.998437
[Epoch 0041] loss=11.7125 cls=0.0155 smmd=0.0455 ct=9.3040 rec=1.1737 | train/val/test=1.000/0.724/0.734 | c=0.998437
[Epoch 0042] loss=11.7077 cls=0.0168 smmd=0.0422 ct=9.3007 rec=1.1740 | train/val/test=1.000/0.728/0.726 | c=0.998437
[Epoch 0043] loss=11.7031 cls=0.0178 smmd=0.0400 ct=9.3013 rec=1.1720 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0044] loss=11.6877 cls=0.0169 smmd=0.0330 ct=9.2957 rec=1.1710 | train/val/test=1.000/0.732/0.730 | c=0.998437
[Epoch 0045] loss=11.6860 cls=0.0183 smmd=0.0404 ct=9.2878 rec=1.1697 | train/val/test=1.000/0.726/0.732 | c=0.998437
[Epoch 0046] loss=11.6799 cls=0.0189 smmd=0.0309 ct=9.2917 rec=1.1692 | train/val/test=1.000/0.732/0.733 | c=0.998437
[Epoch 0047] loss=11.6711 cls=0.0180 smmd=0.0262 ct=9.2886 rec=1.1692 | train/val/test=1.000/0.726/0.726 | c=0.998437
[Epoch 0048] loss=11.6673 cls=0.0191 smmd=0.0268 ct=9.2831 rec=1.1691 | train/val/test=1.000/0.732/0.736 | c=0.998437
[Epoch 0049] loss=11.6636 cls=0.0189 smmd=0.0193 ct=9.2858 rec=1.1698 | train/val/test=1.000/0.728/0.730 | c=0.998437
[Epoch 0050] loss=11.6539 cls=0.0178 smmd=0.0223 ct=9.2757 rec=1.1691 | train/val/test=1.000/0.726/0.728 | c=0.998437
[Epoch 0051] loss=11.6444 cls=0.0178 smmd=0.0156 ct=9.2713 rec=1.1699 | train/val/test=1.000/0.728/0.734 | c=0.998437
[Epoch 0052] loss=11.6512 cls=0.0177 smmd=0.0158 ct=9.2755 rec=1.1711 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0053] loss=11.6447 cls=0.0178 smmd=0.0161 ct=9.2683 rec=1.1713 | train/val/test=1.000/0.728/0.733 | c=0.998437
[Epoch 0054] loss=11.6373 cls=0.0168 smmd=0.0041 ct=9.2737 rec=1.1714 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0055] loss=11.6365 cls=0.0171 smmd=0.0066 ct=9.2692 rec=1.1718 | train/val/test=1.000/0.726/0.733 | c=0.998437
[Epoch 0056] loss=11.6345 cls=0.0169 smmd=0.0097 ct=9.2634 rec=1.1722 | train/val/test=1.000/0.718/0.726 | c=0.998437
[Epoch 0057] loss=11.6302 cls=0.0170 smmd=0.0071 ct=9.2631 rec=1.1715 | train/val/test=1.000/0.730/0.734 | c=0.998437
[Epoch 0058] loss=11.6262 cls=0.0163 smmd=0.0072 ct=9.2608 rec=1.1710 | train/val/test=1.000/0.720/0.730 | c=0.998437
[Epoch 0059] loss=11.6249 cls=0.0169 smmd=0.0048 ct=9.2616 rec=1.1708 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0060] loss=11.6173 cls=0.0167 smmd=-0.0047 ct=9.2634 rec=1.1709 | train/val/test=1.000/0.724/0.731 | c=0.998437
[Epoch 0061] loss=11.6133 cls=0.0170 smmd=0.0024 ct=9.2531 rec=1.1704 | train/val/test=1.000/0.728/0.735 | c=0.998437
[Epoch 0062] loss=11.6090 cls=0.0167 smmd=-0.0034 ct=9.2544 rec=1.1707 | train/val/test=1.000/0.722/0.725 | c=0.998437
[Epoch 0063] loss=11.6105 cls=0.0175 smmd=-0.0016 ct=9.2536 rec=1.1705 | train/val/test=1.000/0.728/0.734 | c=0.998437
[Epoch 0064] loss=11.6082 cls=0.0173 smmd=0.0002 ct=9.2485 rec=1.1711 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0065] loss=11.6082 cls=0.0181 smmd=-0.0015 ct=9.2500 rec=1.1708 | train/val/test=1.000/0.728/0.733 | c=0.998437
[Epoch 0066] loss=11.6007 cls=0.0175 smmd=-0.0078 ct=9.2485 rec=1.1713 | train/val/test=1.000/0.722/0.727 | c=0.998437
[Epoch 0067] loss=11.5999 cls=0.0185 smmd=-0.0065 ct=9.2453 rec=1.1713 | train/val/test=1.000/0.732/0.733 | c=0.998437
[Epoch 0068] loss=11.6075 cls=0.0183 smmd=-0.0077 ct=9.2520 rec=1.1725 | train/val/test=1.000/0.720/0.725 | c=0.998437
[Epoch 0069] loss=11.6194 cls=0.0210 smmd=0.0083 ct=9.2420 rec=1.1741 | train/val/test=1.000/0.730/0.737 | c=0.998437
[Epoch 0070] loss=11.6460 cls=0.0216 smmd=0.0064 ct=9.2628 rec=1.1776 | train/val/test=1.000/0.708/0.716 | c=0.998437
[Epoch 0071] loss=11.7129 cls=0.0331 smmd=0.0485 ct=9.2655 rec=1.1829 | train/val/test=1.000/0.720/0.726 | c=0.998437
[Epoch 0072] loss=11.7461 cls=0.0297 smmd=0.0503 ct=9.2910 rec=1.1875 | train/val/test=1.000/0.710/0.713 | c=0.998437
[Epoch 0073] loss=11.7010 cls=0.0201 smmd=0.0599 ct=9.2735 rec=1.1737 | train/val/test=1.000/0.724/0.730 | c=0.998437
[Epoch 0074] loss=11.5819 cls=0.0104 smmd=-0.0002 ct=9.2459 rec=1.1629 | train/val/test=1.000/0.732/0.729 | c=0.998437
[Epoch 0075] loss=11.7021 cls=0.0177 smmd=0.0516 ct=9.2845 rec=1.1742 | train/val/test=1.000/0.718/0.723 | c=0.998437
[Epoch 0076] loss=11.6484 cls=0.0110 smmd=0.0459 ct=9.2634 rec=1.1641 | train/val/test=1.000/0.718/0.726 | c=0.998437
[Epoch 0077] loss=11.6188 cls=0.0107 smmd=0.0253 ct=9.2551 rec=1.1639 | train/val/test=1.000/0.734/0.735 | c=0.998437
[Epoch 0078] loss=11.6762 cls=0.0141 smmd=0.0458 ct=9.2750 rec=1.1707 | train/val/test=1.000/0.722/0.729 | c=0.998437
[Epoch 0079] loss=11.5862 cls=0.0114 smmd=0.0010 ct=9.2433 rec=1.1652 | train/val/test=1.000/0.714/0.720 | c=0.998437
[Epoch 0080] loss=11.6341 cls=0.0165 smmd=0.0209 ct=9.2513 rec=1.1727 | train/val/test=1.000/0.728/0.740 | c=0.998437
[Epoch 0081] loss=11.6400 cls=0.0163 smmd=0.0139 ct=9.2616 rec=1.1741 | train/val/test=1.000/0.718/0.726 | c=0.998437
[Epoch 0082] loss=11.6039 cls=0.0176 smmd=-0.0036 ct=9.2409 rec=1.1745 | train/val/test=1.000/0.712/0.733 | c=0.998437
[Epoch 0083] loss=11.6198 cls=0.0224 smmd=0.0035 ct=9.2371 rec=1.1784 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0084] loss=11.6381 cls=0.0212 smmd=0.0017 ct=9.2621 rec=1.1765 | train/val/test=1.000/0.720/0.722 | c=0.998437
[Epoch 0085] loss=11.6191 cls=0.0225 smmd=0.0055 ct=9.2408 rec=1.1752 | train/val/test=1.000/0.716/0.736 | c=0.998437
[Epoch 0086] loss=11.5972 cls=0.0177 smmd=-0.0026 ct=9.2385 rec=1.1718 | train/val/test=1.000/0.722/0.727 | c=0.998437
[Epoch 0087] loss=11.6052 cls=0.0185 smmd=-0.0114 ct=9.2563 rec=1.1710 | train/val/test=1.000/0.724/0.726 | c=0.998437
[Epoch 0088] loss=11.5994 cls=0.0186 smmd=0.0030 ct=9.2386 rec=1.1696 | train/val/test=1.000/0.722/0.733 | c=0.998437
[Epoch 0089] loss=11.5866 cls=0.0152 smmd=0.0005 ct=9.2339 rec=1.1685 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0090] loss=11.5926 cls=0.0166 smmd=-0.0126 ct=9.2510 rec=1.1688 | train/val/test=1.000/0.724/0.727 | c=0.998437
[Epoch 0091] loss=11.5893 cls=0.0161 smmd=0.0008 ct=9.2350 rec=1.1687 | train/val/test=1.000/0.728/0.735 | c=0.998437
[Epoch 0092] loss=11.5830 cls=0.0156 smmd=-0.0041 ct=9.2310 rec=1.1702 | train/val/test=1.000/0.718/0.723 | c=0.998437
[Epoch 0093] loss=11.5923 cls=0.0177 smmd=-0.0124 ct=9.2439 rec=1.1716 | train/val/test=1.000/0.724/0.729 | c=0.998437
[Epoch 0094] loss=11.5822 cls=0.0170 smmd=-0.0039 ct=9.2263 rec=1.1714 | train/val/test=1.000/0.726/0.732 | c=0.998437
[Epoch 0095] loss=11.5814 cls=0.0173 smmd=-0.0076 ct=9.2269 rec=1.1724 | train/val/test=1.000/0.716/0.719 | c=0.998437
[Epoch 0096] loss=11.5948 cls=0.0198 smmd=-0.0147 ct=9.2407 rec=1.1745 | train/val/test=1.000/0.722/0.737 | c=0.998437
[Epoch 0097] loss=11.5825 cls=0.0184 smmd=-0.0065 ct=9.2245 rec=1.1731 | train/val/test=1.000/0.726/0.729 | c=0.998437
[Epoch 0098] loss=11.5633 cls=0.0169 smmd=-0.0237 ct=9.2291 rec=1.1705 | train/val/test=1.000/0.718/0.723 | c=0.998437
[Epoch 0099] loss=11.5711 cls=0.0179 smmd=-0.0246 ct=9.2349 rec=1.1714 | train/val/test=1.000/0.720/0.737 | c=0.998437
=== Best @ epoch 77: val=0.7340, test=0.7350 ===

==================================================
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5 - 2025-09-21 04:28:32:
Running experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5...
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.0882 cls=1.9497 smmd=4.0956 ct=9.2651 rec=1.3889 | train/val/test=0.207/0.316/0.319 | c=0.998437
[Epoch 0001] loss=16.5374 cls=1.8929 smmd=2.6756 ct=9.1901 rec=1.3894 | train/val/test=0.655/0.440/0.441 | c=0.998437
[Epoch 0002] loss=15.0595 cls=1.7724 smmd=1.4267 ct=9.0828 rec=1.3888 | train/val/test=0.828/0.336/0.351 | c=0.998437
[Epoch 0003] loss=14.8048 cls=1.5349 smmd=1.4570 ct=9.0376 rec=1.3876 | train/val/test=0.828/0.544/0.509 | c=0.998437
[Epoch 0004] loss=14.5448 cls=1.2025 smmd=1.6546 ct=8.9259 rec=1.3809 | train/val/test=0.931/0.628/0.607 | c=0.998437
[Epoch 0005] loss=13.9990 cls=0.8331 smmd=1.5739 ct=8.8647 rec=1.3636 | train/val/test=0.931/0.622/0.606 | c=0.998437
[Epoch 0006] loss=14.0439 cls=0.5274 smmd=1.3509 ct=9.4930 rec=1.3364 | train/val/test=0.966/0.678/0.653 | c=0.998437
[Epoch 0007] loss=13.3980 cls=0.3205 smmd=1.1189 ct=9.3475 rec=1.3055 | train/val/test=1.000/0.698/0.679 | c=0.998437
[Epoch 0008] loss=13.1537 cls=0.1956 smmd=1.1341 ct=9.2711 rec=1.2764 | train/val/test=1.000/0.688/0.673 | c=0.998437
[Epoch 0009] loss=13.1336 cls=0.1168 smmd=1.2479 ct=9.2668 rec=1.2510 | train/val/test=1.000/0.674/0.677 | c=0.998437
[Epoch 0010] loss=13.0673 cls=0.0686 smmd=1.2317 ct=9.3041 rec=1.2315 | train/val/test=1.000/0.670/0.682 | c=0.998437
[Epoch 0011] loss=12.9038 cls=0.0411 smmd=1.0722 ct=9.3549 rec=1.2178 | train/val/test=1.000/0.672/0.685 | c=0.998437
[Epoch 0012] loss=12.7082 cls=0.0251 smmd=0.8877 ct=9.3822 rec=1.2066 | train/val/test=1.000/0.674/0.694 | c=0.998437
[Epoch 0013] loss=12.5454 cls=0.0175 smmd=0.7454 ct=9.3850 rec=1.1988 | train/val/test=1.000/0.686/0.693 | c=0.998437
[Epoch 0014] loss=12.4895 cls=0.0120 smmd=0.7133 ct=9.3751 rec=1.1946 | train/val/test=1.000/0.700/0.702 | c=0.998437
[Epoch 0015] loss=12.4676 cls=0.0084 smmd=0.7115 ct=9.3634 rec=1.1921 | train/val/test=1.000/0.698/0.705 | c=0.998437
[Epoch 0016] loss=12.3993 cls=0.0069 smmd=0.6525 ct=9.3565 rec=1.1917 | train/val/test=1.000/0.696/0.702 | c=0.998437
[Epoch 0017] loss=12.3025 cls=0.0068 smmd=0.5619 ct=9.3491 rec=1.1923 | train/val/test=1.000/0.696/0.704 | c=0.998437
[Epoch 0018] loss=12.2059 cls=0.0073 smmd=0.4669 ct=9.3447 rec=1.1935 | train/val/test=1.000/0.706/0.707 | c=0.998437
[Epoch 0019] loss=12.1715 cls=0.0087 smmd=0.4220 ct=9.3500 rec=1.1954 | train/val/test=1.000/0.702/0.707 | c=0.998437
[Epoch 0020] loss=12.1561 cls=0.0109 smmd=0.3901 ct=9.3580 rec=1.1986 | train/val/test=1.000/0.704/0.710 | c=0.998437
[Epoch 0021] loss=12.1073 cls=0.0145 smmd=0.3380 ct=9.3534 rec=1.2007 | train/val/test=1.000/0.706/0.712 | c=0.998437
[Epoch 0022] loss=12.0454 cls=0.0189 smmd=0.2790 ct=9.3435 rec=1.2020 | train/val/test=1.000/0.706/0.709 | c=0.998437
[Epoch 0023] loss=12.0289 cls=0.0231 smmd=0.2588 ct=9.3447 rec=1.2011 | train/val/test=1.000/0.716/0.719 | c=0.998437
[Epoch 0024] loss=12.0092 cls=0.0274 smmd=0.2348 ct=9.3509 rec=1.1981 | train/val/test=1.000/0.720/0.720 | c=0.998437
[Epoch 0025] loss=11.9699 cls=0.0315 smmd=0.1956 ct=9.3532 rec=1.1948 | train/val/test=1.000/0.720/0.738 | c=0.998437
[Epoch 0026] loss=11.9586 cls=0.0353 smmd=0.1860 ct=9.3563 rec=1.1905 | train/val/test=1.000/0.716/0.716 | c=0.998437
[Epoch 0027] loss=11.9381 cls=0.0424 smmd=0.1680 ct=9.3526 rec=1.1875 | train/val/test=1.000/0.718/0.736 | c=0.998437
[Epoch 0028] loss=11.9513 cls=0.0431 smmd=0.1850 ct=9.3496 rec=1.1868 | train/val/test=1.000/0.706/0.720 | c=0.998437
[Epoch 0029] loss=11.9241 cls=0.0440 smmd=0.1817 ct=9.3383 rec=1.1801 | train/val/test=1.000/0.728/0.742 | c=0.998437
[Epoch 0030] loss=11.8369 cls=0.0231 smmd=0.1377 ct=9.3308 rec=1.1726 | train/val/test=1.000/0.730/0.738 | c=0.998437
[Epoch 0031] loss=11.8270 cls=0.0226 smmd=0.1243 ct=9.3358 rec=1.1722 | train/val/test=1.000/0.716/0.721 | c=0.998437
[Epoch 0032] loss=11.8266 cls=0.0157 smmd=0.1397 ct=9.3331 rec=1.1691 | train/val/test=1.000/0.728/0.740 | c=0.998437
[Epoch 0033] loss=11.7820 cls=0.0124 smmd=0.1143 ct=9.3194 rec=1.1680 | train/val/test=1.000/0.726/0.733 | c=0.998437
[Epoch 0034] loss=11.7856 cls=0.0152 smmd=0.1069 ct=9.3234 rec=1.1700 | train/val/test=1.000/0.718/0.725 | c=0.998437
[Epoch 0035] loss=11.7634 cls=0.0117 smmd=0.0921 ct=9.3207 rec=1.1694 | train/val/test=1.000/0.722/0.739 | c=0.998437
[Epoch 0036] loss=11.7544 cls=0.0122 smmd=0.0890 ct=9.3099 rec=1.1716 | train/val/test=1.000/0.722/0.723 | c=0.998437
[Epoch 0037] loss=11.7383 cls=0.0136 smmd=0.0704 ct=9.3096 rec=1.1724 | train/val/test=1.000/0.720/0.724 | c=0.998437
[Epoch 0038] loss=11.7357 cls=0.0141 smmd=0.0615 ct=9.3123 rec=1.1739 | train/val/test=1.000/0.728/0.740 | c=0.998437
[Epoch 0039] loss=11.7453 cls=0.0158 smmd=0.0672 ct=9.3076 rec=1.1774 | train/val/test=1.000/0.722/0.716 | c=0.998437
[Epoch 0040] loss=11.7254 cls=0.0165 smmd=0.0530 ct=9.3055 rec=1.1752 | train/val/test=1.000/0.722/0.733 | c=0.998437
[Epoch 0041] loss=11.7125 cls=0.0155 smmd=0.0455 ct=9.3040 rec=1.1737 | train/val/test=1.000/0.724/0.734 | c=0.998437
[Epoch 0042] loss=11.7077 cls=0.0168 smmd=0.0422 ct=9.3007 rec=1.1740 | train/val/test=1.000/0.728/0.726 | c=0.998437
[Epoch 0043] loss=11.7031 cls=0.0178 smmd=0.0400 ct=9.3013 rec=1.1720 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0044] loss=11.6877 cls=0.0169 smmd=0.0330 ct=9.2957 rec=1.1710 | train/val/test=1.000/0.732/0.730 | c=0.998437
[Epoch 0045] loss=11.6860 cls=0.0183 smmd=0.0404 ct=9.2878 rec=1.1697 | train/val/test=1.000/0.726/0.732 | c=0.998437
[Epoch 0046] loss=11.6799 cls=0.0189 smmd=0.0309 ct=9.2917 rec=1.1692 | train/val/test=1.000/0.732/0.733 | c=0.998437
[Epoch 0047] loss=11.6711 cls=0.0180 smmd=0.0262 ct=9.2886 rec=1.1692 | train/val/test=1.000/0.726/0.726 | c=0.998437
[Epoch 0048] loss=11.6673 cls=0.0191 smmd=0.0268 ct=9.2831 rec=1.1691 | train/val/test=1.000/0.732/0.736 | c=0.998437
[Epoch 0049] loss=11.6636 cls=0.0189 smmd=0.0193 ct=9.2858 rec=1.1698 | train/val/test=1.000/0.728/0.730 | c=0.998437
[Epoch 0050] loss=11.6539 cls=0.0178 smmd=0.0223 ct=9.2757 rec=1.1691 | train/val/test=1.000/0.726/0.728 | c=0.998437
[Epoch 0051] loss=11.6444 cls=0.0178 smmd=0.0156 ct=9.2713 rec=1.1699 | train/val/test=1.000/0.728/0.734 | c=0.998437
[Epoch 0052] loss=11.6512 cls=0.0177 smmd=0.0158 ct=9.2755 rec=1.1711 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0053] loss=11.6447 cls=0.0178 smmd=0.0161 ct=9.2683 rec=1.1713 | train/val/test=1.000/0.728/0.733 | c=0.998437
[Epoch 0054] loss=11.6373 cls=0.0168 smmd=0.0041 ct=9.2737 rec=1.1714 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0055] loss=11.6365 cls=0.0171 smmd=0.0066 ct=9.2692 rec=1.1718 | train/val/test=1.000/0.726/0.733 | c=0.998437
[Epoch 0056] loss=11.6345 cls=0.0169 smmd=0.0097 ct=9.2634 rec=1.1722 | train/val/test=1.000/0.718/0.726 | c=0.998437
[Epoch 0057] loss=11.6302 cls=0.0170 smmd=0.0071 ct=9.2631 rec=1.1715 | train/val/test=1.000/0.730/0.734 | c=0.998437
[Epoch 0058] loss=11.6262 cls=0.0163 smmd=0.0072 ct=9.2608 rec=1.1710 | train/val/test=1.000/0.720/0.730 | c=0.998437
[Epoch 0059] loss=11.6249 cls=0.0169 smmd=0.0048 ct=9.2616 rec=1.1708 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0060] loss=11.6173 cls=0.0167 smmd=-0.0047 ct=9.2634 rec=1.1709 | train/val/test=1.000/0.724/0.731 | c=0.998437
[Epoch 0061] loss=11.6133 cls=0.0170 smmd=0.0024 ct=9.2531 rec=1.1704 | train/val/test=1.000/0.728/0.735 | c=0.998437
[Epoch 0062] loss=11.6090 cls=0.0167 smmd=-0.0034 ct=9.2544 rec=1.1707 | train/val/test=1.000/0.722/0.725 | c=0.998437
[Epoch 0063] loss=11.6105 cls=0.0175 smmd=-0.0016 ct=9.2536 rec=1.1705 | train/val/test=1.000/0.728/0.734 | c=0.998437
[Epoch 0064] loss=11.6082 cls=0.0173 smmd=0.0002 ct=9.2485 rec=1.1711 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0065] loss=11.6082 cls=0.0181 smmd=-0.0015 ct=9.2500 rec=1.1708 | train/val/test=1.000/0.728/0.733 | c=0.998437
[Epoch 0066] loss=11.6007 cls=0.0175 smmd=-0.0078 ct=9.2485 rec=1.1713 | train/val/test=1.000/0.722/0.727 | c=0.998437
[Epoch 0067] loss=11.5999 cls=0.0185 smmd=-0.0065 ct=9.2453 rec=1.1713 | train/val/test=1.000/0.732/0.733 | c=0.998437
[Epoch 0068] loss=11.6075 cls=0.0183 smmd=-0.0077 ct=9.2520 rec=1.1725 | train/val/test=1.000/0.720/0.725 | c=0.998437
[Epoch 0069] loss=11.6194 cls=0.0210 smmd=0.0083 ct=9.2420 rec=1.1741 | train/val/test=1.000/0.730/0.737 | c=0.998437
[Epoch 0070] loss=11.6460 cls=0.0216 smmd=0.0064 ct=9.2628 rec=1.1776 | train/val/test=1.000/0.708/0.716 | c=0.998437
[Epoch 0071] loss=11.7129 cls=0.0331 smmd=0.0485 ct=9.2655 rec=1.1829 | train/val/test=1.000/0.720/0.726 | c=0.998437
[Epoch 0072] loss=11.7461 cls=0.0297 smmd=0.0503 ct=9.2910 rec=1.1875 | train/val/test=1.000/0.710/0.713 | c=0.998437
[Epoch 0073] loss=11.7010 cls=0.0201 smmd=0.0599 ct=9.2735 rec=1.1737 | train/val/test=1.000/0.724/0.730 | c=0.998437
[Epoch 0074] loss=11.5819 cls=0.0104 smmd=-0.0002 ct=9.2459 rec=1.1629 | train/val/test=1.000/0.732/0.729 | c=0.998437
[Epoch 0075] loss=11.7021 cls=0.0177 smmd=0.0516 ct=9.2845 rec=1.1742 | train/val/test=1.000/0.718/0.723 | c=0.998437
[Epoch 0076] loss=11.6484 cls=0.0110 smmd=0.0459 ct=9.2634 rec=1.1641 | train/val/test=1.000/0.718/0.726 | c=0.998437
[Epoch 0077] loss=11.6188 cls=0.0107 smmd=0.0253 ct=9.2551 rec=1.1639 | train/val/test=1.000/0.734/0.735 | c=0.998437
[Epoch 0078] loss=11.6762 cls=0.0141 smmd=0.0458 ct=9.2750 rec=1.1707 | train/val/test=1.000/0.722/0.729 | c=0.998437
[Epoch 0079] loss=11.5862 cls=0.0114 smmd=0.0010 ct=9.2433 rec=1.1652 | train/val/test=1.000/0.714/0.720 | c=0.998437
[Epoch 0080] loss=11.6341 cls=0.0165 smmd=0.0209 ct=9.2513 rec=1.1727 | train/val/test=1.000/0.728/0.740 | c=0.998437
[Epoch 0081] loss=11.6400 cls=0.0163 smmd=0.0139 ct=9.2616 rec=1.1741 | train/val/test=1.000/0.718/0.726 | c=0.998437
[Epoch 0082] loss=11.6039 cls=0.0176 smmd=-0.0036 ct=9.2409 rec=1.1745 | train/val/test=1.000/0.712/0.733 | c=0.998437
[Epoch 0083] loss=11.6198 cls=0.0224 smmd=0.0035 ct=9.2371 rec=1.1784 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0084] loss=11.6381 cls=0.0212 smmd=0.0017 ct=9.2621 rec=1.1765 | train/val/test=1.000/0.720/0.722 | c=0.998437
[Epoch 0085] loss=11.6191 cls=0.0225 smmd=0.0055 ct=9.2408 rec=1.1752 | train/val/test=1.000/0.716/0.736 | c=0.998437
[Epoch 0086] loss=11.5972 cls=0.0177 smmd=-0.0026 ct=9.2385 rec=1.1718 | train/val/test=1.000/0.722/0.727 | c=0.998437
[Epoch 0087] loss=11.6052 cls=0.0185 smmd=-0.0114 ct=9.2563 rec=1.1710 | train/val/test=1.000/0.724/0.726 | c=0.998437
[Epoch 0088] loss=11.5994 cls=0.0186 smmd=0.0030 ct=9.2386 rec=1.1696 | train/val/test=1.000/0.722/0.733 | c=0.998437
[Epoch 0089] loss=11.5866 cls=0.0152 smmd=0.0005 ct=9.2339 rec=1.1685 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0090] loss=11.5926 cls=0.0166 smmd=-0.0126 ct=9.2510 rec=1.1688 | train/val/test=1.000/0.724/0.727 | c=0.998437
[Epoch 0091] loss=11.5893 cls=0.0161 smmd=0.0008 ct=9.2350 rec=1.1687 | train/val/test=1.000/0.728/0.735 | c=0.998437
[Epoch 0092] loss=11.5830 cls=0.0156 smmd=-0.0041 ct=9.2310 rec=1.1702 | train/val/test=1.000/0.718/0.723 | c=0.998437
[Epoch 0093] loss=11.5923 cls=0.0177 smmd=-0.0124 ct=9.2439 rec=1.1716 | train/val/test=1.000/0.724/0.729 | c=0.998437
[Epoch 0094] loss=11.5822 cls=0.0170 smmd=-0.0039 ct=9.2263 rec=1.1714 | train/val/test=1.000/0.726/0.732 | c=0.998437
[Epoch 0095] loss=11.5814 cls=0.0173 smmd=-0.0076 ct=9.2269 rec=1.1724 | train/val/test=1.000/0.716/0.719 | c=0.998437
[Epoch 0096] loss=11.5948 cls=0.0198 smmd=-0.0147 ct=9.2407 rec=1.1745 | train/val/test=1.000/0.722/0.737 | c=0.998437
[Epoch 0097] loss=11.5825 cls=0.0184 smmd=-0.0065 ct=9.2245 rec=1.1731 | train/val/test=1.000/0.726/0.729 | c=0.998437
[Epoch 0098] loss=11.5633 cls=0.0169 smmd=-0.0237 ct=9.2291 rec=1.1705 | train/val/test=1.000/0.718/0.723 | c=0.998437
[Epoch 0099] loss=11.5711 cls=0.0179 smmd=-0.0246 ct=9.2349 rec=1.1714 | train/val/test=1.000/0.720/0.737 | c=0.998437
=== Best @ epoch 77: val=0.7340, test=0.7350 ===

Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-5 completed in 21.27 seconds.
==================================================
