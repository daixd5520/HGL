Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-1 - 2025-09-21 03:29:53:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-1...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.2039 cls=1.0999 smmd=5.5442 ct=7.2527 rec=1.4138 | train/val/test=0.391/0.395/0.395 | c=0.998437
[Epoch 0001] loss=51.4195 cls=1.0706 smmd=3.5803 ct=7.1868 rec=1.4147 | train/val/test=0.551/0.554/0.556 | c=0.998437
[Epoch 0002] loss=37.6260 cls=1.0779 smmd=2.2128 ct=7.1261 rec=1.4135 | train/val/test=0.546/0.552/0.552 | c=0.998437
[Epoch 0003] loss=40.3318 cls=1.0595 smmd=2.4900 ct=7.0977 rec=1.4131 | train/val/test=0.534/0.537/0.543 | c=0.998437
[Epoch 0004] loss=40.3306 cls=1.0124 smmd=2.3641 ct=7.7390 rec=1.4114 | train/val/test=0.527/0.540/0.543 | c=0.998437
[Epoch 0005] loss=36.1855 cls=0.9725 smmd=2.0039 ct=7.4782 rec=1.4077 | train/val/test=0.531/0.542/0.546 | c=0.998437
[Epoch 0006] loss=31.9775 cls=0.9608 smmd=1.5891 ct=7.4527 rec=1.4023 | train/val/test=0.534/0.544/0.550 | c=0.998437
[Epoch 0007] loss=34.2697 cls=0.9405 smmd=1.8024 ct=7.5390 rec=1.3955 | train/val/test=0.533/0.542/0.548 | c=0.998437
[Epoch 0008] loss=35.1124 cls=0.9029 smmd=1.8798 ct=7.5850 rec=1.3849 | train/val/test=0.540/0.546/0.553 | c=0.998437
[Epoch 0009] loss=29.0169 cls=0.8759 smmd=1.2756 ct=7.5671 rec=1.3783 | train/val/test=0.548/0.554/0.560 | c=0.998437
[Epoch 0010] loss=27.7260 cls=0.8406 smmd=1.1503 ct=7.5578 rec=1.3743 | train/val/test=0.572/0.581/0.585 | c=0.998437
[Epoch 0011] loss=30.2043 cls=0.8062 smmd=1.3990 ct=7.5618 rec=1.3745 | train/val/test=0.637/0.641/0.650 | c=0.998437
[Epoch 0012] loss=26.8794 cls=0.7695 smmd=1.0774 ct=7.5171 rec=1.3729 | train/val/test=0.699/0.698/0.705 | c=0.998437
[Epoch 0013] loss=26.1120 cls=0.7267 smmd=1.0018 ct=7.5237 rec=1.3670 | train/val/test=0.676/0.675/0.685 | c=0.998437
[Epoch 0014] loss=25.8331 cls=0.7094 smmd=0.9617 ct=7.5887 rec=1.3674 | train/val/test=0.721/0.715/0.726 | c=0.998437
[Epoch 0015] loss=25.0277 cls=0.6702 smmd=0.8887 ct=7.5623 rec=1.3628 | train/val/test=0.800/0.801/0.807 | c=0.998437
[Epoch 0016] loss=24.3550 cls=0.6271 smmd=0.8363 ct=7.5002 rec=1.3569 | train/val/test=0.807/0.812/0.813 | c=0.998437
[Epoch 0017] loss=23.3942 cls=0.6062 smmd=0.7407 ct=7.5043 rec=1.3520 | train/val/test=0.799/0.803/0.808 | c=0.998437
[Epoch 0018] loss=23.0636 cls=0.5750 smmd=0.7059 ct=7.5237 rec=1.3401 | train/val/test=0.796/0.795/0.802 | c=0.998437
[Epoch 0019] loss=22.4287 cls=0.5594 smmd=0.6398 ct=7.5417 rec=1.3347 | train/val/test=0.808/0.811/0.814 | c=0.998437
[Epoch 0020] loss=22.2050 cls=0.5391 smmd=0.6211 ct=7.5300 rec=1.3291 | train/val/test=0.819/0.820/0.825 | c=0.998437
[Epoch 0021] loss=21.3426 cls=0.5261 smmd=0.5421 ct=7.4979 rec=1.3260 | train/val/test=0.819/0.817/0.825 | c=0.998437
[Epoch 0022] loss=21.4341 cls=0.5247 smmd=0.5535 ct=7.4875 rec=1.3244 | train/val/test=0.819/0.819/0.823 | c=0.998437
[Epoch 0023] loss=20.9355 cls=0.5117 smmd=0.4977 ct=7.5217 rec=1.3188 | train/val/test=0.819/0.816/0.821 | c=0.998437
[Epoch 0024] loss=20.2827 cls=0.5032 smmd=0.4312 ct=7.5299 rec=1.3178 | train/val/test=0.820/0.817/0.822 | c=0.998437
[Epoch 0025] loss=20.6173 cls=0.5002 smmd=0.4680 ct=7.5146 rec=1.3159 | train/val/test=0.824/0.820/0.827 | c=0.998437
[Epoch 0026] loss=19.6428 cls=0.4968 smmd=0.3738 ct=7.4998 rec=1.3138 | train/val/test=0.826/0.822/0.831 | c=0.998437
[Epoch 0027] loss=19.9464 cls=0.4920 smmd=0.4050 ct=7.4967 rec=1.3139 | train/val/test=0.826/0.823/0.827 | c=0.998437
[Epoch 0028] loss=19.5811 cls=0.4823 smmd=0.3662 ct=7.5112 rec=1.3113 | train/val/test=0.828/0.825/0.830 | c=0.998437
[Epoch 0029] loss=19.2442 cls=0.4750 smmd=0.3316 ct=7.5178 rec=1.3107 | train/val/test=0.830/0.824/0.831 | c=0.998437
[Epoch 0030] loss=19.2010 cls=0.4701 smmd=0.3302 ct=7.5049 rec=1.3083 | train/val/test=0.831/0.829/0.832 | c=0.998437
[Epoch 0031] loss=18.8304 cls=0.4657 smmd=0.2971 ct=7.4867 rec=1.3072 | train/val/test=0.833/0.832/0.836 | c=0.998437
[Epoch 0032] loss=18.6813 cls=0.4626 smmd=0.2831 ct=7.4821 rec=1.3090 | train/val/test=0.834/0.829/0.834 | c=0.998437
[Epoch 0033] loss=18.6239 cls=0.4602 smmd=0.2725 ct=7.5075 rec=1.3074 | train/val/test=0.835/0.833/0.836 | c=0.998437
[Epoch 0034] loss=18.4485 cls=0.4573 smmd=0.2551 ct=7.5072 rec=1.3084 | train/val/test=0.837/0.835/0.837 | c=0.998437
[Epoch 0035] loss=18.2499 cls=0.4571 smmd=0.2387 ct=7.4893 rec=1.3103 | train/val/test=0.837/0.829/0.836 | c=0.998437
[Epoch 0036] loss=18.1989 cls=0.4577 smmd=0.2341 ct=7.4870 rec=1.3102 | train/val/test=0.841/0.839/0.838 | c=0.998437
[Epoch 0037] loss=18.0930 cls=0.4566 smmd=0.2220 ct=7.4944 rec=1.3123 | train/val/test=0.838/0.831/0.837 | c=0.998437
[Epoch 0038] loss=17.8988 cls=0.4568 smmd=0.2012 ct=7.5014 rec=1.3119 | train/val/test=0.842/0.839/0.839 | c=0.998437
[Epoch 0039] loss=17.8708 cls=0.4564 smmd=0.1984 ct=7.5011 rec=1.3125 | train/val/test=0.842/0.836/0.839 | c=0.998437
[Epoch 0040] loss=17.7489 cls=0.4557 smmd=0.1887 ct=7.4888 rec=1.3129 | train/val/test=0.837/0.830/0.839 | c=0.998437
[Epoch 0041] loss=17.6975 cls=0.4559 smmd=0.1833 ct=7.4901 rec=1.3135 | train/val/test=0.843/0.837/0.841 | c=0.998437
[Epoch 0042] loss=17.5832 cls=0.4551 smmd=0.1707 ct=7.4956 rec=1.3141 | train/val/test=0.837/0.830/0.836 | c=0.998437
[Epoch 0043] loss=17.5240 cls=0.4568 smmd=0.1651 ct=7.4939 rec=1.3132 | train/val/test=0.843/0.841/0.840 | c=0.998437
[Epoch 0044] loss=17.4274 cls=0.4562 smmd=0.1563 ct=7.4896 rec=1.3146 | train/val/test=0.837/0.829/0.837 | c=0.998437
[Epoch 0045] loss=17.4326 cls=0.4574 smmd=0.1567 ct=7.4900 rec=1.3142 | train/val/test=0.843/0.841/0.842 | c=0.998437
[Epoch 0046] loss=17.3876 cls=0.4585 smmd=0.1524 ct=7.4882 rec=1.3157 | train/val/test=0.835/0.827/0.833 | c=0.998437
[Epoch 0047] loss=17.2769 cls=0.4614 smmd=0.1401 ct=7.4935 rec=1.3159 | train/val/test=0.843/0.841/0.843 | c=0.998437
[Epoch 0048] loss=17.2499 cls=0.4614 smmd=0.1378 ct=7.4910 rec=1.3176 | train/val/test=0.838/0.831/0.837 | c=0.998437
[Epoch 0049] loss=17.2165 cls=0.4635 smmd=0.1353 ct=7.4870 rec=1.3164 | train/val/test=0.843/0.839/0.841 | c=0.998437
[Epoch 0050] loss=17.2243 cls=0.4630 smmd=0.1353 ct=7.4905 rec=1.3185 | train/val/test=0.839/0.833/0.838 | c=0.998437
[Epoch 0051] loss=17.1594 cls=0.4654 smmd=0.1293 ct=7.4877 rec=1.3172 | train/val/test=0.842/0.839/0.843 | c=0.998437
[Epoch 0052] loss=17.1408 cls=0.4647 smmd=0.1259 ct=7.4949 rec=1.3184 | train/val/test=0.839/0.834/0.840 | c=0.998437
[Epoch 0053] loss=17.1360 cls=0.4663 smmd=0.1280 ct=7.4821 rec=1.3176 | train/val/test=0.842/0.838/0.842 | c=0.998437
[Epoch 0054] loss=17.0845 cls=0.4671 smmd=0.1213 ct=7.4893 rec=1.3179 | train/val/test=0.839/0.834/0.841 | c=0.998437
[Epoch 0055] loss=17.0905 cls=0.4668 smmd=0.1227 ct=7.4855 rec=1.3174 | train/val/test=0.841/0.836/0.842 | c=0.998437
[Epoch 0056] loss=17.0548 cls=0.4676 smmd=0.1198 ct=7.4823 rec=1.3173 | train/val/test=0.840/0.835/0.842 | c=0.998437
[Epoch 0057] loss=17.0619 cls=0.4678 smmd=0.1192 ct=7.4887 rec=1.3175 | train/val/test=0.841/0.835/0.842 | c=0.998437
[Epoch 0058] loss=17.0885 cls=0.4685 smmd=0.1231 ct=7.4823 rec=1.3176 | train/val/test=0.840/0.835/0.843 | c=0.998437
[Epoch 0059] loss=17.0306 cls=0.4701 smmd=0.1168 ct=7.4847 rec=1.3172 | train/val/test=0.839/0.832/0.840 | c=0.998437
[Epoch 0060] loss=17.0209 cls=0.4694 smmd=0.1167 ct=7.4800 rec=1.3179 | train/val/test=0.841/0.834/0.842 | c=0.998437
[Epoch 0061] loss=17.0478 cls=0.4704 smmd=0.1183 ct=7.4854 rec=1.3182 | train/val/test=0.835/0.828/0.834 | c=0.998437
[Epoch 0062] loss=17.0220 cls=0.4728 smmd=0.1157 ct=7.4851 rec=1.3179 | train/val/test=0.843/0.840/0.848 | c=0.998437
[Epoch 0063] loss=16.9568 cls=0.4739 smmd=0.1094 ct=7.4828 rec=1.3208 | train/val/test=0.826/0.819/0.826 | c=0.998437
[Epoch 0064] loss=17.0502 cls=0.4801 smmd=0.1192 ct=7.4793 rec=1.3193 | train/val/test=0.842/0.838/0.849 | c=0.998437
[Epoch 0065] loss=17.1006 cls=0.4794 smmd=0.1217 ct=7.4913 rec=1.3229 | train/val/test=0.819/0.815/0.817 | c=0.998437
[Epoch 0066] loss=17.1606 cls=0.4880 smmd=0.1305 ct=7.4757 rec=1.3213 | train/val/test=0.832/0.828/0.843 | c=0.998437
[Epoch 0067] loss=17.2307 cls=0.4928 smmd=0.1336 ct=7.4927 rec=1.3265 | train/val/test=0.807/0.802/0.803 | c=0.998437
[Epoch 0068] loss=17.2524 cls=0.5040 smmd=0.1383 ct=7.4773 rec=1.3250 | train/val/test=0.825/0.823/0.836 | c=0.998437
[Epoch 0069] loss=17.2213 cls=0.5015 smmd=0.1322 ct=7.4922 rec=1.3279 | train/val/test=0.813/0.806/0.809 | c=0.998437
[Epoch 0070] loss=17.2494 cls=0.4939 smmd=0.1398 ct=7.4717 rec=1.3219 | train/val/test=0.838/0.835/0.847 | c=0.998437
[Epoch 0071] loss=17.1845 cls=0.4785 smmd=0.1315 ct=7.4852 rec=1.3205 | train/val/test=0.831/0.823/0.827 | c=0.998437
[Epoch 0072] loss=17.0886 cls=0.4687 smmd=0.1269 ct=7.4635 rec=1.3156 | train/val/test=0.844/0.841/0.847 | c=0.998437
[Epoch 0073] loss=17.0053 cls=0.4647 smmd=0.1162 ct=7.4765 rec=1.3168 | train/val/test=0.839/0.834/0.840 | c=0.998437
[Epoch 0074] loss=17.0054 cls=0.4658 smmd=0.1170 ct=7.4720 rec=1.3172 | train/val/test=0.839/0.830/0.837 | c=0.998437
[Epoch 0075] loss=17.0169 cls=0.4695 smmd=0.1179 ct=7.4716 rec=1.3195 | train/val/test=0.846/0.840/0.848 | c=0.998437
[Epoch 0076] loss=17.0360 cls=0.4742 smmd=0.1175 ct=7.4811 rec=1.3227 | train/val/test=0.835/0.825/0.832 | c=0.998437
[Epoch 0077] loss=17.0974 cls=0.4803 smmd=0.1245 ct=7.4749 rec=1.3239 | train/val/test=0.845/0.844/0.850 | c=0.998437
[Epoch 0078] loss=17.1209 cls=0.4817 smmd=0.1255 ct=7.4806 rec=1.3267 | train/val/test=0.830/0.820/0.828 | c=0.998437
[Epoch 0079] loss=17.2059 cls=0.4849 smmd=0.1350 ct=7.4755 rec=1.3260 | train/val/test=0.842/0.839/0.847 | c=0.998437
[Epoch 0080] loss=17.2918 cls=0.4861 smmd=0.1420 ct=7.4825 rec=1.3275 | train/val/test=0.821/0.815/0.820 | c=0.998437
[Epoch 0081] loss=17.3420 cls=0.4901 smmd=0.1504 ct=7.4646 rec=1.3267 | train/val/test=0.832/0.829/0.839 | c=0.998437
[Epoch 0082] loss=17.2293 cls=0.4964 smmd=0.1342 ct=7.4872 rec=1.3289 | train/val/test=0.812/0.806/0.812 | c=0.998437
[Epoch 0083] loss=17.2442 cls=0.4975 smmd=0.1412 ct=7.4602 rec=1.3260 | train/val/test=0.828/0.827/0.836 | c=0.998437
[Epoch 0084] loss=17.2073 cls=0.4967 smmd=0.1340 ct=7.4772 rec=1.3284 | train/val/test=0.818/0.813/0.817 | c=0.998437
[Epoch 0085] loss=17.1294 cls=0.4867 smmd=0.1306 ct=7.4598 rec=1.3212 | train/val/test=0.841/0.838/0.848 | c=0.998437
[Epoch 0086] loss=17.0558 cls=0.4755 smmd=0.1219 ct=7.4691 rec=1.3223 | train/val/test=0.833/0.825/0.834 | c=0.998437
[Epoch 0087] loss=16.9271 cls=0.4696 smmd=0.1120 ct=7.4569 rec=1.3182 | train/val/test=0.843/0.840/0.843 | c=0.998437
[Epoch 0088] loss=16.9310 cls=0.4681 smmd=0.1104 ct=7.4664 rec=1.3204 | train/val/test=0.840/0.833/0.840 | c=0.998437
[Epoch 0089] loss=17.0056 cls=0.4718 smmd=0.1182 ct=7.4634 rec=1.3223 | train/val/test=0.839/0.829/0.835 | c=0.998437
[Epoch 0090] loss=17.0010 cls=0.4764 smmd=0.1164 ct=7.4684 rec=1.3247 | train/val/test=0.846/0.840/0.846 | c=0.998437
[Epoch 0091] loss=17.0324 cls=0.4777 smmd=0.1202 ct=7.4640 rec=1.3266 | train/val/test=0.835/0.824/0.833 | c=0.998437
[Epoch 0092] loss=17.0896 cls=0.4838 smmd=0.1251 ct=7.4664 rec=1.3282 | train/val/test=0.843/0.839/0.850 | c=0.998437
[Epoch 0093] loss=17.1044 cls=0.4844 smmd=0.1265 ct=7.4662 rec=1.3291 | train/val/test=0.821/0.811/0.821 | c=0.998437
[Epoch 0094] loss=17.1333 cls=0.4958 smmd=0.1312 ct=7.4534 rec=1.3322 | train/val/test=0.827/0.826/0.838 | c=0.998437
[Epoch 0095] loss=17.1390 cls=0.5040 smmd=0.1268 ct=7.4762 rec=1.3326 | train/val/test=0.800/0.795/0.798 | c=0.998437
[Epoch 0096] loss=17.2218 cls=0.5222 smmd=0.1406 ct=7.4427 rec=1.3385 | train/val/test=0.797/0.794/0.805 | c=0.998437
[Epoch 0097] loss=17.3778 cls=0.5382 smmd=0.1462 ct=7.4883 rec=1.3399 | train/val/test=0.789/0.786/0.787 | c=0.998437
[Epoch 0098] loss=17.4011 cls=0.5370 smmd=0.1575 ct=7.4441 rec=1.3398 | train/val/test=0.815/0.812/0.824 | c=0.998437
[Epoch 0099] loss=17.1683 cls=0.5143 smmd=0.1309 ct=7.4678 rec=1.3331 | train/val/test=0.823/0.819/0.825 | c=0.998437
=== Best @ epoch 77: val=0.8435, test=0.8496 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-1 - 2025-09-21 03:29:53:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-1...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.2039 cls=1.0999 smmd=5.5442 ct=7.2527 rec=1.4138 | train/val/test=0.391/0.395/0.395 | c=0.998437
[Epoch 0001] loss=51.4195 cls=1.0706 smmd=3.5803 ct=7.1868 rec=1.4147 | train/val/test=0.551/0.554/0.556 | c=0.998437
[Epoch 0002] loss=37.6260 cls=1.0779 smmd=2.2128 ct=7.1261 rec=1.4135 | train/val/test=0.546/0.552/0.552 | c=0.998437
[Epoch 0003] loss=40.3318 cls=1.0595 smmd=2.4900 ct=7.0977 rec=1.4131 | train/val/test=0.534/0.537/0.543 | c=0.998437
[Epoch 0004] loss=40.3306 cls=1.0124 smmd=2.3641 ct=7.7390 rec=1.4114 | train/val/test=0.527/0.540/0.543 | c=0.998437
[Epoch 0005] loss=36.1855 cls=0.9725 smmd=2.0039 ct=7.4782 rec=1.4077 | train/val/test=0.531/0.542/0.546 | c=0.998437
[Epoch 0006] loss=31.9775 cls=0.9608 smmd=1.5891 ct=7.4527 rec=1.4023 | train/val/test=0.534/0.544/0.550 | c=0.998437
[Epoch 0007] loss=34.2697 cls=0.9405 smmd=1.8024 ct=7.5390 rec=1.3955 | train/val/test=0.533/0.542/0.548 | c=0.998437
[Epoch 0008] loss=35.1124 cls=0.9029 smmd=1.8798 ct=7.5850 rec=1.3849 | train/val/test=0.540/0.546/0.553 | c=0.998437
[Epoch 0009] loss=29.0169 cls=0.8759 smmd=1.2756 ct=7.5671 rec=1.3783 | train/val/test=0.548/0.554/0.560 | c=0.998437
[Epoch 0010] loss=27.7260 cls=0.8406 smmd=1.1503 ct=7.5578 rec=1.3743 | train/val/test=0.572/0.581/0.585 | c=0.998437
[Epoch 0011] loss=30.2043 cls=0.8062 smmd=1.3990 ct=7.5618 rec=1.3745 | train/val/test=0.637/0.641/0.650 | c=0.998437
[Epoch 0012] loss=26.8794 cls=0.7695 smmd=1.0774 ct=7.5171 rec=1.3729 | train/val/test=0.699/0.698/0.705 | c=0.998437
[Epoch 0013] loss=26.1120 cls=0.7267 smmd=1.0018 ct=7.5237 rec=1.3670 | train/val/test=0.676/0.675/0.685 | c=0.998437
[Epoch 0014] loss=25.8331 cls=0.7094 smmd=0.9617 ct=7.5887 rec=1.3674 | train/val/test=0.721/0.715/0.726 | c=0.998437
[Epoch 0015] loss=25.0277 cls=0.6702 smmd=0.8887 ct=7.5623 rec=1.3628 | train/val/test=0.800/0.801/0.807 | c=0.998437
[Epoch 0016] loss=24.3550 cls=0.6271 smmd=0.8363 ct=7.5002 rec=1.3569 | train/val/test=0.807/0.812/0.813 | c=0.998437
[Epoch 0017] loss=23.3942 cls=0.6062 smmd=0.7407 ct=7.5043 rec=1.3520 | train/val/test=0.799/0.803/0.808 | c=0.998437
[Epoch 0018] loss=23.0636 cls=0.5750 smmd=0.7059 ct=7.5237 rec=1.3401 | train/val/test=0.796/0.795/0.802 | c=0.998437
[Epoch 0019] loss=22.4287 cls=0.5594 smmd=0.6398 ct=7.5417 rec=1.3347 | train/val/test=0.808/0.811/0.814 | c=0.998437
[Epoch 0020] loss=22.2050 cls=0.5391 smmd=0.6211 ct=7.5300 rec=1.3291 | train/val/test=0.819/0.820/0.825 | c=0.998437
[Epoch 0021] loss=21.3426 cls=0.5261 smmd=0.5421 ct=7.4979 rec=1.3260 | train/val/test=0.819/0.817/0.825 | c=0.998437
[Epoch 0022] loss=21.4341 cls=0.5247 smmd=0.5535 ct=7.4875 rec=1.3244 | train/val/test=0.819/0.819/0.823 | c=0.998437
[Epoch 0023] loss=20.9355 cls=0.5117 smmd=0.4977 ct=7.5217 rec=1.3188 | train/val/test=0.819/0.816/0.821 | c=0.998437
[Epoch 0024] loss=20.2827 cls=0.5032 smmd=0.4312 ct=7.5299 rec=1.3178 | train/val/test=0.820/0.817/0.822 | c=0.998437
[Epoch 0025] loss=20.6173 cls=0.5002 smmd=0.4680 ct=7.5146 rec=1.3159 | train/val/test=0.824/0.820/0.827 | c=0.998437
[Epoch 0026] loss=19.6428 cls=0.4968 smmd=0.3738 ct=7.4998 rec=1.3138 | train/val/test=0.826/0.822/0.831 | c=0.998437
[Epoch 0027] loss=19.9464 cls=0.4920 smmd=0.4050 ct=7.4967 rec=1.3139 | train/val/test=0.826/0.823/0.827 | c=0.998437
[Epoch 0028] loss=19.5811 cls=0.4823 smmd=0.3662 ct=7.5112 rec=1.3113 | train/val/test=0.828/0.825/0.830 | c=0.998437
[Epoch 0029] loss=19.2442 cls=0.4750 smmd=0.3316 ct=7.5178 rec=1.3107 | train/val/test=0.830/0.824/0.831 | c=0.998437
[Epoch 0030] loss=19.2010 cls=0.4701 smmd=0.3302 ct=7.5049 rec=1.3083 | train/val/test=0.831/0.829/0.832 | c=0.998437
[Epoch 0031] loss=18.8304 cls=0.4657 smmd=0.2971 ct=7.4867 rec=1.3072 | train/val/test=0.833/0.832/0.836 | c=0.998437
[Epoch 0032] loss=18.6813 cls=0.4626 smmd=0.2831 ct=7.4821 rec=1.3090 | train/val/test=0.834/0.829/0.834 | c=0.998437
[Epoch 0033] loss=18.6239 cls=0.4602 smmd=0.2725 ct=7.5075 rec=1.3074 | train/val/test=0.835/0.833/0.836 | c=0.998437
[Epoch 0034] loss=18.4485 cls=0.4573 smmd=0.2551 ct=7.5072 rec=1.3084 | train/val/test=0.837/0.835/0.837 | c=0.998437
[Epoch 0035] loss=18.2499 cls=0.4571 smmd=0.2387 ct=7.4893 rec=1.3103 | train/val/test=0.837/0.829/0.836 | c=0.998437
[Epoch 0036] loss=18.1989 cls=0.4577 smmd=0.2341 ct=7.4870 rec=1.3102 | train/val/test=0.841/0.839/0.838 | c=0.998437
[Epoch 0037] loss=18.0930 cls=0.4566 smmd=0.2220 ct=7.4944 rec=1.3123 | train/val/test=0.838/0.831/0.837 | c=0.998437
[Epoch 0038] loss=17.8988 cls=0.4568 smmd=0.2012 ct=7.5014 rec=1.3119 | train/val/test=0.842/0.839/0.839 | c=0.998437
[Epoch 0039] loss=17.8708 cls=0.4564 smmd=0.1984 ct=7.5011 rec=1.3125 | train/val/test=0.842/0.836/0.839 | c=0.998437
[Epoch 0040] loss=17.7489 cls=0.4557 smmd=0.1887 ct=7.4888 rec=1.3129 | train/val/test=0.837/0.830/0.839 | c=0.998437
[Epoch 0041] loss=17.6975 cls=0.4559 smmd=0.1833 ct=7.4901 rec=1.3135 | train/val/test=0.843/0.837/0.841 | c=0.998437
[Epoch 0042] loss=17.5832 cls=0.4551 smmd=0.1707 ct=7.4956 rec=1.3141 | train/val/test=0.837/0.830/0.836 | c=0.998437
[Epoch 0043] loss=17.5240 cls=0.4568 smmd=0.1651 ct=7.4939 rec=1.3132 | train/val/test=0.843/0.841/0.840 | c=0.998437
[Epoch 0044] loss=17.4274 cls=0.4562 smmd=0.1563 ct=7.4896 rec=1.3146 | train/val/test=0.837/0.829/0.837 | c=0.998437
[Epoch 0045] loss=17.4326 cls=0.4574 smmd=0.1567 ct=7.4900 rec=1.3142 | train/val/test=0.843/0.841/0.842 | c=0.998437
[Epoch 0046] loss=17.3876 cls=0.4585 smmd=0.1524 ct=7.4882 rec=1.3157 | train/val/test=0.835/0.827/0.833 | c=0.998437
[Epoch 0047] loss=17.2769 cls=0.4614 smmd=0.1401 ct=7.4935 rec=1.3159 | train/val/test=0.843/0.841/0.843 | c=0.998437
[Epoch 0048] loss=17.2499 cls=0.4614 smmd=0.1378 ct=7.4910 rec=1.3176 | train/val/test=0.838/0.831/0.837 | c=0.998437
[Epoch 0049] loss=17.2165 cls=0.4635 smmd=0.1353 ct=7.4870 rec=1.3164 | train/val/test=0.843/0.839/0.841 | c=0.998437
[Epoch 0050] loss=17.2243 cls=0.4630 smmd=0.1353 ct=7.4905 rec=1.3185 | train/val/test=0.839/0.833/0.838 | c=0.998437
[Epoch 0051] loss=17.1594 cls=0.4654 smmd=0.1293 ct=7.4877 rec=1.3172 | train/val/test=0.842/0.839/0.843 | c=0.998437
[Epoch 0052] loss=17.1408 cls=0.4647 smmd=0.1259 ct=7.4949 rec=1.3184 | train/val/test=0.839/0.834/0.840 | c=0.998437
[Epoch 0053] loss=17.1360 cls=0.4663 smmd=0.1280 ct=7.4821 rec=1.3176 | train/val/test=0.842/0.838/0.842 | c=0.998437
[Epoch 0054] loss=17.0845 cls=0.4671 smmd=0.1213 ct=7.4893 rec=1.3179 | train/val/test=0.839/0.834/0.841 | c=0.998437
[Epoch 0055] loss=17.0905 cls=0.4668 smmd=0.1227 ct=7.4855 rec=1.3174 | train/val/test=0.841/0.836/0.842 | c=0.998437
[Epoch 0056] loss=17.0548 cls=0.4676 smmd=0.1198 ct=7.4823 rec=1.3173 | train/val/test=0.840/0.835/0.842 | c=0.998437
[Epoch 0057] loss=17.0619 cls=0.4678 smmd=0.1192 ct=7.4887 rec=1.3175 | train/val/test=0.841/0.835/0.842 | c=0.998437
[Epoch 0058] loss=17.0885 cls=0.4685 smmd=0.1231 ct=7.4823 rec=1.3176 | train/val/test=0.840/0.835/0.843 | c=0.998437
[Epoch 0059] loss=17.0306 cls=0.4701 smmd=0.1168 ct=7.4847 rec=1.3172 | train/val/test=0.839/0.832/0.840 | c=0.998437
[Epoch 0060] loss=17.0209 cls=0.4694 smmd=0.1167 ct=7.4800 rec=1.3179 | train/val/test=0.841/0.834/0.842 | c=0.998437
[Epoch 0061] loss=17.0478 cls=0.4704 smmd=0.1183 ct=7.4854 rec=1.3182 | train/val/test=0.835/0.828/0.834 | c=0.998437
[Epoch 0062] loss=17.0220 cls=0.4728 smmd=0.1157 ct=7.4851 rec=1.3179 | train/val/test=0.843/0.840/0.848 | c=0.998437
[Epoch 0063] loss=16.9568 cls=0.4739 smmd=0.1094 ct=7.4828 rec=1.3208 | train/val/test=0.826/0.819/0.826 | c=0.998437
[Epoch 0064] loss=17.0502 cls=0.4801 smmd=0.1192 ct=7.4793 rec=1.3193 | train/val/test=0.842/0.838/0.849 | c=0.998437
[Epoch 0065] loss=17.1006 cls=0.4794 smmd=0.1217 ct=7.4913 rec=1.3229 | train/val/test=0.819/0.815/0.817 | c=0.998437
[Epoch 0066] loss=17.1606 cls=0.4880 smmd=0.1305 ct=7.4757 rec=1.3213 | train/val/test=0.832/0.828/0.843 | c=0.998437
[Epoch 0067] loss=17.2307 cls=0.4928 smmd=0.1336 ct=7.4927 rec=1.3265 | train/val/test=0.807/0.802/0.803 | c=0.998437
[Epoch 0068] loss=17.2524 cls=0.5040 smmd=0.1383 ct=7.4773 rec=1.3250 | train/val/test=0.825/0.823/0.836 | c=0.998437
[Epoch 0069] loss=17.2213 cls=0.5015 smmd=0.1322 ct=7.4922 rec=1.3279 | train/val/test=0.813/0.806/0.809 | c=0.998437
[Epoch 0070] loss=17.2494 cls=0.4939 smmd=0.1398 ct=7.4717 rec=1.3219 | train/val/test=0.838/0.835/0.847 | c=0.998437
[Epoch 0071] loss=17.1845 cls=0.4785 smmd=0.1315 ct=7.4852 rec=1.3205 | train/val/test=0.831/0.823/0.827 | c=0.998437
[Epoch 0072] loss=17.0886 cls=0.4687 smmd=0.1269 ct=7.4635 rec=1.3156 | train/val/test=0.844/0.841/0.847 | c=0.998437
[Epoch 0073] loss=17.0053 cls=0.4647 smmd=0.1162 ct=7.4765 rec=1.3168 | train/val/test=0.839/0.834/0.840 | c=0.998437
[Epoch 0074] loss=17.0054 cls=0.4658 smmd=0.1170 ct=7.4720 rec=1.3172 | train/val/test=0.839/0.830/0.837 | c=0.998437
[Epoch 0075] loss=17.0169 cls=0.4695 smmd=0.1179 ct=7.4716 rec=1.3195 | train/val/test=0.846/0.840/0.848 | c=0.998437
[Epoch 0076] loss=17.0360 cls=0.4742 smmd=0.1175 ct=7.4811 rec=1.3227 | train/val/test=0.835/0.825/0.832 | c=0.998437
[Epoch 0077] loss=17.0974 cls=0.4803 smmd=0.1245 ct=7.4749 rec=1.3239 | train/val/test=0.845/0.844/0.850 | c=0.998437
[Epoch 0078] loss=17.1209 cls=0.4817 smmd=0.1255 ct=7.4806 rec=1.3267 | train/val/test=0.830/0.820/0.828 | c=0.998437
[Epoch 0079] loss=17.2059 cls=0.4849 smmd=0.1350 ct=7.4755 rec=1.3260 | train/val/test=0.842/0.839/0.847 | c=0.998437
[Epoch 0080] loss=17.2918 cls=0.4861 smmd=0.1420 ct=7.4825 rec=1.3275 | train/val/test=0.821/0.815/0.820 | c=0.998437
[Epoch 0081] loss=17.3420 cls=0.4901 smmd=0.1504 ct=7.4646 rec=1.3267 | train/val/test=0.832/0.829/0.839 | c=0.998437
[Epoch 0082] loss=17.2293 cls=0.4964 smmd=0.1342 ct=7.4872 rec=1.3289 | train/val/test=0.812/0.806/0.812 | c=0.998437
[Epoch 0083] loss=17.2442 cls=0.4975 smmd=0.1412 ct=7.4602 rec=1.3260 | train/val/test=0.828/0.827/0.836 | c=0.998437
[Epoch 0084] loss=17.2073 cls=0.4967 smmd=0.1340 ct=7.4772 rec=1.3284 | train/val/test=0.818/0.813/0.817 | c=0.998437
[Epoch 0085] loss=17.1294 cls=0.4867 smmd=0.1306 ct=7.4598 rec=1.3212 | train/val/test=0.841/0.838/0.848 | c=0.998437
[Epoch 0086] loss=17.0558 cls=0.4755 smmd=0.1219 ct=7.4691 rec=1.3223 | train/val/test=0.833/0.825/0.834 | c=0.998437
[Epoch 0087] loss=16.9271 cls=0.4696 smmd=0.1120 ct=7.4569 rec=1.3182 | train/val/test=0.843/0.840/0.843 | c=0.998437
[Epoch 0088] loss=16.9310 cls=0.4681 smmd=0.1104 ct=7.4664 rec=1.3204 | train/val/test=0.840/0.833/0.840 | c=0.998437
[Epoch 0089] loss=17.0056 cls=0.4718 smmd=0.1182 ct=7.4634 rec=1.3223 | train/val/test=0.839/0.829/0.835 | c=0.998437
[Epoch 0090] loss=17.0010 cls=0.4764 smmd=0.1164 ct=7.4684 rec=1.3247 | train/val/test=0.846/0.840/0.846 | c=0.998437
[Epoch 0091] loss=17.0324 cls=0.4777 smmd=0.1202 ct=7.4640 rec=1.3266 | train/val/test=0.835/0.824/0.833 | c=0.998437
[Epoch 0092] loss=17.0896 cls=0.4838 smmd=0.1251 ct=7.4664 rec=1.3282 | train/val/test=0.843/0.839/0.850 | c=0.998437
[Epoch 0093] loss=17.1044 cls=0.4844 smmd=0.1265 ct=7.4662 rec=1.3291 | train/val/test=0.821/0.811/0.821 | c=0.998437
[Epoch 0094] loss=17.1333 cls=0.4958 smmd=0.1312 ct=7.4534 rec=1.3322 | train/val/test=0.827/0.826/0.838 | c=0.998437
[Epoch 0095] loss=17.1390 cls=0.5040 smmd=0.1268 ct=7.4762 rec=1.3326 | train/val/test=0.800/0.795/0.798 | c=0.998437
[Epoch 0096] loss=17.2218 cls=0.5222 smmd=0.1406 ct=7.4427 rec=1.3385 | train/val/test=0.797/0.794/0.805 | c=0.998437
[Epoch 0097] loss=17.3778 cls=0.5382 smmd=0.1462 ct=7.4883 rec=1.3399 | train/val/test=0.789/0.786/0.787 | c=0.998437
[Epoch 0098] loss=17.4011 cls=0.5370 smmd=0.1575 ct=7.4441 rec=1.3398 | train/val/test=0.815/0.812/0.824 | c=0.998437
[Epoch 0099] loss=17.1683 cls=0.5143 smmd=0.1309 ct=7.4678 rec=1.3331 | train/val/test=0.823/0.819/0.825 | c=0.998437
=== Best @ epoch 77: val=0.8435, test=0.8496 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-1 completed in 143.71 seconds.
==================================================
