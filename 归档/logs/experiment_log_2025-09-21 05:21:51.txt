Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-4 - 2025-09-21 05:21:51:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-4...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.4276 cls=1.0842 smmd=5.5669 ct=7.2550 rec=1.4138 | train/val/test=0.435/0.428/0.424 | c=0.998347
[Epoch 0001] loss=51.4103 cls=1.0598 smmd=3.5761 ct=7.2059 rec=1.4159 | train/val/test=0.494/0.477/0.486 | c=0.998347
[Epoch 0002] loss=39.2134 cls=1.0855 smmd=2.3621 ct=7.1712 rec=1.4135 | train/val/test=0.502/0.494/0.488 | c=0.998347
[Epoch 0003] loss=40.5057 cls=1.0691 smmd=2.4935 ct=7.1649 rec=1.4135 | train/val/test=0.584/0.570/0.581 | c=0.998347
[Epoch 0004] loss=39.9549 cls=1.0258 smmd=2.4497 ct=7.1186 rec=1.4155 | train/val/test=0.568/0.555/0.570 | c=0.998347
[Epoch 0005] loss=36.0705 cls=0.9977 smmd=2.0803 ct=7.0300 rec=1.4182 | train/val/test=0.559/0.542/0.559 | c=0.998347
[Epoch 0006] loss=30.8892 cls=0.9704 smmd=1.5773 ct=6.9610 rec=1.4174 | train/val/test=0.556/0.536/0.555 | c=0.998347
[Epoch 0007] loss=33.5320 cls=0.9334 smmd=1.8465 ct=6.9473 rec=1.4120 | train/val/test=0.553/0.537/0.557 | c=0.998347
[Epoch 0008] loss=34.3687 cls=0.8915 smmd=1.9335 ct=6.9429 rec=1.4043 | train/val/test=0.559/0.542/0.558 | c=0.998347
[Epoch 0009] loss=28.0719 cls=0.8435 smmd=1.3134 ct=6.9095 rec=1.3938 | train/val/test=0.586/0.573/0.582 | c=0.998347
[Epoch 0010] loss=28.2032 cls=0.8032 smmd=1.2027 ct=7.5416 rec=1.3834 | train/val/test=0.641/0.631/0.636 | c=0.998347
[Epoch 0011] loss=30.5506 cls=0.7690 smmd=1.4535 ct=7.4717 rec=1.3755 | train/val/test=0.687/0.678/0.673 | c=0.998347
[Epoch 0012] loss=27.3844 cls=0.7341 smmd=1.1419 ct=7.4573 rec=1.3668 | train/val/test=0.702/0.695/0.693 | c=0.998347
[Epoch 0013] loss=26.4957 cls=0.7079 smmd=1.0467 ct=7.4965 rec=1.3627 | train/val/test=0.712/0.706/0.712 | c=0.998347
[Epoch 0014] loss=26.1569 cls=0.6849 smmd=1.0059 ct=7.5375 rec=1.3609 | train/val/test=0.729/0.730/0.718 | c=0.998347
[Epoch 0015] loss=24.9662 cls=0.6605 smmd=0.8905 ct=7.5266 rec=1.3557 | train/val/test=0.742/0.743/0.724 | c=0.998347
[Epoch 0016] loss=25.0771 cls=0.6559 smmd=0.9061 ct=7.5061 rec=1.3516 | train/val/test=0.764/0.764/0.755 | c=0.998347
[Epoch 0017] loss=23.5603 cls=0.6426 smmd=0.7579 ct=7.4942 rec=1.3432 | train/val/test=0.787/0.782/0.781 | c=0.998347
[Epoch 0018] loss=23.2961 cls=0.5951 smmd=0.7340 ct=7.4936 rec=1.3418 | train/val/test=0.793/0.787/0.784 | c=0.998347
[Epoch 0019] loss=23.0878 cls=0.5753 smmd=0.7083 ct=7.5231 rec=1.3428 | train/val/test=0.792/0.789/0.785 | c=0.998347
[Epoch 0020] loss=22.1971 cls=0.5604 smmd=0.6192 ct=7.5286 rec=1.3358 | train/val/test=0.791/0.789/0.777 | c=0.998347
[Epoch 0021] loss=21.8453 cls=0.5619 smmd=0.5876 ct=7.5117 rec=1.3300 | train/val/test=0.803/0.795/0.791 | c=0.998347
[Epoch 0022] loss=21.5208 cls=0.5565 smmd=0.5606 ct=7.4866 rec=1.3258 | train/val/test=0.816/0.814/0.807 | c=0.998347
[Epoch 0023] loss=21.1675 cls=0.5290 smmd=0.5252 ct=7.4937 rec=1.3261 | train/val/test=0.817/0.808/0.806 | c=0.998347
[Epoch 0024] loss=20.6266 cls=0.5074 smmd=0.4682 ct=7.5143 rec=1.3242 | train/val/test=0.817/0.810/0.805 | c=0.998347
[Epoch 0025] loss=20.4524 cls=0.4976 smmd=0.4536 ct=7.5040 rec=1.3196 | train/val/test=0.821/0.810/0.807 | c=0.998347
[Epoch 0026] loss=20.1745 cls=0.4939 smmd=0.4271 ct=7.4993 rec=1.3149 | train/val/test=0.825/0.813/0.809 | c=0.998347
[Epoch 0027] loss=19.7941 cls=0.4862 smmd=0.3911 ct=7.4914 rec=1.3140 | train/val/test=0.828/0.821/0.818 | c=0.998347
[Epoch 0028] loss=19.7259 cls=0.4794 smmd=0.3867 ct=7.4802 rec=1.3184 | train/val/test=0.829/0.817/0.815 | c=0.998347
[Epoch 0029] loss=19.3178 cls=0.4674 smmd=0.3415 ct=7.5056 rec=1.3152 | train/val/test=0.829/0.818/0.815 | c=0.998347
[Epoch 0030] loss=19.2121 cls=0.4649 smmd=0.3315 ct=7.5040 rec=1.3134 | train/val/test=0.838/0.827/0.823 | c=0.998347
[Epoch 0031] loss=19.0379 cls=0.4623 smmd=0.3198 ct=7.4763 rec=1.3130 | train/val/test=0.837/0.829/0.824 | c=0.998347
[Epoch 0032] loss=18.8711 cls=0.4572 smmd=0.3010 ct=7.4881 rec=1.3122 | train/val/test=0.840/0.830/0.826 | c=0.998347
[Epoch 0033] loss=18.6893 cls=0.4526 smmd=0.2830 ct=7.4878 rec=1.3146 | train/val/test=0.839/0.830/0.826 | c=0.998347
[Epoch 0034] loss=18.4558 cls=0.4507 smmd=0.2594 ct=7.4898 rec=1.3130 | train/val/test=0.837/0.832/0.824 | c=0.998347
[Epoch 0035] loss=18.4701 cls=0.4533 smmd=0.2619 ct=7.4847 rec=1.3109 | train/val/test=0.844/0.838/0.833 | c=0.998347
[Epoch 0036] loss=18.1468 cls=0.4512 smmd=0.2317 ct=7.4740 rec=1.3132 | train/val/test=0.837/0.830/0.825 | c=0.998347
[Epoch 0037] loss=18.1523 cls=0.4493 smmd=0.2296 ct=7.4875 rec=1.3132 | train/val/test=0.844/0.838/0.832 | c=0.998347
[Epoch 0038] loss=17.9301 cls=0.4487 smmd=0.2103 ct=7.4731 rec=1.3140 | train/val/test=0.841/0.836/0.830 | c=0.998347
[Epoch 0039] loss=17.9162 cls=0.4500 smmd=0.2082 ct=7.4764 rec=1.3129 | train/val/test=0.835/0.831/0.819 | c=0.998347
[Epoch 0040] loss=17.7592 cls=0.4539 smmd=0.1904 ct=7.4858 rec=1.3129 | train/val/test=0.846/0.840/0.832 | c=0.998347
[Epoch 0041] loss=17.7270 cls=0.4510 smmd=0.1909 ct=7.4675 rec=1.3158 | train/val/test=0.839/0.834/0.822 | c=0.998347
[Epoch 0042] loss=17.5688 cls=0.4513 smmd=0.1738 ct=7.4734 rec=1.3158 | train/val/test=0.842/0.838/0.829 | c=0.998347
[Epoch 0043] loss=17.5583 cls=0.4523 smmd=0.1730 ct=7.4723 rec=1.3153 | train/val/test=0.839/0.837/0.822 | c=0.998347
[Epoch 0044] loss=17.4318 cls=0.4544 smmd=0.1604 ct=7.4717 rec=1.3153 | train/val/test=0.842/0.836/0.827 | c=0.998347
[Epoch 0045] loss=17.4397 cls=0.4522 smmd=0.1612 ct=7.4715 rec=1.3177 | train/val/test=0.844/0.841/0.828 | c=0.998347
[Epoch 0046] loss=17.2961 cls=0.4529 smmd=0.1481 ct=7.4650 rec=1.3180 | train/val/test=0.840/0.837/0.825 | c=0.998347
[Epoch 0047] loss=17.2785 cls=0.4551 smmd=0.1466 ct=7.4631 rec=1.3177 | train/val/test=0.843/0.838/0.828 | c=0.998347
[Epoch 0048] loss=17.2381 cls=0.4537 smmd=0.1416 ct=7.4679 rec=1.3193 | train/val/test=0.840/0.834/0.824 | c=0.998347
[Epoch 0049] loss=17.2347 cls=0.4566 smmd=0.1420 ct=7.4633 rec=1.3189 | train/val/test=0.846/0.839/0.835 | c=0.998347
[Epoch 0050] loss=17.1863 cls=0.4555 smmd=0.1384 ct=7.4570 rec=1.3218 | train/val/test=0.840/0.833/0.822 | c=0.998347
[Epoch 0051] loss=17.1245 cls=0.4589 smmd=0.1310 ct=7.4623 rec=1.3202 | train/val/test=0.847/0.839/0.835 | c=0.998347
[Epoch 0052] loss=17.1079 cls=0.4583 smmd=0.1308 ct=7.4548 rec=1.3229 | train/val/test=0.841/0.834/0.822 | c=0.998347
[Epoch 0053] loss=17.1101 cls=0.4609 smmd=0.1291 ct=7.4638 rec=1.3222 | train/val/test=0.847/0.840/0.836 | c=0.998347
[Epoch 0054] loss=17.0561 cls=0.4615 smmd=0.1274 ct=7.4448 rec=1.3237 | train/val/test=0.839/0.831/0.823 | c=0.998347
[Epoch 0055] loss=17.0666 cls=0.4620 smmd=0.1254 ct=7.4598 rec=1.3235 | train/val/test=0.846/0.840/0.836 | c=0.998347
[Epoch 0056] loss=17.0787 cls=0.4631 smmd=0.1283 ct=7.4510 rec=1.3241 | train/val/test=0.840/0.831/0.824 | c=0.998347
[Epoch 0057] loss=17.0649 cls=0.4637 smmd=0.1275 ct=7.4479 rec=1.3239 | train/val/test=0.846/0.840/0.836 | c=0.998347
[Epoch 0058] loss=17.0332 cls=0.4628 smmd=0.1250 ct=7.4447 rec=1.3242 | train/val/test=0.839/0.832/0.823 | c=0.998347
[Epoch 0059] loss=17.0017 cls=0.4638 smmd=0.1212 ct=7.4478 rec=1.3241 | train/val/test=0.846/0.840/0.836 | c=0.998347
[Epoch 0060] loss=16.9342 cls=0.4624 smmd=0.1162 ct=7.4395 rec=1.3241 | train/val/test=0.839/0.832/0.821 | c=0.998347
[Epoch 0061] loss=16.9794 cls=0.4643 smmd=0.1189 ct=7.4482 rec=1.3242 | train/val/test=0.846/0.840/0.837 | c=0.998347
[Epoch 0062] loss=17.0423 cls=0.4638 smmd=0.1290 ct=7.4287 rec=1.3251 | train/val/test=0.835/0.824/0.816 | c=0.998347
[Epoch 0063] loss=17.0430 cls=0.4703 smmd=0.1249 ct=7.4479 rec=1.3256 | train/val/test=0.846/0.841/0.835 | c=0.998347
[Epoch 0064] loss=17.0801 cls=0.4671 smmd=0.1309 ct=7.4370 rec=1.3276 | train/val/test=0.831/0.819/0.811 | c=0.998347
[Epoch 0065] loss=17.0933 cls=0.4757 smmd=0.1305 ct=7.4438 rec=1.3261 | train/val/test=0.843/0.837/0.831 | c=0.998347
[Epoch 0066] loss=17.1334 cls=0.4744 smmd=0.1370 ct=7.4303 rec=1.3302 | train/val/test=0.818/0.811/0.797 | c=0.998347
[Epoch 0067] loss=17.2118 cls=0.4932 smmd=0.1394 ct=7.4532 rec=1.3301 | train/val/test=0.830/0.827/0.821 | c=0.998347
[Epoch 0068] loss=17.2369 cls=0.4932 smmd=0.1473 ct=7.4246 rec=1.3353 | train/val/test=0.812/0.807/0.790 | c=0.998347
[Epoch 0069] loss=17.2446 cls=0.5034 smmd=0.1408 ct=7.4596 rec=1.3314 | train/val/test=0.835/0.831/0.826 | c=0.998347
[Epoch 0070] loss=17.1177 cls=0.4805 smmd=0.1381 ct=7.4162 rec=1.3283 | train/val/test=0.829/0.817/0.808 | c=0.998347
[Epoch 0071] loss=17.0496 cls=0.4692 smmd=0.1281 ct=7.4366 rec=1.3216 | train/val/test=0.845/0.839/0.832 | c=0.998347
[Epoch 0072] loss=16.9681 cls=0.4551 smmd=0.1235 ct=7.4233 rec=1.3188 | train/val/test=0.842/0.838/0.828 | c=0.998347
[Epoch 0073] loss=16.8721 cls=0.4560 smmd=0.1143 ct=7.4208 rec=1.3190 | train/val/test=0.843/0.838/0.826 | c=0.998347
[Epoch 0074] loss=16.8774 cls=0.4586 smmd=0.1133 ct=7.4272 rec=1.3219 | train/val/test=0.844/0.837/0.830 | c=0.998347
[Epoch 0075] loss=16.9608 cls=0.4641 smmd=0.1213 ct=7.4267 rec=1.3240 | train/val/test=0.843/0.835/0.827 | c=0.998347
[Epoch 0076] loss=16.9562 cls=0.4685 smmd=0.1196 ct=7.4308 rec=1.3282 | train/val/test=0.847/0.840/0.833 | c=0.998347
[Epoch 0077] loss=16.9634 cls=0.4708 smmd=0.1216 ct=7.4239 rec=1.3285 | train/val/test=0.838/0.830/0.824 | c=0.998347
[Epoch 0078] loss=17.0252 cls=0.4750 smmd=0.1248 ct=7.4368 rec=1.3314 | train/val/test=0.846/0.839/0.837 | c=0.998347
[Epoch 0079] loss=17.0688 cls=0.4740 smmd=0.1328 ct=7.4195 rec=1.3294 | train/val/test=0.834/0.825/0.819 | c=0.998347
[Epoch 0080] loss=16.9963 cls=0.4730 smmd=0.1223 ct=7.4356 rec=1.3305 | train/val/test=0.845/0.840/0.835 | c=0.998347
[Epoch 0081] loss=16.9829 cls=0.4722 smmd=0.1260 ct=7.4118 rec=1.3273 | train/val/test=0.832/0.821/0.812 | c=0.998347
[Epoch 0082] loss=16.9947 cls=0.4695 smmd=0.1229 ct=7.4340 rec=1.3266 | train/val/test=0.842/0.836/0.830 | c=0.998347
[Epoch 0083] loss=16.9302 cls=0.4726 smmd=0.1215 ct=7.4079 rec=1.3265 | train/val/test=0.831/0.818/0.812 | c=0.998347
[Epoch 0084] loss=16.9248 cls=0.4700 smmd=0.1164 ct=7.4319 rec=1.3247 | train/val/test=0.842/0.838/0.831 | c=0.998347
[Epoch 0085] loss=16.9436 cls=0.4717 smmd=0.1218 ct=7.4129 rec=1.3273 | train/val/test=0.831/0.818/0.812 | c=0.998347
[Epoch 0086] loss=16.9852 cls=0.4735 smmd=0.1226 ct=7.4298 rec=1.3253 | train/val/test=0.842/0.838/0.829 | c=0.998347
[Epoch 0087] loss=17.0066 cls=0.4774 smmd=0.1262 ct=7.4199 rec=1.3313 | train/val/test=0.823/0.815/0.803 | c=0.998347
[Epoch 0088] loss=17.0722 cls=0.4895 smmd=0.1285 ct=7.4386 rec=1.3311 | train/val/test=0.831/0.829/0.821 | c=0.998347
[Epoch 0089] loss=17.2063 cls=0.4963 smmd=0.1444 ct=7.4224 rec=1.3384 | train/val/test=0.805/0.802/0.783 | c=0.998347
[Epoch 0090] loss=17.3706 cls=0.5222 smmd=0.1525 ct=7.4573 rec=1.3398 | train/val/test=0.811/0.813/0.803 | c=0.998347
[Epoch 0091] loss=17.4104 cls=0.5170 smmd=0.1633 ct=7.4237 rec=1.3437 | train/val/test=0.802/0.799/0.779 | c=0.998347
[Epoch 0092] loss=17.3682 cls=0.5246 smmd=0.1523 ct=7.4574 rec=1.3360 | train/val/test=0.833/0.824/0.822 | c=0.998347
[Epoch 0093] loss=17.1495 cls=0.4820 smmd=0.1423 ct=7.4111 rec=1.3275 | train/val/test=0.830/0.823/0.811 | c=0.998347
[Epoch 0094] loss=16.8898 cls=0.4615 smmd=0.1160 ct=7.4205 rec=1.3163 | train/val/test=0.839/0.835/0.826 | c=0.998347
[Epoch 0095] loss=16.7893 cls=0.4526 smmd=0.1082 ct=7.4123 rec=1.3139 | train/val/test=0.843/0.837/0.830 | c=0.998347
[Epoch 0096] loss=16.8239 cls=0.4588 smmd=0.1125 ct=7.4051 rec=1.3195 | train/val/test=0.825/0.816/0.804 | c=0.998347
[Epoch 0097] loss=16.9035 cls=0.4858 smmd=0.1131 ct=7.4331 rec=1.3274 | train/val/test=0.841/0.839/0.833 | c=0.998347
[Epoch 0098] loss=17.0144 cls=0.4823 smmd=0.1291 ct=7.4081 rec=1.3313 | train/val/test=0.821/0.812/0.799 | c=0.998347
[Epoch 0099] loss=17.1432 cls=0.5066 smmd=0.1327 ct=7.4464 rec=1.3391 | train/val/test=0.840/0.839/0.831 | c=0.998347
=== Best @ epoch 45: val=0.8410, test=0.8283 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-4 - 2025-09-21 05:21:51:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-4...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.4276 cls=1.0842 smmd=5.5669 ct=7.2550 rec=1.4138 | train/val/test=0.435/0.428/0.424 | c=0.998347
[Epoch 0001] loss=51.4103 cls=1.0598 smmd=3.5761 ct=7.2059 rec=1.4159 | train/val/test=0.494/0.477/0.486 | c=0.998347
[Epoch 0002] loss=39.2134 cls=1.0855 smmd=2.3621 ct=7.1712 rec=1.4135 | train/val/test=0.502/0.494/0.488 | c=0.998347
[Epoch 0003] loss=40.5057 cls=1.0691 smmd=2.4935 ct=7.1649 rec=1.4135 | train/val/test=0.584/0.570/0.581 | c=0.998347
[Epoch 0004] loss=39.9549 cls=1.0258 smmd=2.4497 ct=7.1186 rec=1.4155 | train/val/test=0.568/0.555/0.570 | c=0.998347
[Epoch 0005] loss=36.0705 cls=0.9977 smmd=2.0803 ct=7.0300 rec=1.4182 | train/val/test=0.559/0.542/0.559 | c=0.998347
[Epoch 0006] loss=30.8892 cls=0.9704 smmd=1.5773 ct=6.9610 rec=1.4174 | train/val/test=0.556/0.536/0.555 | c=0.998347
[Epoch 0007] loss=33.5320 cls=0.9334 smmd=1.8465 ct=6.9473 rec=1.4120 | train/val/test=0.553/0.537/0.557 | c=0.998347
[Epoch 0008] loss=34.3687 cls=0.8915 smmd=1.9335 ct=6.9429 rec=1.4043 | train/val/test=0.559/0.542/0.558 | c=0.998347
[Epoch 0009] loss=28.0719 cls=0.8435 smmd=1.3134 ct=6.9095 rec=1.3938 | train/val/test=0.586/0.573/0.582 | c=0.998347
[Epoch 0010] loss=28.2032 cls=0.8032 smmd=1.2027 ct=7.5416 rec=1.3834 | train/val/test=0.641/0.631/0.636 | c=0.998347
[Epoch 0011] loss=30.5506 cls=0.7690 smmd=1.4535 ct=7.4717 rec=1.3755 | train/val/test=0.687/0.678/0.673 | c=0.998347
[Epoch 0012] loss=27.3844 cls=0.7341 smmd=1.1419 ct=7.4573 rec=1.3668 | train/val/test=0.702/0.695/0.693 | c=0.998347
[Epoch 0013] loss=26.4957 cls=0.7079 smmd=1.0467 ct=7.4965 rec=1.3627 | train/val/test=0.712/0.706/0.712 | c=0.998347
[Epoch 0014] loss=26.1569 cls=0.6849 smmd=1.0059 ct=7.5375 rec=1.3609 | train/val/test=0.729/0.730/0.718 | c=0.998347
[Epoch 0015] loss=24.9662 cls=0.6605 smmd=0.8905 ct=7.5266 rec=1.3557 | train/val/test=0.742/0.743/0.724 | c=0.998347
[Epoch 0016] loss=25.0771 cls=0.6559 smmd=0.9061 ct=7.5061 rec=1.3516 | train/val/test=0.764/0.764/0.755 | c=0.998347
[Epoch 0017] loss=23.5603 cls=0.6426 smmd=0.7579 ct=7.4942 rec=1.3432 | train/val/test=0.787/0.782/0.781 | c=0.998347
[Epoch 0018] loss=23.2961 cls=0.5951 smmd=0.7340 ct=7.4936 rec=1.3418 | train/val/test=0.793/0.787/0.784 | c=0.998347
[Epoch 0019] loss=23.0878 cls=0.5753 smmd=0.7083 ct=7.5231 rec=1.3428 | train/val/test=0.792/0.789/0.785 | c=0.998347
[Epoch 0020] loss=22.1971 cls=0.5604 smmd=0.6192 ct=7.5286 rec=1.3358 | train/val/test=0.791/0.789/0.777 | c=0.998347
[Epoch 0021] loss=21.8453 cls=0.5619 smmd=0.5876 ct=7.5117 rec=1.3300 | train/val/test=0.803/0.795/0.791 | c=0.998347
[Epoch 0022] loss=21.5208 cls=0.5565 smmd=0.5606 ct=7.4866 rec=1.3258 | train/val/test=0.816/0.814/0.807 | c=0.998347
[Epoch 0023] loss=21.1675 cls=0.5290 smmd=0.5252 ct=7.4937 rec=1.3261 | train/val/test=0.817/0.808/0.806 | c=0.998347
[Epoch 0024] loss=20.6266 cls=0.5074 smmd=0.4682 ct=7.5143 rec=1.3242 | train/val/test=0.817/0.810/0.805 | c=0.998347
[Epoch 0025] loss=20.4524 cls=0.4976 smmd=0.4536 ct=7.5040 rec=1.3196 | train/val/test=0.821/0.810/0.807 | c=0.998347
[Epoch 0026] loss=20.1745 cls=0.4939 smmd=0.4271 ct=7.4993 rec=1.3149 | train/val/test=0.825/0.813/0.809 | c=0.998347
[Epoch 0027] loss=19.7941 cls=0.4862 smmd=0.3911 ct=7.4914 rec=1.3140 | train/val/test=0.828/0.821/0.818 | c=0.998347
[Epoch 0028] loss=19.7259 cls=0.4794 smmd=0.3867 ct=7.4802 rec=1.3184 | train/val/test=0.829/0.817/0.815 | c=0.998347
[Epoch 0029] loss=19.3178 cls=0.4674 smmd=0.3415 ct=7.5056 rec=1.3152 | train/val/test=0.829/0.818/0.815 | c=0.998347
[Epoch 0030] loss=19.2121 cls=0.4649 smmd=0.3315 ct=7.5040 rec=1.3134 | train/val/test=0.838/0.827/0.823 | c=0.998347
[Epoch 0031] loss=19.0379 cls=0.4623 smmd=0.3198 ct=7.4763 rec=1.3130 | train/val/test=0.837/0.829/0.824 | c=0.998347
[Epoch 0032] loss=18.8711 cls=0.4572 smmd=0.3010 ct=7.4881 rec=1.3122 | train/val/test=0.840/0.830/0.826 | c=0.998347
[Epoch 0033] loss=18.6893 cls=0.4526 smmd=0.2830 ct=7.4878 rec=1.3146 | train/val/test=0.839/0.830/0.826 | c=0.998347
[Epoch 0034] loss=18.4558 cls=0.4507 smmd=0.2594 ct=7.4898 rec=1.3130 | train/val/test=0.837/0.832/0.824 | c=0.998347
[Epoch 0035] loss=18.4701 cls=0.4533 smmd=0.2619 ct=7.4847 rec=1.3109 | train/val/test=0.844/0.838/0.833 | c=0.998347
[Epoch 0036] loss=18.1468 cls=0.4512 smmd=0.2317 ct=7.4740 rec=1.3132 | train/val/test=0.837/0.830/0.825 | c=0.998347
[Epoch 0037] loss=18.1523 cls=0.4493 smmd=0.2296 ct=7.4875 rec=1.3132 | train/val/test=0.844/0.838/0.832 | c=0.998347
[Epoch 0038] loss=17.9301 cls=0.4487 smmd=0.2103 ct=7.4731 rec=1.3140 | train/val/test=0.841/0.836/0.830 | c=0.998347
[Epoch 0039] loss=17.9162 cls=0.4500 smmd=0.2082 ct=7.4764 rec=1.3129 | train/val/test=0.835/0.831/0.819 | c=0.998347
[Epoch 0040] loss=17.7592 cls=0.4539 smmd=0.1904 ct=7.4858 rec=1.3129 | train/val/test=0.846/0.840/0.832 | c=0.998347
[Epoch 0041] loss=17.7270 cls=0.4510 smmd=0.1909 ct=7.4675 rec=1.3158 | train/val/test=0.839/0.834/0.822 | c=0.998347
[Epoch 0042] loss=17.5688 cls=0.4513 smmd=0.1738 ct=7.4734 rec=1.3158 | train/val/test=0.842/0.838/0.829 | c=0.998347
[Epoch 0043] loss=17.5583 cls=0.4523 smmd=0.1730 ct=7.4723 rec=1.3153 | train/val/test=0.839/0.837/0.822 | c=0.998347
[Epoch 0044] loss=17.4318 cls=0.4544 smmd=0.1604 ct=7.4717 rec=1.3153 | train/val/test=0.842/0.836/0.827 | c=0.998347
[Epoch 0045] loss=17.4397 cls=0.4522 smmd=0.1612 ct=7.4715 rec=1.3177 | train/val/test=0.844/0.841/0.828 | c=0.998347
[Epoch 0046] loss=17.2961 cls=0.4529 smmd=0.1481 ct=7.4650 rec=1.3180 | train/val/test=0.840/0.837/0.825 | c=0.998347
[Epoch 0047] loss=17.2785 cls=0.4551 smmd=0.1466 ct=7.4631 rec=1.3177 | train/val/test=0.843/0.838/0.828 | c=0.998347
[Epoch 0048] loss=17.2381 cls=0.4537 smmd=0.1416 ct=7.4679 rec=1.3193 | train/val/test=0.840/0.834/0.824 | c=0.998347
[Epoch 0049] loss=17.2347 cls=0.4566 smmd=0.1420 ct=7.4633 rec=1.3189 | train/val/test=0.846/0.839/0.835 | c=0.998347
[Epoch 0050] loss=17.1863 cls=0.4555 smmd=0.1384 ct=7.4570 rec=1.3218 | train/val/test=0.840/0.833/0.822 | c=0.998347
[Epoch 0051] loss=17.1245 cls=0.4589 smmd=0.1310 ct=7.4623 rec=1.3202 | train/val/test=0.847/0.839/0.835 | c=0.998347
[Epoch 0052] loss=17.1079 cls=0.4583 smmd=0.1308 ct=7.4548 rec=1.3229 | train/val/test=0.841/0.834/0.822 | c=0.998347
[Epoch 0053] loss=17.1101 cls=0.4609 smmd=0.1291 ct=7.4638 rec=1.3222 | train/val/test=0.847/0.840/0.836 | c=0.998347
[Epoch 0054] loss=17.0561 cls=0.4615 smmd=0.1274 ct=7.4448 rec=1.3237 | train/val/test=0.839/0.831/0.823 | c=0.998347
[Epoch 0055] loss=17.0666 cls=0.4620 smmd=0.1254 ct=7.4598 rec=1.3235 | train/val/test=0.846/0.840/0.836 | c=0.998347
[Epoch 0056] loss=17.0787 cls=0.4631 smmd=0.1283 ct=7.4510 rec=1.3241 | train/val/test=0.840/0.831/0.824 | c=0.998347
[Epoch 0057] loss=17.0649 cls=0.4637 smmd=0.1275 ct=7.4479 rec=1.3239 | train/val/test=0.846/0.840/0.836 | c=0.998347
[Epoch 0058] loss=17.0332 cls=0.4628 smmd=0.1250 ct=7.4447 rec=1.3242 | train/val/test=0.839/0.832/0.823 | c=0.998347
[Epoch 0059] loss=17.0017 cls=0.4638 smmd=0.1212 ct=7.4478 rec=1.3241 | train/val/test=0.846/0.840/0.836 | c=0.998347
[Epoch 0060] loss=16.9342 cls=0.4624 smmd=0.1162 ct=7.4395 rec=1.3241 | train/val/test=0.839/0.832/0.821 | c=0.998347
[Epoch 0061] loss=16.9794 cls=0.4643 smmd=0.1189 ct=7.4482 rec=1.3242 | train/val/test=0.846/0.840/0.837 | c=0.998347
[Epoch 0062] loss=17.0423 cls=0.4638 smmd=0.1290 ct=7.4287 rec=1.3251 | train/val/test=0.835/0.824/0.816 | c=0.998347
[Epoch 0063] loss=17.0430 cls=0.4703 smmd=0.1249 ct=7.4479 rec=1.3256 | train/val/test=0.846/0.841/0.835 | c=0.998347
[Epoch 0064] loss=17.0801 cls=0.4671 smmd=0.1309 ct=7.4370 rec=1.3276 | train/val/test=0.831/0.819/0.811 | c=0.998347
[Epoch 0065] loss=17.0933 cls=0.4757 smmd=0.1305 ct=7.4438 rec=1.3261 | train/val/test=0.843/0.837/0.831 | c=0.998347
[Epoch 0066] loss=17.1334 cls=0.4744 smmd=0.1370 ct=7.4303 rec=1.3302 | train/val/test=0.818/0.811/0.797 | c=0.998347
[Epoch 0067] loss=17.2118 cls=0.4932 smmd=0.1394 ct=7.4532 rec=1.3301 | train/val/test=0.830/0.827/0.821 | c=0.998347
[Epoch 0068] loss=17.2369 cls=0.4932 smmd=0.1473 ct=7.4246 rec=1.3353 | train/val/test=0.812/0.807/0.790 | c=0.998347
[Epoch 0069] loss=17.2446 cls=0.5034 smmd=0.1408 ct=7.4596 rec=1.3314 | train/val/test=0.835/0.831/0.826 | c=0.998347
[Epoch 0070] loss=17.1177 cls=0.4805 smmd=0.1381 ct=7.4162 rec=1.3283 | train/val/test=0.829/0.817/0.808 | c=0.998347
[Epoch 0071] loss=17.0496 cls=0.4692 smmd=0.1281 ct=7.4366 rec=1.3216 | train/val/test=0.845/0.839/0.832 | c=0.998347
[Epoch 0072] loss=16.9681 cls=0.4551 smmd=0.1235 ct=7.4233 rec=1.3188 | train/val/test=0.842/0.838/0.828 | c=0.998347
[Epoch 0073] loss=16.8721 cls=0.4560 smmd=0.1143 ct=7.4208 rec=1.3190 | train/val/test=0.843/0.838/0.826 | c=0.998347
[Epoch 0074] loss=16.8774 cls=0.4586 smmd=0.1133 ct=7.4272 rec=1.3219 | train/val/test=0.844/0.837/0.830 | c=0.998347
[Epoch 0075] loss=16.9608 cls=0.4641 smmd=0.1213 ct=7.4267 rec=1.3240 | train/val/test=0.843/0.835/0.827 | c=0.998347
[Epoch 0076] loss=16.9562 cls=0.4685 smmd=0.1196 ct=7.4308 rec=1.3282 | train/val/test=0.847/0.840/0.833 | c=0.998347
[Epoch 0077] loss=16.9634 cls=0.4708 smmd=0.1216 ct=7.4239 rec=1.3285 | train/val/test=0.838/0.830/0.824 | c=0.998347
[Epoch 0078] loss=17.0252 cls=0.4750 smmd=0.1248 ct=7.4368 rec=1.3314 | train/val/test=0.846/0.839/0.837 | c=0.998347
[Epoch 0079] loss=17.0688 cls=0.4740 smmd=0.1328 ct=7.4195 rec=1.3294 | train/val/test=0.834/0.825/0.819 | c=0.998347
[Epoch 0080] loss=16.9963 cls=0.4730 smmd=0.1223 ct=7.4356 rec=1.3305 | train/val/test=0.845/0.840/0.835 | c=0.998347
[Epoch 0081] loss=16.9829 cls=0.4722 smmd=0.1260 ct=7.4118 rec=1.3273 | train/val/test=0.832/0.821/0.812 | c=0.998347
[Epoch 0082] loss=16.9947 cls=0.4695 smmd=0.1229 ct=7.4340 rec=1.3266 | train/val/test=0.842/0.836/0.830 | c=0.998347
[Epoch 0083] loss=16.9302 cls=0.4726 smmd=0.1215 ct=7.4079 rec=1.3265 | train/val/test=0.831/0.818/0.812 | c=0.998347
[Epoch 0084] loss=16.9248 cls=0.4700 smmd=0.1164 ct=7.4319 rec=1.3247 | train/val/test=0.842/0.838/0.831 | c=0.998347
[Epoch 0085] loss=16.9436 cls=0.4717 smmd=0.1218 ct=7.4129 rec=1.3273 | train/val/test=0.831/0.818/0.812 | c=0.998347
[Epoch 0086] loss=16.9852 cls=0.4735 smmd=0.1226 ct=7.4298 rec=1.3253 | train/val/test=0.842/0.838/0.829 | c=0.998347
[Epoch 0087] loss=17.0066 cls=0.4774 smmd=0.1262 ct=7.4199 rec=1.3313 | train/val/test=0.823/0.815/0.803 | c=0.998347
[Epoch 0088] loss=17.0722 cls=0.4895 smmd=0.1285 ct=7.4386 rec=1.3311 | train/val/test=0.831/0.829/0.821 | c=0.998347
[Epoch 0089] loss=17.2063 cls=0.4963 smmd=0.1444 ct=7.4224 rec=1.3384 | train/val/test=0.805/0.802/0.783 | c=0.998347
[Epoch 0090] loss=17.3706 cls=0.5222 smmd=0.1525 ct=7.4573 rec=1.3398 | train/val/test=0.811/0.813/0.803 | c=0.998347
[Epoch 0091] loss=17.4104 cls=0.5170 smmd=0.1633 ct=7.4237 rec=1.3437 | train/val/test=0.802/0.799/0.779 | c=0.998347
[Epoch 0092] loss=17.3682 cls=0.5246 smmd=0.1523 ct=7.4574 rec=1.3360 | train/val/test=0.833/0.824/0.822 | c=0.998347
[Epoch 0093] loss=17.1495 cls=0.4820 smmd=0.1423 ct=7.4111 rec=1.3275 | train/val/test=0.830/0.823/0.811 | c=0.998347
[Epoch 0094] loss=16.8898 cls=0.4615 smmd=0.1160 ct=7.4205 rec=1.3163 | train/val/test=0.839/0.835/0.826 | c=0.998347
[Epoch 0095] loss=16.7893 cls=0.4526 smmd=0.1082 ct=7.4123 rec=1.3139 | train/val/test=0.843/0.837/0.830 | c=0.998347
[Epoch 0096] loss=16.8239 cls=0.4588 smmd=0.1125 ct=7.4051 rec=1.3195 | train/val/test=0.825/0.816/0.804 | c=0.998347
[Epoch 0097] loss=16.9035 cls=0.4858 smmd=0.1131 ct=7.4331 rec=1.3274 | train/val/test=0.841/0.839/0.833 | c=0.998347
[Epoch 0098] loss=17.0144 cls=0.4823 smmd=0.1291 ct=7.4081 rec=1.3313 | train/val/test=0.821/0.812/0.799 | c=0.998347
[Epoch 0099] loss=17.1432 cls=0.5066 smmd=0.1327 ct=7.4464 rec=1.3391 | train/val/test=0.840/0.839/0.831 | c=0.998347
=== Best @ epoch 45: val=0.8410, test=0.8283 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-4 completed in 190.70 seconds.
==================================================
