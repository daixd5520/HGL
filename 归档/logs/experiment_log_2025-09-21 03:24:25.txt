Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-4 - 2025-09-21 03:24:25:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-4...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.5365 cls=1.1110 smmd=5.5765 ct=7.2546 rec=1.4137 | train/val/test=0.393/0.398/0.387 | c=0.998437
[Epoch 0001] loss=51.8572 cls=1.0674 smmd=3.6207 ct=7.2044 rec=1.4150 | train/val/test=0.393/0.398/0.387 | c=0.998437
[Epoch 0002] loss=37.9352 cls=1.0792 smmd=2.2448 ct=7.1202 rec=1.4137 | train/val/test=0.499/0.499/0.501 | c=0.998437
[Epoch 0003] loss=40.1061 cls=1.0880 smmd=2.4681 ct=7.0873 rec=1.4135 | train/val/test=0.506/0.504/0.508 | c=0.998437
[Epoch 0004] loss=39.8682 cls=1.0321 smmd=2.4604 ct=7.0208 rec=1.4142 | train/val/test=0.533/0.531/0.539 | c=0.998437
[Epoch 0005] loss=35.6731 cls=0.9893 smmd=2.0536 ct=6.9671 rec=1.4164 | train/val/test=0.540/0.532/0.549 | c=0.998437
[Epoch 0006] loss=30.1575 cls=0.9540 smmd=1.5101 ct=6.9357 rec=1.4162 | train/val/test=0.538/0.533/0.549 | c=0.998437
[Epoch 0007] loss=33.0160 cls=0.9105 smmd=1.7975 ct=6.9400 rec=1.4116 | train/val/test=0.559/0.554/0.570 | c=0.998437
[Epoch 0008] loss=35.2330 cls=0.8644 smmd=1.9142 ct=7.4784 rec=1.4045 | train/val/test=0.636/0.634/0.650 | c=0.998437
[Epoch 0009] loss=29.4540 cls=0.8238 smmd=1.3469 ct=7.4374 rec=1.3960 | train/val/test=0.663/0.653/0.677 | c=0.998437
[Epoch 0010] loss=27.2742 cls=0.7951 smmd=1.1235 ct=7.4734 rec=1.3894 | train/val/test=0.688/0.678/0.695 | c=0.998437
[Epoch 0011] loss=30.1214 cls=0.7704 smmd=1.4002 ct=7.5208 rec=1.3855 | train/val/test=0.700/0.687/0.708 | c=0.998437
[Epoch 0012] loss=27.3159 cls=0.7485 smmd=1.1259 ct=7.4959 rec=1.3817 | train/val/test=0.689/0.678/0.698 | c=0.998437
[Epoch 0013] loss=26.1257 cls=0.7321 smmd=1.0157 ct=7.4577 rec=1.3742 | train/val/test=0.697/0.686/0.706 | c=0.998437
[Epoch 0014] loss=25.6737 cls=0.7099 smmd=0.9681 ct=7.4759 rec=1.3709 | train/val/test=0.709/0.699/0.713 | c=0.998437
[Epoch 0015] loss=24.8817 cls=0.6950 smmd=0.8910 ct=7.4693 rec=1.3708 | train/val/test=0.721/0.710/0.728 | c=0.998437
[Epoch 0016] loss=24.7685 cls=0.6763 smmd=0.8800 ct=7.4753 rec=1.3591 | train/val/test=0.728/0.711/0.729 | c=0.998437
[Epoch 0017] loss=23.2518 cls=0.6726 smmd=0.7294 ct=7.4733 rec=1.3495 | train/val/test=0.743/0.729/0.748 | c=0.998437
[Epoch 0018] loss=22.9697 cls=0.6339 smmd=0.7052 ct=7.4636 rec=1.3461 | train/val/test=0.756/0.746/0.764 | c=0.998437
[Epoch 0019] loss=22.5257 cls=0.6116 smmd=0.6585 ct=7.4816 rec=1.3435 | train/val/test=0.770/0.759/0.778 | c=0.998437
[Epoch 0020] loss=22.0619 cls=0.5916 smmd=0.6185 ct=7.4564 rec=1.3367 | train/val/test=0.775/0.768/0.782 | c=0.998437
[Epoch 0021] loss=21.5058 cls=0.5808 smmd=0.5653 ct=7.4485 rec=1.3314 | train/val/test=0.788/0.780/0.793 | c=0.998437
[Epoch 0022] loss=21.2669 cls=0.5679 smmd=0.5426 ct=7.4468 rec=1.3276 | train/val/test=0.802/0.793/0.808 | c=0.998437
[Epoch 0023] loss=20.7917 cls=0.5412 smmd=0.4939 ct=7.4594 rec=1.3264 | train/val/test=0.809/0.800/0.814 | c=0.998437
[Epoch 0024] loss=20.3454 cls=0.5240 smmd=0.4526 ct=7.4473 rec=1.3257 | train/val/test=0.816/0.806/0.820 | c=0.998437
[Epoch 0025] loss=20.2536 cls=0.5109 smmd=0.4444 ct=7.4456 rec=1.3254 | train/val/test=0.816/0.811/0.820 | c=0.998437
[Epoch 0026] loss=19.7027 cls=0.5034 smmd=0.3891 ct=7.4491 rec=1.3243 | train/val/test=0.818/0.809/0.819 | c=0.998437
[Epoch 0027] loss=19.8309 cls=0.5093 smmd=0.4027 ct=7.4446 rec=1.3208 | train/val/test=0.824/0.819/0.828 | c=0.998437
[Epoch 0028] loss=19.3246 cls=0.4875 smmd=0.3549 ct=7.4350 rec=1.3228 | train/val/test=0.829/0.820/0.831 | c=0.998437
[Epoch 0029] loss=19.1483 cls=0.4829 smmd=0.3362 ct=7.4417 rec=1.3230 | train/val/test=0.828/0.820/0.831 | c=0.998437
[Epoch 0030] loss=19.0716 cls=0.4799 smmd=0.3283 ct=7.4445 rec=1.3189 | train/val/test=0.828/0.817/0.828 | c=0.998437
[Epoch 0031] loss=18.7442 cls=0.4760 smmd=0.2969 ct=7.4383 rec=1.3202 | train/val/test=0.832/0.824/0.833 | c=0.998437
[Epoch 0032] loss=18.7988 cls=0.4728 smmd=0.3037 ct=7.4341 rec=1.3149 | train/val/test=0.834/0.822/0.837 | c=0.998437
[Epoch 0033] loss=18.4047 cls=0.4674 smmd=0.2655 ct=7.4288 rec=1.3175 | train/val/test=0.834/0.822/0.834 | c=0.998437
[Epoch 0034] loss=18.2749 cls=0.4638 smmd=0.2516 ct=7.4346 rec=1.3148 | train/val/test=0.833/0.824/0.834 | c=0.998437
[Epoch 0035] loss=18.2038 cls=0.4643 smmd=0.2456 ct=7.4300 rec=1.3117 | train/val/test=0.837/0.823/0.838 | c=0.998437
[Epoch 0036] loss=18.0855 cls=0.4610 smmd=0.2354 ct=7.4215 rec=1.3152 | train/val/test=0.835/0.824/0.838 | c=0.998437
[Epoch 0037] loss=17.8366 cls=0.4600 smmd=0.2083 ct=7.4332 rec=1.3136 | train/val/test=0.835/0.828/0.840 | c=0.998437
[Epoch 0038] loss=17.8854 cls=0.4615 smmd=0.2124 ct=7.4373 rec=1.3128 | train/val/test=0.838/0.829/0.843 | c=0.998437
[Epoch 0039] loss=17.6676 cls=0.4614 smmd=0.1929 ct=7.4255 rec=1.3138 | train/val/test=0.839/0.829/0.843 | c=0.998437
[Epoch 0040] loss=17.6737 cls=0.4609 smmd=0.1945 ct=7.4205 rec=1.3156 | train/val/test=0.839/0.830/0.839 | c=0.998437
[Epoch 0041] loss=17.5585 cls=0.4614 smmd=0.1808 ct=7.4308 rec=1.3171 | train/val/test=0.838/0.832/0.843 | c=0.998437
[Epoch 0042] loss=17.4976 cls=0.4653 smmd=0.1740 ct=7.4338 rec=1.3154 | train/val/test=0.840/0.831/0.843 | c=0.998437
[Epoch 0043] loss=17.4139 cls=0.4614 smmd=0.1651 ct=7.4365 rec=1.3181 | train/val/test=0.839/0.833/0.843 | c=0.998437
[Epoch 0044] loss=17.3698 cls=0.4639 smmd=0.1638 ct=7.4207 rec=1.3174 | train/val/test=0.842/0.834/0.848 | c=0.998437
[Epoch 0045] loss=17.2717 cls=0.4623 smmd=0.1548 ct=7.4165 rec=1.3187 | train/val/test=0.841/0.833/0.844 | c=0.998437
[Epoch 0046] loss=17.2093 cls=0.4631 smmd=0.1452 ct=7.4331 rec=1.3189 | train/val/test=0.842/0.834/0.846 | c=0.998437
[Epoch 0047] loss=17.1658 cls=0.4644 smmd=0.1415 ct=7.4297 rec=1.3189 | train/val/test=0.844/0.832/0.848 | c=0.998437
[Epoch 0048] loss=17.1085 cls=0.4634 smmd=0.1375 ct=7.4206 rec=1.3204 | train/val/test=0.843/0.833/0.846 | c=0.998437
[Epoch 0049] loss=17.0554 cls=0.4664 smmd=0.1322 ct=7.4201 rec=1.3190 | train/val/test=0.844/0.832/0.848 | c=0.998437
[Epoch 0050] loss=17.0207 cls=0.4645 smmd=0.1277 ct=7.4254 rec=1.3208 | train/val/test=0.844/0.832/0.849 | c=0.998437
[Epoch 0051] loss=17.0118 cls=0.4677 smmd=0.1280 ct=7.4190 rec=1.3205 | train/val/test=0.840/0.829/0.843 | c=0.998437
[Epoch 0052] loss=16.9911 cls=0.4669 smmd=0.1260 ct=7.4187 rec=1.3208 | train/val/test=0.843/0.833/0.849 | c=0.998437
[Epoch 0053] loss=16.9512 cls=0.4701 smmd=0.1204 ct=7.4260 rec=1.3202 | train/val/test=0.841/0.829/0.844 | c=0.998437
[Epoch 0054] loss=16.9424 cls=0.4682 smmd=0.1218 ct=7.4148 rec=1.3215 | train/val/test=0.844/0.832/0.848 | c=0.998437
[Epoch 0055] loss=16.9431 cls=0.4701 smmd=0.1215 ct=7.4162 rec=1.3214 | train/val/test=0.838/0.828/0.841 | c=0.998437
[Epoch 0056] loss=16.8978 cls=0.4716 smmd=0.1166 ct=7.4178 rec=1.3210 | train/val/test=0.843/0.831/0.849 | c=0.998437
[Epoch 0057] loss=16.8737 cls=0.4714 smmd=0.1144 ct=7.4165 rec=1.3219 | train/val/test=0.838/0.828/0.840 | c=0.998437
[Epoch 0058] loss=16.8835 cls=0.4729 smmd=0.1152 ct=7.4174 rec=1.3213 | train/val/test=0.843/0.830/0.849 | c=0.998437
[Epoch 0059] loss=16.9209 cls=0.4716 smmd=0.1198 ct=7.4128 rec=1.3231 | train/val/test=0.834/0.827/0.838 | c=0.998437
[Epoch 0060] loss=16.9621 cls=0.4773 smmd=0.1249 ct=7.4071 rec=1.3217 | train/val/test=0.843/0.832/0.849 | c=0.998437
[Epoch 0061] loss=16.9619 cls=0.4725 smmd=0.1233 ct=7.4157 rec=1.3235 | train/val/test=0.837/0.827/0.840 | c=0.998437
[Epoch 0062] loss=16.8417 cls=0.4741 smmd=0.1128 ct=7.4077 rec=1.3221 | train/val/test=0.842/0.831/0.848 | c=0.998437
[Epoch 0063] loss=16.8100 cls=0.4726 smmd=0.1109 ct=7.4019 rec=1.3221 | train/val/test=0.839/0.831/0.843 | c=0.998437
[Epoch 0064] loss=16.8045 cls=0.4719 smmd=0.1101 ct=7.4032 rec=1.3226 | train/val/test=0.843/0.830/0.850 | c=0.998437
[Epoch 0065] loss=16.8225 cls=0.4731 smmd=0.1129 ct=7.3975 rec=1.3233 | train/val/test=0.838/0.828/0.841 | c=0.998437
[Epoch 0066] loss=16.8609 cls=0.4754 smmd=0.1166 ct=7.3977 rec=1.3240 | train/val/test=0.844/0.830/0.847 | c=0.998437
[Epoch 0067] loss=16.8027 cls=0.4773 smmd=0.1101 ct=7.3999 rec=1.3263 | train/val/test=0.835/0.827/0.839 | c=0.998437
[Epoch 0068] loss=16.8174 cls=0.4796 smmd=0.1144 ct=7.3847 rec=1.3279 | train/val/test=0.846/0.830/0.846 | c=0.998437
[Epoch 0069] loss=16.8574 cls=0.4849 smmd=0.1158 ct=7.3966 rec=1.3278 | train/val/test=0.827/0.823/0.832 | c=0.998437
[Epoch 0070] loss=16.9044 cls=0.4878 smmd=0.1210 ct=7.3920 rec=1.3333 | train/val/test=0.839/0.826/0.834 | c=0.998437
[Epoch 0071] loss=16.9468 cls=0.5010 smmd=0.1253 ct=7.3891 rec=1.3303 | train/val/test=0.812/0.807/0.816 | c=0.998437
[Epoch 0072] loss=17.0449 cls=0.5027 smmd=0.1338 ct=7.3929 rec=1.3395 | train/val/test=0.825/0.815/0.825 | c=0.998437
[Epoch 0073] loss=17.1582 cls=0.5241 smmd=0.1432 ct=7.3986 rec=1.3331 | train/val/test=0.801/0.795/0.808 | c=0.998437
[Epoch 0074] loss=17.2495 cls=0.5145 smmd=0.1540 ct=7.3902 rec=1.3432 | train/val/test=0.826/0.816/0.828 | c=0.998437
[Epoch 0075] loss=17.1516 cls=0.5183 smmd=0.1442 ct=7.3927 rec=1.3293 | train/val/test=0.830/0.822/0.835 | c=0.998437
[Epoch 0076] loss=16.9786 cls=0.4731 smmd=0.1330 ct=7.3738 rec=1.3285 | train/val/test=0.843/0.832/0.843 | c=0.998437
[Epoch 0077] loss=16.7914 cls=0.4692 smmd=0.1164 ct=7.3662 rec=1.3210 | train/val/test=0.843/0.828/0.847 | c=0.998437
[Epoch 0078] loss=16.7174 cls=0.4695 smmd=0.1089 ct=7.3658 rec=1.3247 | train/val/test=0.833/0.823/0.837 | c=0.998437
[Epoch 0079] loss=16.7345 cls=0.4775 smmd=0.1099 ct=7.3665 rec=1.3282 | train/val/test=0.842/0.826/0.842 | c=0.998437
[Epoch 0080] loss=16.7841 cls=0.4883 smmd=0.1132 ct=7.3712 rec=1.3305 | train/val/test=0.829/0.817/0.832 | c=0.998437
[Epoch 0081] loss=16.8576 cls=0.4943 smmd=0.1209 ct=7.3666 rec=1.3359 | train/val/test=0.842/0.826/0.842 | c=0.998437
[Epoch 0082] loss=16.9145 cls=0.4963 smmd=0.1256 ct=7.3713 rec=1.3351 | train/val/test=0.829/0.819/0.833 | c=0.998437
[Epoch 0083] loss=16.9688 cls=0.5001 smmd=0.1308 ct=7.3709 rec=1.3382 | train/val/test=0.841/0.826/0.840 | c=0.998437
[Epoch 0084] loss=16.9346 cls=0.4966 smmd=0.1286 ct=7.3660 rec=1.3358 | train/val/test=0.830/0.820/0.833 | c=0.998437
[Epoch 0085] loss=16.8989 cls=0.4950 smmd=0.1250 ct=7.3665 rec=1.3362 | train/val/test=0.842/0.828/0.840 | c=0.998437
[Epoch 0086] loss=16.9421 cls=0.4913 smmd=0.1303 ct=7.3635 rec=1.3320 | train/val/test=0.829/0.820/0.834 | c=0.998437
[Epoch 0087] loss=16.8835 cls=0.4860 smmd=0.1252 ct=7.3613 rec=1.3314 | train/val/test=0.844/0.829/0.841 | c=0.998437
[Epoch 0088] loss=16.7951 cls=0.4837 smmd=0.1173 ct=7.3587 rec=1.3269 | train/val/test=0.836/0.827/0.840 | c=0.998437
[Epoch 0089] loss=16.7173 cls=0.4767 smmd=0.1110 ct=7.3532 rec=1.3260 | train/val/test=0.842/0.831/0.842 | c=0.998437
[Epoch 0090] loss=16.6862 cls=0.4793 smmd=0.1071 ct=7.3568 rec=1.3241 | train/val/test=0.840/0.827/0.845 | c=0.998437
[Epoch 0091] loss=16.6555 cls=0.4786 smmd=0.1047 ct=7.3528 rec=1.3268 | train/val/test=0.840/0.828/0.844 | c=0.998437
[Epoch 0092] loss=16.6754 cls=0.4857 smmd=0.1058 ct=7.3557 rec=1.3263 | train/val/test=0.839/0.826/0.844 | c=0.998437
[Epoch 0093] loss=16.6630 cls=0.4855 smmd=0.1041 ct=7.3568 rec=1.3307 | train/val/test=0.841/0.829/0.846 | c=0.998437
[Epoch 0094] loss=16.6939 cls=0.4909 smmd=0.1075 ct=7.3545 rec=1.3299 | train/val/test=0.839/0.828/0.843 | c=0.998437
[Epoch 0095] loss=16.7902 cls=0.4873 smmd=0.1162 ct=7.3589 rec=1.3340 | train/val/test=0.840/0.832/0.844 | c=0.998437
[Epoch 0096] loss=16.7806 cls=0.4919 smmd=0.1157 ct=7.3563 rec=1.3301 | train/val/test=0.836/0.826/0.840 | c=0.998437
[Epoch 0097] loss=16.8006 cls=0.4861 smmd=0.1170 ct=7.3600 rec=1.3358 | train/val/test=0.837/0.822/0.835 | c=0.998437
[Epoch 0098] loss=16.8554 cls=0.5063 smmd=0.1206 ct=7.3662 rec=1.3285 | train/val/test=0.816/0.806/0.820 | c=0.998437
[Epoch 0099] loss=17.0748 cls=0.5034 smmd=0.1402 ct=7.3754 rec=1.3408 | train/val/test=0.823/0.812/0.823 | c=0.998437
=== Best @ epoch 44: val=0.8336, test=0.8479 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-4 - 2025-09-21 03:24:25:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-4...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.5365 cls=1.1110 smmd=5.5765 ct=7.2546 rec=1.4137 | train/val/test=0.393/0.398/0.387 | c=0.998437
[Epoch 0001] loss=51.8572 cls=1.0674 smmd=3.6207 ct=7.2044 rec=1.4150 | train/val/test=0.393/0.398/0.387 | c=0.998437
[Epoch 0002] loss=37.9352 cls=1.0792 smmd=2.2448 ct=7.1202 rec=1.4137 | train/val/test=0.499/0.499/0.501 | c=0.998437
[Epoch 0003] loss=40.1061 cls=1.0880 smmd=2.4681 ct=7.0873 rec=1.4135 | train/val/test=0.506/0.504/0.508 | c=0.998437
[Epoch 0004] loss=39.8682 cls=1.0321 smmd=2.4604 ct=7.0208 rec=1.4142 | train/val/test=0.533/0.531/0.539 | c=0.998437
[Epoch 0005] loss=35.6731 cls=0.9893 smmd=2.0536 ct=6.9671 rec=1.4164 | train/val/test=0.540/0.532/0.549 | c=0.998437
[Epoch 0006] loss=30.1575 cls=0.9540 smmd=1.5101 ct=6.9357 rec=1.4162 | train/val/test=0.538/0.533/0.549 | c=0.998437
[Epoch 0007] loss=33.0160 cls=0.9105 smmd=1.7975 ct=6.9400 rec=1.4116 | train/val/test=0.559/0.554/0.570 | c=0.998437
[Epoch 0008] loss=35.2330 cls=0.8644 smmd=1.9142 ct=7.4784 rec=1.4045 | train/val/test=0.636/0.634/0.650 | c=0.998437
[Epoch 0009] loss=29.4540 cls=0.8238 smmd=1.3469 ct=7.4374 rec=1.3960 | train/val/test=0.663/0.653/0.677 | c=0.998437
[Epoch 0010] loss=27.2742 cls=0.7951 smmd=1.1235 ct=7.4734 rec=1.3894 | train/val/test=0.688/0.678/0.695 | c=0.998437
[Epoch 0011] loss=30.1214 cls=0.7704 smmd=1.4002 ct=7.5208 rec=1.3855 | train/val/test=0.700/0.687/0.708 | c=0.998437
[Epoch 0012] loss=27.3159 cls=0.7485 smmd=1.1259 ct=7.4959 rec=1.3817 | train/val/test=0.689/0.678/0.698 | c=0.998437
[Epoch 0013] loss=26.1257 cls=0.7321 smmd=1.0157 ct=7.4577 rec=1.3742 | train/val/test=0.697/0.686/0.706 | c=0.998437
[Epoch 0014] loss=25.6737 cls=0.7099 smmd=0.9681 ct=7.4759 rec=1.3709 | train/val/test=0.709/0.699/0.713 | c=0.998437
[Epoch 0015] loss=24.8817 cls=0.6950 smmd=0.8910 ct=7.4693 rec=1.3708 | train/val/test=0.721/0.710/0.728 | c=0.998437
[Epoch 0016] loss=24.7685 cls=0.6763 smmd=0.8800 ct=7.4753 rec=1.3591 | train/val/test=0.728/0.711/0.729 | c=0.998437
[Epoch 0017] loss=23.2518 cls=0.6726 smmd=0.7294 ct=7.4733 rec=1.3495 | train/val/test=0.743/0.729/0.748 | c=0.998437
[Epoch 0018] loss=22.9697 cls=0.6339 smmd=0.7052 ct=7.4636 rec=1.3461 | train/val/test=0.756/0.746/0.764 | c=0.998437
[Epoch 0019] loss=22.5257 cls=0.6116 smmd=0.6585 ct=7.4816 rec=1.3435 | train/val/test=0.770/0.759/0.778 | c=0.998437
[Epoch 0020] loss=22.0619 cls=0.5916 smmd=0.6185 ct=7.4564 rec=1.3367 | train/val/test=0.775/0.768/0.782 | c=0.998437
[Epoch 0021] loss=21.5058 cls=0.5808 smmd=0.5653 ct=7.4485 rec=1.3314 | train/val/test=0.788/0.780/0.793 | c=0.998437
[Epoch 0022] loss=21.2669 cls=0.5679 smmd=0.5426 ct=7.4468 rec=1.3276 | train/val/test=0.802/0.793/0.808 | c=0.998437
[Epoch 0023] loss=20.7917 cls=0.5412 smmd=0.4939 ct=7.4594 rec=1.3264 | train/val/test=0.809/0.800/0.814 | c=0.998437
[Epoch 0024] loss=20.3454 cls=0.5240 smmd=0.4526 ct=7.4473 rec=1.3257 | train/val/test=0.816/0.806/0.820 | c=0.998437
[Epoch 0025] loss=20.2536 cls=0.5109 smmd=0.4444 ct=7.4456 rec=1.3254 | train/val/test=0.816/0.811/0.820 | c=0.998437
[Epoch 0026] loss=19.7027 cls=0.5034 smmd=0.3891 ct=7.4491 rec=1.3243 | train/val/test=0.818/0.809/0.819 | c=0.998437
[Epoch 0027] loss=19.8309 cls=0.5093 smmd=0.4027 ct=7.4446 rec=1.3208 | train/val/test=0.824/0.819/0.828 | c=0.998437
[Epoch 0028] loss=19.3246 cls=0.4875 smmd=0.3549 ct=7.4350 rec=1.3228 | train/val/test=0.829/0.820/0.831 | c=0.998437
[Epoch 0029] loss=19.1483 cls=0.4829 smmd=0.3362 ct=7.4417 rec=1.3230 | train/val/test=0.828/0.820/0.831 | c=0.998437
[Epoch 0030] loss=19.0716 cls=0.4799 smmd=0.3283 ct=7.4445 rec=1.3189 | train/val/test=0.828/0.817/0.828 | c=0.998437
[Epoch 0031] loss=18.7442 cls=0.4760 smmd=0.2969 ct=7.4383 rec=1.3202 | train/val/test=0.832/0.824/0.833 | c=0.998437
[Epoch 0032] loss=18.7988 cls=0.4728 smmd=0.3037 ct=7.4341 rec=1.3149 | train/val/test=0.834/0.822/0.837 | c=0.998437
[Epoch 0033] loss=18.4047 cls=0.4674 smmd=0.2655 ct=7.4288 rec=1.3175 | train/val/test=0.834/0.822/0.834 | c=0.998437
[Epoch 0034] loss=18.2749 cls=0.4638 smmd=0.2516 ct=7.4346 rec=1.3148 | train/val/test=0.833/0.824/0.834 | c=0.998437
[Epoch 0035] loss=18.2038 cls=0.4643 smmd=0.2456 ct=7.4300 rec=1.3117 | train/val/test=0.837/0.823/0.838 | c=0.998437
[Epoch 0036] loss=18.0855 cls=0.4610 smmd=0.2354 ct=7.4215 rec=1.3152 | train/val/test=0.835/0.824/0.838 | c=0.998437
[Epoch 0037] loss=17.8366 cls=0.4600 smmd=0.2083 ct=7.4332 rec=1.3136 | train/val/test=0.835/0.828/0.840 | c=0.998437
[Epoch 0038] loss=17.8854 cls=0.4615 smmd=0.2124 ct=7.4373 rec=1.3128 | train/val/test=0.838/0.829/0.843 | c=0.998437
[Epoch 0039] loss=17.6676 cls=0.4614 smmd=0.1929 ct=7.4255 rec=1.3138 | train/val/test=0.839/0.829/0.843 | c=0.998437
[Epoch 0040] loss=17.6737 cls=0.4609 smmd=0.1945 ct=7.4205 rec=1.3156 | train/val/test=0.839/0.830/0.839 | c=0.998437
[Epoch 0041] loss=17.5585 cls=0.4614 smmd=0.1808 ct=7.4308 rec=1.3171 | train/val/test=0.838/0.832/0.843 | c=0.998437
[Epoch 0042] loss=17.4976 cls=0.4653 smmd=0.1740 ct=7.4338 rec=1.3154 | train/val/test=0.840/0.831/0.843 | c=0.998437
[Epoch 0043] loss=17.4139 cls=0.4614 smmd=0.1651 ct=7.4365 rec=1.3181 | train/val/test=0.839/0.833/0.843 | c=0.998437
[Epoch 0044] loss=17.3698 cls=0.4639 smmd=0.1638 ct=7.4207 rec=1.3174 | train/val/test=0.842/0.834/0.848 | c=0.998437
[Epoch 0045] loss=17.2717 cls=0.4623 smmd=0.1548 ct=7.4165 rec=1.3187 | train/val/test=0.841/0.833/0.844 | c=0.998437
[Epoch 0046] loss=17.2093 cls=0.4631 smmd=0.1452 ct=7.4331 rec=1.3189 | train/val/test=0.842/0.834/0.846 | c=0.998437
[Epoch 0047] loss=17.1658 cls=0.4644 smmd=0.1415 ct=7.4297 rec=1.3189 | train/val/test=0.844/0.832/0.848 | c=0.998437
[Epoch 0048] loss=17.1085 cls=0.4634 smmd=0.1375 ct=7.4206 rec=1.3204 | train/val/test=0.843/0.833/0.846 | c=0.998437
[Epoch 0049] loss=17.0554 cls=0.4664 smmd=0.1322 ct=7.4201 rec=1.3190 | train/val/test=0.844/0.832/0.848 | c=0.998437
[Epoch 0050] loss=17.0207 cls=0.4645 smmd=0.1277 ct=7.4254 rec=1.3208 | train/val/test=0.844/0.832/0.849 | c=0.998437
[Epoch 0051] loss=17.0118 cls=0.4677 smmd=0.1280 ct=7.4190 rec=1.3205 | train/val/test=0.840/0.829/0.843 | c=0.998437
[Epoch 0052] loss=16.9911 cls=0.4669 smmd=0.1260 ct=7.4187 rec=1.3208 | train/val/test=0.843/0.833/0.849 | c=0.998437
[Epoch 0053] loss=16.9512 cls=0.4701 smmd=0.1204 ct=7.4260 rec=1.3202 | train/val/test=0.841/0.829/0.844 | c=0.998437
[Epoch 0054] loss=16.9424 cls=0.4682 smmd=0.1218 ct=7.4148 rec=1.3215 | train/val/test=0.844/0.832/0.848 | c=0.998437
[Epoch 0055] loss=16.9431 cls=0.4701 smmd=0.1215 ct=7.4162 rec=1.3214 | train/val/test=0.838/0.828/0.841 | c=0.998437
[Epoch 0056] loss=16.8978 cls=0.4716 smmd=0.1166 ct=7.4178 rec=1.3210 | train/val/test=0.843/0.831/0.849 | c=0.998437
[Epoch 0057] loss=16.8737 cls=0.4714 smmd=0.1144 ct=7.4165 rec=1.3219 | train/val/test=0.838/0.828/0.840 | c=0.998437
[Epoch 0058] loss=16.8835 cls=0.4729 smmd=0.1152 ct=7.4174 rec=1.3213 | train/val/test=0.843/0.830/0.849 | c=0.998437
[Epoch 0059] loss=16.9209 cls=0.4716 smmd=0.1198 ct=7.4128 rec=1.3231 | train/val/test=0.834/0.827/0.838 | c=0.998437
[Epoch 0060] loss=16.9621 cls=0.4773 smmd=0.1249 ct=7.4071 rec=1.3217 | train/val/test=0.843/0.832/0.849 | c=0.998437
[Epoch 0061] loss=16.9619 cls=0.4725 smmd=0.1233 ct=7.4157 rec=1.3235 | train/val/test=0.837/0.827/0.840 | c=0.998437
[Epoch 0062] loss=16.8417 cls=0.4741 smmd=0.1128 ct=7.4077 rec=1.3221 | train/val/test=0.842/0.831/0.848 | c=0.998437
[Epoch 0063] loss=16.8100 cls=0.4726 smmd=0.1109 ct=7.4019 rec=1.3221 | train/val/test=0.839/0.831/0.843 | c=0.998437
[Epoch 0064] loss=16.8045 cls=0.4719 smmd=0.1101 ct=7.4032 rec=1.3226 | train/val/test=0.843/0.830/0.850 | c=0.998437
[Epoch 0065] loss=16.8225 cls=0.4731 smmd=0.1129 ct=7.3975 rec=1.3233 | train/val/test=0.838/0.828/0.841 | c=0.998437
[Epoch 0066] loss=16.8609 cls=0.4754 smmd=0.1166 ct=7.3977 rec=1.3240 | train/val/test=0.844/0.830/0.847 | c=0.998437
[Epoch 0067] loss=16.8027 cls=0.4773 smmd=0.1101 ct=7.3999 rec=1.3263 | train/val/test=0.835/0.827/0.839 | c=0.998437
[Epoch 0068] loss=16.8174 cls=0.4796 smmd=0.1144 ct=7.3847 rec=1.3279 | train/val/test=0.846/0.830/0.846 | c=0.998437
[Epoch 0069] loss=16.8574 cls=0.4849 smmd=0.1158 ct=7.3966 rec=1.3278 | train/val/test=0.827/0.823/0.832 | c=0.998437
[Epoch 0070] loss=16.9044 cls=0.4878 smmd=0.1210 ct=7.3920 rec=1.3333 | train/val/test=0.839/0.826/0.834 | c=0.998437
[Epoch 0071] loss=16.9468 cls=0.5010 smmd=0.1253 ct=7.3891 rec=1.3303 | train/val/test=0.812/0.807/0.816 | c=0.998437
[Epoch 0072] loss=17.0449 cls=0.5027 smmd=0.1338 ct=7.3929 rec=1.3395 | train/val/test=0.825/0.815/0.825 | c=0.998437
[Epoch 0073] loss=17.1582 cls=0.5241 smmd=0.1432 ct=7.3986 rec=1.3331 | train/val/test=0.801/0.795/0.808 | c=0.998437
[Epoch 0074] loss=17.2495 cls=0.5145 smmd=0.1540 ct=7.3902 rec=1.3432 | train/val/test=0.826/0.816/0.828 | c=0.998437
[Epoch 0075] loss=17.1516 cls=0.5183 smmd=0.1442 ct=7.3927 rec=1.3293 | train/val/test=0.830/0.822/0.835 | c=0.998437
[Epoch 0076] loss=16.9786 cls=0.4731 smmd=0.1330 ct=7.3738 rec=1.3285 | train/val/test=0.843/0.832/0.843 | c=0.998437
[Epoch 0077] loss=16.7914 cls=0.4692 smmd=0.1164 ct=7.3662 rec=1.3210 | train/val/test=0.843/0.828/0.847 | c=0.998437
[Epoch 0078] loss=16.7174 cls=0.4695 smmd=0.1089 ct=7.3658 rec=1.3247 | train/val/test=0.833/0.823/0.837 | c=0.998437
[Epoch 0079] loss=16.7345 cls=0.4775 smmd=0.1099 ct=7.3665 rec=1.3282 | train/val/test=0.842/0.826/0.842 | c=0.998437
[Epoch 0080] loss=16.7841 cls=0.4883 smmd=0.1132 ct=7.3712 rec=1.3305 | train/val/test=0.829/0.817/0.832 | c=0.998437
[Epoch 0081] loss=16.8576 cls=0.4943 smmd=0.1209 ct=7.3666 rec=1.3359 | train/val/test=0.842/0.826/0.842 | c=0.998437
[Epoch 0082] loss=16.9145 cls=0.4963 smmd=0.1256 ct=7.3713 rec=1.3351 | train/val/test=0.829/0.819/0.833 | c=0.998437
[Epoch 0083] loss=16.9688 cls=0.5001 smmd=0.1308 ct=7.3709 rec=1.3382 | train/val/test=0.841/0.826/0.840 | c=0.998437
[Epoch 0084] loss=16.9346 cls=0.4966 smmd=0.1286 ct=7.3660 rec=1.3358 | train/val/test=0.830/0.820/0.833 | c=0.998437
[Epoch 0085] loss=16.8989 cls=0.4950 smmd=0.1250 ct=7.3665 rec=1.3362 | train/val/test=0.842/0.828/0.840 | c=0.998437
[Epoch 0086] loss=16.9421 cls=0.4913 smmd=0.1303 ct=7.3635 rec=1.3320 | train/val/test=0.829/0.820/0.834 | c=0.998437
[Epoch 0087] loss=16.8835 cls=0.4860 smmd=0.1252 ct=7.3613 rec=1.3314 | train/val/test=0.844/0.829/0.841 | c=0.998437
[Epoch 0088] loss=16.7951 cls=0.4837 smmd=0.1173 ct=7.3587 rec=1.3269 | train/val/test=0.836/0.827/0.840 | c=0.998437
[Epoch 0089] loss=16.7173 cls=0.4767 smmd=0.1110 ct=7.3532 rec=1.3260 | train/val/test=0.842/0.831/0.842 | c=0.998437
[Epoch 0090] loss=16.6862 cls=0.4793 smmd=0.1071 ct=7.3568 rec=1.3241 | train/val/test=0.840/0.827/0.845 | c=0.998437
[Epoch 0091] loss=16.6555 cls=0.4786 smmd=0.1047 ct=7.3528 rec=1.3268 | train/val/test=0.840/0.828/0.844 | c=0.998437
[Epoch 0092] loss=16.6754 cls=0.4857 smmd=0.1058 ct=7.3557 rec=1.3263 | train/val/test=0.839/0.826/0.844 | c=0.998437
[Epoch 0093] loss=16.6630 cls=0.4855 smmd=0.1041 ct=7.3568 rec=1.3307 | train/val/test=0.841/0.829/0.846 | c=0.998437
[Epoch 0094] loss=16.6939 cls=0.4909 smmd=0.1075 ct=7.3545 rec=1.3299 | train/val/test=0.839/0.828/0.843 | c=0.998437
[Epoch 0095] loss=16.7902 cls=0.4873 smmd=0.1162 ct=7.3589 rec=1.3340 | train/val/test=0.840/0.832/0.844 | c=0.998437
[Epoch 0096] loss=16.7806 cls=0.4919 smmd=0.1157 ct=7.3563 rec=1.3301 | train/val/test=0.836/0.826/0.840 | c=0.998437
[Epoch 0097] loss=16.8006 cls=0.4861 smmd=0.1170 ct=7.3600 rec=1.3358 | train/val/test=0.837/0.822/0.835 | c=0.998437
[Epoch 0098] loss=16.8554 cls=0.5063 smmd=0.1206 ct=7.3662 rec=1.3285 | train/val/test=0.816/0.806/0.820 | c=0.998437
[Epoch 0099] loss=17.0748 cls=0.5034 smmd=0.1402 ct=7.3754 rec=1.3408 | train/val/test=0.823/0.812/0.823 | c=0.998437
=== Best @ epoch 44: val=0.8336, test=0.8479 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-4 completed in 140.67 seconds.
==================================================
