Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-4 - 2025-09-21 03:37:30:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-4...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.3941 cls=1.1155 smmd=5.6626 ct=7.2515 rec=1.4140 | train/val/test=0.390/0.392/0.402 | c=0.998437
[Epoch 0001] loss=52.7553 cls=1.0688 smmd=3.7134 ct=7.1898 rec=1.4146 | train/val/test=0.557/0.551/0.563 | c=0.998437
[Epoch 0002] loss=38.0794 cls=1.0766 smmd=2.2591 ct=7.1215 rec=1.4135 | train/val/test=0.555/0.549/0.563 | c=0.998437
[Epoch 0003] loss=40.4139 cls=1.0606 smmd=2.4995 ct=7.0911 rec=1.4134 | train/val/test=0.581/0.587/0.583 | c=0.998437
[Epoch 0004] loss=39.8336 cls=1.0136 smmd=2.4556 ct=7.0320 rec=1.4141 | train/val/test=0.580/0.586/0.575 | c=0.998437
[Epoch 0005] loss=35.5191 cls=0.9754 smmd=2.0372 ct=6.9759 rec=1.4160 | train/val/test=0.575/0.577/0.571 | c=0.998437
[Epoch 0006] loss=30.3440 cls=0.9440 smmd=1.5303 ct=6.9308 rec=1.4145 | train/val/test=0.573/0.575/0.575 | c=0.998437
[Epoch 0007] loss=34.6406 cls=0.8991 smmd=1.8132 ct=7.6776 rec=1.4074 | train/val/test=0.576/0.578/0.578 | c=0.998437
[Epoch 0008] loss=35.6035 cls=0.8595 smmd=1.9434 ct=7.5197 rec=1.4004 | train/val/test=0.592/0.594/0.596 | c=0.998437
[Epoch 0009] loss=29.2788 cls=0.8223 smmd=1.3308 ct=7.4316 rec=1.3927 | train/val/test=0.623/0.619/0.629 | c=0.998437
[Epoch 0010] loss=28.3401 cls=0.7916 smmd=1.2323 ct=7.4642 rec=1.3867 | train/val/test=0.665/0.669/0.670 | c=0.998437
[Epoch 0011] loss=30.1048 cls=0.7626 smmd=1.3971 ct=7.5307 rec=1.3830 | train/val/test=0.702/0.701/0.710 | c=0.998437
[Epoch 0012] loss=27.1176 cls=0.7295 smmd=1.0952 ct=7.5564 rec=1.3764 | train/val/test=0.735/0.733/0.745 | c=0.998437
[Epoch 0013] loss=26.6890 cls=0.6960 smmd=1.0556 ct=7.5502 rec=1.3684 | train/val/test=0.767/0.760/0.767 | c=0.998437
[Epoch 0014] loss=25.6531 cls=0.6709 smmd=0.9609 ct=7.5135 rec=1.3636 | train/val/test=0.749/0.743/0.761 | c=0.998437
[Epoch 0015] loss=25.0998 cls=0.6510 smmd=0.9140 ct=7.4767 rec=1.3614 | train/val/test=0.768/0.760/0.773 | c=0.998437
[Epoch 0016] loss=25.2054 cls=0.6262 smmd=0.9137 ct=7.5384 rec=1.3560 | train/val/test=0.786/0.778/0.785 | c=0.998437
[Epoch 0017] loss=23.1096 cls=0.5998 smmd=0.7003 ct=7.5672 rec=1.3456 | train/val/test=0.794/0.783/0.788 | c=0.998437
[Epoch 0018] loss=23.2594 cls=0.5834 smmd=0.7267 ct=7.5158 rec=1.3382 | train/val/test=0.802/0.795/0.795 | c=0.998437
[Epoch 0019] loss=23.0438 cls=0.5709 smmd=0.7081 ct=7.5053 rec=1.3327 | train/val/test=0.810/0.799/0.805 | c=0.998437
[Epoch 0020] loss=21.9179 cls=0.5453 smmd=0.5964 ct=7.5080 rec=1.3300 | train/val/test=0.812/0.799/0.805 | c=0.998437
[Epoch 0021] loss=21.9392 cls=0.5313 smmd=0.5947 ct=7.5315 rec=1.3267 | train/val/test=0.814/0.806/0.805 | c=0.998437
[Epoch 0022] loss=21.5647 cls=0.5258 smmd=0.5592 ct=7.5248 rec=1.3199 | train/val/test=0.814/0.806/0.800 | c=0.998437
[Epoch 0023] loss=20.8654 cls=0.5185 smmd=0.4922 ct=7.5128 rec=1.3165 | train/val/test=0.818/0.811/0.808 | c=0.998437
[Epoch 0024] loss=20.8169 cls=0.5084 smmd=0.4879 ct=7.5132 rec=1.3148 | train/val/test=0.821/0.811/0.812 | c=0.998437
[Epoch 0025] loss=20.3652 cls=0.4965 smmd=0.4461 ct=7.4991 rec=1.3152 | train/val/test=0.825/0.816/0.817 | c=0.998437
[Epoch 0026] loss=19.9866 cls=0.4891 smmd=0.4073 ct=7.5058 rec=1.3158 | train/val/test=0.826/0.820/0.816 | c=0.998437
[Epoch 0027] loss=20.0322 cls=0.4925 smmd=0.4063 ct=7.5337 rec=1.3120 | train/val/test=0.827/0.820/0.815 | c=0.998437
[Epoch 0028] loss=19.5833 cls=0.4894 smmd=0.3663 ct=7.5105 rec=1.3100 | train/val/test=0.827/0.820/0.819 | c=0.998437
[Epoch 0029] loss=19.2393 cls=0.4761 smmd=0.3353 ct=7.4964 rec=1.3117 | train/val/test=0.831/0.823/0.820 | c=0.998437
[Epoch 0030] loss=19.3048 cls=0.4707 smmd=0.3412 ct=7.5009 rec=1.3120 | train/val/test=0.833/0.826/0.818 | c=0.998437
[Epoch 0031] loss=18.9439 cls=0.4674 smmd=0.3072 ct=7.4918 rec=1.3096 | train/val/test=0.836/0.829/0.821 | c=0.998437
[Epoch 0032] loss=18.7061 cls=0.4687 smmd=0.2791 ct=7.5133 rec=1.3078 | train/val/test=0.837/0.829/0.820 | c=0.998437
[Epoch 0033] loss=18.6992 cls=0.4622 smmd=0.2806 ct=7.5039 rec=1.3086 | train/val/test=0.836/0.829/0.823 | c=0.998437
[Epoch 0034] loss=18.3275 cls=0.4589 smmd=0.2490 ct=7.4766 rec=1.3103 | train/val/test=0.840/0.835/0.825 | c=0.998437
[Epoch 0035] loss=18.3523 cls=0.4591 smmd=0.2488 ct=7.4896 rec=1.3102 | train/val/test=0.841/0.834/0.826 | c=0.998437
[Epoch 0036] loss=18.2952 cls=0.4586 smmd=0.2404 ct=7.5032 rec=1.3099 | train/val/test=0.841/0.835/0.827 | c=0.998437
[Epoch 0037] loss=18.0478 cls=0.4588 smmd=0.2161 ct=7.5011 rec=1.3105 | train/val/test=0.841/0.831/0.827 | c=0.998437
[Epoch 0038] loss=17.9443 cls=0.4583 smmd=0.2077 ct=7.4909 rec=1.3120 | train/val/test=0.840/0.838/0.828 | c=0.998437
[Epoch 0039] loss=17.9898 cls=0.4586 smmd=0.2142 ct=7.4810 rec=1.3135 | train/val/test=0.840/0.836/0.829 | c=0.998437
[Epoch 0040] loss=17.7464 cls=0.4605 smmd=0.1857 ct=7.5018 rec=1.3115 | train/val/test=0.840/0.831/0.826 | c=0.998437
[Epoch 0041] loss=17.7553 cls=0.4595 smmd=0.1870 ct=7.4994 rec=1.3129 | train/val/test=0.841/0.835/0.827 | c=0.998437
[Epoch 0042] loss=17.5946 cls=0.4591 smmd=0.1730 ct=7.4892 rec=1.3130 | train/val/test=0.840/0.833/0.827 | c=0.998437
[Epoch 0043] loss=17.6227 cls=0.4604 smmd=0.1766 ct=7.4854 rec=1.3122 | train/val/test=0.841/0.835/0.829 | c=0.998437
[Epoch 0044] loss=17.5281 cls=0.4592 smmd=0.1666 ct=7.4878 rec=1.3138 | train/val/test=0.838/0.835/0.825 | c=0.998437
[Epoch 0045] loss=17.3792 cls=0.4622 smmd=0.1500 ct=7.4959 rec=1.3117 | train/val/test=0.841/0.835/0.827 | c=0.998437
[Epoch 0046] loss=17.3449 cls=0.4607 smmd=0.1500 ct=7.4791 rec=1.3135 | train/val/test=0.842/0.837/0.828 | c=0.998437
[Epoch 0047] loss=17.3355 cls=0.4620 smmd=0.1483 ct=7.4824 rec=1.3142 | train/val/test=0.840/0.831/0.826 | c=0.998437
[Epoch 0048] loss=17.3323 cls=0.4652 smmd=0.1456 ct=7.4933 rec=1.3150 | train/val/test=0.842/0.839/0.827 | c=0.998437
[Epoch 0049] loss=17.1979 cls=0.4671 smmd=0.1347 ct=7.4797 rec=1.3166 | train/val/test=0.839/0.829/0.828 | c=0.998437
[Epoch 0050] loss=17.1849 cls=0.4687 smmd=0.1332 ct=7.4801 rec=1.3169 | train/val/test=0.841/0.835/0.823 | c=0.998437
[Epoch 0051] loss=17.1474 cls=0.4718 smmd=0.1274 ct=7.4892 rec=1.3184 | train/val/test=0.838/0.829/0.826 | c=0.998437
[Epoch 0052] loss=17.2285 cls=0.4728 smmd=0.1362 ct=7.4855 rec=1.3180 | train/val/test=0.842/0.836/0.824 | c=0.998437
[Epoch 0053] loss=17.1989 cls=0.4726 smmd=0.1354 ct=7.4743 rec=1.3199 | train/val/test=0.839/0.831/0.827 | c=0.998437
[Epoch 0054] loss=17.2007 cls=0.4753 smmd=0.1337 ct=7.4836 rec=1.3182 | train/val/test=0.840/0.836/0.821 | c=0.998437
[Epoch 0055] loss=17.1326 cls=0.4756 smmd=0.1265 ct=7.4849 rec=1.3199 | train/val/test=0.839/0.830/0.824 | c=0.998437
[Epoch 0056] loss=17.0822 cls=0.4750 smmd=0.1233 ct=7.4763 rec=1.3182 | train/val/test=0.842/0.835/0.823 | c=0.998437
[Epoch 0057] loss=17.0513 cls=0.4739 smmd=0.1199 ct=7.4783 rec=1.3185 | train/val/test=0.839/0.831/0.825 | c=0.998437
[Epoch 0058] loss=17.0589 cls=0.4742 smmd=0.1214 ct=7.4743 rec=1.3177 | train/val/test=0.841/0.833/0.823 | c=0.998437
[Epoch 0059] loss=17.0192 cls=0.4747 smmd=0.1164 ct=7.4796 rec=1.3172 | train/val/test=0.838/0.829/0.825 | c=0.998437
[Epoch 0060] loss=17.0910 cls=0.4735 smmd=0.1253 ct=7.4711 rec=1.3172 | train/val/test=0.839/0.834/0.821 | c=0.998437
[Epoch 0061] loss=17.0806 cls=0.4771 smmd=0.1242 ct=7.4706 rec=1.3171 | train/val/test=0.830/0.823/0.822 | c=0.998437
[Epoch 0062] loss=17.0689 cls=0.4786 smmd=0.1204 ct=7.4829 rec=1.3191 | train/val/test=0.837/0.833/0.823 | c=0.998437
[Epoch 0063] loss=17.0376 cls=0.4818 smmd=0.1208 ct=7.4647 rec=1.3185 | train/val/test=0.827/0.821/0.817 | c=0.998437
[Epoch 0064] loss=17.0244 cls=0.4820 smmd=0.1169 ct=7.4771 rec=1.3197 | train/val/test=0.837/0.834/0.827 | c=0.998437
[Epoch 0065] loss=17.1296 cls=0.4869 smmd=0.1282 ct=7.4719 rec=1.3215 | train/val/test=0.817/0.814/0.814 | c=0.998437
[Epoch 0066] loss=17.2255 cls=0.4947 smmd=0.1365 ct=7.4758 rec=1.3242 | train/val/test=0.825/0.827/0.819 | c=0.998437
[Epoch 0067] loss=17.2269 cls=0.5045 smmd=0.1359 ct=7.4762 rec=1.3263 | train/val/test=0.812/0.809/0.809 | c=0.998437
[Epoch 0068] loss=17.1981 cls=0.5027 smmd=0.1342 ct=7.4706 rec=1.3269 | train/val/test=0.829/0.831/0.821 | c=0.998437
[Epoch 0069] loss=17.1743 cls=0.4966 smmd=0.1317 ct=7.4734 rec=1.3249 | train/val/test=0.825/0.820/0.819 | c=0.998437
[Epoch 0070] loss=17.1730 cls=0.4856 smmd=0.1337 ct=7.4665 rec=1.3207 | train/val/test=0.838/0.834/0.828 | c=0.998437
[Epoch 0071] loss=17.0871 cls=0.4769 smmd=0.1271 ct=7.4587 rec=1.3205 | train/val/test=0.836/0.832/0.825 | c=0.998437
[Epoch 0072] loss=17.0172 cls=0.4733 smmd=0.1191 ct=7.4655 rec=1.3171 | train/val/test=0.841/0.834/0.825 | c=0.998437
[Epoch 0073] loss=17.0289 cls=0.4702 smmd=0.1231 ct=7.4518 rec=1.3187 | train/val/test=0.841/0.838/0.826 | c=0.998437
[Epoch 0074] loss=17.0012 cls=0.4725 smmd=0.1175 ct=7.4652 rec=1.3193 | train/val/test=0.840/0.837/0.828 | c=0.998437
[Epoch 0075] loss=16.9949 cls=0.4753 smmd=0.1183 ct=7.4568 rec=1.3214 | train/val/test=0.842/0.835/0.827 | c=0.998437
[Epoch 0076] loss=17.0052 cls=0.4780 smmd=0.1190 ct=7.4571 rec=1.3230 | train/val/test=0.840/0.836/0.829 | c=0.998437
[Epoch 0077] loss=17.0118 cls=0.4795 smmd=0.1187 ct=7.4612 rec=1.3244 | train/val/test=0.843/0.835/0.829 | c=0.998437
[Epoch 0078] loss=17.0142 cls=0.4794 smmd=0.1207 ct=7.4524 rec=1.3247 | train/val/test=0.842/0.839/0.829 | c=0.998437
[Epoch 0079] loss=17.0082 cls=0.4797 smmd=0.1191 ct=7.4575 rec=1.3240 | train/val/test=0.842/0.835/0.827 | c=0.998437
[Epoch 0080] loss=16.9318 cls=0.4767 smmd=0.1148 ct=7.4413 rec=1.3248 | train/val/test=0.838/0.835/0.828 | c=0.998437
[Epoch 0081] loss=16.9277 cls=0.4800 smmd=0.1120 ct=7.4530 rec=1.3231 | train/val/test=0.840/0.836/0.828 | c=0.998437
[Epoch 0082] loss=16.9282 cls=0.4761 smmd=0.1155 ct=7.4367 rec=1.3244 | train/val/test=0.836/0.830/0.825 | c=0.998437
[Epoch 0083] loss=16.8822 cls=0.4796 smmd=0.1099 ct=7.4406 rec=1.3236 | train/val/test=0.837/0.837/0.829 | c=0.998437
[Epoch 0084] loss=16.9233 cls=0.4830 smmd=0.1142 ct=7.4388 rec=1.3253 | train/val/test=0.824/0.817/0.821 | c=0.998437
[Epoch 0085] loss=16.9617 cls=0.4917 smmd=0.1165 ct=7.4427 rec=1.3302 | train/val/test=0.821/0.825/0.818 | c=0.998437
[Epoch 0086] loss=17.1657 cls=0.5139 smmd=0.1361 ct=7.4409 rec=1.3318 | train/val/test=0.788/0.783/0.787 | c=0.998437
[Epoch 0087] loss=17.3934 cls=0.5445 smmd=0.1516 ct=7.4653 rec=1.3489 | train/val/test=0.783/0.792/0.780 | c=0.998437
[Epoch 0088] loss=17.5952 cls=0.5703 smmd=0.1726 ct=7.4563 rec=1.3433 | train/val/test=0.777/0.773/0.775 | c=0.998437
[Epoch 0089] loss=17.5763 cls=0.5647 smmd=0.1695 ct=7.4613 rec=1.3519 | train/val/test=0.809/0.813/0.808 | c=0.998437
[Epoch 0090] loss=17.3325 cls=0.5231 smmd=0.1507 ct=7.4490 rec=1.3317 | train/val/test=0.829/0.826/0.820 | c=0.998437
[Epoch 0091] loss=17.0532 cls=0.4682 smmd=0.1330 ct=7.4152 rec=1.3164 | train/val/test=0.838/0.833/0.827 | c=0.998437
[Epoch 0092] loss=16.9114 cls=0.4575 smmd=0.1179 ct=7.4228 rec=1.3157 | train/val/test=0.834/0.837/0.825 | c=0.998437
[Epoch 0093] loss=16.8891 cls=0.4810 smmd=0.1139 ct=7.4249 rec=1.3200 | train/val/test=0.827/0.819/0.822 | c=0.998437
[Epoch 0094] loss=16.9400 cls=0.4845 smmd=0.1194 ct=7.4203 rec=1.3269 | train/val/test=0.838/0.838/0.830 | c=0.998437
[Epoch 0095] loss=17.0072 cls=0.4900 smmd=0.1245 ct=7.4264 rec=1.3290 | train/val/test=0.834/0.830/0.826 | c=0.998437
[Epoch 0096] loss=17.0493 cls=0.4965 smmd=0.1280 ct=7.4272 rec=1.3333 | train/val/test=0.842/0.836/0.832 | c=0.998437
[Epoch 0097] loss=17.0980 cls=0.5016 smmd=0.1337 ct=7.4211 rec=1.3362 | train/val/test=0.841/0.837/0.830 | c=0.998437
[Epoch 0098] loss=17.1242 cls=0.5058 smmd=0.1341 ct=7.4305 rec=1.3377 | train/val/test=0.843/0.839/0.833 | c=0.998437
[Epoch 0099] loss=17.1466 cls=0.5027 smmd=0.1389 ct=7.4187 rec=1.3371 | train/val/test=0.842/0.839/0.830 | c=0.998437
=== Best @ epoch 99: val=0.8392, test=0.8296 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-4 - 2025-09-21 03:37:30:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-4...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.3941 cls=1.1155 smmd=5.6626 ct=7.2515 rec=1.4140 | train/val/test=0.390/0.392/0.402 | c=0.998437
[Epoch 0001] loss=52.7553 cls=1.0688 smmd=3.7134 ct=7.1898 rec=1.4146 | train/val/test=0.557/0.551/0.563 | c=0.998437
[Epoch 0002] loss=38.0794 cls=1.0766 smmd=2.2591 ct=7.1215 rec=1.4135 | train/val/test=0.555/0.549/0.563 | c=0.998437
[Epoch 0003] loss=40.4139 cls=1.0606 smmd=2.4995 ct=7.0911 rec=1.4134 | train/val/test=0.581/0.587/0.583 | c=0.998437
[Epoch 0004] loss=39.8336 cls=1.0136 smmd=2.4556 ct=7.0320 rec=1.4141 | train/val/test=0.580/0.586/0.575 | c=0.998437
[Epoch 0005] loss=35.5191 cls=0.9754 smmd=2.0372 ct=6.9759 rec=1.4160 | train/val/test=0.575/0.577/0.571 | c=0.998437
[Epoch 0006] loss=30.3440 cls=0.9440 smmd=1.5303 ct=6.9308 rec=1.4145 | train/val/test=0.573/0.575/0.575 | c=0.998437
[Epoch 0007] loss=34.6406 cls=0.8991 smmd=1.8132 ct=7.6776 rec=1.4074 | train/val/test=0.576/0.578/0.578 | c=0.998437
[Epoch 0008] loss=35.6035 cls=0.8595 smmd=1.9434 ct=7.5197 rec=1.4004 | train/val/test=0.592/0.594/0.596 | c=0.998437
[Epoch 0009] loss=29.2788 cls=0.8223 smmd=1.3308 ct=7.4316 rec=1.3927 | train/val/test=0.623/0.619/0.629 | c=0.998437
[Epoch 0010] loss=28.3401 cls=0.7916 smmd=1.2323 ct=7.4642 rec=1.3867 | train/val/test=0.665/0.669/0.670 | c=0.998437
[Epoch 0011] loss=30.1048 cls=0.7626 smmd=1.3971 ct=7.5307 rec=1.3830 | train/val/test=0.702/0.701/0.710 | c=0.998437
[Epoch 0012] loss=27.1176 cls=0.7295 smmd=1.0952 ct=7.5564 rec=1.3764 | train/val/test=0.735/0.733/0.745 | c=0.998437
[Epoch 0013] loss=26.6890 cls=0.6960 smmd=1.0556 ct=7.5502 rec=1.3684 | train/val/test=0.767/0.760/0.767 | c=0.998437
[Epoch 0014] loss=25.6531 cls=0.6709 smmd=0.9609 ct=7.5135 rec=1.3636 | train/val/test=0.749/0.743/0.761 | c=0.998437
[Epoch 0015] loss=25.0998 cls=0.6510 smmd=0.9140 ct=7.4767 rec=1.3614 | train/val/test=0.768/0.760/0.773 | c=0.998437
[Epoch 0016] loss=25.2054 cls=0.6262 smmd=0.9137 ct=7.5384 rec=1.3560 | train/val/test=0.786/0.778/0.785 | c=0.998437
[Epoch 0017] loss=23.1096 cls=0.5998 smmd=0.7003 ct=7.5672 rec=1.3456 | train/val/test=0.794/0.783/0.788 | c=0.998437
[Epoch 0018] loss=23.2594 cls=0.5834 smmd=0.7267 ct=7.5158 rec=1.3382 | train/val/test=0.802/0.795/0.795 | c=0.998437
[Epoch 0019] loss=23.0438 cls=0.5709 smmd=0.7081 ct=7.5053 rec=1.3327 | train/val/test=0.810/0.799/0.805 | c=0.998437
[Epoch 0020] loss=21.9179 cls=0.5453 smmd=0.5964 ct=7.5080 rec=1.3300 | train/val/test=0.812/0.799/0.805 | c=0.998437
[Epoch 0021] loss=21.9392 cls=0.5313 smmd=0.5947 ct=7.5315 rec=1.3267 | train/val/test=0.814/0.806/0.805 | c=0.998437
[Epoch 0022] loss=21.5647 cls=0.5258 smmd=0.5592 ct=7.5248 rec=1.3199 | train/val/test=0.814/0.806/0.800 | c=0.998437
[Epoch 0023] loss=20.8654 cls=0.5185 smmd=0.4922 ct=7.5128 rec=1.3165 | train/val/test=0.818/0.811/0.808 | c=0.998437
[Epoch 0024] loss=20.8169 cls=0.5084 smmd=0.4879 ct=7.5132 rec=1.3148 | train/val/test=0.821/0.811/0.812 | c=0.998437
[Epoch 0025] loss=20.3652 cls=0.4965 smmd=0.4461 ct=7.4991 rec=1.3152 | train/val/test=0.825/0.816/0.817 | c=0.998437
[Epoch 0026] loss=19.9866 cls=0.4891 smmd=0.4073 ct=7.5058 rec=1.3158 | train/val/test=0.826/0.820/0.816 | c=0.998437
[Epoch 0027] loss=20.0322 cls=0.4925 smmd=0.4063 ct=7.5337 rec=1.3120 | train/val/test=0.827/0.820/0.815 | c=0.998437
[Epoch 0028] loss=19.5833 cls=0.4894 smmd=0.3663 ct=7.5105 rec=1.3100 | train/val/test=0.827/0.820/0.819 | c=0.998437
[Epoch 0029] loss=19.2393 cls=0.4761 smmd=0.3353 ct=7.4964 rec=1.3117 | train/val/test=0.831/0.823/0.820 | c=0.998437
[Epoch 0030] loss=19.3048 cls=0.4707 smmd=0.3412 ct=7.5009 rec=1.3120 | train/val/test=0.833/0.826/0.818 | c=0.998437
[Epoch 0031] loss=18.9439 cls=0.4674 smmd=0.3072 ct=7.4918 rec=1.3096 | train/val/test=0.836/0.829/0.821 | c=0.998437
[Epoch 0032] loss=18.7061 cls=0.4687 smmd=0.2791 ct=7.5133 rec=1.3078 | train/val/test=0.837/0.829/0.820 | c=0.998437
[Epoch 0033] loss=18.6992 cls=0.4622 smmd=0.2806 ct=7.5039 rec=1.3086 | train/val/test=0.836/0.829/0.823 | c=0.998437
[Epoch 0034] loss=18.3275 cls=0.4589 smmd=0.2490 ct=7.4766 rec=1.3103 | train/val/test=0.840/0.835/0.825 | c=0.998437
[Epoch 0035] loss=18.3523 cls=0.4591 smmd=0.2488 ct=7.4896 rec=1.3102 | train/val/test=0.841/0.834/0.826 | c=0.998437
[Epoch 0036] loss=18.2952 cls=0.4586 smmd=0.2404 ct=7.5032 rec=1.3099 | train/val/test=0.841/0.835/0.827 | c=0.998437
[Epoch 0037] loss=18.0478 cls=0.4588 smmd=0.2161 ct=7.5011 rec=1.3105 | train/val/test=0.841/0.831/0.827 | c=0.998437
[Epoch 0038] loss=17.9443 cls=0.4583 smmd=0.2077 ct=7.4909 rec=1.3120 | train/val/test=0.840/0.838/0.828 | c=0.998437
[Epoch 0039] loss=17.9898 cls=0.4586 smmd=0.2142 ct=7.4810 rec=1.3135 | train/val/test=0.840/0.836/0.829 | c=0.998437
[Epoch 0040] loss=17.7464 cls=0.4605 smmd=0.1857 ct=7.5018 rec=1.3115 | train/val/test=0.840/0.831/0.826 | c=0.998437
[Epoch 0041] loss=17.7553 cls=0.4595 smmd=0.1870 ct=7.4994 rec=1.3129 | train/val/test=0.841/0.835/0.827 | c=0.998437
[Epoch 0042] loss=17.5946 cls=0.4591 smmd=0.1730 ct=7.4892 rec=1.3130 | train/val/test=0.840/0.833/0.827 | c=0.998437
[Epoch 0043] loss=17.6227 cls=0.4604 smmd=0.1766 ct=7.4854 rec=1.3122 | train/val/test=0.841/0.835/0.829 | c=0.998437
[Epoch 0044] loss=17.5281 cls=0.4592 smmd=0.1666 ct=7.4878 rec=1.3138 | train/val/test=0.838/0.835/0.825 | c=0.998437
[Epoch 0045] loss=17.3792 cls=0.4622 smmd=0.1500 ct=7.4959 rec=1.3117 | train/val/test=0.841/0.835/0.827 | c=0.998437
[Epoch 0046] loss=17.3449 cls=0.4607 smmd=0.1500 ct=7.4791 rec=1.3135 | train/val/test=0.842/0.837/0.828 | c=0.998437
[Epoch 0047] loss=17.3355 cls=0.4620 smmd=0.1483 ct=7.4824 rec=1.3142 | train/val/test=0.840/0.831/0.826 | c=0.998437
[Epoch 0048] loss=17.3323 cls=0.4652 smmd=0.1456 ct=7.4933 rec=1.3150 | train/val/test=0.842/0.839/0.827 | c=0.998437
[Epoch 0049] loss=17.1979 cls=0.4671 smmd=0.1347 ct=7.4797 rec=1.3166 | train/val/test=0.839/0.829/0.828 | c=0.998437
[Epoch 0050] loss=17.1849 cls=0.4687 smmd=0.1332 ct=7.4801 rec=1.3169 | train/val/test=0.841/0.835/0.823 | c=0.998437
[Epoch 0051] loss=17.1474 cls=0.4718 smmd=0.1274 ct=7.4892 rec=1.3184 | train/val/test=0.838/0.829/0.826 | c=0.998437
[Epoch 0052] loss=17.2285 cls=0.4728 smmd=0.1362 ct=7.4855 rec=1.3180 | train/val/test=0.842/0.836/0.824 | c=0.998437
[Epoch 0053] loss=17.1989 cls=0.4726 smmd=0.1354 ct=7.4743 rec=1.3199 | train/val/test=0.839/0.831/0.827 | c=0.998437
[Epoch 0054] loss=17.2007 cls=0.4753 smmd=0.1337 ct=7.4836 rec=1.3182 | train/val/test=0.840/0.836/0.821 | c=0.998437
[Epoch 0055] loss=17.1326 cls=0.4756 smmd=0.1265 ct=7.4849 rec=1.3199 | train/val/test=0.839/0.830/0.824 | c=0.998437
[Epoch 0056] loss=17.0822 cls=0.4750 smmd=0.1233 ct=7.4763 rec=1.3182 | train/val/test=0.842/0.835/0.823 | c=0.998437
[Epoch 0057] loss=17.0513 cls=0.4739 smmd=0.1199 ct=7.4783 rec=1.3185 | train/val/test=0.839/0.831/0.825 | c=0.998437
[Epoch 0058] loss=17.0589 cls=0.4742 smmd=0.1214 ct=7.4743 rec=1.3177 | train/val/test=0.841/0.833/0.823 | c=0.998437
[Epoch 0059] loss=17.0192 cls=0.4747 smmd=0.1164 ct=7.4796 rec=1.3172 | train/val/test=0.838/0.829/0.825 | c=0.998437
[Epoch 0060] loss=17.0910 cls=0.4735 smmd=0.1253 ct=7.4711 rec=1.3172 | train/val/test=0.839/0.834/0.821 | c=0.998437
[Epoch 0061] loss=17.0806 cls=0.4771 smmd=0.1242 ct=7.4706 rec=1.3171 | train/val/test=0.830/0.823/0.822 | c=0.998437
[Epoch 0062] loss=17.0689 cls=0.4786 smmd=0.1204 ct=7.4829 rec=1.3191 | train/val/test=0.837/0.833/0.823 | c=0.998437
[Epoch 0063] loss=17.0376 cls=0.4818 smmd=0.1208 ct=7.4647 rec=1.3185 | train/val/test=0.827/0.821/0.817 | c=0.998437
[Epoch 0064] loss=17.0244 cls=0.4820 smmd=0.1169 ct=7.4771 rec=1.3197 | train/val/test=0.837/0.834/0.827 | c=0.998437
[Epoch 0065] loss=17.1296 cls=0.4869 smmd=0.1282 ct=7.4719 rec=1.3215 | train/val/test=0.817/0.814/0.814 | c=0.998437
[Epoch 0066] loss=17.2255 cls=0.4947 smmd=0.1365 ct=7.4758 rec=1.3242 | train/val/test=0.825/0.827/0.819 | c=0.998437
[Epoch 0067] loss=17.2269 cls=0.5045 smmd=0.1359 ct=7.4762 rec=1.3263 | train/val/test=0.812/0.809/0.809 | c=0.998437
[Epoch 0068] loss=17.1981 cls=0.5027 smmd=0.1342 ct=7.4706 rec=1.3269 | train/val/test=0.829/0.831/0.821 | c=0.998437
[Epoch 0069] loss=17.1743 cls=0.4966 smmd=0.1317 ct=7.4734 rec=1.3249 | train/val/test=0.825/0.820/0.819 | c=0.998437
[Epoch 0070] loss=17.1730 cls=0.4856 smmd=0.1337 ct=7.4665 rec=1.3207 | train/val/test=0.838/0.834/0.828 | c=0.998437
[Epoch 0071] loss=17.0871 cls=0.4769 smmd=0.1271 ct=7.4587 rec=1.3205 | train/val/test=0.836/0.832/0.825 | c=0.998437
[Epoch 0072] loss=17.0172 cls=0.4733 smmd=0.1191 ct=7.4655 rec=1.3171 | train/val/test=0.841/0.834/0.825 | c=0.998437
[Epoch 0073] loss=17.0289 cls=0.4702 smmd=0.1231 ct=7.4518 rec=1.3187 | train/val/test=0.841/0.838/0.826 | c=0.998437
[Epoch 0074] loss=17.0012 cls=0.4725 smmd=0.1175 ct=7.4652 rec=1.3193 | train/val/test=0.840/0.837/0.828 | c=0.998437
[Epoch 0075] loss=16.9949 cls=0.4753 smmd=0.1183 ct=7.4568 rec=1.3214 | train/val/test=0.842/0.835/0.827 | c=0.998437
[Epoch 0076] loss=17.0052 cls=0.4780 smmd=0.1190 ct=7.4571 rec=1.3230 | train/val/test=0.840/0.836/0.829 | c=0.998437
[Epoch 0077] loss=17.0118 cls=0.4795 smmd=0.1187 ct=7.4612 rec=1.3244 | train/val/test=0.843/0.835/0.829 | c=0.998437
[Epoch 0078] loss=17.0142 cls=0.4794 smmd=0.1207 ct=7.4524 rec=1.3247 | train/val/test=0.842/0.839/0.829 | c=0.998437
[Epoch 0079] loss=17.0082 cls=0.4797 smmd=0.1191 ct=7.4575 rec=1.3240 | train/val/test=0.842/0.835/0.827 | c=0.998437
[Epoch 0080] loss=16.9318 cls=0.4767 smmd=0.1148 ct=7.4413 rec=1.3248 | train/val/test=0.838/0.835/0.828 | c=0.998437
[Epoch 0081] loss=16.9277 cls=0.4800 smmd=0.1120 ct=7.4530 rec=1.3231 | train/val/test=0.840/0.836/0.828 | c=0.998437
[Epoch 0082] loss=16.9282 cls=0.4761 smmd=0.1155 ct=7.4367 rec=1.3244 | train/val/test=0.836/0.830/0.825 | c=0.998437
[Epoch 0083] loss=16.8822 cls=0.4796 smmd=0.1099 ct=7.4406 rec=1.3236 | train/val/test=0.837/0.837/0.829 | c=0.998437
[Epoch 0084] loss=16.9233 cls=0.4830 smmd=0.1142 ct=7.4388 rec=1.3253 | train/val/test=0.824/0.817/0.821 | c=0.998437
[Epoch 0085] loss=16.9617 cls=0.4917 smmd=0.1165 ct=7.4427 rec=1.3302 | train/val/test=0.821/0.825/0.818 | c=0.998437
[Epoch 0086] loss=17.1657 cls=0.5139 smmd=0.1361 ct=7.4409 rec=1.3318 | train/val/test=0.788/0.783/0.787 | c=0.998437
[Epoch 0087] loss=17.3934 cls=0.5445 smmd=0.1516 ct=7.4653 rec=1.3489 | train/val/test=0.783/0.792/0.780 | c=0.998437
[Epoch 0088] loss=17.5952 cls=0.5703 smmd=0.1726 ct=7.4563 rec=1.3433 | train/val/test=0.777/0.773/0.775 | c=0.998437
[Epoch 0089] loss=17.5763 cls=0.5647 smmd=0.1695 ct=7.4613 rec=1.3519 | train/val/test=0.809/0.813/0.808 | c=0.998437
[Epoch 0090] loss=17.3325 cls=0.5231 smmd=0.1507 ct=7.4490 rec=1.3317 | train/val/test=0.829/0.826/0.820 | c=0.998437
[Epoch 0091] loss=17.0532 cls=0.4682 smmd=0.1330 ct=7.4152 rec=1.3164 | train/val/test=0.838/0.833/0.827 | c=0.998437
[Epoch 0092] loss=16.9114 cls=0.4575 smmd=0.1179 ct=7.4228 rec=1.3157 | train/val/test=0.834/0.837/0.825 | c=0.998437
[Epoch 0093] loss=16.8891 cls=0.4810 smmd=0.1139 ct=7.4249 rec=1.3200 | train/val/test=0.827/0.819/0.822 | c=0.998437
[Epoch 0094] loss=16.9400 cls=0.4845 smmd=0.1194 ct=7.4203 rec=1.3269 | train/val/test=0.838/0.838/0.830 | c=0.998437
[Epoch 0095] loss=17.0072 cls=0.4900 smmd=0.1245 ct=7.4264 rec=1.3290 | train/val/test=0.834/0.830/0.826 | c=0.998437
[Epoch 0096] loss=17.0493 cls=0.4965 smmd=0.1280 ct=7.4272 rec=1.3333 | train/val/test=0.842/0.836/0.832 | c=0.998437
[Epoch 0097] loss=17.0980 cls=0.5016 smmd=0.1337 ct=7.4211 rec=1.3362 | train/val/test=0.841/0.837/0.830 | c=0.998437
[Epoch 0098] loss=17.1242 cls=0.5058 smmd=0.1341 ct=7.4305 rec=1.3377 | train/val/test=0.843/0.839/0.833 | c=0.998437
[Epoch 0099] loss=17.1466 cls=0.5027 smmd=0.1389 ct=7.4187 rec=1.3371 | train/val/test=0.842/0.839/0.830 | c=0.998437
=== Best @ epoch 99: val=0.8392, test=0.8296 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-4 completed in 147.57 seconds.
==================================================
