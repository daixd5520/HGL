Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3 - 2025-09-21 04:27:46:
Running experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3...
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.1884 cls=1.9440 smmd=4.1890 ct=9.2777 rec=1.3889 | train/val/test=0.379/0.264/0.312 | c=0.998437
[Epoch 0001] loss=16.6657 cls=1.8860 smmd=2.7909 ct=9.2100 rec=1.3894 | train/val/test=0.690/0.420/0.403 | c=0.998437
[Epoch 0002] loss=15.0918 cls=1.7245 smmd=1.4465 ct=9.1434 rec=1.3887 | train/val/test=0.379/0.324/0.331 | c=0.998437
[Epoch 0003] loss=14.9605 cls=1.4652 smmd=1.5417 ct=9.1729 rec=1.3904 | train/val/test=0.828/0.476/0.500 | c=0.998437
[Epoch 0004] loss=14.5855 cls=1.0938 smmd=1.7482 ct=8.9812 rec=1.3811 | train/val/test=0.897/0.474/0.454 | c=0.998437
[Epoch 0005] loss=14.0944 cls=0.8014 smmd=1.6433 ct=8.9165 rec=1.3666 | train/val/test=0.931/0.532/0.561 | c=0.998437
[Epoch 0006] loss=13.3860 cls=0.4885 smmd=1.3436 ct=8.8675 rec=1.3432 | train/val/test=0.931/0.540/0.573 | c=0.998437
[Epoch 0007] loss=13.5505 cls=0.3142 smmd=1.0733 ct=9.5410 rec=1.3110 | train/val/test=0.966/0.558/0.582 | c=0.998437
[Epoch 0008] loss=13.1952 cls=0.2055 smmd=1.0746 ct=9.3440 rec=1.2855 | train/val/test=0.966/0.572/0.588 | c=0.998437
[Epoch 0009] loss=13.1649 cls=0.1343 smmd=1.2216 ct=9.2749 rec=1.2670 | train/val/test=1.000/0.586/0.616 | c=0.998437
[Epoch 0010] loss=13.1109 cls=0.0618 smmd=1.3148 ct=9.2456 rec=1.2443 | train/val/test=1.000/0.608/0.629 | c=0.998437
[Epoch 0011] loss=12.9739 cls=0.0333 smmd=1.2036 ct=9.2778 rec=1.2296 | train/val/test=1.000/0.616/0.639 | c=0.998437
[Epoch 0012] loss=12.7537 cls=0.0198 smmd=0.9842 ct=9.3130 rec=1.2183 | train/val/test=1.000/0.628/0.651 | c=0.998437
[Epoch 0013] loss=12.5770 cls=0.0098 smmd=0.8201 ct=9.3314 rec=1.2078 | train/val/test=1.000/0.630/0.654 | c=0.998437
[Epoch 0014] loss=12.4949 cls=0.0062 smmd=0.7310 ct=9.3534 rec=1.2021 | train/val/test=1.000/0.640/0.657 | c=0.998437
[Epoch 0015] loss=12.4749 cls=0.0047 smmd=0.7178 ct=9.3586 rec=1.1969 | train/val/test=1.000/0.646/0.667 | c=0.998437
[Epoch 0016] loss=12.4394 cls=0.0039 smmd=0.6985 ct=9.3518 rec=1.1926 | train/val/test=1.000/0.646/0.672 | c=0.998437
[Epoch 0017] loss=12.3779 cls=0.0040 smmd=0.6511 ct=9.3400 rec=1.1914 | train/val/test=1.000/0.660/0.671 | c=0.998437
[Epoch 0018] loss=12.2407 cls=0.0047 smmd=0.5386 ct=9.3152 rec=1.1911 | train/val/test=1.000/0.664/0.668 | c=0.998437
[Epoch 0019] loss=12.1654 cls=0.0060 smmd=0.4735 ct=9.3013 rec=1.1923 | train/val/test=1.000/0.666/0.675 | c=0.998437
[Epoch 0020] loss=12.1447 cls=0.0070 smmd=0.4460 ct=9.3059 rec=1.1929 | train/val/test=1.000/0.662/0.685 | c=0.998437
[Epoch 0021] loss=12.1039 cls=0.0085 smmd=0.3830 ct=9.3227 rec=1.1949 | train/val/test=1.000/0.668/0.685 | c=0.998437
[Epoch 0022] loss=12.0393 cls=0.0117 smmd=0.3088 ct=9.3254 rec=1.1967 | train/val/test=1.000/0.682/0.692 | c=0.998437
[Epoch 0023] loss=12.0059 cls=0.0161 smmd=0.2767 ct=9.3185 rec=1.1973 | train/val/test=1.000/0.688/0.705 | c=0.998437
[Epoch 0024] loss=11.9783 cls=0.0203 smmd=0.2345 ct=9.3313 rec=1.1961 | train/val/test=1.000/0.698/0.710 | c=0.998437
[Epoch 0025] loss=11.9642 cls=0.0251 smmd=0.2101 ct=9.3432 rec=1.1929 | train/val/test=1.000/0.698/0.712 | c=0.998437
[Epoch 0026] loss=11.9262 cls=0.0297 smmd=0.1959 ct=9.3203 rec=1.1901 | train/val/test=1.000/0.706/0.714 | c=0.998437
[Epoch 0027] loss=11.9060 cls=0.0312 smmd=0.1874 ct=9.3169 rec=1.1852 | train/val/test=1.000/0.714/0.722 | c=0.998437
[Epoch 0028] loss=11.8849 cls=0.0308 smmd=0.1762 ct=9.3147 rec=1.1816 | train/val/test=1.000/0.716/0.723 | c=0.998437
[Epoch 0029] loss=11.8495 cls=0.0289 smmd=0.1485 ct=9.3173 rec=1.1774 | train/val/test=1.000/0.714/0.725 | c=0.998437
[Epoch 0030] loss=11.8313 cls=0.0267 smmd=0.1406 ct=9.3171 rec=1.1734 | train/val/test=1.000/0.716/0.728 | c=0.998437
[Epoch 0031] loss=11.8020 cls=0.0228 smmd=0.1244 ct=9.3134 rec=1.1707 | train/val/test=1.000/0.716/0.728 | c=0.998437
[Epoch 0032] loss=11.7917 cls=0.0197 smmd=0.1264 ct=9.3085 rec=1.1685 | train/val/test=1.000/0.718/0.731 | c=0.998437
[Epoch 0033] loss=11.7592 cls=0.0169 smmd=0.0997 ct=9.3084 rec=1.1670 | train/val/test=1.000/0.722/0.731 | c=0.998437
[Epoch 0034] loss=11.7440 cls=0.0145 smmd=0.0881 ct=9.3088 rec=1.1663 | train/val/test=1.000/0.718/0.734 | c=0.998437
[Epoch 0035] loss=11.7275 cls=0.0132 smmd=0.0802 ct=9.3018 rec=1.1661 | train/val/test=1.000/0.718/0.736 | c=0.998437
[Epoch 0036] loss=11.7212 cls=0.0125 smmd=0.0777 ct=9.2981 rec=1.1665 | train/val/test=1.000/0.718/0.737 | c=0.998437
[Epoch 0037] loss=11.7133 cls=0.0120 smmd=0.0644 ct=9.3024 rec=1.1673 | train/val/test=1.000/0.714/0.737 | c=0.998437
[Epoch 0038] loss=11.7079 cls=0.0125 smmd=0.0600 ct=9.2990 rec=1.1682 | train/val/test=1.000/0.716/0.739 | c=0.998437
[Epoch 0039] loss=11.6974 cls=0.0134 smmd=0.0515 ct=9.2937 rec=1.1694 | train/val/test=1.000/0.712/0.737 | c=0.998437
[Epoch 0040] loss=11.6909 cls=0.0139 smmd=0.0394 ct=9.2975 rec=1.1701 | train/val/test=1.000/0.714/0.740 | c=0.998437
[Epoch 0041] loss=11.6863 cls=0.0144 smmd=0.0358 ct=9.2952 rec=1.1704 | train/val/test=1.000/0.710/0.737 | c=0.998437
[Epoch 0042] loss=11.6804 cls=0.0148 smmd=0.0285 ct=9.2975 rec=1.1698 | train/val/test=1.000/0.718/0.741 | c=0.998437
[Epoch 0043] loss=11.6851 cls=0.0154 smmd=0.0461 ct=9.2837 rec=1.1699 | train/val/test=1.000/0.710/0.734 | c=0.998437
[Epoch 0044] loss=11.6739 cls=0.0162 smmd=0.0274 ct=9.2934 rec=1.1685 | train/val/test=1.000/0.720/0.738 | c=0.998437
[Epoch 0045] loss=11.6803 cls=0.0163 smmd=0.0437 ct=9.2823 rec=1.1690 | train/val/test=1.000/0.710/0.727 | c=0.998437
[Epoch 0046] loss=11.6934 cls=0.0191 smmd=0.0347 ct=9.3026 rec=1.1685 | train/val/test=1.000/0.718/0.744 | c=0.998437
[Epoch 0047] loss=11.6969 cls=0.0173 smmd=0.0525 ct=9.2894 rec=1.1689 | train/val/test=1.000/0.708/0.725 | c=0.998437
[Epoch 0048] loss=11.6836 cls=0.0192 smmd=0.0338 ct=9.2960 rec=1.1673 | train/val/test=1.000/0.718/0.737 | c=0.998437
[Epoch 0049] loss=11.6668 cls=0.0148 smmd=0.0339 ct=9.2858 rec=1.1661 | train/val/test=1.000/0.708/0.736 | c=0.998437
[Epoch 0050] loss=11.6485 cls=0.0135 smmd=0.0375 ct=9.2702 rec=1.1636 | train/val/test=1.000/0.712/0.732 | c=0.998437
[Epoch 0051] loss=11.6419 cls=0.0129 smmd=0.0139 ct=9.2879 rec=1.1636 | train/val/test=1.000/0.718/0.737 | c=0.998437
[Epoch 0052] loss=11.6429 cls=0.0137 smmd=0.0158 ct=9.2818 rec=1.1659 | train/val/test=1.000/0.708/0.728 | c=0.998437
[Epoch 0053] loss=11.6509 cls=0.0151 smmd=0.0223 ct=9.2783 rec=1.1676 | train/val/test=1.000/0.712/0.734 | c=0.998437
[Epoch 0054] loss=11.6450 cls=0.0136 smmd=0.0128 ct=9.2821 rec=1.1683 | train/val/test=1.000/0.714/0.739 | c=0.998437
[Epoch 0055] loss=11.6358 cls=0.0145 smmd=0.0195 ct=9.2661 rec=1.1679 | train/val/test=1.000/0.712/0.733 | c=0.998437
[Epoch 0056] loss=11.6278 cls=0.0142 smmd=0.0029 ct=9.2742 rec=1.1683 | train/val/test=1.000/0.716/0.733 | c=0.998437
[Epoch 0057] loss=11.6408 cls=0.0146 smmd=0.0117 ct=9.2742 rec=1.1702 | train/val/test=1.000/0.706/0.724 | c=0.998437
[Epoch 0058] loss=11.6559 cls=0.0185 smmd=0.0184 ct=9.2749 rec=1.1721 | train/val/test=1.000/0.718/0.738 | c=0.998437
[Epoch 0059] loss=11.6625 cls=0.0165 smmd=0.0200 ct=9.2805 rec=1.1727 | train/val/test=1.000/0.708/0.720 | c=0.998437
[Epoch 0060] loss=11.6649 cls=0.0190 smmd=0.0192 ct=9.2842 rec=1.1713 | train/val/test=1.000/0.726/0.739 | c=0.998437
[Epoch 0061] loss=11.6500 cls=0.0153 smmd=0.0323 ct=9.2654 rec=1.1685 | train/val/test=1.000/0.716/0.729 | c=0.998437
[Epoch 0062] loss=11.6209 cls=0.0133 smmd=0.0027 ct=9.2749 rec=1.1649 | train/val/test=1.000/0.710/0.733 | c=0.998437
[Epoch 0063] loss=11.6163 cls=0.0131 smmd=0.0098 ct=9.2650 rec=1.1642 | train/val/test=1.000/0.724/0.737 | c=0.998437
[Epoch 0064] loss=11.6283 cls=0.0139 smmd=0.0174 ct=9.2644 rec=1.1663 | train/val/test=1.000/0.708/0.724 | c=0.998437
[Epoch 0065] loss=11.6275 cls=0.0150 smmd=0.0039 ct=9.2739 rec=1.1673 | train/val/test=1.000/0.722/0.735 | c=0.998437
[Epoch 0066] loss=11.6166 cls=0.0140 smmd=0.0100 ct=9.2583 rec=1.1672 | train/val/test=1.000/0.716/0.730 | c=0.998437
[Epoch 0067] loss=11.6075 cls=0.0144 smmd=-0.0036 ct=9.2610 rec=1.1678 | train/val/test=1.000/0.710/0.729 | c=0.998437
[Epoch 0068] loss=11.6196 cls=0.0166 smmd=-0.0002 ct=9.2623 rec=1.1705 | train/val/test=1.000/0.720/0.733 | c=0.998437
[Epoch 0069] loss=11.6365 cls=0.0173 smmd=0.0131 ct=9.2601 rec=1.1730 | train/val/test=1.000/0.706/0.718 | c=0.998437
[Epoch 0070] loss=11.6462 cls=0.0206 smmd=0.0059 ct=9.2697 rec=1.1750 | train/val/test=1.000/0.722/0.736 | c=0.998437
[Epoch 0071] loss=11.6556 cls=0.0193 smmd=0.0234 ct=9.2614 rec=1.1757 | train/val/test=1.000/0.708/0.719 | c=0.998437
[Epoch 0072] loss=11.6497 cls=0.0194 smmd=0.0099 ct=9.2747 rec=1.1729 | train/val/test=1.000/0.720/0.735 | c=0.998437
[Epoch 0073] loss=11.6155 cls=0.0147 smmd=0.0061 ct=9.2572 rec=1.1688 | train/val/test=1.000/0.714/0.731 | c=0.998437
[Epoch 0074] loss=11.5917 cls=0.0129 smmd=-0.0018 ct=9.2498 rec=1.1654 | train/val/test=1.000/0.710/0.727 | c=0.998437
[Epoch 0075] loss=11.6084 cls=0.0138 smmd=0.0030 ct=9.2591 rec=1.1663 | train/val/test=1.000/0.718/0.736 | c=0.998437
[Epoch 0076] loss=11.6117 cls=0.0136 smmd=0.0071 ct=9.2543 rec=1.1683 | train/val/test=1.000/0.710/0.727 | c=0.998437
[Epoch 0077] loss=11.5971 cls=0.0139 smmd=-0.0041 ct=9.2528 rec=1.1673 | train/val/test=1.000/0.712/0.731 | c=0.998437
[Epoch 0078] loss=11.5875 cls=0.0135 smmd=-0.0130 ct=9.2518 rec=1.1676 | train/val/test=1.000/0.718/0.733 | c=0.998437
[Epoch 0079] loss=11.5907 cls=0.0145 smmd=-0.0063 ct=9.2433 rec=1.1696 | train/val/test=1.000/0.708/0.721 | c=0.998437
[Epoch 0080] loss=11.6036 cls=0.0173 smmd=-0.0107 ct=9.2520 rec=1.1725 | train/val/test=1.000/0.718/0.735 | c=0.998437
[Epoch 0081] loss=11.6132 cls=0.0171 smmd=-0.0008 ct=9.2495 rec=1.1737 | train/val/test=1.000/0.708/0.719 | c=0.998437
[Epoch 0082] loss=11.6184 cls=0.0202 smmd=0.0004 ct=9.2487 rec=1.1745 | train/val/test=1.000/0.720/0.739 | c=0.998437
[Epoch 0083] loss=11.6141 cls=0.0176 smmd=-0.0063 ct=9.2558 rec=1.1735 | train/val/test=1.000/0.710/0.722 | c=0.998437
[Epoch 0084] loss=11.6052 cls=0.0185 smmd=0.0015 ct=9.2426 rec=1.1713 | train/val/test=1.000/0.714/0.734 | c=0.998437
[Epoch 0085] loss=11.5866 cls=0.0149 smmd=-0.0149 ct=9.2494 rec=1.1686 | train/val/test=1.000/0.718/0.729 | c=0.998437
[Epoch 0086] loss=11.5765 cls=0.0143 smmd=-0.0087 ct=9.2374 rec=1.1667 | train/val/test=1.000/0.712/0.725 | c=0.998437
[Epoch 0087] loss=11.5806 cls=0.0144 smmd=-0.0078 ct=9.2398 rec=1.1671 | train/val/test=1.000/0.716/0.737 | c=0.998437
[Epoch 0088] loss=11.5839 cls=0.0143 smmd=-0.0136 ct=9.2461 rec=1.1685 | train/val/test=1.000/0.710/0.727 | c=0.998437
[Epoch 0089] loss=11.5826 cls=0.0152 smmd=-0.0061 ct=9.2361 rec=1.1687 | train/val/test=1.000/0.716/0.734 | c=0.998437
[Epoch 0090] loss=11.5756 cls=0.0140 smmd=-0.0142 ct=9.2387 rec=1.1686 | train/val/test=1.000/0.712/0.729 | c=0.998437
[Epoch 0091] loss=11.5666 cls=0.0147 smmd=-0.0218 ct=9.2359 rec=1.1689 | train/val/test=1.000/0.712/0.726 | c=0.998437
[Epoch 0092] loss=11.5708 cls=0.0158 smmd=-0.0135 ct=9.2286 rec=1.1699 | train/val/test=1.000/0.714/0.730 | c=0.998437
[Epoch 0093] loss=11.5792 cls=0.0159 smmd=-0.0225 ct=9.2416 rec=1.1721 | train/val/test=1.000/0.710/0.721 | c=0.998437
[Epoch 0094] loss=11.5919 cls=0.0193 smmd=-0.0052 ct=9.2309 rec=1.1734 | train/val/test=1.000/0.720/0.738 | c=0.998437
[Epoch 0095] loss=11.6027 cls=0.0180 smmd=-0.0133 ct=9.2469 rec=1.1755 | train/val/test=1.000/0.704/0.714 | c=0.998437
[Epoch 0096] loss=11.6274 cls=0.0223 smmd=0.0092 ct=9.2442 rec=1.1759 | train/val/test=1.000/0.718/0.743 | c=0.998437
[Epoch 0097] loss=11.6389 cls=0.0208 smmd=0.0150 ct=9.2486 rec=1.1772 | train/val/test=1.000/0.710/0.713 | c=0.998437
[Epoch 0098] loss=11.6375 cls=0.0190 smmd=0.0054 ct=9.2670 rec=1.1730 | train/val/test=1.000/0.718/0.736 | c=0.998437
[Epoch 0099] loss=11.5940 cls=0.0131 smmd=0.0175 ct=9.2286 rec=1.1674 | train/val/test=1.000/0.722/0.737 | c=0.998437
=== Best @ epoch 60: val=0.7260, test=0.7390 ===

==================================================
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3 - 2025-09-21 04:27:46:
Running experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3...
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=29, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=18.1884 cls=1.9440 smmd=4.1890 ct=9.2777 rec=1.3889 | train/val/test=0.379/0.264/0.312 | c=0.998437
[Epoch 0001] loss=16.6657 cls=1.8860 smmd=2.7909 ct=9.2100 rec=1.3894 | train/val/test=0.690/0.420/0.403 | c=0.998437
[Epoch 0002] loss=15.0918 cls=1.7245 smmd=1.4465 ct=9.1434 rec=1.3887 | train/val/test=0.379/0.324/0.331 | c=0.998437
[Epoch 0003] loss=14.9605 cls=1.4652 smmd=1.5417 ct=9.1729 rec=1.3904 | train/val/test=0.828/0.476/0.500 | c=0.998437
[Epoch 0004] loss=14.5855 cls=1.0938 smmd=1.7482 ct=8.9812 rec=1.3811 | train/val/test=0.897/0.474/0.454 | c=0.998437
[Epoch 0005] loss=14.0944 cls=0.8014 smmd=1.6433 ct=8.9165 rec=1.3666 | train/val/test=0.931/0.532/0.561 | c=0.998437
[Epoch 0006] loss=13.3860 cls=0.4885 smmd=1.3436 ct=8.8675 rec=1.3432 | train/val/test=0.931/0.540/0.573 | c=0.998437
[Epoch 0007] loss=13.5505 cls=0.3142 smmd=1.0733 ct=9.5410 rec=1.3110 | train/val/test=0.966/0.558/0.582 | c=0.998437
[Epoch 0008] loss=13.1952 cls=0.2055 smmd=1.0746 ct=9.3440 rec=1.2855 | train/val/test=0.966/0.572/0.588 | c=0.998437
[Epoch 0009] loss=13.1649 cls=0.1343 smmd=1.2216 ct=9.2749 rec=1.2670 | train/val/test=1.000/0.586/0.616 | c=0.998437
[Epoch 0010] loss=13.1109 cls=0.0618 smmd=1.3148 ct=9.2456 rec=1.2443 | train/val/test=1.000/0.608/0.629 | c=0.998437
[Epoch 0011] loss=12.9739 cls=0.0333 smmd=1.2036 ct=9.2778 rec=1.2296 | train/val/test=1.000/0.616/0.639 | c=0.998437
[Epoch 0012] loss=12.7537 cls=0.0198 smmd=0.9842 ct=9.3130 rec=1.2183 | train/val/test=1.000/0.628/0.651 | c=0.998437
[Epoch 0013] loss=12.5770 cls=0.0098 smmd=0.8201 ct=9.3314 rec=1.2078 | train/val/test=1.000/0.630/0.654 | c=0.998437
[Epoch 0014] loss=12.4949 cls=0.0062 smmd=0.7310 ct=9.3534 rec=1.2021 | train/val/test=1.000/0.640/0.657 | c=0.998437
[Epoch 0015] loss=12.4749 cls=0.0047 smmd=0.7178 ct=9.3586 rec=1.1969 | train/val/test=1.000/0.646/0.667 | c=0.998437
[Epoch 0016] loss=12.4394 cls=0.0039 smmd=0.6985 ct=9.3518 rec=1.1926 | train/val/test=1.000/0.646/0.672 | c=0.998437
[Epoch 0017] loss=12.3779 cls=0.0040 smmd=0.6511 ct=9.3400 rec=1.1914 | train/val/test=1.000/0.660/0.671 | c=0.998437
[Epoch 0018] loss=12.2407 cls=0.0047 smmd=0.5386 ct=9.3152 rec=1.1911 | train/val/test=1.000/0.664/0.668 | c=0.998437
[Epoch 0019] loss=12.1654 cls=0.0060 smmd=0.4735 ct=9.3013 rec=1.1923 | train/val/test=1.000/0.666/0.675 | c=0.998437
[Epoch 0020] loss=12.1447 cls=0.0070 smmd=0.4460 ct=9.3059 rec=1.1929 | train/val/test=1.000/0.662/0.685 | c=0.998437
[Epoch 0021] loss=12.1039 cls=0.0085 smmd=0.3830 ct=9.3227 rec=1.1949 | train/val/test=1.000/0.668/0.685 | c=0.998437
[Epoch 0022] loss=12.0393 cls=0.0117 smmd=0.3088 ct=9.3254 rec=1.1967 | train/val/test=1.000/0.682/0.692 | c=0.998437
[Epoch 0023] loss=12.0059 cls=0.0161 smmd=0.2767 ct=9.3185 rec=1.1973 | train/val/test=1.000/0.688/0.705 | c=0.998437
[Epoch 0024] loss=11.9783 cls=0.0203 smmd=0.2345 ct=9.3313 rec=1.1961 | train/val/test=1.000/0.698/0.710 | c=0.998437
[Epoch 0025] loss=11.9642 cls=0.0251 smmd=0.2101 ct=9.3432 rec=1.1929 | train/val/test=1.000/0.698/0.712 | c=0.998437
[Epoch 0026] loss=11.9262 cls=0.0297 smmd=0.1959 ct=9.3203 rec=1.1901 | train/val/test=1.000/0.706/0.714 | c=0.998437
[Epoch 0027] loss=11.9060 cls=0.0312 smmd=0.1874 ct=9.3169 rec=1.1852 | train/val/test=1.000/0.714/0.722 | c=0.998437
[Epoch 0028] loss=11.8849 cls=0.0308 smmd=0.1762 ct=9.3147 rec=1.1816 | train/val/test=1.000/0.716/0.723 | c=0.998437
[Epoch 0029] loss=11.8495 cls=0.0289 smmd=0.1485 ct=9.3173 rec=1.1774 | train/val/test=1.000/0.714/0.725 | c=0.998437
[Epoch 0030] loss=11.8313 cls=0.0267 smmd=0.1406 ct=9.3171 rec=1.1734 | train/val/test=1.000/0.716/0.728 | c=0.998437
[Epoch 0031] loss=11.8020 cls=0.0228 smmd=0.1244 ct=9.3134 rec=1.1707 | train/val/test=1.000/0.716/0.728 | c=0.998437
[Epoch 0032] loss=11.7917 cls=0.0197 smmd=0.1264 ct=9.3085 rec=1.1685 | train/val/test=1.000/0.718/0.731 | c=0.998437
[Epoch 0033] loss=11.7592 cls=0.0169 smmd=0.0997 ct=9.3084 rec=1.1670 | train/val/test=1.000/0.722/0.731 | c=0.998437
[Epoch 0034] loss=11.7440 cls=0.0145 smmd=0.0881 ct=9.3088 rec=1.1663 | train/val/test=1.000/0.718/0.734 | c=0.998437
[Epoch 0035] loss=11.7275 cls=0.0132 smmd=0.0802 ct=9.3018 rec=1.1661 | train/val/test=1.000/0.718/0.736 | c=0.998437
[Epoch 0036] loss=11.7212 cls=0.0125 smmd=0.0777 ct=9.2981 rec=1.1665 | train/val/test=1.000/0.718/0.737 | c=0.998437
[Epoch 0037] loss=11.7133 cls=0.0120 smmd=0.0644 ct=9.3024 rec=1.1673 | train/val/test=1.000/0.714/0.737 | c=0.998437
[Epoch 0038] loss=11.7079 cls=0.0125 smmd=0.0600 ct=9.2990 rec=1.1682 | train/val/test=1.000/0.716/0.739 | c=0.998437
[Epoch 0039] loss=11.6974 cls=0.0134 smmd=0.0515 ct=9.2937 rec=1.1694 | train/val/test=1.000/0.712/0.737 | c=0.998437
[Epoch 0040] loss=11.6909 cls=0.0139 smmd=0.0394 ct=9.2975 rec=1.1701 | train/val/test=1.000/0.714/0.740 | c=0.998437
[Epoch 0041] loss=11.6863 cls=0.0144 smmd=0.0358 ct=9.2952 rec=1.1704 | train/val/test=1.000/0.710/0.737 | c=0.998437
[Epoch 0042] loss=11.6804 cls=0.0148 smmd=0.0285 ct=9.2975 rec=1.1698 | train/val/test=1.000/0.718/0.741 | c=0.998437
[Epoch 0043] loss=11.6851 cls=0.0154 smmd=0.0461 ct=9.2837 rec=1.1699 | train/val/test=1.000/0.710/0.734 | c=0.998437
[Epoch 0044] loss=11.6739 cls=0.0162 smmd=0.0274 ct=9.2934 rec=1.1685 | train/val/test=1.000/0.720/0.738 | c=0.998437
[Epoch 0045] loss=11.6803 cls=0.0163 smmd=0.0437 ct=9.2823 rec=1.1690 | train/val/test=1.000/0.710/0.727 | c=0.998437
[Epoch 0046] loss=11.6934 cls=0.0191 smmd=0.0347 ct=9.3026 rec=1.1685 | train/val/test=1.000/0.718/0.744 | c=0.998437
[Epoch 0047] loss=11.6969 cls=0.0173 smmd=0.0525 ct=9.2894 rec=1.1689 | train/val/test=1.000/0.708/0.725 | c=0.998437
[Epoch 0048] loss=11.6836 cls=0.0192 smmd=0.0338 ct=9.2960 rec=1.1673 | train/val/test=1.000/0.718/0.737 | c=0.998437
[Epoch 0049] loss=11.6668 cls=0.0148 smmd=0.0339 ct=9.2858 rec=1.1661 | train/val/test=1.000/0.708/0.736 | c=0.998437
[Epoch 0050] loss=11.6485 cls=0.0135 smmd=0.0375 ct=9.2702 rec=1.1636 | train/val/test=1.000/0.712/0.732 | c=0.998437
[Epoch 0051] loss=11.6419 cls=0.0129 smmd=0.0139 ct=9.2879 rec=1.1636 | train/val/test=1.000/0.718/0.737 | c=0.998437
[Epoch 0052] loss=11.6429 cls=0.0137 smmd=0.0158 ct=9.2818 rec=1.1659 | train/val/test=1.000/0.708/0.728 | c=0.998437
[Epoch 0053] loss=11.6509 cls=0.0151 smmd=0.0223 ct=9.2783 rec=1.1676 | train/val/test=1.000/0.712/0.734 | c=0.998437
[Epoch 0054] loss=11.6450 cls=0.0136 smmd=0.0128 ct=9.2821 rec=1.1683 | train/val/test=1.000/0.714/0.739 | c=0.998437
[Epoch 0055] loss=11.6358 cls=0.0145 smmd=0.0195 ct=9.2661 rec=1.1679 | train/val/test=1.000/0.712/0.733 | c=0.998437
[Epoch 0056] loss=11.6278 cls=0.0142 smmd=0.0029 ct=9.2742 rec=1.1683 | train/val/test=1.000/0.716/0.733 | c=0.998437
[Epoch 0057] loss=11.6408 cls=0.0146 smmd=0.0117 ct=9.2742 rec=1.1702 | train/val/test=1.000/0.706/0.724 | c=0.998437
[Epoch 0058] loss=11.6559 cls=0.0185 smmd=0.0184 ct=9.2749 rec=1.1721 | train/val/test=1.000/0.718/0.738 | c=0.998437
[Epoch 0059] loss=11.6625 cls=0.0165 smmd=0.0200 ct=9.2805 rec=1.1727 | train/val/test=1.000/0.708/0.720 | c=0.998437
[Epoch 0060] loss=11.6649 cls=0.0190 smmd=0.0192 ct=9.2842 rec=1.1713 | train/val/test=1.000/0.726/0.739 | c=0.998437
[Epoch 0061] loss=11.6500 cls=0.0153 smmd=0.0323 ct=9.2654 rec=1.1685 | train/val/test=1.000/0.716/0.729 | c=0.998437
[Epoch 0062] loss=11.6209 cls=0.0133 smmd=0.0027 ct=9.2749 rec=1.1649 | train/val/test=1.000/0.710/0.733 | c=0.998437
[Epoch 0063] loss=11.6163 cls=0.0131 smmd=0.0098 ct=9.2650 rec=1.1642 | train/val/test=1.000/0.724/0.737 | c=0.998437
[Epoch 0064] loss=11.6283 cls=0.0139 smmd=0.0174 ct=9.2644 rec=1.1663 | train/val/test=1.000/0.708/0.724 | c=0.998437
[Epoch 0065] loss=11.6275 cls=0.0150 smmd=0.0039 ct=9.2739 rec=1.1673 | train/val/test=1.000/0.722/0.735 | c=0.998437
[Epoch 0066] loss=11.6166 cls=0.0140 smmd=0.0100 ct=9.2583 rec=1.1672 | train/val/test=1.000/0.716/0.730 | c=0.998437
[Epoch 0067] loss=11.6075 cls=0.0144 smmd=-0.0036 ct=9.2610 rec=1.1678 | train/val/test=1.000/0.710/0.729 | c=0.998437
[Epoch 0068] loss=11.6196 cls=0.0166 smmd=-0.0002 ct=9.2623 rec=1.1705 | train/val/test=1.000/0.720/0.733 | c=0.998437
[Epoch 0069] loss=11.6365 cls=0.0173 smmd=0.0131 ct=9.2601 rec=1.1730 | train/val/test=1.000/0.706/0.718 | c=0.998437
[Epoch 0070] loss=11.6462 cls=0.0206 smmd=0.0059 ct=9.2697 rec=1.1750 | train/val/test=1.000/0.722/0.736 | c=0.998437
[Epoch 0071] loss=11.6556 cls=0.0193 smmd=0.0234 ct=9.2614 rec=1.1757 | train/val/test=1.000/0.708/0.719 | c=0.998437
[Epoch 0072] loss=11.6497 cls=0.0194 smmd=0.0099 ct=9.2747 rec=1.1729 | train/val/test=1.000/0.720/0.735 | c=0.998437
[Epoch 0073] loss=11.6155 cls=0.0147 smmd=0.0061 ct=9.2572 rec=1.1688 | train/val/test=1.000/0.714/0.731 | c=0.998437
[Epoch 0074] loss=11.5917 cls=0.0129 smmd=-0.0018 ct=9.2498 rec=1.1654 | train/val/test=1.000/0.710/0.727 | c=0.998437
[Epoch 0075] loss=11.6084 cls=0.0138 smmd=0.0030 ct=9.2591 rec=1.1663 | train/val/test=1.000/0.718/0.736 | c=0.998437
[Epoch 0076] loss=11.6117 cls=0.0136 smmd=0.0071 ct=9.2543 rec=1.1683 | train/val/test=1.000/0.710/0.727 | c=0.998437
[Epoch 0077] loss=11.5971 cls=0.0139 smmd=-0.0041 ct=9.2528 rec=1.1673 | train/val/test=1.000/0.712/0.731 | c=0.998437
[Epoch 0078] loss=11.5875 cls=0.0135 smmd=-0.0130 ct=9.2518 rec=1.1676 | train/val/test=1.000/0.718/0.733 | c=0.998437
[Epoch 0079] loss=11.5907 cls=0.0145 smmd=-0.0063 ct=9.2433 rec=1.1696 | train/val/test=1.000/0.708/0.721 | c=0.998437
[Epoch 0080] loss=11.6036 cls=0.0173 smmd=-0.0107 ct=9.2520 rec=1.1725 | train/val/test=1.000/0.718/0.735 | c=0.998437
[Epoch 0081] loss=11.6132 cls=0.0171 smmd=-0.0008 ct=9.2495 rec=1.1737 | train/val/test=1.000/0.708/0.719 | c=0.998437
[Epoch 0082] loss=11.6184 cls=0.0202 smmd=0.0004 ct=9.2487 rec=1.1745 | train/val/test=1.000/0.720/0.739 | c=0.998437
[Epoch 0083] loss=11.6141 cls=0.0176 smmd=-0.0063 ct=9.2558 rec=1.1735 | train/val/test=1.000/0.710/0.722 | c=0.998437
[Epoch 0084] loss=11.6052 cls=0.0185 smmd=0.0015 ct=9.2426 rec=1.1713 | train/val/test=1.000/0.714/0.734 | c=0.998437
[Epoch 0085] loss=11.5866 cls=0.0149 smmd=-0.0149 ct=9.2494 rec=1.1686 | train/val/test=1.000/0.718/0.729 | c=0.998437
[Epoch 0086] loss=11.5765 cls=0.0143 smmd=-0.0087 ct=9.2374 rec=1.1667 | train/val/test=1.000/0.712/0.725 | c=0.998437
[Epoch 0087] loss=11.5806 cls=0.0144 smmd=-0.0078 ct=9.2398 rec=1.1671 | train/val/test=1.000/0.716/0.737 | c=0.998437
[Epoch 0088] loss=11.5839 cls=0.0143 smmd=-0.0136 ct=9.2461 rec=1.1685 | train/val/test=1.000/0.710/0.727 | c=0.998437
[Epoch 0089] loss=11.5826 cls=0.0152 smmd=-0.0061 ct=9.2361 rec=1.1687 | train/val/test=1.000/0.716/0.734 | c=0.998437
[Epoch 0090] loss=11.5756 cls=0.0140 smmd=-0.0142 ct=9.2387 rec=1.1686 | train/val/test=1.000/0.712/0.729 | c=0.998437
[Epoch 0091] loss=11.5666 cls=0.0147 smmd=-0.0218 ct=9.2359 rec=1.1689 | train/val/test=1.000/0.712/0.726 | c=0.998437
[Epoch 0092] loss=11.5708 cls=0.0158 smmd=-0.0135 ct=9.2286 rec=1.1699 | train/val/test=1.000/0.714/0.730 | c=0.998437
[Epoch 0093] loss=11.5792 cls=0.0159 smmd=-0.0225 ct=9.2416 rec=1.1721 | train/val/test=1.000/0.710/0.721 | c=0.998437
[Epoch 0094] loss=11.5919 cls=0.0193 smmd=-0.0052 ct=9.2309 rec=1.1734 | train/val/test=1.000/0.720/0.738 | c=0.998437
[Epoch 0095] loss=11.6027 cls=0.0180 smmd=-0.0133 ct=9.2469 rec=1.1755 | train/val/test=1.000/0.704/0.714 | c=0.998437
[Epoch 0096] loss=11.6274 cls=0.0223 smmd=0.0092 ct=9.2442 rec=1.1759 | train/val/test=1.000/0.718/0.743 | c=0.998437
[Epoch 0097] loss=11.6389 cls=0.0208 smmd=0.0150 ct=9.2486 rec=1.1772 | train/val/test=1.000/0.710/0.713 | c=0.998437
[Epoch 0098] loss=11.6375 cls=0.0190 smmd=0.0054 ct=9.2670 rec=1.1730 | train/val/test=1.000/0.718/0.736 | c=0.998437
[Epoch 0099] loss=11.5940 cls=0.0131 smmd=0.0175 ct=9.2286 rec=1.1674 | train/val/test=1.000/0.722/0.737 | c=0.998437
=== Best @ epoch 60: val=0.7260, test=0.7390 ===

Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3 completed in 23.26 seconds.
==================================================
