Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1 - 2025-09-21 04:28:56:
Running experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1...
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.2145 cls=1.9494 smmd=4.2320 ct=9.2553 rec=1.3889 | train/val/test=0.310/0.184/0.191 | c=0.998437
[Epoch 0001] loss=16.6952 cls=1.9079 smmd=2.8070 ct=9.2017 rec=1.3893 | train/val/test=0.207/0.124/0.137 | c=0.998437
[Epoch 0002] loss=15.2152 cls=1.8077 smmd=1.4897 ct=9.1399 rec=1.3889 | train/val/test=0.586/0.230/0.250 | c=0.998437
[Epoch 0003] loss=14.9328 cls=1.6278 smmd=1.4491 ct=9.0799 rec=1.3880 | train/val/test=0.759/0.442/0.450 | c=0.998437
[Epoch 0004] loss=15.4365 cls=1.3475 smmd=1.7167 ct=9.6047 rec=1.3838 | train/val/test=0.810/0.488/0.471 | c=0.998437
[Epoch 0005] loss=14.8260 cls=1.0416 smmd=1.7464 ct=9.2905 rec=1.3737 | train/val/test=0.862/0.506/0.475 | c=0.998437
[Epoch 0006] loss=14.2355 cls=0.7435 smmd=1.5973 ct=9.1895 rec=1.3526 | train/val/test=0.914/0.518/0.484 | c=0.998437
[Epoch 0007] loss=13.6827 cls=0.5160 smmd=1.3981 ct=9.1200 rec=1.3243 | train/val/test=0.914/0.570/0.531 | c=0.998437
[Epoch 0008] loss=13.3684 cls=0.3490 smmd=1.2473 ct=9.1816 rec=1.2953 | train/val/test=0.966/0.624/0.603 | c=0.998437
[Epoch 0009] loss=13.2334 cls=0.2162 smmd=1.2103 ct=9.2661 rec=1.2704 | train/val/test=0.983/0.660/0.633 | c=0.998437
[Epoch 0010] loss=13.1723 cls=0.1347 smmd=1.1795 ct=9.3538 rec=1.2521 | train/val/test=1.000/0.676/0.642 | c=0.998437
[Epoch 0011] loss=12.9738 cls=0.0847 smmd=1.0498 ct=9.3725 rec=1.2334 | train/val/test=1.000/0.692/0.639 | c=0.998437
[Epoch 0012] loss=12.7373 cls=0.0571 smmd=0.8950 ct=9.3470 rec=1.2191 | train/val/test=1.000/0.700/0.655 | c=0.998437
[Epoch 0013] loss=12.5468 cls=0.0361 smmd=0.7812 ct=9.3100 rec=1.2097 | train/val/test=1.000/0.712/0.670 | c=0.998437
[Epoch 0014] loss=12.5281 cls=0.0237 smmd=0.8165 ct=9.2815 rec=1.2032 | train/val/test=1.000/0.714/0.678 | c=0.998437
[Epoch 0015] loss=12.5150 cls=0.0176 smmd=0.8248 ct=9.2765 rec=1.1981 | train/val/test=1.000/0.718/0.681 | c=0.998437
[Epoch 0016] loss=12.4461 cls=0.0139 smmd=0.7563 ct=9.2880 rec=1.1939 | train/val/test=1.000/0.712/0.688 | c=0.998437
[Epoch 0017] loss=12.3131 cls=0.0121 smmd=0.6142 ct=9.3026 rec=1.1920 | train/val/test=1.000/0.728/0.707 | c=0.998437
[Epoch 0018] loss=12.2443 cls=0.0117 smmd=0.5373 ct=9.3116 rec=1.1918 | train/val/test=1.000/0.738/0.715 | c=0.998437
[Epoch 0019] loss=12.1886 cls=0.0126 smmd=0.4759 ct=9.3142 rec=1.1930 | train/val/test=1.000/0.730/0.712 | c=0.998437
[Epoch 0020] loss=12.1663 cls=0.0137 smmd=0.4640 ct=9.3043 rec=1.1921 | train/val/test=1.000/0.736/0.717 | c=0.998437
[Epoch 0021] loss=12.0835 cls=0.0166 smmd=0.3868 ct=9.2940 rec=1.1931 | train/val/test=1.000/0.748/0.724 | c=0.998437
[Epoch 0022] loss=12.0392 cls=0.0199 smmd=0.3370 ct=9.2929 rec=1.1947 | train/val/test=1.000/0.744/0.723 | c=0.998437
[Epoch 0023] loss=12.0093 cls=0.0229 smmd=0.2910 ct=9.3084 rec=1.1935 | train/val/test=1.000/0.752/0.727 | c=0.998437
[Epoch 0024] loss=11.9966 cls=0.0275 smmd=0.2614 ct=9.3227 rec=1.1925 | train/val/test=1.000/0.752/0.734 | c=0.998437
[Epoch 0025] loss=11.9622 cls=0.0321 smmd=0.2208 ct=9.3260 rec=1.1916 | train/val/test=1.000/0.754/0.731 | c=0.998437
[Epoch 0026] loss=11.9245 cls=0.0353 smmd=0.1913 ct=9.3215 rec=1.1882 | train/val/test=1.000/0.762/0.737 | c=0.998437
[Epoch 0027] loss=11.9119 cls=0.0371 smmd=0.1997 ct=9.3030 rec=1.1861 | train/val/test=1.000/0.760/0.737 | c=0.998437
[Epoch 0028] loss=11.8983 cls=0.0385 smmd=0.2019 ct=9.2960 rec=1.1809 | train/val/test=1.000/0.764/0.743 | c=0.998437
[Epoch 0029] loss=11.8618 cls=0.0348 smmd=0.1660 ct=9.3056 rec=1.1777 | train/val/test=1.000/0.764/0.746 | c=0.998437
[Epoch 0030] loss=11.8226 cls=0.0326 smmd=0.1307 ct=9.3114 rec=1.1739 | train/val/test=1.000/0.760/0.746 | c=0.998437
[Epoch 0031] loss=11.8061 cls=0.0280 smmd=0.1230 ct=9.3120 rec=1.1715 | train/val/test=1.000/0.760/0.748 | c=0.998437
[Epoch 0032] loss=11.7857 cls=0.0244 smmd=0.1142 ct=9.3067 rec=1.1702 | train/val/test=1.000/0.758/0.747 | c=0.998437
[Epoch 0033] loss=11.7630 cls=0.0218 smmd=0.1065 ct=9.2970 rec=1.1689 | train/val/test=1.000/0.760/0.747 | c=0.998437
[Epoch 0034] loss=11.7554 cls=0.0200 smmd=0.1063 ct=9.2905 rec=1.1693 | train/val/test=1.000/0.752/0.745 | c=0.998437
[Epoch 0035] loss=11.7363 cls=0.0190 smmd=0.0967 ct=9.2830 rec=1.1688 | train/val/test=1.000/0.756/0.746 | c=0.998437
[Epoch 0036] loss=11.7259 cls=0.0183 smmd=0.0865 ct=9.2821 rec=1.1695 | train/val/test=1.000/0.750/0.748 | c=0.998437
[Epoch 0037] loss=11.7155 cls=0.0183 smmd=0.0646 ct=9.2936 rec=1.1695 | train/val/test=1.000/0.754/0.750 | c=0.998437
[Epoch 0038] loss=11.7131 cls=0.0194 smmd=0.0600 ct=9.2932 rec=1.1702 | train/val/test=1.000/0.758/0.744 | c=0.998437
[Epoch 0039] loss=11.7118 cls=0.0196 smmd=0.0560 ct=9.2927 rec=1.1718 | train/val/test=1.000/0.758/0.749 | c=0.998437
[Epoch 0040] loss=11.7187 cls=0.0238 smmd=0.0654 ct=9.2829 rec=1.1733 | train/val/test=1.000/0.752/0.742 | c=0.998437
[Epoch 0041] loss=11.7416 cls=0.0240 smmd=0.0710 ct=9.2935 rec=1.1765 | train/val/test=1.000/0.752/0.729 | c=0.998437
[Epoch 0042] loss=11.7665 cls=0.0334 smmd=0.0871 ct=9.2922 rec=1.1769 | train/val/test=1.000/0.752/0.742 | c=0.998437
[Epoch 0043] loss=11.7376 cls=0.0224 smmd=0.0696 ct=9.3013 rec=1.1721 | train/val/test=1.000/0.764/0.743 | c=0.998437
[Epoch 0044] loss=11.6644 cls=0.0176 smmd=0.0348 ct=9.2845 rec=1.1637 | train/val/test=1.000/0.756/0.739 | c=0.998437
[Epoch 0045] loss=11.6807 cls=0.0196 smmd=0.0456 ct=9.2861 rec=1.1647 | train/val/test=1.000/0.754/0.742 | c=0.998437
[Epoch 0046] loss=11.6893 cls=0.0192 smmd=0.0550 ct=9.2836 rec=1.1657 | train/val/test=1.000/0.762/0.746 | c=0.998437
[Epoch 0047] loss=11.6496 cls=0.0164 smmd=0.0394 ct=9.2696 rec=1.1620 | train/val/test=1.000/0.758/0.736 | c=0.998437
[Epoch 0048] loss=11.6606 cls=0.0188 smmd=0.0323 ct=9.2807 rec=1.1644 | train/val/test=1.000/0.752/0.738 | c=0.998437
[Epoch 0049] loss=11.6738 cls=0.0207 smmd=0.0367 ct=9.2817 rec=1.1673 | train/val/test=1.000/0.762/0.743 | c=0.998437
[Epoch 0050] loss=11.6425 cls=0.0187 smmd=0.0245 ct=9.2688 rec=1.1652 | train/val/test=1.000/0.758/0.740 | c=0.998437
[Epoch 0051] loss=11.6371 cls=0.0195 smmd=0.0208 ct=9.2648 rec=1.1660 | train/val/test=1.000/0.756/0.741 | c=0.998437
[Epoch 0052] loss=11.6586 cls=0.0221 smmd=0.0274 ct=9.2692 rec=1.1700 | train/val/test=1.000/0.758/0.738 | c=0.998437
[Epoch 0053] loss=11.6633 cls=0.0240 smmd=0.0238 ct=9.2740 rec=1.1708 | train/val/test=1.000/0.754/0.735 | c=0.998437
[Epoch 0054] loss=11.6518 cls=0.0222 smmd=0.0209 ct=9.2701 rec=1.1693 | train/val/test=1.000/0.754/0.739 | c=0.998437
[Epoch 0055] loss=11.6275 cls=0.0215 smmd=0.0140 ct=9.2589 rec=1.1666 | train/val/test=1.000/0.750/0.740 | c=0.998437
[Epoch 0056] loss=11.6198 cls=0.0208 smmd=0.0066 ct=9.2619 rec=1.1653 | train/val/test=1.000/0.758/0.736 | c=0.998437
[Epoch 0057] loss=11.6258 cls=0.0200 smmd=0.0147 ct=9.2597 rec=1.1657 | train/val/test=1.000/0.756/0.739 | c=0.998437
[Epoch 0058] loss=11.6167 cls=0.0210 smmd=0.0075 ct=9.2581 rec=1.1651 | train/val/test=1.000/0.752/0.739 | c=0.998437
[Epoch 0059] loss=11.6097 cls=0.0197 smmd=0.0015 ct=9.2594 rec=1.1645 | train/val/test=1.000/0.760/0.738 | c=0.998437
[Epoch 0060] loss=11.6117 cls=0.0199 smmd=0.0109 ct=9.2501 rec=1.1654 | train/val/test=1.000/0.754/0.734 | c=0.998437
[Epoch 0061] loss=11.6111 cls=0.0207 smmd=0.0016 ct=9.2560 rec=1.1664 | train/val/test=1.000/0.750/0.735 | c=0.998437
[Epoch 0062] loss=11.6104 cls=0.0212 smmd=0.0023 ct=9.2520 rec=1.1674 | train/val/test=1.000/0.756/0.740 | c=0.998437
[Epoch 0063] loss=11.6130 cls=0.0215 smmd=0.0087 ct=9.2472 rec=1.1678 | train/val/test=1.000/0.754/0.735 | c=0.998437
[Epoch 0064] loss=11.6034 cls=0.0222 smmd=-0.0062 ct=9.2500 rec=1.1688 | train/val/test=1.000/0.754/0.738 | c=0.998437
[Epoch 0065] loss=11.6022 cls=0.0225 smmd=-0.0023 ct=9.2443 rec=1.1688 | train/val/test=1.000/0.752/0.733 | c=0.998437
[Epoch 0066] loss=11.6024 cls=0.0225 smmd=-0.0066 ct=9.2486 rec=1.1690 | train/val/test=1.000/0.752/0.735 | c=0.998437
[Epoch 0067] loss=11.6025 cls=0.0225 smmd=-0.0024 ct=9.2446 rec=1.1689 | train/val/test=1.000/0.754/0.732 | c=0.998437
[Epoch 0068] loss=11.5969 cls=0.0228 smmd=-0.0073 ct=9.2447 rec=1.1683 | train/val/test=1.000/0.750/0.735 | c=0.998437
[Epoch 0069] loss=11.5965 cls=0.0218 smmd=-0.0042 ct=9.2432 rec=1.1678 | train/val/test=1.000/0.752/0.733 | c=0.998437
[Epoch 0070] loss=11.5931 cls=0.0217 smmd=-0.0051 ct=9.2421 rec=1.1672 | train/val/test=1.000/0.756/0.736 | c=0.998437
[Epoch 0071] loss=11.5871 cls=0.0214 smmd=-0.0086 ct=9.2403 rec=1.1670 | train/val/test=1.000/0.750/0.733 | c=0.998437
[Epoch 0072] loss=11.5860 cls=0.0214 smmd=-0.0105 ct=9.2404 rec=1.1673 | train/val/test=1.000/0.758/0.733 | c=0.998437
[Epoch 0073] loss=11.5856 cls=0.0214 smmd=-0.0089 ct=9.2381 rec=1.1675 | train/val/test=1.000/0.758/0.734 | c=0.998437
[Epoch 0074] loss=11.5847 cls=0.0216 smmd=-0.0073 ct=9.2347 rec=1.1679 | train/val/test=1.000/0.758/0.730 | c=0.998437
[Epoch 0075] loss=11.5875 cls=0.0215 smmd=-0.0105 ct=9.2403 rec=1.1681 | train/val/test=1.000/0.760/0.733 | c=0.998437
[Epoch 0076] loss=11.5829 cls=0.0215 smmd=-0.0075 ct=9.2328 rec=1.1681 | train/val/test=1.000/0.754/0.726 | c=0.998437
[Epoch 0077] loss=11.5860 cls=0.0220 smmd=-0.0108 ct=9.2383 rec=1.1682 | train/val/test=1.000/0.756/0.733 | c=0.998437
[Epoch 0078] loss=11.5919 cls=0.0220 smmd=-0.0003 ct=9.2334 rec=1.1684 | train/val/test=1.000/0.754/0.724 | c=0.998437
[Epoch 0079] loss=11.5848 cls=0.0224 smmd=-0.0128 ct=9.2380 rec=1.1686 | train/val/test=1.000/0.756/0.734 | c=0.998437
[Epoch 0080] loss=11.5960 cls=0.0243 smmd=-0.0041 ct=9.2366 rec=1.1696 | train/val/test=1.000/0.748/0.723 | c=0.998437
[Epoch 0081] loss=11.6141 cls=0.0241 smmd=0.0028 ct=9.2450 rec=1.1711 | train/val/test=1.000/0.754/0.729 | c=0.998437
[Epoch 0082] loss=11.6380 cls=0.0290 smmd=0.0186 ct=9.2449 rec=1.1727 | train/val/test=1.000/0.746/0.724 | c=0.998437
[Epoch 0083] loss=11.6386 cls=0.0248 smmd=0.0146 ct=9.2545 rec=1.1724 | train/val/test=1.000/0.752/0.730 | c=0.998437
[Epoch 0084] loss=11.6076 cls=0.0228 smmd=0.0090 ct=9.2406 rec=1.1676 | train/val/test=1.000/0.756/0.733 | c=0.998437
[Epoch 0085] loss=11.5674 cls=0.0169 smmd=-0.0119 ct=9.2375 rec=1.1625 | train/val/test=1.000/0.758/0.729 | c=0.998437
[Epoch 0086] loss=11.5849 cls=0.0174 smmd=0.0016 ct=9.2377 rec=1.1641 | train/val/test=1.000/0.752/0.729 | c=0.998437
[Epoch 0087] loss=11.6010 cls=0.0208 smmd=0.0064 ct=9.2391 rec=1.1674 | train/val/test=1.000/0.756/0.726 | c=0.998437
[Epoch 0088] loss=11.5876 cls=0.0197 smmd=-0.0076 ct=9.2407 rec=1.1674 | train/val/test=1.000/0.762/0.731 | c=0.998437
[Epoch 0089] loss=11.5739 cls=0.0191 smmd=-0.0051 ct=9.2267 rec=1.1666 | train/val/test=1.000/0.758/0.734 | c=0.998437
[Epoch 0090] loss=11.5717 cls=0.0206 smmd=-0.0185 ct=9.2339 rec=1.1678 | train/val/test=1.000/0.756/0.729 | c=0.998437
[Epoch 0091] loss=11.5941 cls=0.0233 smmd=-0.0058 ct=9.2328 rec=1.1719 | train/val/test=1.000/0.752/0.723 | c=0.998437
[Epoch 0092] loss=11.6331 cls=0.0285 smmd=0.0075 ct=9.2452 rec=1.1759 | train/val/test=1.000/0.750/0.728 | c=0.998437
[Epoch 0093] loss=11.6913 cls=0.0336 smmd=0.0372 ct=9.2567 rec=1.1819 | train/val/test=1.000/0.748/0.709 | c=0.998437
[Epoch 0094] loss=11.7229 cls=0.0402 smmd=0.0490 ct=9.2699 rec=1.1819 | train/val/test=1.000/0.750/0.728 | c=0.998437
[Epoch 0095] loss=11.6527 cls=0.0213 smmd=0.0332 ct=9.2607 rec=1.1687 | train/val/test=1.000/0.760/0.736 | c=0.998437
[Epoch 0096] loss=11.5761 cls=0.0155 smmd=0.0033 ct=9.2360 rec=1.1606 | train/val/test=1.000/0.752/0.721 | c=0.998437
[Epoch 0097] loss=11.6401 cls=0.0198 smmd=0.0333 ct=9.2571 rec=1.1650 | train/val/test=1.000/0.760/0.731 | c=0.998437
[Epoch 0098] loss=11.5769 cls=0.0133 smmd=-0.0004 ct=9.2458 rec=1.1591 | train/val/test=1.000/0.760/0.735 | c=0.998437
[Epoch 0099] loss=11.6147 cls=0.0160 smmd=0.0295 ct=9.2408 rec=1.1642 | train/val/test=1.000/0.754/0.723 | c=0.998437
=== Best @ epoch 28: val=0.7640, test=0.7430 ===

==================================================
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1 - 2025-09-21 04:28:56:
Running experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1...
Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=58, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=18.2145 cls=1.9494 smmd=4.2320 ct=9.2553 rec=1.3889 | train/val/test=0.310/0.184/0.191 | c=0.998437
[Epoch 0001] loss=16.6952 cls=1.9079 smmd=2.8070 ct=9.2017 rec=1.3893 | train/val/test=0.207/0.124/0.137 | c=0.998437
[Epoch 0002] loss=15.2152 cls=1.8077 smmd=1.4897 ct=9.1399 rec=1.3889 | train/val/test=0.586/0.230/0.250 | c=0.998437
[Epoch 0003] loss=14.9328 cls=1.6278 smmd=1.4491 ct=9.0799 rec=1.3880 | train/val/test=0.759/0.442/0.450 | c=0.998437
[Epoch 0004] loss=15.4365 cls=1.3475 smmd=1.7167 ct=9.6047 rec=1.3838 | train/val/test=0.810/0.488/0.471 | c=0.998437
[Epoch 0005] loss=14.8260 cls=1.0416 smmd=1.7464 ct=9.2905 rec=1.3737 | train/val/test=0.862/0.506/0.475 | c=0.998437
[Epoch 0006] loss=14.2355 cls=0.7435 smmd=1.5973 ct=9.1895 rec=1.3526 | train/val/test=0.914/0.518/0.484 | c=0.998437
[Epoch 0007] loss=13.6827 cls=0.5160 smmd=1.3981 ct=9.1200 rec=1.3243 | train/val/test=0.914/0.570/0.531 | c=0.998437
[Epoch 0008] loss=13.3684 cls=0.3490 smmd=1.2473 ct=9.1816 rec=1.2953 | train/val/test=0.966/0.624/0.603 | c=0.998437
[Epoch 0009] loss=13.2334 cls=0.2162 smmd=1.2103 ct=9.2661 rec=1.2704 | train/val/test=0.983/0.660/0.633 | c=0.998437
[Epoch 0010] loss=13.1723 cls=0.1347 smmd=1.1795 ct=9.3538 rec=1.2521 | train/val/test=1.000/0.676/0.642 | c=0.998437
[Epoch 0011] loss=12.9738 cls=0.0847 smmd=1.0498 ct=9.3725 rec=1.2334 | train/val/test=1.000/0.692/0.639 | c=0.998437
[Epoch 0012] loss=12.7373 cls=0.0571 smmd=0.8950 ct=9.3470 rec=1.2191 | train/val/test=1.000/0.700/0.655 | c=0.998437
[Epoch 0013] loss=12.5468 cls=0.0361 smmd=0.7812 ct=9.3100 rec=1.2097 | train/val/test=1.000/0.712/0.670 | c=0.998437
[Epoch 0014] loss=12.5281 cls=0.0237 smmd=0.8165 ct=9.2815 rec=1.2032 | train/val/test=1.000/0.714/0.678 | c=0.998437
[Epoch 0015] loss=12.5150 cls=0.0176 smmd=0.8248 ct=9.2765 rec=1.1981 | train/val/test=1.000/0.718/0.681 | c=0.998437
[Epoch 0016] loss=12.4461 cls=0.0139 smmd=0.7563 ct=9.2880 rec=1.1939 | train/val/test=1.000/0.712/0.688 | c=0.998437
[Epoch 0017] loss=12.3131 cls=0.0121 smmd=0.6142 ct=9.3026 rec=1.1920 | train/val/test=1.000/0.728/0.707 | c=0.998437
[Epoch 0018] loss=12.2443 cls=0.0117 smmd=0.5373 ct=9.3116 rec=1.1918 | train/val/test=1.000/0.738/0.715 | c=0.998437
[Epoch 0019] loss=12.1886 cls=0.0126 smmd=0.4759 ct=9.3142 rec=1.1930 | train/val/test=1.000/0.730/0.712 | c=0.998437
[Epoch 0020] loss=12.1663 cls=0.0137 smmd=0.4640 ct=9.3043 rec=1.1921 | train/val/test=1.000/0.736/0.717 | c=0.998437
[Epoch 0021] loss=12.0835 cls=0.0166 smmd=0.3868 ct=9.2940 rec=1.1931 | train/val/test=1.000/0.748/0.724 | c=0.998437
[Epoch 0022] loss=12.0392 cls=0.0199 smmd=0.3370 ct=9.2929 rec=1.1947 | train/val/test=1.000/0.744/0.723 | c=0.998437
[Epoch 0023] loss=12.0093 cls=0.0229 smmd=0.2910 ct=9.3084 rec=1.1935 | train/val/test=1.000/0.752/0.727 | c=0.998437
[Epoch 0024] loss=11.9966 cls=0.0275 smmd=0.2614 ct=9.3227 rec=1.1925 | train/val/test=1.000/0.752/0.734 | c=0.998437
[Epoch 0025] loss=11.9622 cls=0.0321 smmd=0.2208 ct=9.3260 rec=1.1916 | train/val/test=1.000/0.754/0.731 | c=0.998437
[Epoch 0026] loss=11.9245 cls=0.0353 smmd=0.1913 ct=9.3215 rec=1.1882 | train/val/test=1.000/0.762/0.737 | c=0.998437
[Epoch 0027] loss=11.9119 cls=0.0371 smmd=0.1997 ct=9.3030 rec=1.1861 | train/val/test=1.000/0.760/0.737 | c=0.998437
[Epoch 0028] loss=11.8983 cls=0.0385 smmd=0.2019 ct=9.2960 rec=1.1809 | train/val/test=1.000/0.764/0.743 | c=0.998437
[Epoch 0029] loss=11.8618 cls=0.0348 smmd=0.1660 ct=9.3056 rec=1.1777 | train/val/test=1.000/0.764/0.746 | c=0.998437
[Epoch 0030] loss=11.8226 cls=0.0326 smmd=0.1307 ct=9.3114 rec=1.1739 | train/val/test=1.000/0.760/0.746 | c=0.998437
[Epoch 0031] loss=11.8061 cls=0.0280 smmd=0.1230 ct=9.3120 rec=1.1715 | train/val/test=1.000/0.760/0.748 | c=0.998437
[Epoch 0032] loss=11.7857 cls=0.0244 smmd=0.1142 ct=9.3067 rec=1.1702 | train/val/test=1.000/0.758/0.747 | c=0.998437
[Epoch 0033] loss=11.7630 cls=0.0218 smmd=0.1065 ct=9.2970 rec=1.1689 | train/val/test=1.000/0.760/0.747 | c=0.998437
[Epoch 0034] loss=11.7554 cls=0.0200 smmd=0.1063 ct=9.2905 rec=1.1693 | train/val/test=1.000/0.752/0.745 | c=0.998437
[Epoch 0035] loss=11.7363 cls=0.0190 smmd=0.0967 ct=9.2830 rec=1.1688 | train/val/test=1.000/0.756/0.746 | c=0.998437
[Epoch 0036] loss=11.7259 cls=0.0183 smmd=0.0865 ct=9.2821 rec=1.1695 | train/val/test=1.000/0.750/0.748 | c=0.998437
[Epoch 0037] loss=11.7155 cls=0.0183 smmd=0.0646 ct=9.2936 rec=1.1695 | train/val/test=1.000/0.754/0.750 | c=0.998437
[Epoch 0038] loss=11.7131 cls=0.0194 smmd=0.0600 ct=9.2932 rec=1.1702 | train/val/test=1.000/0.758/0.744 | c=0.998437
[Epoch 0039] loss=11.7118 cls=0.0196 smmd=0.0560 ct=9.2927 rec=1.1718 | train/val/test=1.000/0.758/0.749 | c=0.998437
[Epoch 0040] loss=11.7187 cls=0.0238 smmd=0.0654 ct=9.2829 rec=1.1733 | train/val/test=1.000/0.752/0.742 | c=0.998437
[Epoch 0041] loss=11.7416 cls=0.0240 smmd=0.0710 ct=9.2935 rec=1.1765 | train/val/test=1.000/0.752/0.729 | c=0.998437
[Epoch 0042] loss=11.7665 cls=0.0334 smmd=0.0871 ct=9.2922 rec=1.1769 | train/val/test=1.000/0.752/0.742 | c=0.998437
[Epoch 0043] loss=11.7376 cls=0.0224 smmd=0.0696 ct=9.3013 rec=1.1721 | train/val/test=1.000/0.764/0.743 | c=0.998437
[Epoch 0044] loss=11.6644 cls=0.0176 smmd=0.0348 ct=9.2845 rec=1.1637 | train/val/test=1.000/0.756/0.739 | c=0.998437
[Epoch 0045] loss=11.6807 cls=0.0196 smmd=0.0456 ct=9.2861 rec=1.1647 | train/val/test=1.000/0.754/0.742 | c=0.998437
[Epoch 0046] loss=11.6893 cls=0.0192 smmd=0.0550 ct=9.2836 rec=1.1657 | train/val/test=1.000/0.762/0.746 | c=0.998437
[Epoch 0047] loss=11.6496 cls=0.0164 smmd=0.0394 ct=9.2696 rec=1.1620 | train/val/test=1.000/0.758/0.736 | c=0.998437
[Epoch 0048] loss=11.6606 cls=0.0188 smmd=0.0323 ct=9.2807 rec=1.1644 | train/val/test=1.000/0.752/0.738 | c=0.998437
[Epoch 0049] loss=11.6738 cls=0.0207 smmd=0.0367 ct=9.2817 rec=1.1673 | train/val/test=1.000/0.762/0.743 | c=0.998437
[Epoch 0050] loss=11.6425 cls=0.0187 smmd=0.0245 ct=9.2688 rec=1.1652 | train/val/test=1.000/0.758/0.740 | c=0.998437
[Epoch 0051] loss=11.6371 cls=0.0195 smmd=0.0208 ct=9.2648 rec=1.1660 | train/val/test=1.000/0.756/0.741 | c=0.998437
[Epoch 0052] loss=11.6586 cls=0.0221 smmd=0.0274 ct=9.2692 rec=1.1700 | train/val/test=1.000/0.758/0.738 | c=0.998437
[Epoch 0053] loss=11.6633 cls=0.0240 smmd=0.0238 ct=9.2740 rec=1.1708 | train/val/test=1.000/0.754/0.735 | c=0.998437
[Epoch 0054] loss=11.6518 cls=0.0222 smmd=0.0209 ct=9.2701 rec=1.1693 | train/val/test=1.000/0.754/0.739 | c=0.998437
[Epoch 0055] loss=11.6275 cls=0.0215 smmd=0.0140 ct=9.2589 rec=1.1666 | train/val/test=1.000/0.750/0.740 | c=0.998437
[Epoch 0056] loss=11.6198 cls=0.0208 smmd=0.0066 ct=9.2619 rec=1.1653 | train/val/test=1.000/0.758/0.736 | c=0.998437
[Epoch 0057] loss=11.6258 cls=0.0200 smmd=0.0147 ct=9.2597 rec=1.1657 | train/val/test=1.000/0.756/0.739 | c=0.998437
[Epoch 0058] loss=11.6167 cls=0.0210 smmd=0.0075 ct=9.2581 rec=1.1651 | train/val/test=1.000/0.752/0.739 | c=0.998437
[Epoch 0059] loss=11.6097 cls=0.0197 smmd=0.0015 ct=9.2594 rec=1.1645 | train/val/test=1.000/0.760/0.738 | c=0.998437
[Epoch 0060] loss=11.6117 cls=0.0199 smmd=0.0109 ct=9.2501 rec=1.1654 | train/val/test=1.000/0.754/0.734 | c=0.998437
[Epoch 0061] loss=11.6111 cls=0.0207 smmd=0.0016 ct=9.2560 rec=1.1664 | train/val/test=1.000/0.750/0.735 | c=0.998437
[Epoch 0062] loss=11.6104 cls=0.0212 smmd=0.0023 ct=9.2520 rec=1.1674 | train/val/test=1.000/0.756/0.740 | c=0.998437
[Epoch 0063] loss=11.6130 cls=0.0215 smmd=0.0087 ct=9.2472 rec=1.1678 | train/val/test=1.000/0.754/0.735 | c=0.998437
[Epoch 0064] loss=11.6034 cls=0.0222 smmd=-0.0062 ct=9.2500 rec=1.1688 | train/val/test=1.000/0.754/0.738 | c=0.998437
[Epoch 0065] loss=11.6022 cls=0.0225 smmd=-0.0023 ct=9.2443 rec=1.1688 | train/val/test=1.000/0.752/0.733 | c=0.998437
[Epoch 0066] loss=11.6024 cls=0.0225 smmd=-0.0066 ct=9.2486 rec=1.1690 | train/val/test=1.000/0.752/0.735 | c=0.998437
[Epoch 0067] loss=11.6025 cls=0.0225 smmd=-0.0024 ct=9.2446 rec=1.1689 | train/val/test=1.000/0.754/0.732 | c=0.998437
[Epoch 0068] loss=11.5969 cls=0.0228 smmd=-0.0073 ct=9.2447 rec=1.1683 | train/val/test=1.000/0.750/0.735 | c=0.998437
[Epoch 0069] loss=11.5965 cls=0.0218 smmd=-0.0042 ct=9.2432 rec=1.1678 | train/val/test=1.000/0.752/0.733 | c=0.998437
[Epoch 0070] loss=11.5931 cls=0.0217 smmd=-0.0051 ct=9.2421 rec=1.1672 | train/val/test=1.000/0.756/0.736 | c=0.998437
[Epoch 0071] loss=11.5871 cls=0.0214 smmd=-0.0086 ct=9.2403 rec=1.1670 | train/val/test=1.000/0.750/0.733 | c=0.998437
[Epoch 0072] loss=11.5860 cls=0.0214 smmd=-0.0105 ct=9.2404 rec=1.1673 | train/val/test=1.000/0.758/0.733 | c=0.998437
[Epoch 0073] loss=11.5856 cls=0.0214 smmd=-0.0089 ct=9.2381 rec=1.1675 | train/val/test=1.000/0.758/0.734 | c=0.998437
[Epoch 0074] loss=11.5847 cls=0.0216 smmd=-0.0073 ct=9.2347 rec=1.1679 | train/val/test=1.000/0.758/0.730 | c=0.998437
[Epoch 0075] loss=11.5875 cls=0.0215 smmd=-0.0105 ct=9.2403 rec=1.1681 | train/val/test=1.000/0.760/0.733 | c=0.998437
[Epoch 0076] loss=11.5829 cls=0.0215 smmd=-0.0075 ct=9.2328 rec=1.1681 | train/val/test=1.000/0.754/0.726 | c=0.998437
[Epoch 0077] loss=11.5860 cls=0.0220 smmd=-0.0108 ct=9.2383 rec=1.1682 | train/val/test=1.000/0.756/0.733 | c=0.998437
[Epoch 0078] loss=11.5919 cls=0.0220 smmd=-0.0003 ct=9.2334 rec=1.1684 | train/val/test=1.000/0.754/0.724 | c=0.998437
[Epoch 0079] loss=11.5848 cls=0.0224 smmd=-0.0128 ct=9.2380 rec=1.1686 | train/val/test=1.000/0.756/0.734 | c=0.998437
[Epoch 0080] loss=11.5960 cls=0.0243 smmd=-0.0041 ct=9.2366 rec=1.1696 | train/val/test=1.000/0.748/0.723 | c=0.998437
[Epoch 0081] loss=11.6141 cls=0.0241 smmd=0.0028 ct=9.2450 rec=1.1711 | train/val/test=1.000/0.754/0.729 | c=0.998437
[Epoch 0082] loss=11.6380 cls=0.0290 smmd=0.0186 ct=9.2449 rec=1.1727 | train/val/test=1.000/0.746/0.724 | c=0.998437
[Epoch 0083] loss=11.6386 cls=0.0248 smmd=0.0146 ct=9.2545 rec=1.1724 | train/val/test=1.000/0.752/0.730 | c=0.998437
[Epoch 0084] loss=11.6076 cls=0.0228 smmd=0.0090 ct=9.2406 rec=1.1676 | train/val/test=1.000/0.756/0.733 | c=0.998437
[Epoch 0085] loss=11.5674 cls=0.0169 smmd=-0.0119 ct=9.2375 rec=1.1625 | train/val/test=1.000/0.758/0.729 | c=0.998437
[Epoch 0086] loss=11.5849 cls=0.0174 smmd=0.0016 ct=9.2377 rec=1.1641 | train/val/test=1.000/0.752/0.729 | c=0.998437
[Epoch 0087] loss=11.6010 cls=0.0208 smmd=0.0064 ct=9.2391 rec=1.1674 | train/val/test=1.000/0.756/0.726 | c=0.998437
[Epoch 0088] loss=11.5876 cls=0.0197 smmd=-0.0076 ct=9.2407 rec=1.1674 | train/val/test=1.000/0.762/0.731 | c=0.998437
[Epoch 0089] loss=11.5739 cls=0.0191 smmd=-0.0051 ct=9.2267 rec=1.1666 | train/val/test=1.000/0.758/0.734 | c=0.998437
[Epoch 0090] loss=11.5717 cls=0.0206 smmd=-0.0185 ct=9.2339 rec=1.1678 | train/val/test=1.000/0.756/0.729 | c=0.998437
[Epoch 0091] loss=11.5941 cls=0.0233 smmd=-0.0058 ct=9.2328 rec=1.1719 | train/val/test=1.000/0.752/0.723 | c=0.998437
[Epoch 0092] loss=11.6331 cls=0.0285 smmd=0.0075 ct=9.2452 rec=1.1759 | train/val/test=1.000/0.750/0.728 | c=0.998437
[Epoch 0093] loss=11.6913 cls=0.0336 smmd=0.0372 ct=9.2567 rec=1.1819 | train/val/test=1.000/0.748/0.709 | c=0.998437
[Epoch 0094] loss=11.7229 cls=0.0402 smmd=0.0490 ct=9.2699 rec=1.1819 | train/val/test=1.000/0.750/0.728 | c=0.998437
[Epoch 0095] loss=11.6527 cls=0.0213 smmd=0.0332 ct=9.2607 rec=1.1687 | train/val/test=1.000/0.760/0.736 | c=0.998437
[Epoch 0096] loss=11.5761 cls=0.0155 smmd=0.0033 ct=9.2360 rec=1.1606 | train/val/test=1.000/0.752/0.721 | c=0.998437
[Epoch 0097] loss=11.6401 cls=0.0198 smmd=0.0333 ct=9.2571 rec=1.1650 | train/val/test=1.000/0.760/0.731 | c=0.998437
[Epoch 0098] loss=11.5769 cls=0.0133 smmd=-0.0004 ct=9.2458 rec=1.1591 | train/val/test=1.000/0.760/0.735 | c=0.998437
[Epoch 0099] loss=11.6147 cls=0.0160 smmd=0.0295 ct=9.2408 rec=1.1642 | train/val/test=1.000/0.754/0.723 | c=0.998437
=== Best @ epoch 28: val=0.7640, test=0.7430 ===

Experiment Cora-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1 completed in 23.90 seconds.
==================================================
