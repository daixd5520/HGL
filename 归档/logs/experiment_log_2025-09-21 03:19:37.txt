Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-2 - 2025-09-21 03:19:37:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-2...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-2 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.0633 cls=1.1013 smmd=5.6309 ct=7.2487 rec=1.4136 | train/val/test=0.396/0.411/0.398 | c=0.998437
[Epoch 0001] loss=52.7062 cls=1.0660 smmd=3.7109 ct=7.1782 rec=1.4149 | train/val/test=0.432/0.450/0.437 | c=0.998437
[Epoch 0002] loss=37.2077 cls=1.0695 smmd=2.1789 ct=7.0888 rec=1.4135 | train/val/test=0.550/0.553/0.549 | c=0.998437
[Epoch 0003] loss=40.6809 cls=1.0498 smmd=2.5272 ct=7.0889 rec=1.4130 | train/val/test=0.565/0.562/0.556 | c=0.998437
[Epoch 0004] loss=41.4591 cls=0.9918 smmd=2.4884 ct=7.6870 rec=1.4107 | train/val/test=0.548/0.547/0.535 | c=0.998437
[Epoch 0005] loss=36.5184 cls=0.9507 smmd=2.0468 ct=7.4363 rec=1.4049 | train/val/test=0.549/0.549/0.537 | c=0.998437
[Epoch 0006] loss=31.6401 cls=0.9251 smmd=1.5617 ct=7.4314 rec=1.3955 | train/val/test=0.549/0.549/0.541 | c=0.998437
[Epoch 0007] loss=34.8640 cls=0.9072 smmd=1.8689 ct=7.5138 rec=1.3878 | train/val/test=0.554/0.553/0.546 | c=0.998437
[Epoch 0008] loss=35.6732 cls=0.8746 smmd=1.9537 ct=7.5048 rec=1.3777 | train/val/test=0.563/0.559/0.550 | c=0.998437
[Epoch 0009] loss=29.4979 cls=0.8431 smmd=1.3434 ct=7.4789 rec=1.3693 | train/val/test=0.574/0.573/0.564 | c=0.998437
[Epoch 0010] loss=27.6065 cls=0.8137 smmd=1.1442 ct=7.5375 rec=1.3660 | train/val/test=0.604/0.597/0.596 | c=0.998437
[Epoch 0011] loss=30.3460 cls=0.7797 smmd=1.4185 ct=7.5440 rec=1.3671 | train/val/test=0.686/0.681/0.677 | c=0.998437
[Epoch 0012] loss=27.7142 cls=0.7400 smmd=1.1639 ct=7.5120 rec=1.3631 | train/val/test=0.710/0.703/0.692 | c=0.998437
[Epoch 0013] loss=26.0485 cls=0.7175 smmd=0.9962 ct=7.5236 rec=1.3617 | train/val/test=0.746/0.734/0.725 | c=0.998437
[Epoch 0014] loss=25.8086 cls=0.6841 smmd=0.9698 ct=7.5446 rec=1.3592 | train/val/test=0.778/0.768/0.768 | c=0.998437
[Epoch 0015] loss=25.5453 cls=0.6486 smmd=0.9504 ct=7.5201 rec=1.3542 | train/val/test=0.800/0.795/0.796 | c=0.998437
[Epoch 0016] loss=24.6229 cls=0.6226 smmd=0.8646 ct=7.4947 rec=1.3527 | train/val/test=0.805/0.797/0.799 | c=0.998437
[Epoch 0017] loss=23.2400 cls=0.6026 smmd=0.7285 ct=7.4902 rec=1.3456 | train/val/test=0.773/0.766/0.768 | c=0.998437
[Epoch 0018] loss=23.2921 cls=0.6181 smmd=0.7261 ct=7.5258 rec=1.3412 | train/val/test=0.784/0.775/0.777 | c=0.998437
[Epoch 0019] loss=22.8003 cls=0.5873 smmd=0.6742 ct=7.5483 rec=1.3365 | train/val/test=0.816/0.813/0.812 | c=0.998437
[Epoch 0020] loss=22.0254 cls=0.5466 smmd=0.6040 ct=7.5232 rec=1.3316 | train/val/test=0.810/0.812/0.809 | c=0.998437
[Epoch 0021] loss=21.6342 cls=0.5482 smmd=0.5715 ct=7.4902 rec=1.3302 | train/val/test=0.814/0.810/0.814 | c=0.998437
[Epoch 0022] loss=21.5312 cls=0.5287 smmd=0.5622 ct=7.4924 rec=1.3210 | train/val/test=0.816/0.810/0.812 | c=0.998437
[Epoch 0023] loss=20.8479 cls=0.5166 smmd=0.4895 ct=7.5176 rec=1.3195 | train/val/test=0.821/0.817/0.820 | c=0.998437
[Epoch 0024] loss=20.5461 cls=0.5096 smmd=0.4613 ct=7.5095 rec=1.3191 | train/val/test=0.822/0.816/0.819 | c=0.998437
[Epoch 0025] loss=20.4932 cls=0.5066 smmd=0.4575 ct=7.5034 rec=1.3165 | train/val/test=0.827/0.820/0.822 | c=0.998437
[Epoch 0026] loss=19.7639 cls=0.5002 smmd=0.3841 ct=7.5066 rec=1.3184 | train/val/test=0.828/0.818/0.824 | c=0.998437
[Epoch 0027] loss=19.9994 cls=0.4948 smmd=0.4076 ct=7.5081 rec=1.3192 | train/val/test=0.826/0.818/0.821 | c=0.998437
[Epoch 0028] loss=19.5382 cls=0.4878 smmd=0.3612 ct=7.5119 rec=1.3164 | train/val/test=0.832/0.823/0.828 | c=0.998437
[Epoch 0029] loss=19.3020 cls=0.4784 smmd=0.3406 ct=7.4992 rec=1.3163 | train/val/test=0.833/0.825/0.828 | c=0.998437
[Epoch 0030] loss=19.0642 cls=0.4713 smmd=0.3195 ct=7.4886 rec=1.3132 | train/val/test=0.835/0.829/0.834 | c=0.998437
[Epoch 0031] loss=19.0622 cls=0.4675 smmd=0.3186 ct=7.4935 rec=1.3113 | train/val/test=0.836/0.829/0.832 | c=0.998437
[Epoch 0032] loss=18.5981 cls=0.4601 smmd=0.2718 ct=7.4967 rec=1.3123 | train/val/test=0.835/0.826/0.833 | c=0.998437
[Epoch 0033] loss=18.6271 cls=0.4582 smmd=0.2747 ct=7.4979 rec=1.3109 | train/val/test=0.836/0.835/0.834 | c=0.998437
[Epoch 0034] loss=18.4511 cls=0.4557 smmd=0.2603 ct=7.4827 rec=1.3100 | train/val/test=0.838/0.834/0.837 | c=0.998437
[Epoch 0035] loss=18.2478 cls=0.4544 smmd=0.2397 ct=7.4846 rec=1.3096 | train/val/test=0.839/0.837/0.835 | c=0.998437
[Epoch 0036] loss=18.2445 cls=0.4544 smmd=0.2383 ct=7.4898 rec=1.3095 | train/val/test=0.840/0.832/0.839 | c=0.998437
[Epoch 0037] loss=18.0372 cls=0.4531 smmd=0.2188 ct=7.4837 rec=1.3105 | train/val/test=0.838/0.834/0.838 | c=0.998437
[Epoch 0038] loss=17.8682 cls=0.4552 smmd=0.2023 ct=7.4813 rec=1.3100 | train/val/test=0.838/0.837/0.839 | c=0.998437
[Epoch 0039] loss=17.9988 cls=0.4576 smmd=0.2128 ct=7.4934 rec=1.3107 | train/val/test=0.839/0.832/0.837 | c=0.998437
[Epoch 0040] loss=17.7461 cls=0.4577 smmd=0.1878 ct=7.4918 rec=1.3121 | train/val/test=0.840/0.834/0.839 | c=0.998437
[Epoch 0041] loss=17.7707 cls=0.4593 smmd=0.1933 ct=7.4762 rec=1.3124 | train/val/test=0.837/0.830/0.834 | c=0.998437
[Epoch 0042] loss=17.5689 cls=0.4609 smmd=0.1713 ct=7.4851 rec=1.3112 | train/val/test=0.839/0.835/0.841 | c=0.998437
[Epoch 0043] loss=17.5287 cls=0.4602 smmd=0.1678 ct=7.4819 rec=1.3134 | train/val/test=0.840/0.832/0.839 | c=0.998437
[Epoch 0044] loss=17.5150 cls=0.4595 smmd=0.1665 ct=7.4824 rec=1.3118 | train/val/test=0.840/0.833/0.839 | c=0.998437
[Epoch 0045] loss=17.4341 cls=0.4593 smmd=0.1584 ct=7.4822 rec=1.3121 | train/val/test=0.840/0.834/0.839 | c=0.998437
[Epoch 0046] loss=17.3558 cls=0.4587 smmd=0.1526 ct=7.4718 rec=1.3130 | train/val/test=0.840/0.833/0.838 | c=0.998437
[Epoch 0047] loss=17.2872 cls=0.4592 smmd=0.1449 ct=7.4762 rec=1.3133 | train/val/test=0.841/0.838/0.842 | c=0.998437
[Epoch 0048] loss=17.2200 cls=0.4610 smmd=0.1381 ct=7.4756 rec=1.3146 | train/val/test=0.839/0.836/0.838 | c=0.998437
[Epoch 0049] loss=17.1927 cls=0.4624 smmd=0.1352 ct=7.4760 rec=1.3156 | train/val/test=0.842/0.838/0.843 | c=0.998437
[Epoch 0050] loss=17.2383 cls=0.4639 smmd=0.1392 ct=7.4778 rec=1.3178 | train/val/test=0.839/0.834/0.836 | c=0.998437
[Epoch 0051] loss=17.1729 cls=0.4687 smmd=0.1332 ct=7.4737 rec=1.3177 | train/val/test=0.843/0.838/0.843 | c=0.998437
[Epoch 0052] loss=17.1397 cls=0.4675 smmd=0.1297 ct=7.4747 rec=1.3193 | train/val/test=0.842/0.836/0.841 | c=0.998437
[Epoch 0053] loss=17.1312 cls=0.4687 smmd=0.1289 ct=7.4743 rec=1.3191 | train/val/test=0.842/0.836/0.840 | c=0.998437
[Epoch 0054] loss=17.1073 cls=0.4687 smmd=0.1269 ct=7.4723 rec=1.3192 | train/val/test=0.841/0.840/0.841 | c=0.998437
[Epoch 0055] loss=17.1014 cls=0.4716 smmd=0.1259 ct=7.4737 rec=1.3179 | train/val/test=0.840/0.833/0.839 | c=0.998437
[Epoch 0056] loss=17.1436 cls=0.4689 smmd=0.1324 ct=7.4631 rec=1.3186 | train/val/test=0.841/0.835/0.841 | c=0.998437
[Epoch 0057] loss=17.0828 cls=0.4690 smmd=0.1249 ct=7.4702 rec=1.3178 | train/val/test=0.840/0.835/0.840 | c=0.998437
[Epoch 0058] loss=17.0247 cls=0.4700 smmd=0.1197 ct=7.4671 rec=1.3173 | train/val/test=0.840/0.836/0.842 | c=0.998437
[Epoch 0059] loss=17.0284 cls=0.4711 smmd=0.1215 ct=7.4596 rec=1.3171 | train/val/test=0.840/0.835/0.838 | c=0.998437
[Epoch 0060] loss=17.0010 cls=0.4710 smmd=0.1176 ct=7.4650 rec=1.3189 | train/val/test=0.840/0.835/0.841 | c=0.998437
[Epoch 0061] loss=16.9684 cls=0.4736 smmd=0.1149 ct=7.4621 rec=1.3177 | train/val/test=0.840/0.836/0.840 | c=0.998437
[Epoch 0062] loss=17.0322 cls=0.4741 smmd=0.1208 ct=7.4635 rec=1.3202 | train/val/test=0.839/0.835/0.835 | c=0.998437
[Epoch 0063] loss=17.0610 cls=0.4769 smmd=0.1240 ct=7.4613 rec=1.3199 | train/val/test=0.840/0.838/0.840 | c=0.998437
[Epoch 0064] loss=17.0464 cls=0.4777 smmd=0.1219 ct=7.4634 rec=1.3227 | train/val/test=0.833/0.833/0.830 | c=0.998437
[Epoch 0065] loss=17.0832 cls=0.4843 smmd=0.1268 ct=7.4563 rec=1.3214 | train/val/test=0.836/0.836/0.833 | c=0.998437
[Epoch 0066] loss=17.0673 cls=0.4828 smmd=0.1237 ct=7.4632 rec=1.3253 | train/val/test=0.829/0.823/0.827 | c=0.998437
[Epoch 0067] loss=17.1569 cls=0.4903 smmd=0.1336 ct=7.4569 rec=1.3231 | train/val/test=0.832/0.830/0.826 | c=0.998437
[Epoch 0068] loss=17.2169 cls=0.4891 smmd=0.1400 ct=7.4543 rec=1.3271 | train/val/test=0.819/0.809/0.810 | c=0.998437
[Epoch 0069] loss=17.2551 cls=0.5060 smmd=0.1429 ct=7.4550 rec=1.3272 | train/val/test=0.813/0.811/0.811 | c=0.998437
[Epoch 0070] loss=17.2805 cls=0.5109 smmd=0.1443 ct=7.4577 rec=1.3327 | train/val/test=0.812/0.802/0.800 | c=0.998437
[Epoch 0071] loss=17.3137 cls=0.5177 smmd=0.1482 ct=7.4537 rec=1.3302 | train/val/test=0.818/0.819/0.817 | c=0.998437
[Epoch 0072] loss=17.2381 cls=0.5021 smmd=0.1431 ct=7.4456 rec=1.3292 | train/val/test=0.826/0.821/0.824 | c=0.998437
[Epoch 0073] loss=17.1177 cls=0.4886 smmd=0.1328 ct=7.4421 rec=1.3224 | train/val/test=0.840/0.836/0.836 | c=0.998437
[Epoch 0074] loss=16.9409 cls=0.4731 smmd=0.1169 ct=7.4374 rec=1.3204 | train/val/test=0.839/0.839/0.838 | c=0.998437
[Epoch 0075] loss=16.8861 cls=0.4733 smmd=0.1139 ct=7.4253 rec=1.3199 | train/val/test=0.837/0.837/0.836 | c=0.998437
[Epoch 0076] loss=16.8805 cls=0.4771 smmd=0.1104 ct=7.4380 rec=1.3239 | train/val/test=0.840/0.838/0.840 | c=0.998437
[Epoch 0077] loss=16.9133 cls=0.4837 smmd=0.1141 ct=7.4334 rec=1.3269 | train/val/test=0.835/0.830/0.832 | c=0.998437
[Epoch 0078] loss=16.9817 cls=0.4952 smmd=0.1210 ct=7.4291 rec=1.3312 | train/val/test=0.836/0.837/0.831 | c=0.998437
[Epoch 0079] loss=17.0284 cls=0.4959 smmd=0.1230 ct=7.4419 rec=1.3340 | train/val/test=0.830/0.821/0.824 | c=0.998437
[Epoch 0080] loss=17.0587 cls=0.5097 smmd=0.1284 ct=7.4261 rec=1.3359 | train/val/test=0.824/0.822/0.819 | c=0.998437
[Epoch 0081] loss=17.1446 cls=0.5092 smmd=0.1347 ct=7.4370 rec=1.3388 | train/val/test=0.816/0.802/0.803 | c=0.998437
[Epoch 0082] loss=17.2709 cls=0.5289 smmd=0.1468 ct=7.4342 rec=1.3402 | train/val/test=0.799/0.796/0.792 | c=0.998437
[Epoch 0083] loss=17.2867 cls=0.5298 smmd=0.1492 ct=7.4293 rec=1.3432 | train/val/test=0.811/0.798/0.797 | c=0.998437
[Epoch 0084] loss=17.2325 cls=0.5288 smmd=0.1436 ct=7.4319 rec=1.3375 | train/val/test=0.815/0.813/0.812 | c=0.998437
[Epoch 0085] loss=17.0717 cls=0.5086 smmd=0.1315 ct=7.4179 rec=1.3338 | train/val/test=0.830/0.824/0.828 | c=0.998437
[Epoch 0086] loss=16.9183 cls=0.4804 smmd=0.1209 ct=7.4039 rec=1.3226 | train/val/test=0.838/0.836/0.839 | c=0.998437
[Epoch 0087] loss=16.7658 cls=0.4706 smmd=0.1057 ct=7.4064 rec=1.3205 | train/val/test=0.838/0.835/0.836 | c=0.998437
[Epoch 0088] loss=16.7834 cls=0.4765 smmd=0.1080 ct=7.4017 rec=1.3241 | train/val/test=0.829/0.824/0.827 | c=0.998437
[Epoch 0089] loss=16.8204 cls=0.4924 smmd=0.1095 ct=7.4070 rec=1.3298 | train/val/test=0.831/0.827/0.825 | c=0.998437
[Epoch 0090] loss=16.9518 cls=0.5061 smmd=0.1193 ct=7.4190 rec=1.3363 | train/val/test=0.811/0.804/0.803 | c=0.998437
[Epoch 0091] loss=17.1147 cls=0.5299 smmd=0.1338 ct=7.4195 rec=1.3453 | train/val/test=0.815/0.812/0.813 | c=0.998437
[Epoch 0092] loss=17.2365 cls=0.5290 smmd=0.1458 ct=7.4209 rec=1.3447 | train/val/test=0.798/0.786/0.783 | c=0.998437
[Epoch 0093] loss=17.3355 cls=0.5567 smmd=0.1515 ct=7.4328 rec=1.3525 | train/val/test=0.807/0.804/0.801 | c=0.998437
[Epoch 0094] loss=17.2761 cls=0.5312 smmd=0.1517 ct=7.4104 rec=1.3445 | train/val/test=0.815/0.801/0.800 | c=0.998437
[Epoch 0095] loss=17.1476 cls=0.5260 smmd=0.1383 ct=7.4160 rec=1.3391 | train/val/test=0.834/0.832/0.832 | c=0.998437
[Epoch 0096] loss=16.9113 cls=0.4870 smmd=0.1225 ct=7.3895 rec=1.3280 | train/val/test=0.836/0.834/0.835 | c=0.998437
[Epoch 0097] loss=16.7197 cls=0.4750 smmd=0.1052 ct=7.3848 rec=1.3220 | train/val/test=0.835/0.835/0.833 | c=0.998437
[Epoch 0098] loss=16.7229 cls=0.4784 smmd=0.1040 ct=7.3911 rec=1.3223 | train/val/test=0.837/0.833/0.834 | c=0.998437
[Epoch 0099] loss=16.7835 cls=0.4862 smmd=0.1106 ct=7.3853 rec=1.3277 | train/val/test=0.828/0.819/0.824 | c=0.998437
=== Best @ epoch 54: val=0.8397, test=0.8413 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-2 - 2025-09-21 03:19:37:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-2...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-2 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.0633 cls=1.1013 smmd=5.6309 ct=7.2487 rec=1.4136 | train/val/test=0.396/0.411/0.398 | c=0.998437
[Epoch 0001] loss=52.7062 cls=1.0660 smmd=3.7109 ct=7.1782 rec=1.4149 | train/val/test=0.432/0.450/0.437 | c=0.998437
[Epoch 0002] loss=37.2077 cls=1.0695 smmd=2.1789 ct=7.0888 rec=1.4135 | train/val/test=0.550/0.553/0.549 | c=0.998437
[Epoch 0003] loss=40.6809 cls=1.0498 smmd=2.5272 ct=7.0889 rec=1.4130 | train/val/test=0.565/0.562/0.556 | c=0.998437
[Epoch 0004] loss=41.4591 cls=0.9918 smmd=2.4884 ct=7.6870 rec=1.4107 | train/val/test=0.548/0.547/0.535 | c=0.998437
[Epoch 0005] loss=36.5184 cls=0.9507 smmd=2.0468 ct=7.4363 rec=1.4049 | train/val/test=0.549/0.549/0.537 | c=0.998437
[Epoch 0006] loss=31.6401 cls=0.9251 smmd=1.5617 ct=7.4314 rec=1.3955 | train/val/test=0.549/0.549/0.541 | c=0.998437
[Epoch 0007] loss=34.8640 cls=0.9072 smmd=1.8689 ct=7.5138 rec=1.3878 | train/val/test=0.554/0.553/0.546 | c=0.998437
[Epoch 0008] loss=35.6732 cls=0.8746 smmd=1.9537 ct=7.5048 rec=1.3777 | train/val/test=0.563/0.559/0.550 | c=0.998437
[Epoch 0009] loss=29.4979 cls=0.8431 smmd=1.3434 ct=7.4789 rec=1.3693 | train/val/test=0.574/0.573/0.564 | c=0.998437
[Epoch 0010] loss=27.6065 cls=0.8137 smmd=1.1442 ct=7.5375 rec=1.3660 | train/val/test=0.604/0.597/0.596 | c=0.998437
[Epoch 0011] loss=30.3460 cls=0.7797 smmd=1.4185 ct=7.5440 rec=1.3671 | train/val/test=0.686/0.681/0.677 | c=0.998437
[Epoch 0012] loss=27.7142 cls=0.7400 smmd=1.1639 ct=7.5120 rec=1.3631 | train/val/test=0.710/0.703/0.692 | c=0.998437
[Epoch 0013] loss=26.0485 cls=0.7175 smmd=0.9962 ct=7.5236 rec=1.3617 | train/val/test=0.746/0.734/0.725 | c=0.998437
[Epoch 0014] loss=25.8086 cls=0.6841 smmd=0.9698 ct=7.5446 rec=1.3592 | train/val/test=0.778/0.768/0.768 | c=0.998437
[Epoch 0015] loss=25.5453 cls=0.6486 smmd=0.9504 ct=7.5201 rec=1.3542 | train/val/test=0.800/0.795/0.796 | c=0.998437
[Epoch 0016] loss=24.6229 cls=0.6226 smmd=0.8646 ct=7.4947 rec=1.3527 | train/val/test=0.805/0.797/0.799 | c=0.998437
[Epoch 0017] loss=23.2400 cls=0.6026 smmd=0.7285 ct=7.4902 rec=1.3456 | train/val/test=0.773/0.766/0.768 | c=0.998437
[Epoch 0018] loss=23.2921 cls=0.6181 smmd=0.7261 ct=7.5258 rec=1.3412 | train/val/test=0.784/0.775/0.777 | c=0.998437
[Epoch 0019] loss=22.8003 cls=0.5873 smmd=0.6742 ct=7.5483 rec=1.3365 | train/val/test=0.816/0.813/0.812 | c=0.998437
[Epoch 0020] loss=22.0254 cls=0.5466 smmd=0.6040 ct=7.5232 rec=1.3316 | train/val/test=0.810/0.812/0.809 | c=0.998437
[Epoch 0021] loss=21.6342 cls=0.5482 smmd=0.5715 ct=7.4902 rec=1.3302 | train/val/test=0.814/0.810/0.814 | c=0.998437
[Epoch 0022] loss=21.5312 cls=0.5287 smmd=0.5622 ct=7.4924 rec=1.3210 | train/val/test=0.816/0.810/0.812 | c=0.998437
[Epoch 0023] loss=20.8479 cls=0.5166 smmd=0.4895 ct=7.5176 rec=1.3195 | train/val/test=0.821/0.817/0.820 | c=0.998437
[Epoch 0024] loss=20.5461 cls=0.5096 smmd=0.4613 ct=7.5095 rec=1.3191 | train/val/test=0.822/0.816/0.819 | c=0.998437
[Epoch 0025] loss=20.4932 cls=0.5066 smmd=0.4575 ct=7.5034 rec=1.3165 | train/val/test=0.827/0.820/0.822 | c=0.998437
[Epoch 0026] loss=19.7639 cls=0.5002 smmd=0.3841 ct=7.5066 rec=1.3184 | train/val/test=0.828/0.818/0.824 | c=0.998437
[Epoch 0027] loss=19.9994 cls=0.4948 smmd=0.4076 ct=7.5081 rec=1.3192 | train/val/test=0.826/0.818/0.821 | c=0.998437
[Epoch 0028] loss=19.5382 cls=0.4878 smmd=0.3612 ct=7.5119 rec=1.3164 | train/val/test=0.832/0.823/0.828 | c=0.998437
[Epoch 0029] loss=19.3020 cls=0.4784 smmd=0.3406 ct=7.4992 rec=1.3163 | train/val/test=0.833/0.825/0.828 | c=0.998437
[Epoch 0030] loss=19.0642 cls=0.4713 smmd=0.3195 ct=7.4886 rec=1.3132 | train/val/test=0.835/0.829/0.834 | c=0.998437
[Epoch 0031] loss=19.0622 cls=0.4675 smmd=0.3186 ct=7.4935 rec=1.3113 | train/val/test=0.836/0.829/0.832 | c=0.998437
[Epoch 0032] loss=18.5981 cls=0.4601 smmd=0.2718 ct=7.4967 rec=1.3123 | train/val/test=0.835/0.826/0.833 | c=0.998437
[Epoch 0033] loss=18.6271 cls=0.4582 smmd=0.2747 ct=7.4979 rec=1.3109 | train/val/test=0.836/0.835/0.834 | c=0.998437
[Epoch 0034] loss=18.4511 cls=0.4557 smmd=0.2603 ct=7.4827 rec=1.3100 | train/val/test=0.838/0.834/0.837 | c=0.998437
[Epoch 0035] loss=18.2478 cls=0.4544 smmd=0.2397 ct=7.4846 rec=1.3096 | train/val/test=0.839/0.837/0.835 | c=0.998437
[Epoch 0036] loss=18.2445 cls=0.4544 smmd=0.2383 ct=7.4898 rec=1.3095 | train/val/test=0.840/0.832/0.839 | c=0.998437
[Epoch 0037] loss=18.0372 cls=0.4531 smmd=0.2188 ct=7.4837 rec=1.3105 | train/val/test=0.838/0.834/0.838 | c=0.998437
[Epoch 0038] loss=17.8682 cls=0.4552 smmd=0.2023 ct=7.4813 rec=1.3100 | train/val/test=0.838/0.837/0.839 | c=0.998437
[Epoch 0039] loss=17.9988 cls=0.4576 smmd=0.2128 ct=7.4934 rec=1.3107 | train/val/test=0.839/0.832/0.837 | c=0.998437
[Epoch 0040] loss=17.7461 cls=0.4577 smmd=0.1878 ct=7.4918 rec=1.3121 | train/val/test=0.840/0.834/0.839 | c=0.998437
[Epoch 0041] loss=17.7707 cls=0.4593 smmd=0.1933 ct=7.4762 rec=1.3124 | train/val/test=0.837/0.830/0.834 | c=0.998437
[Epoch 0042] loss=17.5689 cls=0.4609 smmd=0.1713 ct=7.4851 rec=1.3112 | train/val/test=0.839/0.835/0.841 | c=0.998437
[Epoch 0043] loss=17.5287 cls=0.4602 smmd=0.1678 ct=7.4819 rec=1.3134 | train/val/test=0.840/0.832/0.839 | c=0.998437
[Epoch 0044] loss=17.5150 cls=0.4595 smmd=0.1665 ct=7.4824 rec=1.3118 | train/val/test=0.840/0.833/0.839 | c=0.998437
[Epoch 0045] loss=17.4341 cls=0.4593 smmd=0.1584 ct=7.4822 rec=1.3121 | train/val/test=0.840/0.834/0.839 | c=0.998437
[Epoch 0046] loss=17.3558 cls=0.4587 smmd=0.1526 ct=7.4718 rec=1.3130 | train/val/test=0.840/0.833/0.838 | c=0.998437
[Epoch 0047] loss=17.2872 cls=0.4592 smmd=0.1449 ct=7.4762 rec=1.3133 | train/val/test=0.841/0.838/0.842 | c=0.998437
[Epoch 0048] loss=17.2200 cls=0.4610 smmd=0.1381 ct=7.4756 rec=1.3146 | train/val/test=0.839/0.836/0.838 | c=0.998437
[Epoch 0049] loss=17.1927 cls=0.4624 smmd=0.1352 ct=7.4760 rec=1.3156 | train/val/test=0.842/0.838/0.843 | c=0.998437
[Epoch 0050] loss=17.2383 cls=0.4639 smmd=0.1392 ct=7.4778 rec=1.3178 | train/val/test=0.839/0.834/0.836 | c=0.998437
[Epoch 0051] loss=17.1729 cls=0.4687 smmd=0.1332 ct=7.4737 rec=1.3177 | train/val/test=0.843/0.838/0.843 | c=0.998437
[Epoch 0052] loss=17.1397 cls=0.4675 smmd=0.1297 ct=7.4747 rec=1.3193 | train/val/test=0.842/0.836/0.841 | c=0.998437
[Epoch 0053] loss=17.1312 cls=0.4687 smmd=0.1289 ct=7.4743 rec=1.3191 | train/val/test=0.842/0.836/0.840 | c=0.998437
[Epoch 0054] loss=17.1073 cls=0.4687 smmd=0.1269 ct=7.4723 rec=1.3192 | train/val/test=0.841/0.840/0.841 | c=0.998437
[Epoch 0055] loss=17.1014 cls=0.4716 smmd=0.1259 ct=7.4737 rec=1.3179 | train/val/test=0.840/0.833/0.839 | c=0.998437
[Epoch 0056] loss=17.1436 cls=0.4689 smmd=0.1324 ct=7.4631 rec=1.3186 | train/val/test=0.841/0.835/0.841 | c=0.998437
[Epoch 0057] loss=17.0828 cls=0.4690 smmd=0.1249 ct=7.4702 rec=1.3178 | train/val/test=0.840/0.835/0.840 | c=0.998437
[Epoch 0058] loss=17.0247 cls=0.4700 smmd=0.1197 ct=7.4671 rec=1.3173 | train/val/test=0.840/0.836/0.842 | c=0.998437
[Epoch 0059] loss=17.0284 cls=0.4711 smmd=0.1215 ct=7.4596 rec=1.3171 | train/val/test=0.840/0.835/0.838 | c=0.998437
[Epoch 0060] loss=17.0010 cls=0.4710 smmd=0.1176 ct=7.4650 rec=1.3189 | train/val/test=0.840/0.835/0.841 | c=0.998437
[Epoch 0061] loss=16.9684 cls=0.4736 smmd=0.1149 ct=7.4621 rec=1.3177 | train/val/test=0.840/0.836/0.840 | c=0.998437
[Epoch 0062] loss=17.0322 cls=0.4741 smmd=0.1208 ct=7.4635 rec=1.3202 | train/val/test=0.839/0.835/0.835 | c=0.998437
[Epoch 0063] loss=17.0610 cls=0.4769 smmd=0.1240 ct=7.4613 rec=1.3199 | train/val/test=0.840/0.838/0.840 | c=0.998437
[Epoch 0064] loss=17.0464 cls=0.4777 smmd=0.1219 ct=7.4634 rec=1.3227 | train/val/test=0.833/0.833/0.830 | c=0.998437
[Epoch 0065] loss=17.0832 cls=0.4843 smmd=0.1268 ct=7.4563 rec=1.3214 | train/val/test=0.836/0.836/0.833 | c=0.998437
[Epoch 0066] loss=17.0673 cls=0.4828 smmd=0.1237 ct=7.4632 rec=1.3253 | train/val/test=0.829/0.823/0.827 | c=0.998437
[Epoch 0067] loss=17.1569 cls=0.4903 smmd=0.1336 ct=7.4569 rec=1.3231 | train/val/test=0.832/0.830/0.826 | c=0.998437
[Epoch 0068] loss=17.2169 cls=0.4891 smmd=0.1400 ct=7.4543 rec=1.3271 | train/val/test=0.819/0.809/0.810 | c=0.998437
[Epoch 0069] loss=17.2551 cls=0.5060 smmd=0.1429 ct=7.4550 rec=1.3272 | train/val/test=0.813/0.811/0.811 | c=0.998437
[Epoch 0070] loss=17.2805 cls=0.5109 smmd=0.1443 ct=7.4577 rec=1.3327 | train/val/test=0.812/0.802/0.800 | c=0.998437
[Epoch 0071] loss=17.3137 cls=0.5177 smmd=0.1482 ct=7.4537 rec=1.3302 | train/val/test=0.818/0.819/0.817 | c=0.998437
[Epoch 0072] loss=17.2381 cls=0.5021 smmd=0.1431 ct=7.4456 rec=1.3292 | train/val/test=0.826/0.821/0.824 | c=0.998437
[Epoch 0073] loss=17.1177 cls=0.4886 smmd=0.1328 ct=7.4421 rec=1.3224 | train/val/test=0.840/0.836/0.836 | c=0.998437
[Epoch 0074] loss=16.9409 cls=0.4731 smmd=0.1169 ct=7.4374 rec=1.3204 | train/val/test=0.839/0.839/0.838 | c=0.998437
[Epoch 0075] loss=16.8861 cls=0.4733 smmd=0.1139 ct=7.4253 rec=1.3199 | train/val/test=0.837/0.837/0.836 | c=0.998437
[Epoch 0076] loss=16.8805 cls=0.4771 smmd=0.1104 ct=7.4380 rec=1.3239 | train/val/test=0.840/0.838/0.840 | c=0.998437
[Epoch 0077] loss=16.9133 cls=0.4837 smmd=0.1141 ct=7.4334 rec=1.3269 | train/val/test=0.835/0.830/0.832 | c=0.998437
[Epoch 0078] loss=16.9817 cls=0.4952 smmd=0.1210 ct=7.4291 rec=1.3312 | train/val/test=0.836/0.837/0.831 | c=0.998437
[Epoch 0079] loss=17.0284 cls=0.4959 smmd=0.1230 ct=7.4419 rec=1.3340 | train/val/test=0.830/0.821/0.824 | c=0.998437
[Epoch 0080] loss=17.0587 cls=0.5097 smmd=0.1284 ct=7.4261 rec=1.3359 | train/val/test=0.824/0.822/0.819 | c=0.998437
[Epoch 0081] loss=17.1446 cls=0.5092 smmd=0.1347 ct=7.4370 rec=1.3388 | train/val/test=0.816/0.802/0.803 | c=0.998437
[Epoch 0082] loss=17.2709 cls=0.5289 smmd=0.1468 ct=7.4342 rec=1.3402 | train/val/test=0.799/0.796/0.792 | c=0.998437
[Epoch 0083] loss=17.2867 cls=0.5298 smmd=0.1492 ct=7.4293 rec=1.3432 | train/val/test=0.811/0.798/0.797 | c=0.998437
[Epoch 0084] loss=17.2325 cls=0.5288 smmd=0.1436 ct=7.4319 rec=1.3375 | train/val/test=0.815/0.813/0.812 | c=0.998437
[Epoch 0085] loss=17.0717 cls=0.5086 smmd=0.1315 ct=7.4179 rec=1.3338 | train/val/test=0.830/0.824/0.828 | c=0.998437
[Epoch 0086] loss=16.9183 cls=0.4804 smmd=0.1209 ct=7.4039 rec=1.3226 | train/val/test=0.838/0.836/0.839 | c=0.998437
[Epoch 0087] loss=16.7658 cls=0.4706 smmd=0.1057 ct=7.4064 rec=1.3205 | train/val/test=0.838/0.835/0.836 | c=0.998437
[Epoch 0088] loss=16.7834 cls=0.4765 smmd=0.1080 ct=7.4017 rec=1.3241 | train/val/test=0.829/0.824/0.827 | c=0.998437
[Epoch 0089] loss=16.8204 cls=0.4924 smmd=0.1095 ct=7.4070 rec=1.3298 | train/val/test=0.831/0.827/0.825 | c=0.998437
[Epoch 0090] loss=16.9518 cls=0.5061 smmd=0.1193 ct=7.4190 rec=1.3363 | train/val/test=0.811/0.804/0.803 | c=0.998437
[Epoch 0091] loss=17.1147 cls=0.5299 smmd=0.1338 ct=7.4195 rec=1.3453 | train/val/test=0.815/0.812/0.813 | c=0.998437
[Epoch 0092] loss=17.2365 cls=0.5290 smmd=0.1458 ct=7.4209 rec=1.3447 | train/val/test=0.798/0.786/0.783 | c=0.998437
[Epoch 0093] loss=17.3355 cls=0.5567 smmd=0.1515 ct=7.4328 rec=1.3525 | train/val/test=0.807/0.804/0.801 | c=0.998437
[Epoch 0094] loss=17.2761 cls=0.5312 smmd=0.1517 ct=7.4104 rec=1.3445 | train/val/test=0.815/0.801/0.800 | c=0.998437
[Epoch 0095] loss=17.1476 cls=0.5260 smmd=0.1383 ct=7.4160 rec=1.3391 | train/val/test=0.834/0.832/0.832 | c=0.998437
[Epoch 0096] loss=16.9113 cls=0.4870 smmd=0.1225 ct=7.3895 rec=1.3280 | train/val/test=0.836/0.834/0.835 | c=0.998437
[Epoch 0097] loss=16.7197 cls=0.4750 smmd=0.1052 ct=7.3848 rec=1.3220 | train/val/test=0.835/0.835/0.833 | c=0.998437
[Epoch 0098] loss=16.7229 cls=0.4784 smmd=0.1040 ct=7.3911 rec=1.3223 | train/val/test=0.837/0.833/0.834 | c=0.998437
[Epoch 0099] loss=16.7835 cls=0.4862 smmd=0.1106 ct=7.3853 rec=1.3277 | train/val/test=0.828/0.819/0.824 | c=0.998437
=== Best @ epoch 54: val=0.8397, test=0.8413 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-2 completed in 138.21 seconds.
==================================================
