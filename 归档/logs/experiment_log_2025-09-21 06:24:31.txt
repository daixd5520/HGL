Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-3 - 2025-09-21 06:24:31:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-3...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.8624 cls=1.7929 smmd=4.1009 ct=9.4740 rec=1.3917 | train/val/test=0.200/0.174/0.181 | c=0.998347
[Epoch 0001] loss=37.6929 cls=1.7862 smmd=3.9248 ct=9.4790 rec=1.3917 | train/val/test=0.380/0.154/0.154 | c=0.998347
[Epoch 0002] loss=36.5997 cls=1.7773 smmd=3.0073 ct=9.3935 rec=1.3917 | train/val/test=0.320/0.100/0.119 | c=0.998347
[Epoch 0003] loss=35.8757 cls=1.7623 smmd=2.4682 ct=9.3049 rec=1.3917 | train/val/test=0.580/0.290/0.291 | c=0.998347
[Epoch 0004] loss=35.0756 cls=1.7369 smmd=2.1291 ct=9.0813 rec=1.3916 | train/val/test=0.500/0.328/0.309 | c=0.998347
[Epoch 0005] loss=34.6737 cls=1.7030 smmd=1.8030 ct=9.0533 rec=1.3913 | train/val/test=0.640/0.426/0.419 | c=0.998347
[Epoch 0006] loss=34.4878 cls=1.6607 smmd=1.7477 ct=9.0014 rec=1.3907 | train/val/test=0.720/0.488/0.467 | c=0.998347
[Epoch 0007] loss=34.2704 cls=1.6156 smmd=1.5699 ct=8.9970 rec=1.3899 | train/val/test=0.680/0.484/0.486 | c=0.998347
[Epoch 0008] loss=33.9846 cls=1.5706 smmd=1.3346 ct=8.9886 rec=1.3887 | train/val/test=0.700/0.498/0.493 | c=0.998347
[Epoch 0009] loss=33.9727 cls=1.5269 smmd=1.3601 ct=8.9871 rec=1.3875 | train/val/test=0.760/0.522/0.532 | c=0.998347
[Epoch 0010] loss=35.2135 cls=1.4810 smmd=1.2495 ct=9.6797 rec=1.3864 | train/val/test=0.780/0.552/0.567 | c=0.998347
[Epoch 0011] loss=34.8992 cls=1.4365 smmd=1.2466 ct=9.5367 rec=1.3861 | train/val/test=0.840/0.514/0.547 | c=0.998347
[Epoch 0012] loss=34.8774 cls=1.3941 smmd=1.4463 ct=9.4406 rec=1.3853 | train/val/test=0.820/0.508/0.517 | c=0.998347
[Epoch 0013] loss=34.8769 cls=1.3531 smmd=1.4520 ct=9.4538 rec=1.3841 | train/val/test=0.860/0.584/0.578 | c=0.998347
[Epoch 0014] loss=34.5418 cls=1.3012 smmd=1.0843 ct=9.4843 rec=1.3838 | train/val/test=0.880/0.574/0.572 | c=0.998347
[Epoch 0015] loss=34.4637 cls=1.2491 smmd=0.8569 ct=9.5765 rec=1.3829 | train/val/test=0.860/0.550/0.518 | c=0.998347
[Epoch 0016] loss=34.4581 cls=1.2007 smmd=0.8231 ct=9.6132 rec=1.3808 | train/val/test=0.900/0.584/0.569 | c=0.998347
[Epoch 0017] loss=34.3531 cls=1.1388 smmd=0.8933 ct=9.5455 rec=1.3799 | train/val/test=0.860/0.562/0.507 | c=0.998347
[Epoch 0018] loss=34.2283 cls=1.0877 smmd=0.8766 ct=9.5304 rec=1.3747 | train/val/test=0.940/0.548/0.557 | c=0.998347
[Epoch 0019] loss=34.0678 cls=1.0137 smmd=0.8496 ct=9.4993 rec=1.3713 | train/val/test=0.920/0.602/0.563 | c=0.998347
[Epoch 0020] loss=33.9052 cls=0.9586 smmd=0.7361 ct=9.5265 rec=1.3637 | train/val/test=0.920/0.600/0.555 | c=0.998347
[Epoch 0021] loss=33.7649 cls=0.9055 smmd=0.6452 ct=9.5512 rec=1.3565 | train/val/test=0.960/0.596/0.576 | c=0.998347
[Epoch 0022] loss=33.6220 cls=0.8459 smmd=0.5701 ct=9.5656 rec=1.3498 | train/val/test=0.920/0.592/0.549 | c=0.998347
[Epoch 0023] loss=33.5279 cls=0.8167 smmd=0.5357 ct=9.5813 rec=1.3421 | train/val/test=0.920/0.590/0.567 | c=0.998347
[Epoch 0024] loss=33.4151 cls=0.7750 smmd=0.5660 ct=9.5548 rec=1.3352 | train/val/test=0.920/0.596/0.573 | c=0.998347
[Epoch 0025] loss=33.3119 cls=0.7349 smmd=0.5797 ct=9.5382 rec=1.3288 | train/val/test=0.920/0.588/0.566 | c=0.998347
[Epoch 0026] loss=33.2574 cls=0.7119 smmd=0.5593 ct=9.5523 rec=1.3238 | train/val/test=0.960/0.616/0.596 | c=0.998347
[Epoch 0027] loss=33.1185 cls=0.6671 smmd=0.4710 ct=9.5680 rec=1.3178 | train/val/test=0.960/0.604/0.599 | c=0.998347
[Epoch 0028] loss=33.0428 cls=0.6426 smmd=0.4232 ct=9.5812 rec=1.3136 | train/val/test=0.960/0.618/0.606 | c=0.998347
[Epoch 0029] loss=32.9749 cls=0.6112 smmd=0.4202 ct=9.5776 rec=1.3094 | train/val/test=0.960/0.624/0.613 | c=0.998347
[Epoch 0030] loss=32.8948 cls=0.5726 smmd=0.4343 ct=9.5643 rec=1.3046 | train/val/test=0.960/0.618/0.617 | c=0.998347
[Epoch 0031] loss=32.8363 cls=0.5499 smmd=0.4137 ct=9.5659 rec=1.3016 | train/val/test=0.960/0.638/0.637 | c=0.998347
[Epoch 0032] loss=32.7705 cls=0.5049 smmd=0.4177 ct=9.5686 rec=1.2963 | train/val/test=0.960/0.622/0.620 | c=0.998347
[Epoch 0033] loss=32.6812 cls=0.4890 smmd=0.3522 ct=9.5785 rec=1.2927 | train/val/test=0.960/0.638/0.642 | c=0.998347
[Epoch 0034] loss=32.6238 cls=0.4473 smmd=0.3818 ct=9.5765 rec=1.2865 | train/val/test=0.960/0.624/0.624 | c=0.998347
[Epoch 0035] loss=32.5335 cls=0.4350 smmd=0.3341 ct=9.5858 rec=1.2810 | train/val/test=0.960/0.630/0.637 | c=0.998347
[Epoch 0036] loss=32.4650 cls=0.3947 smmd=0.3885 ct=9.5721 rec=1.2735 | train/val/test=0.960/0.634/0.627 | c=0.998347
[Epoch 0037] loss=32.3831 cls=0.3900 smmd=0.3683 ct=9.5817 rec=1.2656 | train/val/test=0.960/0.636/0.639 | c=0.998347
[Epoch 0038] loss=32.2864 cls=0.3521 smmd=0.3880 ct=9.5717 rec=1.2579 | train/val/test=0.960/0.644/0.643 | c=0.998347
[Epoch 0039] loss=32.1956 cls=0.3503 smmd=0.3518 ct=9.5853 rec=1.2498 | train/val/test=0.960/0.646/0.647 | c=0.998347
[Epoch 0040] loss=32.0982 cls=0.3228 smmd=0.3490 ct=9.5808 rec=1.2426 | train/val/test=0.960/0.648/0.648 | c=0.998347
[Epoch 0041] loss=32.0410 cls=0.3101 smmd=0.3573 ct=9.5815 rec=1.2366 | train/val/test=0.960/0.654/0.652 | c=0.998347
[Epoch 0042] loss=31.9910 cls=0.3034 smmd=0.3546 ct=9.5840 rec=1.2317 | train/val/test=0.980/0.656/0.657 | c=0.998347
[Epoch 0043] loss=31.9525 cls=0.2833 smmd=0.3744 ct=9.5746 rec=1.2287 | train/val/test=0.980/0.648/0.652 | c=0.998347
[Epoch 0044] loss=31.9119 cls=0.2900 smmd=0.3334 ct=9.5940 rec=1.2246 | train/val/test=0.980/0.656/0.654 | c=0.998347
[Epoch 0045] loss=31.8955 cls=0.2662 smmd=0.3677 ct=9.5809 rec=1.2233 | train/val/test=0.980/0.654/0.659 | c=0.998347
[Epoch 0046] loss=31.8519 cls=0.2797 smmd=0.3162 ct=9.6071 rec=1.2182 | train/val/test=0.980/0.652/0.656 | c=0.998347
[Epoch 0047] loss=31.8184 cls=0.2526 smmd=0.3580 ct=9.5802 rec=1.2174 | train/val/test=0.980/0.656/0.660 | c=0.998347
[Epoch 0048] loss=31.7842 cls=0.2698 smmd=0.3373 ct=9.6019 rec=1.2108 | train/val/test=0.980/0.652/0.660 | c=0.998347
[Epoch 0049] loss=31.7222 cls=0.2419 smmd=0.3565 ct=9.5810 rec=1.2083 | train/val/test=0.980/0.656/0.665 | c=0.998347
[Epoch 0050] loss=31.6446 cls=0.2450 smmd=0.2960 ct=9.5983 rec=1.2029 | train/val/test=0.980/0.658/0.664 | c=0.998347
[Epoch 0051] loss=31.6107 cls=0.2333 smmd=0.3129 ct=9.5881 rec=1.2005 | train/val/test=0.980/0.656/0.666 | c=0.998347
[Epoch 0052] loss=31.5974 cls=0.2224 smmd=0.3230 ct=9.5836 rec=1.1996 | train/val/test=0.980/0.658/0.668 | c=0.998347
[Epoch 0053] loss=31.5976 cls=0.2296 smmd=0.2997 ct=9.6015 rec=1.1980 | train/val/test=0.980/0.658/0.663 | c=0.998347
[Epoch 0054] loss=31.6191 cls=0.2153 smmd=0.3348 ct=9.5819 rec=1.2013 | train/val/test=0.980/0.660/0.668 | c=0.998347
[Epoch 0055] loss=31.7000 cls=0.2450 smmd=0.3357 ct=9.6309 rec=1.1980 | train/val/test=0.960/0.650/0.668 | c=0.998347
[Epoch 0056] loss=31.8324 cls=0.2230 smmd=0.4778 ct=9.5891 rec=1.2065 | train/val/test=0.980/0.656/0.659 | c=0.998347
[Epoch 0057] loss=31.7458 cls=0.2588 smmd=0.3780 ct=9.6518 rec=1.1935 | train/val/test=0.980/0.656/0.672 | c=0.998347
[Epoch 0058] loss=31.4930 cls=0.2025 smmd=0.3883 ct=9.5842 rec=1.1835 | train/val/test=0.980/0.660/0.669 | c=0.998347
[Epoch 0059] loss=31.4461 cls=0.1913 smmd=0.3828 ct=9.5888 rec=1.1790 | train/val/test=0.980/0.664/0.665 | c=0.998347
[Epoch 0060] loss=31.5416 cls=0.2245 smmd=0.3555 ct=9.6326 rec=1.1809 | train/val/test=0.980/0.660/0.675 | c=0.998347
[Epoch 0061] loss=31.4601 cls=0.1836 smmd=0.3854 ct=9.5835 rec=1.1816 | train/val/test=0.980/0.656/0.671 | c=0.998347
[Epoch 0062] loss=31.3936 cls=0.1790 smmd=0.3298 ct=9.5877 rec=1.1799 | train/val/test=0.980/0.648/0.666 | c=0.998347
[Epoch 0063] loss=31.5102 cls=0.2066 smmd=0.3049 ct=9.6286 rec=1.1845 | train/val/test=0.980/0.662/0.680 | c=0.998347
[Epoch 0064] loss=31.7269 cls=0.1944 smmd=0.4366 ct=9.5898 rec=1.2014 | train/val/test=0.980/0.650/0.660 | c=0.998347
[Epoch 0065] loss=31.7650 cls=0.2544 smmd=0.3883 ct=9.6607 rec=1.1928 | train/val/test=0.960/0.668/0.682 | c=0.998347
[Epoch 0066] loss=31.6037 cls=0.1854 smmd=0.4716 ct=9.5941 rec=1.1851 | train/val/test=0.980/0.656/0.674 | c=0.998347
[Epoch 0067] loss=31.3235 cls=0.1816 smmd=0.3505 ct=9.5911 rec=1.1700 | train/val/test=0.960/0.648/0.666 | c=0.998347
[Epoch 0068] loss=31.5539 cls=0.2446 smmd=0.3907 ct=9.6466 rec=1.1748 | train/val/test=0.980/0.662/0.678 | c=0.998347
[Epoch 0069] loss=31.4379 cls=0.1705 smmd=0.4626 ct=9.5917 rec=1.1707 | train/val/test=0.980/0.660/0.672 | c=0.998347
[Epoch 0070] loss=31.3404 cls=0.1643 smmd=0.3984 ct=9.5847 rec=1.1691 | train/val/test=0.960/0.650/0.663 | c=0.998347
[Epoch 0071] loss=31.5468 cls=0.2182 smmd=0.3900 ct=9.6483 rec=1.1751 | train/val/test=0.980/0.666/0.673 | c=0.998347
[Epoch 0072] loss=31.3889 cls=0.1532 smmd=0.3782 ct=9.5877 rec=1.1759 | train/val/test=0.980/0.656/0.670 | c=0.998347
[Epoch 0073] loss=31.3155 cls=0.1585 smmd=0.3274 ct=9.5833 rec=1.1742 | train/val/test=0.980/0.658/0.668 | c=0.998347
[Epoch 0074] loss=31.5728 cls=0.2021 smmd=0.3523 ct=9.6540 rec=1.1811 | train/val/test=0.960/0.652/0.682 | c=0.998347
[Epoch 0075] loss=31.6894 cls=0.1830 smmd=0.4777 ct=9.5927 rec=1.1935 | train/val/test=0.980/0.658/0.667 | c=0.998347
[Epoch 0076] loss=31.4003 cls=0.1862 smmd=0.3339 ct=9.6226 rec=1.1728 | train/val/test=0.980/0.660/0.675 | c=0.998347
[Epoch 0077] loss=31.3429 cls=0.1979 smmd=0.3622 ct=9.6092 rec=1.1663 | train/val/test=0.980/0.666/0.677 | c=0.998347
[Epoch 0078] loss=31.4125 cls=0.1601 smmd=0.4416 ct=9.5993 rec=1.1692 | train/val/test=0.980/0.654/0.663 | c=0.998347
[Epoch 0079] loss=31.3043 cls=0.1639 smmd=0.3795 ct=9.5996 rec=1.1644 | train/val/test=0.980/0.656/0.669 | c=0.998347
[Epoch 0080] loss=31.4140 cls=0.2096 smmd=0.3910 ct=9.6238 rec=1.1671 | train/val/test=0.980/0.666/0.674 | c=0.998347
[Epoch 0081] loss=31.4129 cls=0.1526 smmd=0.4309 ct=9.5956 rec=1.1715 | train/val/test=0.980/0.648/0.662 | c=0.998347
[Epoch 0082] loss=31.3810 cls=0.1575 smmd=0.3920 ct=9.5955 rec=1.1719 | train/val/test=0.980/0.656/0.668 | c=0.998347
[Epoch 0083] loss=31.4300 cls=0.1852 smmd=0.3495 ct=9.6363 rec=1.1715 | train/val/test=0.980/0.660/0.683 | c=0.998347
[Epoch 0084] loss=31.5198 cls=0.1657 smmd=0.4390 ct=9.5923 rec=1.1813 | train/val/test=0.980/0.644/0.657 | c=0.998347
[Epoch 0085] loss=31.5019 cls=0.1810 smmd=0.4045 ct=9.6229 rec=1.1761 | train/val/test=0.980/0.648/0.669 | c=0.998347
[Epoch 0086] loss=31.2546 cls=0.1666 smmd=0.3330 ct=9.6049 rec=1.1629 | train/val/test=0.980/0.656/0.679 | c=0.998347
[Epoch 0087] loss=31.4374 cls=0.1711 smmd=0.4452 ct=9.5991 rec=1.1709 | train/val/test=0.980/0.644/0.661 | c=0.998347
[Epoch 0088] loss=31.4133 cls=0.1693 smmd=0.4304 ct=9.6149 rec=1.1668 | train/val/test=0.980/0.644/0.663 | c=0.998347
[Epoch 0089] loss=31.2334 cls=0.1642 smmd=0.3169 ct=9.6098 rec=1.1615 | train/val/test=0.980/0.656/0.680 | c=0.998347
[Epoch 0090] loss=31.5013 cls=0.1713 smmd=0.4763 ct=9.6039 rec=1.1732 | train/val/test=0.980/0.650/0.664 | c=0.998347
[Epoch 0091] loss=31.2513 cls=0.1505 smmd=0.3409 ct=9.5979 rec=1.1639 | train/val/test=0.980/0.648/0.655 | c=0.998347
[Epoch 0092] loss=31.3415 cls=0.1567 smmd=0.3419 ct=9.6175 rec=1.1686 | train/val/test=0.980/0.658/0.677 | c=0.998347
[Epoch 0093] loss=31.4486 cls=0.1694 smmd=0.4149 ct=9.5974 rec=1.1754 | train/val/test=0.980/0.650/0.661 | c=0.998347
[Epoch 0094] loss=31.2374 cls=0.1491 smmd=0.2845 ct=9.6090 rec=1.1660 | train/val/test=0.980/0.650/0.659 | c=0.998347
[Epoch 0095] loss=31.3048 cls=0.1507 smmd=0.3440 ct=9.5937 rec=1.1698 | train/val/test=0.980/0.658/0.674 | c=0.998347
[Epoch 0096] loss=31.3210 cls=0.1592 smmd=0.3516 ct=9.6002 rec=1.1689 | train/val/test=0.980/0.648/0.664 | c=0.998347
[Epoch 0097] loss=31.2305 cls=0.1676 smmd=0.3010 ct=9.6019 rec=1.1642 | train/val/test=0.980/0.652/0.660 | c=0.998347
[Epoch 0098] loss=31.2700 cls=0.1400 smmd=0.3308 ct=9.5947 rec=1.1680 | train/val/test=0.980/0.656/0.670 | c=0.998347
[Epoch 0099] loss=31.2502 cls=0.1686 smmd=0.3307 ct=9.5890 rec=1.1657 | train/val/test=0.980/0.652/0.660 | c=0.998347
[Epoch 0100] loss=31.2515 cls=0.1648 smmd=0.2815 ct=9.6119 rec=1.1664 | train/val/test=0.980/0.642/0.664 | c=0.998347
[Epoch 0101] loss=31.3034 cls=0.1475 smmd=0.3562 ct=9.5819 rec=1.1710 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0102] loss=31.2704 cls=0.1560 smmd=0.2927 ct=9.6155 rec=1.1669 | train/val/test=0.960/0.652/0.665 | c=0.998347
[Epoch 0103] loss=31.3036 cls=0.1754 smmd=0.3397 ct=9.5970 rec=1.1682 | train/val/test=0.980/0.652/0.665 | c=0.998347
[Epoch 0104] loss=31.3530 cls=0.1386 smmd=0.3473 ct=9.6081 rec=1.1720 | train/val/test=0.980/0.646/0.668 | c=0.998347
[Epoch 0105] loss=31.2650 cls=0.1799 smmd=0.3193 ct=9.5985 rec=1.1659 | train/val/test=0.980/0.650/0.666 | c=0.998347
[Epoch 0106] loss=31.2091 cls=0.1408 smmd=0.3130 ct=9.5977 rec=1.1630 | train/val/test=0.980/0.644/0.665 | c=0.998347
[Epoch 0107] loss=31.1729 cls=0.1450 smmd=0.2957 ct=9.5901 rec=1.1625 | train/val/test=0.980/0.642/0.664 | c=0.998347
[Epoch 0108] loss=31.1826 cls=0.1601 smmd=0.2974 ct=9.5908 rec=1.1624 | train/val/test=0.980/0.652/0.669 | c=0.998347
[Epoch 0109] loss=31.2387 cls=0.1493 smmd=0.2827 ct=9.6047 rec=1.1672 | train/val/test=0.980/0.644/0.664 | c=0.998347
[Epoch 0110] loss=31.2932 cls=0.1666 smmd=0.3272 ct=9.5879 rec=1.1707 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0111] loss=31.2906 cls=0.1504 smmd=0.2833 ct=9.6130 rec=1.1706 | train/val/test=0.980/0.654/0.667 | c=0.998347
[Epoch 0112] loss=31.3299 cls=0.1778 smmd=0.3418 ct=9.5937 rec=1.1712 | train/val/test=0.980/0.650/0.660 | c=0.998347
[Epoch 0113] loss=31.3309 cls=0.1550 smmd=0.3249 ct=9.6217 rec=1.1685 | train/val/test=0.980/0.654/0.666 | c=0.998347
[Epoch 0114] loss=31.1897 cls=0.1358 smmd=0.3286 ct=9.5811 rec=1.1631 | train/val/test=0.980/0.650/0.666 | c=0.998347
[Epoch 0115] loss=31.1704 cls=0.1550 smmd=0.3019 ct=9.6010 rec=1.1589 | train/val/test=0.980/0.654/0.661 | c=0.998347
[Epoch 0116] loss=31.1756 cls=0.1313 smmd=0.3024 ct=9.5964 rec=1.1615 | train/val/test=0.980/0.648/0.664 | c=0.998347
[Epoch 0117] loss=31.1829 cls=0.1461 smmd=0.3173 ct=9.5796 rec=1.1633 | train/val/test=0.980/0.652/0.668 | c=0.998347
[Epoch 0118] loss=31.2753 cls=0.1637 smmd=0.2899 ct=9.6195 rec=1.1665 | train/val/test=0.980/0.648/0.667 | c=0.998347
[Epoch 0119] loss=31.2938 cls=0.1480 smmd=0.3280 ct=9.5811 rec=1.1730 | train/val/test=0.980/0.650/0.668 | c=0.998347
[Epoch 0120] loss=31.2782 cls=0.1670 smmd=0.2720 ct=9.6206 rec=1.1681 | train/val/test=0.980/0.656/0.664 | c=0.998347
[Epoch 0121] loss=31.2497 cls=0.1572 smmd=0.3190 ct=9.5827 rec=1.1687 | train/val/test=0.980/0.650/0.657 | c=0.998347
[Epoch 0122] loss=31.2766 cls=0.1554 smmd=0.2969 ct=9.6160 rec=1.1670 | train/val/test=0.980/0.660/0.667 | c=0.998347
[Epoch 0123] loss=31.1969 cls=0.1495 smmd=0.3157 ct=9.5872 rec=1.1632 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0124] loss=31.1501 cls=0.1410 smmd=0.2987 ct=9.5946 rec=1.1592 | train/val/test=0.980/0.654/0.660 | c=0.998347
[Epoch 0125] loss=31.1482 cls=0.1276 smmd=0.2835 ct=9.5949 rec=1.1611 | train/val/test=0.980/0.646/0.665 | c=0.998347
[Epoch 0126] loss=31.1797 cls=0.1468 smmd=0.3064 ct=9.5846 rec=1.1631 | train/val/test=0.980/0.650/0.658 | c=0.998347
[Epoch 0127] loss=31.2229 cls=0.1454 smmd=0.2748 ct=9.6076 rec=1.1660 | train/val/test=0.980/0.644/0.664 | c=0.998347
[Epoch 0128] loss=31.2518 cls=0.1483 smmd=0.3201 ct=9.5811 rec=1.1695 | train/val/test=0.980/0.650/0.662 | c=0.998347
[Epoch 0129] loss=31.2262 cls=0.1512 smmd=0.2568 ct=9.6128 rec=1.1668 | train/val/test=0.980/0.644/0.665 | c=0.998347
[Epoch 0130] loss=31.2063 cls=0.1560 smmd=0.3031 ct=9.5842 rec=1.1657 | train/val/test=0.980/0.654/0.662 | c=0.998347
[Epoch 0131] loss=31.2374 cls=0.1498 smmd=0.2887 ct=9.6083 rec=1.1657 | train/val/test=0.980/0.652/0.663 | c=0.998347
[Epoch 0132] loss=31.2015 cls=0.1497 smmd=0.3146 ct=9.5903 rec=1.1631 | train/val/test=0.980/0.650/0.661 | c=0.998347
[Epoch 0133] loss=31.1228 cls=0.1423 smmd=0.2690 ct=9.5961 rec=1.1590 | train/val/test=0.980/0.654/0.661 | c=0.998347
[Epoch 0134] loss=31.1675 cls=0.1235 smmd=0.2993 ct=9.5865 rec=1.1633 | train/val/test=0.960/0.652/0.663 | c=0.998347
[Epoch 0135] loss=31.2292 cls=0.1644 smmd=0.3030 ct=9.6032 rec=1.1638 | train/val/test=0.980/0.652/0.665 | c=0.998347
[Epoch 0136] loss=31.2299 cls=0.1323 smmd=0.3016 ct=9.5928 rec=1.1677 | train/val/test=0.980/0.642/0.660 | c=0.998347
[Epoch 0137] loss=31.3115 cls=0.1859 smmd=0.3256 ct=9.6011 rec=1.1691 | train/val/test=0.980/0.654/0.670 | c=0.998347
[Epoch 0138] loss=31.3623 cls=0.1448 smmd=0.3508 ct=9.6123 rec=1.1715 | train/val/test=0.980/0.640/0.664 | c=0.998347
[Epoch 0139] loss=31.2987 cls=0.1866 smmd=0.3528 ct=9.6037 rec=1.1645 | train/val/test=0.980/0.654/0.657 | c=0.998347
[Epoch 0140] loss=31.1304 cls=0.1330 smmd=0.3122 ct=9.5849 rec=1.1582 | train/val/test=0.980/0.648/0.666 | c=0.998347
[Epoch 0141] loss=31.1925 cls=0.1419 smmd=0.3042 ct=9.6045 rec=1.1608 | train/val/test=0.980/0.642/0.661 | c=0.998347
[Epoch 0142] loss=31.2281 cls=0.1676 smmd=0.3270 ct=9.6042 rec=1.1609 | train/val/test=0.980/0.656/0.662 | c=0.998347
[Epoch 0143] loss=31.1871 cls=0.1177 smmd=0.3245 ct=9.5776 rec=1.1649 | train/val/test=0.980/0.652/0.663 | c=0.998347
[Epoch 0144] loss=31.2572 cls=0.1553 smmd=0.3046 ct=9.6180 rec=1.1639 | train/val/test=0.980/0.642/0.665 | c=0.998347
[Epoch 0145] loss=31.2801 cls=0.1499 smmd=0.3485 ct=9.5825 rec=1.1692 | train/val/test=0.980/0.654/0.666 | c=0.998347
[Epoch 0146] loss=31.3837 cls=0.1637 smmd=0.3215 ct=9.6394 rec=1.1701 | train/val/test=0.980/0.652/0.663 | c=0.998347
[Epoch 0147] loss=31.2883 cls=0.1755 smmd=0.3689 ct=9.5866 rec=1.1658 | train/val/test=0.980/0.648/0.660 | c=0.998347
[Epoch 0148] loss=31.0979 cls=0.1282 smmd=0.2797 ct=9.5934 rec=1.1567 | train/val/test=0.980/0.652/0.659 | c=0.998347
[Epoch 0149] loss=31.1152 cls=0.1206 smmd=0.2870 ct=9.5960 rec=1.1576 | train/val/test=0.980/0.654/0.664 | c=0.998347
[Epoch 0150] loss=31.2136 cls=0.1514 smmd=0.3380 ct=9.5891 rec=1.1622 | train/val/test=0.980/0.650/0.661 | c=0.998347
[Epoch 0151] loss=31.1848 cls=0.1331 smmd=0.2726 ct=9.6126 rec=1.1621 | train/val/test=0.980/0.650/0.665 | c=0.998347
[Epoch 0152] loss=31.1832 cls=0.1205 smmd=0.3161 ct=9.5748 rec=1.1657 | train/val/test=0.980/0.656/0.663 | c=0.998347
[Epoch 0153] loss=31.2448 cls=0.1657 smmd=0.2901 ct=9.6119 rec=1.1648 | train/val/test=0.980/0.652/0.670 | c=0.998347
[Epoch 0154] loss=31.3338 cls=0.1276 smmd=0.3515 ct=9.5939 rec=1.1731 | train/val/test=0.980/0.644/0.663 | c=0.998347
[Epoch 0155] loss=31.4428 cls=0.2285 smmd=0.3702 ct=9.6217 rec=1.1715 | train/val/test=0.980/0.664/0.670 | c=0.998347
[Epoch 0156] loss=31.3492 cls=0.1505 smmd=0.4196 ct=9.6020 rec=1.1650 | train/val/test=0.980/0.652/0.660 | c=0.998347
[Epoch 0157] loss=31.1293 cls=0.1520 smmd=0.3250 ct=9.5942 rec=1.1540 | train/val/test=0.980/0.650/0.664 | c=0.998347
[Epoch 0158] loss=31.2312 cls=0.1837 smmd=0.3459 ct=9.6080 rec=1.1577 | train/val/test=0.980/0.662/0.669 | c=0.998347
[Epoch 0159] loss=31.2451 cls=0.1313 smmd=0.3836 ct=9.5913 rec=1.1613 | train/val/test=0.980/0.650/0.660 | c=0.998347
[Epoch 0160] loss=31.1211 cls=0.1288 smmd=0.2809 ct=9.5991 rec=1.1578 | train/val/test=0.980/0.642/0.664 | c=0.998347
[Epoch 0161] loss=31.2396 cls=0.1490 smmd=0.3279 ct=9.5975 rec=1.1642 | train/val/test=0.980/0.650/0.670 | c=0.998347
[Epoch 0162] loss=31.3337 cls=0.1239 smmd=0.3200 ct=9.5972 rec=1.1757 | train/val/test=0.980/0.650/0.664 | c=0.998347
[Epoch 0163] loss=31.4567 cls=0.2002 smmd=0.3389 ct=9.6378 rec=1.1742 | train/val/test=0.980/0.652/0.670 | c=0.998347
[Epoch 0164] loss=31.7036 cls=0.1503 smmd=0.5639 ct=9.6032 rec=1.1858 | train/val/test=0.960/0.660/0.660 | c=0.998347
[Epoch 0165] loss=31.4564 cls=0.2149 smmd=0.3938 ct=9.6443 rec=1.1667 | train/val/test=0.960/0.646/0.665 | c=0.998347
[Epoch 0166] loss=31.3695 cls=0.2366 smmd=0.4502 ct=9.6095 rec=1.1582 | train/val/test=0.980/0.656/0.667 | c=0.998347
[Epoch 0167] loss=31.3101 cls=0.1617 smmd=0.5154 ct=9.5919 rec=1.1530 | train/val/test=0.980/0.658/0.671 | c=0.998347
[Epoch 0168] loss=31.4408 cls=0.1413 smmd=0.5145 ct=9.6315 rec=1.1593 | train/val/test=0.980/0.656/0.665 | c=0.998347
[Epoch 0169] loss=31.2586 cls=0.1763 smmd=0.4309 ct=9.6111 rec=1.1517 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0170] loss=31.3170 cls=0.1726 smmd=0.4412 ct=9.5921 rec=1.1605 | train/val/test=0.980/0.656/0.671 | c=0.998347
[Epoch 0171] loss=31.4046 cls=0.1177 smmd=0.4108 ct=9.6167 rec=1.1702 | train/val/test=0.980/0.654/0.662 | c=0.998347
[Epoch 0172] loss=31.1711 cls=0.1361 smmd=0.2901 ct=9.6016 rec=1.1610 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0173] loss=31.3960 cls=0.1611 smmd=0.3861 ct=9.5873 rec=1.1755 | train/val/test=0.960/0.648/0.654 | c=0.998347
[Epoch 0174] loss=31.7857 cls=0.2001 smmd=0.4396 ct=9.6894 rec=1.1867 | train/val/test=0.980/0.652/0.667 | c=0.998347
[Epoch 0175] loss=31.3342 cls=0.1578 smmd=0.4312 ct=9.5771 rec=1.1670 | train/val/test=0.960/0.646/0.658 | c=0.998347
[Epoch 0176] loss=31.2194 cls=0.1694 smmd=0.3867 ct=9.5946 rec=1.1559 | train/val/test=0.960/0.658/0.668 | c=0.998347
[Epoch 0177] loss=31.3344 cls=0.1535 smmd=0.4075 ct=9.6400 rec=1.1570 | train/val/test=0.980/0.650/0.665 | c=0.998347
[Epoch 0178] loss=31.1746 cls=0.1280 smmd=0.3941 ct=9.5918 rec=1.1533 | train/val/test=0.960/0.642/0.659 | c=0.998347
[Epoch 0179] loss=31.3267 cls=0.1561 smmd=0.4605 ct=9.5885 rec=1.1611 | train/val/test=0.980/0.658/0.665 | c=0.998347
[Epoch 0180] loss=31.3000 cls=0.1393 smmd=0.3542 ct=9.6355 rec=1.1605 | train/val/test=0.980/0.654/0.665 | c=0.998347
[Epoch 0181] loss=31.2322 cls=0.1095 smmd=0.3413 ct=9.5961 rec=1.1644 | train/val/test=0.960/0.640/0.650 | c=0.998347
[Epoch 0182] loss=31.4944 cls=0.1801 smmd=0.4311 ct=9.6021 rec=1.1769 | train/val/test=0.980/0.648/0.666 | c=0.998347
[Epoch 0183] loss=31.5088 cls=0.1745 smmd=0.3675 ct=9.6615 rec=1.1731 | train/val/test=0.980/0.658/0.668 | c=0.998347
[Epoch 0184] loss=31.3843 cls=0.1159 smmd=0.4184 ct=9.5900 rec=1.1728 | train/val/test=0.960/0.640/0.649 | c=0.998347
[Epoch 0185] loss=31.4629 cls=0.2129 smmd=0.4558 ct=9.6075 rec=1.1686 | train/val/test=0.980/0.658/0.669 | c=0.998347
[Epoch 0186] loss=31.2544 cls=0.1880 smmd=0.3638 ct=9.6172 rec=1.1562 | train/val/test=0.980/0.660/0.671 | c=0.998347
[Epoch 0187] loss=31.3914 cls=0.1366 smmd=0.4720 ct=9.6197 rec=1.1612 | train/val/test=0.980/0.638/0.651 | c=0.998347
[Epoch 0188] loss=31.2838 cls=0.1607 smmd=0.4616 ct=9.5862 rec=1.1570 | train/val/test=0.980/0.644/0.663 | c=0.998347
[Epoch 0189] loss=31.2920 cls=0.1911 smmd=0.3880 ct=9.6156 rec=1.1577 | train/val/test=0.980/0.660/0.669 | c=0.998347
[Epoch 0190] loss=31.3092 cls=0.1320 smmd=0.4024 ct=9.6063 rec=1.1628 | train/val/test=0.980/0.654/0.662 | c=0.998347
[Epoch 0191] loss=31.2234 cls=0.1269 smmd=0.3623 ct=9.5832 rec=1.1631 | train/val/test=0.980/0.644/0.660 | c=0.998347
[Epoch 0192] loss=31.3571 cls=0.1784 smmd=0.3603 ct=9.6179 rec=1.1672 | train/val/test=0.980/0.658/0.672 | c=0.998347
[Epoch 0193] loss=31.3373 cls=0.1308 smmd=0.3459 ct=9.5943 rec=1.1737 | train/val/test=0.980/0.650/0.657 | c=0.998347
[Epoch 0194] loss=31.3438 cls=0.1658 smmd=0.3339 ct=9.6136 rec=1.1700 | train/val/test=0.980/0.654/0.662 | c=0.998347
[Epoch 0195] loss=31.3430 cls=0.1811 smmd=0.4055 ct=9.5897 rec=1.1668 | train/val/test=0.980/0.652/0.662 | c=0.998347
[Epoch 0196] loss=31.2166 cls=0.1456 smmd=0.3267 ct=9.6065 rec=1.1604 | train/val/test=0.980/0.652/0.658 | c=0.998347
[Epoch 0197] loss=31.1532 cls=0.1388 smmd=0.3214 ct=9.5958 rec=1.1571 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0198] loss=31.2474 cls=0.1551 smmd=0.3853 ct=9.5869 rec=1.1611 | train/val/test=0.980/0.650/0.667 | c=0.998347
[Epoch 0199] loss=31.1900 cls=0.1368 smmd=0.3333 ct=9.6016 rec=1.1585 | train/val/test=0.980/0.652/0.660 | c=0.998347
=== Best @ epoch 65: val=0.6680, test=0.6820 ===

==================================================
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-3 - 2025-09-21 06:24:31:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-3...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.8624 cls=1.7929 smmd=4.1009 ct=9.4740 rec=1.3917 | train/val/test=0.200/0.174/0.181 | c=0.998347
[Epoch 0001] loss=37.6929 cls=1.7862 smmd=3.9248 ct=9.4790 rec=1.3917 | train/val/test=0.380/0.154/0.154 | c=0.998347
[Epoch 0002] loss=36.5997 cls=1.7773 smmd=3.0073 ct=9.3935 rec=1.3917 | train/val/test=0.320/0.100/0.119 | c=0.998347
[Epoch 0003] loss=35.8757 cls=1.7623 smmd=2.4682 ct=9.3049 rec=1.3917 | train/val/test=0.580/0.290/0.291 | c=0.998347
[Epoch 0004] loss=35.0756 cls=1.7369 smmd=2.1291 ct=9.0813 rec=1.3916 | train/val/test=0.500/0.328/0.309 | c=0.998347
[Epoch 0005] loss=34.6737 cls=1.7030 smmd=1.8030 ct=9.0533 rec=1.3913 | train/val/test=0.640/0.426/0.419 | c=0.998347
[Epoch 0006] loss=34.4878 cls=1.6607 smmd=1.7477 ct=9.0014 rec=1.3907 | train/val/test=0.720/0.488/0.467 | c=0.998347
[Epoch 0007] loss=34.2704 cls=1.6156 smmd=1.5699 ct=8.9970 rec=1.3899 | train/val/test=0.680/0.484/0.486 | c=0.998347
[Epoch 0008] loss=33.9846 cls=1.5706 smmd=1.3346 ct=8.9886 rec=1.3887 | train/val/test=0.700/0.498/0.493 | c=0.998347
[Epoch 0009] loss=33.9727 cls=1.5269 smmd=1.3601 ct=8.9871 rec=1.3875 | train/val/test=0.760/0.522/0.532 | c=0.998347
[Epoch 0010] loss=35.2135 cls=1.4810 smmd=1.2495 ct=9.6797 rec=1.3864 | train/val/test=0.780/0.552/0.567 | c=0.998347
[Epoch 0011] loss=34.8992 cls=1.4365 smmd=1.2466 ct=9.5367 rec=1.3861 | train/val/test=0.840/0.514/0.547 | c=0.998347
[Epoch 0012] loss=34.8774 cls=1.3941 smmd=1.4463 ct=9.4406 rec=1.3853 | train/val/test=0.820/0.508/0.517 | c=0.998347
[Epoch 0013] loss=34.8769 cls=1.3531 smmd=1.4520 ct=9.4538 rec=1.3841 | train/val/test=0.860/0.584/0.578 | c=0.998347
[Epoch 0014] loss=34.5418 cls=1.3012 smmd=1.0843 ct=9.4843 rec=1.3838 | train/val/test=0.880/0.574/0.572 | c=0.998347
[Epoch 0015] loss=34.4637 cls=1.2491 smmd=0.8569 ct=9.5765 rec=1.3829 | train/val/test=0.860/0.550/0.518 | c=0.998347
[Epoch 0016] loss=34.4581 cls=1.2007 smmd=0.8231 ct=9.6132 rec=1.3808 | train/val/test=0.900/0.584/0.569 | c=0.998347
[Epoch 0017] loss=34.3531 cls=1.1388 smmd=0.8933 ct=9.5455 rec=1.3799 | train/val/test=0.860/0.562/0.507 | c=0.998347
[Epoch 0018] loss=34.2283 cls=1.0877 smmd=0.8766 ct=9.5304 rec=1.3747 | train/val/test=0.940/0.548/0.557 | c=0.998347
[Epoch 0019] loss=34.0678 cls=1.0137 smmd=0.8496 ct=9.4993 rec=1.3713 | train/val/test=0.920/0.602/0.563 | c=0.998347
[Epoch 0020] loss=33.9052 cls=0.9586 smmd=0.7361 ct=9.5265 rec=1.3637 | train/val/test=0.920/0.600/0.555 | c=0.998347
[Epoch 0021] loss=33.7649 cls=0.9055 smmd=0.6452 ct=9.5512 rec=1.3565 | train/val/test=0.960/0.596/0.576 | c=0.998347
[Epoch 0022] loss=33.6220 cls=0.8459 smmd=0.5701 ct=9.5656 rec=1.3498 | train/val/test=0.920/0.592/0.549 | c=0.998347
[Epoch 0023] loss=33.5279 cls=0.8167 smmd=0.5357 ct=9.5813 rec=1.3421 | train/val/test=0.920/0.590/0.567 | c=0.998347
[Epoch 0024] loss=33.4151 cls=0.7750 smmd=0.5660 ct=9.5548 rec=1.3352 | train/val/test=0.920/0.596/0.573 | c=0.998347
[Epoch 0025] loss=33.3119 cls=0.7349 smmd=0.5797 ct=9.5382 rec=1.3288 | train/val/test=0.920/0.588/0.566 | c=0.998347
[Epoch 0026] loss=33.2574 cls=0.7119 smmd=0.5593 ct=9.5523 rec=1.3238 | train/val/test=0.960/0.616/0.596 | c=0.998347
[Epoch 0027] loss=33.1185 cls=0.6671 smmd=0.4710 ct=9.5680 rec=1.3178 | train/val/test=0.960/0.604/0.599 | c=0.998347
[Epoch 0028] loss=33.0428 cls=0.6426 smmd=0.4232 ct=9.5812 rec=1.3136 | train/val/test=0.960/0.618/0.606 | c=0.998347
[Epoch 0029] loss=32.9749 cls=0.6112 smmd=0.4202 ct=9.5776 rec=1.3094 | train/val/test=0.960/0.624/0.613 | c=0.998347
[Epoch 0030] loss=32.8948 cls=0.5726 smmd=0.4343 ct=9.5643 rec=1.3046 | train/val/test=0.960/0.618/0.617 | c=0.998347
[Epoch 0031] loss=32.8363 cls=0.5499 smmd=0.4137 ct=9.5659 rec=1.3016 | train/val/test=0.960/0.638/0.637 | c=0.998347
[Epoch 0032] loss=32.7705 cls=0.5049 smmd=0.4177 ct=9.5686 rec=1.2963 | train/val/test=0.960/0.622/0.620 | c=0.998347
[Epoch 0033] loss=32.6812 cls=0.4890 smmd=0.3522 ct=9.5785 rec=1.2927 | train/val/test=0.960/0.638/0.642 | c=0.998347
[Epoch 0034] loss=32.6238 cls=0.4473 smmd=0.3818 ct=9.5765 rec=1.2865 | train/val/test=0.960/0.624/0.624 | c=0.998347
[Epoch 0035] loss=32.5335 cls=0.4350 smmd=0.3341 ct=9.5858 rec=1.2810 | train/val/test=0.960/0.630/0.637 | c=0.998347
[Epoch 0036] loss=32.4650 cls=0.3947 smmd=0.3885 ct=9.5721 rec=1.2735 | train/val/test=0.960/0.634/0.627 | c=0.998347
[Epoch 0037] loss=32.3831 cls=0.3900 smmd=0.3683 ct=9.5817 rec=1.2656 | train/val/test=0.960/0.636/0.639 | c=0.998347
[Epoch 0038] loss=32.2864 cls=0.3521 smmd=0.3880 ct=9.5717 rec=1.2579 | train/val/test=0.960/0.644/0.643 | c=0.998347
[Epoch 0039] loss=32.1956 cls=0.3503 smmd=0.3518 ct=9.5853 rec=1.2498 | train/val/test=0.960/0.646/0.647 | c=0.998347
[Epoch 0040] loss=32.0982 cls=0.3228 smmd=0.3490 ct=9.5808 rec=1.2426 | train/val/test=0.960/0.648/0.648 | c=0.998347
[Epoch 0041] loss=32.0410 cls=0.3101 smmd=0.3573 ct=9.5815 rec=1.2366 | train/val/test=0.960/0.654/0.652 | c=0.998347
[Epoch 0042] loss=31.9910 cls=0.3034 smmd=0.3546 ct=9.5840 rec=1.2317 | train/val/test=0.980/0.656/0.657 | c=0.998347
[Epoch 0043] loss=31.9525 cls=0.2833 smmd=0.3744 ct=9.5746 rec=1.2287 | train/val/test=0.980/0.648/0.652 | c=0.998347
[Epoch 0044] loss=31.9119 cls=0.2900 smmd=0.3334 ct=9.5940 rec=1.2246 | train/val/test=0.980/0.656/0.654 | c=0.998347
[Epoch 0045] loss=31.8955 cls=0.2662 smmd=0.3677 ct=9.5809 rec=1.2233 | train/val/test=0.980/0.654/0.659 | c=0.998347
[Epoch 0046] loss=31.8519 cls=0.2797 smmd=0.3162 ct=9.6071 rec=1.2182 | train/val/test=0.980/0.652/0.656 | c=0.998347
[Epoch 0047] loss=31.8184 cls=0.2526 smmd=0.3580 ct=9.5802 rec=1.2174 | train/val/test=0.980/0.656/0.660 | c=0.998347
[Epoch 0048] loss=31.7842 cls=0.2698 smmd=0.3373 ct=9.6019 rec=1.2108 | train/val/test=0.980/0.652/0.660 | c=0.998347
[Epoch 0049] loss=31.7222 cls=0.2419 smmd=0.3565 ct=9.5810 rec=1.2083 | train/val/test=0.980/0.656/0.665 | c=0.998347
[Epoch 0050] loss=31.6446 cls=0.2450 smmd=0.2960 ct=9.5983 rec=1.2029 | train/val/test=0.980/0.658/0.664 | c=0.998347
[Epoch 0051] loss=31.6107 cls=0.2333 smmd=0.3129 ct=9.5881 rec=1.2005 | train/val/test=0.980/0.656/0.666 | c=0.998347
[Epoch 0052] loss=31.5974 cls=0.2224 smmd=0.3230 ct=9.5836 rec=1.1996 | train/val/test=0.980/0.658/0.668 | c=0.998347
[Epoch 0053] loss=31.5976 cls=0.2296 smmd=0.2997 ct=9.6015 rec=1.1980 | train/val/test=0.980/0.658/0.663 | c=0.998347
[Epoch 0054] loss=31.6191 cls=0.2153 smmd=0.3348 ct=9.5819 rec=1.2013 | train/val/test=0.980/0.660/0.668 | c=0.998347
[Epoch 0055] loss=31.7000 cls=0.2450 smmd=0.3357 ct=9.6309 rec=1.1980 | train/val/test=0.960/0.650/0.668 | c=0.998347
[Epoch 0056] loss=31.8324 cls=0.2230 smmd=0.4778 ct=9.5891 rec=1.2065 | train/val/test=0.980/0.656/0.659 | c=0.998347
[Epoch 0057] loss=31.7458 cls=0.2588 smmd=0.3780 ct=9.6518 rec=1.1935 | train/val/test=0.980/0.656/0.672 | c=0.998347
[Epoch 0058] loss=31.4930 cls=0.2025 smmd=0.3883 ct=9.5842 rec=1.1835 | train/val/test=0.980/0.660/0.669 | c=0.998347
[Epoch 0059] loss=31.4461 cls=0.1913 smmd=0.3828 ct=9.5888 rec=1.1790 | train/val/test=0.980/0.664/0.665 | c=0.998347
[Epoch 0060] loss=31.5416 cls=0.2245 smmd=0.3555 ct=9.6326 rec=1.1809 | train/val/test=0.980/0.660/0.675 | c=0.998347
[Epoch 0061] loss=31.4601 cls=0.1836 smmd=0.3854 ct=9.5835 rec=1.1816 | train/val/test=0.980/0.656/0.671 | c=0.998347
[Epoch 0062] loss=31.3936 cls=0.1790 smmd=0.3298 ct=9.5877 rec=1.1799 | train/val/test=0.980/0.648/0.666 | c=0.998347
[Epoch 0063] loss=31.5102 cls=0.2066 smmd=0.3049 ct=9.6286 rec=1.1845 | train/val/test=0.980/0.662/0.680 | c=0.998347
[Epoch 0064] loss=31.7269 cls=0.1944 smmd=0.4366 ct=9.5898 rec=1.2014 | train/val/test=0.980/0.650/0.660 | c=0.998347
[Epoch 0065] loss=31.7650 cls=0.2544 smmd=0.3883 ct=9.6607 rec=1.1928 | train/val/test=0.960/0.668/0.682 | c=0.998347
[Epoch 0066] loss=31.6037 cls=0.1854 smmd=0.4716 ct=9.5941 rec=1.1851 | train/val/test=0.980/0.656/0.674 | c=0.998347
[Epoch 0067] loss=31.3235 cls=0.1816 smmd=0.3505 ct=9.5911 rec=1.1700 | train/val/test=0.960/0.648/0.666 | c=0.998347
[Epoch 0068] loss=31.5539 cls=0.2446 smmd=0.3907 ct=9.6466 rec=1.1748 | train/val/test=0.980/0.662/0.678 | c=0.998347
[Epoch 0069] loss=31.4379 cls=0.1705 smmd=0.4626 ct=9.5917 rec=1.1707 | train/val/test=0.980/0.660/0.672 | c=0.998347
[Epoch 0070] loss=31.3404 cls=0.1643 smmd=0.3984 ct=9.5847 rec=1.1691 | train/val/test=0.960/0.650/0.663 | c=0.998347
[Epoch 0071] loss=31.5468 cls=0.2182 smmd=0.3900 ct=9.6483 rec=1.1751 | train/val/test=0.980/0.666/0.673 | c=0.998347
[Epoch 0072] loss=31.3889 cls=0.1532 smmd=0.3782 ct=9.5877 rec=1.1759 | train/val/test=0.980/0.656/0.670 | c=0.998347
[Epoch 0073] loss=31.3155 cls=0.1585 smmd=0.3274 ct=9.5833 rec=1.1742 | train/val/test=0.980/0.658/0.668 | c=0.998347
[Epoch 0074] loss=31.5728 cls=0.2021 smmd=0.3523 ct=9.6540 rec=1.1811 | train/val/test=0.960/0.652/0.682 | c=0.998347
[Epoch 0075] loss=31.6894 cls=0.1830 smmd=0.4777 ct=9.5927 rec=1.1935 | train/val/test=0.980/0.658/0.667 | c=0.998347
[Epoch 0076] loss=31.4003 cls=0.1862 smmd=0.3339 ct=9.6226 rec=1.1728 | train/val/test=0.980/0.660/0.675 | c=0.998347
[Epoch 0077] loss=31.3429 cls=0.1979 smmd=0.3622 ct=9.6092 rec=1.1663 | train/val/test=0.980/0.666/0.677 | c=0.998347
[Epoch 0078] loss=31.4125 cls=0.1601 smmd=0.4416 ct=9.5993 rec=1.1692 | train/val/test=0.980/0.654/0.663 | c=0.998347
[Epoch 0079] loss=31.3043 cls=0.1639 smmd=0.3795 ct=9.5996 rec=1.1644 | train/val/test=0.980/0.656/0.669 | c=0.998347
[Epoch 0080] loss=31.4140 cls=0.2096 smmd=0.3910 ct=9.6238 rec=1.1671 | train/val/test=0.980/0.666/0.674 | c=0.998347
[Epoch 0081] loss=31.4129 cls=0.1526 smmd=0.4309 ct=9.5956 rec=1.1715 | train/val/test=0.980/0.648/0.662 | c=0.998347
[Epoch 0082] loss=31.3810 cls=0.1575 smmd=0.3920 ct=9.5955 rec=1.1719 | train/val/test=0.980/0.656/0.668 | c=0.998347
[Epoch 0083] loss=31.4300 cls=0.1852 smmd=0.3495 ct=9.6363 rec=1.1715 | train/val/test=0.980/0.660/0.683 | c=0.998347
[Epoch 0084] loss=31.5198 cls=0.1657 smmd=0.4390 ct=9.5923 rec=1.1813 | train/val/test=0.980/0.644/0.657 | c=0.998347
[Epoch 0085] loss=31.5019 cls=0.1810 smmd=0.4045 ct=9.6229 rec=1.1761 | train/val/test=0.980/0.648/0.669 | c=0.998347
[Epoch 0086] loss=31.2546 cls=0.1666 smmd=0.3330 ct=9.6049 rec=1.1629 | train/val/test=0.980/0.656/0.679 | c=0.998347
[Epoch 0087] loss=31.4374 cls=0.1711 smmd=0.4452 ct=9.5991 rec=1.1709 | train/val/test=0.980/0.644/0.661 | c=0.998347
[Epoch 0088] loss=31.4133 cls=0.1693 smmd=0.4304 ct=9.6149 rec=1.1668 | train/val/test=0.980/0.644/0.663 | c=0.998347
[Epoch 0089] loss=31.2334 cls=0.1642 smmd=0.3169 ct=9.6098 rec=1.1615 | train/val/test=0.980/0.656/0.680 | c=0.998347
[Epoch 0090] loss=31.5013 cls=0.1713 smmd=0.4763 ct=9.6039 rec=1.1732 | train/val/test=0.980/0.650/0.664 | c=0.998347
[Epoch 0091] loss=31.2513 cls=0.1505 smmd=0.3409 ct=9.5979 rec=1.1639 | train/val/test=0.980/0.648/0.655 | c=0.998347
[Epoch 0092] loss=31.3415 cls=0.1567 smmd=0.3419 ct=9.6175 rec=1.1686 | train/val/test=0.980/0.658/0.677 | c=0.998347
[Epoch 0093] loss=31.4486 cls=0.1694 smmd=0.4149 ct=9.5974 rec=1.1754 | train/val/test=0.980/0.650/0.661 | c=0.998347
[Epoch 0094] loss=31.2374 cls=0.1491 smmd=0.2845 ct=9.6090 rec=1.1660 | train/val/test=0.980/0.650/0.659 | c=0.998347
[Epoch 0095] loss=31.3048 cls=0.1507 smmd=0.3440 ct=9.5937 rec=1.1698 | train/val/test=0.980/0.658/0.674 | c=0.998347
[Epoch 0096] loss=31.3210 cls=0.1592 smmd=0.3516 ct=9.6002 rec=1.1689 | train/val/test=0.980/0.648/0.664 | c=0.998347
[Epoch 0097] loss=31.2305 cls=0.1676 smmd=0.3010 ct=9.6019 rec=1.1642 | train/val/test=0.980/0.652/0.660 | c=0.998347
[Epoch 0098] loss=31.2700 cls=0.1400 smmd=0.3308 ct=9.5947 rec=1.1680 | train/val/test=0.980/0.656/0.670 | c=0.998347
[Epoch 0099] loss=31.2502 cls=0.1686 smmd=0.3307 ct=9.5890 rec=1.1657 | train/val/test=0.980/0.652/0.660 | c=0.998347
[Epoch 0100] loss=31.2515 cls=0.1648 smmd=0.2815 ct=9.6119 rec=1.1664 | train/val/test=0.980/0.642/0.664 | c=0.998347
[Epoch 0101] loss=31.3034 cls=0.1475 smmd=0.3562 ct=9.5819 rec=1.1710 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0102] loss=31.2704 cls=0.1560 smmd=0.2927 ct=9.6155 rec=1.1669 | train/val/test=0.960/0.652/0.665 | c=0.998347
[Epoch 0103] loss=31.3036 cls=0.1754 smmd=0.3397 ct=9.5970 rec=1.1682 | train/val/test=0.980/0.652/0.665 | c=0.998347
[Epoch 0104] loss=31.3530 cls=0.1386 smmd=0.3473 ct=9.6081 rec=1.1720 | train/val/test=0.980/0.646/0.668 | c=0.998347
[Epoch 0105] loss=31.2650 cls=0.1799 smmd=0.3193 ct=9.5985 rec=1.1659 | train/val/test=0.980/0.650/0.666 | c=0.998347
[Epoch 0106] loss=31.2091 cls=0.1408 smmd=0.3130 ct=9.5977 rec=1.1630 | train/val/test=0.980/0.644/0.665 | c=0.998347
[Epoch 0107] loss=31.1729 cls=0.1450 smmd=0.2957 ct=9.5901 rec=1.1625 | train/val/test=0.980/0.642/0.664 | c=0.998347
[Epoch 0108] loss=31.1826 cls=0.1601 smmd=0.2974 ct=9.5908 rec=1.1624 | train/val/test=0.980/0.652/0.669 | c=0.998347
[Epoch 0109] loss=31.2387 cls=0.1493 smmd=0.2827 ct=9.6047 rec=1.1672 | train/val/test=0.980/0.644/0.664 | c=0.998347
[Epoch 0110] loss=31.2932 cls=0.1666 smmd=0.3272 ct=9.5879 rec=1.1707 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0111] loss=31.2906 cls=0.1504 smmd=0.2833 ct=9.6130 rec=1.1706 | train/val/test=0.980/0.654/0.667 | c=0.998347
[Epoch 0112] loss=31.3299 cls=0.1778 smmd=0.3418 ct=9.5937 rec=1.1712 | train/val/test=0.980/0.650/0.660 | c=0.998347
[Epoch 0113] loss=31.3309 cls=0.1550 smmd=0.3249 ct=9.6217 rec=1.1685 | train/val/test=0.980/0.654/0.666 | c=0.998347
[Epoch 0114] loss=31.1897 cls=0.1358 smmd=0.3286 ct=9.5811 rec=1.1631 | train/val/test=0.980/0.650/0.666 | c=0.998347
[Epoch 0115] loss=31.1704 cls=0.1550 smmd=0.3019 ct=9.6010 rec=1.1589 | train/val/test=0.980/0.654/0.661 | c=0.998347
[Epoch 0116] loss=31.1756 cls=0.1313 smmd=0.3024 ct=9.5964 rec=1.1615 | train/val/test=0.980/0.648/0.664 | c=0.998347
[Epoch 0117] loss=31.1829 cls=0.1461 smmd=0.3173 ct=9.5796 rec=1.1633 | train/val/test=0.980/0.652/0.668 | c=0.998347
[Epoch 0118] loss=31.2753 cls=0.1637 smmd=0.2899 ct=9.6195 rec=1.1665 | train/val/test=0.980/0.648/0.667 | c=0.998347
[Epoch 0119] loss=31.2938 cls=0.1480 smmd=0.3280 ct=9.5811 rec=1.1730 | train/val/test=0.980/0.650/0.668 | c=0.998347
[Epoch 0120] loss=31.2782 cls=0.1670 smmd=0.2720 ct=9.6206 rec=1.1681 | train/val/test=0.980/0.656/0.664 | c=0.998347
[Epoch 0121] loss=31.2497 cls=0.1572 smmd=0.3190 ct=9.5827 rec=1.1687 | train/val/test=0.980/0.650/0.657 | c=0.998347
[Epoch 0122] loss=31.2766 cls=0.1554 smmd=0.2969 ct=9.6160 rec=1.1670 | train/val/test=0.980/0.660/0.667 | c=0.998347
[Epoch 0123] loss=31.1969 cls=0.1495 smmd=0.3157 ct=9.5872 rec=1.1632 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0124] loss=31.1501 cls=0.1410 smmd=0.2987 ct=9.5946 rec=1.1592 | train/val/test=0.980/0.654/0.660 | c=0.998347
[Epoch 0125] loss=31.1482 cls=0.1276 smmd=0.2835 ct=9.5949 rec=1.1611 | train/val/test=0.980/0.646/0.665 | c=0.998347
[Epoch 0126] loss=31.1797 cls=0.1468 smmd=0.3064 ct=9.5846 rec=1.1631 | train/val/test=0.980/0.650/0.658 | c=0.998347
[Epoch 0127] loss=31.2229 cls=0.1454 smmd=0.2748 ct=9.6076 rec=1.1660 | train/val/test=0.980/0.644/0.664 | c=0.998347
[Epoch 0128] loss=31.2518 cls=0.1483 smmd=0.3201 ct=9.5811 rec=1.1695 | train/val/test=0.980/0.650/0.662 | c=0.998347
[Epoch 0129] loss=31.2262 cls=0.1512 smmd=0.2568 ct=9.6128 rec=1.1668 | train/val/test=0.980/0.644/0.665 | c=0.998347
[Epoch 0130] loss=31.2063 cls=0.1560 smmd=0.3031 ct=9.5842 rec=1.1657 | train/val/test=0.980/0.654/0.662 | c=0.998347
[Epoch 0131] loss=31.2374 cls=0.1498 smmd=0.2887 ct=9.6083 rec=1.1657 | train/val/test=0.980/0.652/0.663 | c=0.998347
[Epoch 0132] loss=31.2015 cls=0.1497 smmd=0.3146 ct=9.5903 rec=1.1631 | train/val/test=0.980/0.650/0.661 | c=0.998347
[Epoch 0133] loss=31.1228 cls=0.1423 smmd=0.2690 ct=9.5961 rec=1.1590 | train/val/test=0.980/0.654/0.661 | c=0.998347
[Epoch 0134] loss=31.1675 cls=0.1235 smmd=0.2993 ct=9.5865 rec=1.1633 | train/val/test=0.960/0.652/0.663 | c=0.998347
[Epoch 0135] loss=31.2292 cls=0.1644 smmd=0.3030 ct=9.6032 rec=1.1638 | train/val/test=0.980/0.652/0.665 | c=0.998347
[Epoch 0136] loss=31.2299 cls=0.1323 smmd=0.3016 ct=9.5928 rec=1.1677 | train/val/test=0.980/0.642/0.660 | c=0.998347
[Epoch 0137] loss=31.3115 cls=0.1859 smmd=0.3256 ct=9.6011 rec=1.1691 | train/val/test=0.980/0.654/0.670 | c=0.998347
[Epoch 0138] loss=31.3623 cls=0.1448 smmd=0.3508 ct=9.6123 rec=1.1715 | train/val/test=0.980/0.640/0.664 | c=0.998347
[Epoch 0139] loss=31.2987 cls=0.1866 smmd=0.3528 ct=9.6037 rec=1.1645 | train/val/test=0.980/0.654/0.657 | c=0.998347
[Epoch 0140] loss=31.1304 cls=0.1330 smmd=0.3122 ct=9.5849 rec=1.1582 | train/val/test=0.980/0.648/0.666 | c=0.998347
[Epoch 0141] loss=31.1925 cls=0.1419 smmd=0.3042 ct=9.6045 rec=1.1608 | train/val/test=0.980/0.642/0.661 | c=0.998347
[Epoch 0142] loss=31.2281 cls=0.1676 smmd=0.3270 ct=9.6042 rec=1.1609 | train/val/test=0.980/0.656/0.662 | c=0.998347
[Epoch 0143] loss=31.1871 cls=0.1177 smmd=0.3245 ct=9.5776 rec=1.1649 | train/val/test=0.980/0.652/0.663 | c=0.998347
[Epoch 0144] loss=31.2572 cls=0.1553 smmd=0.3046 ct=9.6180 rec=1.1639 | train/val/test=0.980/0.642/0.665 | c=0.998347
[Epoch 0145] loss=31.2801 cls=0.1499 smmd=0.3485 ct=9.5825 rec=1.1692 | train/val/test=0.980/0.654/0.666 | c=0.998347
[Epoch 0146] loss=31.3837 cls=0.1637 smmd=0.3215 ct=9.6394 rec=1.1701 | train/val/test=0.980/0.652/0.663 | c=0.998347
[Epoch 0147] loss=31.2883 cls=0.1755 smmd=0.3689 ct=9.5866 rec=1.1658 | train/val/test=0.980/0.648/0.660 | c=0.998347
[Epoch 0148] loss=31.0979 cls=0.1282 smmd=0.2797 ct=9.5934 rec=1.1567 | train/val/test=0.980/0.652/0.659 | c=0.998347
[Epoch 0149] loss=31.1152 cls=0.1206 smmd=0.2870 ct=9.5960 rec=1.1576 | train/val/test=0.980/0.654/0.664 | c=0.998347
[Epoch 0150] loss=31.2136 cls=0.1514 smmd=0.3380 ct=9.5891 rec=1.1622 | train/val/test=0.980/0.650/0.661 | c=0.998347
[Epoch 0151] loss=31.1848 cls=0.1331 smmd=0.2726 ct=9.6126 rec=1.1621 | train/val/test=0.980/0.650/0.665 | c=0.998347
[Epoch 0152] loss=31.1832 cls=0.1205 smmd=0.3161 ct=9.5748 rec=1.1657 | train/val/test=0.980/0.656/0.663 | c=0.998347
[Epoch 0153] loss=31.2448 cls=0.1657 smmd=0.2901 ct=9.6119 rec=1.1648 | train/val/test=0.980/0.652/0.670 | c=0.998347
[Epoch 0154] loss=31.3338 cls=0.1276 smmd=0.3515 ct=9.5939 rec=1.1731 | train/val/test=0.980/0.644/0.663 | c=0.998347
[Epoch 0155] loss=31.4428 cls=0.2285 smmd=0.3702 ct=9.6217 rec=1.1715 | train/val/test=0.980/0.664/0.670 | c=0.998347
[Epoch 0156] loss=31.3492 cls=0.1505 smmd=0.4196 ct=9.6020 rec=1.1650 | train/val/test=0.980/0.652/0.660 | c=0.998347
[Epoch 0157] loss=31.1293 cls=0.1520 smmd=0.3250 ct=9.5942 rec=1.1540 | train/val/test=0.980/0.650/0.664 | c=0.998347
[Epoch 0158] loss=31.2312 cls=0.1837 smmd=0.3459 ct=9.6080 rec=1.1577 | train/val/test=0.980/0.662/0.669 | c=0.998347
[Epoch 0159] loss=31.2451 cls=0.1313 smmd=0.3836 ct=9.5913 rec=1.1613 | train/val/test=0.980/0.650/0.660 | c=0.998347
[Epoch 0160] loss=31.1211 cls=0.1288 smmd=0.2809 ct=9.5991 rec=1.1578 | train/val/test=0.980/0.642/0.664 | c=0.998347
[Epoch 0161] loss=31.2396 cls=0.1490 smmd=0.3279 ct=9.5975 rec=1.1642 | train/val/test=0.980/0.650/0.670 | c=0.998347
[Epoch 0162] loss=31.3337 cls=0.1239 smmd=0.3200 ct=9.5972 rec=1.1757 | train/val/test=0.980/0.650/0.664 | c=0.998347
[Epoch 0163] loss=31.4567 cls=0.2002 smmd=0.3389 ct=9.6378 rec=1.1742 | train/val/test=0.980/0.652/0.670 | c=0.998347
[Epoch 0164] loss=31.7036 cls=0.1503 smmd=0.5639 ct=9.6032 rec=1.1858 | train/val/test=0.960/0.660/0.660 | c=0.998347
[Epoch 0165] loss=31.4564 cls=0.2149 smmd=0.3938 ct=9.6443 rec=1.1667 | train/val/test=0.960/0.646/0.665 | c=0.998347
[Epoch 0166] loss=31.3695 cls=0.2366 smmd=0.4502 ct=9.6095 rec=1.1582 | train/val/test=0.980/0.656/0.667 | c=0.998347
[Epoch 0167] loss=31.3101 cls=0.1617 smmd=0.5154 ct=9.5919 rec=1.1530 | train/val/test=0.980/0.658/0.671 | c=0.998347
[Epoch 0168] loss=31.4408 cls=0.1413 smmd=0.5145 ct=9.6315 rec=1.1593 | train/val/test=0.980/0.656/0.665 | c=0.998347
[Epoch 0169] loss=31.2586 cls=0.1763 smmd=0.4309 ct=9.6111 rec=1.1517 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0170] loss=31.3170 cls=0.1726 smmd=0.4412 ct=9.5921 rec=1.1605 | train/val/test=0.980/0.656/0.671 | c=0.998347
[Epoch 0171] loss=31.4046 cls=0.1177 smmd=0.4108 ct=9.6167 rec=1.1702 | train/val/test=0.980/0.654/0.662 | c=0.998347
[Epoch 0172] loss=31.1711 cls=0.1361 smmd=0.2901 ct=9.6016 rec=1.1610 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0173] loss=31.3960 cls=0.1611 smmd=0.3861 ct=9.5873 rec=1.1755 | train/val/test=0.960/0.648/0.654 | c=0.998347
[Epoch 0174] loss=31.7857 cls=0.2001 smmd=0.4396 ct=9.6894 rec=1.1867 | train/val/test=0.980/0.652/0.667 | c=0.998347
[Epoch 0175] loss=31.3342 cls=0.1578 smmd=0.4312 ct=9.5771 rec=1.1670 | train/val/test=0.960/0.646/0.658 | c=0.998347
[Epoch 0176] loss=31.2194 cls=0.1694 smmd=0.3867 ct=9.5946 rec=1.1559 | train/val/test=0.960/0.658/0.668 | c=0.998347
[Epoch 0177] loss=31.3344 cls=0.1535 smmd=0.4075 ct=9.6400 rec=1.1570 | train/val/test=0.980/0.650/0.665 | c=0.998347
[Epoch 0178] loss=31.1746 cls=0.1280 smmd=0.3941 ct=9.5918 rec=1.1533 | train/val/test=0.960/0.642/0.659 | c=0.998347
[Epoch 0179] loss=31.3267 cls=0.1561 smmd=0.4605 ct=9.5885 rec=1.1611 | train/val/test=0.980/0.658/0.665 | c=0.998347
[Epoch 0180] loss=31.3000 cls=0.1393 smmd=0.3542 ct=9.6355 rec=1.1605 | train/val/test=0.980/0.654/0.665 | c=0.998347
[Epoch 0181] loss=31.2322 cls=0.1095 smmd=0.3413 ct=9.5961 rec=1.1644 | train/val/test=0.960/0.640/0.650 | c=0.998347
[Epoch 0182] loss=31.4944 cls=0.1801 smmd=0.4311 ct=9.6021 rec=1.1769 | train/val/test=0.980/0.648/0.666 | c=0.998347
[Epoch 0183] loss=31.5088 cls=0.1745 smmd=0.3675 ct=9.6615 rec=1.1731 | train/val/test=0.980/0.658/0.668 | c=0.998347
[Epoch 0184] loss=31.3843 cls=0.1159 smmd=0.4184 ct=9.5900 rec=1.1728 | train/val/test=0.960/0.640/0.649 | c=0.998347
[Epoch 0185] loss=31.4629 cls=0.2129 smmd=0.4558 ct=9.6075 rec=1.1686 | train/val/test=0.980/0.658/0.669 | c=0.998347
[Epoch 0186] loss=31.2544 cls=0.1880 smmd=0.3638 ct=9.6172 rec=1.1562 | train/val/test=0.980/0.660/0.671 | c=0.998347
[Epoch 0187] loss=31.3914 cls=0.1366 smmd=0.4720 ct=9.6197 rec=1.1612 | train/val/test=0.980/0.638/0.651 | c=0.998347
[Epoch 0188] loss=31.2838 cls=0.1607 smmd=0.4616 ct=9.5862 rec=1.1570 | train/val/test=0.980/0.644/0.663 | c=0.998347
[Epoch 0189] loss=31.2920 cls=0.1911 smmd=0.3880 ct=9.6156 rec=1.1577 | train/val/test=0.980/0.660/0.669 | c=0.998347
[Epoch 0190] loss=31.3092 cls=0.1320 smmd=0.4024 ct=9.6063 rec=1.1628 | train/val/test=0.980/0.654/0.662 | c=0.998347
[Epoch 0191] loss=31.2234 cls=0.1269 smmd=0.3623 ct=9.5832 rec=1.1631 | train/val/test=0.980/0.644/0.660 | c=0.998347
[Epoch 0192] loss=31.3571 cls=0.1784 smmd=0.3603 ct=9.6179 rec=1.1672 | train/val/test=0.980/0.658/0.672 | c=0.998347
[Epoch 0193] loss=31.3373 cls=0.1308 smmd=0.3459 ct=9.5943 rec=1.1737 | train/val/test=0.980/0.650/0.657 | c=0.998347
[Epoch 0194] loss=31.3438 cls=0.1658 smmd=0.3339 ct=9.6136 rec=1.1700 | train/val/test=0.980/0.654/0.662 | c=0.998347
[Epoch 0195] loss=31.3430 cls=0.1811 smmd=0.4055 ct=9.5897 rec=1.1668 | train/val/test=0.980/0.652/0.662 | c=0.998347
[Epoch 0196] loss=31.2166 cls=0.1456 smmd=0.3267 ct=9.6065 rec=1.1604 | train/val/test=0.980/0.652/0.658 | c=0.998347
[Epoch 0197] loss=31.1532 cls=0.1388 smmd=0.3214 ct=9.5958 rec=1.1571 | train/val/test=0.980/0.652/0.664 | c=0.998347
[Epoch 0198] loss=31.2474 cls=0.1551 smmd=0.3853 ct=9.5869 rec=1.1611 | train/val/test=0.980/0.650/0.667 | c=0.998347
[Epoch 0199] loss=31.1900 cls=0.1368 smmd=0.3333 ct=9.6016 rec=1.1585 | train/val/test=0.980/0.652/0.660 | c=0.998347
=== Best @ epoch 65: val=0.6680, test=0.6820 ===

Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-3 completed in 49.86 seconds.
==================================================
