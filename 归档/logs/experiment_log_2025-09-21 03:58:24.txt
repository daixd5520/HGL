Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-3 - 2025-09-21 03:58:24:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=39.7743 cls=1.0988 smmd=5.5618 ct=11.2746 rec=1.4137 | train/val/test=0.346/0.200/0.178 | c=0.998437
[Epoch 0001] loss=29.8360 cls=1.0824 smmd=3.5815 ct=11.2461 rec=1.4136 | train/val/test=0.385/0.210/0.200 | c=0.998437
[Epoch 0002] loss=34.9596 cls=1.0578 smmd=4.6061 ct=11.2588 rec=1.4137 | train/val/test=0.500/0.268/0.252 | c=0.998437
[Epoch 0003] loss=33.7252 cls=1.0070 smmd=4.3717 ct=11.2218 rec=1.4135 | train/val/test=0.654/0.426/0.405 | c=0.998437
[Epoch 0004] loss=24.3784 cls=0.9071 smmd=2.5497 ct=11.0354 rec=1.4103 | train/val/test=0.615/0.430/0.407 | c=0.998437
[Epoch 0005] loss=26.5117 cls=0.8039 smmd=2.9804 ct=11.0676 rec=1.4040 | train/val/test=0.654/0.486/0.487 | c=0.998437
[Epoch 0006] loss=28.2663 cls=0.6758 smmd=3.3585 ct=10.9967 rec=1.3925 | train/val/test=0.769/0.564/0.567 | c=0.998437
[Epoch 0007] loss=25.7055 cls=0.5683 smmd=2.8710 ct=10.9287 rec=1.3786 | train/val/test=0.846/0.670/0.622 | c=0.998437
[Epoch 0008] loss=22.0038 cls=0.4981 smmd=2.0180 ct=11.5282 rec=1.3649 | train/val/test=0.962/0.736/0.710 | c=0.998437
[Epoch 0009] loss=23.1186 cls=0.4171 smmd=2.2583 ct=11.4827 rec=1.3570 | train/val/test=1.000/0.776/0.738 | c=0.998437
[Epoch 0010] loss=24.7743 cls=0.3562 smmd=2.5923 ct=11.4991 rec=1.3571 | train/val/test=1.000/0.782/0.755 | c=0.998437
[Epoch 0011] loss=22.2542 cls=0.2994 smmd=2.1011 ct=11.4637 rec=1.3541 | train/val/test=1.000/0.762/0.734 | c=0.998437
[Epoch 0012] loss=21.0198 cls=0.2530 smmd=1.8605 ct=11.4559 rec=1.3499 | train/val/test=1.000/0.760/0.730 | c=0.998437
[Epoch 0013] loss=22.8421 cls=0.2150 smmd=2.2113 ct=11.5439 rec=1.3439 | train/val/test=1.000/0.804/0.786 | c=0.998437
[Epoch 0014] loss=21.2893 cls=0.1766 smmd=1.9195 ct=11.4698 rec=1.3375 | train/val/test=1.000/0.792/0.775 | c=0.998437
[Epoch 0015] loss=19.4198 cls=0.1375 smmd=1.5517 ct=11.4606 rec=1.3213 | train/val/test=1.000/0.782/0.768 | c=0.998437
[Epoch 0016] loss=19.8868 cls=0.1050 smmd=1.6439 ct=11.4840 rec=1.3069 | train/val/test=1.000/0.804/0.779 | c=0.998437
[Epoch 0017] loss=19.4032 cls=0.0846 smmd=1.5555 ct=11.4532 rec=1.3024 | train/val/test=1.000/0.810/0.785 | c=0.998437
[Epoch 0018] loss=18.3015 cls=0.0783 smmd=1.3451 ct=11.4059 rec=1.3088 | train/val/test=1.000/0.812/0.778 | c=0.998437
[Epoch 0019] loss=18.0605 cls=0.0693 smmd=1.2889 ct=11.4513 rec=1.3004 | train/val/test=1.000/0.784/0.757 | c=0.998437
[Epoch 0020] loss=18.4294 cls=0.0799 smmd=1.3526 ct=11.4962 rec=1.3028 | train/val/test=1.000/0.792/0.762 | c=0.998437
[Epoch 0021] loss=17.3633 cls=0.0821 smmd=1.1457 ct=11.4629 rec=1.3093 | train/val/test=1.000/0.804/0.762 | c=0.998437
[Epoch 0022] loss=18.2378 cls=0.0940 smmd=1.3206 ct=11.4563 rec=1.3180 | train/val/test=1.000/0.794/0.763 | c=0.998437
[Epoch 0023] loss=17.6223 cls=0.1013 smmd=1.1949 ct=11.4655 rec=1.3173 | train/val/test=1.000/0.780/0.749 | c=0.998437
[Epoch 0024] loss=17.2861 cls=0.1019 smmd=1.1236 ct=11.4857 rec=1.3127 | train/val/test=1.000/0.786/0.765 | c=0.998437
[Epoch 0025] loss=16.8269 cls=0.0873 smmd=1.0360 ct=11.4729 rec=1.3052 | train/val/test=1.000/0.796/0.766 | c=0.998437
[Epoch 0026] loss=16.4994 cls=0.0767 smmd=0.9797 ct=11.4325 rec=1.3015 | train/val/test=1.000/0.810/0.773 | c=0.998437
[Epoch 0027] loss=16.1245 cls=0.0699 smmd=0.9044 ct=11.4374 rec=1.3023 | train/val/test=1.000/0.802/0.768 | c=0.998437
[Epoch 0028] loss=15.7506 cls=0.0694 smmd=0.8290 ct=11.4412 rec=1.2967 | train/val/test=1.000/0.796/0.759 | c=0.998437
[Epoch 0029] loss=15.7481 cls=0.0720 smmd=0.8321 ct=11.4217 rec=1.2980 | train/val/test=1.000/0.816/0.769 | c=0.998437
[Epoch 0030] loss=15.5021 cls=0.0780 smmd=0.7752 ct=11.4564 rec=1.3064 | train/val/test=1.000/0.804/0.761 | c=0.998437
[Epoch 0031] loss=15.7649 cls=0.0821 smmd=0.8234 ct=11.4758 rec=1.3086 | train/val/test=1.000/0.810/0.759 | c=0.998437
[Epoch 0032] loss=16.0016 cls=0.0882 smmd=0.8824 ct=11.4137 rec=1.3152 | train/val/test=1.000/0.808/0.758 | c=0.998437
[Epoch 0033] loss=15.8113 cls=0.0877 smmd=0.8329 ct=11.4715 rec=1.3158 | train/val/test=1.000/0.808/0.757 | c=0.998437
[Epoch 0034] loss=15.5302 cls=0.0783 smmd=0.7780 ct=11.4696 rec=1.3123 | train/val/test=1.000/0.816/0.753 | c=0.998437
[Epoch 0035] loss=15.1185 cls=0.0744 smmd=0.7068 ct=11.4161 rec=1.3139 | train/val/test=1.000/0.802/0.751 | c=0.998437
[Epoch 0036] loss=14.8913 cls=0.0689 smmd=0.6567 ct=11.4427 rec=1.3067 | train/val/test=1.000/0.814/0.750 | c=0.998437
[Epoch 0037] loss=14.6877 cls=0.0663 smmd=0.6208 ct=11.4197 rec=1.3093 | train/val/test=1.000/0.824/0.763 | c=0.998437
[Epoch 0038] loss=14.4083 cls=0.0651 smmd=0.5659 ct=11.4156 rec=1.3066 | train/val/test=1.000/0.816/0.761 | c=0.998437
[Epoch 0039] loss=14.5132 cls=0.0707 smmd=0.5817 ct=11.4385 rec=1.3104 | train/val/test=1.000/0.822/0.761 | c=0.998437
[Epoch 0040] loss=14.6645 cls=0.0796 smmd=0.6140 ct=11.4231 rec=1.3163 | train/val/test=1.000/0.814/0.757 | c=0.998437
[Epoch 0041] loss=14.6264 cls=0.0910 smmd=0.6016 ct=11.4409 rec=1.3205 | train/val/test=1.000/0.806/0.757 | c=0.998437
[Epoch 0042] loss=15.0462 cls=0.1005 smmd=0.6837 ct=11.4448 rec=1.3271 | train/val/test=1.000/0.796/0.741 | c=0.998437
[Epoch 0043] loss=15.1313 cls=0.1044 smmd=0.6929 ct=11.4819 rec=1.3255 | train/val/test=1.000/0.800/0.761 | c=0.998437
[Epoch 0044] loss=14.7219 cls=0.0975 smmd=0.6262 ct=11.4100 rec=1.3238 | train/val/test=1.000/0.786/0.740 | c=0.998437
[Epoch 0045] loss=14.3059 cls=0.0941 smmd=0.5359 ct=11.4475 rec=1.3173 | train/val/test=1.000/0.812/0.752 | c=0.998437
[Epoch 0046] loss=14.2552 cls=0.0815 smmd=0.5325 ct=11.4202 rec=1.3164 | train/val/test=1.000/0.814/0.746 | c=0.998437
[Epoch 0047] loss=14.0633 cls=0.0815 smmd=0.4944 ct=11.4192 rec=1.3136 | train/val/test=1.000/0.804/0.756 | c=0.998437
[Epoch 0048] loss=13.7820 cls=0.0823 smmd=0.4425 ct=11.3966 rec=1.3162 | train/val/test=1.000/0.814/0.748 | c=0.998437
[Epoch 0049] loss=14.0895 cls=0.0898 smmd=0.4946 ct=11.4392 rec=1.3234 | train/val/test=1.000/0.796/0.745 | c=0.998437
[Epoch 0050] loss=14.4928 cls=0.1041 smmd=0.5760 ct=11.4276 rec=1.3309 | train/val/test=1.000/0.768/0.716 | c=0.998437
[Epoch 0051] loss=14.7242 cls=0.1171 smmd=0.6153 ct=11.4552 rec=1.3383 | train/val/test=1.000/0.752/0.736 | c=0.998437
[Epoch 0052] loss=14.9033 cls=0.1401 smmd=0.6473 ct=11.4619 rec=1.3459 | train/val/test=1.000/0.700/0.668 | c=0.998437
[Epoch 0053] loss=14.4878 cls=0.1315 smmd=0.5600 ct=11.4877 rec=1.3445 | train/val/test=1.000/0.758/0.732 | c=0.998437
[Epoch 0054] loss=14.3190 cls=0.1183 smmd=0.5407 ct=11.4227 rec=1.3370 | train/val/test=1.000/0.742/0.699 | c=0.998437
[Epoch 0055] loss=13.7621 cls=0.0952 smmd=0.4267 ct=11.4479 rec=1.3288 | train/val/test=1.000/0.780/0.737 | c=0.998437
[Epoch 0056] loss=13.8829 cls=0.0819 smmd=0.4623 ct=11.3986 rec=1.3178 | train/val/test=1.000/0.802/0.734 | c=0.998437
[Epoch 0057] loss=13.6164 cls=0.0787 smmd=0.4064 ct=11.4129 rec=1.3207 | train/val/test=1.000/0.796/0.748 | c=0.998437
[Epoch 0058] loss=13.6957 cls=0.0856 smmd=0.4206 ct=11.4176 rec=1.3230 | train/val/test=1.000/0.770/0.724 | c=0.998437
[Epoch 0059] loss=13.9569 cls=0.0995 smmd=0.4665 ct=11.4416 rec=1.3317 | train/val/test=1.000/0.790/0.741 | c=0.998437
[Epoch 0060] loss=14.3378 cls=0.1150 smmd=0.5416 ct=11.4383 rec=1.3398 | train/val/test=1.000/0.752/0.698 | c=0.998437
[Epoch 0061] loss=14.7659 cls=0.1211 smmd=0.6156 ct=11.4930 rec=1.3421 | train/val/test=1.000/0.782/0.736 | c=0.998437
[Epoch 0062] loss=14.5879 cls=0.1254 smmd=0.5928 ct=11.4266 rec=1.3437 | train/val/test=1.000/0.734/0.676 | c=0.998437
[Epoch 0063] loss=14.0300 cls=0.1189 smmd=0.4673 ct=11.4998 rec=1.3402 | train/val/test=1.000/0.780/0.748 | c=0.998437
[Epoch 0064] loss=13.9059 cls=0.1001 smmd=0.4616 ct=11.4146 rec=1.3313 | train/val/test=1.000/0.752/0.699 | c=0.998437
[Epoch 0065] loss=13.6457 cls=0.0924 smmd=0.4063 ct=11.4351 rec=1.3264 | train/val/test=1.000/0.786/0.754 | c=0.998437
[Epoch 0066] loss=13.5079 cls=0.0807 smmd=0.3863 ct=11.4038 rec=1.3209 | train/val/test=1.000/0.780/0.729 | c=0.998437
[Epoch 0067] loss=13.5262 cls=0.0863 smmd=0.3864 ct=11.4184 rec=1.3247 | train/val/test=1.000/0.794/0.746 | c=0.998437
[Epoch 0068] loss=13.6283 cls=0.0958 smmd=0.4048 ct=11.4234 rec=1.3306 | train/val/test=1.000/0.776/0.739 | c=0.998437
[Epoch 0069] loss=13.9845 cls=0.1076 smmd=0.4692 ct=11.4511 rec=1.3374 | train/val/test=1.000/0.772/0.750 | c=0.998437
[Epoch 0070] loss=14.6045 cls=0.1242 smmd=0.5917 ct=11.4496 rec=1.3433 | train/val/test=1.000/0.722/0.688 | c=0.998437
[Epoch 0071] loss=14.6931 cls=0.1279 smmd=0.6015 ct=11.4868 rec=1.3501 | train/val/test=1.000/0.708/0.702 | c=0.998437
[Epoch 0072] loss=14.3013 cls=0.1498 smmd=0.5300 ct=11.4412 rec=1.3524 | train/val/test=1.000/0.674/0.649 | c=0.998437
[Epoch 0073] loss=13.8022 cls=0.1238 smmd=0.4252 ct=11.4790 rec=1.3521 | train/val/test=1.000/0.760/0.733 | c=0.998437
[Epoch 0074] loss=13.6078 cls=0.0940 smmd=0.4046 ct=11.4055 rec=1.3223 | train/val/test=1.000/0.778/0.730 | c=0.998437
[Epoch 0075] loss=13.3909 cls=0.0678 smmd=0.3645 ct=11.4031 rec=1.3160 | train/val/test=1.000/0.796/0.746 | c=0.998437
[Epoch 0076] loss=13.3424 cls=0.0691 smmd=0.3532 ct=11.4100 rec=1.3172 | train/val/test=1.000/0.772/0.734 | c=0.998437
[Epoch 0077] loss=13.5008 cls=0.0795 smmd=0.3817 ct=11.4202 rec=1.3234 | train/val/test=1.000/0.786/0.740 | c=0.998437
[Epoch 0078] loss=13.6745 cls=0.0934 smmd=0.4133 ct=11.4278 rec=1.3344 | train/val/test=1.000/0.754/0.723 | c=0.998437
[Epoch 0079] loss=14.3114 cls=0.1091 smmd=0.5288 ct=11.4790 rec=1.3408 | train/val/test=1.000/0.770/0.729 | c=0.998437
[Epoch 0080] loss=15.3036 cls=0.1196 smmd=0.7339 ct=11.4396 rec=1.3481 | train/val/test=1.000/0.726/0.677 | c=0.998437
[Epoch 0081] loss=14.2080 cls=0.1209 smmd=0.5040 ct=11.4929 rec=1.3445 | train/val/test=1.000/0.784/0.744 | c=0.998437
[Epoch 0082] loss=13.8492 cls=0.0957 smmd=0.4464 ct=11.4356 rec=1.3369 | train/val/test=1.000/0.708/0.663 | c=0.998437
[Epoch 0083] loss=13.8588 cls=0.1064 smmd=0.4432 ct=11.4561 rec=1.3339 | train/val/test=1.000/0.784/0.765 | c=0.998437
[Epoch 0084] loss=13.3990 cls=0.0779 smmd=0.3649 ct=11.4035 rec=1.3229 | train/val/test=1.000/0.764/0.702 | c=0.998437
[Epoch 0085] loss=13.3630 cls=0.0861 smmd=0.3520 ct=11.4276 rec=1.3245 | train/val/test=1.000/0.790/0.759 | c=0.998437
[Epoch 0086] loss=13.4288 cls=0.0858 smmd=0.3695 ct=11.4058 rec=1.3235 | train/val/test=1.000/0.792/0.756 | c=0.998437
[Epoch 0087] loss=13.4722 cls=0.0969 smmd=0.3721 ct=11.4299 rec=1.3317 | train/val/test=1.000/0.768/0.744 | c=0.998437
[Epoch 0088] loss=14.1071 cls=0.1223 smmd=0.4899 ct=11.4623 rec=1.3403 | train/val/test=1.000/0.730/0.697 | c=0.998437
[Epoch 0089] loss=15.1828 cls=0.1690 smmd=0.6957 ct=11.4831 rec=1.3676 | train/val/test=1.000/0.654/0.634 | c=0.998437
[Epoch 0090] loss=15.1182 cls=0.2033 smmd=0.6583 ct=11.5888 rec=1.3643 | train/val/test=1.000/0.632/0.612 | c=0.998437
[Epoch 0091] loss=14.4117 cls=0.2042 smmd=0.5335 ct=11.5026 rec=1.3976 | train/val/test=1.000/0.734/0.704 | c=0.998437
[Epoch 0092] loss=13.8108 cls=0.0978 smmd=0.4338 ct=11.4604 rec=1.3222 | train/val/test=1.000/0.794/0.757 | c=0.998437
[Epoch 0093] loss=13.4008 cls=0.0528 smmd=0.3695 ct=11.3964 rec=1.3034 | train/val/test=1.000/0.764/0.736 | c=0.998437
[Epoch 0094] loss=13.2891 cls=0.0593 smmd=0.3428 ct=11.4135 rec=1.3189 | train/val/test=1.000/0.782/0.743 | c=0.998437
[Epoch 0095] loss=13.3139 cls=0.0577 smmd=0.3480 ct=11.4140 rec=1.3090 | train/val/test=1.000/0.770/0.723 | c=0.998437
[Epoch 0096] loss=13.3839 cls=0.0700 smmd=0.3567 ct=11.4334 rec=1.3200 | train/val/test=1.000/0.794/0.759 | c=0.998437
[Epoch 0097] loss=13.6322 cls=0.0895 smmd=0.4020 ct=11.4438 rec=1.3351 | train/val/test=1.000/0.720/0.676 | c=0.998437
[Epoch 0098] loss=14.4952 cls=0.1235 smmd=0.5565 ct=11.5159 rec=1.3473 | train/val/test=0.962/0.624/0.622 | c=0.998437
[Epoch 0099] loss=15.8685 cls=0.1983 smmd=0.8216 ct=11.5230 rec=1.3851 | train/val/test=0.962/0.574/0.569 | c=0.998437
=== Best @ epoch 37: val=0.8240, test=0.7630 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-3 - 2025-09-21 03:58:24:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=39.7743 cls=1.0988 smmd=5.5618 ct=11.2746 rec=1.4137 | train/val/test=0.346/0.200/0.178 | c=0.998437
[Epoch 0001] loss=29.8360 cls=1.0824 smmd=3.5815 ct=11.2461 rec=1.4136 | train/val/test=0.385/0.210/0.200 | c=0.998437
[Epoch 0002] loss=34.9596 cls=1.0578 smmd=4.6061 ct=11.2588 rec=1.4137 | train/val/test=0.500/0.268/0.252 | c=0.998437
[Epoch 0003] loss=33.7252 cls=1.0070 smmd=4.3717 ct=11.2218 rec=1.4135 | train/val/test=0.654/0.426/0.405 | c=0.998437
[Epoch 0004] loss=24.3784 cls=0.9071 smmd=2.5497 ct=11.0354 rec=1.4103 | train/val/test=0.615/0.430/0.407 | c=0.998437
[Epoch 0005] loss=26.5117 cls=0.8039 smmd=2.9804 ct=11.0676 rec=1.4040 | train/val/test=0.654/0.486/0.487 | c=0.998437
[Epoch 0006] loss=28.2663 cls=0.6758 smmd=3.3585 ct=10.9967 rec=1.3925 | train/val/test=0.769/0.564/0.567 | c=0.998437
[Epoch 0007] loss=25.7055 cls=0.5683 smmd=2.8710 ct=10.9287 rec=1.3786 | train/val/test=0.846/0.670/0.622 | c=0.998437
[Epoch 0008] loss=22.0038 cls=0.4981 smmd=2.0180 ct=11.5282 rec=1.3649 | train/val/test=0.962/0.736/0.710 | c=0.998437
[Epoch 0009] loss=23.1186 cls=0.4171 smmd=2.2583 ct=11.4827 rec=1.3570 | train/val/test=1.000/0.776/0.738 | c=0.998437
[Epoch 0010] loss=24.7743 cls=0.3562 smmd=2.5923 ct=11.4991 rec=1.3571 | train/val/test=1.000/0.782/0.755 | c=0.998437
[Epoch 0011] loss=22.2542 cls=0.2994 smmd=2.1011 ct=11.4637 rec=1.3541 | train/val/test=1.000/0.762/0.734 | c=0.998437
[Epoch 0012] loss=21.0198 cls=0.2530 smmd=1.8605 ct=11.4559 rec=1.3499 | train/val/test=1.000/0.760/0.730 | c=0.998437
[Epoch 0013] loss=22.8421 cls=0.2150 smmd=2.2113 ct=11.5439 rec=1.3439 | train/val/test=1.000/0.804/0.786 | c=0.998437
[Epoch 0014] loss=21.2893 cls=0.1766 smmd=1.9195 ct=11.4698 rec=1.3375 | train/val/test=1.000/0.792/0.775 | c=0.998437
[Epoch 0015] loss=19.4198 cls=0.1375 smmd=1.5517 ct=11.4606 rec=1.3213 | train/val/test=1.000/0.782/0.768 | c=0.998437
[Epoch 0016] loss=19.8868 cls=0.1050 smmd=1.6439 ct=11.4840 rec=1.3069 | train/val/test=1.000/0.804/0.779 | c=0.998437
[Epoch 0017] loss=19.4032 cls=0.0846 smmd=1.5555 ct=11.4532 rec=1.3024 | train/val/test=1.000/0.810/0.785 | c=0.998437
[Epoch 0018] loss=18.3015 cls=0.0783 smmd=1.3451 ct=11.4059 rec=1.3088 | train/val/test=1.000/0.812/0.778 | c=0.998437
[Epoch 0019] loss=18.0605 cls=0.0693 smmd=1.2889 ct=11.4513 rec=1.3004 | train/val/test=1.000/0.784/0.757 | c=0.998437
[Epoch 0020] loss=18.4294 cls=0.0799 smmd=1.3526 ct=11.4962 rec=1.3028 | train/val/test=1.000/0.792/0.762 | c=0.998437
[Epoch 0021] loss=17.3633 cls=0.0821 smmd=1.1457 ct=11.4629 rec=1.3093 | train/val/test=1.000/0.804/0.762 | c=0.998437
[Epoch 0022] loss=18.2378 cls=0.0940 smmd=1.3206 ct=11.4563 rec=1.3180 | train/val/test=1.000/0.794/0.763 | c=0.998437
[Epoch 0023] loss=17.6223 cls=0.1013 smmd=1.1949 ct=11.4655 rec=1.3173 | train/val/test=1.000/0.780/0.749 | c=0.998437
[Epoch 0024] loss=17.2861 cls=0.1019 smmd=1.1236 ct=11.4857 rec=1.3127 | train/val/test=1.000/0.786/0.765 | c=0.998437
[Epoch 0025] loss=16.8269 cls=0.0873 smmd=1.0360 ct=11.4729 rec=1.3052 | train/val/test=1.000/0.796/0.766 | c=0.998437
[Epoch 0026] loss=16.4994 cls=0.0767 smmd=0.9797 ct=11.4325 rec=1.3015 | train/val/test=1.000/0.810/0.773 | c=0.998437
[Epoch 0027] loss=16.1245 cls=0.0699 smmd=0.9044 ct=11.4374 rec=1.3023 | train/val/test=1.000/0.802/0.768 | c=0.998437
[Epoch 0028] loss=15.7506 cls=0.0694 smmd=0.8290 ct=11.4412 rec=1.2967 | train/val/test=1.000/0.796/0.759 | c=0.998437
[Epoch 0029] loss=15.7481 cls=0.0720 smmd=0.8321 ct=11.4217 rec=1.2980 | train/val/test=1.000/0.816/0.769 | c=0.998437
[Epoch 0030] loss=15.5021 cls=0.0780 smmd=0.7752 ct=11.4564 rec=1.3064 | train/val/test=1.000/0.804/0.761 | c=0.998437
[Epoch 0031] loss=15.7649 cls=0.0821 smmd=0.8234 ct=11.4758 rec=1.3086 | train/val/test=1.000/0.810/0.759 | c=0.998437
[Epoch 0032] loss=16.0016 cls=0.0882 smmd=0.8824 ct=11.4137 rec=1.3152 | train/val/test=1.000/0.808/0.758 | c=0.998437
[Epoch 0033] loss=15.8113 cls=0.0877 smmd=0.8329 ct=11.4715 rec=1.3158 | train/val/test=1.000/0.808/0.757 | c=0.998437
[Epoch 0034] loss=15.5302 cls=0.0783 smmd=0.7780 ct=11.4696 rec=1.3123 | train/val/test=1.000/0.816/0.753 | c=0.998437
[Epoch 0035] loss=15.1185 cls=0.0744 smmd=0.7068 ct=11.4161 rec=1.3139 | train/val/test=1.000/0.802/0.751 | c=0.998437
[Epoch 0036] loss=14.8913 cls=0.0689 smmd=0.6567 ct=11.4427 rec=1.3067 | train/val/test=1.000/0.814/0.750 | c=0.998437
[Epoch 0037] loss=14.6877 cls=0.0663 smmd=0.6208 ct=11.4197 rec=1.3093 | train/val/test=1.000/0.824/0.763 | c=0.998437
[Epoch 0038] loss=14.4083 cls=0.0651 smmd=0.5659 ct=11.4156 rec=1.3066 | train/val/test=1.000/0.816/0.761 | c=0.998437
[Epoch 0039] loss=14.5132 cls=0.0707 smmd=0.5817 ct=11.4385 rec=1.3104 | train/val/test=1.000/0.822/0.761 | c=0.998437
[Epoch 0040] loss=14.6645 cls=0.0796 smmd=0.6140 ct=11.4231 rec=1.3163 | train/val/test=1.000/0.814/0.757 | c=0.998437
[Epoch 0041] loss=14.6264 cls=0.0910 smmd=0.6016 ct=11.4409 rec=1.3205 | train/val/test=1.000/0.806/0.757 | c=0.998437
[Epoch 0042] loss=15.0462 cls=0.1005 smmd=0.6837 ct=11.4448 rec=1.3271 | train/val/test=1.000/0.796/0.741 | c=0.998437
[Epoch 0043] loss=15.1313 cls=0.1044 smmd=0.6929 ct=11.4819 rec=1.3255 | train/val/test=1.000/0.800/0.761 | c=0.998437
[Epoch 0044] loss=14.7219 cls=0.0975 smmd=0.6262 ct=11.4100 rec=1.3238 | train/val/test=1.000/0.786/0.740 | c=0.998437
[Epoch 0045] loss=14.3059 cls=0.0941 smmd=0.5359 ct=11.4475 rec=1.3173 | train/val/test=1.000/0.812/0.752 | c=0.998437
[Epoch 0046] loss=14.2552 cls=0.0815 smmd=0.5325 ct=11.4202 rec=1.3164 | train/val/test=1.000/0.814/0.746 | c=0.998437
[Epoch 0047] loss=14.0633 cls=0.0815 smmd=0.4944 ct=11.4192 rec=1.3136 | train/val/test=1.000/0.804/0.756 | c=0.998437
[Epoch 0048] loss=13.7820 cls=0.0823 smmd=0.4425 ct=11.3966 rec=1.3162 | train/val/test=1.000/0.814/0.748 | c=0.998437
[Epoch 0049] loss=14.0895 cls=0.0898 smmd=0.4946 ct=11.4392 rec=1.3234 | train/val/test=1.000/0.796/0.745 | c=0.998437
[Epoch 0050] loss=14.4928 cls=0.1041 smmd=0.5760 ct=11.4276 rec=1.3309 | train/val/test=1.000/0.768/0.716 | c=0.998437
[Epoch 0051] loss=14.7242 cls=0.1171 smmd=0.6153 ct=11.4552 rec=1.3383 | train/val/test=1.000/0.752/0.736 | c=0.998437
[Epoch 0052] loss=14.9033 cls=0.1401 smmd=0.6473 ct=11.4619 rec=1.3459 | train/val/test=1.000/0.700/0.668 | c=0.998437
[Epoch 0053] loss=14.4878 cls=0.1315 smmd=0.5600 ct=11.4877 rec=1.3445 | train/val/test=1.000/0.758/0.732 | c=0.998437
[Epoch 0054] loss=14.3190 cls=0.1183 smmd=0.5407 ct=11.4227 rec=1.3370 | train/val/test=1.000/0.742/0.699 | c=0.998437
[Epoch 0055] loss=13.7621 cls=0.0952 smmd=0.4267 ct=11.4479 rec=1.3288 | train/val/test=1.000/0.780/0.737 | c=0.998437
[Epoch 0056] loss=13.8829 cls=0.0819 smmd=0.4623 ct=11.3986 rec=1.3178 | train/val/test=1.000/0.802/0.734 | c=0.998437
[Epoch 0057] loss=13.6164 cls=0.0787 smmd=0.4064 ct=11.4129 rec=1.3207 | train/val/test=1.000/0.796/0.748 | c=0.998437
[Epoch 0058] loss=13.6957 cls=0.0856 smmd=0.4206 ct=11.4176 rec=1.3230 | train/val/test=1.000/0.770/0.724 | c=0.998437
[Epoch 0059] loss=13.9569 cls=0.0995 smmd=0.4665 ct=11.4416 rec=1.3317 | train/val/test=1.000/0.790/0.741 | c=0.998437
[Epoch 0060] loss=14.3378 cls=0.1150 smmd=0.5416 ct=11.4383 rec=1.3398 | train/val/test=1.000/0.752/0.698 | c=0.998437
[Epoch 0061] loss=14.7659 cls=0.1211 smmd=0.6156 ct=11.4930 rec=1.3421 | train/val/test=1.000/0.782/0.736 | c=0.998437
[Epoch 0062] loss=14.5879 cls=0.1254 smmd=0.5928 ct=11.4266 rec=1.3437 | train/val/test=1.000/0.734/0.676 | c=0.998437
[Epoch 0063] loss=14.0300 cls=0.1189 smmd=0.4673 ct=11.4998 rec=1.3402 | train/val/test=1.000/0.780/0.748 | c=0.998437
[Epoch 0064] loss=13.9059 cls=0.1001 smmd=0.4616 ct=11.4146 rec=1.3313 | train/val/test=1.000/0.752/0.699 | c=0.998437
[Epoch 0065] loss=13.6457 cls=0.0924 smmd=0.4063 ct=11.4351 rec=1.3264 | train/val/test=1.000/0.786/0.754 | c=0.998437
[Epoch 0066] loss=13.5079 cls=0.0807 smmd=0.3863 ct=11.4038 rec=1.3209 | train/val/test=1.000/0.780/0.729 | c=0.998437
[Epoch 0067] loss=13.5262 cls=0.0863 smmd=0.3864 ct=11.4184 rec=1.3247 | train/val/test=1.000/0.794/0.746 | c=0.998437
[Epoch 0068] loss=13.6283 cls=0.0958 smmd=0.4048 ct=11.4234 rec=1.3306 | train/val/test=1.000/0.776/0.739 | c=0.998437
[Epoch 0069] loss=13.9845 cls=0.1076 smmd=0.4692 ct=11.4511 rec=1.3374 | train/val/test=1.000/0.772/0.750 | c=0.998437
[Epoch 0070] loss=14.6045 cls=0.1242 smmd=0.5917 ct=11.4496 rec=1.3433 | train/val/test=1.000/0.722/0.688 | c=0.998437
[Epoch 0071] loss=14.6931 cls=0.1279 smmd=0.6015 ct=11.4868 rec=1.3501 | train/val/test=1.000/0.708/0.702 | c=0.998437
[Epoch 0072] loss=14.3013 cls=0.1498 smmd=0.5300 ct=11.4412 rec=1.3524 | train/val/test=1.000/0.674/0.649 | c=0.998437
[Epoch 0073] loss=13.8022 cls=0.1238 smmd=0.4252 ct=11.4790 rec=1.3521 | train/val/test=1.000/0.760/0.733 | c=0.998437
[Epoch 0074] loss=13.6078 cls=0.0940 smmd=0.4046 ct=11.4055 rec=1.3223 | train/val/test=1.000/0.778/0.730 | c=0.998437
[Epoch 0075] loss=13.3909 cls=0.0678 smmd=0.3645 ct=11.4031 rec=1.3160 | train/val/test=1.000/0.796/0.746 | c=0.998437
[Epoch 0076] loss=13.3424 cls=0.0691 smmd=0.3532 ct=11.4100 rec=1.3172 | train/val/test=1.000/0.772/0.734 | c=0.998437
[Epoch 0077] loss=13.5008 cls=0.0795 smmd=0.3817 ct=11.4202 rec=1.3234 | train/val/test=1.000/0.786/0.740 | c=0.998437
[Epoch 0078] loss=13.6745 cls=0.0934 smmd=0.4133 ct=11.4278 rec=1.3344 | train/val/test=1.000/0.754/0.723 | c=0.998437
[Epoch 0079] loss=14.3114 cls=0.1091 smmd=0.5288 ct=11.4790 rec=1.3408 | train/val/test=1.000/0.770/0.729 | c=0.998437
[Epoch 0080] loss=15.3036 cls=0.1196 smmd=0.7339 ct=11.4396 rec=1.3481 | train/val/test=1.000/0.726/0.677 | c=0.998437
[Epoch 0081] loss=14.2080 cls=0.1209 smmd=0.5040 ct=11.4929 rec=1.3445 | train/val/test=1.000/0.784/0.744 | c=0.998437
[Epoch 0082] loss=13.8492 cls=0.0957 smmd=0.4464 ct=11.4356 rec=1.3369 | train/val/test=1.000/0.708/0.663 | c=0.998437
[Epoch 0083] loss=13.8588 cls=0.1064 smmd=0.4432 ct=11.4561 rec=1.3339 | train/val/test=1.000/0.784/0.765 | c=0.998437
[Epoch 0084] loss=13.3990 cls=0.0779 smmd=0.3649 ct=11.4035 rec=1.3229 | train/val/test=1.000/0.764/0.702 | c=0.998437
[Epoch 0085] loss=13.3630 cls=0.0861 smmd=0.3520 ct=11.4276 rec=1.3245 | train/val/test=1.000/0.790/0.759 | c=0.998437
[Epoch 0086] loss=13.4288 cls=0.0858 smmd=0.3695 ct=11.4058 rec=1.3235 | train/val/test=1.000/0.792/0.756 | c=0.998437
[Epoch 0087] loss=13.4722 cls=0.0969 smmd=0.3721 ct=11.4299 rec=1.3317 | train/val/test=1.000/0.768/0.744 | c=0.998437
[Epoch 0088] loss=14.1071 cls=0.1223 smmd=0.4899 ct=11.4623 rec=1.3403 | train/val/test=1.000/0.730/0.697 | c=0.998437
[Epoch 0089] loss=15.1828 cls=0.1690 smmd=0.6957 ct=11.4831 rec=1.3676 | train/val/test=1.000/0.654/0.634 | c=0.998437
[Epoch 0090] loss=15.1182 cls=0.2033 smmd=0.6583 ct=11.5888 rec=1.3643 | train/val/test=1.000/0.632/0.612 | c=0.998437
[Epoch 0091] loss=14.4117 cls=0.2042 smmd=0.5335 ct=11.5026 rec=1.3976 | train/val/test=1.000/0.734/0.704 | c=0.998437
[Epoch 0092] loss=13.8108 cls=0.0978 smmd=0.4338 ct=11.4604 rec=1.3222 | train/val/test=1.000/0.794/0.757 | c=0.998437
[Epoch 0093] loss=13.4008 cls=0.0528 smmd=0.3695 ct=11.3964 rec=1.3034 | train/val/test=1.000/0.764/0.736 | c=0.998437
[Epoch 0094] loss=13.2891 cls=0.0593 smmd=0.3428 ct=11.4135 rec=1.3189 | train/val/test=1.000/0.782/0.743 | c=0.998437
[Epoch 0095] loss=13.3139 cls=0.0577 smmd=0.3480 ct=11.4140 rec=1.3090 | train/val/test=1.000/0.770/0.723 | c=0.998437
[Epoch 0096] loss=13.3839 cls=0.0700 smmd=0.3567 ct=11.4334 rec=1.3200 | train/val/test=1.000/0.794/0.759 | c=0.998437
[Epoch 0097] loss=13.6322 cls=0.0895 smmd=0.4020 ct=11.4438 rec=1.3351 | train/val/test=1.000/0.720/0.676 | c=0.998437
[Epoch 0098] loss=14.4952 cls=0.1235 smmd=0.5565 ct=11.5159 rec=1.3473 | train/val/test=0.962/0.624/0.622 | c=0.998437
[Epoch 0099] loss=15.8685 cls=0.1983 smmd=0.8216 ct=11.5230 rec=1.3851 | train/val/test=0.962/0.574/0.569 | c=0.998437
=== Best @ epoch 37: val=0.8240, test=0.7630 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-3 completed in 139.28 seconds.
==================================================
