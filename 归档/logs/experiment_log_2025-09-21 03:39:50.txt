Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-5 - 2025-09-21 03:39:50:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-5...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.4076 cls=1.0854 smmd=5.6656 ct=7.2510 rec=1.4137 | train/val/test=0.421/0.424/0.425 | c=0.998437
[Epoch 0001] loss=53.1999 cls=1.0581 smmd=3.7576 ct=7.1933 rec=1.4160 | train/val/test=0.551/0.541/0.542 | c=0.998437
[Epoch 0002] loss=37.4995 cls=1.0631 smmd=2.2074 ct=7.0933 rec=1.4139 | train/val/test=0.511/0.516/0.512 | c=0.998437
[Epoch 0003] loss=40.7598 cls=1.0485 smmd=2.5285 ct=7.1218 rec=1.4135 | train/val/test=0.481/0.486/0.472 | c=0.998437
[Epoch 0004] loss=41.8277 cls=1.0084 smmd=2.4952 ct=7.8320 rec=1.4138 | train/val/test=0.597/0.590/0.576 | c=0.998437
[Epoch 0005] loss=37.1531 cls=0.9667 smmd=2.0916 ct=7.5229 rec=1.4167 | train/val/test=0.590/0.584/0.574 | c=0.998437
[Epoch 0006] loss=31.7342 cls=0.9332 smmd=1.5722 ct=7.4187 rec=1.4164 | train/val/test=0.603/0.597/0.587 | c=0.998437
[Epoch 0007] loss=34.8873 cls=0.8932 smmd=1.8797 ct=7.4689 rec=1.4112 | train/val/test=0.656/0.645/0.635 | c=0.998437
[Epoch 0008] loss=36.1556 cls=0.8556 smmd=2.0029 ct=7.4982 rec=1.4041 | train/val/test=0.694/0.687/0.675 | c=0.998437
[Epoch 0009] loss=29.5573 cls=0.8191 smmd=1.3464 ct=7.4928 rec=1.3954 | train/val/test=0.686/0.682/0.665 | c=0.998437
[Epoch 0010] loss=27.9559 cls=0.7917 smmd=1.1732 ct=7.5669 rec=1.3878 | train/val/test=0.711/0.704/0.693 | c=0.998437
[Epoch 0011] loss=30.4428 cls=0.7664 smmd=1.4261 ct=7.5530 rec=1.3854 | train/val/test=0.721/0.714/0.708 | c=0.998437
[Epoch 0012] loss=27.8197 cls=0.7413 smmd=1.1777 ct=7.4914 rec=1.3783 | train/val/test=0.713/0.723/0.703 | c=0.998437
[Epoch 0013] loss=26.0351 cls=0.7369 smmd=0.9960 ct=7.5124 rec=1.3639 | train/val/test=0.696/0.703/0.684 | c=0.998437
[Epoch 0014] loss=26.1741 cls=0.7259 smmd=0.9914 ct=7.6082 rec=1.3606 | train/val/test=0.738/0.740/0.723 | c=0.998437
[Epoch 0015] loss=25.3757 cls=0.6760 smmd=0.9279 ct=7.5402 rec=1.3561 | train/val/test=0.718/0.713/0.708 | c=0.998437
[Epoch 0016] loss=24.6508 cls=0.6739 smmd=0.8629 ct=7.5036 rec=1.3557 | train/val/test=0.733/0.730/0.723 | c=0.998437
[Epoch 0017] loss=23.7673 cls=0.6430 smmd=0.7792 ct=7.4901 rec=1.3469 | train/val/test=0.765/0.769/0.759 | c=0.998437
[Epoch 0018] loss=23.0054 cls=0.6275 smmd=0.6963 ct=7.5293 rec=1.3395 | train/val/test=0.767/0.775/0.765 | c=0.998437
[Epoch 0019] loss=23.0300 cls=0.6321 smmd=0.6884 ct=7.5806 rec=1.3372 | train/val/test=0.781/0.782/0.773 | c=0.998437
[Epoch 0020] loss=22.1024 cls=0.5877 smmd=0.6048 ct=7.5473 rec=1.3322 | train/val/test=0.774/0.771/0.765 | c=0.998437
[Epoch 0021] loss=21.6820 cls=0.5724 smmd=0.5731 ct=7.4999 rec=1.3307 | train/val/test=0.777/0.775/0.773 | c=0.998437
[Epoch 0022] loss=21.7356 cls=0.5626 smmd=0.5806 ct=7.4918 rec=1.3292 | train/val/test=0.804/0.798/0.797 | c=0.998437
[Epoch 0023] loss=20.8563 cls=0.5414 smmd=0.4871 ct=7.5257 rec=1.3275 | train/val/test=0.816/0.814/0.810 | c=0.998437
[Epoch 0024] loss=20.7808 cls=0.5399 smmd=0.4735 ct=7.5563 rec=1.3268 | train/val/test=0.818/0.815/0.814 | c=0.998437
[Epoch 0025] loss=20.3704 cls=0.5297 smmd=0.4359 ct=7.5422 rec=1.3239 | train/val/test=0.812/0.804/0.807 | c=0.998437
[Epoch 0026] loss=20.1609 cls=0.5163 smmd=0.4223 ct=7.5086 rec=1.3245 | train/val/test=0.817/0.811/0.810 | c=0.998437
[Epoch 0027] loss=19.8333 cls=0.5071 smmd=0.3896 ct=7.5110 rec=1.3228 | train/val/test=0.825/0.821/0.823 | c=0.998437
[Epoch 0028] loss=19.5334 cls=0.4971 smmd=0.3578 ct=7.5236 rec=1.3200 | train/val/test=0.828/0.826/0.823 | c=0.998437
[Epoch 0029] loss=19.6233 cls=0.4937 smmd=0.3663 ct=7.5272 rec=1.3174 | train/val/test=0.829/0.828/0.823 | c=0.998437
[Epoch 0030] loss=18.9835 cls=0.4855 smmd=0.3041 ct=7.5206 rec=1.3163 | train/val/test=0.828/0.825/0.825 | c=0.998437
[Epoch 0031] loss=19.0971 cls=0.4787 smmd=0.3174 ct=7.5124 rec=1.3170 | train/val/test=0.829/0.824/0.824 | c=0.998437
[Epoch 0032] loss=18.8371 cls=0.4748 smmd=0.2941 ct=7.5004 rec=1.3150 | train/val/test=0.833/0.828/0.825 | c=0.998437
[Epoch 0033] loss=18.5980 cls=0.4748 smmd=0.2703 ct=7.5006 rec=1.3125 | train/val/test=0.834/0.829/0.827 | c=0.998437
[Epoch 0034] loss=18.4714 cls=0.4698 smmd=0.2569 ct=7.5057 rec=1.3130 | train/val/test=0.835/0.829/0.827 | c=0.998437
[Epoch 0035] loss=18.3436 cls=0.4666 smmd=0.2448 ct=7.5028 rec=1.3143 | train/val/test=0.834/0.828/0.829 | c=0.998437
[Epoch 0036] loss=18.1896 cls=0.4670 smmd=0.2309 ct=7.4952 rec=1.3133 | train/val/test=0.830/0.825/0.824 | c=0.998437
[Epoch 0037] loss=18.1018 cls=0.4687 smmd=0.2225 ct=7.4929 rec=1.3141 | train/val/test=0.839/0.830/0.830 | c=0.998437
[Epoch 0038] loss=18.0514 cls=0.4694 smmd=0.2167 ct=7.4961 rec=1.3150 | train/val/test=0.838/0.829/0.830 | c=0.998437
[Epoch 0039] loss=17.8993 cls=0.4703 smmd=0.2038 ct=7.4841 rec=1.3151 | train/val/test=0.827/0.822/0.820 | c=0.998437
[Epoch 0040] loss=17.8084 cls=0.4735 smmd=0.1942 ct=7.4856 rec=1.3172 | train/val/test=0.838/0.828/0.830 | c=0.998437
[Epoch 0041] loss=17.7189 cls=0.4716 smmd=0.1842 ct=7.4912 rec=1.3183 | train/val/test=0.840/0.833/0.832 | c=0.998437
[Epoch 0042] loss=17.6374 cls=0.4742 smmd=0.1773 ct=7.4841 rec=1.3183 | train/val/test=0.837/0.830/0.829 | c=0.998437
[Epoch 0043] loss=17.5770 cls=0.4745 smmd=0.1733 ct=7.4738 rec=1.3189 | train/val/test=0.840/0.830/0.830 | c=0.998437
[Epoch 0044] loss=17.5384 cls=0.4748 smmd=0.1698 ct=7.4712 rec=1.3212 | train/val/test=0.835/0.829/0.827 | c=0.998437
[Epoch 0045] loss=17.4155 cls=0.4778 smmd=0.1571 ct=7.4725 rec=1.3214 | train/val/test=0.843/0.835/0.834 | c=0.998437
[Epoch 0046] loss=17.3693 cls=0.4787 smmd=0.1520 ct=7.4745 rec=1.3225 | train/val/test=0.840/0.834/0.831 | c=0.998437
[Epoch 0047] loss=17.2965 cls=0.4794 smmd=0.1479 ct=7.4579 rec=1.3238 | train/val/test=0.840/0.835/0.833 | c=0.998437
[Epoch 0048] loss=17.2592 cls=0.4810 smmd=0.1440 ct=7.4579 rec=1.3249 | train/val/test=0.839/0.833/0.832 | c=0.998437
[Epoch 0049] loss=17.2186 cls=0.4830 smmd=0.1394 ct=7.4601 rec=1.3259 | train/val/test=0.841/0.836/0.832 | c=0.998437
[Epoch 0050] loss=17.1528 cls=0.4845 smmd=0.1349 ct=7.4492 rec=1.3266 | train/val/test=0.841/0.838/0.836 | c=0.998437
[Epoch 0051] loss=17.0702 cls=0.4843 smmd=0.1260 ct=7.4522 rec=1.3280 | train/val/test=0.840/0.832/0.832 | c=0.998437
[Epoch 0052] loss=17.0936 cls=0.4860 smmd=0.1299 ct=7.4435 rec=1.3285 | train/val/test=0.842/0.839/0.840 | c=0.998437
[Epoch 0053] loss=17.0398 cls=0.4869 smmd=0.1231 ct=7.4505 rec=1.3285 | train/val/test=0.837/0.829/0.829 | c=0.998437
[Epoch 0054] loss=17.0751 cls=0.4862 smmd=0.1291 ct=7.4381 rec=1.3301 | train/val/test=0.842/0.838/0.837 | c=0.998437
[Epoch 0055] loss=17.0526 cls=0.4856 smmd=0.1259 ct=7.4430 rec=1.3290 | train/val/test=0.840/0.834/0.832 | c=0.998437
[Epoch 0056] loss=16.9678 cls=0.4835 smmd=0.1188 ct=7.4369 rec=1.3293 | train/val/test=0.841/0.837/0.836 | c=0.998437
[Epoch 0057] loss=16.9128 cls=0.4826 smmd=0.1132 ct=7.4378 rec=1.3284 | train/val/test=0.841/0.835/0.834 | c=0.998437
[Epoch 0058] loss=16.9402 cls=0.4808 smmd=0.1173 ct=7.4313 rec=1.3282 | train/val/test=0.841/0.834/0.835 | c=0.998437
[Epoch 0059] loss=16.9316 cls=0.4792 smmd=0.1172 ct=7.4281 rec=1.3282 | train/val/test=0.840/0.831/0.832 | c=0.998437
[Epoch 0060] loss=16.9238 cls=0.4795 smmd=0.1169 ct=7.4257 rec=1.3271 | train/val/test=0.843/0.838/0.837 | c=0.998437
[Epoch 0061] loss=16.9157 cls=0.4792 smmd=0.1163 ct=7.4249 rec=1.3275 | train/val/test=0.839/0.830/0.830 | c=0.998437
[Epoch 0062] loss=16.8585 cls=0.4799 smmd=0.1112 ct=7.4213 rec=1.3277 | train/val/test=0.842/0.836/0.836 | c=0.998437
[Epoch 0063] loss=16.8557 cls=0.4802 smmd=0.1116 ct=7.4178 rec=1.3286 | train/val/test=0.837/0.829/0.828 | c=0.998437
[Epoch 0064] loss=16.8534 cls=0.4846 smmd=0.1110 ct=7.4182 rec=1.3286 | train/val/test=0.844/0.840/0.841 | c=0.998437
[Epoch 0065] loss=16.8712 cls=0.4869 smmd=0.1115 ct=7.4236 rec=1.3303 | train/val/test=0.819/0.810/0.816 | c=0.998437
[Epoch 0066] loss=16.9735 cls=0.4991 smmd=0.1231 ct=7.4126 rec=1.3344 | train/val/test=0.832/0.829/0.828 | c=0.998437
[Epoch 0067] loss=17.1532 cls=0.5137 smmd=0.1337 ct=7.4456 rec=1.3355 | train/val/test=0.790/0.778/0.782 | c=0.998437
[Epoch 0068] loss=17.3068 cls=0.5369 smmd=0.1535 ct=7.4151 rec=1.3459 | train/val/test=0.807/0.813/0.805 | c=0.998437
[Epoch 0069] loss=17.4380 cls=0.5405 smmd=0.1576 ct=7.4612 rec=1.3388 | train/val/test=0.791/0.776/0.782 | c=0.998437
[Epoch 0070] loss=17.4678 cls=0.5292 smmd=0.1721 ct=7.4056 rec=1.3415 | train/val/test=0.834/0.834/0.831 | c=0.998437
[Epoch 0071] loss=17.2135 cls=0.5027 smmd=0.1407 ct=7.4458 rec=1.3262 | train/val/test=0.829/0.823/0.826 | c=0.998437
[Epoch 0072] loss=16.9633 cls=0.4715 smmd=0.1302 ct=7.3822 rec=1.3214 | train/val/test=0.835/0.829/0.829 | c=0.998437
[Epoch 0073] loss=16.8801 cls=0.4717 smmd=0.1175 ct=7.4050 rec=1.3195 | train/val/test=0.842/0.841/0.836 | c=0.998437
[Epoch 0074] loss=16.8975 cls=0.4850 smmd=0.1167 ct=7.4127 rec=1.3252 | train/val/test=0.822/0.814/0.819 | c=0.998437
[Epoch 0075] loss=16.9430 cls=0.4956 smmd=0.1243 ct=7.3926 rec=1.3329 | train/val/test=0.843/0.839/0.839 | c=0.998437
[Epoch 0076] loss=16.9594 cls=0.5018 smmd=0.1200 ct=7.4208 rec=1.3328 | train/val/test=0.832/0.823/0.824 | c=0.998437
[Epoch 0077] loss=16.9704 cls=0.5044 smmd=0.1243 ct=7.4028 rec=1.3385 | train/val/test=0.842/0.839/0.840 | c=0.998437
[Epoch 0078] loss=16.9757 cls=0.5062 smmd=0.1227 ct=7.4132 rec=1.3377 | train/val/test=0.837/0.831/0.830 | c=0.998437
[Epoch 0079] loss=17.0452 cls=0.5047 smmd=0.1312 ct=7.4059 rec=1.3391 | train/val/test=0.842/0.839/0.841 | c=0.998437
[Epoch 0080] loss=17.0172 cls=0.5010 smmd=0.1269 ct=7.4149 rec=1.3366 | train/val/test=0.835/0.828/0.828 | c=0.998437
[Epoch 0081] loss=17.0070 cls=0.4949 smmd=0.1297 ct=7.3971 rec=1.3357 | train/val/test=0.845/0.842/0.840 | c=0.998437
[Epoch 0082] loss=16.9213 cls=0.4926 smmd=0.1182 ct=7.4135 rec=1.3315 | train/val/test=0.833/0.826/0.830 | c=0.998437
[Epoch 0083] loss=16.8591 cls=0.4842 smmd=0.1163 ct=7.3944 rec=1.3295 | train/val/test=0.843/0.842/0.840 | c=0.998437
[Epoch 0084] loss=16.8198 cls=0.4838 smmd=0.1105 ct=7.4046 rec=1.3276 | train/val/test=0.835/0.831/0.831 | c=0.998437
[Epoch 0085] loss=16.7673 cls=0.4819 smmd=0.1082 ct=7.3903 rec=1.3273 | train/val/test=0.840/0.838/0.837 | c=0.998437
[Epoch 0086] loss=16.7343 cls=0.4857 smmd=0.1021 ct=7.4033 rec=1.3280 | train/val/test=0.837/0.830/0.830 | c=0.998437
[Epoch 0087] loss=16.7563 cls=0.4892 smmd=0.1056 ct=7.3951 rec=1.3309 | train/val/test=0.839/0.834/0.835 | c=0.998437
[Epoch 0088] loss=16.7998 cls=0.4933 smmd=0.1084 ct=7.4016 rec=1.3315 | train/val/test=0.836/0.829/0.830 | c=0.998437
[Epoch 0089] loss=16.8738 cls=0.4947 smmd=0.1152 ct=7.4035 rec=1.3345 | train/val/test=0.840/0.838/0.838 | c=0.998437
[Epoch 0090] loss=16.8795 cls=0.4940 smmd=0.1156 ct=7.4052 rec=1.3321 | train/val/test=0.827/0.818/0.823 | c=0.998437
[Epoch 0091] loss=16.9177 cls=0.4960 smmd=0.1209 ct=7.3966 rec=1.3359 | train/val/test=0.843/0.845/0.836 | c=0.998437
[Epoch 0092] loss=17.0737 cls=0.4968 smmd=0.1305 ct=7.4273 rec=1.3311 | train/val/test=0.802/0.792/0.793 | c=0.998437
[Epoch 0093] loss=17.2242 cls=0.5161 smmd=0.1520 ct=7.3875 rec=1.3413 | train/val/test=0.809/0.817/0.811 | c=0.998437
[Epoch 0094] loss=17.3367 cls=0.5413 smmd=0.1471 ct=7.4630 rec=1.3386 | train/val/test=0.774/0.766/0.764 | c=0.998437
[Epoch 0095] loss=17.4247 cls=0.5599 smmd=0.1687 ct=7.3912 rec=1.3513 | train/val/test=0.791/0.796/0.789 | c=0.998437
[Epoch 0096] loss=17.4104 cls=0.5563 smmd=0.1528 ct=7.4671 rec=1.3394 | train/val/test=0.810/0.801/0.803 | c=0.998437
[Epoch 0097] loss=17.1386 cls=0.4967 smmd=0.1470 ct=7.3782 rec=1.3272 | train/val/test=0.841/0.839/0.837 | c=0.998437
[Epoch 0098] loss=16.8099 cls=0.4659 smmd=0.1129 ct=7.3941 rec=1.3187 | train/val/test=0.842/0.843/0.837 | c=0.998437
[Epoch 0099] loss=16.7952 cls=0.4788 smmd=0.1097 ct=7.3995 rec=1.3200 | train/val/test=0.814/0.801/0.804 | c=0.998437
=== Best @ epoch 91: val=0.8445, test=0.8360 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-5 - 2025-09-21 03:39:50:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-5...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.4076 cls=1.0854 smmd=5.6656 ct=7.2510 rec=1.4137 | train/val/test=0.421/0.424/0.425 | c=0.998437
[Epoch 0001] loss=53.1999 cls=1.0581 smmd=3.7576 ct=7.1933 rec=1.4160 | train/val/test=0.551/0.541/0.542 | c=0.998437
[Epoch 0002] loss=37.4995 cls=1.0631 smmd=2.2074 ct=7.0933 rec=1.4139 | train/val/test=0.511/0.516/0.512 | c=0.998437
[Epoch 0003] loss=40.7598 cls=1.0485 smmd=2.5285 ct=7.1218 rec=1.4135 | train/val/test=0.481/0.486/0.472 | c=0.998437
[Epoch 0004] loss=41.8277 cls=1.0084 smmd=2.4952 ct=7.8320 rec=1.4138 | train/val/test=0.597/0.590/0.576 | c=0.998437
[Epoch 0005] loss=37.1531 cls=0.9667 smmd=2.0916 ct=7.5229 rec=1.4167 | train/val/test=0.590/0.584/0.574 | c=0.998437
[Epoch 0006] loss=31.7342 cls=0.9332 smmd=1.5722 ct=7.4187 rec=1.4164 | train/val/test=0.603/0.597/0.587 | c=0.998437
[Epoch 0007] loss=34.8873 cls=0.8932 smmd=1.8797 ct=7.4689 rec=1.4112 | train/val/test=0.656/0.645/0.635 | c=0.998437
[Epoch 0008] loss=36.1556 cls=0.8556 smmd=2.0029 ct=7.4982 rec=1.4041 | train/val/test=0.694/0.687/0.675 | c=0.998437
[Epoch 0009] loss=29.5573 cls=0.8191 smmd=1.3464 ct=7.4928 rec=1.3954 | train/val/test=0.686/0.682/0.665 | c=0.998437
[Epoch 0010] loss=27.9559 cls=0.7917 smmd=1.1732 ct=7.5669 rec=1.3878 | train/val/test=0.711/0.704/0.693 | c=0.998437
[Epoch 0011] loss=30.4428 cls=0.7664 smmd=1.4261 ct=7.5530 rec=1.3854 | train/val/test=0.721/0.714/0.708 | c=0.998437
[Epoch 0012] loss=27.8197 cls=0.7413 smmd=1.1777 ct=7.4914 rec=1.3783 | train/val/test=0.713/0.723/0.703 | c=0.998437
[Epoch 0013] loss=26.0351 cls=0.7369 smmd=0.9960 ct=7.5124 rec=1.3639 | train/val/test=0.696/0.703/0.684 | c=0.998437
[Epoch 0014] loss=26.1741 cls=0.7259 smmd=0.9914 ct=7.6082 rec=1.3606 | train/val/test=0.738/0.740/0.723 | c=0.998437
[Epoch 0015] loss=25.3757 cls=0.6760 smmd=0.9279 ct=7.5402 rec=1.3561 | train/val/test=0.718/0.713/0.708 | c=0.998437
[Epoch 0016] loss=24.6508 cls=0.6739 smmd=0.8629 ct=7.5036 rec=1.3557 | train/val/test=0.733/0.730/0.723 | c=0.998437
[Epoch 0017] loss=23.7673 cls=0.6430 smmd=0.7792 ct=7.4901 rec=1.3469 | train/val/test=0.765/0.769/0.759 | c=0.998437
[Epoch 0018] loss=23.0054 cls=0.6275 smmd=0.6963 ct=7.5293 rec=1.3395 | train/val/test=0.767/0.775/0.765 | c=0.998437
[Epoch 0019] loss=23.0300 cls=0.6321 smmd=0.6884 ct=7.5806 rec=1.3372 | train/val/test=0.781/0.782/0.773 | c=0.998437
[Epoch 0020] loss=22.1024 cls=0.5877 smmd=0.6048 ct=7.5473 rec=1.3322 | train/val/test=0.774/0.771/0.765 | c=0.998437
[Epoch 0021] loss=21.6820 cls=0.5724 smmd=0.5731 ct=7.4999 rec=1.3307 | train/val/test=0.777/0.775/0.773 | c=0.998437
[Epoch 0022] loss=21.7356 cls=0.5626 smmd=0.5806 ct=7.4918 rec=1.3292 | train/val/test=0.804/0.798/0.797 | c=0.998437
[Epoch 0023] loss=20.8563 cls=0.5414 smmd=0.4871 ct=7.5257 rec=1.3275 | train/val/test=0.816/0.814/0.810 | c=0.998437
[Epoch 0024] loss=20.7808 cls=0.5399 smmd=0.4735 ct=7.5563 rec=1.3268 | train/val/test=0.818/0.815/0.814 | c=0.998437
[Epoch 0025] loss=20.3704 cls=0.5297 smmd=0.4359 ct=7.5422 rec=1.3239 | train/val/test=0.812/0.804/0.807 | c=0.998437
[Epoch 0026] loss=20.1609 cls=0.5163 smmd=0.4223 ct=7.5086 rec=1.3245 | train/val/test=0.817/0.811/0.810 | c=0.998437
[Epoch 0027] loss=19.8333 cls=0.5071 smmd=0.3896 ct=7.5110 rec=1.3228 | train/val/test=0.825/0.821/0.823 | c=0.998437
[Epoch 0028] loss=19.5334 cls=0.4971 smmd=0.3578 ct=7.5236 rec=1.3200 | train/val/test=0.828/0.826/0.823 | c=0.998437
[Epoch 0029] loss=19.6233 cls=0.4937 smmd=0.3663 ct=7.5272 rec=1.3174 | train/val/test=0.829/0.828/0.823 | c=0.998437
[Epoch 0030] loss=18.9835 cls=0.4855 smmd=0.3041 ct=7.5206 rec=1.3163 | train/val/test=0.828/0.825/0.825 | c=0.998437
[Epoch 0031] loss=19.0971 cls=0.4787 smmd=0.3174 ct=7.5124 rec=1.3170 | train/val/test=0.829/0.824/0.824 | c=0.998437
[Epoch 0032] loss=18.8371 cls=0.4748 smmd=0.2941 ct=7.5004 rec=1.3150 | train/val/test=0.833/0.828/0.825 | c=0.998437
[Epoch 0033] loss=18.5980 cls=0.4748 smmd=0.2703 ct=7.5006 rec=1.3125 | train/val/test=0.834/0.829/0.827 | c=0.998437
[Epoch 0034] loss=18.4714 cls=0.4698 smmd=0.2569 ct=7.5057 rec=1.3130 | train/val/test=0.835/0.829/0.827 | c=0.998437
[Epoch 0035] loss=18.3436 cls=0.4666 smmd=0.2448 ct=7.5028 rec=1.3143 | train/val/test=0.834/0.828/0.829 | c=0.998437
[Epoch 0036] loss=18.1896 cls=0.4670 smmd=0.2309 ct=7.4952 rec=1.3133 | train/val/test=0.830/0.825/0.824 | c=0.998437
[Epoch 0037] loss=18.1018 cls=0.4687 smmd=0.2225 ct=7.4929 rec=1.3141 | train/val/test=0.839/0.830/0.830 | c=0.998437
[Epoch 0038] loss=18.0514 cls=0.4694 smmd=0.2167 ct=7.4961 rec=1.3150 | train/val/test=0.838/0.829/0.830 | c=0.998437
[Epoch 0039] loss=17.8993 cls=0.4703 smmd=0.2038 ct=7.4841 rec=1.3151 | train/val/test=0.827/0.822/0.820 | c=0.998437
[Epoch 0040] loss=17.8084 cls=0.4735 smmd=0.1942 ct=7.4856 rec=1.3172 | train/val/test=0.838/0.828/0.830 | c=0.998437
[Epoch 0041] loss=17.7189 cls=0.4716 smmd=0.1842 ct=7.4912 rec=1.3183 | train/val/test=0.840/0.833/0.832 | c=0.998437
[Epoch 0042] loss=17.6374 cls=0.4742 smmd=0.1773 ct=7.4841 rec=1.3183 | train/val/test=0.837/0.830/0.829 | c=0.998437
[Epoch 0043] loss=17.5770 cls=0.4745 smmd=0.1733 ct=7.4738 rec=1.3189 | train/val/test=0.840/0.830/0.830 | c=0.998437
[Epoch 0044] loss=17.5384 cls=0.4748 smmd=0.1698 ct=7.4712 rec=1.3212 | train/val/test=0.835/0.829/0.827 | c=0.998437
[Epoch 0045] loss=17.4155 cls=0.4778 smmd=0.1571 ct=7.4725 rec=1.3214 | train/val/test=0.843/0.835/0.834 | c=0.998437
[Epoch 0046] loss=17.3693 cls=0.4787 smmd=0.1520 ct=7.4745 rec=1.3225 | train/val/test=0.840/0.834/0.831 | c=0.998437
[Epoch 0047] loss=17.2965 cls=0.4794 smmd=0.1479 ct=7.4579 rec=1.3238 | train/val/test=0.840/0.835/0.833 | c=0.998437
[Epoch 0048] loss=17.2592 cls=0.4810 smmd=0.1440 ct=7.4579 rec=1.3249 | train/val/test=0.839/0.833/0.832 | c=0.998437
[Epoch 0049] loss=17.2186 cls=0.4830 smmd=0.1394 ct=7.4601 rec=1.3259 | train/val/test=0.841/0.836/0.832 | c=0.998437
[Epoch 0050] loss=17.1528 cls=0.4845 smmd=0.1349 ct=7.4492 rec=1.3266 | train/val/test=0.841/0.838/0.836 | c=0.998437
[Epoch 0051] loss=17.0702 cls=0.4843 smmd=0.1260 ct=7.4522 rec=1.3280 | train/val/test=0.840/0.832/0.832 | c=0.998437
[Epoch 0052] loss=17.0936 cls=0.4860 smmd=0.1299 ct=7.4435 rec=1.3285 | train/val/test=0.842/0.839/0.840 | c=0.998437
[Epoch 0053] loss=17.0398 cls=0.4869 smmd=0.1231 ct=7.4505 rec=1.3285 | train/val/test=0.837/0.829/0.829 | c=0.998437
[Epoch 0054] loss=17.0751 cls=0.4862 smmd=0.1291 ct=7.4381 rec=1.3301 | train/val/test=0.842/0.838/0.837 | c=0.998437
[Epoch 0055] loss=17.0526 cls=0.4856 smmd=0.1259 ct=7.4430 rec=1.3290 | train/val/test=0.840/0.834/0.832 | c=0.998437
[Epoch 0056] loss=16.9678 cls=0.4835 smmd=0.1188 ct=7.4369 rec=1.3293 | train/val/test=0.841/0.837/0.836 | c=0.998437
[Epoch 0057] loss=16.9128 cls=0.4826 smmd=0.1132 ct=7.4378 rec=1.3284 | train/val/test=0.841/0.835/0.834 | c=0.998437
[Epoch 0058] loss=16.9402 cls=0.4808 smmd=0.1173 ct=7.4313 rec=1.3282 | train/val/test=0.841/0.834/0.835 | c=0.998437
[Epoch 0059] loss=16.9316 cls=0.4792 smmd=0.1172 ct=7.4281 rec=1.3282 | train/val/test=0.840/0.831/0.832 | c=0.998437
[Epoch 0060] loss=16.9238 cls=0.4795 smmd=0.1169 ct=7.4257 rec=1.3271 | train/val/test=0.843/0.838/0.837 | c=0.998437
[Epoch 0061] loss=16.9157 cls=0.4792 smmd=0.1163 ct=7.4249 rec=1.3275 | train/val/test=0.839/0.830/0.830 | c=0.998437
[Epoch 0062] loss=16.8585 cls=0.4799 smmd=0.1112 ct=7.4213 rec=1.3277 | train/val/test=0.842/0.836/0.836 | c=0.998437
[Epoch 0063] loss=16.8557 cls=0.4802 smmd=0.1116 ct=7.4178 rec=1.3286 | train/val/test=0.837/0.829/0.828 | c=0.998437
[Epoch 0064] loss=16.8534 cls=0.4846 smmd=0.1110 ct=7.4182 rec=1.3286 | train/val/test=0.844/0.840/0.841 | c=0.998437
[Epoch 0065] loss=16.8712 cls=0.4869 smmd=0.1115 ct=7.4236 rec=1.3303 | train/val/test=0.819/0.810/0.816 | c=0.998437
[Epoch 0066] loss=16.9735 cls=0.4991 smmd=0.1231 ct=7.4126 rec=1.3344 | train/val/test=0.832/0.829/0.828 | c=0.998437
[Epoch 0067] loss=17.1532 cls=0.5137 smmd=0.1337 ct=7.4456 rec=1.3355 | train/val/test=0.790/0.778/0.782 | c=0.998437
[Epoch 0068] loss=17.3068 cls=0.5369 smmd=0.1535 ct=7.4151 rec=1.3459 | train/val/test=0.807/0.813/0.805 | c=0.998437
[Epoch 0069] loss=17.4380 cls=0.5405 smmd=0.1576 ct=7.4612 rec=1.3388 | train/val/test=0.791/0.776/0.782 | c=0.998437
[Epoch 0070] loss=17.4678 cls=0.5292 smmd=0.1721 ct=7.4056 rec=1.3415 | train/val/test=0.834/0.834/0.831 | c=0.998437
[Epoch 0071] loss=17.2135 cls=0.5027 smmd=0.1407 ct=7.4458 rec=1.3262 | train/val/test=0.829/0.823/0.826 | c=0.998437
[Epoch 0072] loss=16.9633 cls=0.4715 smmd=0.1302 ct=7.3822 rec=1.3214 | train/val/test=0.835/0.829/0.829 | c=0.998437
[Epoch 0073] loss=16.8801 cls=0.4717 smmd=0.1175 ct=7.4050 rec=1.3195 | train/val/test=0.842/0.841/0.836 | c=0.998437
[Epoch 0074] loss=16.8975 cls=0.4850 smmd=0.1167 ct=7.4127 rec=1.3252 | train/val/test=0.822/0.814/0.819 | c=0.998437
[Epoch 0075] loss=16.9430 cls=0.4956 smmd=0.1243 ct=7.3926 rec=1.3329 | train/val/test=0.843/0.839/0.839 | c=0.998437
[Epoch 0076] loss=16.9594 cls=0.5018 smmd=0.1200 ct=7.4208 rec=1.3328 | train/val/test=0.832/0.823/0.824 | c=0.998437
[Epoch 0077] loss=16.9704 cls=0.5044 smmd=0.1243 ct=7.4028 rec=1.3385 | train/val/test=0.842/0.839/0.840 | c=0.998437
[Epoch 0078] loss=16.9757 cls=0.5062 smmd=0.1227 ct=7.4132 rec=1.3377 | train/val/test=0.837/0.831/0.830 | c=0.998437
[Epoch 0079] loss=17.0452 cls=0.5047 smmd=0.1312 ct=7.4059 rec=1.3391 | train/val/test=0.842/0.839/0.841 | c=0.998437
[Epoch 0080] loss=17.0172 cls=0.5010 smmd=0.1269 ct=7.4149 rec=1.3366 | train/val/test=0.835/0.828/0.828 | c=0.998437
[Epoch 0081] loss=17.0070 cls=0.4949 smmd=0.1297 ct=7.3971 rec=1.3357 | train/val/test=0.845/0.842/0.840 | c=0.998437
[Epoch 0082] loss=16.9213 cls=0.4926 smmd=0.1182 ct=7.4135 rec=1.3315 | train/val/test=0.833/0.826/0.830 | c=0.998437
[Epoch 0083] loss=16.8591 cls=0.4842 smmd=0.1163 ct=7.3944 rec=1.3295 | train/val/test=0.843/0.842/0.840 | c=0.998437
[Epoch 0084] loss=16.8198 cls=0.4838 smmd=0.1105 ct=7.4046 rec=1.3276 | train/val/test=0.835/0.831/0.831 | c=0.998437
[Epoch 0085] loss=16.7673 cls=0.4819 smmd=0.1082 ct=7.3903 rec=1.3273 | train/val/test=0.840/0.838/0.837 | c=0.998437
[Epoch 0086] loss=16.7343 cls=0.4857 smmd=0.1021 ct=7.4033 rec=1.3280 | train/val/test=0.837/0.830/0.830 | c=0.998437
[Epoch 0087] loss=16.7563 cls=0.4892 smmd=0.1056 ct=7.3951 rec=1.3309 | train/val/test=0.839/0.834/0.835 | c=0.998437
[Epoch 0088] loss=16.7998 cls=0.4933 smmd=0.1084 ct=7.4016 rec=1.3315 | train/val/test=0.836/0.829/0.830 | c=0.998437
[Epoch 0089] loss=16.8738 cls=0.4947 smmd=0.1152 ct=7.4035 rec=1.3345 | train/val/test=0.840/0.838/0.838 | c=0.998437
[Epoch 0090] loss=16.8795 cls=0.4940 smmd=0.1156 ct=7.4052 rec=1.3321 | train/val/test=0.827/0.818/0.823 | c=0.998437
[Epoch 0091] loss=16.9177 cls=0.4960 smmd=0.1209 ct=7.3966 rec=1.3359 | train/val/test=0.843/0.845/0.836 | c=0.998437
[Epoch 0092] loss=17.0737 cls=0.4968 smmd=0.1305 ct=7.4273 rec=1.3311 | train/val/test=0.802/0.792/0.793 | c=0.998437
[Epoch 0093] loss=17.2242 cls=0.5161 smmd=0.1520 ct=7.3875 rec=1.3413 | train/val/test=0.809/0.817/0.811 | c=0.998437
[Epoch 0094] loss=17.3367 cls=0.5413 smmd=0.1471 ct=7.4630 rec=1.3386 | train/val/test=0.774/0.766/0.764 | c=0.998437
[Epoch 0095] loss=17.4247 cls=0.5599 smmd=0.1687 ct=7.3912 rec=1.3513 | train/val/test=0.791/0.796/0.789 | c=0.998437
[Epoch 0096] loss=17.4104 cls=0.5563 smmd=0.1528 ct=7.4671 rec=1.3394 | train/val/test=0.810/0.801/0.803 | c=0.998437
[Epoch 0097] loss=17.1386 cls=0.4967 smmd=0.1470 ct=7.3782 rec=1.3272 | train/val/test=0.841/0.839/0.837 | c=0.998437
[Epoch 0098] loss=16.8099 cls=0.4659 smmd=0.1129 ct=7.3941 rec=1.3187 | train/val/test=0.842/0.843/0.837 | c=0.998437
[Epoch 0099] loss=16.7952 cls=0.4788 smmd=0.1097 ct=7.3995 rec=1.3200 | train/val/test=0.814/0.801/0.804 | c=0.998437
=== Best @ epoch 91: val=0.8445, test=0.8360 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-5 completed in 140.10 seconds.
==================================================
