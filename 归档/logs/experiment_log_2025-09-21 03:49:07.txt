Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-4 - 2025-09-21 03:49:07:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-4...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.5425 cls=1.0988 smmd=5.6039 ct=11.2765 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.998437
[Epoch 0001] loss=22.2892 cls=1.0860 smmd=3.9154 ct=11.2509 rec=1.4136 | train/val/test=0.462/0.228/0.212 | c=0.998437
[Epoch 0002] loss=24.6141 cls=1.0752 smmd=4.8519 ct=11.2400 rec=1.4136 | train/val/test=0.769/0.612/0.625 | c=0.998437
[Epoch 0003] loss=23.5512 cls=1.0461 smmd=4.4814 ct=11.1180 rec=1.4133 | train/val/test=0.846/0.680/0.679 | c=0.998437
[Epoch 0004] loss=18.2131 cls=0.9925 smmd=2.4227 ct=10.9538 rec=1.4125 | train/val/test=0.692/0.602/0.618 | c=0.998437
[Epoch 0005] loss=19.7185 cls=0.9413 smmd=3.0435 ct=10.9335 rec=1.4111 | train/val/test=0.692/0.624/0.639 | c=0.998437
[Epoch 0006] loss=20.3744 cls=0.8918 smmd=3.3231 ct=10.9164 rec=1.4087 | train/val/test=0.923/0.666/0.664 | c=0.998437
[Epoch 0007] loss=18.4983 cls=0.8429 smmd=2.5981 ct=10.8790 rec=1.4050 | train/val/test=0.923/0.678/0.663 | c=0.998437
[Epoch 0008] loss=16.4408 cls=0.8070 smmd=1.7930 ct=10.8541 rec=1.4013 | train/val/test=0.846/0.666/0.662 | c=0.998437
[Epoch 0009] loss=18.1548 cls=0.7938 smmd=2.4684 ct=10.8870 rec=1.4000 | train/val/test=0.923/0.676/0.665 | c=0.998437
[Epoch 0010] loss=18.3451 cls=0.7741 smmd=2.5440 ct=10.8979 rec=1.4006 | train/val/test=0.923/0.694/0.677 | c=0.998437
[Epoch 0011] loss=16.0883 cls=0.7513 smmd=1.6450 ct=10.8993 rec=1.4019 | train/val/test=0.923/0.682/0.684 | c=0.998437
[Epoch 0012] loss=17.5910 cls=0.7328 smmd=2.2493 ct=10.9010 rec=1.4004 | train/val/test=0.923/0.684/0.679 | c=0.998437
[Epoch 0013] loss=17.2216 cls=0.6973 smmd=2.1116 ct=10.8963 rec=1.3954 | train/val/test=0.923/0.684/0.674 | c=0.998437
[Epoch 0014] loss=15.9760 cls=0.6355 smmd=1.6354 ct=10.8749 rec=1.3896 | train/val/test=0.923/0.696/0.677 | c=0.998437
[Epoch 0015] loss=15.8341 cls=0.5799 smmd=1.5936 ct=10.8684 rec=1.3834 | train/val/test=0.923/0.698/0.680 | c=0.998437
[Epoch 0016] loss=15.5876 cls=0.5370 smmd=1.5085 ct=10.8598 rec=1.3760 | train/val/test=0.923/0.686/0.683 | c=0.998437
[Epoch 0017] loss=15.2849 cls=0.5164 smmd=1.3949 ct=10.8535 rec=1.3719 | train/val/test=1.000/0.682/0.679 | c=0.998437
[Epoch 0018] loss=14.9118 cls=0.5057 smmd=1.2466 ct=10.8565 rec=1.3718 | train/val/test=0.923/0.698/0.687 | c=0.998437
[Epoch 0019] loss=14.9011 cls=0.4923 smmd=1.2426 ct=10.8613 rec=1.3745 | train/val/test=0.923/0.714/0.702 | c=0.998437
[Epoch 0020] loss=14.8857 cls=0.4899 smmd=1.2304 ct=10.8751 rec=1.3793 | train/val/test=0.923/0.704/0.703 | c=0.998437
[Epoch 0021] loss=14.8398 cls=0.4922 smmd=1.2098 ct=10.8781 rec=1.3820 | train/val/test=1.000/0.720/0.713 | c=0.998437
[Epoch 0022] loss=14.6903 cls=0.4840 smmd=1.1476 ct=10.8884 rec=1.3817 | train/val/test=1.000/0.712/0.719 | c=0.998437
[Epoch 0023] loss=14.7811 cls=0.4478 smmd=1.1956 ct=10.8774 rec=1.3817 | train/val/test=1.000/0.730/0.720 | c=0.998437
[Epoch 0024] loss=14.2373 cls=0.4097 smmd=1.0008 ct=10.8441 rec=1.3725 | train/val/test=1.000/0.732/0.723 | c=0.998437
[Epoch 0025] loss=14.0745 cls=0.3716 smmd=0.9458 ct=10.8409 rec=1.3665 | train/val/test=1.000/0.734/0.725 | c=0.998437
[Epoch 0026] loss=13.8811 cls=0.3403 smmd=0.8806 ct=10.8295 rec=1.3600 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0027] loss=13.7364 cls=0.3182 smmd=0.8290 ct=10.8264 rec=1.3570 | train/val/test=1.000/0.728/0.736 | c=0.998437
[Epoch 0028] loss=13.5775 cls=0.3119 smmd=0.7652 ct=10.8298 rec=1.3575 | train/val/test=1.000/0.738/0.735 | c=0.998437
[Epoch 0029] loss=13.7921 cls=0.3191 smmd=0.8449 ct=10.8405 rec=1.3598 | train/val/test=1.000/0.720/0.732 | c=0.998437
[Epoch 0030] loss=13.7577 cls=0.3131 smmd=0.8270 ct=10.8520 rec=1.3634 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0031] loss=13.9120 cls=0.3064 smmd=0.8885 ct=10.8567 rec=1.3614 | train/val/test=1.000/0.730/0.736 | c=0.998437
[Epoch 0032] loss=13.8615 cls=0.2886 smmd=0.8728 ct=10.8557 rec=1.3589 | train/val/test=1.000/0.728/0.719 | c=0.998437
[Epoch 0033] loss=13.6138 cls=0.2669 smmd=0.7841 ct=10.8445 rec=1.3511 | train/val/test=1.000/0.720/0.726 | c=0.998437
[Epoch 0034] loss=13.4152 cls=0.2385 smmd=0.7168 ct=10.8322 rec=1.3438 | train/val/test=1.000/0.724/0.722 | c=0.998437
[Epoch 0035] loss=13.3183 cls=0.2210 smmd=0.6846 ct=10.8269 rec=1.3390 | train/val/test=1.000/0.720/0.721 | c=0.998437
[Epoch 0036] loss=13.1734 cls=0.2147 smmd=0.6263 ct=10.8314 rec=1.3377 | train/val/test=1.000/0.730/0.725 | c=0.998437
[Epoch 0037] loss=13.1501 cls=0.2154 smmd=0.6160 ct=10.8327 rec=1.3393 | train/val/test=1.000/0.728/0.728 | c=0.998437
[Epoch 0038] loss=13.2714 cls=0.2181 smmd=0.6595 ct=10.8413 rec=1.3447 | train/val/test=1.000/0.728/0.735 | c=0.998437
[Epoch 0039] loss=13.3140 cls=0.2292 smmd=0.6699 ct=10.8514 rec=1.3463 | train/val/test=1.000/0.728/0.726 | c=0.998437
[Epoch 0040] loss=13.5510 cls=0.2250 smmd=0.7623 ct=10.8578 rec=1.3499 | train/val/test=1.000/0.720/0.722 | c=0.998437
[Epoch 0041] loss=13.4339 cls=0.2151 smmd=0.7195 ct=10.8557 rec=1.3441 | train/val/test=1.000/0.724/0.715 | c=0.998437
[Epoch 0042] loss=13.1745 cls=0.1938 smmd=0.6254 ct=10.8450 rec=1.3381 | train/val/test=1.000/0.722/0.722 | c=0.998437
[Epoch 0043] loss=13.1048 cls=0.1761 smmd=0.6084 ct=10.8305 rec=1.3302 | train/val/test=1.000/0.718/0.715 | c=0.998437
[Epoch 0044] loss=12.9670 cls=0.1638 smmd=0.5580 ct=10.8270 rec=1.3263 | train/val/test=1.000/0.724/0.720 | c=0.998437
[Epoch 0045] loss=12.8413 cls=0.1618 smmd=0.5081 ct=10.8275 rec=1.3253 | train/val/test=1.000/0.720/0.725 | c=0.998437
[Epoch 0046] loss=13.0078 cls=0.1645 smmd=0.5698 ct=10.8364 rec=1.3292 | train/val/test=1.000/0.728/0.723 | c=0.998437
[Epoch 0047] loss=12.9839 cls=0.1758 smmd=0.5533 ct=10.8466 rec=1.3322 | train/val/test=1.000/0.712/0.714 | c=0.998437
[Epoch 0048] loss=13.3700 cls=0.1835 smmd=0.6965 ct=10.8670 rec=1.3400 | train/val/test=1.000/0.714/0.718 | c=0.998437
[Epoch 0049] loss=13.5928 cls=0.1902 smmd=0.7809 ct=10.8768 rec=1.3374 | train/val/test=1.000/0.678/0.683 | c=0.998437
[Epoch 0050] loss=13.1683 cls=0.1776 smmd=0.6165 ct=10.8700 rec=1.3365 | train/val/test=1.000/0.718/0.707 | c=0.998437
[Epoch 0051] loss=13.0201 cls=0.1530 smmd=0.5711 ct=10.8543 rec=1.3232 | train/val/test=1.000/0.704/0.702 | c=0.998437
[Epoch 0052] loss=12.8259 cls=0.1304 smmd=0.5103 ct=10.8275 rec=1.3148 | train/val/test=1.000/0.724/0.715 | c=0.998437
[Epoch 0053] loss=12.8616 cls=0.1207 smmd=0.5303 ct=10.8196 rec=1.3119 | train/val/test=1.000/0.714/0.717 | c=0.998437
[Epoch 0054] loss=12.6890 cls=0.1237 smmd=0.4555 ct=10.8309 rec=1.3151 | train/val/test=1.000/0.726/0.724 | c=0.998437
[Epoch 0055] loss=12.8462 cls=0.1357 smmd=0.5122 ct=10.8369 rec=1.3217 | train/val/test=1.000/0.712/0.724 | c=0.998437
[Epoch 0056] loss=13.1335 cls=0.1517 smmd=0.6126 ct=10.8602 rec=1.3320 | train/val/test=1.000/0.724/0.724 | c=0.998437
[Epoch 0057] loss=13.2845 cls=0.1594 smmd=0.6701 ct=10.8633 rec=1.3325 | train/val/test=1.000/0.714/0.710 | c=0.998437
[Epoch 0058] loss=13.2303 cls=0.1486 smmd=0.6506 ct=10.8635 rec=1.3317 | train/val/test=1.000/0.718/0.711 | c=0.998437
[Epoch 0059] loss=13.1438 cls=0.1393 smmd=0.6250 ct=10.8507 rec=1.3217 | train/val/test=1.000/0.706/0.701 | c=0.998437
[Epoch 0060] loss=12.7430 cls=0.1171 smmd=0.4771 ct=10.8347 rec=1.3142 | train/val/test=1.000/0.724/0.713 | c=0.998437
[Epoch 0061] loss=12.7101 cls=0.1125 smmd=0.4680 ct=10.8289 rec=1.3100 | train/val/test=1.000/0.702/0.703 | c=0.998437
[Epoch 0062] loss=12.7330 cls=0.1093 smmd=0.4749 ct=10.8360 rec=1.3102 | train/val/test=1.000/0.724/0.714 | c=0.998437
[Epoch 0063] loss=12.7117 cls=0.1135 smmd=0.4659 ct=10.8335 rec=1.3136 | train/val/test=1.000/0.714/0.713 | c=0.998437
[Epoch 0064] loss=12.8506 cls=0.1243 smmd=0.5095 ct=10.8542 rec=1.3212 | train/val/test=1.000/0.726/0.725 | c=0.998437
[Epoch 0065] loss=13.1870 cls=0.1369 smmd=0.6338 ct=10.8710 rec=1.3260 | train/val/test=1.000/0.698/0.692 | c=0.998437
[Epoch 0066] loss=13.3404 cls=0.1461 smmd=0.6874 ct=10.8815 rec=1.3346 | train/val/test=1.000/0.722/0.717 | c=0.998437
[Epoch 0067] loss=13.1476 cls=0.1367 smmd=0.6143 ct=10.8820 rec=1.3232 | train/val/test=1.000/0.684/0.683 | c=0.998437
[Epoch 0068] loss=12.8272 cls=0.1152 smmd=0.5038 ct=10.8525 rec=1.3150 | train/val/test=1.000/0.720/0.718 | c=0.998437
[Epoch 0069] loss=12.7373 cls=0.0857 smmd=0.4854 ct=10.8305 rec=1.3008 | train/val/test=1.000/0.718/0.707 | c=0.998437
[Epoch 0070] loss=12.5490 cls=0.0793 smmd=0.4161 ct=10.8205 rec=1.2974 | train/val/test=1.000/0.724/0.715 | c=0.998437
[Epoch 0071] loss=12.5421 cls=0.0831 smmd=0.4115 ct=10.8216 rec=1.3006 | train/val/test=1.000/0.718/0.721 | c=0.998437
[Epoch 0072] loss=12.6649 cls=0.0950 smmd=0.4482 ct=10.8426 rec=1.3089 | train/val/test=1.000/0.724/0.725 | c=0.998437
[Epoch 0073] loss=12.8309 cls=0.1118 smmd=0.5039 ct=10.8566 rec=1.3173 | train/val/test=1.000/0.718/0.726 | c=0.998437
[Epoch 0074] loss=13.3462 cls=0.1274 smmd=0.7021 ct=10.8652 rec=1.3241 | train/val/test=1.000/0.714/0.718 | c=0.998437
[Epoch 0075] loss=13.3572 cls=0.1199 smmd=0.7069 ct=10.8689 rec=1.3222 | train/val/test=1.000/0.714/0.714 | c=0.998437
[Epoch 0076] loss=12.9254 cls=0.1198 smmd=0.5410 ct=10.8557 rec=1.3144 | train/val/test=1.000/0.694/0.687 | c=0.998437
[Epoch 0077] loss=12.6568 cls=0.0979 smmd=0.4425 ct=10.8474 rec=1.3086 | train/val/test=1.000/0.718/0.716 | c=0.998437
[Epoch 0078] loss=12.5946 cls=0.0948 smmd=0.4260 ct=10.8306 rec=1.3029 | train/val/test=1.000/0.710/0.703 | c=0.998437
[Epoch 0079] loss=12.5398 cls=0.0787 smmd=0.4098 ct=10.8273 rec=1.2976 | train/val/test=1.000/0.726/0.725 | c=0.998437
[Epoch 0080] loss=12.4584 cls=0.0781 smmd=0.3754 ct=10.8306 rec=1.3006 | train/val/test=1.000/0.730/0.717 | c=0.998437
[Epoch 0081] loss=12.6330 cls=0.0923 smmd=0.4369 ct=10.8404 rec=1.3082 | train/val/test=1.000/0.718/0.725 | c=0.998437
[Epoch 0082] loss=12.9575 cls=0.1050 smmd=0.5499 ct=10.8700 rec=1.3204 | train/val/test=1.000/0.718/0.707 | c=0.998437
[Epoch 0083] loss=13.4540 cls=0.1195 smmd=0.7369 ct=10.8916 rec=1.3208 | train/val/test=1.000/0.694/0.720 | c=0.998437
[Epoch 0084] loss=13.4713 cls=0.1227 smmd=0.7461 ct=10.8806 rec=1.3278 | train/val/test=1.000/0.666/0.644 | c=0.998437
[Epoch 0085] loss=12.6809 cls=0.1148 smmd=0.4361 ct=10.8763 rec=1.3140 | train/val/test=1.000/0.706/0.720 | c=0.998437
[Epoch 0086] loss=12.8818 cls=0.0940 smmd=0.5348 ct=10.8473 rec=1.3008 | train/val/test=1.000/0.712/0.696 | c=0.998437
[Epoch 0087] loss=12.5079 cls=0.0522 smmd=0.4109 ct=10.8119 rec=1.2853 | train/val/test=1.000/0.716/0.700 | c=0.998437
[Epoch 0088] loss=12.4356 cls=0.0554 smmd=0.3761 ct=10.8235 rec=1.2884 | train/val/test=1.000/0.722/0.726 | c=0.998437
[Epoch 0089] loss=12.6743 cls=0.0748 smmd=0.4561 ct=10.8461 rec=1.3009 | train/val/test=1.000/0.702/0.681 | c=0.998437
[Epoch 0090] loss=12.7635 cls=0.0966 smmd=0.4748 ct=10.8706 rec=1.3152 | train/val/test=1.000/0.708/0.723 | c=0.998437
[Epoch 0091] loss=13.4033 cls=0.1512 smmd=0.6927 ct=10.9266 rec=1.3389 | train/val/test=1.000/0.480/0.448 | c=0.998437
[Epoch 0092] loss=14.0151 cls=0.2545 smmd=0.8859 ct=10.9835 rec=1.3790 | train/val/test=0.846/0.660/0.688 | c=0.998437
[Epoch 0093] loss=13.6683 cls=0.2452 smmd=0.7576 ct=10.9699 rec=1.3638 | train/val/test=1.000/0.680/0.668 | c=0.998437
[Epoch 0094] loss=12.6322 cls=0.0660 smmd=0.4443 ct=10.8394 rec=1.2981 | train/val/test=1.000/0.662/0.638 | c=0.998437
[Epoch 0095] loss=12.7981 cls=0.0542 smmd=0.5152 ct=10.8363 rec=1.2933 | train/val/test=1.000/0.714/0.725 | c=0.998437
[Epoch 0096] loss=12.5628 cls=0.0417 smmd=0.4244 ct=10.8374 rec=1.2873 | train/val/test=1.000/0.730/0.731 | c=0.998437
[Epoch 0097] loss=12.7119 cls=0.0323 smmd=0.4890 ct=10.8321 rec=1.2822 | train/val/test=1.000/0.652/0.641 | c=0.998437
[Epoch 0098] loss=12.5937 cls=0.0647 smmd=0.4160 ct=10.8677 rec=1.3074 | train/val/test=1.000/0.714/0.731 | c=0.998437
[Epoch 0099] loss=12.6618 cls=0.0654 smmd=0.4449 ct=10.8647 rec=1.3041 | train/val/test=1.000/0.738/0.725 | c=0.998437
=== Best @ epoch 28: val=0.7380, test=0.7350 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-4 - 2025-09-21 03:49:07:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-4...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.5425 cls=1.0988 smmd=5.6039 ct=11.2765 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.998437
[Epoch 0001] loss=22.2892 cls=1.0860 smmd=3.9154 ct=11.2509 rec=1.4136 | train/val/test=0.462/0.228/0.212 | c=0.998437
[Epoch 0002] loss=24.6141 cls=1.0752 smmd=4.8519 ct=11.2400 rec=1.4136 | train/val/test=0.769/0.612/0.625 | c=0.998437
[Epoch 0003] loss=23.5512 cls=1.0461 smmd=4.4814 ct=11.1180 rec=1.4133 | train/val/test=0.846/0.680/0.679 | c=0.998437
[Epoch 0004] loss=18.2131 cls=0.9925 smmd=2.4227 ct=10.9538 rec=1.4125 | train/val/test=0.692/0.602/0.618 | c=0.998437
[Epoch 0005] loss=19.7185 cls=0.9413 smmd=3.0435 ct=10.9335 rec=1.4111 | train/val/test=0.692/0.624/0.639 | c=0.998437
[Epoch 0006] loss=20.3744 cls=0.8918 smmd=3.3231 ct=10.9164 rec=1.4087 | train/val/test=0.923/0.666/0.664 | c=0.998437
[Epoch 0007] loss=18.4983 cls=0.8429 smmd=2.5981 ct=10.8790 rec=1.4050 | train/val/test=0.923/0.678/0.663 | c=0.998437
[Epoch 0008] loss=16.4408 cls=0.8070 smmd=1.7930 ct=10.8541 rec=1.4013 | train/val/test=0.846/0.666/0.662 | c=0.998437
[Epoch 0009] loss=18.1548 cls=0.7938 smmd=2.4684 ct=10.8870 rec=1.4000 | train/val/test=0.923/0.676/0.665 | c=0.998437
[Epoch 0010] loss=18.3451 cls=0.7741 smmd=2.5440 ct=10.8979 rec=1.4006 | train/val/test=0.923/0.694/0.677 | c=0.998437
[Epoch 0011] loss=16.0883 cls=0.7513 smmd=1.6450 ct=10.8993 rec=1.4019 | train/val/test=0.923/0.682/0.684 | c=0.998437
[Epoch 0012] loss=17.5910 cls=0.7328 smmd=2.2493 ct=10.9010 rec=1.4004 | train/val/test=0.923/0.684/0.679 | c=0.998437
[Epoch 0013] loss=17.2216 cls=0.6973 smmd=2.1116 ct=10.8963 rec=1.3954 | train/val/test=0.923/0.684/0.674 | c=0.998437
[Epoch 0014] loss=15.9760 cls=0.6355 smmd=1.6354 ct=10.8749 rec=1.3896 | train/val/test=0.923/0.696/0.677 | c=0.998437
[Epoch 0015] loss=15.8341 cls=0.5799 smmd=1.5936 ct=10.8684 rec=1.3834 | train/val/test=0.923/0.698/0.680 | c=0.998437
[Epoch 0016] loss=15.5876 cls=0.5370 smmd=1.5085 ct=10.8598 rec=1.3760 | train/val/test=0.923/0.686/0.683 | c=0.998437
[Epoch 0017] loss=15.2849 cls=0.5164 smmd=1.3949 ct=10.8535 rec=1.3719 | train/val/test=1.000/0.682/0.679 | c=0.998437
[Epoch 0018] loss=14.9118 cls=0.5057 smmd=1.2466 ct=10.8565 rec=1.3718 | train/val/test=0.923/0.698/0.687 | c=0.998437
[Epoch 0019] loss=14.9011 cls=0.4923 smmd=1.2426 ct=10.8613 rec=1.3745 | train/val/test=0.923/0.714/0.702 | c=0.998437
[Epoch 0020] loss=14.8857 cls=0.4899 smmd=1.2304 ct=10.8751 rec=1.3793 | train/val/test=0.923/0.704/0.703 | c=0.998437
[Epoch 0021] loss=14.8398 cls=0.4922 smmd=1.2098 ct=10.8781 rec=1.3820 | train/val/test=1.000/0.720/0.713 | c=0.998437
[Epoch 0022] loss=14.6903 cls=0.4840 smmd=1.1476 ct=10.8884 rec=1.3817 | train/val/test=1.000/0.712/0.719 | c=0.998437
[Epoch 0023] loss=14.7811 cls=0.4478 smmd=1.1956 ct=10.8774 rec=1.3817 | train/val/test=1.000/0.730/0.720 | c=0.998437
[Epoch 0024] loss=14.2373 cls=0.4097 smmd=1.0008 ct=10.8441 rec=1.3725 | train/val/test=1.000/0.732/0.723 | c=0.998437
[Epoch 0025] loss=14.0745 cls=0.3716 smmd=0.9458 ct=10.8409 rec=1.3665 | train/val/test=1.000/0.734/0.725 | c=0.998437
[Epoch 0026] loss=13.8811 cls=0.3403 smmd=0.8806 ct=10.8295 rec=1.3600 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0027] loss=13.7364 cls=0.3182 smmd=0.8290 ct=10.8264 rec=1.3570 | train/val/test=1.000/0.728/0.736 | c=0.998437
[Epoch 0028] loss=13.5775 cls=0.3119 smmd=0.7652 ct=10.8298 rec=1.3575 | train/val/test=1.000/0.738/0.735 | c=0.998437
[Epoch 0029] loss=13.7921 cls=0.3191 smmd=0.8449 ct=10.8405 rec=1.3598 | train/val/test=1.000/0.720/0.732 | c=0.998437
[Epoch 0030] loss=13.7577 cls=0.3131 smmd=0.8270 ct=10.8520 rec=1.3634 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0031] loss=13.9120 cls=0.3064 smmd=0.8885 ct=10.8567 rec=1.3614 | train/val/test=1.000/0.730/0.736 | c=0.998437
[Epoch 0032] loss=13.8615 cls=0.2886 smmd=0.8728 ct=10.8557 rec=1.3589 | train/val/test=1.000/0.728/0.719 | c=0.998437
[Epoch 0033] loss=13.6138 cls=0.2669 smmd=0.7841 ct=10.8445 rec=1.3511 | train/val/test=1.000/0.720/0.726 | c=0.998437
[Epoch 0034] loss=13.4152 cls=0.2385 smmd=0.7168 ct=10.8322 rec=1.3438 | train/val/test=1.000/0.724/0.722 | c=0.998437
[Epoch 0035] loss=13.3183 cls=0.2210 smmd=0.6846 ct=10.8269 rec=1.3390 | train/val/test=1.000/0.720/0.721 | c=0.998437
[Epoch 0036] loss=13.1734 cls=0.2147 smmd=0.6263 ct=10.8314 rec=1.3377 | train/val/test=1.000/0.730/0.725 | c=0.998437
[Epoch 0037] loss=13.1501 cls=0.2154 smmd=0.6160 ct=10.8327 rec=1.3393 | train/val/test=1.000/0.728/0.728 | c=0.998437
[Epoch 0038] loss=13.2714 cls=0.2181 smmd=0.6595 ct=10.8413 rec=1.3447 | train/val/test=1.000/0.728/0.735 | c=0.998437
[Epoch 0039] loss=13.3140 cls=0.2292 smmd=0.6699 ct=10.8514 rec=1.3463 | train/val/test=1.000/0.728/0.726 | c=0.998437
[Epoch 0040] loss=13.5510 cls=0.2250 smmd=0.7623 ct=10.8578 rec=1.3499 | train/val/test=1.000/0.720/0.722 | c=0.998437
[Epoch 0041] loss=13.4339 cls=0.2151 smmd=0.7195 ct=10.8557 rec=1.3441 | train/val/test=1.000/0.724/0.715 | c=0.998437
[Epoch 0042] loss=13.1745 cls=0.1938 smmd=0.6254 ct=10.8450 rec=1.3381 | train/val/test=1.000/0.722/0.722 | c=0.998437
[Epoch 0043] loss=13.1048 cls=0.1761 smmd=0.6084 ct=10.8305 rec=1.3302 | train/val/test=1.000/0.718/0.715 | c=0.998437
[Epoch 0044] loss=12.9670 cls=0.1638 smmd=0.5580 ct=10.8270 rec=1.3263 | train/val/test=1.000/0.724/0.720 | c=0.998437
[Epoch 0045] loss=12.8413 cls=0.1618 smmd=0.5081 ct=10.8275 rec=1.3253 | train/val/test=1.000/0.720/0.725 | c=0.998437
[Epoch 0046] loss=13.0078 cls=0.1645 smmd=0.5698 ct=10.8364 rec=1.3292 | train/val/test=1.000/0.728/0.723 | c=0.998437
[Epoch 0047] loss=12.9839 cls=0.1758 smmd=0.5533 ct=10.8466 rec=1.3322 | train/val/test=1.000/0.712/0.714 | c=0.998437
[Epoch 0048] loss=13.3700 cls=0.1835 smmd=0.6965 ct=10.8670 rec=1.3400 | train/val/test=1.000/0.714/0.718 | c=0.998437
[Epoch 0049] loss=13.5928 cls=0.1902 smmd=0.7809 ct=10.8768 rec=1.3374 | train/val/test=1.000/0.678/0.683 | c=0.998437
[Epoch 0050] loss=13.1683 cls=0.1776 smmd=0.6165 ct=10.8700 rec=1.3365 | train/val/test=1.000/0.718/0.707 | c=0.998437
[Epoch 0051] loss=13.0201 cls=0.1530 smmd=0.5711 ct=10.8543 rec=1.3232 | train/val/test=1.000/0.704/0.702 | c=0.998437
[Epoch 0052] loss=12.8259 cls=0.1304 smmd=0.5103 ct=10.8275 rec=1.3148 | train/val/test=1.000/0.724/0.715 | c=0.998437
[Epoch 0053] loss=12.8616 cls=0.1207 smmd=0.5303 ct=10.8196 rec=1.3119 | train/val/test=1.000/0.714/0.717 | c=0.998437
[Epoch 0054] loss=12.6890 cls=0.1237 smmd=0.4555 ct=10.8309 rec=1.3151 | train/val/test=1.000/0.726/0.724 | c=0.998437
[Epoch 0055] loss=12.8462 cls=0.1357 smmd=0.5122 ct=10.8369 rec=1.3217 | train/val/test=1.000/0.712/0.724 | c=0.998437
[Epoch 0056] loss=13.1335 cls=0.1517 smmd=0.6126 ct=10.8602 rec=1.3320 | train/val/test=1.000/0.724/0.724 | c=0.998437
[Epoch 0057] loss=13.2845 cls=0.1594 smmd=0.6701 ct=10.8633 rec=1.3325 | train/val/test=1.000/0.714/0.710 | c=0.998437
[Epoch 0058] loss=13.2303 cls=0.1486 smmd=0.6506 ct=10.8635 rec=1.3317 | train/val/test=1.000/0.718/0.711 | c=0.998437
[Epoch 0059] loss=13.1438 cls=0.1393 smmd=0.6250 ct=10.8507 rec=1.3217 | train/val/test=1.000/0.706/0.701 | c=0.998437
[Epoch 0060] loss=12.7430 cls=0.1171 smmd=0.4771 ct=10.8347 rec=1.3142 | train/val/test=1.000/0.724/0.713 | c=0.998437
[Epoch 0061] loss=12.7101 cls=0.1125 smmd=0.4680 ct=10.8289 rec=1.3100 | train/val/test=1.000/0.702/0.703 | c=0.998437
[Epoch 0062] loss=12.7330 cls=0.1093 smmd=0.4749 ct=10.8360 rec=1.3102 | train/val/test=1.000/0.724/0.714 | c=0.998437
[Epoch 0063] loss=12.7117 cls=0.1135 smmd=0.4659 ct=10.8335 rec=1.3136 | train/val/test=1.000/0.714/0.713 | c=0.998437
[Epoch 0064] loss=12.8506 cls=0.1243 smmd=0.5095 ct=10.8542 rec=1.3212 | train/val/test=1.000/0.726/0.725 | c=0.998437
[Epoch 0065] loss=13.1870 cls=0.1369 smmd=0.6338 ct=10.8710 rec=1.3260 | train/val/test=1.000/0.698/0.692 | c=0.998437
[Epoch 0066] loss=13.3404 cls=0.1461 smmd=0.6874 ct=10.8815 rec=1.3346 | train/val/test=1.000/0.722/0.717 | c=0.998437
[Epoch 0067] loss=13.1476 cls=0.1367 smmd=0.6143 ct=10.8820 rec=1.3232 | train/val/test=1.000/0.684/0.683 | c=0.998437
[Epoch 0068] loss=12.8272 cls=0.1152 smmd=0.5038 ct=10.8525 rec=1.3150 | train/val/test=1.000/0.720/0.718 | c=0.998437
[Epoch 0069] loss=12.7373 cls=0.0857 smmd=0.4854 ct=10.8305 rec=1.3008 | train/val/test=1.000/0.718/0.707 | c=0.998437
[Epoch 0070] loss=12.5490 cls=0.0793 smmd=0.4161 ct=10.8205 rec=1.2974 | train/val/test=1.000/0.724/0.715 | c=0.998437
[Epoch 0071] loss=12.5421 cls=0.0831 smmd=0.4115 ct=10.8216 rec=1.3006 | train/val/test=1.000/0.718/0.721 | c=0.998437
[Epoch 0072] loss=12.6649 cls=0.0950 smmd=0.4482 ct=10.8426 rec=1.3089 | train/val/test=1.000/0.724/0.725 | c=0.998437
[Epoch 0073] loss=12.8309 cls=0.1118 smmd=0.5039 ct=10.8566 rec=1.3173 | train/val/test=1.000/0.718/0.726 | c=0.998437
[Epoch 0074] loss=13.3462 cls=0.1274 smmd=0.7021 ct=10.8652 rec=1.3241 | train/val/test=1.000/0.714/0.718 | c=0.998437
[Epoch 0075] loss=13.3572 cls=0.1199 smmd=0.7069 ct=10.8689 rec=1.3222 | train/val/test=1.000/0.714/0.714 | c=0.998437
[Epoch 0076] loss=12.9254 cls=0.1198 smmd=0.5410 ct=10.8557 rec=1.3144 | train/val/test=1.000/0.694/0.687 | c=0.998437
[Epoch 0077] loss=12.6568 cls=0.0979 smmd=0.4425 ct=10.8474 rec=1.3086 | train/val/test=1.000/0.718/0.716 | c=0.998437
[Epoch 0078] loss=12.5946 cls=0.0948 smmd=0.4260 ct=10.8306 rec=1.3029 | train/val/test=1.000/0.710/0.703 | c=0.998437
[Epoch 0079] loss=12.5398 cls=0.0787 smmd=0.4098 ct=10.8273 rec=1.2976 | train/val/test=1.000/0.726/0.725 | c=0.998437
[Epoch 0080] loss=12.4584 cls=0.0781 smmd=0.3754 ct=10.8306 rec=1.3006 | train/val/test=1.000/0.730/0.717 | c=0.998437
[Epoch 0081] loss=12.6330 cls=0.0923 smmd=0.4369 ct=10.8404 rec=1.3082 | train/val/test=1.000/0.718/0.725 | c=0.998437
[Epoch 0082] loss=12.9575 cls=0.1050 smmd=0.5499 ct=10.8700 rec=1.3204 | train/val/test=1.000/0.718/0.707 | c=0.998437
[Epoch 0083] loss=13.4540 cls=0.1195 smmd=0.7369 ct=10.8916 rec=1.3208 | train/val/test=1.000/0.694/0.720 | c=0.998437
[Epoch 0084] loss=13.4713 cls=0.1227 smmd=0.7461 ct=10.8806 rec=1.3278 | train/val/test=1.000/0.666/0.644 | c=0.998437
[Epoch 0085] loss=12.6809 cls=0.1148 smmd=0.4361 ct=10.8763 rec=1.3140 | train/val/test=1.000/0.706/0.720 | c=0.998437
[Epoch 0086] loss=12.8818 cls=0.0940 smmd=0.5348 ct=10.8473 rec=1.3008 | train/val/test=1.000/0.712/0.696 | c=0.998437
[Epoch 0087] loss=12.5079 cls=0.0522 smmd=0.4109 ct=10.8119 rec=1.2853 | train/val/test=1.000/0.716/0.700 | c=0.998437
[Epoch 0088] loss=12.4356 cls=0.0554 smmd=0.3761 ct=10.8235 rec=1.2884 | train/val/test=1.000/0.722/0.726 | c=0.998437
[Epoch 0089] loss=12.6743 cls=0.0748 smmd=0.4561 ct=10.8461 rec=1.3009 | train/val/test=1.000/0.702/0.681 | c=0.998437
[Epoch 0090] loss=12.7635 cls=0.0966 smmd=0.4748 ct=10.8706 rec=1.3152 | train/val/test=1.000/0.708/0.723 | c=0.998437
[Epoch 0091] loss=13.4033 cls=0.1512 smmd=0.6927 ct=10.9266 rec=1.3389 | train/val/test=1.000/0.480/0.448 | c=0.998437
[Epoch 0092] loss=14.0151 cls=0.2545 smmd=0.8859 ct=10.9835 rec=1.3790 | train/val/test=0.846/0.660/0.688 | c=0.998437
[Epoch 0093] loss=13.6683 cls=0.2452 smmd=0.7576 ct=10.9699 rec=1.3638 | train/val/test=1.000/0.680/0.668 | c=0.998437
[Epoch 0094] loss=12.6322 cls=0.0660 smmd=0.4443 ct=10.8394 rec=1.2981 | train/val/test=1.000/0.662/0.638 | c=0.998437
[Epoch 0095] loss=12.7981 cls=0.0542 smmd=0.5152 ct=10.8363 rec=1.2933 | train/val/test=1.000/0.714/0.725 | c=0.998437
[Epoch 0096] loss=12.5628 cls=0.0417 smmd=0.4244 ct=10.8374 rec=1.2873 | train/val/test=1.000/0.730/0.731 | c=0.998437
[Epoch 0097] loss=12.7119 cls=0.0323 smmd=0.4890 ct=10.8321 rec=1.2822 | train/val/test=1.000/0.652/0.641 | c=0.998437
[Epoch 0098] loss=12.5937 cls=0.0647 smmd=0.4160 ct=10.8677 rec=1.3074 | train/val/test=1.000/0.714/0.731 | c=0.998437
[Epoch 0099] loss=12.6618 cls=0.0654 smmd=0.4449 ct=10.8647 rec=1.3041 | train/val/test=1.000/0.738/0.725 | c=0.998437
=== Best @ epoch 28: val=0.7380, test=0.7350 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-4 completed in 139.07 seconds.
==================================================
