Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-10-3 - 2025-09-21 05:32:39:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-10-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-10-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.5087 cls=1.0880 smmd=5.6745 ct=7.2564 rec=1.4137 | train/val/test=0.401/0.385/0.396 | c=0.998347
[Epoch 0001] loss=53.3584 cls=1.0588 smmd=3.7707 ct=7.2068 rec=1.4163 | train/val/test=0.515/0.516/0.521 | c=0.998347
[Epoch 0002] loss=37.8527 cls=1.0609 smmd=2.2369 ct=7.1229 rec=1.4140 | train/val/test=0.605/0.608/0.609 | c=0.998347
[Epoch 0003] loss=40.8176 cls=1.0526 smmd=2.5366 ct=7.1093 rec=1.4132 | train/val/test=0.549/0.556/0.565 | c=0.998347
[Epoch 0004] loss=40.2972 cls=1.0020 smmd=2.4961 ct=7.0642 rec=1.4139 | train/val/test=0.537/0.548/0.556 | c=0.998347
[Epoch 0005] loss=35.5446 cls=0.9601 smmd=2.0340 ct=7.0082 rec=1.4152 | train/val/test=0.533/0.539/0.548 | c=0.998347
[Epoch 0006] loss=30.7394 cls=0.9260 smmd=1.5658 ct=6.9558 rec=1.4133 | train/val/test=0.534/0.543/0.550 | c=0.998347
[Epoch 0007] loss=35.0596 cls=0.8845 smmd=1.8688 ct=7.6130 rec=1.4062 | train/val/test=0.577/0.582/0.597 | c=0.998347
[Epoch 0008] loss=35.8642 cls=0.8459 smmd=1.9805 ct=7.4691 rec=1.3966 | train/val/test=0.660/0.674/0.670 | c=0.998347
[Epoch 0009] loss=29.8073 cls=0.8128 smmd=1.3847 ct=7.4303 rec=1.3871 | train/val/test=0.678/0.688/0.685 | c=0.998347
[Epoch 0010] loss=28.1829 cls=0.7822 smmd=1.2018 ct=7.5417 rec=1.3806 | train/val/test=0.689/0.697/0.695 | c=0.998347
[Epoch 0011] loss=30.3529 cls=0.7662 smmd=1.4078 ct=7.6019 rec=1.3765 | train/val/test=0.694/0.701/0.697 | c=0.998347
[Epoch 0012] loss=28.0235 cls=0.7522 smmd=1.1861 ct=7.5504 rec=1.3709 | train/val/test=0.698/0.704/0.702 | c=0.998347
[Epoch 0013] loss=26.5160 cls=0.7250 smmd=1.0448 ct=7.5123 rec=1.3615 | train/val/test=0.664/0.676/0.681 | c=0.998347
[Epoch 0014] loss=25.7892 cls=0.7228 smmd=0.9688 ct=7.5300 rec=1.3603 | train/val/test=0.700/0.705/0.704 | c=0.998347
[Epoch 0015] loss=25.9370 cls=0.6892 smmd=0.9878 ct=7.5183 rec=1.3555 | train/val/test=0.705/0.713/0.710 | c=0.998347
[Epoch 0016] loss=25.0030 cls=0.6890 smmd=0.8847 ct=7.5678 rec=1.3521 | train/val/test=0.707/0.717/0.710 | c=0.998347
[Epoch 0017] loss=23.3928 cls=0.6716 smmd=0.7250 ct=7.5683 rec=1.3413 | train/val/test=0.705/0.715/0.718 | c=0.998347
[Epoch 0018] loss=23.6548 cls=0.6663 smmd=0.7613 ct=7.5197 rec=1.3389 | train/val/test=0.716/0.730/0.728 | c=0.998347
[Epoch 0019] loss=22.8541 cls=0.6587 smmd=0.6843 ct=7.5063 rec=1.3377 | train/val/test=0.735/0.741/0.743 | c=0.998347
[Epoch 0020] loss=22.4889 cls=0.6266 smmd=0.6445 ct=7.5315 rec=1.3344 | train/val/test=0.740/0.752/0.752 | c=0.998347
[Epoch 0021] loss=21.7996 cls=0.6144 smmd=0.5763 ct=7.5314 rec=1.3339 | train/val/test=0.759/0.768/0.766 | c=0.998347
[Epoch 0022] loss=21.8904 cls=0.5972 smmd=0.5868 ct=7.5294 rec=1.3294 | train/val/test=0.771/0.783/0.781 | c=0.998347
[Epoch 0023] loss=21.1368 cls=0.5785 smmd=0.5105 ct=7.5388 rec=1.3290 | train/val/test=0.785/0.799/0.793 | c=0.998347
[Epoch 0024] loss=20.6164 cls=0.5595 smmd=0.4640 ct=7.5158 rec=1.3297 | train/val/test=0.791/0.801/0.797 | c=0.998347
[Epoch 0025] loss=20.6890 cls=0.5466 smmd=0.4780 ct=7.4863 rec=1.3268 | train/val/test=0.790/0.801/0.795 | c=0.998347
[Epoch 0026] loss=20.1302 cls=0.5388 smmd=0.4160 ct=7.5194 rec=1.3244 | train/val/test=0.802/0.810/0.806 | c=0.998347
[Epoch 0027] loss=19.9620 cls=0.5201 smmd=0.3957 ct=7.5413 rec=1.3252 | train/val/test=0.813/0.822/0.814 | c=0.998347
[Epoch 0028] loss=19.7466 cls=0.5078 smmd=0.3805 ct=7.5130 rec=1.3240 | train/val/test=0.821/0.828/0.822 | c=0.998347
[Epoch 0029] loss=19.5463 cls=0.4997 smmd=0.3636 ct=7.4997 rec=1.3215 | train/val/test=0.820/0.827/0.822 | c=0.998347
[Epoch 0030] loss=19.1939 cls=0.4917 smmd=0.3305 ct=7.4917 rec=1.3197 | train/val/test=0.821/0.829/0.822 | c=0.998347
[Epoch 0031] loss=19.0151 cls=0.4873 smmd=0.3098 ct=7.5076 rec=1.3166 | train/val/test=0.828/0.834/0.826 | c=0.998347
[Epoch 0032] loss=18.8435 cls=0.4796 smmd=0.2904 ct=7.5206 rec=1.3169 | train/val/test=0.830/0.836/0.830 | c=0.998347
[Epoch 0033] loss=18.6933 cls=0.4761 smmd=0.2795 ct=7.5007 rec=1.3173 | train/val/test=0.829/0.833/0.827 | c=0.998347
[Epoch 0034] loss=18.5408 cls=0.4723 smmd=0.2685 ct=7.4817 rec=1.3127 | train/val/test=0.828/0.835/0.828 | c=0.998347
[Epoch 0035] loss=18.3679 cls=0.4692 smmd=0.2501 ct=7.4881 rec=1.3119 | train/val/test=0.832/0.838/0.828 | c=0.998347
[Epoch 0036] loss=18.1700 cls=0.4682 smmd=0.2269 ct=7.5054 rec=1.3121 | train/val/test=0.833/0.839/0.830 | c=0.998347
[Epoch 0037] loss=18.1296 cls=0.4662 smmd=0.2244 ct=7.4982 rec=1.3128 | train/val/test=0.830/0.840/0.828 | c=0.998347
[Epoch 0038] loss=18.0157 cls=0.4649 smmd=0.2164 ct=7.4817 rec=1.3113 | train/val/test=0.829/0.833/0.828 | c=0.998347
[Epoch 0039] loss=17.9868 cls=0.4666 smmd=0.2129 ct=7.4847 rec=1.3103 | train/val/test=0.836/0.840/0.831 | c=0.998347
[Epoch 0040] loss=17.7830 cls=0.4644 smmd=0.1901 ct=7.4964 rec=1.3131 | train/val/test=0.834/0.837/0.828 | c=0.998347
[Epoch 0041] loss=17.7280 cls=0.4646 smmd=0.1864 ct=7.4877 rec=1.3119 | train/val/test=0.828/0.836/0.830 | c=0.998347
[Epoch 0042] loss=17.6484 cls=0.4649 smmd=0.1799 ct=7.4802 rec=1.3130 | train/val/test=0.836/0.838/0.829 | c=0.998347
[Epoch 0043] loss=17.5795 cls=0.4653 smmd=0.1730 ct=7.4802 rec=1.3124 | train/val/test=0.832/0.838/0.830 | c=0.998347
[Epoch 0044] loss=17.4676 cls=0.4644 smmd=0.1608 ct=7.4853 rec=1.3135 | train/val/test=0.838/0.844/0.830 | c=0.998347
[Epoch 0045] loss=17.4657 cls=0.4634 smmd=0.1625 ct=7.4758 rec=1.3148 | train/val/test=0.831/0.837/0.829 | c=0.998347
[Epoch 0046] loss=17.3941 cls=0.4657 smmd=0.1563 ct=7.4704 rec=1.3153 | train/val/test=0.840/0.847/0.830 | c=0.998347
[Epoch 0047] loss=17.3199 cls=0.4643 smmd=0.1476 ct=7.4767 rec=1.3163 | train/val/test=0.835/0.840/0.830 | c=0.998347
[Epoch 0048] loss=17.2017 cls=0.4665 smmd=0.1385 ct=7.4628 rec=1.3168 | train/val/test=0.839/0.847/0.833 | c=0.998347
[Epoch 0049] loss=17.1879 cls=0.4653 smmd=0.1361 ct=7.4676 rec=1.3186 | train/val/test=0.838/0.847/0.835 | c=0.998347
[Epoch 0050] loss=17.1410 cls=0.4663 smmd=0.1312 ct=7.4679 rec=1.3199 | train/val/test=0.839/0.847/0.834 | c=0.998347
[Epoch 0051] loss=17.1139 cls=0.4693 smmd=0.1314 ct=7.4527 rec=1.3202 | train/val/test=0.837/0.845/0.838 | c=0.998347
[Epoch 0052] loss=17.1079 cls=0.4691 smmd=0.1294 ct=7.4588 rec=1.3230 | train/val/test=0.840/0.846/0.835 | c=0.998347
[Epoch 0053] loss=17.0551 cls=0.4729 smmd=0.1254 ct=7.4517 rec=1.3223 | train/val/test=0.838/0.845/0.838 | c=0.998347
[Epoch 0054] loss=17.0279 cls=0.4718 smmd=0.1221 ct=7.4542 rec=1.3252 | train/val/test=0.840/0.845/0.836 | c=0.998347
[Epoch 0055] loss=17.0412 cls=0.4740 smmd=0.1245 ct=7.4485 rec=1.3244 | train/val/test=0.835/0.842/0.833 | c=0.998347
[Epoch 0056] loss=17.0335 cls=0.4739 smmd=0.1254 ct=7.4395 rec=1.3261 | train/val/test=0.842/0.845/0.840 | c=0.998347
[Epoch 0057] loss=16.9832 cls=0.4748 smmd=0.1199 ct=7.4423 rec=1.3247 | train/val/test=0.834/0.840/0.831 | c=0.998347
[Epoch 0058] loss=16.9257 cls=0.4747 smmd=0.1147 ct=7.4393 rec=1.3247 | train/val/test=0.841/0.844/0.842 | c=0.998347
[Epoch 0059] loss=16.9358 cls=0.4740 smmd=0.1172 ct=7.4321 rec=1.3246 | train/val/test=0.829/0.834/0.830 | c=0.998347
[Epoch 0060] loss=16.9824 cls=0.4782 smmd=0.1213 ct=7.4339 rec=1.3243 | train/val/test=0.839/0.843/0.843 | c=0.998347
[Epoch 0061] loss=16.9456 cls=0.4753 smmd=0.1182 ct=7.4321 rec=1.3245 | train/val/test=0.825/0.832/0.826 | c=0.998347
[Epoch 0062] loss=16.9741 cls=0.4815 smmd=0.1216 ct=7.4280 rec=1.3224 | train/val/test=0.837/0.844/0.841 | c=0.998347
[Epoch 0063] loss=16.9482 cls=0.4757 smmd=0.1188 ct=7.4300 rec=1.3252 | train/val/test=0.819/0.827/0.822 | c=0.998347
[Epoch 0064] loss=16.9768 cls=0.4866 smmd=0.1216 ct=7.4281 rec=1.3226 | train/val/test=0.836/0.840/0.838 | c=0.998347
[Epoch 0065] loss=16.9411 cls=0.4781 smmd=0.1204 ct=7.4177 rec=1.3247 | train/val/test=0.822/0.829/0.826 | c=0.998347
[Epoch 0066] loss=16.9546 cls=0.4818 smmd=0.1203 ct=7.4247 rec=1.3228 | train/val/test=0.839/0.844/0.840 | c=0.998347
[Epoch 0067] loss=16.9304 cls=0.4733 smmd=0.1203 ct=7.4149 rec=1.3224 | train/val/test=0.828/0.832/0.831 | c=0.998347
[Epoch 0068] loss=16.8797 cls=0.4778 smmd=0.1138 ct=7.4205 rec=1.3232 | train/val/test=0.840/0.843/0.839 | c=0.998347
[Epoch 0069] loss=16.8350 cls=0.4732 smmd=0.1111 ct=7.4128 rec=1.3227 | train/val/test=0.830/0.838/0.833 | c=0.998347
[Epoch 0070] loss=16.8650 cls=0.4770 smmd=0.1137 ct=7.4133 rec=1.3248 | train/val/test=0.840/0.846/0.838 | c=0.998347
[Epoch 0071] loss=16.9028 cls=0.4750 smmd=0.1171 ct=7.4163 rec=1.3243 | train/val/test=0.833/0.843/0.834 | c=0.998347
[Epoch 0072] loss=16.9336 cls=0.4780 smmd=0.1203 ct=7.4146 rec=1.3253 | train/val/test=0.839/0.847/0.837 | c=0.998347
[Epoch 0073] loss=16.9186 cls=0.4755 smmd=0.1192 ct=7.4132 rec=1.3254 | train/val/test=0.834/0.843/0.834 | c=0.998347
[Epoch 0074] loss=16.9027 cls=0.4773 smmd=0.1173 ct=7.4142 rec=1.3248 | train/val/test=0.840/0.846/0.836 | c=0.998347
[Epoch 0075] loss=16.9192 cls=0.4756 smmd=0.1197 ct=7.4111 rec=1.3245 | train/val/test=0.834/0.841/0.834 | c=0.998347
[Epoch 0076] loss=16.9001 cls=0.4759 smmd=0.1177 ct=7.4117 rec=1.3235 | train/val/test=0.839/0.847/0.835 | c=0.998347
[Epoch 0077] loss=16.8275 cls=0.4737 smmd=0.1110 ct=7.4097 rec=1.3231 | train/val/test=0.835/0.843/0.834 | c=0.998347
[Epoch 0078] loss=16.7965 cls=0.4732 smmd=0.1082 ct=7.4082 rec=1.3220 | train/val/test=0.840/0.847/0.836 | c=0.998347
[Epoch 0079] loss=16.8113 cls=0.4728 smmd=0.1100 ct=7.4067 rec=1.3224 | train/val/test=0.833/0.841/0.834 | c=0.998347
[Epoch 0080] loss=16.7899 cls=0.4739 smmd=0.1069 ct=7.4114 rec=1.3222 | train/val/test=0.839/0.846/0.838 | c=0.998347
[Epoch 0081] loss=16.8007 cls=0.4737 smmd=0.1099 ct=7.4016 rec=1.3236 | train/val/test=0.827/0.834/0.829 | c=0.998347
[Epoch 0082] loss=16.8788 cls=0.4805 smmd=0.1139 ct=7.4185 rec=1.3244 | train/val/test=0.839/0.842/0.840 | c=0.998347
[Epoch 0083] loss=16.9166 cls=0.4816 smmd=0.1212 ct=7.3998 rec=1.3279 | train/val/test=0.814/0.824/0.819 | c=0.998347
[Epoch 0084] loss=16.9648 cls=0.4968 smmd=0.1202 ct=7.4249 rec=1.3291 | train/val/test=0.827/0.831/0.828 | c=0.998347
[Epoch 0085] loss=17.0950 cls=0.5035 smmd=0.1357 ct=7.4097 rec=1.3346 | train/val/test=0.794/0.805/0.795 | c=0.998347
[Epoch 0086] loss=17.3047 cls=0.5309 smmd=0.1499 ct=7.4357 rec=1.3376 | train/val/test=0.803/0.809/0.805 | c=0.998347
[Epoch 0087] loss=17.3868 cls=0.5276 smmd=0.1612 ct=7.4202 rec=1.3405 | train/val/test=0.797/0.809/0.803 | c=0.998347
[Epoch 0088] loss=17.2270 cls=0.5193 smmd=0.1460 ct=7.4211 rec=1.3296 | train/val/test=0.833/0.835/0.838 | c=0.998347
[Epoch 0089] loss=16.9935 cls=0.4797 smmd=0.1282 ct=7.4053 rec=1.3221 | train/val/test=0.828/0.835/0.830 | c=0.998347
[Epoch 0090] loss=16.8450 cls=0.4672 smmd=0.1169 ct=7.3924 rec=1.3150 | train/val/test=0.832/0.839/0.832 | c=0.998347
[Epoch 0091] loss=16.7995 cls=0.4704 smmd=0.1107 ct=7.3998 rec=1.3160 | train/val/test=0.836/0.843/0.841 | c=0.998347
[Epoch 0092] loss=16.7960 cls=0.4738 smmd=0.1100 ct=7.3985 rec=1.3235 | train/val/test=0.823/0.829/0.822 | c=0.998347
[Epoch 0093] loss=16.8710 cls=0.4955 smmd=0.1137 ct=7.4112 rec=1.3272 | train/val/test=0.837/0.847/0.842 | c=0.998347
[Epoch 0094] loss=16.9867 cls=0.4914 smmd=0.1265 ct=7.4044 rec=1.3344 | train/val/test=0.825/0.831/0.824 | c=0.998347
[Epoch 0095] loss=17.0221 cls=0.5069 smmd=0.1263 ct=7.4192 rec=1.3340 | train/val/test=0.837/0.847/0.842 | c=0.998347
[Epoch 0096] loss=17.0856 cls=0.4955 smmd=0.1362 ct=7.4035 rec=1.3378 | train/val/test=0.823/0.829/0.824 | c=0.998347
[Epoch 0097] loss=17.2562 cls=0.5089 smmd=0.1486 ct=7.4249 rec=1.3318 | train/val/test=0.836/0.848/0.841 | c=0.998347
[Epoch 0098] loss=17.3629 cls=0.4913 smmd=0.1647 ct=7.4010 rec=1.3359 | train/val/test=0.821/0.826/0.819 | c=0.998347
[Epoch 0099] loss=17.2046 cls=0.5038 smmd=0.1446 ct=7.4225 rec=1.3238 | train/val/test=0.835/0.845/0.838 | c=0.998347
=== Best @ epoch 97: val=0.8476, test=0.8408 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-10-3 - 2025-09-21 05:32:39:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-10-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-10-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.5087 cls=1.0880 smmd=5.6745 ct=7.2564 rec=1.4137 | train/val/test=0.401/0.385/0.396 | c=0.998347
[Epoch 0001] loss=53.3584 cls=1.0588 smmd=3.7707 ct=7.2068 rec=1.4163 | train/val/test=0.515/0.516/0.521 | c=0.998347
[Epoch 0002] loss=37.8527 cls=1.0609 smmd=2.2369 ct=7.1229 rec=1.4140 | train/val/test=0.605/0.608/0.609 | c=0.998347
[Epoch 0003] loss=40.8176 cls=1.0526 smmd=2.5366 ct=7.1093 rec=1.4132 | train/val/test=0.549/0.556/0.565 | c=0.998347
[Epoch 0004] loss=40.2972 cls=1.0020 smmd=2.4961 ct=7.0642 rec=1.4139 | train/val/test=0.537/0.548/0.556 | c=0.998347
[Epoch 0005] loss=35.5446 cls=0.9601 smmd=2.0340 ct=7.0082 rec=1.4152 | train/val/test=0.533/0.539/0.548 | c=0.998347
[Epoch 0006] loss=30.7394 cls=0.9260 smmd=1.5658 ct=6.9558 rec=1.4133 | train/val/test=0.534/0.543/0.550 | c=0.998347
[Epoch 0007] loss=35.0596 cls=0.8845 smmd=1.8688 ct=7.6130 rec=1.4062 | train/val/test=0.577/0.582/0.597 | c=0.998347
[Epoch 0008] loss=35.8642 cls=0.8459 smmd=1.9805 ct=7.4691 rec=1.3966 | train/val/test=0.660/0.674/0.670 | c=0.998347
[Epoch 0009] loss=29.8073 cls=0.8128 smmd=1.3847 ct=7.4303 rec=1.3871 | train/val/test=0.678/0.688/0.685 | c=0.998347
[Epoch 0010] loss=28.1829 cls=0.7822 smmd=1.2018 ct=7.5417 rec=1.3806 | train/val/test=0.689/0.697/0.695 | c=0.998347
[Epoch 0011] loss=30.3529 cls=0.7662 smmd=1.4078 ct=7.6019 rec=1.3765 | train/val/test=0.694/0.701/0.697 | c=0.998347
[Epoch 0012] loss=28.0235 cls=0.7522 smmd=1.1861 ct=7.5504 rec=1.3709 | train/val/test=0.698/0.704/0.702 | c=0.998347
[Epoch 0013] loss=26.5160 cls=0.7250 smmd=1.0448 ct=7.5123 rec=1.3615 | train/val/test=0.664/0.676/0.681 | c=0.998347
[Epoch 0014] loss=25.7892 cls=0.7228 smmd=0.9688 ct=7.5300 rec=1.3603 | train/val/test=0.700/0.705/0.704 | c=0.998347
[Epoch 0015] loss=25.9370 cls=0.6892 smmd=0.9878 ct=7.5183 rec=1.3555 | train/val/test=0.705/0.713/0.710 | c=0.998347
[Epoch 0016] loss=25.0030 cls=0.6890 smmd=0.8847 ct=7.5678 rec=1.3521 | train/val/test=0.707/0.717/0.710 | c=0.998347
[Epoch 0017] loss=23.3928 cls=0.6716 smmd=0.7250 ct=7.5683 rec=1.3413 | train/val/test=0.705/0.715/0.718 | c=0.998347
[Epoch 0018] loss=23.6548 cls=0.6663 smmd=0.7613 ct=7.5197 rec=1.3389 | train/val/test=0.716/0.730/0.728 | c=0.998347
[Epoch 0019] loss=22.8541 cls=0.6587 smmd=0.6843 ct=7.5063 rec=1.3377 | train/val/test=0.735/0.741/0.743 | c=0.998347
[Epoch 0020] loss=22.4889 cls=0.6266 smmd=0.6445 ct=7.5315 rec=1.3344 | train/val/test=0.740/0.752/0.752 | c=0.998347
[Epoch 0021] loss=21.7996 cls=0.6144 smmd=0.5763 ct=7.5314 rec=1.3339 | train/val/test=0.759/0.768/0.766 | c=0.998347
[Epoch 0022] loss=21.8904 cls=0.5972 smmd=0.5868 ct=7.5294 rec=1.3294 | train/val/test=0.771/0.783/0.781 | c=0.998347
[Epoch 0023] loss=21.1368 cls=0.5785 smmd=0.5105 ct=7.5388 rec=1.3290 | train/val/test=0.785/0.799/0.793 | c=0.998347
[Epoch 0024] loss=20.6164 cls=0.5595 smmd=0.4640 ct=7.5158 rec=1.3297 | train/val/test=0.791/0.801/0.797 | c=0.998347
[Epoch 0025] loss=20.6890 cls=0.5466 smmd=0.4780 ct=7.4863 rec=1.3268 | train/val/test=0.790/0.801/0.795 | c=0.998347
[Epoch 0026] loss=20.1302 cls=0.5388 smmd=0.4160 ct=7.5194 rec=1.3244 | train/val/test=0.802/0.810/0.806 | c=0.998347
[Epoch 0027] loss=19.9620 cls=0.5201 smmd=0.3957 ct=7.5413 rec=1.3252 | train/val/test=0.813/0.822/0.814 | c=0.998347
[Epoch 0028] loss=19.7466 cls=0.5078 smmd=0.3805 ct=7.5130 rec=1.3240 | train/val/test=0.821/0.828/0.822 | c=0.998347
[Epoch 0029] loss=19.5463 cls=0.4997 smmd=0.3636 ct=7.4997 rec=1.3215 | train/val/test=0.820/0.827/0.822 | c=0.998347
[Epoch 0030] loss=19.1939 cls=0.4917 smmd=0.3305 ct=7.4917 rec=1.3197 | train/val/test=0.821/0.829/0.822 | c=0.998347
[Epoch 0031] loss=19.0151 cls=0.4873 smmd=0.3098 ct=7.5076 rec=1.3166 | train/val/test=0.828/0.834/0.826 | c=0.998347
[Epoch 0032] loss=18.8435 cls=0.4796 smmd=0.2904 ct=7.5206 rec=1.3169 | train/val/test=0.830/0.836/0.830 | c=0.998347
[Epoch 0033] loss=18.6933 cls=0.4761 smmd=0.2795 ct=7.5007 rec=1.3173 | train/val/test=0.829/0.833/0.827 | c=0.998347
[Epoch 0034] loss=18.5408 cls=0.4723 smmd=0.2685 ct=7.4817 rec=1.3127 | train/val/test=0.828/0.835/0.828 | c=0.998347
[Epoch 0035] loss=18.3679 cls=0.4692 smmd=0.2501 ct=7.4881 rec=1.3119 | train/val/test=0.832/0.838/0.828 | c=0.998347
[Epoch 0036] loss=18.1700 cls=0.4682 smmd=0.2269 ct=7.5054 rec=1.3121 | train/val/test=0.833/0.839/0.830 | c=0.998347
[Epoch 0037] loss=18.1296 cls=0.4662 smmd=0.2244 ct=7.4982 rec=1.3128 | train/val/test=0.830/0.840/0.828 | c=0.998347
[Epoch 0038] loss=18.0157 cls=0.4649 smmd=0.2164 ct=7.4817 rec=1.3113 | train/val/test=0.829/0.833/0.828 | c=0.998347
[Epoch 0039] loss=17.9868 cls=0.4666 smmd=0.2129 ct=7.4847 rec=1.3103 | train/val/test=0.836/0.840/0.831 | c=0.998347
[Epoch 0040] loss=17.7830 cls=0.4644 smmd=0.1901 ct=7.4964 rec=1.3131 | train/val/test=0.834/0.837/0.828 | c=0.998347
[Epoch 0041] loss=17.7280 cls=0.4646 smmd=0.1864 ct=7.4877 rec=1.3119 | train/val/test=0.828/0.836/0.830 | c=0.998347
[Epoch 0042] loss=17.6484 cls=0.4649 smmd=0.1799 ct=7.4802 rec=1.3130 | train/val/test=0.836/0.838/0.829 | c=0.998347
[Epoch 0043] loss=17.5795 cls=0.4653 smmd=0.1730 ct=7.4802 rec=1.3124 | train/val/test=0.832/0.838/0.830 | c=0.998347
[Epoch 0044] loss=17.4676 cls=0.4644 smmd=0.1608 ct=7.4853 rec=1.3135 | train/val/test=0.838/0.844/0.830 | c=0.998347
[Epoch 0045] loss=17.4657 cls=0.4634 smmd=0.1625 ct=7.4758 rec=1.3148 | train/val/test=0.831/0.837/0.829 | c=0.998347
[Epoch 0046] loss=17.3941 cls=0.4657 smmd=0.1563 ct=7.4704 rec=1.3153 | train/val/test=0.840/0.847/0.830 | c=0.998347
[Epoch 0047] loss=17.3199 cls=0.4643 smmd=0.1476 ct=7.4767 rec=1.3163 | train/val/test=0.835/0.840/0.830 | c=0.998347
[Epoch 0048] loss=17.2017 cls=0.4665 smmd=0.1385 ct=7.4628 rec=1.3168 | train/val/test=0.839/0.847/0.833 | c=0.998347
[Epoch 0049] loss=17.1879 cls=0.4653 smmd=0.1361 ct=7.4676 rec=1.3186 | train/val/test=0.838/0.847/0.835 | c=0.998347
[Epoch 0050] loss=17.1410 cls=0.4663 smmd=0.1312 ct=7.4679 rec=1.3199 | train/val/test=0.839/0.847/0.834 | c=0.998347
[Epoch 0051] loss=17.1139 cls=0.4693 smmd=0.1314 ct=7.4527 rec=1.3202 | train/val/test=0.837/0.845/0.838 | c=0.998347
[Epoch 0052] loss=17.1079 cls=0.4691 smmd=0.1294 ct=7.4588 rec=1.3230 | train/val/test=0.840/0.846/0.835 | c=0.998347
[Epoch 0053] loss=17.0551 cls=0.4729 smmd=0.1254 ct=7.4517 rec=1.3223 | train/val/test=0.838/0.845/0.838 | c=0.998347
[Epoch 0054] loss=17.0279 cls=0.4718 smmd=0.1221 ct=7.4542 rec=1.3252 | train/val/test=0.840/0.845/0.836 | c=0.998347
[Epoch 0055] loss=17.0412 cls=0.4740 smmd=0.1245 ct=7.4485 rec=1.3244 | train/val/test=0.835/0.842/0.833 | c=0.998347
[Epoch 0056] loss=17.0335 cls=0.4739 smmd=0.1254 ct=7.4395 rec=1.3261 | train/val/test=0.842/0.845/0.840 | c=0.998347
[Epoch 0057] loss=16.9832 cls=0.4748 smmd=0.1199 ct=7.4423 rec=1.3247 | train/val/test=0.834/0.840/0.831 | c=0.998347
[Epoch 0058] loss=16.9257 cls=0.4747 smmd=0.1147 ct=7.4393 rec=1.3247 | train/val/test=0.841/0.844/0.842 | c=0.998347
[Epoch 0059] loss=16.9358 cls=0.4740 smmd=0.1172 ct=7.4321 rec=1.3246 | train/val/test=0.829/0.834/0.830 | c=0.998347
[Epoch 0060] loss=16.9824 cls=0.4782 smmd=0.1213 ct=7.4339 rec=1.3243 | train/val/test=0.839/0.843/0.843 | c=0.998347
[Epoch 0061] loss=16.9456 cls=0.4753 smmd=0.1182 ct=7.4321 rec=1.3245 | train/val/test=0.825/0.832/0.826 | c=0.998347
[Epoch 0062] loss=16.9741 cls=0.4815 smmd=0.1216 ct=7.4280 rec=1.3224 | train/val/test=0.837/0.844/0.841 | c=0.998347
[Epoch 0063] loss=16.9482 cls=0.4757 smmd=0.1188 ct=7.4300 rec=1.3252 | train/val/test=0.819/0.827/0.822 | c=0.998347
[Epoch 0064] loss=16.9768 cls=0.4866 smmd=0.1216 ct=7.4281 rec=1.3226 | train/val/test=0.836/0.840/0.838 | c=0.998347
[Epoch 0065] loss=16.9411 cls=0.4781 smmd=0.1204 ct=7.4177 rec=1.3247 | train/val/test=0.822/0.829/0.826 | c=0.998347
[Epoch 0066] loss=16.9546 cls=0.4818 smmd=0.1203 ct=7.4247 rec=1.3228 | train/val/test=0.839/0.844/0.840 | c=0.998347
[Epoch 0067] loss=16.9304 cls=0.4733 smmd=0.1203 ct=7.4149 rec=1.3224 | train/val/test=0.828/0.832/0.831 | c=0.998347
[Epoch 0068] loss=16.8797 cls=0.4778 smmd=0.1138 ct=7.4205 rec=1.3232 | train/val/test=0.840/0.843/0.839 | c=0.998347
[Epoch 0069] loss=16.8350 cls=0.4732 smmd=0.1111 ct=7.4128 rec=1.3227 | train/val/test=0.830/0.838/0.833 | c=0.998347
[Epoch 0070] loss=16.8650 cls=0.4770 smmd=0.1137 ct=7.4133 rec=1.3248 | train/val/test=0.840/0.846/0.838 | c=0.998347
[Epoch 0071] loss=16.9028 cls=0.4750 smmd=0.1171 ct=7.4163 rec=1.3243 | train/val/test=0.833/0.843/0.834 | c=0.998347
[Epoch 0072] loss=16.9336 cls=0.4780 smmd=0.1203 ct=7.4146 rec=1.3253 | train/val/test=0.839/0.847/0.837 | c=0.998347
[Epoch 0073] loss=16.9186 cls=0.4755 smmd=0.1192 ct=7.4132 rec=1.3254 | train/val/test=0.834/0.843/0.834 | c=0.998347
[Epoch 0074] loss=16.9027 cls=0.4773 smmd=0.1173 ct=7.4142 rec=1.3248 | train/val/test=0.840/0.846/0.836 | c=0.998347
[Epoch 0075] loss=16.9192 cls=0.4756 smmd=0.1197 ct=7.4111 rec=1.3245 | train/val/test=0.834/0.841/0.834 | c=0.998347
[Epoch 0076] loss=16.9001 cls=0.4759 smmd=0.1177 ct=7.4117 rec=1.3235 | train/val/test=0.839/0.847/0.835 | c=0.998347
[Epoch 0077] loss=16.8275 cls=0.4737 smmd=0.1110 ct=7.4097 rec=1.3231 | train/val/test=0.835/0.843/0.834 | c=0.998347
[Epoch 0078] loss=16.7965 cls=0.4732 smmd=0.1082 ct=7.4082 rec=1.3220 | train/val/test=0.840/0.847/0.836 | c=0.998347
[Epoch 0079] loss=16.8113 cls=0.4728 smmd=0.1100 ct=7.4067 rec=1.3224 | train/val/test=0.833/0.841/0.834 | c=0.998347
[Epoch 0080] loss=16.7899 cls=0.4739 smmd=0.1069 ct=7.4114 rec=1.3222 | train/val/test=0.839/0.846/0.838 | c=0.998347
[Epoch 0081] loss=16.8007 cls=0.4737 smmd=0.1099 ct=7.4016 rec=1.3236 | train/val/test=0.827/0.834/0.829 | c=0.998347
[Epoch 0082] loss=16.8788 cls=0.4805 smmd=0.1139 ct=7.4185 rec=1.3244 | train/val/test=0.839/0.842/0.840 | c=0.998347
[Epoch 0083] loss=16.9166 cls=0.4816 smmd=0.1212 ct=7.3998 rec=1.3279 | train/val/test=0.814/0.824/0.819 | c=0.998347
[Epoch 0084] loss=16.9648 cls=0.4968 smmd=0.1202 ct=7.4249 rec=1.3291 | train/val/test=0.827/0.831/0.828 | c=0.998347
[Epoch 0085] loss=17.0950 cls=0.5035 smmd=0.1357 ct=7.4097 rec=1.3346 | train/val/test=0.794/0.805/0.795 | c=0.998347
[Epoch 0086] loss=17.3047 cls=0.5309 smmd=0.1499 ct=7.4357 rec=1.3376 | train/val/test=0.803/0.809/0.805 | c=0.998347
[Epoch 0087] loss=17.3868 cls=0.5276 smmd=0.1612 ct=7.4202 rec=1.3405 | train/val/test=0.797/0.809/0.803 | c=0.998347
[Epoch 0088] loss=17.2270 cls=0.5193 smmd=0.1460 ct=7.4211 rec=1.3296 | train/val/test=0.833/0.835/0.838 | c=0.998347
[Epoch 0089] loss=16.9935 cls=0.4797 smmd=0.1282 ct=7.4053 rec=1.3221 | train/val/test=0.828/0.835/0.830 | c=0.998347
[Epoch 0090] loss=16.8450 cls=0.4672 smmd=0.1169 ct=7.3924 rec=1.3150 | train/val/test=0.832/0.839/0.832 | c=0.998347
[Epoch 0091] loss=16.7995 cls=0.4704 smmd=0.1107 ct=7.3998 rec=1.3160 | train/val/test=0.836/0.843/0.841 | c=0.998347
[Epoch 0092] loss=16.7960 cls=0.4738 smmd=0.1100 ct=7.3985 rec=1.3235 | train/val/test=0.823/0.829/0.822 | c=0.998347
[Epoch 0093] loss=16.8710 cls=0.4955 smmd=0.1137 ct=7.4112 rec=1.3272 | train/val/test=0.837/0.847/0.842 | c=0.998347
[Epoch 0094] loss=16.9867 cls=0.4914 smmd=0.1265 ct=7.4044 rec=1.3344 | train/val/test=0.825/0.831/0.824 | c=0.998347
[Epoch 0095] loss=17.0221 cls=0.5069 smmd=0.1263 ct=7.4192 rec=1.3340 | train/val/test=0.837/0.847/0.842 | c=0.998347
[Epoch 0096] loss=17.0856 cls=0.4955 smmd=0.1362 ct=7.4035 rec=1.3378 | train/val/test=0.823/0.829/0.824 | c=0.998347
[Epoch 0097] loss=17.2562 cls=0.5089 smmd=0.1486 ct=7.4249 rec=1.3318 | train/val/test=0.836/0.848/0.841 | c=0.998347
[Epoch 0098] loss=17.3629 cls=0.4913 smmd=0.1647 ct=7.4010 rec=1.3359 | train/val/test=0.821/0.826/0.819 | c=0.998347
[Epoch 0099] loss=17.2046 cls=0.5038 smmd=0.1446 ct=7.4225 rec=1.3238 | train/val/test=0.835/0.845/0.838 | c=0.998347
=== Best @ epoch 97: val=0.8476, test=0.8408 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-10-3 completed in 142.62 seconds.
==================================================
