Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-2 - 2025-09-21 03:56:05:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-2...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-2 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=40.2680 cls=1.1007 smmd=5.6598 ct=11.2773 rec=1.4138 | train/val/test=0.346/0.196/0.180 | c=0.998437
[Epoch 0001] loss=29.8325 cls=1.0845 smmd=3.5816 ct=11.2410 rec=1.4138 | train/val/test=0.731/0.518/0.503 | c=0.998437
[Epoch 0002] loss=35.8954 cls=1.0614 smmd=4.7968 ct=11.2396 rec=1.4134 | train/val/test=0.577/0.372/0.357 | c=0.998437
[Epoch 0003] loss=35.1848 cls=1.0110 smmd=4.6696 ct=11.1898 rec=1.4128 | train/val/test=0.654/0.428/0.420 | c=0.998437
[Epoch 0004] loss=26.4007 cls=0.9285 smmd=2.9508 ct=11.0415 rec=1.4101 | train/val/test=0.692/0.470/0.456 | c=0.998437
[Epoch 0005] loss=25.2559 cls=0.8345 smmd=2.7401 ct=10.9978 rec=1.4030 | train/val/test=0.769/0.620/0.616 | c=0.998437
[Epoch 0006] loss=27.6714 cls=0.7091 smmd=3.2323 ct=11.0165 rec=1.3884 | train/val/test=0.731/0.616/0.614 | c=0.998437
[Epoch 0007] loss=26.3917 cls=0.6092 smmd=2.9952 ct=10.9741 rec=1.3703 | train/val/test=0.731/0.616/0.613 | c=0.998437
[Epoch 0008] loss=21.9940 cls=0.5338 smmd=2.1387 ct=10.8983 rec=1.3532 | train/val/test=0.731/0.624/0.626 | c=0.998437
[Epoch 0009] loss=21.8179 cls=0.4755 smmd=2.1082 ct=10.9050 rec=1.3432 | train/val/test=0.769/0.666/0.658 | c=0.998437
[Epoch 0010] loss=24.6690 cls=0.4208 smmd=2.5363 ct=11.6432 rec=1.3409 | train/val/test=0.923/0.708/0.706 | c=0.998437
[Epoch 0011] loss=23.1243 cls=0.3592 smmd=2.2628 ct=11.4959 rec=1.3468 | train/val/test=1.000/0.722/0.721 | c=0.998437
[Epoch 0012] loss=19.9434 cls=0.3084 smmd=1.6415 ct=11.4471 rec=1.3455 | train/val/test=1.000/0.732/0.722 | c=0.998437
[Epoch 0013] loss=23.1460 cls=0.2854 smmd=2.2370 ct=11.6836 rec=1.3492 | train/val/test=1.000/0.750/0.735 | c=0.998437
[Epoch 0014] loss=22.0643 cls=0.2378 smmd=2.0340 ct=11.6411 rec=1.3444 | train/val/test=1.000/0.752/0.746 | c=0.998437
[Epoch 0015] loss=19.3554 cls=0.1815 smmd=1.5292 ct=11.4848 rec=1.3367 | train/val/test=1.000/0.754/0.748 | c=0.998437
[Epoch 0016] loss=19.7062 cls=0.1498 smmd=1.6055 ct=11.4710 rec=1.3307 | train/val/test=1.000/0.764/0.752 | c=0.998437
[Epoch 0017] loss=20.3637 cls=0.1243 smmd=1.7329 ct=11.5049 rec=1.3243 | train/val/test=1.000/0.784/0.770 | c=0.998437
[Epoch 0018] loss=18.7062 cls=0.1060 smmd=1.4012 ct=11.5152 rec=1.3212 | train/val/test=1.000/0.782/0.774 | c=0.998437
[Epoch 0019] loss=17.5708 cls=0.0993 smmd=1.1797 ct=11.4905 rec=1.3225 | train/val/test=1.000/0.774/0.760 | c=0.998437
[Epoch 0020] loss=18.7561 cls=0.1003 smmd=1.4133 ct=11.5074 rec=1.3199 | train/val/test=1.000/0.780/0.773 | c=0.998437
[Epoch 0021] loss=18.1658 cls=0.1047 smmd=1.2868 ct=11.5469 rec=1.3262 | train/val/test=1.000/0.772/0.752 | c=0.998437
[Epoch 0022] loss=17.0784 cls=0.1016 smmd=1.0714 ct=11.5392 rec=1.3159 | train/val/test=1.000/0.768/0.752 | c=0.998437
[Epoch 0023] loss=17.8222 cls=0.0962 smmd=1.2296 ct=11.4946 rec=1.3149 | train/val/test=1.000/0.774/0.767 | c=0.998437
[Epoch 0024] loss=17.2847 cls=0.0846 smmd=1.1193 ct=11.5148 rec=1.3113 | train/val/test=1.000/0.772/0.773 | c=0.998437
[Epoch 0025] loss=16.6609 cls=0.0782 smmd=0.9975 ct=11.5034 rec=1.3060 | train/val/test=1.000/0.786/0.776 | c=0.998437
[Epoch 0026] loss=16.3108 cls=0.0688 smmd=0.9368 ct=11.4617 rec=1.3088 | train/val/test=1.000/0.780/0.760 | c=0.998437
[Epoch 0027] loss=16.6604 cls=0.0700 smmd=0.9923 ct=11.5338 rec=1.3019 | train/val/test=1.000/0.780/0.767 | c=0.998437
[Epoch 0028] loss=15.7856 cls=0.0647 smmd=0.8188 ct=11.5294 rec=1.3004 | train/val/test=1.000/0.802/0.776 | c=0.998437
[Epoch 0029] loss=15.9728 cls=0.0634 smmd=0.8718 ct=11.4518 rec=1.3049 | train/val/test=1.000/0.784/0.780 | c=0.998437
[Epoch 0030] loss=15.8309 cls=0.0639 smmd=0.8388 ct=11.4747 rec=1.3022 | train/val/test=1.000/0.796/0.770 | c=0.998437
[Epoch 0031] loss=15.8080 cls=0.0732 smmd=0.8183 ct=11.5491 rec=1.3087 | train/val/test=1.000/0.784/0.782 | c=0.998437
[Epoch 0032] loss=15.6921 cls=0.0729 smmd=0.8156 ct=11.4470 rec=1.3041 | train/val/test=1.000/0.802/0.763 | c=0.998437
[Epoch 0033] loss=15.7360 cls=0.0789 smmd=0.8081 ct=11.5249 rec=1.3129 | train/val/test=1.000/0.784/0.777 | c=0.998437
[Epoch 0034] loss=15.6760 cls=0.0770 smmd=0.7968 ct=11.5232 rec=1.3022 | train/val/test=1.000/0.798/0.794 | c=0.998437
[Epoch 0035] loss=14.9615 cls=0.0707 smmd=0.6695 ct=11.4480 rec=1.3041 | train/val/test=1.000/0.808/0.786 | c=0.998437
[Epoch 0036] loss=15.0585 cls=0.0696 smmd=0.6809 ct=11.4885 rec=1.3055 | train/val/test=1.000/0.786/0.789 | c=0.998437
[Epoch 0037] loss=15.0170 cls=0.0699 smmd=0.6701 ct=11.5015 rec=1.2990 | train/val/test=1.000/0.808/0.774 | c=0.998437
[Epoch 0038] loss=14.5370 cls=0.0748 smmd=0.5831 ct=11.4532 rec=1.3107 | train/val/test=1.000/0.782/0.790 | c=0.998437
[Epoch 0039] loss=15.0214 cls=0.0780 smmd=0.6685 ct=11.5093 rec=1.3062 | train/val/test=1.000/0.786/0.784 | c=0.998437
[Epoch 0040] loss=15.0828 cls=0.0821 smmd=0.6776 ct=11.5232 rec=1.3077 | train/val/test=1.000/0.806/0.777 | c=0.998437
[Epoch 0041] loss=14.7382 cls=0.0866 smmd=0.6190 ct=11.4682 rec=1.3162 | train/val/test=1.000/0.790/0.787 | c=0.998437
[Epoch 0042] loss=15.1702 cls=0.0825 smmd=0.6964 ct=11.5160 rec=1.3101 | train/val/test=1.000/0.806/0.780 | c=0.998437
[Epoch 0043] loss=14.7896 cls=0.0797 smmd=0.6243 ct=11.4971 rec=1.3117 | train/val/test=1.000/0.798/0.783 | c=0.998437
[Epoch 0044] loss=14.4982 cls=0.0763 smmd=0.5695 ct=11.4814 rec=1.3112 | train/val/test=1.000/0.802/0.775 | c=0.998437
[Epoch 0045] loss=14.6129 cls=0.0775 smmd=0.5879 ct=11.5037 rec=1.3082 | train/val/test=1.000/0.794/0.784 | c=0.998437
[Epoch 0046] loss=14.3101 cls=0.0746 smmd=0.5330 ct=11.4770 rec=1.3107 | train/val/test=1.000/0.790/0.787 | c=0.998437
[Epoch 0047] loss=14.3259 cls=0.0765 smmd=0.5337 ct=11.4880 rec=1.3105 | train/val/test=1.000/0.806/0.780 | c=0.998437
[Epoch 0048] loss=14.2490 cls=0.0818 smmd=0.5180 ct=11.4864 rec=1.3146 | train/val/test=1.000/0.792/0.788 | c=0.998437
[Epoch 0049] loss=14.1219 cls=0.0885 smmd=0.4910 ct=11.4909 rec=1.3171 | train/val/test=1.000/0.794/0.783 | c=0.998437
[Epoch 0050] loss=14.5661 cls=0.0970 smmd=0.5800 ct=11.4854 rec=1.3225 | train/val/test=1.000/0.786/0.781 | c=0.998437
[Epoch 0051] loss=14.7906 cls=0.1010 smmd=0.6191 ct=11.5126 rec=1.3224 | train/val/test=1.000/0.794/0.781 | c=0.998437
[Epoch 0052] loss=14.5280 cls=0.1069 smmd=0.5714 ct=11.4848 rec=1.3268 | train/val/test=1.000/0.794/0.776 | c=0.998437
[Epoch 0053] loss=14.1282 cls=0.0968 smmd=0.4909 ct=11.4935 rec=1.3206 | train/val/test=1.000/0.780/0.776 | c=0.998437
[Epoch 0054] loss=14.2391 cls=0.0952 smmd=0.5170 ct=11.4743 rec=1.3212 | train/val/test=1.000/0.810/0.763 | c=0.998437
[Epoch 0055] loss=13.9879 cls=0.0918 smmd=0.4644 ct=11.4878 rec=1.3203 | train/val/test=1.000/0.784/0.774 | c=0.998437
[Epoch 0056] loss=13.8373 cls=0.0889 smmd=0.4390 ct=11.4658 rec=1.3196 | train/val/test=1.000/0.800/0.769 | c=0.998437
[Epoch 0057] loss=14.1323 cls=0.0945 smmd=0.4910 ct=11.4977 rec=1.3216 | train/val/test=1.000/0.776/0.769 | c=0.998437
[Epoch 0058] loss=14.3888 cls=0.1043 smmd=0.5439 ct=11.4843 rec=1.3293 | train/val/test=1.000/0.734/0.698 | c=0.998437
[Epoch 0059] loss=14.5048 cls=0.1247 smmd=0.5542 ct=11.5377 rec=1.3347 | train/val/test=1.000/0.754/0.754 | c=0.998437
[Epoch 0060] loss=14.7515 cls=0.1337 smmd=0.6057 ct=11.5220 rec=1.3428 | train/val/test=1.000/0.680/0.657 | c=0.998437
[Epoch 0061] loss=14.2483 cls=0.1257 smmd=0.5008 ct=11.5477 rec=1.3360 | train/val/test=1.000/0.752/0.747 | c=0.998437
[Epoch 0062] loss=14.3296 cls=0.0967 smmd=0.5326 ct=11.4853 rec=1.3301 | train/val/test=1.000/0.780/0.747 | c=0.998437
[Epoch 0063] loss=13.8459 cls=0.0787 smmd=0.4342 ct=11.5036 rec=1.3196 | train/val/test=1.000/0.784/0.771 | c=0.998437
[Epoch 0064] loss=13.7823 cls=0.0701 smmd=0.4347 ct=11.4423 rec=1.3128 | train/val/test=1.000/0.804/0.770 | c=0.998437
[Epoch 0065] loss=13.7546 cls=0.0708 smmd=0.4238 ct=11.4688 rec=1.3166 | train/val/test=1.000/0.792/0.773 | c=0.998437
[Epoch 0066] loss=13.8092 cls=0.0785 smmd=0.4303 ct=11.4863 rec=1.3207 | train/val/test=1.000/0.790/0.768 | c=0.998437
[Epoch 0067] loss=14.2248 cls=0.0903 smmd=0.5142 ct=11.4760 rec=1.3273 | train/val/test=1.000/0.788/0.769 | c=0.998437
[Epoch 0068] loss=14.6026 cls=0.1105 smmd=0.5820 ct=11.5036 rec=1.3366 | train/val/test=1.000/0.792/0.751 | c=0.998437
[Epoch 0069] loss=14.5456 cls=0.1039 smmd=0.5688 ct=11.5163 rec=1.3344 | train/val/test=1.000/0.780/0.766 | c=0.998437
[Epoch 0070] loss=14.3632 cls=0.1095 smmd=0.5413 ct=11.4685 rec=1.3346 | train/val/test=1.000/0.792/0.743 | c=0.998437
[Epoch 0071] loss=13.8240 cls=0.0932 smmd=0.4295 ct=11.4973 rec=1.3279 | train/val/test=1.000/0.786/0.771 | c=0.998437
[Epoch 0072] loss=13.6660 cls=0.0928 smmd=0.4067 ct=11.4532 rec=1.3267 | train/val/test=1.000/0.798/0.749 | c=0.998437
[Epoch 0073] loss=13.7587 cls=0.0910 smmd=0.4217 ct=11.4723 rec=1.3253 | train/val/test=1.000/0.792/0.766 | c=0.998437
[Epoch 0074] loss=13.7418 cls=0.1011 smmd=0.4186 ct=11.4653 rec=1.3317 | train/val/test=1.000/0.766/0.716 | c=0.998437
[Epoch 0075] loss=13.7912 cls=0.1113 smmd=0.4197 ct=11.5037 rec=1.3349 | train/val/test=1.000/0.772/0.758 | c=0.998437
[Epoch 0076] loss=14.2921 cls=0.1325 smmd=0.5176 ct=11.5031 rec=1.3450 | train/val/test=1.000/0.656/0.627 | c=0.998437
[Epoch 0077] loss=14.6084 cls=0.1488 smmd=0.5663 ct=11.5671 rec=1.3514 | train/val/test=1.000/0.738/0.743 | c=0.998437
[Epoch 0078] loss=14.7639 cls=0.1501 smmd=0.6060 ct=11.5233 rec=1.3529 | train/val/test=1.000/0.698/0.660 | c=0.998437
[Epoch 0079] loss=13.9963 cls=0.1125 smmd=0.4494 ct=11.5596 rec=1.3358 | train/val/test=1.000/0.770/0.753 | c=0.998437
[Epoch 0080] loss=13.8296 cls=0.0757 smmd=0.4433 ct=11.4434 rec=1.3209 | train/val/test=1.000/0.784/0.743 | c=0.998437
[Epoch 0081] loss=13.5231 cls=0.0663 smmd=0.3761 ct=11.4775 rec=1.3201 | train/val/test=1.000/0.786/0.759 | c=0.998437
[Epoch 0082] loss=13.3276 cls=0.0639 smmd=0.3416 ct=11.4563 rec=1.3136 | train/val/test=1.000/0.802/0.752 | c=0.998437
[Epoch 0083] loss=13.4779 cls=0.0663 smmd=0.3726 ct=11.4496 rec=1.3192 | train/val/test=1.000/0.800/0.761 | c=0.998437
[Epoch 0084] loss=13.8083 cls=0.0779 smmd=0.4282 ct=11.4954 rec=1.3270 | train/val/test=1.000/0.796/0.759 | c=0.998437
[Epoch 0085] loss=14.2177 cls=0.0915 smmd=0.5078 ct=11.4997 rec=1.3337 | train/val/test=1.000/0.784/0.762 | c=0.998437
[Epoch 0086] loss=14.7270 cls=0.1043 smmd=0.6103 ct=11.4895 rec=1.3383 | train/val/test=1.000/0.788/0.752 | c=0.998437
[Epoch 0087] loss=14.5859 cls=0.1073 smmd=0.5785 ct=11.5057 rec=1.3393 | train/val/test=1.000/0.782/0.767 | c=0.998437
[Epoch 0088] loss=14.0177 cls=0.0971 smmd=0.4747 ct=11.4623 rec=1.3323 | train/val/test=1.000/0.790/0.749 | c=0.998437
[Epoch 0089] loss=13.5820 cls=0.0956 smmd=0.3914 ct=11.4440 rec=1.3327 | train/val/test=1.000/0.784/0.769 | c=0.998437
[Epoch 0090] loss=13.2595 cls=0.0873 smmd=0.3280 ct=11.4435 rec=1.3258 | train/val/test=1.000/0.796/0.757 | c=0.998437
[Epoch 0091] loss=13.3790 cls=0.0903 smmd=0.3498 ct=11.4517 rec=1.3292 | train/val/test=1.000/0.780/0.770 | c=0.998437
[Epoch 0092] loss=13.4240 cls=0.0989 smmd=0.3612 ct=11.4353 rec=1.3325 | train/val/test=1.000/0.790/0.751 | c=0.998437
[Epoch 0093] loss=13.5391 cls=0.1103 smmd=0.3702 ct=11.4987 rec=1.3406 | train/val/test=1.000/0.756/0.728 | c=0.998437
[Epoch 0094] loss=14.3210 cls=0.1329 smmd=0.5247 ct=11.4965 rec=1.3464 | train/val/test=1.000/0.694/0.668 | c=0.998437
[Epoch 0095] loss=15.0842 cls=0.1613 smmd=0.6646 ct=11.5432 rec=1.3722 | train/val/test=1.000/0.632/0.623 | c=0.998437
[Epoch 0096] loss=14.9977 cls=0.2061 smmd=0.6340 ct=11.5884 rec=1.3622 | train/val/test=1.000/0.722/0.684 | c=0.998437
[Epoch 0097] loss=14.1909 cls=0.1051 smmd=0.4980 ct=11.5133 rec=1.3528 | train/val/test=1.000/0.790/0.744 | c=0.998437
[Epoch 0098] loss=13.4747 cls=0.0637 smmd=0.3742 ct=11.4407 rec=1.3093 | train/val/test=1.000/0.776/0.732 | c=0.998437
[Epoch 0099] loss=13.4995 cls=0.0593 smmd=0.3775 ct=11.4514 rec=1.3068 | train/val/test=1.000/0.796/0.750 | c=0.998437
=== Best @ epoch 54: val=0.8100, test=0.7630 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-2 - 2025-09-21 03:56:05:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-2...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-2 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=40.2680 cls=1.1007 smmd=5.6598 ct=11.2773 rec=1.4138 | train/val/test=0.346/0.196/0.180 | c=0.998437
[Epoch 0001] loss=29.8325 cls=1.0845 smmd=3.5816 ct=11.2410 rec=1.4138 | train/val/test=0.731/0.518/0.503 | c=0.998437
[Epoch 0002] loss=35.8954 cls=1.0614 smmd=4.7968 ct=11.2396 rec=1.4134 | train/val/test=0.577/0.372/0.357 | c=0.998437
[Epoch 0003] loss=35.1848 cls=1.0110 smmd=4.6696 ct=11.1898 rec=1.4128 | train/val/test=0.654/0.428/0.420 | c=0.998437
[Epoch 0004] loss=26.4007 cls=0.9285 smmd=2.9508 ct=11.0415 rec=1.4101 | train/val/test=0.692/0.470/0.456 | c=0.998437
[Epoch 0005] loss=25.2559 cls=0.8345 smmd=2.7401 ct=10.9978 rec=1.4030 | train/val/test=0.769/0.620/0.616 | c=0.998437
[Epoch 0006] loss=27.6714 cls=0.7091 smmd=3.2323 ct=11.0165 rec=1.3884 | train/val/test=0.731/0.616/0.614 | c=0.998437
[Epoch 0007] loss=26.3917 cls=0.6092 smmd=2.9952 ct=10.9741 rec=1.3703 | train/val/test=0.731/0.616/0.613 | c=0.998437
[Epoch 0008] loss=21.9940 cls=0.5338 smmd=2.1387 ct=10.8983 rec=1.3532 | train/val/test=0.731/0.624/0.626 | c=0.998437
[Epoch 0009] loss=21.8179 cls=0.4755 smmd=2.1082 ct=10.9050 rec=1.3432 | train/val/test=0.769/0.666/0.658 | c=0.998437
[Epoch 0010] loss=24.6690 cls=0.4208 smmd=2.5363 ct=11.6432 rec=1.3409 | train/val/test=0.923/0.708/0.706 | c=0.998437
[Epoch 0011] loss=23.1243 cls=0.3592 smmd=2.2628 ct=11.4959 rec=1.3468 | train/val/test=1.000/0.722/0.721 | c=0.998437
[Epoch 0012] loss=19.9434 cls=0.3084 smmd=1.6415 ct=11.4471 rec=1.3455 | train/val/test=1.000/0.732/0.722 | c=0.998437
[Epoch 0013] loss=23.1460 cls=0.2854 smmd=2.2370 ct=11.6836 rec=1.3492 | train/val/test=1.000/0.750/0.735 | c=0.998437
[Epoch 0014] loss=22.0643 cls=0.2378 smmd=2.0340 ct=11.6411 rec=1.3444 | train/val/test=1.000/0.752/0.746 | c=0.998437
[Epoch 0015] loss=19.3554 cls=0.1815 smmd=1.5292 ct=11.4848 rec=1.3367 | train/val/test=1.000/0.754/0.748 | c=0.998437
[Epoch 0016] loss=19.7062 cls=0.1498 smmd=1.6055 ct=11.4710 rec=1.3307 | train/val/test=1.000/0.764/0.752 | c=0.998437
[Epoch 0017] loss=20.3637 cls=0.1243 smmd=1.7329 ct=11.5049 rec=1.3243 | train/val/test=1.000/0.784/0.770 | c=0.998437
[Epoch 0018] loss=18.7062 cls=0.1060 smmd=1.4012 ct=11.5152 rec=1.3212 | train/val/test=1.000/0.782/0.774 | c=0.998437
[Epoch 0019] loss=17.5708 cls=0.0993 smmd=1.1797 ct=11.4905 rec=1.3225 | train/val/test=1.000/0.774/0.760 | c=0.998437
[Epoch 0020] loss=18.7561 cls=0.1003 smmd=1.4133 ct=11.5074 rec=1.3199 | train/val/test=1.000/0.780/0.773 | c=0.998437
[Epoch 0021] loss=18.1658 cls=0.1047 smmd=1.2868 ct=11.5469 rec=1.3262 | train/val/test=1.000/0.772/0.752 | c=0.998437
[Epoch 0022] loss=17.0784 cls=0.1016 smmd=1.0714 ct=11.5392 rec=1.3159 | train/val/test=1.000/0.768/0.752 | c=0.998437
[Epoch 0023] loss=17.8222 cls=0.0962 smmd=1.2296 ct=11.4946 rec=1.3149 | train/val/test=1.000/0.774/0.767 | c=0.998437
[Epoch 0024] loss=17.2847 cls=0.0846 smmd=1.1193 ct=11.5148 rec=1.3113 | train/val/test=1.000/0.772/0.773 | c=0.998437
[Epoch 0025] loss=16.6609 cls=0.0782 smmd=0.9975 ct=11.5034 rec=1.3060 | train/val/test=1.000/0.786/0.776 | c=0.998437
[Epoch 0026] loss=16.3108 cls=0.0688 smmd=0.9368 ct=11.4617 rec=1.3088 | train/val/test=1.000/0.780/0.760 | c=0.998437
[Epoch 0027] loss=16.6604 cls=0.0700 smmd=0.9923 ct=11.5338 rec=1.3019 | train/val/test=1.000/0.780/0.767 | c=0.998437
[Epoch 0028] loss=15.7856 cls=0.0647 smmd=0.8188 ct=11.5294 rec=1.3004 | train/val/test=1.000/0.802/0.776 | c=0.998437
[Epoch 0029] loss=15.9728 cls=0.0634 smmd=0.8718 ct=11.4518 rec=1.3049 | train/val/test=1.000/0.784/0.780 | c=0.998437
[Epoch 0030] loss=15.8309 cls=0.0639 smmd=0.8388 ct=11.4747 rec=1.3022 | train/val/test=1.000/0.796/0.770 | c=0.998437
[Epoch 0031] loss=15.8080 cls=0.0732 smmd=0.8183 ct=11.5491 rec=1.3087 | train/val/test=1.000/0.784/0.782 | c=0.998437
[Epoch 0032] loss=15.6921 cls=0.0729 smmd=0.8156 ct=11.4470 rec=1.3041 | train/val/test=1.000/0.802/0.763 | c=0.998437
[Epoch 0033] loss=15.7360 cls=0.0789 smmd=0.8081 ct=11.5249 rec=1.3129 | train/val/test=1.000/0.784/0.777 | c=0.998437
[Epoch 0034] loss=15.6760 cls=0.0770 smmd=0.7968 ct=11.5232 rec=1.3022 | train/val/test=1.000/0.798/0.794 | c=0.998437
[Epoch 0035] loss=14.9615 cls=0.0707 smmd=0.6695 ct=11.4480 rec=1.3041 | train/val/test=1.000/0.808/0.786 | c=0.998437
[Epoch 0036] loss=15.0585 cls=0.0696 smmd=0.6809 ct=11.4885 rec=1.3055 | train/val/test=1.000/0.786/0.789 | c=0.998437
[Epoch 0037] loss=15.0170 cls=0.0699 smmd=0.6701 ct=11.5015 rec=1.2990 | train/val/test=1.000/0.808/0.774 | c=0.998437
[Epoch 0038] loss=14.5370 cls=0.0748 smmd=0.5831 ct=11.4532 rec=1.3107 | train/val/test=1.000/0.782/0.790 | c=0.998437
[Epoch 0039] loss=15.0214 cls=0.0780 smmd=0.6685 ct=11.5093 rec=1.3062 | train/val/test=1.000/0.786/0.784 | c=0.998437
[Epoch 0040] loss=15.0828 cls=0.0821 smmd=0.6776 ct=11.5232 rec=1.3077 | train/val/test=1.000/0.806/0.777 | c=0.998437
[Epoch 0041] loss=14.7382 cls=0.0866 smmd=0.6190 ct=11.4682 rec=1.3162 | train/val/test=1.000/0.790/0.787 | c=0.998437
[Epoch 0042] loss=15.1702 cls=0.0825 smmd=0.6964 ct=11.5160 rec=1.3101 | train/val/test=1.000/0.806/0.780 | c=0.998437
[Epoch 0043] loss=14.7896 cls=0.0797 smmd=0.6243 ct=11.4971 rec=1.3117 | train/val/test=1.000/0.798/0.783 | c=0.998437
[Epoch 0044] loss=14.4982 cls=0.0763 smmd=0.5695 ct=11.4814 rec=1.3112 | train/val/test=1.000/0.802/0.775 | c=0.998437
[Epoch 0045] loss=14.6129 cls=0.0775 smmd=0.5879 ct=11.5037 rec=1.3082 | train/val/test=1.000/0.794/0.784 | c=0.998437
[Epoch 0046] loss=14.3101 cls=0.0746 smmd=0.5330 ct=11.4770 rec=1.3107 | train/val/test=1.000/0.790/0.787 | c=0.998437
[Epoch 0047] loss=14.3259 cls=0.0765 smmd=0.5337 ct=11.4880 rec=1.3105 | train/val/test=1.000/0.806/0.780 | c=0.998437
[Epoch 0048] loss=14.2490 cls=0.0818 smmd=0.5180 ct=11.4864 rec=1.3146 | train/val/test=1.000/0.792/0.788 | c=0.998437
[Epoch 0049] loss=14.1219 cls=0.0885 smmd=0.4910 ct=11.4909 rec=1.3171 | train/val/test=1.000/0.794/0.783 | c=0.998437
[Epoch 0050] loss=14.5661 cls=0.0970 smmd=0.5800 ct=11.4854 rec=1.3225 | train/val/test=1.000/0.786/0.781 | c=0.998437
[Epoch 0051] loss=14.7906 cls=0.1010 smmd=0.6191 ct=11.5126 rec=1.3224 | train/val/test=1.000/0.794/0.781 | c=0.998437
[Epoch 0052] loss=14.5280 cls=0.1069 smmd=0.5714 ct=11.4848 rec=1.3268 | train/val/test=1.000/0.794/0.776 | c=0.998437
[Epoch 0053] loss=14.1282 cls=0.0968 smmd=0.4909 ct=11.4935 rec=1.3206 | train/val/test=1.000/0.780/0.776 | c=0.998437
[Epoch 0054] loss=14.2391 cls=0.0952 smmd=0.5170 ct=11.4743 rec=1.3212 | train/val/test=1.000/0.810/0.763 | c=0.998437
[Epoch 0055] loss=13.9879 cls=0.0918 smmd=0.4644 ct=11.4878 rec=1.3203 | train/val/test=1.000/0.784/0.774 | c=0.998437
[Epoch 0056] loss=13.8373 cls=0.0889 smmd=0.4390 ct=11.4658 rec=1.3196 | train/val/test=1.000/0.800/0.769 | c=0.998437
[Epoch 0057] loss=14.1323 cls=0.0945 smmd=0.4910 ct=11.4977 rec=1.3216 | train/val/test=1.000/0.776/0.769 | c=0.998437
[Epoch 0058] loss=14.3888 cls=0.1043 smmd=0.5439 ct=11.4843 rec=1.3293 | train/val/test=1.000/0.734/0.698 | c=0.998437
[Epoch 0059] loss=14.5048 cls=0.1247 smmd=0.5542 ct=11.5377 rec=1.3347 | train/val/test=1.000/0.754/0.754 | c=0.998437
[Epoch 0060] loss=14.7515 cls=0.1337 smmd=0.6057 ct=11.5220 rec=1.3428 | train/val/test=1.000/0.680/0.657 | c=0.998437
[Epoch 0061] loss=14.2483 cls=0.1257 smmd=0.5008 ct=11.5477 rec=1.3360 | train/val/test=1.000/0.752/0.747 | c=0.998437
[Epoch 0062] loss=14.3296 cls=0.0967 smmd=0.5326 ct=11.4853 rec=1.3301 | train/val/test=1.000/0.780/0.747 | c=0.998437
[Epoch 0063] loss=13.8459 cls=0.0787 smmd=0.4342 ct=11.5036 rec=1.3196 | train/val/test=1.000/0.784/0.771 | c=0.998437
[Epoch 0064] loss=13.7823 cls=0.0701 smmd=0.4347 ct=11.4423 rec=1.3128 | train/val/test=1.000/0.804/0.770 | c=0.998437
[Epoch 0065] loss=13.7546 cls=0.0708 smmd=0.4238 ct=11.4688 rec=1.3166 | train/val/test=1.000/0.792/0.773 | c=0.998437
[Epoch 0066] loss=13.8092 cls=0.0785 smmd=0.4303 ct=11.4863 rec=1.3207 | train/val/test=1.000/0.790/0.768 | c=0.998437
[Epoch 0067] loss=14.2248 cls=0.0903 smmd=0.5142 ct=11.4760 rec=1.3273 | train/val/test=1.000/0.788/0.769 | c=0.998437
[Epoch 0068] loss=14.6026 cls=0.1105 smmd=0.5820 ct=11.5036 rec=1.3366 | train/val/test=1.000/0.792/0.751 | c=0.998437
[Epoch 0069] loss=14.5456 cls=0.1039 smmd=0.5688 ct=11.5163 rec=1.3344 | train/val/test=1.000/0.780/0.766 | c=0.998437
[Epoch 0070] loss=14.3632 cls=0.1095 smmd=0.5413 ct=11.4685 rec=1.3346 | train/val/test=1.000/0.792/0.743 | c=0.998437
[Epoch 0071] loss=13.8240 cls=0.0932 smmd=0.4295 ct=11.4973 rec=1.3279 | train/val/test=1.000/0.786/0.771 | c=0.998437
[Epoch 0072] loss=13.6660 cls=0.0928 smmd=0.4067 ct=11.4532 rec=1.3267 | train/val/test=1.000/0.798/0.749 | c=0.998437
[Epoch 0073] loss=13.7587 cls=0.0910 smmd=0.4217 ct=11.4723 rec=1.3253 | train/val/test=1.000/0.792/0.766 | c=0.998437
[Epoch 0074] loss=13.7418 cls=0.1011 smmd=0.4186 ct=11.4653 rec=1.3317 | train/val/test=1.000/0.766/0.716 | c=0.998437
[Epoch 0075] loss=13.7912 cls=0.1113 smmd=0.4197 ct=11.5037 rec=1.3349 | train/val/test=1.000/0.772/0.758 | c=0.998437
[Epoch 0076] loss=14.2921 cls=0.1325 smmd=0.5176 ct=11.5031 rec=1.3450 | train/val/test=1.000/0.656/0.627 | c=0.998437
[Epoch 0077] loss=14.6084 cls=0.1488 smmd=0.5663 ct=11.5671 rec=1.3514 | train/val/test=1.000/0.738/0.743 | c=0.998437
[Epoch 0078] loss=14.7639 cls=0.1501 smmd=0.6060 ct=11.5233 rec=1.3529 | train/val/test=1.000/0.698/0.660 | c=0.998437
[Epoch 0079] loss=13.9963 cls=0.1125 smmd=0.4494 ct=11.5596 rec=1.3358 | train/val/test=1.000/0.770/0.753 | c=0.998437
[Epoch 0080] loss=13.8296 cls=0.0757 smmd=0.4433 ct=11.4434 rec=1.3209 | train/val/test=1.000/0.784/0.743 | c=0.998437
[Epoch 0081] loss=13.5231 cls=0.0663 smmd=0.3761 ct=11.4775 rec=1.3201 | train/val/test=1.000/0.786/0.759 | c=0.998437
[Epoch 0082] loss=13.3276 cls=0.0639 smmd=0.3416 ct=11.4563 rec=1.3136 | train/val/test=1.000/0.802/0.752 | c=0.998437
[Epoch 0083] loss=13.4779 cls=0.0663 smmd=0.3726 ct=11.4496 rec=1.3192 | train/val/test=1.000/0.800/0.761 | c=0.998437
[Epoch 0084] loss=13.8083 cls=0.0779 smmd=0.4282 ct=11.4954 rec=1.3270 | train/val/test=1.000/0.796/0.759 | c=0.998437
[Epoch 0085] loss=14.2177 cls=0.0915 smmd=0.5078 ct=11.4997 rec=1.3337 | train/val/test=1.000/0.784/0.762 | c=0.998437
[Epoch 0086] loss=14.7270 cls=0.1043 smmd=0.6103 ct=11.4895 rec=1.3383 | train/val/test=1.000/0.788/0.752 | c=0.998437
[Epoch 0087] loss=14.5859 cls=0.1073 smmd=0.5785 ct=11.5057 rec=1.3393 | train/val/test=1.000/0.782/0.767 | c=0.998437
[Epoch 0088] loss=14.0177 cls=0.0971 smmd=0.4747 ct=11.4623 rec=1.3323 | train/val/test=1.000/0.790/0.749 | c=0.998437
[Epoch 0089] loss=13.5820 cls=0.0956 smmd=0.3914 ct=11.4440 rec=1.3327 | train/val/test=1.000/0.784/0.769 | c=0.998437
[Epoch 0090] loss=13.2595 cls=0.0873 smmd=0.3280 ct=11.4435 rec=1.3258 | train/val/test=1.000/0.796/0.757 | c=0.998437
[Epoch 0091] loss=13.3790 cls=0.0903 smmd=0.3498 ct=11.4517 rec=1.3292 | train/val/test=1.000/0.780/0.770 | c=0.998437
[Epoch 0092] loss=13.4240 cls=0.0989 smmd=0.3612 ct=11.4353 rec=1.3325 | train/val/test=1.000/0.790/0.751 | c=0.998437
[Epoch 0093] loss=13.5391 cls=0.1103 smmd=0.3702 ct=11.4987 rec=1.3406 | train/val/test=1.000/0.756/0.728 | c=0.998437
[Epoch 0094] loss=14.3210 cls=0.1329 smmd=0.5247 ct=11.4965 rec=1.3464 | train/val/test=1.000/0.694/0.668 | c=0.998437
[Epoch 0095] loss=15.0842 cls=0.1613 smmd=0.6646 ct=11.5432 rec=1.3722 | train/val/test=1.000/0.632/0.623 | c=0.998437
[Epoch 0096] loss=14.9977 cls=0.2061 smmd=0.6340 ct=11.5884 rec=1.3622 | train/val/test=1.000/0.722/0.684 | c=0.998437
[Epoch 0097] loss=14.1909 cls=0.1051 smmd=0.4980 ct=11.5133 rec=1.3528 | train/val/test=1.000/0.790/0.744 | c=0.998437
[Epoch 0098] loss=13.4747 cls=0.0637 smmd=0.3742 ct=11.4407 rec=1.3093 | train/val/test=1.000/0.776/0.732 | c=0.998437
[Epoch 0099] loss=13.4995 cls=0.0593 smmd=0.3775 ct=11.4514 rec=1.3068 | train/val/test=1.000/0.796/0.750 | c=0.998437
=== Best @ epoch 54: val=0.8100, test=0.7630 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-2 completed in 138.74 seconds.
==================================================
