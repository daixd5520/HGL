Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-2 - 2025-09-21 03:32:13:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-2...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-2 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.1661 cls=1.0975 smmd=5.6401 ct=7.2546 rec=1.4136 | train/val/test=0.397/0.404/0.401 | c=0.998437
[Epoch 0001] loss=52.5203 cls=1.0659 smmd=3.6897 ct=7.1914 rec=1.4154 | train/val/test=0.403/0.417/0.406 | c=0.998437
[Epoch 0002] loss=38.0188 cls=1.0777 smmd=2.2482 ct=7.1458 rec=1.4136 | train/val/test=0.564/0.560/0.570 | c=0.998437
[Epoch 0003] loss=40.5433 cls=1.0560 smmd=2.5075 ct=7.1166 rec=1.4138 | train/val/test=0.562/0.555/0.571 | c=0.998437
[Epoch 0004] loss=40.0789 cls=1.0227 smmd=2.4724 ct=7.0680 rec=1.4148 | train/val/test=0.555/0.550/0.563 | c=0.998437
[Epoch 0005] loss=35.7113 cls=0.9914 smmd=2.0528 ct=6.9896 rec=1.4169 | train/val/test=0.551/0.546/0.558 | c=0.998437
[Epoch 0006] loss=30.7990 cls=0.9699 smmd=1.5711 ct=6.9479 rec=1.4150 | train/val/test=0.536/0.531/0.545 | c=0.998437
[Epoch 0007] loss=33.3481 cls=0.9339 smmd=1.8304 ct=6.9371 rec=1.4058 | train/val/test=0.520/0.520/0.518 | c=0.998437
[Epoch 0008] loss=34.3788 cls=0.9086 smmd=1.9340 ct=6.9429 rec=1.3980 | train/val/test=0.540/0.534/0.542 | c=0.998437
[Epoch 0009] loss=29.7065 cls=0.8740 smmd=1.3293 ct=7.6413 rec=1.3873 | train/val/test=0.566/0.561/0.573 | c=0.998437
[Epoch 0010] loss=27.8641 cls=0.8379 smmd=1.1695 ct=7.5310 rec=1.3763 | train/val/test=0.581/0.580/0.593 | c=0.998437
[Epoch 0011] loss=30.2122 cls=0.8419 smmd=1.4064 ct=7.5197 rec=1.3762 | train/val/test=0.599/0.593/0.605 | c=0.998437
[Epoch 0012] loss=27.6156 cls=0.7982 smmd=1.1531 ct=7.5001 rec=1.3698 | train/val/test=0.681/0.672/0.677 | c=0.998437
[Epoch 0013] loss=26.5422 cls=0.7567 smmd=1.0419 ct=7.5308 rec=1.3665 | train/val/test=0.724/0.714/0.710 | c=0.998437
[Epoch 0014] loss=25.7968 cls=0.7291 smmd=0.9606 ct=7.5728 rec=1.3606 | train/val/test=0.747/0.746/0.743 | c=0.998437
[Epoch 0015] loss=25.2587 cls=0.7008 smmd=0.9083 ct=7.5737 rec=1.3557 | train/val/test=0.744/0.743/0.742 | c=0.998437
[Epoch 0016] loss=24.8705 cls=0.6741 smmd=0.8813 ct=7.5214 rec=1.3550 | train/val/test=0.760/0.761/0.760 | c=0.998437
[Epoch 0017] loss=23.9017 cls=0.6423 smmd=0.7902 ct=7.5016 rec=1.3506 | train/val/test=0.781/0.778/0.767 | c=0.998437
[Epoch 0018] loss=23.0385 cls=0.6270 smmd=0.6970 ct=7.5417 rec=1.3430 | train/val/test=0.779/0.774/0.771 | c=0.998437
[Epoch 0019] loss=22.8106 cls=0.6265 smmd=0.6724 ct=7.5518 rec=1.3393 | train/val/test=0.790/0.786/0.781 | c=0.998437
[Epoch 0020] loss=22.6754 cls=0.5973 smmd=0.6653 ct=7.5286 rec=1.3339 | train/val/test=0.796/0.796/0.788 | c=0.998437
[Epoch 0021] loss=21.5621 cls=0.5730 smmd=0.5572 ct=7.5189 rec=1.3306 | train/val/test=0.803/0.805/0.796 | c=0.998437
[Epoch 0022] loss=21.5583 cls=0.5570 smmd=0.5574 ct=7.5212 rec=1.3279 | train/val/test=0.808/0.811/0.801 | c=0.998437
[Epoch 0023] loss=21.1703 cls=0.5502 smmd=0.5148 ct=7.5427 rec=1.3247 | train/val/test=0.812/0.812/0.807 | c=0.998437
[Epoch 0024] loss=20.6327 cls=0.5406 smmd=0.4629 ct=7.5361 rec=1.3227 | train/val/test=0.815/0.816/0.809 | c=0.998437
[Epoch 0025] loss=20.3997 cls=0.5258 smmd=0.4434 ct=7.5215 rec=1.3202 | train/val/test=0.815/0.814/0.808 | c=0.998437
[Epoch 0026] loss=20.1218 cls=0.5158 smmd=0.4161 ct=7.5217 rec=1.3185 | train/val/test=0.819/0.818/0.812 | c=0.998437
[Epoch 0027] loss=19.9325 cls=0.5037 smmd=0.3974 ct=7.5239 rec=1.3188 | train/val/test=0.823/0.821/0.814 | c=0.998437
[Epoch 0028] loss=19.5157 cls=0.4966 smmd=0.3546 ct=7.5310 rec=1.3179 | train/val/test=0.825/0.821/0.817 | c=0.998437
[Epoch 0029] loss=19.4124 cls=0.4876 smmd=0.3459 ct=7.5258 rec=1.3153 | train/val/test=0.827/0.823/0.817 | c=0.998437
[Epoch 0030] loss=19.2432 cls=0.4800 smmd=0.3327 ct=7.5095 rec=1.3139 | train/val/test=0.828/0.825/0.819 | c=0.998437
[Epoch 0031] loss=18.9123 cls=0.4737 smmd=0.2988 ct=7.5155 rec=1.3129 | train/val/test=0.831/0.826/0.822 | c=0.998437
[Epoch 0032] loss=18.8200 cls=0.4673 smmd=0.2901 ct=7.5143 rec=1.3137 | train/val/test=0.834/0.830/0.825 | c=0.998437
[Epoch 0033] loss=18.6779 cls=0.4628 smmd=0.2766 ct=7.5121 rec=1.3132 | train/val/test=0.833/0.831/0.828 | c=0.998437
[Epoch 0034] loss=18.3590 cls=0.4597 smmd=0.2436 ct=7.5188 rec=1.3119 | train/val/test=0.837/0.832/0.831 | c=0.998437
[Epoch 0035] loss=18.4192 cls=0.4572 smmd=0.2536 ct=7.4992 rec=1.3122 | train/val/test=0.837/0.834/0.831 | c=0.998437
[Epoch 0036] loss=18.2309 cls=0.4562 smmd=0.2337 ct=7.5049 rec=1.3119 | train/val/test=0.837/0.833/0.832 | c=0.998437
[Epoch 0037] loss=18.0702 cls=0.4544 smmd=0.2134 ct=7.5264 rec=1.3125 | train/val/test=0.841/0.839/0.832 | c=0.998437
[Epoch 0038] loss=18.0688 cls=0.4559 smmd=0.2182 ct=7.5014 rec=1.3121 | train/val/test=0.836/0.834/0.834 | c=0.998437
[Epoch 0039] loss=17.9218 cls=0.4545 smmd=0.2018 ct=7.5103 rec=1.3120 | train/val/test=0.840/0.838/0.832 | c=0.998437
[Epoch 0040] loss=17.8286 cls=0.4543 smmd=0.1925 ct=7.5102 rec=1.3123 | train/val/test=0.838/0.836/0.832 | c=0.998437
[Epoch 0041] loss=17.7241 cls=0.4549 smmd=0.1833 ct=7.5046 rec=1.3101 | train/val/test=0.838/0.835/0.833 | c=0.998437
[Epoch 0042] loss=17.6441 cls=0.4529 smmd=0.1729 ct=7.5168 rec=1.3103 | train/val/test=0.836/0.834/0.832 | c=0.998437
[Epoch 0043] loss=17.5013 cls=0.4533 smmd=0.1626 ct=7.4970 rec=1.3096 | train/val/test=0.839/0.836/0.831 | c=0.998437
[Epoch 0044] loss=17.5352 cls=0.4544 smmd=0.1643 ct=7.5048 rec=1.3099 | train/val/test=0.837/0.836/0.830 | c=0.998437
[Epoch 0045] loss=17.3913 cls=0.4548 smmd=0.1491 ct=7.5092 rec=1.3097 | train/val/test=0.833/0.832/0.831 | c=0.998437
[Epoch 0046] loss=17.3850 cls=0.4571 smmd=0.1499 ct=7.5013 rec=1.3105 | train/val/test=0.839/0.835/0.831 | c=0.998437
[Epoch 0047] loss=17.3228 cls=0.4575 smmd=0.1428 ct=7.5050 rec=1.3120 | train/val/test=0.836/0.834/0.830 | c=0.998437
[Epoch 0048] loss=17.2265 cls=0.4595 smmd=0.1339 ct=7.5008 rec=1.3116 | train/val/test=0.839/0.835/0.832 | c=0.998437
[Epoch 0049] loss=17.2742 cls=0.4593 smmd=0.1370 ct=7.5085 rec=1.3140 | train/val/test=0.837/0.835/0.831 | c=0.998437
[Epoch 0050] loss=17.2127 cls=0.4617 smmd=0.1314 ct=7.5055 rec=1.3143 | train/val/test=0.837/0.835/0.833 | c=0.998437
[Epoch 0051] loss=17.2043 cls=0.4627 smmd=0.1319 ct=7.4979 rec=1.3154 | train/val/test=0.840/0.837/0.833 | c=0.998437
[Epoch 0052] loss=17.1640 cls=0.4634 smmd=0.1264 ct=7.5050 rec=1.3169 | train/val/test=0.836/0.835/0.833 | c=0.998437
[Epoch 0053] loss=17.1612 cls=0.4658 smmd=0.1254 ct=7.5078 rec=1.3166 | train/val/test=0.843/0.838/0.834 | c=0.998437
[Epoch 0054] loss=17.1928 cls=0.4664 smmd=0.1305 ct=7.4979 rec=1.3186 | train/val/test=0.831/0.832/0.829 | c=0.998437
[Epoch 0055] loss=17.1269 cls=0.4704 smmd=0.1229 ct=7.5020 rec=1.3181 | train/val/test=0.843/0.838/0.837 | c=0.998437
[Epoch 0056] loss=17.1456 cls=0.4724 smmd=0.1243 ct=7.5029 rec=1.3208 | train/val/test=0.827/0.827/0.827 | c=0.998437
[Epoch 0057] loss=17.1418 cls=0.4747 smmd=0.1247 ct=7.4991 rec=1.3190 | train/val/test=0.844/0.839/0.837 | c=0.998437
[Epoch 0058] loss=17.1160 cls=0.4743 smmd=0.1214 ct=7.5021 rec=1.3208 | train/val/test=0.826/0.826/0.826 | c=0.998437
[Epoch 0059] loss=17.1615 cls=0.4740 smmd=0.1276 ct=7.4945 rec=1.3192 | train/val/test=0.843/0.839/0.839 | c=0.998437
[Epoch 0060] loss=17.1794 cls=0.4778 smmd=0.1272 ct=7.5038 rec=1.3209 | train/val/test=0.823/0.822/0.823 | c=0.998437
[Epoch 0061] loss=17.1516 cls=0.4766 smmd=0.1274 ct=7.4900 rec=1.3194 | train/val/test=0.843/0.839/0.838 | c=0.998437
[Epoch 0062] loss=17.1303 cls=0.4761 smmd=0.1237 ct=7.4977 rec=1.3200 | train/val/test=0.828/0.827/0.827 | c=0.998437
[Epoch 0063] loss=17.1408 cls=0.4718 smmd=0.1260 ct=7.4930 rec=1.3173 | train/val/test=0.842/0.839/0.836 | c=0.998437
[Epoch 0064] loss=17.0938 cls=0.4717 smmd=0.1220 ct=7.4892 rec=1.3191 | train/val/test=0.830/0.830/0.827 | c=0.998437
[Epoch 0065] loss=17.0200 cls=0.4709 smmd=0.1156 ct=7.4849 rec=1.3175 | train/val/test=0.843/0.839/0.837 | c=0.998437
[Epoch 0066] loss=17.0459 cls=0.4690 smmd=0.1161 ct=7.4956 rec=1.3187 | train/val/test=0.834/0.833/0.830 | c=0.998437
[Epoch 0067] loss=17.0645 cls=0.4691 smmd=0.1210 ct=7.4803 rec=1.3182 | train/val/test=0.843/0.839/0.836 | c=0.998437
[Epoch 0068] loss=17.0000 cls=0.4705 smmd=0.1133 ct=7.4859 rec=1.3196 | train/val/test=0.833/0.830/0.830 | c=0.998437
[Epoch 0069] loss=16.9761 cls=0.4723 smmd=0.1096 ct=7.4916 rec=1.3212 | train/val/test=0.845/0.843/0.839 | c=0.998437
[Epoch 0070] loss=16.9913 cls=0.4741 smmd=0.1135 ct=7.4794 rec=1.3213 | train/val/test=0.834/0.832/0.831 | c=0.998437
[Epoch 0071] loss=17.0539 cls=0.4726 smmd=0.1184 ct=7.4860 rec=1.3225 | train/val/test=0.846/0.840/0.839 | c=0.998437
[Epoch 0072] loss=17.0684 cls=0.4741 smmd=0.1205 ct=7.4830 rec=1.3213 | train/val/test=0.832/0.831/0.830 | c=0.998437
[Epoch 0073] loss=17.0505 cls=0.4731 smmd=0.1191 ct=7.4807 rec=1.3231 | train/val/test=0.845/0.841/0.842 | c=0.998437
[Epoch 0074] loss=17.0602 cls=0.4763 smmd=0.1205 ct=7.4781 rec=1.3223 | train/val/test=0.827/0.823/0.827 | c=0.998437
[Epoch 0075] loss=17.0456 cls=0.4763 smmd=0.1196 ct=7.4749 rec=1.3232 | train/val/test=0.842/0.838/0.840 | c=0.998437
[Epoch 0076] loss=17.0243 cls=0.4803 smmd=0.1166 ct=7.4784 rec=1.3232 | train/val/test=0.821/0.817/0.822 | c=0.998437
[Epoch 0077] loss=17.1147 cls=0.4828 smmd=0.1272 ct=7.4692 rec=1.3250 | train/val/test=0.833/0.826/0.828 | c=0.998437
[Epoch 0078] loss=17.1620 cls=0.4959 smmd=0.1288 ct=7.4808 rec=1.3284 | train/val/test=0.807/0.808/0.809 | c=0.998437
[Epoch 0079] loss=17.1799 cls=0.5033 smmd=0.1322 ct=7.4702 rec=1.3309 | train/val/test=0.825/0.820/0.820 | c=0.998437
[Epoch 0080] loss=17.2019 cls=0.5065 smmd=0.1319 ct=7.4819 rec=1.3308 | train/val/test=0.804/0.806/0.808 | c=0.998437
[Epoch 0081] loss=17.1944 cls=0.5048 smmd=0.1349 ct=7.4634 rec=1.3321 | train/val/test=0.834/0.825/0.829 | c=0.998437
[Epoch 0082] loss=17.1546 cls=0.4921 smmd=0.1296 ct=7.4750 rec=1.3261 | train/val/test=0.824/0.822/0.825 | c=0.998437
[Epoch 0083] loss=17.0569 cls=0.4759 smmd=0.1248 ct=7.4545 rec=1.3240 | train/val/test=0.844/0.841/0.839 | c=0.998437
[Epoch 0084] loss=16.9406 cls=0.4654 smmd=0.1135 ct=7.4561 rec=1.3204 | train/val/test=0.841/0.835/0.835 | c=0.998437
[Epoch 0085] loss=16.9007 cls=0.4642 smmd=0.1109 ct=7.4492 rec=1.3219 | train/val/test=0.841/0.836/0.836 | c=0.998437
[Epoch 0086] loss=16.8858 cls=0.4700 smmd=0.1087 ct=7.4507 rec=1.3255 | train/val/test=0.848/0.840/0.841 | c=0.998437
[Epoch 0087] loss=16.8669 cls=0.4790 smmd=0.1057 ct=7.4530 rec=1.3285 | train/val/test=0.827/0.824/0.828 | c=0.998437
[Epoch 0088] loss=16.9471 cls=0.4930 smmd=0.1133 ct=7.4501 rec=1.3357 | train/val/test=0.840/0.834/0.837 | c=0.998437
[Epoch 0089] loss=17.0343 cls=0.5017 smmd=0.1196 ct=7.4598 rec=1.3352 | train/val/test=0.808/0.808/0.811 | c=0.998437
[Epoch 0090] loss=17.1282 cls=0.5139 smmd=0.1292 ct=7.4536 rec=1.3431 | train/val/test=0.815/0.809/0.811 | c=0.998437
[Epoch 0091] loss=17.3010 cls=0.5329 smmd=0.1431 ct=7.4669 rec=1.3404 | train/val/test=0.778/0.780/0.784 | c=0.998437
[Epoch 0092] loss=17.5092 cls=0.5479 smmd=0.1637 ct=7.4611 rec=1.3520 | train/val/test=0.784/0.778/0.779 | c=0.998437
[Epoch 0093] loss=17.4774 cls=0.5647 smmd=0.1565 ct=7.4795 rec=1.3423 | train/val/test=0.806/0.806/0.809 | c=0.998437
[Epoch 0094] loss=17.2114 cls=0.5021 smmd=0.1422 ct=7.4363 rec=1.3322 | train/val/test=0.839/0.836/0.836 | c=0.998437
[Epoch 0095] loss=16.9012 cls=0.4704 smmd=0.1119 ct=7.4435 rec=1.3193 | train/val/test=0.841/0.839/0.834 | c=0.998437
[Epoch 0096] loss=16.8119 cls=0.4629 smmd=0.1060 ct=7.4312 rec=1.3160 | train/val/test=0.824/0.823/0.826 | c=0.998437
[Epoch 0097] loss=16.9074 cls=0.4758 smmd=0.1145 ct=7.4311 rec=1.3244 | train/val/test=0.834/0.828/0.828 | c=0.998437
[Epoch 0098] loss=17.0270 cls=0.5034 smmd=0.1200 ct=7.4551 rec=1.3305 | train/val/test=0.812/0.812/0.815 | c=0.998437
[Epoch 0099] loss=17.0988 cls=0.5128 smmd=0.1286 ct=7.4429 rec=1.3408 | train/val/test=0.836/0.830/0.833 | c=0.998437
=== Best @ epoch 69: val=0.8425, test=0.8392 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-2 - 2025-09-21 03:32:13:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-2...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-2 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.1661 cls=1.0975 smmd=5.6401 ct=7.2546 rec=1.4136 | train/val/test=0.397/0.404/0.401 | c=0.998437
[Epoch 0001] loss=52.5203 cls=1.0659 smmd=3.6897 ct=7.1914 rec=1.4154 | train/val/test=0.403/0.417/0.406 | c=0.998437
[Epoch 0002] loss=38.0188 cls=1.0777 smmd=2.2482 ct=7.1458 rec=1.4136 | train/val/test=0.564/0.560/0.570 | c=0.998437
[Epoch 0003] loss=40.5433 cls=1.0560 smmd=2.5075 ct=7.1166 rec=1.4138 | train/val/test=0.562/0.555/0.571 | c=0.998437
[Epoch 0004] loss=40.0789 cls=1.0227 smmd=2.4724 ct=7.0680 rec=1.4148 | train/val/test=0.555/0.550/0.563 | c=0.998437
[Epoch 0005] loss=35.7113 cls=0.9914 smmd=2.0528 ct=6.9896 rec=1.4169 | train/val/test=0.551/0.546/0.558 | c=0.998437
[Epoch 0006] loss=30.7990 cls=0.9699 smmd=1.5711 ct=6.9479 rec=1.4150 | train/val/test=0.536/0.531/0.545 | c=0.998437
[Epoch 0007] loss=33.3481 cls=0.9339 smmd=1.8304 ct=6.9371 rec=1.4058 | train/val/test=0.520/0.520/0.518 | c=0.998437
[Epoch 0008] loss=34.3788 cls=0.9086 smmd=1.9340 ct=6.9429 rec=1.3980 | train/val/test=0.540/0.534/0.542 | c=0.998437
[Epoch 0009] loss=29.7065 cls=0.8740 smmd=1.3293 ct=7.6413 rec=1.3873 | train/val/test=0.566/0.561/0.573 | c=0.998437
[Epoch 0010] loss=27.8641 cls=0.8379 smmd=1.1695 ct=7.5310 rec=1.3763 | train/val/test=0.581/0.580/0.593 | c=0.998437
[Epoch 0011] loss=30.2122 cls=0.8419 smmd=1.4064 ct=7.5197 rec=1.3762 | train/val/test=0.599/0.593/0.605 | c=0.998437
[Epoch 0012] loss=27.6156 cls=0.7982 smmd=1.1531 ct=7.5001 rec=1.3698 | train/val/test=0.681/0.672/0.677 | c=0.998437
[Epoch 0013] loss=26.5422 cls=0.7567 smmd=1.0419 ct=7.5308 rec=1.3665 | train/val/test=0.724/0.714/0.710 | c=0.998437
[Epoch 0014] loss=25.7968 cls=0.7291 smmd=0.9606 ct=7.5728 rec=1.3606 | train/val/test=0.747/0.746/0.743 | c=0.998437
[Epoch 0015] loss=25.2587 cls=0.7008 smmd=0.9083 ct=7.5737 rec=1.3557 | train/val/test=0.744/0.743/0.742 | c=0.998437
[Epoch 0016] loss=24.8705 cls=0.6741 smmd=0.8813 ct=7.5214 rec=1.3550 | train/val/test=0.760/0.761/0.760 | c=0.998437
[Epoch 0017] loss=23.9017 cls=0.6423 smmd=0.7902 ct=7.5016 rec=1.3506 | train/val/test=0.781/0.778/0.767 | c=0.998437
[Epoch 0018] loss=23.0385 cls=0.6270 smmd=0.6970 ct=7.5417 rec=1.3430 | train/val/test=0.779/0.774/0.771 | c=0.998437
[Epoch 0019] loss=22.8106 cls=0.6265 smmd=0.6724 ct=7.5518 rec=1.3393 | train/val/test=0.790/0.786/0.781 | c=0.998437
[Epoch 0020] loss=22.6754 cls=0.5973 smmd=0.6653 ct=7.5286 rec=1.3339 | train/val/test=0.796/0.796/0.788 | c=0.998437
[Epoch 0021] loss=21.5621 cls=0.5730 smmd=0.5572 ct=7.5189 rec=1.3306 | train/val/test=0.803/0.805/0.796 | c=0.998437
[Epoch 0022] loss=21.5583 cls=0.5570 smmd=0.5574 ct=7.5212 rec=1.3279 | train/val/test=0.808/0.811/0.801 | c=0.998437
[Epoch 0023] loss=21.1703 cls=0.5502 smmd=0.5148 ct=7.5427 rec=1.3247 | train/val/test=0.812/0.812/0.807 | c=0.998437
[Epoch 0024] loss=20.6327 cls=0.5406 smmd=0.4629 ct=7.5361 rec=1.3227 | train/val/test=0.815/0.816/0.809 | c=0.998437
[Epoch 0025] loss=20.3997 cls=0.5258 smmd=0.4434 ct=7.5215 rec=1.3202 | train/val/test=0.815/0.814/0.808 | c=0.998437
[Epoch 0026] loss=20.1218 cls=0.5158 smmd=0.4161 ct=7.5217 rec=1.3185 | train/val/test=0.819/0.818/0.812 | c=0.998437
[Epoch 0027] loss=19.9325 cls=0.5037 smmd=0.3974 ct=7.5239 rec=1.3188 | train/val/test=0.823/0.821/0.814 | c=0.998437
[Epoch 0028] loss=19.5157 cls=0.4966 smmd=0.3546 ct=7.5310 rec=1.3179 | train/val/test=0.825/0.821/0.817 | c=0.998437
[Epoch 0029] loss=19.4124 cls=0.4876 smmd=0.3459 ct=7.5258 rec=1.3153 | train/val/test=0.827/0.823/0.817 | c=0.998437
[Epoch 0030] loss=19.2432 cls=0.4800 smmd=0.3327 ct=7.5095 rec=1.3139 | train/val/test=0.828/0.825/0.819 | c=0.998437
[Epoch 0031] loss=18.9123 cls=0.4737 smmd=0.2988 ct=7.5155 rec=1.3129 | train/val/test=0.831/0.826/0.822 | c=0.998437
[Epoch 0032] loss=18.8200 cls=0.4673 smmd=0.2901 ct=7.5143 rec=1.3137 | train/val/test=0.834/0.830/0.825 | c=0.998437
[Epoch 0033] loss=18.6779 cls=0.4628 smmd=0.2766 ct=7.5121 rec=1.3132 | train/val/test=0.833/0.831/0.828 | c=0.998437
[Epoch 0034] loss=18.3590 cls=0.4597 smmd=0.2436 ct=7.5188 rec=1.3119 | train/val/test=0.837/0.832/0.831 | c=0.998437
[Epoch 0035] loss=18.4192 cls=0.4572 smmd=0.2536 ct=7.4992 rec=1.3122 | train/val/test=0.837/0.834/0.831 | c=0.998437
[Epoch 0036] loss=18.2309 cls=0.4562 smmd=0.2337 ct=7.5049 rec=1.3119 | train/val/test=0.837/0.833/0.832 | c=0.998437
[Epoch 0037] loss=18.0702 cls=0.4544 smmd=0.2134 ct=7.5264 rec=1.3125 | train/val/test=0.841/0.839/0.832 | c=0.998437
[Epoch 0038] loss=18.0688 cls=0.4559 smmd=0.2182 ct=7.5014 rec=1.3121 | train/val/test=0.836/0.834/0.834 | c=0.998437
[Epoch 0039] loss=17.9218 cls=0.4545 smmd=0.2018 ct=7.5103 rec=1.3120 | train/val/test=0.840/0.838/0.832 | c=0.998437
[Epoch 0040] loss=17.8286 cls=0.4543 smmd=0.1925 ct=7.5102 rec=1.3123 | train/val/test=0.838/0.836/0.832 | c=0.998437
[Epoch 0041] loss=17.7241 cls=0.4549 smmd=0.1833 ct=7.5046 rec=1.3101 | train/val/test=0.838/0.835/0.833 | c=0.998437
[Epoch 0042] loss=17.6441 cls=0.4529 smmd=0.1729 ct=7.5168 rec=1.3103 | train/val/test=0.836/0.834/0.832 | c=0.998437
[Epoch 0043] loss=17.5013 cls=0.4533 smmd=0.1626 ct=7.4970 rec=1.3096 | train/val/test=0.839/0.836/0.831 | c=0.998437
[Epoch 0044] loss=17.5352 cls=0.4544 smmd=0.1643 ct=7.5048 rec=1.3099 | train/val/test=0.837/0.836/0.830 | c=0.998437
[Epoch 0045] loss=17.3913 cls=0.4548 smmd=0.1491 ct=7.5092 rec=1.3097 | train/val/test=0.833/0.832/0.831 | c=0.998437
[Epoch 0046] loss=17.3850 cls=0.4571 smmd=0.1499 ct=7.5013 rec=1.3105 | train/val/test=0.839/0.835/0.831 | c=0.998437
[Epoch 0047] loss=17.3228 cls=0.4575 smmd=0.1428 ct=7.5050 rec=1.3120 | train/val/test=0.836/0.834/0.830 | c=0.998437
[Epoch 0048] loss=17.2265 cls=0.4595 smmd=0.1339 ct=7.5008 rec=1.3116 | train/val/test=0.839/0.835/0.832 | c=0.998437
[Epoch 0049] loss=17.2742 cls=0.4593 smmd=0.1370 ct=7.5085 rec=1.3140 | train/val/test=0.837/0.835/0.831 | c=0.998437
[Epoch 0050] loss=17.2127 cls=0.4617 smmd=0.1314 ct=7.5055 rec=1.3143 | train/val/test=0.837/0.835/0.833 | c=0.998437
[Epoch 0051] loss=17.2043 cls=0.4627 smmd=0.1319 ct=7.4979 rec=1.3154 | train/val/test=0.840/0.837/0.833 | c=0.998437
[Epoch 0052] loss=17.1640 cls=0.4634 smmd=0.1264 ct=7.5050 rec=1.3169 | train/val/test=0.836/0.835/0.833 | c=0.998437
[Epoch 0053] loss=17.1612 cls=0.4658 smmd=0.1254 ct=7.5078 rec=1.3166 | train/val/test=0.843/0.838/0.834 | c=0.998437
[Epoch 0054] loss=17.1928 cls=0.4664 smmd=0.1305 ct=7.4979 rec=1.3186 | train/val/test=0.831/0.832/0.829 | c=0.998437
[Epoch 0055] loss=17.1269 cls=0.4704 smmd=0.1229 ct=7.5020 rec=1.3181 | train/val/test=0.843/0.838/0.837 | c=0.998437
[Epoch 0056] loss=17.1456 cls=0.4724 smmd=0.1243 ct=7.5029 rec=1.3208 | train/val/test=0.827/0.827/0.827 | c=0.998437
[Epoch 0057] loss=17.1418 cls=0.4747 smmd=0.1247 ct=7.4991 rec=1.3190 | train/val/test=0.844/0.839/0.837 | c=0.998437
[Epoch 0058] loss=17.1160 cls=0.4743 smmd=0.1214 ct=7.5021 rec=1.3208 | train/val/test=0.826/0.826/0.826 | c=0.998437
[Epoch 0059] loss=17.1615 cls=0.4740 smmd=0.1276 ct=7.4945 rec=1.3192 | train/val/test=0.843/0.839/0.839 | c=0.998437
[Epoch 0060] loss=17.1794 cls=0.4778 smmd=0.1272 ct=7.5038 rec=1.3209 | train/val/test=0.823/0.822/0.823 | c=0.998437
[Epoch 0061] loss=17.1516 cls=0.4766 smmd=0.1274 ct=7.4900 rec=1.3194 | train/val/test=0.843/0.839/0.838 | c=0.998437
[Epoch 0062] loss=17.1303 cls=0.4761 smmd=0.1237 ct=7.4977 rec=1.3200 | train/val/test=0.828/0.827/0.827 | c=0.998437
[Epoch 0063] loss=17.1408 cls=0.4718 smmd=0.1260 ct=7.4930 rec=1.3173 | train/val/test=0.842/0.839/0.836 | c=0.998437
[Epoch 0064] loss=17.0938 cls=0.4717 smmd=0.1220 ct=7.4892 rec=1.3191 | train/val/test=0.830/0.830/0.827 | c=0.998437
[Epoch 0065] loss=17.0200 cls=0.4709 smmd=0.1156 ct=7.4849 rec=1.3175 | train/val/test=0.843/0.839/0.837 | c=0.998437
[Epoch 0066] loss=17.0459 cls=0.4690 smmd=0.1161 ct=7.4956 rec=1.3187 | train/val/test=0.834/0.833/0.830 | c=0.998437
[Epoch 0067] loss=17.0645 cls=0.4691 smmd=0.1210 ct=7.4803 rec=1.3182 | train/val/test=0.843/0.839/0.836 | c=0.998437
[Epoch 0068] loss=17.0000 cls=0.4705 smmd=0.1133 ct=7.4859 rec=1.3196 | train/val/test=0.833/0.830/0.830 | c=0.998437
[Epoch 0069] loss=16.9761 cls=0.4723 smmd=0.1096 ct=7.4916 rec=1.3212 | train/val/test=0.845/0.843/0.839 | c=0.998437
[Epoch 0070] loss=16.9913 cls=0.4741 smmd=0.1135 ct=7.4794 rec=1.3213 | train/val/test=0.834/0.832/0.831 | c=0.998437
[Epoch 0071] loss=17.0539 cls=0.4726 smmd=0.1184 ct=7.4860 rec=1.3225 | train/val/test=0.846/0.840/0.839 | c=0.998437
[Epoch 0072] loss=17.0684 cls=0.4741 smmd=0.1205 ct=7.4830 rec=1.3213 | train/val/test=0.832/0.831/0.830 | c=0.998437
[Epoch 0073] loss=17.0505 cls=0.4731 smmd=0.1191 ct=7.4807 rec=1.3231 | train/val/test=0.845/0.841/0.842 | c=0.998437
[Epoch 0074] loss=17.0602 cls=0.4763 smmd=0.1205 ct=7.4781 rec=1.3223 | train/val/test=0.827/0.823/0.827 | c=0.998437
[Epoch 0075] loss=17.0456 cls=0.4763 smmd=0.1196 ct=7.4749 rec=1.3232 | train/val/test=0.842/0.838/0.840 | c=0.998437
[Epoch 0076] loss=17.0243 cls=0.4803 smmd=0.1166 ct=7.4784 rec=1.3232 | train/val/test=0.821/0.817/0.822 | c=0.998437
[Epoch 0077] loss=17.1147 cls=0.4828 smmd=0.1272 ct=7.4692 rec=1.3250 | train/val/test=0.833/0.826/0.828 | c=0.998437
[Epoch 0078] loss=17.1620 cls=0.4959 smmd=0.1288 ct=7.4808 rec=1.3284 | train/val/test=0.807/0.808/0.809 | c=0.998437
[Epoch 0079] loss=17.1799 cls=0.5033 smmd=0.1322 ct=7.4702 rec=1.3309 | train/val/test=0.825/0.820/0.820 | c=0.998437
[Epoch 0080] loss=17.2019 cls=0.5065 smmd=0.1319 ct=7.4819 rec=1.3308 | train/val/test=0.804/0.806/0.808 | c=0.998437
[Epoch 0081] loss=17.1944 cls=0.5048 smmd=0.1349 ct=7.4634 rec=1.3321 | train/val/test=0.834/0.825/0.829 | c=0.998437
[Epoch 0082] loss=17.1546 cls=0.4921 smmd=0.1296 ct=7.4750 rec=1.3261 | train/val/test=0.824/0.822/0.825 | c=0.998437
[Epoch 0083] loss=17.0569 cls=0.4759 smmd=0.1248 ct=7.4545 rec=1.3240 | train/val/test=0.844/0.841/0.839 | c=0.998437
[Epoch 0084] loss=16.9406 cls=0.4654 smmd=0.1135 ct=7.4561 rec=1.3204 | train/val/test=0.841/0.835/0.835 | c=0.998437
[Epoch 0085] loss=16.9007 cls=0.4642 smmd=0.1109 ct=7.4492 rec=1.3219 | train/val/test=0.841/0.836/0.836 | c=0.998437
[Epoch 0086] loss=16.8858 cls=0.4700 smmd=0.1087 ct=7.4507 rec=1.3255 | train/val/test=0.848/0.840/0.841 | c=0.998437
[Epoch 0087] loss=16.8669 cls=0.4790 smmd=0.1057 ct=7.4530 rec=1.3285 | train/val/test=0.827/0.824/0.828 | c=0.998437
[Epoch 0088] loss=16.9471 cls=0.4930 smmd=0.1133 ct=7.4501 rec=1.3357 | train/val/test=0.840/0.834/0.837 | c=0.998437
[Epoch 0089] loss=17.0343 cls=0.5017 smmd=0.1196 ct=7.4598 rec=1.3352 | train/val/test=0.808/0.808/0.811 | c=0.998437
[Epoch 0090] loss=17.1282 cls=0.5139 smmd=0.1292 ct=7.4536 rec=1.3431 | train/val/test=0.815/0.809/0.811 | c=0.998437
[Epoch 0091] loss=17.3010 cls=0.5329 smmd=0.1431 ct=7.4669 rec=1.3404 | train/val/test=0.778/0.780/0.784 | c=0.998437
[Epoch 0092] loss=17.5092 cls=0.5479 smmd=0.1637 ct=7.4611 rec=1.3520 | train/val/test=0.784/0.778/0.779 | c=0.998437
[Epoch 0093] loss=17.4774 cls=0.5647 smmd=0.1565 ct=7.4795 rec=1.3423 | train/val/test=0.806/0.806/0.809 | c=0.998437
[Epoch 0094] loss=17.2114 cls=0.5021 smmd=0.1422 ct=7.4363 rec=1.3322 | train/val/test=0.839/0.836/0.836 | c=0.998437
[Epoch 0095] loss=16.9012 cls=0.4704 smmd=0.1119 ct=7.4435 rec=1.3193 | train/val/test=0.841/0.839/0.834 | c=0.998437
[Epoch 0096] loss=16.8119 cls=0.4629 smmd=0.1060 ct=7.4312 rec=1.3160 | train/val/test=0.824/0.823/0.826 | c=0.998437
[Epoch 0097] loss=16.9074 cls=0.4758 smmd=0.1145 ct=7.4311 rec=1.3244 | train/val/test=0.834/0.828/0.828 | c=0.998437
[Epoch 0098] loss=17.0270 cls=0.5034 smmd=0.1200 ct=7.4551 rec=1.3305 | train/val/test=0.812/0.812/0.815 | c=0.998437
[Epoch 0099] loss=17.0988 cls=0.5128 smmd=0.1286 ct=7.4429 rec=1.3408 | train/val/test=0.836/0.830/0.833 | c=0.998437
=== Best @ epoch 69: val=0.8425, test=0.8392 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-10-2 completed in 139.72 seconds.
==================================================
