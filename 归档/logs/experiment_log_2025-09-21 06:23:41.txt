Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-2 - 2025-09-21 06:23:41:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-2...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-2 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.8362 cls=1.7915 smmd=4.0721 ct=9.4758 rec=1.3917 | train/val/test=0.180/0.058/0.077 | c=0.998347
[Epoch 0001] loss=37.6901 cls=1.7840 smmd=3.9258 ct=9.4777 rec=1.3917 | train/val/test=0.200/0.062/0.076 | c=0.998347
[Epoch 0002] loss=36.4901 cls=1.7744 smmd=2.9413 ct=9.3725 rec=1.3917 | train/val/test=0.500/0.280/0.261 | c=0.998347
[Epoch 0003] loss=36.1121 cls=1.7562 smmd=2.5366 ct=9.3905 rec=1.3916 | train/val/test=0.520/0.328/0.307 | c=0.998347
[Epoch 0004] loss=35.2542 cls=1.7188 smmd=2.2387 ct=9.1204 rec=1.3915 | train/val/test=0.460/0.322/0.312 | c=0.998347
[Epoch 0005] loss=34.9633 cls=1.6744 smmd=1.9108 ct=9.1514 rec=1.3912 | train/val/test=0.540/0.408/0.389 | c=0.998347
[Epoch 0006] loss=34.5440 cls=1.6178 smmd=1.7545 ct=9.0385 rec=1.3904 | train/val/test=0.620/0.452/0.417 | c=0.998347
[Epoch 0007] loss=34.4110 cls=1.5611 smmd=1.6739 ct=9.0322 rec=1.3892 | train/val/test=0.620/0.454/0.433 | c=0.998347
[Epoch 0008] loss=34.1281 cls=1.5044 smmd=1.4659 ct=9.0158 rec=1.3878 | train/val/test=0.680/0.474/0.481 | c=0.998347
[Epoch 0009] loss=33.9679 cls=1.4509 smmd=1.3981 ct=8.9904 rec=1.3863 | train/val/test=0.660/0.520/0.513 | c=0.998347
[Epoch 0010] loss=33.9005 cls=1.3999 smmd=1.3850 ct=8.9844 rec=1.3847 | train/val/test=0.740/0.540/0.533 | c=0.998347
[Epoch 0011] loss=33.7059 cls=1.3520 smmd=1.2265 ct=8.9853 rec=1.3833 | train/val/test=0.760/0.560/0.553 | c=0.998347
[Epoch 0012] loss=33.5765 cls=1.3047 smmd=1.1270 ct=8.9868 rec=1.3824 | train/val/test=0.820/0.564/0.555 | c=0.998347
[Epoch 0013] loss=33.5013 cls=1.2593 smmd=1.0653 ct=8.9949 rec=1.3817 | train/val/test=0.880/0.582/0.576 | c=0.998347
[Epoch 0014] loss=33.3261 cls=1.2121 smmd=0.9243 ct=8.9974 rec=1.3801 | train/val/test=0.820/0.578/0.560 | c=0.998347
[Epoch 0015] loss=33.2294 cls=1.1658 smmd=0.8637 ct=8.9994 rec=1.3784 | train/val/test=0.860/0.552/0.556 | c=0.998347
[Epoch 0016] loss=33.1422 cls=1.1092 smmd=0.8266 ct=8.9966 rec=1.3768 | train/val/test=0.920/0.578/0.573 | c=0.998347
[Epoch 0017] loss=32.9677 cls=1.0537 smmd=0.7064 ct=8.9955 rec=1.3743 | train/val/test=0.920/0.608/0.588 | c=0.998347
[Epoch 0018] loss=32.9015 cls=1.0024 smmd=0.6972 ct=8.9985 rec=1.3706 | train/val/test=0.920/0.602/0.587 | c=0.998347
[Epoch 0019] loss=32.7636 cls=0.9432 smmd=0.6311 ct=8.9981 rec=1.3665 | train/val/test=0.920/0.602/0.581 | c=0.998347
[Epoch 0020] loss=32.6370 cls=0.8847 smmd=0.5880 ct=8.9957 rec=1.3615 | train/val/test=0.900/0.614/0.591 | c=0.998347
[Epoch 0021] loss=32.5401 cls=0.8359 smmd=0.5838 ct=8.9918 rec=1.3555 | train/val/test=0.900/0.618/0.609 | c=0.998347
[Epoch 0022] loss=32.4013 cls=0.7850 smmd=0.5424 ct=8.9885 rec=1.3489 | train/val/test=0.920/0.618/0.605 | c=0.998347
[Epoch 0023] loss=32.2764 cls=0.7351 smmd=0.5115 ct=8.9883 rec=1.3421 | train/val/test=0.940/0.628/0.630 | c=0.998347
[Epoch 0024] loss=32.1844 cls=0.6977 smmd=0.5141 ct=8.9869 rec=1.3348 | train/val/test=0.940/0.630/0.624 | c=0.998347
[Epoch 0025] loss=32.0447 cls=0.6623 smmd=0.4649 ct=8.9870 rec=1.3275 | train/val/test=0.960/0.640/0.622 | c=0.998347
[Epoch 0026] loss=31.9332 cls=0.6244 smmd=0.4401 ct=8.9882 rec=1.3205 | train/val/test=0.920/0.644/0.637 | c=0.998347
[Epoch 0027] loss=31.8456 cls=0.5943 smmd=0.4376 ct=8.9868 rec=1.3137 | train/val/test=0.920/0.636/0.646 | c=0.998347
[Epoch 0028] loss=31.7348 cls=0.5650 smmd=0.4153 ct=8.9844 rec=1.3068 | train/val/test=0.900/0.638/0.645 | c=0.998347
[Epoch 0029] loss=31.6363 cls=0.5351 smmd=0.3979 ct=8.9859 rec=1.2999 | train/val/test=0.900/0.648/0.651 | c=0.998347
[Epoch 0030] loss=31.5586 cls=0.5131 smmd=0.3960 ct=8.9859 rec=1.2934 | train/val/test=0.900/0.656/0.660 | c=0.998347
[Epoch 0031] loss=31.4474 cls=0.4858 smmd=0.3657 ct=8.9850 rec=1.2869 | train/val/test=0.900/0.658/0.668 | c=0.998347
[Epoch 0032] loss=31.3735 cls=0.4630 smmd=0.3730 ct=8.9829 rec=1.2803 | train/val/test=0.900/0.662/0.681 | c=0.998347
[Epoch 0033] loss=31.2806 cls=0.4458 smmd=0.3548 ct=8.9814 rec=1.2740 | train/val/test=0.920/0.668/0.687 | c=0.998347
[Epoch 0034] loss=31.1954 cls=0.4206 smmd=0.3457 ct=8.9822 rec=1.2675 | train/val/test=0.920/0.674/0.703 | c=0.998347
[Epoch 0035] loss=31.1242 cls=0.4080 smmd=0.3489 ct=8.9808 rec=1.2610 | train/val/test=0.920/0.676/0.710 | c=0.998347
[Epoch 0036] loss=31.0203 cls=0.3886 smmd=0.3184 ct=8.9805 rec=1.2547 | train/val/test=0.920/0.684/0.708 | c=0.998347
[Epoch 0037] loss=30.9543 cls=0.3774 smmd=0.3257 ct=8.9792 rec=1.2482 | train/val/test=0.920/0.682/0.711 | c=0.998347
[Epoch 0038] loss=30.8888 cls=0.3590 smmd=0.3289 ct=8.9796 rec=1.2421 | train/val/test=0.920/0.688/0.714 | c=0.998347
[Epoch 0039] loss=30.8184 cls=0.3489 smmd=0.3210 ct=8.9796 rec=1.2364 | train/val/test=0.940/0.694/0.712 | c=0.998347
[Epoch 0040] loss=30.7477 cls=0.3393 smmd=0.3071 ct=8.9799 rec=1.2311 | train/val/test=0.940/0.700/0.716 | c=0.998347
[Epoch 0041] loss=30.6825 cls=0.3285 smmd=0.2933 ct=8.9801 rec=1.2265 | train/val/test=0.940/0.698/0.717 | c=0.998347
[Epoch 0042] loss=30.6483 cls=0.3194 smmd=0.3063 ct=8.9802 rec=1.2222 | train/val/test=0.940/0.698/0.716 | c=0.998347
[Epoch 0043] loss=30.5901 cls=0.3078 smmd=0.2878 ct=8.9808 rec=1.2187 | train/val/test=0.940/0.708/0.718 | c=0.998347
[Epoch 0044] loss=30.5553 cls=0.3048 smmd=0.2870 ct=8.9815 rec=1.2153 | train/val/test=0.940/0.696/0.716 | c=0.998347
[Epoch 0045] loss=30.5175 cls=0.2890 smmd=0.2792 ct=8.9823 rec=1.2129 | train/val/test=0.960/0.712/0.723 | c=0.998347
[Epoch 0046] loss=30.4976 cls=0.2943 smmd=0.2849 ct=8.9819 rec=1.2102 | train/val/test=0.960/0.706/0.722 | c=0.998347
[Epoch 0047] loss=30.5058 cls=0.2665 smmd=0.2980 ct=8.9873 rec=1.2100 | train/val/test=0.960/0.718/0.726 | c=0.998347
[Epoch 0048] loss=30.5509 cls=0.3041 smmd=0.3265 ct=8.9913 rec=1.2090 | train/val/test=0.980/0.690/0.719 | c=0.998347
[Epoch 0049] loss=30.7191 cls=0.2490 smmd=0.4072 ct=9.0114 rec=1.2165 | train/val/test=0.960/0.724/0.731 | c=0.998347
[Epoch 0050] loss=30.6721 cls=0.3224 smmd=0.4203 ct=9.0042 rec=1.2082 | train/val/test=0.960/0.704/0.723 | c=0.998347
[Epoch 0051] loss=30.4287 cls=0.2258 smmd=0.3611 ct=8.9942 rec=1.1966 | train/val/test=0.940/0.706/0.722 | c=0.998347
[Epoch 0052] loss=30.3110 cls=0.2320 smmd=0.3234 ct=8.9857 rec=1.1900 | train/val/test=0.960/0.722/0.731 | c=0.998347
[Epoch 0053] loss=30.4492 cls=0.2861 smmd=0.3887 ct=8.9928 rec=1.1932 | train/val/test=0.980/0.718/0.727 | c=0.998347
[Epoch 0054] loss=30.3239 cls=0.2057 smmd=0.3435 ct=8.9897 rec=1.1898 | train/val/test=0.960/0.712/0.727 | c=0.998347
[Epoch 0055] loss=30.2825 cls=0.2135 smmd=0.3147 ct=8.9864 rec=1.1888 | train/val/test=0.960/0.720/0.732 | c=0.998347
[Epoch 0056] loss=30.4497 cls=0.2682 smmd=0.3723 ct=8.9969 rec=1.1949 | train/val/test=0.980/0.696/0.720 | c=0.998347
[Epoch 0057] loss=30.4344 cls=0.1976 smmd=0.3358 ct=9.0022 rec=1.1995 | train/val/test=0.960/0.722/0.743 | c=0.998347
[Epoch 0058] loss=30.2459 cls=0.2226 smmd=0.2805 ct=8.9850 rec=1.1884 | train/val/test=0.980/0.712/0.733 | c=0.998347
[Epoch 0059] loss=30.2754 cls=0.2356 smmd=0.2998 ct=8.9877 rec=1.1882 | train/val/test=0.980/0.704/0.725 | c=0.998347
[Epoch 0060] loss=30.3546 cls=0.1888 smmd=0.3238 ct=9.0021 rec=1.1932 | train/val/test=0.960/0.714/0.736 | c=0.998347
[Epoch 0061] loss=30.2324 cls=0.2273 smmd=0.3049 ct=8.9862 rec=1.1841 | train/val/test=0.980/0.716/0.732 | c=0.998347
[Epoch 0062] loss=30.1515 cls=0.2116 smmd=0.2706 ct=8.9832 rec=1.1809 | train/val/test=0.980/0.710/0.737 | c=0.998347
[Epoch 0063] loss=30.2230 cls=0.1856 smmd=0.3031 ct=8.9940 rec=1.1839 | train/val/test=0.980/0.718/0.735 | c=0.998347
[Epoch 0064] loss=30.1919 cls=0.2151 smmd=0.2964 ct=8.9869 rec=1.1814 | train/val/test=0.980/0.716/0.739 | c=0.998347
[Epoch 0065] loss=30.1382 cls=0.1889 smmd=0.2678 ct=8.9849 rec=1.1806 | train/val/test=0.980/0.706/0.741 | c=0.998347
[Epoch 0066] loss=30.1406 cls=0.1803 smmd=0.2445 ct=8.9893 rec=1.1827 | train/val/test=0.980/0.716/0.736 | c=0.998347
[Epoch 0067] loss=30.1941 cls=0.2044 smmd=0.2718 ct=8.9908 rec=1.1839 | train/val/test=0.980/0.702/0.742 | c=0.998347
[Epoch 0068] loss=30.2177 cls=0.1791 smmd=0.2732 ct=8.9975 rec=1.1860 | train/val/test=0.980/0.712/0.743 | c=0.998347
[Epoch 0069] loss=30.1423 cls=0.1936 smmd=0.2519 ct=8.9891 rec=1.1815 | train/val/test=0.980/0.704/0.738 | c=0.998347
[Epoch 0070] loss=30.0835 cls=0.1859 smmd=0.2386 ct=8.9876 rec=1.1777 | train/val/test=0.980/0.698/0.740 | c=0.998347
[Epoch 0071] loss=30.0641 cls=0.1728 smmd=0.2300 ct=8.9876 rec=1.1772 | train/val/test=0.980/0.714/0.737 | c=0.998347
[Epoch 0072] loss=30.1042 cls=0.1990 smmd=0.2663 ct=8.9877 rec=1.1763 | train/val/test=0.980/0.696/0.742 | c=0.998347
[Epoch 0073] loss=30.0795 cls=0.1659 smmd=0.2392 ct=8.9914 rec=1.1774 | train/val/test=0.980/0.712/0.743 | c=0.998347
[Epoch 0074] loss=30.0581 cls=0.1856 smmd=0.2429 ct=8.9866 rec=1.1749 | train/val/test=0.980/0.702/0.745 | c=0.998347
[Epoch 0075] loss=30.0511 cls=0.1671 smmd=0.2283 ct=8.9880 rec=1.1763 | train/val/test=0.980/0.708/0.742 | c=0.998347
[Epoch 0076] loss=30.1063 cls=0.1766 smmd=0.2485 ct=8.9948 rec=1.1780 | train/val/test=0.980/0.706/0.741 | c=0.998347
[Epoch 0077] loss=30.1317 cls=0.1735 smmd=0.2584 ct=8.9945 rec=1.1797 | train/val/test=0.960/0.708/0.741 | c=0.998347
[Epoch 0078] loss=30.2014 cls=0.1860 smmd=0.2939 ct=9.0070 rec=1.1800 | train/val/test=0.980/0.704/0.736 | c=0.998347
[Epoch 0079] loss=30.1755 cls=0.1673 smmd=0.2928 ct=9.0007 rec=1.1798 | train/val/test=0.960/0.706/0.742 | c=0.998347
[Epoch 0080] loss=30.1757 cls=0.1984 smmd=0.3188 ct=9.0010 rec=1.1756 | train/val/test=0.980/0.692/0.733 | c=0.998347
[Epoch 0081] loss=30.1510 cls=0.1447 smmd=0.3323 ct=9.0008 rec=1.1745 | train/val/test=0.980/0.706/0.744 | c=0.998347
[Epoch 0082] loss=30.0072 cls=0.1755 smmd=0.2845 ct=8.9854 rec=1.1664 | train/val/test=0.980/0.704/0.739 | c=0.998347
[Epoch 0083] loss=30.0318 cls=0.1659 smmd=0.2877 ct=8.9903 rec=1.1680 | train/val/test=0.980/0.690/0.731 | c=0.998347
[Epoch 0084] loss=30.1087 cls=0.1435 smmd=0.2981 ct=8.9992 rec=1.1740 | train/val/test=0.980/0.706/0.738 | c=0.998347
[Epoch 0085] loss=30.0826 cls=0.1829 smmd=0.2834 ct=8.9920 rec=1.1724 | train/val/test=0.980/0.696/0.737 | c=0.998347
[Epoch 0086] loss=30.0571 cls=0.1414 smmd=0.2427 ct=8.9939 rec=1.1756 | train/val/test=0.980/0.704/0.735 | c=0.998347
[Epoch 0087] loss=30.0641 cls=0.1810 smmd=0.2493 ct=8.9919 rec=1.1740 | train/val/test=0.980/0.700/0.737 | c=0.998347
[Epoch 0088] loss=30.0949 cls=0.1677 smmd=0.2439 ct=8.9965 rec=1.1774 | train/val/test=0.980/0.694/0.728 | c=0.998347
[Epoch 0089] loss=30.2181 cls=0.1633 smmd=0.2995 ct=9.0087 rec=1.1820 | train/val/test=0.960/0.716/0.738 | c=0.998347
[Epoch 0090] loss=30.3336 cls=0.2319 smmd=0.3730 ct=9.0181 rec=1.1809 | train/val/test=0.960/0.688/0.727 | c=0.998347
[Epoch 0091] loss=30.3523 cls=0.1422 smmd=0.4250 ct=9.0236 rec=1.1809 | train/val/test=0.960/0.700/0.736 | c=0.998347
[Epoch 0092] loss=30.0370 cls=0.1850 smmd=0.3489 ct=8.9888 rec=1.1618 | train/val/test=0.980/0.714/0.731 | c=0.998347
[Epoch 0093] loss=30.1492 cls=0.1942 smmd=0.3912 ct=9.0006 rec=1.1660 | train/val/test=0.960/0.694/0.735 | c=0.998347
[Epoch 0094] loss=30.1390 cls=0.1302 smmd=0.4140 ct=9.0007 rec=1.1658 | train/val/test=0.980/0.690/0.729 | c=0.998347
[Epoch 0095] loss=30.1140 cls=0.1632 smmd=0.3758 ct=8.9981 rec=1.1660 | train/val/test=0.980/0.710/0.735 | c=0.998347
[Epoch 0096] loss=30.1044 cls=0.1777 smmd=0.3282 ct=8.9967 rec=1.1694 | train/val/test=0.960/0.688/0.732 | c=0.998347
[Epoch 0097] loss=30.2094 cls=0.1419 smmd=0.3395 ct=9.0057 rec=1.1788 | train/val/test=0.960/0.692/0.729 | c=0.998347
[Epoch 0098] loss=30.2198 cls=0.2008 smmd=0.3647 ct=9.0014 rec=1.1752 | train/val/test=0.980/0.708/0.731 | c=0.998347
[Epoch 0099] loss=30.1278 cls=0.1769 smmd=0.3030 ct=9.0007 rec=1.1735 | train/val/test=0.960/0.684/0.723 | c=0.998347
[Epoch 0100] loss=30.3271 cls=0.1432 smmd=0.3828 ct=9.0142 rec=1.1844 | train/val/test=0.960/0.702/0.726 | c=0.998347
[Epoch 0101] loss=30.1500 cls=0.2200 smmd=0.3657 ct=8.9975 rec=1.1679 | train/val/test=0.980/0.710/0.732 | c=0.998347
[Epoch 0102] loss=29.9823 cls=0.1749 smmd=0.2993 ct=8.9872 rec=1.1621 | train/val/test=0.960/0.690/0.735 | c=0.998347
[Epoch 0103] loss=30.1281 cls=0.1346 smmd=0.3818 ct=9.0000 rec=1.1679 | train/val/test=0.980/0.702/0.726 | c=0.998347
[Epoch 0104] loss=29.9643 cls=0.1662 smmd=0.3011 ct=8.9838 rec=1.1612 | train/val/test=0.980/0.712/0.733 | c=0.998347
[Epoch 0105] loss=30.0458 cls=0.1868 smmd=0.3096 ct=8.9929 rec=1.1657 | train/val/test=0.960/0.692/0.732 | c=0.998347
[Epoch 0106] loss=30.1136 cls=0.1346 smmd=0.3149 ct=9.0000 rec=1.1731 | train/val/test=0.980/0.700/0.732 | c=0.998347
[Epoch 0107] loss=29.9856 cls=0.1609 smmd=0.2444 ct=8.9864 rec=1.1688 | train/val/test=0.980/0.702/0.729 | c=0.998347
[Epoch 0108] loss=30.0776 cls=0.1731 smmd=0.2730 ct=8.9986 rec=1.1721 | train/val/test=0.960/0.692/0.731 | c=0.998347
[Epoch 0109] loss=30.1208 cls=0.1383 smmd=0.2837 ct=8.9981 rec=1.1772 | train/val/test=0.960/0.700/0.732 | c=0.998347
[Epoch 0110] loss=29.9898 cls=0.1759 smmd=0.2462 ct=8.9881 rec=1.1679 | train/val/test=0.980/0.696/0.732 | c=0.998347
[Epoch 0111] loss=29.9637 cls=0.1537 smmd=0.2379 ct=8.9904 rec=1.1668 | train/val/test=0.960/0.698/0.732 | c=0.998347
[Epoch 0112] loss=30.0235 cls=0.1516 smmd=0.2862 ct=8.9917 rec=1.1678 | train/val/test=0.980/0.698/0.731 | c=0.998347
[Epoch 0113] loss=29.9357 cls=0.1662 smmd=0.2393 ct=8.9862 rec=1.1641 | train/val/test=0.980/0.698/0.731 | c=0.998347
[Epoch 0114] loss=29.9343 cls=0.1514 smmd=0.2254 ct=8.9898 rec=1.1654 | train/val/test=0.960/0.698/0.733 | c=0.998347
[Epoch 0115] loss=30.0137 cls=0.1505 smmd=0.2644 ct=8.9913 rec=1.1692 | train/val/test=0.980/0.700/0.731 | c=0.998347
[Epoch 0116] loss=29.9577 cls=0.1552 smmd=0.2263 ct=8.9900 rec=1.1674 | train/val/test=0.980/0.696/0.730 | c=0.998347
[Epoch 0117] loss=29.9343 cls=0.1444 smmd=0.2012 ct=8.9886 rec=1.1684 | train/val/test=0.960/0.696/0.729 | c=0.998347
[Epoch 0118] loss=30.0090 cls=0.1491 smmd=0.2318 ct=8.9909 rec=1.1721 | train/val/test=0.980/0.706/0.733 | c=0.998347
[Epoch 0119] loss=30.0181 cls=0.1625 smmd=0.2303 ct=8.9984 rec=1.1710 | train/val/test=0.960/0.698/0.729 | c=0.998347
[Epoch 0120] loss=29.9406 cls=0.1519 smmd=0.2108 ct=8.9876 rec=1.1679 | train/val/test=0.980/0.696/0.730 | c=0.998347
[Epoch 0121] loss=29.9224 cls=0.1438 smmd=0.2124 ct=8.9895 rec=1.1659 | train/val/test=0.980/0.696/0.729 | c=0.998347
[Epoch 0122] loss=29.9659 cls=0.1587 smmd=0.2420 ct=8.9917 rec=1.1661 | train/val/test=0.960/0.696/0.730 | c=0.998347
[Epoch 0123] loss=29.9302 cls=0.1563 smmd=0.2253 ct=8.9882 rec=1.1650 | train/val/test=0.980/0.694/0.729 | c=0.998347
[Epoch 0124] loss=29.9321 cls=0.1330 smmd=0.2236 ct=8.9901 rec=1.1662 | train/val/test=0.980/0.702/0.732 | c=0.998347
[Epoch 0125] loss=29.9739 cls=0.1728 smmd=0.2403 ct=8.9927 rec=1.1662 | train/val/test=0.960/0.694/0.729 | c=0.998347
[Epoch 0126] loss=29.9778 cls=0.1329 smmd=0.2266 ct=8.9928 rec=1.1699 | train/val/test=0.980/0.698/0.732 | c=0.998347
[Epoch 0127] loss=29.9485 cls=0.1602 smmd=0.2086 ct=8.9924 rec=1.1675 | train/val/test=0.980/0.692/0.731 | c=0.998347
[Epoch 0128] loss=30.0074 cls=0.1437 smmd=0.2317 ct=8.9969 rec=1.1710 | train/val/test=0.960/0.706/0.727 | c=0.998347
[Epoch 0129] loss=30.1351 cls=0.1748 smmd=0.2873 ct=9.0077 rec=1.1745 | train/val/test=0.980/0.698/0.718 | c=0.998347
[Epoch 0130] loss=30.3243 cls=0.1562 smmd=0.3742 ct=9.0264 rec=1.1819 | train/val/test=0.960/0.702/0.726 | c=0.998347
[Epoch 0131] loss=30.1685 cls=0.2022 smmd=0.3718 ct=9.0093 rec=1.1677 | train/val/test=0.960/0.696/0.732 | c=0.998347
[Epoch 0132] loss=29.9449 cls=0.1221 smmd=0.3142 ct=8.9905 rec=1.1589 | train/val/test=0.980/0.694/0.730 | c=0.998347
[Epoch 0133] loss=30.0236 cls=0.1365 smmd=0.3626 ct=8.9964 rec=1.1600 | train/val/test=0.980/0.698/0.728 | c=0.998347
[Epoch 0134] loss=29.9575 cls=0.1616 smmd=0.3045 ct=8.9907 rec=1.1591 | train/val/test=0.960/0.692/0.732 | c=0.998347
[Epoch 0135] loss=29.9926 cls=0.1256 smmd=0.2938 ct=8.9938 rec=1.1648 | train/val/test=0.980/0.700/0.729 | c=0.998347
[Epoch 0136] loss=30.0544 cls=0.1468 smmd=0.2951 ct=8.9983 rec=1.1689 | train/val/test=0.980/0.706/0.730 | c=0.998347
[Epoch 0137] loss=30.1380 cls=0.1733 smmd=0.3052 ct=9.0080 rec=1.1730 | train/val/test=0.960/0.692/0.730 | c=0.998347
[Epoch 0138] loss=30.2011 cls=0.1481 smmd=0.2942 ct=9.0081 rec=1.1817 | train/val/test=0.960/0.700/0.725 | c=0.998347
[Epoch 0139] loss=30.1042 cls=0.2081 smmd=0.2944 ct=9.0040 rec=1.1698 | train/val/test=0.980/0.696/0.731 | c=0.998347
[Epoch 0140] loss=29.9858 cls=0.1312 smmd=0.2675 ct=8.9957 rec=1.1661 | train/val/test=0.960/0.700/0.733 | c=0.998347
[Epoch 0141] loss=30.0355 cls=0.1520 smmd=0.3451 ct=8.9929 rec=1.1629 | train/val/test=0.980/0.698/0.728 | c=0.998347
[Epoch 0142] loss=29.8976 cls=0.1613 smmd=0.2816 ct=8.9834 rec=1.1569 | train/val/test=0.980/0.694/0.732 | c=0.998347
[Epoch 0143] loss=30.0102 cls=0.1386 smmd=0.3073 ct=8.9982 rec=1.1637 | train/val/test=0.960/0.702/0.729 | c=0.998347
[Epoch 0144] loss=30.0356 cls=0.1475 smmd=0.3434 ct=8.9942 rec=1.1630 | train/val/test=0.980/0.696/0.728 | c=0.998347
[Epoch 0145] loss=29.9149 cls=0.1374 smmd=0.2493 ct=8.9865 rec=1.1624 | train/val/test=0.980/0.696/0.730 | c=0.998347
[Epoch 0146] loss=30.1478 cls=0.1427 smmd=0.3097 ct=9.0090 rec=1.1749 | train/val/test=0.960/0.712/0.736 | c=0.998347
[Epoch 0147] loss=30.3056 cls=0.1829 smmd=0.3892 ct=9.0146 rec=1.1796 | train/val/test=0.980/0.684/0.722 | c=0.998347
[Epoch 0148] loss=30.2336 cls=0.1286 smmd=0.3323 ct=9.0134 rec=1.1810 | train/val/test=0.940/0.712/0.736 | c=0.998347
[Epoch 0149] loss=30.2846 cls=0.2427 smmd=0.4227 ct=9.0167 rec=1.1707 | train/val/test=0.960/0.698/0.732 | c=0.998347
[Epoch 0150] loss=29.9389 cls=0.1361 smmd=0.3307 ct=8.9873 rec=1.1566 | train/val/test=0.960/0.696/0.730 | c=0.998347
[Epoch 0151] loss=30.0897 cls=0.1305 smmd=0.4197 ct=8.9999 rec=1.1605 | train/val/test=0.980/0.706/0.734 | c=0.998347
[Epoch 0152] loss=29.9885 cls=0.1603 smmd=0.3556 ct=8.9920 rec=1.1569 | train/val/test=0.980/0.702/0.733 | c=0.998347
[Epoch 0153] loss=29.9874 cls=0.1524 smmd=0.3300 ct=8.9925 rec=1.1596 | train/val/test=0.960/0.692/0.729 | c=0.998347
[Epoch 0154] loss=30.0617 cls=0.1378 smmd=0.3350 ct=8.9946 rec=1.1669 | train/val/test=0.980/0.700/0.732 | c=0.998347
[Epoch 0155] loss=29.9163 cls=0.1319 smmd=0.2259 ct=8.9893 rec=1.1646 | train/val/test=0.980/0.700/0.730 | c=0.998347
[Epoch 0156] loss=30.1364 cls=0.1604 smmd=0.3083 ct=9.0073 rec=1.1733 | train/val/test=0.960/0.694/0.730 | c=0.998347
[Epoch 0157] loss=30.1891 cls=0.1482 smmd=0.3124 ct=9.0094 rec=1.1784 | train/val/test=0.980/0.700/0.735 | c=0.998347
[Epoch 0158] loss=29.9778 cls=0.1379 smmd=0.2464 ct=8.9938 rec=1.1675 | train/val/test=0.980/0.704/0.730 | c=0.998347
[Epoch 0159] loss=29.9828 cls=0.1790 smmd=0.2767 ct=8.9942 rec=1.1628 | train/val/test=0.960/0.696/0.733 | c=0.998347
[Epoch 0160] loss=29.9549 cls=0.1277 smmd=0.2936 ct=8.9914 rec=1.1615 | train/val/test=0.960/0.700/0.730 | c=0.998347
[Epoch 0161] loss=29.8930 cls=0.1384 smmd=0.2687 ct=8.9854 rec=1.1584 | train/val/test=0.980/0.698/0.729 | c=0.998347
[Epoch 0162] loss=29.9557 cls=0.1630 smmd=0.2815 ct=8.9920 rec=1.1609 | train/val/test=0.960/0.694/0.732 | c=0.998347
[Epoch 0163] loss=29.9063 cls=0.1272 smmd=0.2261 ct=8.9891 rec=1.1638 | train/val/test=0.960/0.704/0.728 | c=0.998347
[Epoch 0164] loss=29.9650 cls=0.1440 smmd=0.2374 ct=8.9910 rec=1.1674 | train/val/test=0.980/0.694/0.729 | c=0.998347
[Epoch 0165] loss=30.0338 cls=0.1473 smmd=0.2323 ct=9.0020 rec=1.1724 | train/val/test=0.980/0.706/0.732 | c=0.998347
[Epoch 0166] loss=30.0663 cls=0.1548 smmd=0.2590 ct=8.9996 rec=1.1731 | train/val/test=0.980/0.696/0.730 | c=0.998347
[Epoch 0167] loss=30.1322 cls=0.1338 smmd=0.2789 ct=9.0088 rec=1.1769 | train/val/test=0.920/0.708/0.727 | c=0.998347
[Epoch 0168] loss=30.2880 cls=0.2496 smmd=0.3664 ct=9.0203 rec=1.1756 | train/val/test=0.960/0.692/0.729 | c=0.998347
[Epoch 0169] loss=30.1595 cls=0.1288 smmd=0.3797 ct=9.0114 rec=1.1693 | train/val/test=0.980/0.700/0.730 | c=0.998347
[Epoch 0170] loss=29.8553 cls=0.1316 smmd=0.2950 ct=8.9822 rec=1.1530 | train/val/test=0.960/0.710/0.728 | c=0.998347
[Epoch 0171] loss=30.1004 cls=0.2069 smmd=0.3760 ct=9.0019 rec=1.1617 | train/val/test=0.960/0.698/0.730 | c=0.998347
[Epoch 0172] loss=29.9436 cls=0.1173 smmd=0.3047 ct=8.9938 rec=1.1593 | train/val/test=0.960/0.696/0.731 | c=0.998347
[Epoch 0173] loss=29.9169 cls=0.1284 smmd=0.2694 ct=8.9878 rec=1.1608 | train/val/test=0.980/0.706/0.727 | c=0.998347
[Epoch 0174] loss=30.1970 cls=0.1891 smmd=0.3327 ct=9.0144 rec=1.1741 | train/val/test=0.980/0.680/0.715 | c=0.998347
[Epoch 0175] loss=30.4320 cls=0.1445 smmd=0.3886 ct=9.0337 rec=1.1904 | train/val/test=0.960/0.712/0.733 | c=0.998347
[Epoch 0176] loss=30.3182 cls=0.1882 smmd=0.4022 ct=9.0155 rec=1.1791 | train/val/test=0.980/0.694/0.729 | c=0.998347
[Epoch 0177] loss=29.8926 cls=0.1322 smmd=0.2711 ct=8.9861 rec=1.1583 | train/val/test=0.980/0.694/0.723 | c=0.998347
[Epoch 0178] loss=30.0944 cls=0.1415 smmd=0.3655 ct=9.0048 rec=1.1649 | train/val/test=0.980/0.706/0.731 | c=0.998347
[Epoch 0179] loss=29.9888 cls=0.1548 smmd=0.3699 ct=8.9918 rec=1.1558 | train/val/test=0.960/0.706/0.730 | c=0.998347
[Epoch 0180] loss=30.0055 cls=0.1528 smmd=0.3649 ct=8.9948 rec=1.1575 | train/val/test=0.980/0.698/0.729 | c=0.998347
[Epoch 0181] loss=30.0140 cls=0.1163 smmd=0.3279 ct=8.9973 rec=1.1633 | train/val/test=0.980/0.696/0.732 | c=0.998347
[Epoch 0182] loss=29.8954 cls=0.1343 smmd=0.2417 ct=8.9879 rec=1.1611 | train/val/test=0.960/0.708/0.733 | c=0.998347
[Epoch 0183] loss=30.1012 cls=0.1603 smmd=0.3120 ct=9.0007 rec=1.1708 | train/val/test=0.980/0.692/0.724 | c=0.998347
[Epoch 0184] loss=30.1598 cls=0.1309 smmd=0.2837 ct=9.0089 rec=1.1793 | train/val/test=0.980/0.704/0.729 | c=0.998347
[Epoch 0185] loss=30.1788 cls=0.1920 smmd=0.3077 ct=9.0144 rec=1.1746 | train/val/test=0.960/0.694/0.727 | c=0.998347
[Epoch 0186] loss=30.0885 cls=0.1286 smmd=0.3035 ct=9.0051 rec=1.1710 | train/val/test=0.980/0.700/0.727 | c=0.998347
[Epoch 0187] loss=29.8539 cls=0.1406 smmd=0.2427 ct=8.9846 rec=1.1572 | train/val/test=0.960/0.698/0.733 | c=0.998347
[Epoch 0188] loss=29.9718 cls=0.1836 smmd=0.2996 ct=8.9927 rec=1.1595 | train/val/test=0.960/0.696/0.734 | c=0.998347
[Epoch 0189] loss=29.9604 cls=0.1245 smmd=0.2992 ct=8.9954 rec=1.1608 | train/val/test=0.980/0.698/0.729 | c=0.998347
[Epoch 0190] loss=29.8691 cls=0.1316 smmd=0.2488 ct=8.9860 rec=1.1582 | train/val/test=0.980/0.704/0.730 | c=0.998347
[Epoch 0191] loss=30.0083 cls=0.1694 smmd=0.2718 ct=8.9991 rec=1.1654 | train/val/test=0.960/0.692/0.732 | c=0.998347
[Epoch 0192] loss=30.0632 cls=0.1302 smmd=0.2570 ct=9.0039 rec=1.1733 | train/val/test=0.980/0.704/0.729 | c=0.998347
[Epoch 0193] loss=29.9960 cls=0.1549 smmd=0.2386 ct=8.9963 rec=1.1687 | train/val/test=0.980/0.698/0.731 | c=0.998347
[Epoch 0194] loss=29.9715 cls=0.1390 smmd=0.2335 ct=8.9964 rec=1.1676 | train/val/test=0.980/0.694/0.729 | c=0.998347
[Epoch 0195] loss=29.9493 cls=0.1267 smmd=0.2365 ct=8.9932 rec=1.1663 | train/val/test=0.980/0.700/0.732 | c=0.998347
[Epoch 0196] loss=29.9183 cls=0.1553 smmd=0.2280 ct=8.9898 rec=1.1633 | train/val/test=0.980/0.694/0.733 | c=0.998347
[Epoch 0197] loss=29.9069 cls=0.1323 smmd=0.2200 ct=8.9941 rec=1.1632 | train/val/test=0.980/0.696/0.728 | c=0.998347
[Epoch 0198] loss=29.8691 cls=0.1410 smmd=0.2176 ct=8.9880 rec=1.1605 | train/val/test=0.980/0.696/0.730 | c=0.998347
[Epoch 0199] loss=29.8789 cls=0.1463 smmd=0.2233 ct=8.9876 rec=1.1607 | train/val/test=0.980/0.694/0.732 | c=0.998347
=== Best @ epoch 49: val=0.7240, test=0.7310 ===

==================================================
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-2 - 2025-09-21 06:23:41:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-2...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-2 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.8362 cls=1.7915 smmd=4.0721 ct=9.4758 rec=1.3917 | train/val/test=0.180/0.058/0.077 | c=0.998347
[Epoch 0001] loss=37.6901 cls=1.7840 smmd=3.9258 ct=9.4777 rec=1.3917 | train/val/test=0.200/0.062/0.076 | c=0.998347
[Epoch 0002] loss=36.4901 cls=1.7744 smmd=2.9413 ct=9.3725 rec=1.3917 | train/val/test=0.500/0.280/0.261 | c=0.998347
[Epoch 0003] loss=36.1121 cls=1.7562 smmd=2.5366 ct=9.3905 rec=1.3916 | train/val/test=0.520/0.328/0.307 | c=0.998347
[Epoch 0004] loss=35.2542 cls=1.7188 smmd=2.2387 ct=9.1204 rec=1.3915 | train/val/test=0.460/0.322/0.312 | c=0.998347
[Epoch 0005] loss=34.9633 cls=1.6744 smmd=1.9108 ct=9.1514 rec=1.3912 | train/val/test=0.540/0.408/0.389 | c=0.998347
[Epoch 0006] loss=34.5440 cls=1.6178 smmd=1.7545 ct=9.0385 rec=1.3904 | train/val/test=0.620/0.452/0.417 | c=0.998347
[Epoch 0007] loss=34.4110 cls=1.5611 smmd=1.6739 ct=9.0322 rec=1.3892 | train/val/test=0.620/0.454/0.433 | c=0.998347
[Epoch 0008] loss=34.1281 cls=1.5044 smmd=1.4659 ct=9.0158 rec=1.3878 | train/val/test=0.680/0.474/0.481 | c=0.998347
[Epoch 0009] loss=33.9679 cls=1.4509 smmd=1.3981 ct=8.9904 rec=1.3863 | train/val/test=0.660/0.520/0.513 | c=0.998347
[Epoch 0010] loss=33.9005 cls=1.3999 smmd=1.3850 ct=8.9844 rec=1.3847 | train/val/test=0.740/0.540/0.533 | c=0.998347
[Epoch 0011] loss=33.7059 cls=1.3520 smmd=1.2265 ct=8.9853 rec=1.3833 | train/val/test=0.760/0.560/0.553 | c=0.998347
[Epoch 0012] loss=33.5765 cls=1.3047 smmd=1.1270 ct=8.9868 rec=1.3824 | train/val/test=0.820/0.564/0.555 | c=0.998347
[Epoch 0013] loss=33.5013 cls=1.2593 smmd=1.0653 ct=8.9949 rec=1.3817 | train/val/test=0.880/0.582/0.576 | c=0.998347
[Epoch 0014] loss=33.3261 cls=1.2121 smmd=0.9243 ct=8.9974 rec=1.3801 | train/val/test=0.820/0.578/0.560 | c=0.998347
[Epoch 0015] loss=33.2294 cls=1.1658 smmd=0.8637 ct=8.9994 rec=1.3784 | train/val/test=0.860/0.552/0.556 | c=0.998347
[Epoch 0016] loss=33.1422 cls=1.1092 smmd=0.8266 ct=8.9966 rec=1.3768 | train/val/test=0.920/0.578/0.573 | c=0.998347
[Epoch 0017] loss=32.9677 cls=1.0537 smmd=0.7064 ct=8.9955 rec=1.3743 | train/val/test=0.920/0.608/0.588 | c=0.998347
[Epoch 0018] loss=32.9015 cls=1.0024 smmd=0.6972 ct=8.9985 rec=1.3706 | train/val/test=0.920/0.602/0.587 | c=0.998347
[Epoch 0019] loss=32.7636 cls=0.9432 smmd=0.6311 ct=8.9981 rec=1.3665 | train/val/test=0.920/0.602/0.581 | c=0.998347
[Epoch 0020] loss=32.6370 cls=0.8847 smmd=0.5880 ct=8.9957 rec=1.3615 | train/val/test=0.900/0.614/0.591 | c=0.998347
[Epoch 0021] loss=32.5401 cls=0.8359 smmd=0.5838 ct=8.9918 rec=1.3555 | train/val/test=0.900/0.618/0.609 | c=0.998347
[Epoch 0022] loss=32.4013 cls=0.7850 smmd=0.5424 ct=8.9885 rec=1.3489 | train/val/test=0.920/0.618/0.605 | c=0.998347
[Epoch 0023] loss=32.2764 cls=0.7351 smmd=0.5115 ct=8.9883 rec=1.3421 | train/val/test=0.940/0.628/0.630 | c=0.998347
[Epoch 0024] loss=32.1844 cls=0.6977 smmd=0.5141 ct=8.9869 rec=1.3348 | train/val/test=0.940/0.630/0.624 | c=0.998347
[Epoch 0025] loss=32.0447 cls=0.6623 smmd=0.4649 ct=8.9870 rec=1.3275 | train/val/test=0.960/0.640/0.622 | c=0.998347
[Epoch 0026] loss=31.9332 cls=0.6244 smmd=0.4401 ct=8.9882 rec=1.3205 | train/val/test=0.920/0.644/0.637 | c=0.998347
[Epoch 0027] loss=31.8456 cls=0.5943 smmd=0.4376 ct=8.9868 rec=1.3137 | train/val/test=0.920/0.636/0.646 | c=0.998347
[Epoch 0028] loss=31.7348 cls=0.5650 smmd=0.4153 ct=8.9844 rec=1.3068 | train/val/test=0.900/0.638/0.645 | c=0.998347
[Epoch 0029] loss=31.6363 cls=0.5351 smmd=0.3979 ct=8.9859 rec=1.2999 | train/val/test=0.900/0.648/0.651 | c=0.998347
[Epoch 0030] loss=31.5586 cls=0.5131 smmd=0.3960 ct=8.9859 rec=1.2934 | train/val/test=0.900/0.656/0.660 | c=0.998347
[Epoch 0031] loss=31.4474 cls=0.4858 smmd=0.3657 ct=8.9850 rec=1.2869 | train/val/test=0.900/0.658/0.668 | c=0.998347
[Epoch 0032] loss=31.3735 cls=0.4630 smmd=0.3730 ct=8.9829 rec=1.2803 | train/val/test=0.900/0.662/0.681 | c=0.998347
[Epoch 0033] loss=31.2806 cls=0.4458 smmd=0.3548 ct=8.9814 rec=1.2740 | train/val/test=0.920/0.668/0.687 | c=0.998347
[Epoch 0034] loss=31.1954 cls=0.4206 smmd=0.3457 ct=8.9822 rec=1.2675 | train/val/test=0.920/0.674/0.703 | c=0.998347
[Epoch 0035] loss=31.1242 cls=0.4080 smmd=0.3489 ct=8.9808 rec=1.2610 | train/val/test=0.920/0.676/0.710 | c=0.998347
[Epoch 0036] loss=31.0203 cls=0.3886 smmd=0.3184 ct=8.9805 rec=1.2547 | train/val/test=0.920/0.684/0.708 | c=0.998347
[Epoch 0037] loss=30.9543 cls=0.3774 smmd=0.3257 ct=8.9792 rec=1.2482 | train/val/test=0.920/0.682/0.711 | c=0.998347
[Epoch 0038] loss=30.8888 cls=0.3590 smmd=0.3289 ct=8.9796 rec=1.2421 | train/val/test=0.920/0.688/0.714 | c=0.998347
[Epoch 0039] loss=30.8184 cls=0.3489 smmd=0.3210 ct=8.9796 rec=1.2364 | train/val/test=0.940/0.694/0.712 | c=0.998347
[Epoch 0040] loss=30.7477 cls=0.3393 smmd=0.3071 ct=8.9799 rec=1.2311 | train/val/test=0.940/0.700/0.716 | c=0.998347
[Epoch 0041] loss=30.6825 cls=0.3285 smmd=0.2933 ct=8.9801 rec=1.2265 | train/val/test=0.940/0.698/0.717 | c=0.998347
[Epoch 0042] loss=30.6483 cls=0.3194 smmd=0.3063 ct=8.9802 rec=1.2222 | train/val/test=0.940/0.698/0.716 | c=0.998347
[Epoch 0043] loss=30.5901 cls=0.3078 smmd=0.2878 ct=8.9808 rec=1.2187 | train/val/test=0.940/0.708/0.718 | c=0.998347
[Epoch 0044] loss=30.5553 cls=0.3048 smmd=0.2870 ct=8.9815 rec=1.2153 | train/val/test=0.940/0.696/0.716 | c=0.998347
[Epoch 0045] loss=30.5175 cls=0.2890 smmd=0.2792 ct=8.9823 rec=1.2129 | train/val/test=0.960/0.712/0.723 | c=0.998347
[Epoch 0046] loss=30.4976 cls=0.2943 smmd=0.2849 ct=8.9819 rec=1.2102 | train/val/test=0.960/0.706/0.722 | c=0.998347
[Epoch 0047] loss=30.5058 cls=0.2665 smmd=0.2980 ct=8.9873 rec=1.2100 | train/val/test=0.960/0.718/0.726 | c=0.998347
[Epoch 0048] loss=30.5509 cls=0.3041 smmd=0.3265 ct=8.9913 rec=1.2090 | train/val/test=0.980/0.690/0.719 | c=0.998347
[Epoch 0049] loss=30.7191 cls=0.2490 smmd=0.4072 ct=9.0114 rec=1.2165 | train/val/test=0.960/0.724/0.731 | c=0.998347
[Epoch 0050] loss=30.6721 cls=0.3224 smmd=0.4203 ct=9.0042 rec=1.2082 | train/val/test=0.960/0.704/0.723 | c=0.998347
[Epoch 0051] loss=30.4287 cls=0.2258 smmd=0.3611 ct=8.9942 rec=1.1966 | train/val/test=0.940/0.706/0.722 | c=0.998347
[Epoch 0052] loss=30.3110 cls=0.2320 smmd=0.3234 ct=8.9857 rec=1.1900 | train/val/test=0.960/0.722/0.731 | c=0.998347
[Epoch 0053] loss=30.4492 cls=0.2861 smmd=0.3887 ct=8.9928 rec=1.1932 | train/val/test=0.980/0.718/0.727 | c=0.998347
[Epoch 0054] loss=30.3239 cls=0.2057 smmd=0.3435 ct=8.9897 rec=1.1898 | train/val/test=0.960/0.712/0.727 | c=0.998347
[Epoch 0055] loss=30.2825 cls=0.2135 smmd=0.3147 ct=8.9864 rec=1.1888 | train/val/test=0.960/0.720/0.732 | c=0.998347
[Epoch 0056] loss=30.4497 cls=0.2682 smmd=0.3723 ct=8.9969 rec=1.1949 | train/val/test=0.980/0.696/0.720 | c=0.998347
[Epoch 0057] loss=30.4344 cls=0.1976 smmd=0.3358 ct=9.0022 rec=1.1995 | train/val/test=0.960/0.722/0.743 | c=0.998347
[Epoch 0058] loss=30.2459 cls=0.2226 smmd=0.2805 ct=8.9850 rec=1.1884 | train/val/test=0.980/0.712/0.733 | c=0.998347
[Epoch 0059] loss=30.2754 cls=0.2356 smmd=0.2998 ct=8.9877 rec=1.1882 | train/val/test=0.980/0.704/0.725 | c=0.998347
[Epoch 0060] loss=30.3546 cls=0.1888 smmd=0.3238 ct=9.0021 rec=1.1932 | train/val/test=0.960/0.714/0.736 | c=0.998347
[Epoch 0061] loss=30.2324 cls=0.2273 smmd=0.3049 ct=8.9862 rec=1.1841 | train/val/test=0.980/0.716/0.732 | c=0.998347
[Epoch 0062] loss=30.1515 cls=0.2116 smmd=0.2706 ct=8.9832 rec=1.1809 | train/val/test=0.980/0.710/0.737 | c=0.998347
[Epoch 0063] loss=30.2230 cls=0.1856 smmd=0.3031 ct=8.9940 rec=1.1839 | train/val/test=0.980/0.718/0.735 | c=0.998347
[Epoch 0064] loss=30.1919 cls=0.2151 smmd=0.2964 ct=8.9869 rec=1.1814 | train/val/test=0.980/0.716/0.739 | c=0.998347
[Epoch 0065] loss=30.1382 cls=0.1889 smmd=0.2678 ct=8.9849 rec=1.1806 | train/val/test=0.980/0.706/0.741 | c=0.998347
[Epoch 0066] loss=30.1406 cls=0.1803 smmd=0.2445 ct=8.9893 rec=1.1827 | train/val/test=0.980/0.716/0.736 | c=0.998347
[Epoch 0067] loss=30.1941 cls=0.2044 smmd=0.2718 ct=8.9908 rec=1.1839 | train/val/test=0.980/0.702/0.742 | c=0.998347
[Epoch 0068] loss=30.2177 cls=0.1791 smmd=0.2732 ct=8.9975 rec=1.1860 | train/val/test=0.980/0.712/0.743 | c=0.998347
[Epoch 0069] loss=30.1423 cls=0.1936 smmd=0.2519 ct=8.9891 rec=1.1815 | train/val/test=0.980/0.704/0.738 | c=0.998347
[Epoch 0070] loss=30.0835 cls=0.1859 smmd=0.2386 ct=8.9876 rec=1.1777 | train/val/test=0.980/0.698/0.740 | c=0.998347
[Epoch 0071] loss=30.0641 cls=0.1728 smmd=0.2300 ct=8.9876 rec=1.1772 | train/val/test=0.980/0.714/0.737 | c=0.998347
[Epoch 0072] loss=30.1042 cls=0.1990 smmd=0.2663 ct=8.9877 rec=1.1763 | train/val/test=0.980/0.696/0.742 | c=0.998347
[Epoch 0073] loss=30.0795 cls=0.1659 smmd=0.2392 ct=8.9914 rec=1.1774 | train/val/test=0.980/0.712/0.743 | c=0.998347
[Epoch 0074] loss=30.0581 cls=0.1856 smmd=0.2429 ct=8.9866 rec=1.1749 | train/val/test=0.980/0.702/0.745 | c=0.998347
[Epoch 0075] loss=30.0511 cls=0.1671 smmd=0.2283 ct=8.9880 rec=1.1763 | train/val/test=0.980/0.708/0.742 | c=0.998347
[Epoch 0076] loss=30.1063 cls=0.1766 smmd=0.2485 ct=8.9948 rec=1.1780 | train/val/test=0.980/0.706/0.741 | c=0.998347
[Epoch 0077] loss=30.1317 cls=0.1735 smmd=0.2584 ct=8.9945 rec=1.1797 | train/val/test=0.960/0.708/0.741 | c=0.998347
[Epoch 0078] loss=30.2014 cls=0.1860 smmd=0.2939 ct=9.0070 rec=1.1800 | train/val/test=0.980/0.704/0.736 | c=0.998347
[Epoch 0079] loss=30.1755 cls=0.1673 smmd=0.2928 ct=9.0007 rec=1.1798 | train/val/test=0.960/0.706/0.742 | c=0.998347
[Epoch 0080] loss=30.1757 cls=0.1984 smmd=0.3188 ct=9.0010 rec=1.1756 | train/val/test=0.980/0.692/0.733 | c=0.998347
[Epoch 0081] loss=30.1510 cls=0.1447 smmd=0.3323 ct=9.0008 rec=1.1745 | train/val/test=0.980/0.706/0.744 | c=0.998347
[Epoch 0082] loss=30.0072 cls=0.1755 smmd=0.2845 ct=8.9854 rec=1.1664 | train/val/test=0.980/0.704/0.739 | c=0.998347
[Epoch 0083] loss=30.0318 cls=0.1659 smmd=0.2877 ct=8.9903 rec=1.1680 | train/val/test=0.980/0.690/0.731 | c=0.998347
[Epoch 0084] loss=30.1087 cls=0.1435 smmd=0.2981 ct=8.9992 rec=1.1740 | train/val/test=0.980/0.706/0.738 | c=0.998347
[Epoch 0085] loss=30.0826 cls=0.1829 smmd=0.2834 ct=8.9920 rec=1.1724 | train/val/test=0.980/0.696/0.737 | c=0.998347
[Epoch 0086] loss=30.0571 cls=0.1414 smmd=0.2427 ct=8.9939 rec=1.1756 | train/val/test=0.980/0.704/0.735 | c=0.998347
[Epoch 0087] loss=30.0641 cls=0.1810 smmd=0.2493 ct=8.9919 rec=1.1740 | train/val/test=0.980/0.700/0.737 | c=0.998347
[Epoch 0088] loss=30.0949 cls=0.1677 smmd=0.2439 ct=8.9965 rec=1.1774 | train/val/test=0.980/0.694/0.728 | c=0.998347
[Epoch 0089] loss=30.2181 cls=0.1633 smmd=0.2995 ct=9.0087 rec=1.1820 | train/val/test=0.960/0.716/0.738 | c=0.998347
[Epoch 0090] loss=30.3336 cls=0.2319 smmd=0.3730 ct=9.0181 rec=1.1809 | train/val/test=0.960/0.688/0.727 | c=0.998347
[Epoch 0091] loss=30.3523 cls=0.1422 smmd=0.4250 ct=9.0236 rec=1.1809 | train/val/test=0.960/0.700/0.736 | c=0.998347
[Epoch 0092] loss=30.0370 cls=0.1850 smmd=0.3489 ct=8.9888 rec=1.1618 | train/val/test=0.980/0.714/0.731 | c=0.998347
[Epoch 0093] loss=30.1492 cls=0.1942 smmd=0.3912 ct=9.0006 rec=1.1660 | train/val/test=0.960/0.694/0.735 | c=0.998347
[Epoch 0094] loss=30.1390 cls=0.1302 smmd=0.4140 ct=9.0007 rec=1.1658 | train/val/test=0.980/0.690/0.729 | c=0.998347
[Epoch 0095] loss=30.1140 cls=0.1632 smmd=0.3758 ct=8.9981 rec=1.1660 | train/val/test=0.980/0.710/0.735 | c=0.998347
[Epoch 0096] loss=30.1044 cls=0.1777 smmd=0.3282 ct=8.9967 rec=1.1694 | train/val/test=0.960/0.688/0.732 | c=0.998347
[Epoch 0097] loss=30.2094 cls=0.1419 smmd=0.3395 ct=9.0057 rec=1.1788 | train/val/test=0.960/0.692/0.729 | c=0.998347
[Epoch 0098] loss=30.2198 cls=0.2008 smmd=0.3647 ct=9.0014 rec=1.1752 | train/val/test=0.980/0.708/0.731 | c=0.998347
[Epoch 0099] loss=30.1278 cls=0.1769 smmd=0.3030 ct=9.0007 rec=1.1735 | train/val/test=0.960/0.684/0.723 | c=0.998347
[Epoch 0100] loss=30.3271 cls=0.1432 smmd=0.3828 ct=9.0142 rec=1.1844 | train/val/test=0.960/0.702/0.726 | c=0.998347
[Epoch 0101] loss=30.1500 cls=0.2200 smmd=0.3657 ct=8.9975 rec=1.1679 | train/val/test=0.980/0.710/0.732 | c=0.998347
[Epoch 0102] loss=29.9823 cls=0.1749 smmd=0.2993 ct=8.9872 rec=1.1621 | train/val/test=0.960/0.690/0.735 | c=0.998347
[Epoch 0103] loss=30.1281 cls=0.1346 smmd=0.3818 ct=9.0000 rec=1.1679 | train/val/test=0.980/0.702/0.726 | c=0.998347
[Epoch 0104] loss=29.9643 cls=0.1662 smmd=0.3011 ct=8.9838 rec=1.1612 | train/val/test=0.980/0.712/0.733 | c=0.998347
[Epoch 0105] loss=30.0458 cls=0.1868 smmd=0.3096 ct=8.9929 rec=1.1657 | train/val/test=0.960/0.692/0.732 | c=0.998347
[Epoch 0106] loss=30.1136 cls=0.1346 smmd=0.3149 ct=9.0000 rec=1.1731 | train/val/test=0.980/0.700/0.732 | c=0.998347
[Epoch 0107] loss=29.9856 cls=0.1609 smmd=0.2444 ct=8.9864 rec=1.1688 | train/val/test=0.980/0.702/0.729 | c=0.998347
[Epoch 0108] loss=30.0776 cls=0.1731 smmd=0.2730 ct=8.9986 rec=1.1721 | train/val/test=0.960/0.692/0.731 | c=0.998347
[Epoch 0109] loss=30.1208 cls=0.1383 smmd=0.2837 ct=8.9981 rec=1.1772 | train/val/test=0.960/0.700/0.732 | c=0.998347
[Epoch 0110] loss=29.9898 cls=0.1759 smmd=0.2462 ct=8.9881 rec=1.1679 | train/val/test=0.980/0.696/0.732 | c=0.998347
[Epoch 0111] loss=29.9637 cls=0.1537 smmd=0.2379 ct=8.9904 rec=1.1668 | train/val/test=0.960/0.698/0.732 | c=0.998347
[Epoch 0112] loss=30.0235 cls=0.1516 smmd=0.2862 ct=8.9917 rec=1.1678 | train/val/test=0.980/0.698/0.731 | c=0.998347
[Epoch 0113] loss=29.9357 cls=0.1662 smmd=0.2393 ct=8.9862 rec=1.1641 | train/val/test=0.980/0.698/0.731 | c=0.998347
[Epoch 0114] loss=29.9343 cls=0.1514 smmd=0.2254 ct=8.9898 rec=1.1654 | train/val/test=0.960/0.698/0.733 | c=0.998347
[Epoch 0115] loss=30.0137 cls=0.1505 smmd=0.2644 ct=8.9913 rec=1.1692 | train/val/test=0.980/0.700/0.731 | c=0.998347
[Epoch 0116] loss=29.9577 cls=0.1552 smmd=0.2263 ct=8.9900 rec=1.1674 | train/val/test=0.980/0.696/0.730 | c=0.998347
[Epoch 0117] loss=29.9343 cls=0.1444 smmd=0.2012 ct=8.9886 rec=1.1684 | train/val/test=0.960/0.696/0.729 | c=0.998347
[Epoch 0118] loss=30.0090 cls=0.1491 smmd=0.2318 ct=8.9909 rec=1.1721 | train/val/test=0.980/0.706/0.733 | c=0.998347
[Epoch 0119] loss=30.0181 cls=0.1625 smmd=0.2303 ct=8.9984 rec=1.1710 | train/val/test=0.960/0.698/0.729 | c=0.998347
[Epoch 0120] loss=29.9406 cls=0.1519 smmd=0.2108 ct=8.9876 rec=1.1679 | train/val/test=0.980/0.696/0.730 | c=0.998347
[Epoch 0121] loss=29.9224 cls=0.1438 smmd=0.2124 ct=8.9895 rec=1.1659 | train/val/test=0.980/0.696/0.729 | c=0.998347
[Epoch 0122] loss=29.9659 cls=0.1587 smmd=0.2420 ct=8.9917 rec=1.1661 | train/val/test=0.960/0.696/0.730 | c=0.998347
[Epoch 0123] loss=29.9302 cls=0.1563 smmd=0.2253 ct=8.9882 rec=1.1650 | train/val/test=0.980/0.694/0.729 | c=0.998347
[Epoch 0124] loss=29.9321 cls=0.1330 smmd=0.2236 ct=8.9901 rec=1.1662 | train/val/test=0.980/0.702/0.732 | c=0.998347
[Epoch 0125] loss=29.9739 cls=0.1728 smmd=0.2403 ct=8.9927 rec=1.1662 | train/val/test=0.960/0.694/0.729 | c=0.998347
[Epoch 0126] loss=29.9778 cls=0.1329 smmd=0.2266 ct=8.9928 rec=1.1699 | train/val/test=0.980/0.698/0.732 | c=0.998347
[Epoch 0127] loss=29.9485 cls=0.1602 smmd=0.2086 ct=8.9924 rec=1.1675 | train/val/test=0.980/0.692/0.731 | c=0.998347
[Epoch 0128] loss=30.0074 cls=0.1437 smmd=0.2317 ct=8.9969 rec=1.1710 | train/val/test=0.960/0.706/0.727 | c=0.998347
[Epoch 0129] loss=30.1351 cls=0.1748 smmd=0.2873 ct=9.0077 rec=1.1745 | train/val/test=0.980/0.698/0.718 | c=0.998347
[Epoch 0130] loss=30.3243 cls=0.1562 smmd=0.3742 ct=9.0264 rec=1.1819 | train/val/test=0.960/0.702/0.726 | c=0.998347
[Epoch 0131] loss=30.1685 cls=0.2022 smmd=0.3718 ct=9.0093 rec=1.1677 | train/val/test=0.960/0.696/0.732 | c=0.998347
[Epoch 0132] loss=29.9449 cls=0.1221 smmd=0.3142 ct=8.9905 rec=1.1589 | train/val/test=0.980/0.694/0.730 | c=0.998347
[Epoch 0133] loss=30.0236 cls=0.1365 smmd=0.3626 ct=8.9964 rec=1.1600 | train/val/test=0.980/0.698/0.728 | c=0.998347
[Epoch 0134] loss=29.9575 cls=0.1616 smmd=0.3045 ct=8.9907 rec=1.1591 | train/val/test=0.960/0.692/0.732 | c=0.998347
[Epoch 0135] loss=29.9926 cls=0.1256 smmd=0.2938 ct=8.9938 rec=1.1648 | train/val/test=0.980/0.700/0.729 | c=0.998347
[Epoch 0136] loss=30.0544 cls=0.1468 smmd=0.2951 ct=8.9983 rec=1.1689 | train/val/test=0.980/0.706/0.730 | c=0.998347
[Epoch 0137] loss=30.1380 cls=0.1733 smmd=0.3052 ct=9.0080 rec=1.1730 | train/val/test=0.960/0.692/0.730 | c=0.998347
[Epoch 0138] loss=30.2011 cls=0.1481 smmd=0.2942 ct=9.0081 rec=1.1817 | train/val/test=0.960/0.700/0.725 | c=0.998347
[Epoch 0139] loss=30.1042 cls=0.2081 smmd=0.2944 ct=9.0040 rec=1.1698 | train/val/test=0.980/0.696/0.731 | c=0.998347
[Epoch 0140] loss=29.9858 cls=0.1312 smmd=0.2675 ct=8.9957 rec=1.1661 | train/val/test=0.960/0.700/0.733 | c=0.998347
[Epoch 0141] loss=30.0355 cls=0.1520 smmd=0.3451 ct=8.9929 rec=1.1629 | train/val/test=0.980/0.698/0.728 | c=0.998347
[Epoch 0142] loss=29.8976 cls=0.1613 smmd=0.2816 ct=8.9834 rec=1.1569 | train/val/test=0.980/0.694/0.732 | c=0.998347
[Epoch 0143] loss=30.0102 cls=0.1386 smmd=0.3073 ct=8.9982 rec=1.1637 | train/val/test=0.960/0.702/0.729 | c=0.998347
[Epoch 0144] loss=30.0356 cls=0.1475 smmd=0.3434 ct=8.9942 rec=1.1630 | train/val/test=0.980/0.696/0.728 | c=0.998347
[Epoch 0145] loss=29.9149 cls=0.1374 smmd=0.2493 ct=8.9865 rec=1.1624 | train/val/test=0.980/0.696/0.730 | c=0.998347
[Epoch 0146] loss=30.1478 cls=0.1427 smmd=0.3097 ct=9.0090 rec=1.1749 | train/val/test=0.960/0.712/0.736 | c=0.998347
[Epoch 0147] loss=30.3056 cls=0.1829 smmd=0.3892 ct=9.0146 rec=1.1796 | train/val/test=0.980/0.684/0.722 | c=0.998347
[Epoch 0148] loss=30.2336 cls=0.1286 smmd=0.3323 ct=9.0134 rec=1.1810 | train/val/test=0.940/0.712/0.736 | c=0.998347
[Epoch 0149] loss=30.2846 cls=0.2427 smmd=0.4227 ct=9.0167 rec=1.1707 | train/val/test=0.960/0.698/0.732 | c=0.998347
[Epoch 0150] loss=29.9389 cls=0.1361 smmd=0.3307 ct=8.9873 rec=1.1566 | train/val/test=0.960/0.696/0.730 | c=0.998347
[Epoch 0151] loss=30.0897 cls=0.1305 smmd=0.4197 ct=8.9999 rec=1.1605 | train/val/test=0.980/0.706/0.734 | c=0.998347
[Epoch 0152] loss=29.9885 cls=0.1603 smmd=0.3556 ct=8.9920 rec=1.1569 | train/val/test=0.980/0.702/0.733 | c=0.998347
[Epoch 0153] loss=29.9874 cls=0.1524 smmd=0.3300 ct=8.9925 rec=1.1596 | train/val/test=0.960/0.692/0.729 | c=0.998347
[Epoch 0154] loss=30.0617 cls=0.1378 smmd=0.3350 ct=8.9946 rec=1.1669 | train/val/test=0.980/0.700/0.732 | c=0.998347
[Epoch 0155] loss=29.9163 cls=0.1319 smmd=0.2259 ct=8.9893 rec=1.1646 | train/val/test=0.980/0.700/0.730 | c=0.998347
[Epoch 0156] loss=30.1364 cls=0.1604 smmd=0.3083 ct=9.0073 rec=1.1733 | train/val/test=0.960/0.694/0.730 | c=0.998347
[Epoch 0157] loss=30.1891 cls=0.1482 smmd=0.3124 ct=9.0094 rec=1.1784 | train/val/test=0.980/0.700/0.735 | c=0.998347
[Epoch 0158] loss=29.9778 cls=0.1379 smmd=0.2464 ct=8.9938 rec=1.1675 | train/val/test=0.980/0.704/0.730 | c=0.998347
[Epoch 0159] loss=29.9828 cls=0.1790 smmd=0.2767 ct=8.9942 rec=1.1628 | train/val/test=0.960/0.696/0.733 | c=0.998347
[Epoch 0160] loss=29.9549 cls=0.1277 smmd=0.2936 ct=8.9914 rec=1.1615 | train/val/test=0.960/0.700/0.730 | c=0.998347
[Epoch 0161] loss=29.8930 cls=0.1384 smmd=0.2687 ct=8.9854 rec=1.1584 | train/val/test=0.980/0.698/0.729 | c=0.998347
[Epoch 0162] loss=29.9557 cls=0.1630 smmd=0.2815 ct=8.9920 rec=1.1609 | train/val/test=0.960/0.694/0.732 | c=0.998347
[Epoch 0163] loss=29.9063 cls=0.1272 smmd=0.2261 ct=8.9891 rec=1.1638 | train/val/test=0.960/0.704/0.728 | c=0.998347
[Epoch 0164] loss=29.9650 cls=0.1440 smmd=0.2374 ct=8.9910 rec=1.1674 | train/val/test=0.980/0.694/0.729 | c=0.998347
[Epoch 0165] loss=30.0338 cls=0.1473 smmd=0.2323 ct=9.0020 rec=1.1724 | train/val/test=0.980/0.706/0.732 | c=0.998347
[Epoch 0166] loss=30.0663 cls=0.1548 smmd=0.2590 ct=8.9996 rec=1.1731 | train/val/test=0.980/0.696/0.730 | c=0.998347
[Epoch 0167] loss=30.1322 cls=0.1338 smmd=0.2789 ct=9.0088 rec=1.1769 | train/val/test=0.920/0.708/0.727 | c=0.998347
[Epoch 0168] loss=30.2880 cls=0.2496 smmd=0.3664 ct=9.0203 rec=1.1756 | train/val/test=0.960/0.692/0.729 | c=0.998347
[Epoch 0169] loss=30.1595 cls=0.1288 smmd=0.3797 ct=9.0114 rec=1.1693 | train/val/test=0.980/0.700/0.730 | c=0.998347
[Epoch 0170] loss=29.8553 cls=0.1316 smmd=0.2950 ct=8.9822 rec=1.1530 | train/val/test=0.960/0.710/0.728 | c=0.998347
[Epoch 0171] loss=30.1004 cls=0.2069 smmd=0.3760 ct=9.0019 rec=1.1617 | train/val/test=0.960/0.698/0.730 | c=0.998347
[Epoch 0172] loss=29.9436 cls=0.1173 smmd=0.3047 ct=8.9938 rec=1.1593 | train/val/test=0.960/0.696/0.731 | c=0.998347
[Epoch 0173] loss=29.9169 cls=0.1284 smmd=0.2694 ct=8.9878 rec=1.1608 | train/val/test=0.980/0.706/0.727 | c=0.998347
[Epoch 0174] loss=30.1970 cls=0.1891 smmd=0.3327 ct=9.0144 rec=1.1741 | train/val/test=0.980/0.680/0.715 | c=0.998347
[Epoch 0175] loss=30.4320 cls=0.1445 smmd=0.3886 ct=9.0337 rec=1.1904 | train/val/test=0.960/0.712/0.733 | c=0.998347
[Epoch 0176] loss=30.3182 cls=0.1882 smmd=0.4022 ct=9.0155 rec=1.1791 | train/val/test=0.980/0.694/0.729 | c=0.998347
[Epoch 0177] loss=29.8926 cls=0.1322 smmd=0.2711 ct=8.9861 rec=1.1583 | train/val/test=0.980/0.694/0.723 | c=0.998347
[Epoch 0178] loss=30.0944 cls=0.1415 smmd=0.3655 ct=9.0048 rec=1.1649 | train/val/test=0.980/0.706/0.731 | c=0.998347
[Epoch 0179] loss=29.9888 cls=0.1548 smmd=0.3699 ct=8.9918 rec=1.1558 | train/val/test=0.960/0.706/0.730 | c=0.998347
[Epoch 0180] loss=30.0055 cls=0.1528 smmd=0.3649 ct=8.9948 rec=1.1575 | train/val/test=0.980/0.698/0.729 | c=0.998347
[Epoch 0181] loss=30.0140 cls=0.1163 smmd=0.3279 ct=8.9973 rec=1.1633 | train/val/test=0.980/0.696/0.732 | c=0.998347
[Epoch 0182] loss=29.8954 cls=0.1343 smmd=0.2417 ct=8.9879 rec=1.1611 | train/val/test=0.960/0.708/0.733 | c=0.998347
[Epoch 0183] loss=30.1012 cls=0.1603 smmd=0.3120 ct=9.0007 rec=1.1708 | train/val/test=0.980/0.692/0.724 | c=0.998347
[Epoch 0184] loss=30.1598 cls=0.1309 smmd=0.2837 ct=9.0089 rec=1.1793 | train/val/test=0.980/0.704/0.729 | c=0.998347
[Epoch 0185] loss=30.1788 cls=0.1920 smmd=0.3077 ct=9.0144 rec=1.1746 | train/val/test=0.960/0.694/0.727 | c=0.998347
[Epoch 0186] loss=30.0885 cls=0.1286 smmd=0.3035 ct=9.0051 rec=1.1710 | train/val/test=0.980/0.700/0.727 | c=0.998347
[Epoch 0187] loss=29.8539 cls=0.1406 smmd=0.2427 ct=8.9846 rec=1.1572 | train/val/test=0.960/0.698/0.733 | c=0.998347
[Epoch 0188] loss=29.9718 cls=0.1836 smmd=0.2996 ct=8.9927 rec=1.1595 | train/val/test=0.960/0.696/0.734 | c=0.998347
[Epoch 0189] loss=29.9604 cls=0.1245 smmd=0.2992 ct=8.9954 rec=1.1608 | train/val/test=0.980/0.698/0.729 | c=0.998347
[Epoch 0190] loss=29.8691 cls=0.1316 smmd=0.2488 ct=8.9860 rec=1.1582 | train/val/test=0.980/0.704/0.730 | c=0.998347
[Epoch 0191] loss=30.0083 cls=0.1694 smmd=0.2718 ct=8.9991 rec=1.1654 | train/val/test=0.960/0.692/0.732 | c=0.998347
[Epoch 0192] loss=30.0632 cls=0.1302 smmd=0.2570 ct=9.0039 rec=1.1733 | train/val/test=0.980/0.704/0.729 | c=0.998347
[Epoch 0193] loss=29.9960 cls=0.1549 smmd=0.2386 ct=8.9963 rec=1.1687 | train/val/test=0.980/0.698/0.731 | c=0.998347
[Epoch 0194] loss=29.9715 cls=0.1390 smmd=0.2335 ct=8.9964 rec=1.1676 | train/val/test=0.980/0.694/0.729 | c=0.998347
[Epoch 0195] loss=29.9493 cls=0.1267 smmd=0.2365 ct=8.9932 rec=1.1663 | train/val/test=0.980/0.700/0.732 | c=0.998347
[Epoch 0196] loss=29.9183 cls=0.1553 smmd=0.2280 ct=8.9898 rec=1.1633 | train/val/test=0.980/0.694/0.733 | c=0.998347
[Epoch 0197] loss=29.9069 cls=0.1323 smmd=0.2200 ct=8.9941 rec=1.1632 | train/val/test=0.980/0.696/0.728 | c=0.998347
[Epoch 0198] loss=29.8691 cls=0.1410 smmd=0.2176 ct=8.9880 rec=1.1605 | train/val/test=0.980/0.696/0.730 | c=0.998347
[Epoch 0199] loss=29.8789 cls=0.1463 smmd=0.2233 ct=8.9876 rec=1.1607 | train/val/test=0.980/0.694/0.732 | c=0.998347
=== Best @ epoch 49: val=0.7240, test=0.7310 ===

Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-2 completed in 45.82 seconds.
==================================================
