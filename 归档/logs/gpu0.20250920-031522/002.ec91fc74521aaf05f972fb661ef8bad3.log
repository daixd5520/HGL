[2025-09-20 03:17:40] START attempt 1: python main.py --is_transfer True --test_dataset Photo --pretrained_model_name /mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth --few True --shot 5 --gpu_id 0
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=39, val=1522, test=6089 (mode=few, shot=5)
[Epoch 0000] loss=9.8257 cls=2.0805 smmd=5.5369 ct=10.3488 rec=1.3844 | train/val/test=0.128/0.115/0.106 | c=0.999488
[Epoch 0001] loss=7.8999 cls=2.0732 smmd=3.4799 ct=11.0415 rec=1.3844 | train/val/test=0.128/0.118/0.115 | c=0.999488
[Epoch 0002] loss=7.3967 cls=2.0688 smmd=3.0633 ct=10.6307 rec=1.3844 | train/val/test=0.256/0.191/0.202 | c=0.999488
[Epoch 0003] loss=7.5683 cls=2.0606 smmd=3.3524 ct=10.0841 rec=1.3844 | train/val/test=0.359/0.413/0.411 | c=0.999488
[Epoch 0004] loss=6.9404 cls=2.0485 smmd=2.7655 ct=9.9399 rec=1.3844 | train/val/test=0.513/0.494/0.488 | c=0.999488
[Epoch 0005] loss=5.9886 cls=2.0305 smmd=1.8496 ct=9.8505 rec=1.3844 | train/val/test=0.795/0.665/0.677 | c=0.999488
[Epoch 0006] loss=5.8428 cls=2.0074 smmd=1.6958 ct=10.0056 rec=1.3843 | train/val/test=0.769/0.708/0.704 | c=0.999488
[Epoch 0007] loss=5.8265 cls=1.9802 smmd=1.7411 ct=9.8342 rec=1.3842 | train/val/test=0.872/0.759/0.730 | c=0.999488
[Epoch 0008] loss=5.5309 cls=1.9454 smmd=1.4895 ct=9.7875 rec=1.3841 | train/val/test=0.872/0.718/0.707 | c=0.999488
[Epoch 0009] loss=5.1788 cls=1.9028 smmd=1.1771 ct=9.8027 rec=1.3839 | train/val/test=0.846/0.731/0.718 | c=0.999488
[Epoch 0010] loss=4.8717 cls=1.8543 smmd=0.9256 ct=9.7670 rec=1.3834 | train/val/test=0.821/0.713/0.694 | c=0.999488
[Epoch 0011] loss=4.6831 cls=1.8012 smmd=0.7890 ct=9.7733 rec=1.3827 | train/val/test=0.795/0.703/0.678 | c=0.999488
[Epoch 0012] loss=4.5971 cls=1.7401 smmd=0.7584 ct=9.8022 rec=1.3818 | train/val/test=0.846/0.671/0.662 | c=0.999488
[Epoch 0013] loss=4.4969 cls=1.6722 smmd=0.7179 ct=9.8441 rec=1.3805 | train/val/test=0.846/0.668/0.660 | c=0.999488
[Epoch 0014] loss=4.3027 cls=1.6001 smmd=0.5934 ct=9.8565 rec=1.3787 | train/val/test=0.846/0.677/0.669 | c=0.999488
[Epoch 0015] loss=4.0903 cls=1.5244 smmd=0.4575 ct=9.8537 rec=1.3763 | train/val/test=0.846/0.696/0.688 | c=0.999488
[Epoch 0016] loss=3.9663 cls=1.4449 smmd=0.4095 ct=9.8724 rec=1.3732 | train/val/test=0.846/0.709/0.703 | c=0.999488
[Epoch 0017] loss=3.9119 cls=1.3640 smmd=0.4298 ct=9.9054 rec=1.3694 | train/val/test=0.846/0.711/0.709 | c=0.999488
[Epoch 0018] loss=3.8307 cls=1.2840 smmd=0.4263 ct=9.9197 rec=1.3650 | train/val/test=0.846/0.714/0.709 | c=0.999488
[Epoch 0019] loss=3.7077 cls=1.2054 smmd=0.3817 ct=9.9228 rec=1.3596 | train/val/test=0.846/0.712/0.711 | c=0.999488
[Epoch 0020] loss=3.5820 cls=1.1277 smmd=0.3315 ct=9.9375 rec=1.3535 | train/val/test=0.846/0.715/0.715 | c=0.999488
[Epoch 0021] loss=3.4949 cls=1.0513 smmd=0.3158 ct=9.9653 rec=1.3468 | train/val/test=0.846/0.722/0.722 | c=0.999488
[Epoch 0022] loss=3.4313 cls=0.9790 smmd=0.3203 ct=9.9904 rec=1.3395 | train/val/test=0.872/0.737/0.730 | c=0.999488
[Epoch 0023] loss=3.3669 cls=0.9114 smmd=0.3220 ct=10.0015 rec=1.3317 | train/val/test=0.897/0.751/0.741 | c=0.999488
[Epoch 0024] loss=3.2947 cls=0.8477 smmd=0.3135 ct=10.0057 rec=1.3236 | train/val/test=0.897/0.763/0.754 | c=0.999488
[Epoch 0025] loss=3.2196 cls=0.7874 smmd=0.2980 ct=10.0137 rec=1.3153 | train/val/test=0.923/0.775/0.767 | c=0.999488
[Epoch 0026] loss=3.1606 cls=0.7315 smmd=0.2936 ct=10.0241 rec=1.3070 | train/val/test=0.923/0.784/0.781 | c=0.999488
[Epoch 0027] loss=3.1048 cls=0.6806 smmd=0.2882 ct=10.0305 rec=1.2988 | train/val/test=0.923/0.790/0.788 | c=0.999488
[Epoch 0028] loss=3.0602 cls=0.6338 smmd=0.2908 ct=10.0325 rec=1.2907 | train/val/test=0.949/0.799/0.798 | c=0.999488
[Epoch 0029] loss=3.0125 cls=0.5896 smmd=0.2875 ct=10.0353 rec=1.2830 | train/val/test=0.974/0.807/0.807 | c=0.999488
[Epoch 0030] loss=2.9621 cls=0.5478 smmd=0.2780 ct=10.0434 rec=1.2758 | train/val/test=1.000/0.817/0.814 | c=0.999488
[Epoch 0031] loss=2.9231 cls=0.5091 smmd=0.2765 ct=10.0530 rec=1.2688 | train/val/test=1.000/0.823/0.822 | c=0.999488
[Epoch 0032] loss=2.8775 cls=0.4737 smmd=0.2657 ct=10.0595 rec=1.2622 | train/val/test=1.000/0.828/0.827 | c=0.999488
[Epoch 0033] loss=2.8358 cls=0.4409 smmd=0.2572 ct=10.0602 rec=1.2558 | train/val/test=1.000/0.832/0.832 | c=0.999488
[Epoch 0034] loss=2.8024 cls=0.4103 smmd=0.2553 ct=10.0590 rec=1.2499 | train/val/test=1.000/0.835/0.835 | c=0.999488
[Epoch 0035] loss=2.7685 cls=0.3817 smmd=0.2503 ct=10.0604 rec=1.2442 | train/val/test=1.000/0.837/0.839 | c=0.999488
[Epoch 0036] loss=2.7312 cls=0.3551 smmd=0.2393 ct=10.0643 rec=1.2388 | train/val/test=1.000/0.840/0.843 | c=0.999488
[Epoch 0037] loss=2.7048 cls=0.3303 smmd=0.2379 ct=10.0661 rec=1.2339 | train/val/test=1.000/0.841/0.846 | c=0.999488
[Epoch 0038] loss=2.6710 cls=0.3074 smmd=0.2278 ct=10.0645 rec=1.2294 | train/val/test=1.000/0.840/0.847 | c=0.999488
[Epoch 0039] loss=2.6378 cls=0.2860 smmd=0.2166 ct=10.0631 rec=1.2253 | train/val/test=1.000/0.842/0.849 | c=0.999488
[Epoch 0040] loss=2.6140 cls=0.2662 smmd=0.2131 ct=10.0631 rec=1.2214 | train/val/test=1.000/0.841/0.850 | c=0.999488
[Epoch 0041] loss=2.5866 cls=0.2478 smmd=0.2044 ct=10.0629 rec=1.2179 | train/val/test=1.000/0.845/0.852 | c=0.999488
[Epoch 0042] loss=2.5611 cls=0.2308 smmd=0.1965 ct=10.0616 rec=1.2149 | train/val/test=1.000/0.848/0.852 | c=0.999488
[Epoch 0043] loss=2.5332 cls=0.2151 smmd=0.1847 ct=10.0611 rec=1.2121 | train/val/test=1.000/0.850/0.854 | c=0.999488
[Epoch 0044] loss=2.5112 cls=0.2009 smmd=0.1775 ct=10.0596 rec=1.2094 | train/val/test=1.000/0.850/0.855 | c=0.999488
[Epoch 0045] loss=2.4937 cls=0.1879 smmd=0.1737 ct=10.0569 rec=1.2068 | train/val/test=1.000/0.851/0.856 | c=0.999488
[Epoch 0046] loss=2.4692 cls=0.1761 smmd=0.1620 ct=10.0527 rec=1.2045 | train/val/test=1.000/0.852/0.856 | c=0.999488
[Epoch 0047] loss=2.4516 cls=0.1654 smmd=0.1564 ct=10.0479 rec=1.2024 | train/val/test=1.000/0.852/0.856 | c=0.999488
[Epoch 0048] loss=2.4327 cls=0.1557 smmd=0.1481 ct=10.0440 rec=1.2006 | train/val/test=1.000/0.850/0.857 | c=0.999488
[Epoch 0049] loss=2.4184 cls=0.1470 smmd=0.1434 ct=10.0406 rec=1.1991 | train/val/test=1.000/0.852/0.857 | c=0.999488
[Epoch 0050] loss=2.4013 cls=0.1391 smmd=0.1351 ct=10.0368 rec=1.1977 | train/val/test=1.000/0.852/0.857 | c=0.999488
[Epoch 0051] loss=2.3868 cls=0.1319 smmd=0.1288 ct=10.0318 rec=1.1964 | train/val/test=1.000/0.852/0.858 | c=0.999488
[Epoch 0052] loss=2.3734 cls=0.1255 smmd=0.1230 ct=10.0267 rec=1.1953 | train/val/test=1.000/0.852/0.859 | c=0.999488
[Epoch 0053] loss=2.3619 cls=0.1197 smmd=0.1181 ct=10.0232 rec=1.1943 | train/val/test=1.000/0.852/0.859 | c=0.999488
[Epoch 0054] loss=2.3525 cls=0.1144 smmd=0.1148 ct=10.0197 rec=1.1933 | train/val/test=1.000/0.853/0.858 | c=0.999488
[Epoch 0055] loss=2.3441 cls=0.1098 smmd=0.1122 ct=10.0145 rec=1.1924 | train/val/test=1.000/0.853/0.859 | c=0.999488
[Epoch 0056] loss=2.3350 cls=0.1055 smmd=0.1087 ct=10.0084 rec=1.1918 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0057] loss=2.3244 cls=0.1017 smmd=0.1029 ct=10.0034 rec=1.1912 | train/val/test=1.000/0.853/0.859 | c=0.999488
[Epoch 0058] loss=2.3201 cls=0.0981 smmd=0.1028 ct=10.0003 rec=1.1906 | train/val/test=1.000/0.855/0.860 | c=0.999488
[Epoch 0059] loss=2.3131 cls=0.0948 smmd=0.0998 ct=9.9975 rec=1.1900 | train/val/test=1.000/0.856/0.860 | c=0.999488
[Epoch 0060] loss=2.3055 cls=0.0918 smmd=0.0959 ct=9.9938 rec=1.1895 | train/val/test=1.000/0.856/0.860 | c=0.999488
[Epoch 0061] loss=2.3021 cls=0.0890 smmd=0.0965 ct=9.9886 rec=1.1891 | train/val/test=1.000/0.856/0.859 | c=0.999488
[Epoch 0062] loss=2.2969 cls=0.0864 smmd=0.0947 ct=9.9849 rec=1.1885 | train/val/test=1.000/0.857/0.860 | c=0.999488
[Epoch 0063] loss=2.2934 cls=0.0839 smmd=0.0942 ct=9.9824 rec=1.1880 | train/val/test=1.000/0.857/0.862 | c=0.999488
[Epoch 0064] loss=2.2895 cls=0.0816 smmd=0.0931 ct=9.9803 rec=1.1876 | train/val/test=1.000/0.856/0.861 | c=0.999488
[Epoch 0065] loss=2.2837 cls=0.0793 smmd=0.0901 ct=9.9777 rec=1.1872 | train/val/test=1.000/0.855/0.862 | c=0.999488
[Epoch 0066] loss=2.2820 cls=0.0772 smmd=0.0913 ct=9.9748 rec=1.1866 | train/val/test=1.000/0.857/0.862 | c=0.999488
[Epoch 0067] loss=2.2783 cls=0.0750 smmd=0.0901 ct=9.9729 rec=1.1859 | train/val/test=1.000/0.855/0.862 | c=0.999488
[Epoch 0068] loss=2.2757 cls=0.0729 smmd=0.0899 ct=9.9720 rec=1.1853 | train/val/test=1.000/0.855/0.862 | c=0.999488
[Epoch 0069] loss=2.2718 cls=0.0708 smmd=0.0885 ct=9.9701 rec=1.1847 | train/val/test=1.000/0.857/0.862 | c=0.999488
[Epoch 0070] loss=2.2700 cls=0.0689 smmd=0.0895 ct=9.9662 rec=1.1840 | train/val/test=1.000/0.854/0.862 | c=0.999488
[Epoch 0071] loss=2.2674 cls=0.0669 smmd=0.0889 ct=9.9660 rec=1.1834 | train/val/test=1.000/0.855/0.862 | c=0.999488
[Epoch 0072] loss=2.2653 cls=0.0649 smmd=0.0886 ct=9.9673 rec=1.1828 | train/val/test=1.000/0.855/0.861 | c=0.999488
[Epoch 0073] loss=2.2626 cls=0.0630 smmd=0.0885 ct=9.9647 rec=1.1819 | train/val/test=1.000/0.856/0.861 | c=0.999488
[Epoch 0074] loss=2.2602 cls=0.0611 smmd=0.0882 ct=9.9639 rec=1.1811 | train/val/test=1.000/0.855/0.862 | c=0.999488
[Epoch 0075] loss=2.2597 cls=0.0593 smmd=0.0898 ct=9.9623 rec=1.1806 | train/val/test=1.000/0.855/0.861 | c=0.999488
[Epoch 0076] loss=2.2566 cls=0.0576 smmd=0.0886 ct=9.9618 rec=1.1798 | train/val/test=1.000/0.855/0.861 | c=0.999488
[Epoch 0077] loss=2.2540 cls=0.0558 smmd=0.0879 ct=9.9617 rec=1.1789 | train/val/test=1.000/0.855/0.861 | c=0.999488
[Epoch 0078] loss=2.2529 cls=0.0542 smmd=0.0888 ct=9.9601 rec=1.1781 | train/val/test=1.000/0.855/0.860 | c=0.999488
[Epoch 0079] loss=2.2503 cls=0.0526 smmd=0.0877 ct=9.9611 rec=1.1775 | train/val/test=1.000/0.856/0.859 | c=0.999488
[Epoch 0080] loss=2.2484 cls=0.0510 smmd=0.0875 ct=9.9611 rec=1.1769 | train/val/test=1.000/0.856/0.860 | c=0.999488
[Epoch 0081] loss=2.2479 cls=0.0496 smmd=0.0890 ct=9.9584 rec=1.1761 | train/val/test=1.000/0.857/0.860 | c=0.999488
[Epoch 0082] loss=2.2448 cls=0.0482 smmd=0.0875 ct=9.9579 rec=1.1754 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0083] loss=2.2436 cls=0.0468 smmd=0.0871 ct=9.9613 rec=1.1748 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0084] loss=2.2420 cls=0.0456 smmd=0.0874 ct=9.9579 rec=1.1743 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0085] loss=2.2409 cls=0.0444 smmd=0.0878 ct=9.9569 rec=1.1736 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0086] loss=2.2385 cls=0.0432 smmd=0.0860 ct=9.9604 rec=1.1731 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0087] loss=2.2379 cls=0.0422 smmd=0.0873 ct=9.9558 rec=1.1726 | train/val/test=1.000/0.857/0.859 | c=0.999488
[Epoch 0088] loss=2.2370 cls=0.0412 smmd=0.0876 ct=9.9548 rec=1.1722 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0089] loss=2.2355 cls=0.0402 smmd=0.0864 ct=9.9582 rec=1.1717 | train/val/test=1.000/0.855/0.857 | c=0.999488
[Epoch 0090] loss=2.2339 cls=0.0394 smmd=0.0864 ct=9.9553 rec=1.1711 | train/val/test=1.000/0.856/0.858 | c=0.999488
[Epoch 0091] loss=2.2343 cls=0.0385 smmd=0.0881 ct=9.9530 rec=1.1709 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0092] loss=2.2316 cls=0.0377 smmd=0.0858 ct=9.9549 rec=1.1705 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0093] loss=2.2309 cls=0.0370 smmd=0.0859 ct=9.9550 rec=1.1702 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0094] loss=2.2304 cls=0.0363 smmd=0.0868 ct=9.9515 rec=1.1700 | train/val/test=1.000/0.855/0.857 | c=0.999488
[Epoch 0095] loss=2.2295 cls=0.0357 smmd=0.0867 ct=9.9506 rec=1.1695 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0096] loss=2.2281 cls=0.0351 smmd=0.0861 ct=9.9499 rec=1.1694 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0097] loss=2.2276 cls=0.0346 smmd=0.0860 ct=9.9503 rec=1.1692 | train/val/test=1.000/0.855/0.857 | c=0.999488
[Epoch 0098] loss=2.2258 cls=0.0341 smmd=0.0852 ct=9.9482 rec=1.1689 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0099] loss=2.2250 cls=0.0336 smmd=0.0851 ct=9.9473 rec=1.1686 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0100] loss=2.2250 cls=0.0331 smmd=0.0856 ct=9.9469 rec=1.1687 | train/val/test=1.000/0.855/0.857 | c=0.999488
[Epoch 0101] loss=2.2227 cls=0.0328 smmd=0.0842 ct=9.9445 rec=1.1682 | train/val/test=1.000/0.855/0.857 | c=0.999488
[Epoch 0102] loss=2.2229 cls=0.0324 smmd=0.0851 ct=9.9431 rec=1.1682 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0103] loss=2.2215 cls=0.0320 smmd=0.0839 ct=9.9441 rec=1.1682 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0104] loss=2.2212 cls=0.0316 smmd=0.0844 ct=9.9418 rec=1.1679 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0105] loss=2.2211 cls=0.0313 smmd=0.0850 ct=9.9396 rec=1.1678 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0106] loss=2.2196 cls=0.0310 smmd=0.0840 ct=9.9394 rec=1.1677 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0107] loss=2.2190 cls=0.0307 smmd=0.0839 ct=9.9383 rec=1.1675 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0108] loss=2.2167 cls=0.0305 smmd=0.0826 ct=9.9346 rec=1.1675 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0109] loss=2.2167 cls=0.0301 smmd=0.0826 ct=9.9365 rec=1.1673 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0110] loss=2.2162 cls=0.0299 smmd=0.0826 ct=9.9353 rec=1.1672 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0111] loss=2.2148 cls=0.0296 smmd=0.0821 ct=9.9320 rec=1.1672 | train/val/test=1.000/0.854/0.858 | c=0.999488
[Epoch 0112] loss=2.2152 cls=0.0293 smmd=0.0829 ct=9.9315 rec=1.1670 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0113] loss=2.2146 cls=0.0291 smmd=0.0827 ct=9.9303 rec=1.1669 | train/val/test=1.000/0.854/0.859 | c=0.999488
[Epoch 0114] loss=2.2131 cls=0.0288 smmd=0.0816 ct=9.9304 rec=1.1669 | train/val/test=1.000/0.854/0.858 | c=0.999488
[Epoch 0115] loss=2.2131 cls=0.0286 smmd=0.0822 ct=9.9285 rec=1.1667 | train/val/test=1.000/0.854/0.859 | c=0.999488
[Epoch 0116] loss=2.2119 cls=0.0284 smmd=0.0817 ct=9.9261 rec=1.1667 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0117] loss=2.2112 cls=0.0281 smmd=0.0809 ct=9.9279 rec=1.1665 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0118] loss=2.2098 cls=0.0279 smmd=0.0804 ct=9.9243 rec=1.1663 | train/val/test=1.000/0.854/0.859 | c=0.999488
[Epoch 0119] loss=2.2106 cls=0.0277 smmd=0.0814 ct=9.9242 rec=1.1665 | train/val/test=1.000/0.853/0.858 | c=0.999488
[Epoch 0120] loss=2.2103 cls=0.0275 smmd=0.0820 ct=9.9211 rec=1.1662 | train/val/test=1.000/0.853/0.858 | c=0.999488
[Epoch 0121] loss=2.2087 cls=0.0272 smmd=0.0803 ct=9.9228 rec=1.1661 | train/val/test=1.000/0.854/0.859 | c=0.999488
[Epoch 0122] loss=2.2085 cls=0.0270 smmd=0.0805 ct=9.9220 rec=1.1661 | train/val/test=1.000/0.854/0.858 | c=0.999488
[Epoch 0123] loss=2.2069 cls=0.0269 smmd=0.0797 ct=9.9187 rec=1.1658 | train/val/test=1.000/0.854/0.859 | c=0.999488
[Epoch 0124] loss=2.2063 cls=0.0267 smmd=0.0795 ct=9.9174 rec=1.1660 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0125] loss=2.2055 cls=0.0265 smmd=0.0788 ct=9.9181 rec=1.1657 | train/val/test=1.000/0.854/0.858 | c=0.999488
[Epoch 0126] loss=2.2050 cls=0.0263 smmd=0.0790 ct=9.9160 rec=1.1656 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0127] loss=2.2036 cls=0.0261 smmd=0.0781 ct=9.9140 rec=1.1657 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0128] loss=2.2039 cls=0.0259 smmd=0.0785 ct=9.9147 rec=1.1653 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0129] loss=2.2032 cls=0.0257 smmd=0.0784 ct=9.9124 rec=1.1655 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0130] loss=2.2028 cls=0.0256 smmd=0.0782 ct=9.9129 rec=1.1652 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0131] loss=2.2021 cls=0.0254 smmd=0.0779 ct=9.9113 rec=1.1652 | train/val/test=1.000/0.854/0.858 | c=0.999488
[Epoch 0132] loss=2.2009 cls=0.0253 smmd=0.0778 ct=9.9066 rec=1.1652 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0133] loss=2.2007 cls=0.0250 smmd=0.0771 ct=9.9103 rec=1.1648 | train/val/test=1.000/0.854/0.858 | c=0.999488
[Epoch 0134] loss=2.1999 cls=0.0249 smmd=0.0768 ct=9.9083 rec=1.1649 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0135] loss=2.2000 cls=0.0247 smmd=0.0775 ct=9.9064 rec=1.1648 | train/val/test=1.000/0.857/0.859 | c=0.999488
[Epoch 0136] loss=2.1984 cls=0.0246 smmd=0.0761 ct=9.9060 rec=1.1648 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0137] loss=2.1984 cls=0.0245 smmd=0.0767 ct=9.9037 rec=1.1645 | train/val/test=1.000/0.855/0.859 | c=0.999488
[Epoch 0138] loss=2.1975 cls=0.0243 smmd=0.0758 ct=9.9047 rec=1.1646 | train/val/test=1.000/0.855/0.857 | c=0.999488
[Epoch 0139] loss=2.1967 cls=0.0243 smmd=0.0762 ct=9.8993 rec=1.1644 | train/val/test=1.000/0.855/0.858 | c=0.999488
[Epoch 0140] loss=2.1958 cls=0.0240 smmd=0.0745 ct=9.9040 rec=1.1644 | train/val/test=1.000/0.857/0.858 | c=0.999488
[Epoch 0141] loss=2.1956 cls=0.0240 smmd=0.0756 ct=9.8982 rec=1.1643 | train/val/test=1.000/0.854/0.857 | c=0.999488
[Epoch 0142] loss=2.1959 cls=0.0238 smmd=0.0762 ct=9.8972 rec=1.1643 | train/val/test=1.000/0.855/0.857 | c=0.999488
[Epoch 0143] loss=2.1947 cls=0.0237 smmd=0.0748 ct=9.8988 rec=1.1640 | train/val/test=1.000/0.857/0.859 | c=0.999488
[Epoch 0144] loss=2.1933 cls=0.0236 smmd=0.0740 ct=9.8962 rec=1.1643 | train/val/test=1.000/0.854/0.856 | c=0.999488
[Epoch 0145] loss=2.1937 cls=0.0235 smmd=0.0747 ct=9.8952 rec=1.1636 | train/val/test=1.000/0.857/0.859 | c=0.999488
[Epoch 0146] loss=2.1928 cls=0.0235 smmd=0.0743 ct=9.8932 rec=1.1643 | train/val/test=1.000/0.855/0.857 | c=0.999488
[Epoch 0147] loss=2.1923 cls=0.0233 smmd=0.0737 ct=9.8949 rec=1.1634 | train/val/test=1.000/0.857/0.859 | c=0.999488
[Epoch 0148] loss=2.1926 cls=0.0231 smmd=0.0747 ct=9.8920 rec=1.1641 | train/val/test=1.000/0.855/0.857 | c=0.999488
[Epoch 0149] loss=2.1920 cls=0.0232 smmd=0.0749 ct=9.8881 rec=1.1633 | train/val/test=1.000/0.857/0.859 | c=0.999488
[Epoch 0150] loss=2.1909 cls=0.0229 smmd=0.0731 ct=9.8923 rec=1.1638 | train/val/test=1.000/0.855/0.857 | c=0.999488
[Epoch 0151] loss=2.1889 cls=0.0229 smmd=0.0723 ct=9.8872 rec=1.1632 | train/val/test=1.000/0.857/0.859 | c=0.999488
[Epoch 0152] loss=2.1902 cls=0.0227 smmd=0.0736 ct=9.8875 rec=1.1636 | train/val/test=1.000/0.854/0.857 | c=0.999488
[Epoch 0153] loss=2.1900 cls=0.0227 smmd=0.0733 ct=9.8887 rec=1.1630 | train/val/test=1.000/0.857/0.859 | c=0.999488
[Epoch 0154] loss=2.1892 cls=0.0226 smmd=0.0735 ct=9.8838 rec=1.1634 | train/val/test=1.000/0.853/0.856 | c=0.999488
[Epoch 0155] loss=2.1874 cls=0.0226 smmd=0.0715 ct=9.8851 rec=1.1629 | train/val/test=1.000/0.858/0.860 | c=0.999488
[Epoch 0156] loss=2.1890 cls=0.0224 smmd=0.0732 ct=9.8852 rec=1.1634 | train/val/test=1.000/0.856/0.857 | c=0.999488
[Epoch 0157] loss=2.1885 cls=0.0226 smmd=0.0738 ct=9.8792 rec=1.1627 | train/val/test=1.000/0.857/0.860 | c=0.999488
[Epoch 0158] loss=2.1886 cls=0.0222 smmd=0.0729 ct=9.8858 rec=1.1633 | train/val/test=1.000/0.853/0.856 | c=0.999488
[Epoch 0159] loss=2.1874 cls=0.0226 smmd=0.0730 ct=9.8776 rec=1.1626 | train/val/test=1.000/0.859/0.860 | c=0.999488
[Epoch 0160] loss=2.1872 cls=0.0223 smmd=0.0716 ct=9.8844 rec=1.1638 | train/val/test=1.000/0.851/0.855 | c=0.999488
[Epoch 0161] loss=2.1894 cls=0.0231 smmd=0.0753 ct=9.8741 rec=1.1625 | train/val/test=1.000/0.861/0.862 | c=0.999488
[Epoch 0162] loss=2.1886 cls=0.0227 smmd=0.0715 ct=9.8896 rec=1.1650 | train/val/test=1.000/0.851/0.853 | c=0.999488
[Epoch 0163] loss=2.1922 cls=0.0239 smmd=0.0778 ct=9.8714 rec=1.1626 | train/val/test=1.000/0.861/0.862 | c=0.999488
[Epoch 0164] loss=2.1934 cls=0.0238 smmd=0.0753 ct=9.8883 rec=1.1672 | train/val/test=1.000/0.849/0.852 | c=0.999488
[Epoch 0165] loss=2.1949 cls=0.0251 smmd=0.0775 ct=9.8802 rec=1.1628 | train/val/test=1.000/0.861/0.862 | c=0.999488
[Epoch 0166] loss=2.1944 cls=0.0242 smmd=0.0769 ct=9.8824 rec=1.1682 | train/val/test=1.000/0.848/0.852 | c=0.999488
[Epoch 0167] loss=2.1930 cls=0.0238 smmd=0.0769 ct=9.8808 rec=1.1619 | train/val/test=1.000/0.860/0.863 | c=0.999488
[Epoch 0168] loss=2.1859 cls=0.0217 smmd=0.0725 ct=9.8759 rec=1.1646 | train/val/test=1.000/0.853/0.857 | c=0.999488
[Epoch 0169] loss=2.1823 cls=0.0208 smmd=0.0709 ct=9.8729 rec=1.1601 | train/val/test=1.000/0.853/0.857 | c=0.999488
[Epoch 0170] loss=2.1807 cls=0.0206 smmd=0.0690 ct=9.8744 rec=1.1616 | train/val/test=1.000/0.863/0.864 | c=0.999488
[Epoch 0171] loss=2.1844 cls=0.0210 smmd=0.0715 ct=9.8781 rec=1.1623 | train/val/test=1.000/0.850/0.853 | c=0.999488
[Epoch 0172] loss=2.1853 cls=0.0219 smmd=0.0732 ct=9.8701 rec=1.1618 | train/val/test=1.000/0.863/0.863 | c=0.999488
[Epoch 0173] loss=2.1847 cls=0.0208 smmd=0.0714 ct=9.8812 rec=1.1628 | train/val/test=1.000/0.852/0.855 | c=0.999488
[Epoch 0174] loss=2.1814 cls=0.0203 smmd=0.0720 ct=9.8653 rec=1.1606 | train/val/test=1.000/0.856/0.859 | c=0.999488
[Epoch 0175] loss=2.1791 cls=0.0194 smmd=0.0690 ct=9.8736 rec=1.1601 | train/val/test=1.000/0.859/0.862 | c=0.999488
[Epoch 0176] loss=2.1779 cls=0.0195 smmd=0.0683 ct=9.8701 rec=1.1609 | train/val/test=1.000/0.850/0.854 | c=0.999488
[Epoch 0177] loss=2.1794 cls=0.0202 smmd=0.0704 ct=9.8639 rec=1.1602 | train/val/test=1.000/0.863/0.863 | c=0.999488
[Epoch 0178] loss=2.1791 cls=0.0198 smmd=0.0682 ct=9.8745 rec=1.1621 | train/val/test=1.000/0.852/0.854 | c=0.999488
[Epoch 0179] loss=2.1783 cls=0.0201 smmd=0.0693 ct=9.8643 rec=1.1602 | train/val/test=1.000/0.856/0.860 | c=0.999488
[Epoch 0180] loss=2.1759 cls=0.0192 smmd=0.0669 ct=9.8686 rec=1.1606 | train/val/test=1.000/0.858/0.861 | c=0.999488
[Epoch 0181] loss=2.1763 cls=0.0192 smmd=0.0688 ct=9.8615 rec=1.1602 | train/val/test=1.000/0.852/0.856 | c=0.999488
[Epoch 0182] loss=2.1749 cls=0.0192 smmd=0.0673 ct=9.8621 rec=1.1596 | train/val/test=1.000/0.859/0.862 | c=0.999488
[Epoch 0183] loss=2.1753 cls=0.0193 smmd=0.0672 ct=9.8636 rec=1.1614 | train/val/test=1.000/0.852/0.855 | c=0.999488
[Epoch 0184] loss=2.1755 cls=0.0198 smmd=0.0678 ct=9.8598 rec=1.1596 | train/val/test=1.000/0.859/0.862 | c=0.999488
[Epoch 0185] loss=2.1749 cls=0.0194 smmd=0.0668 ct=9.8625 rec=1.1620 | train/val/test=1.000/0.852/0.856 | c=0.999488
[Epoch 0186] loss=2.1746 cls=0.0196 smmd=0.0673 ct=9.8585 rec=1.1594 | train/val/test=1.000/0.856/0.860 | c=0.999488
[Epoch 0187] loss=2.1730 cls=0.0192 smmd=0.0661 ct=9.8573 rec=1.1615 | train/val/test=1.000/0.852/0.858 | c=0.999488
[Epoch 0188] loss=2.1738 cls=0.0194 smmd=0.0668 ct=9.8588 rec=1.1593 | train/val/test=1.000/0.854/0.859 | c=0.999488
[Epoch 0189] loss=2.1758 cls=0.0197 smmd=0.0694 ct=9.8524 rec=1.1619 | train/val/test=1.000/0.850/0.857 | c=0.999488
[Epoch 0190] loss=2.1767 cls=0.0203 smmd=0.0677 ct=9.8639 rec=1.1596 | train/val/test=1.000/0.851/0.858 | c=0.999488
[Epoch 0191] loss=2.1816 cls=0.0222 smmd=0.0728 ct=9.8508 rec=1.1646 | train/val/test=1.000/0.844/0.851 | c=0.999488
[Epoch 0192] loss=2.1944 cls=0.0258 smmd=0.0760 ct=9.8821 rec=1.1618 | train/val/test=1.000/0.843/0.844 | c=0.999488
[Epoch 0193] loss=2.2307 cls=0.0413 smmd=0.0974 ct=9.8717 rec=1.1766 | train/val/test=0.923/0.772/0.783 | c=0.999488
[Epoch 0194] loss=2.4328 cls=0.1580 smmd=0.1487 ct=10.0260 rec=1.2093 | train/val/test=0.615/0.486/0.473 | c=0.999488
[Epoch 0195] loss=4.8872 cls=1.8374 smmd=0.8561 ct=10.3126 rec=1.3124 | train/val/test=0.538/0.377/0.392 | c=0.999488
[Epoch 0196] loss=6.0640 cls=2.5548 smmd=1.2444 ct=10.6650 rec=1.3183 | train/val/test=0.205/0.129/0.143 | c=0.999488
[Epoch 0197] loss=8.5673 cls=4.6483 smmd=1.6364 ct=10.6312 rec=1.5633 | train/val/test=0.333/0.367/0.355 | c=0.999488
[Epoch 0198] loss=7.6664 cls=3.7236 smmd=1.7400 ct=10.2677 rec=1.4923 | train/val/test=0.615/0.455/0.467 | c=0.999488
[Epoch 0199] loss=7.1727 cls=2.6282 smmd=2.3458 ct=10.3559 rec=1.2757 | train/val/test=0.590/0.484/0.494 | c=0.999488
=== Best @ epoch 172: val=0.8633, test=0.8630 ===
[2025-09-20 03:19:38] END attempt 1: exit_code=0
