[2025-09-20 03:52:03] START attempt 1: python main.py --is_transfer True --test_dataset PubMed --pretrained_model_name /mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth --few True --shot 5 --gpu_id 0
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.4496 cls=1.1015 smmd=5.5623 ct=11.2864 rec=1.4136 | train/val/test=0.385/0.388/0.413 | c=0.998437
[Epoch 0001] loss=22.4113 cls=1.0903 smmd=3.9628 ct=11.2522 rec=1.4136 | train/val/test=0.692/0.496/0.515 | c=0.998437
[Epoch 0002] loss=24.2636 cls=1.0830 smmd=4.7033 ct=11.2570 rec=1.4136 | train/val/test=0.538/0.484/0.522 | c=0.998437
[Epoch 0003] loss=22.9770 cls=1.0601 smmd=4.2341 ct=11.1550 rec=1.4136 | train/val/test=0.538/0.538/0.574 | c=0.998437
[Epoch 0004] loss=18.9472 cls=1.0213 smmd=2.4095 ct=11.7063 rec=1.4133 | train/val/test=0.538/0.514/0.559 | c=0.998437
[Epoch 0005] loss=20.3613 cls=0.9835 smmd=3.0987 ct=11.4158 rec=1.4141 | train/val/test=0.538/0.546/0.579 | c=0.998437
[Epoch 0006] loss=20.7312 cls=0.9375 smmd=3.2757 ct=11.3678 rec=1.4106 | train/val/test=0.769/0.536/0.557 | c=0.998437
[Epoch 0007] loss=18.8557 cls=0.8969 smmd=2.5220 ct=11.3988 rec=1.4068 | train/val/test=0.769/0.538/0.562 | c=0.998437
[Epoch 0008] loss=17.2833 cls=0.8637 smmd=1.8791 ct=11.4515 rec=1.4045 | train/val/test=0.846/0.570/0.595 | c=0.998437
[Epoch 0009] loss=18.7279 cls=0.8448 smmd=2.4073 ct=11.5850 rec=1.4044 | train/val/test=0.692/0.554/0.583 | c=0.998437
[Epoch 0010] loss=18.5740 cls=0.8308 smmd=2.3610 ct=11.5527 rec=1.4069 | train/val/test=0.769/0.564/0.597 | c=0.998437
[Epoch 0011] loss=16.4970 cls=0.8124 smmd=1.5614 ct=11.4837 rec=1.4070 | train/val/test=0.846/0.634/0.655 | c=0.998437
[Epoch 0012] loss=18.5380 cls=0.7967 smmd=2.3525 ct=11.5556 rec=1.4054 | train/val/test=0.846/0.560/0.599 | c=0.998437
[Epoch 0013] loss=17.7801 cls=0.7421 smmd=2.1239 ct=11.3964 rec=1.4057 | train/val/test=0.923/0.670/0.693 | c=0.998437
[Epoch 0014] loss=16.4405 cls=0.6755 smmd=1.6040 ct=11.3948 rec=1.3960 | train/val/test=0.923/0.678/0.692 | c=0.998437
[Epoch 0015] loss=16.5897 cls=0.6087 smmd=1.6260 ct=11.5247 rec=1.3915 | train/val/test=0.923/0.678/0.684 | c=0.998437
[Epoch 0016] loss=16.2621 cls=0.5616 smmd=1.4997 ct=11.5388 rec=1.3865 | train/val/test=0.923/0.672/0.701 | c=0.998437
[Epoch 0017] loss=15.5701 cls=0.5326 smmd=1.2625 ct=11.4576 rec=1.3799 | train/val/test=0.923/0.668/0.689 | c=0.998437
[Epoch 0018] loss=15.7385 cls=0.5219 smmd=1.3551 ct=11.4004 rec=1.3789 | train/val/test=0.923/0.694/0.707 | c=0.998437
[Epoch 0019] loss=15.3703 cls=0.5041 smmd=1.2106 ct=11.4014 rec=1.3808 | train/val/test=0.923/0.696/0.709 | c=0.998437
[Epoch 0020] loss=15.4094 cls=0.5074 smmd=1.1932 ct=11.4807 rec=1.3839 | train/val/test=0.923/0.682/0.699 | c=0.998437
[Epoch 0021] loss=15.4731 cls=0.5124 smmd=1.2067 ct=11.5053 rec=1.3899 | train/val/test=1.000/0.714/0.706 | c=0.998437
[Epoch 0022] loss=15.3428 cls=0.5089 smmd=1.1589 ct=11.4963 rec=1.3893 | train/val/test=0.846/0.670/0.689 | c=0.998437
[Epoch 0023] loss=15.3688 cls=0.4851 smmd=1.1931 ct=11.4471 rec=1.3929 | train/val/test=1.000/0.718/0.713 | c=0.998437
[Epoch 0024] loss=15.0005 cls=0.4511 smmd=1.0324 ct=11.5030 rec=1.3816 | train/val/test=0.923/0.672/0.709 | c=0.998437
[Epoch 0025] loss=14.7630 cls=0.3992 smmd=0.9693 ct=11.4491 rec=1.3820 | train/val/test=1.000/0.696/0.711 | c=0.998437
[Epoch 0026] loss=14.5991 cls=0.3631 smmd=0.9109 ct=11.4559 rec=1.3688 | train/val/test=1.000/0.704/0.718 | c=0.998437
[Epoch 0027] loss=14.4312 cls=0.3268 smmd=0.8562 ct=11.4441 rec=1.3662 | train/val/test=1.000/0.710/0.718 | c=0.998437
[Epoch 0028] loss=14.1877 cls=0.3115 smmd=0.7494 ct=11.4775 rec=1.3621 | train/val/test=1.000/0.720/0.719 | c=0.998437
[Epoch 0029] loss=14.4120 cls=0.3127 smmd=0.8542 ct=11.4389 rec=1.3628 | train/val/test=1.000/0.710/0.717 | c=0.998437
[Epoch 0030] loss=14.2707 cls=0.3051 smmd=0.7958 ct=11.4454 rec=1.3665 | train/val/test=1.000/0.720/0.719 | c=0.998437
[Epoch 0031] loss=14.5294 cls=0.3061 smmd=0.8688 ct=11.5225 rec=1.3637 | train/val/test=1.000/0.702/0.712 | c=0.998437
[Epoch 0032] loss=14.4935 cls=0.2908 smmd=0.8893 ct=11.4417 rec=1.3662 | train/val/test=1.000/0.710/0.725 | c=0.998437
[Epoch 0033] loss=14.2544 cls=0.2777 smmd=0.7730 ct=11.5046 rec=1.3572 | train/val/test=1.000/0.698/0.714 | c=0.998437
[Epoch 0034] loss=14.2663 cls=0.2478 smmd=0.8063 ct=11.4493 rec=1.3547 | train/val/test=1.000/0.714/0.720 | c=0.998437
[Epoch 0035] loss=13.8259 cls=0.2293 smmd=0.6437 ct=11.4297 rec=1.3444 | train/val/test=1.000/0.714/0.718 | c=0.998437
[Epoch 0036] loss=13.8641 cls=0.2124 smmd=0.6459 ct=11.4722 rec=1.3418 | train/val/test=1.000/0.712/0.715 | c=0.998437
[Epoch 0037] loss=13.7468 cls=0.2129 smmd=0.6008 ct=11.4673 rec=1.3423 | train/val/test=1.000/0.710/0.721 | c=0.998437
[Epoch 0038] loss=13.7742 cls=0.2196 smmd=0.6311 ct=11.4128 rec=1.3477 | train/val/test=1.000/0.714/0.716 | c=0.998437
[Epoch 0039] loss=13.8519 cls=0.2378 smmd=0.6298 ct=11.4826 rec=1.3521 | train/val/test=1.000/0.690/0.700 | c=0.998437
[Epoch 0040] loss=14.1931 cls=0.2476 smmd=0.7673 ct=11.4683 rec=1.3653 | train/val/test=1.000/0.688/0.703 | c=0.998437
[Epoch 0041] loss=14.0678 cls=0.2500 smmd=0.6941 ct=11.5296 rec=1.3560 | train/val/test=1.000/0.682/0.689 | c=0.998437
[Epoch 0042] loss=14.2397 cls=0.2431 smmd=0.7835 ct=11.4759 rec=1.3672 | train/val/test=1.000/0.678/0.680 | c=0.998437
[Epoch 0043] loss=13.7988 cls=0.2042 smmd=0.6046 ct=11.5129 rec=1.3444 | train/val/test=1.000/0.694/0.714 | c=0.998437
[Epoch 0044] loss=13.8520 cls=0.1685 smmd=0.6651 ct=11.4386 rec=1.3328 | train/val/test=1.000/0.710/0.707 | c=0.998437
[Epoch 0045] loss=13.5592 cls=0.1374 smmd=0.5407 ct=11.4781 rec=1.3210 | train/val/test=1.000/0.712/0.709 | c=0.998437
[Epoch 0046] loss=13.4526 cls=0.1328 smmd=0.5073 ct=11.4577 rec=1.3204 | train/val/test=1.000/0.708/0.718 | c=0.998437
[Epoch 0047] loss=13.5863 cls=0.1415 smmd=0.5738 ct=11.4181 rec=1.3260 | train/val/test=1.000/0.722/0.713 | c=0.998437
[Epoch 0048] loss=13.6771 cls=0.1607 smmd=0.5747 ct=11.4926 rec=1.3351 | train/val/test=1.000/0.706/0.712 | c=0.998437
[Epoch 0049] loss=14.0678 cls=0.1839 smmd=0.7278 ct=11.4798 rec=1.3531 | train/val/test=1.000/0.678/0.701 | c=0.998437
[Epoch 0050] loss=14.2187 cls=0.2258 smmd=0.7628 ct=11.5222 rec=1.3532 | train/val/test=1.000/0.622/0.628 | c=0.998437
[Epoch 0051] loss=14.3152 cls=0.2519 smmd=0.7930 ct=11.5088 rec=1.3956 | train/val/test=1.000/0.614/0.631 | c=0.998437
[Epoch 0052] loss=13.8096 cls=0.2220 smmd=0.5703 ct=11.5988 rec=1.3483 | train/val/test=1.000/0.702/0.722 | c=0.998437
[Epoch 0053] loss=13.7634 cls=0.1167 smmd=0.6531 ct=11.4135 rec=1.3177 | train/val/test=1.000/0.718/0.719 | c=0.998437
[Epoch 0054] loss=13.2315 cls=0.0927 smmd=0.4437 ct=11.4238 rec=1.3042 | train/val/test=1.000/0.696/0.703 | c=0.998437
[Epoch 0055] loss=13.5150 cls=0.1151 smmd=0.5097 ct=11.5243 rec=1.3179 | train/val/test=1.000/0.712/0.727 | c=0.998437
[Epoch 0056] loss=13.4586 cls=0.1065 smmd=0.5283 ct=11.4281 rec=1.3132 | train/val/test=1.000/0.726/0.728 | c=0.998437
[Epoch 0057] loss=13.4712 cls=0.1165 smmd=0.5195 ct=11.4546 rec=1.3194 | train/val/test=1.000/0.730/0.719 | c=0.998437
[Epoch 0058] loss=14.0108 cls=0.1413 smmd=0.7015 ct=11.5194 rec=1.3338 | train/val/test=1.000/0.730/0.739 | c=0.998437
[Epoch 0059] loss=14.2800 cls=0.1540 smmd=0.8292 ct=11.4611 rec=1.3380 | train/val/test=1.000/0.704/0.701 | c=0.998437
[Epoch 0060] loss=13.8637 cls=0.1588 smmd=0.6575 ct=11.4668 rec=1.3472 | train/val/test=1.000/0.682/0.701 | c=0.998437
[Epoch 0061] loss=13.8222 cls=0.1823 smmd=0.6042 ct=11.5496 rec=1.3418 | train/val/test=1.000/0.670/0.677 | c=0.998437
[Epoch 0062] loss=13.5443 cls=0.1602 smmd=0.5304 ct=11.4613 rec=1.3536 | train/val/test=1.000/0.732/0.719 | c=0.998437
[Epoch 0063] loss=13.3718 cls=0.1121 smmd=0.4812 ct=11.4543 rec=1.3168 | train/val/test=1.000/0.738/0.739 | c=0.998437
[Epoch 0064] loss=13.2665 cls=0.0882 smmd=0.4575 ct=11.4254 rec=1.3068 | train/val/test=1.000/0.720/0.720 | c=0.998437
[Epoch 0065] loss=13.0763 cls=0.0924 smmd=0.3712 ct=11.4459 rec=1.3125 | train/val/test=1.000/0.730/0.733 | c=0.998437
[Epoch 0066] loss=13.4985 cls=0.1181 smmd=0.5132 ct=11.4946 rec=1.3234 | train/val/test=1.000/0.672/0.686 | c=0.998437
[Epoch 0067] loss=13.7586 cls=0.1596 smmd=0.6117 ct=11.4709 rec=1.3572 | train/val/test=0.923/0.526/0.530 | c=0.998437
[Epoch 0068] loss=14.7562 cls=0.3311 smmd=0.8570 ct=11.7615 rec=1.3735 | train/val/test=0.769/0.474/0.486 | c=0.998437
[Epoch 0069] loss=15.3793 cls=0.4987 smmd=1.1070 ct=11.6157 rec=1.4937 | train/val/test=1.000/0.656/0.661 | c=0.998437
[Epoch 0070] loss=13.1695 cls=0.0744 smmd=0.3834 ct=11.5158 rec=1.3160 | train/val/test=1.000/0.690/0.695 | c=0.998437
[Epoch 0071] loss=14.0119 cls=0.0800 smmd=0.6982 ct=11.5621 rec=1.3286 | train/val/test=1.000/0.712/0.726 | c=0.998437
[Epoch 0072] loss=13.2813 cls=0.0501 smmd=0.4651 ct=11.4465 rec=1.2939 | train/val/test=1.000/0.722/0.718 | c=0.998437
[Epoch 0073] loss=13.6372 cls=0.0352 smmd=0.5985 ct=11.4799 rec=1.2870 | train/val/test=1.000/0.718/0.717 | c=0.998437
[Epoch 0074] loss=13.1161 cls=0.0456 smmd=0.3720 ct=11.5146 rec=1.2974 | train/val/test=1.000/0.748/0.734 | c=0.998437
[Epoch 0075] loss=13.5878 cls=0.0584 smmd=0.5752 ct=11.4689 rec=1.3036 | train/val/test=1.000/0.696/0.690 | c=0.998437
[Epoch 0076] loss=13.5720 cls=0.0806 smmd=0.5457 ct=11.5033 rec=1.3280 | train/val/test=1.000/0.712/0.729 | c=0.998437
[Epoch 0077] loss=13.7991 cls=0.1369 smmd=0.6032 ct=11.5568 rec=1.3319 | train/val/test=1.000/0.678/0.662 | c=0.998437
[Epoch 0078] loss=14.4839 cls=0.1508 smmd=0.9006 ct=11.4802 rec=1.3536 | train/val/test=1.000/0.674/0.659 | c=0.998437
[Epoch 0079] loss=14.0596 cls=0.2419 smmd=0.6836 ct=11.5553 rec=1.3485 | train/val/test=0.769/0.540/0.537 | c=0.998437
[Epoch 0080] loss=14.2202 cls=0.3239 smmd=0.7180 ct=11.5549 rec=1.4169 | train/val/test=0.923/0.612/0.599 | c=0.998437
[Epoch 0081] loss=13.7536 cls=0.2649 smmd=0.5578 ct=11.5537 rec=1.3455 | train/val/test=1.000/0.750/0.740 | c=0.998437
[Epoch 0082] loss=13.4988 cls=0.0837 smmd=0.5495 ct=11.4294 rec=1.3075 | train/val/test=1.000/0.732/0.710 | c=0.998437
[Epoch 0083] loss=13.1296 cls=0.0699 smmd=0.4123 ct=11.4123 rec=1.3032 | train/val/test=1.000/0.692/0.686 | c=0.998437
[Epoch 0084] loss=13.5289 cls=0.0854 smmd=0.5347 ct=11.4913 rec=1.3164 | train/val/test=1.000/0.718/0.715 | c=0.998437
[Epoch 0085] loss=13.3443 cls=0.0924 smmd=0.4640 ct=11.4820 rec=1.3121 | train/val/test=1.000/0.730/0.726 | c=0.998437
[Epoch 0086] loss=13.3956 cls=0.0666 smmd=0.4923 ct=11.4766 rec=1.3100 | train/val/test=1.000/0.736/0.738 | c=0.998437
[Epoch 0087] loss=13.8087 cls=0.0762 smmd=0.6496 ct=11.4905 rec=1.3120 | train/val/test=1.000/0.706/0.689 | c=0.998437
[Epoch 0088] loss=14.1259 cls=0.0805 smmd=0.7712 ct=11.4982 rec=1.3188 | train/val/test=1.000/0.760/0.754 | c=0.998437
[Epoch 0089] loss=13.8200 cls=0.0782 smmd=0.6458 ct=11.5107 rec=1.3113 | train/val/test=1.000/0.722/0.704 | c=0.998437
[Epoch 0090] loss=13.5301 cls=0.0705 smmd=0.5576 ct=11.4482 rec=1.3056 | train/val/test=1.000/0.746/0.748 | c=0.998437
[Epoch 0091] loss=13.1956 cls=0.0673 smmd=0.4199 ct=11.4632 rec=1.2982 | train/val/test=1.000/0.718/0.721 | c=0.998437
[Epoch 0092] loss=13.2289 cls=0.0748 smmd=0.4433 ct=11.4342 rec=1.2980 | train/val/test=1.000/0.726/0.724 | c=0.998437
[Epoch 0093] loss=13.0679 cls=0.0912 smmd=0.3779 ct=11.4254 rec=1.3042 | train/val/test=1.000/0.752/0.757 | c=0.998437
[Epoch 0094] loss=13.1955 cls=0.1093 smmd=0.4103 ct=11.4576 rec=1.3150 | train/val/test=1.000/0.692/0.707 | c=0.998437
[Epoch 0095] loss=13.2874 cls=0.1491 smmd=0.4393 ct=11.4492 rec=1.3306 | train/val/test=1.000/0.762/0.754 | c=0.998437
[Epoch 0096] loss=13.6348 cls=0.1523 smmd=0.5558 ct=11.5025 rec=1.3331 | train/val/test=1.000/0.626/0.618 | c=0.998437
[Epoch 0097] loss=13.9753 cls=0.1618 smmd=0.6905 ct=11.4947 rec=1.3468 | train/val/test=0.923/0.760/0.760 | c=0.998437
[Epoch 0098] loss=13.9437 cls=0.1992 smmd=0.6652 ct=11.5151 rec=1.3323 | train/val/test=1.000/0.564/0.536 | c=0.998437
[Epoch 0099] loss=13.5504 cls=0.1223 smmd=0.5125 ct=11.5363 rec=1.3433 | train/val/test=0.923/0.716/0.730 | c=0.998437
=== Best @ epoch 95: val=0.7620, test=0.7540 ===
[2025-09-20 03:55:14] END attempt 1: exit_code=0
