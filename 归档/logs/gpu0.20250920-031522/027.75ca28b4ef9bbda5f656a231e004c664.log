[2025-09-20 04:52:54] START attempt 1: python main.py --is_transfer True --test_dataset CiteSeer --pretrained_model_name /mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth --few True --shot 10 --gpu_id 0
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.9240 cls=1.7931 smmd=4.1813 ct=9.4647 rec=1.3917 | train/val/test=0.180/0.172/0.182 | c=0.998347
[Epoch 0001] loss=37.6176 cls=1.7848 smmd=3.8433 ct=9.4824 rec=1.3917 | train/val/test=0.300/0.074/0.096 | c=0.998347
[Epoch 0002] loss=36.5166 cls=1.7720 smmd=2.9711 ct=9.3713 rec=1.3917 | train/val/test=0.500/0.168/0.216 | c=0.998347
[Epoch 0003] loss=36.0935 cls=1.7540 smmd=2.5331 ct=9.3835 rec=1.3916 | train/val/test=0.740/0.486/0.480 | c=0.998347
[Epoch 0004] loss=36.7375 cls=1.7170 smmd=2.2288 ct=9.8676 rec=1.3915 | train/val/test=0.300/0.286/0.281 | c=0.998347
[Epoch 0005] loss=36.3067 cls=1.6836 smmd=2.4201 ct=9.5635 rec=1.3918 | train/val/test=0.400/0.334/0.331 | c=0.998347
[Epoch 0006] loss=36.1457 cls=1.6381 smmd=2.5164 ct=9.4485 rec=1.3913 | train/val/test=0.560/0.440/0.443 | c=0.998347
[Epoch 0007] loss=35.9124 cls=1.5706 smmd=2.4957 ct=9.3666 rec=1.3898 | train/val/test=0.700/0.566/0.561 | c=0.998347
[Epoch 0008] loss=35.8115 cls=1.5164 smmd=2.2617 ct=9.4545 rec=1.3883 | train/val/test=0.700/0.612/0.610 | c=0.998347
[Epoch 0009] loss=35.4908 cls=1.4652 smmd=1.8397 ct=9.5249 rec=1.3869 | train/val/test=0.660/0.560/0.571 | c=0.998347
[Epoch 0010] loss=35.1998 cls=1.4136 smmd=1.5389 ct=9.5483 rec=1.3857 | train/val/test=0.760/0.530/0.547 | c=0.998347
[Epoch 0011] loss=35.1128 cls=1.3703 smmd=1.4055 ct=9.5860 rec=1.3850 | train/val/test=0.780/0.548/0.562 | c=0.998347
[Epoch 0012] loss=35.0765 cls=1.3269 smmd=1.3899 ct=9.5905 rec=1.3842 | train/val/test=0.780/0.610/0.608 | c=0.998347
[Epoch 0013] loss=34.9381 cls=1.2799 smmd=1.3764 ct=9.5446 rec=1.3832 | train/val/test=0.780/0.640/0.639 | c=0.998347
[Epoch 0014] loss=34.7875 cls=1.2368 smmd=1.3557 ct=9.4939 rec=1.3826 | train/val/test=0.800/0.614/0.623 | c=0.998347
[Epoch 0015] loss=34.6571 cls=1.1906 smmd=1.3588 ct=9.4411 rec=1.3821 | train/val/test=0.880/0.594/0.598 | c=0.998347
[Epoch 0016] loss=34.5559 cls=1.1401 smmd=1.2937 ct=9.4375 rec=1.3817 | train/val/test=0.880/0.616/0.603 | c=0.998347
[Epoch 0017] loss=34.4580 cls=1.0870 smmd=1.1110 ct=9.4978 rec=1.3808 | train/val/test=0.900/0.630/0.625 | c=0.998347
[Epoch 0018] loss=34.3394 cls=1.0331 smmd=0.8780 ct=9.5760 rec=1.3793 | train/val/test=0.920/0.606/0.581 | c=0.998347
[Epoch 0019] loss=34.1993 cls=0.9719 smmd=0.8307 ct=9.5527 rec=1.3777 | train/val/test=0.920/0.588/0.586 | c=0.998347
[Epoch 0020] loss=34.1432 cls=0.9097 smmd=0.8964 ct=9.5221 rec=1.3748 | train/val/test=0.920/0.640/0.615 | c=0.998347
[Epoch 0021] loss=34.0016 cls=0.8470 smmd=0.8760 ct=9.4974 rec=1.3707 | train/val/test=0.940/0.646/0.636 | c=0.998347
[Epoch 0022] loss=33.8700 cls=0.7818 smmd=0.8152 ct=9.5037 rec=1.3656 | train/val/test=0.940/0.622/0.608 | c=0.998347
[Epoch 0023] loss=33.7560 cls=0.7234 smmd=0.7425 ct=9.5266 rec=1.3599 | train/val/test=0.940/0.640/0.627 | c=0.998347
[Epoch 0024] loss=33.6289 cls=0.6709 smmd=0.6520 ct=9.5545 rec=1.3532 | train/val/test=0.920/0.646/0.642 | c=0.998347
[Epoch 0025] loss=33.5050 cls=0.6218 smmd=0.5972 ct=9.5739 rec=1.3449 | train/val/test=0.920/0.644/0.636 | c=0.998347
[Epoch 0026] loss=33.3690 cls=0.5791 smmd=0.6188 ct=9.5476 rec=1.3365 | train/val/test=0.920/0.638/0.632 | c=0.998347
[Epoch 0027] loss=33.2877 cls=0.5395 smmd=0.6695 ct=9.5364 rec=1.3276 | train/val/test=0.920/0.644/0.643 | c=0.998347
[Epoch 0028] loss=33.1393 cls=0.5056 smmd=0.5830 ct=9.5632 rec=1.3177 | train/val/test=0.920/0.656/0.647 | c=0.998347
[Epoch 0029] loss=33.0221 cls=0.4777 smmd=0.5407 ct=9.5771 rec=1.3088 | train/val/test=0.920/0.638/0.640 | c=0.998347
[Epoch 0030] loss=32.9027 cls=0.4502 smmd=0.5243 ct=9.5788 rec=1.2996 | train/val/test=0.920/0.648/0.634 | c=0.998347
[Epoch 0031] loss=32.8088 cls=0.4279 smmd=0.5334 ct=9.5767 rec=1.2908 | train/val/test=0.920/0.648/0.640 | c=0.998347
[Epoch 0032] loss=32.6745 cls=0.4081 smmd=0.4842 ct=9.5765 rec=1.2833 | train/val/test=0.920/0.656/0.654 | c=0.998347
[Epoch 0033] loss=32.6077 cls=0.3835 smmd=0.4871 ct=9.5834 rec=1.2762 | train/val/test=0.920/0.658/0.658 | c=0.998347
[Epoch 0034] loss=32.5257 cls=0.3657 smmd=0.4718 ct=9.5830 rec=1.2705 | train/val/test=0.920/0.658/0.657 | c=0.998347
[Epoch 0035] loss=32.4552 cls=0.3511 smmd=0.4538 ct=9.5868 rec=1.2652 | train/val/test=0.940/0.666/0.665 | c=0.998347
[Epoch 0036] loss=32.3933 cls=0.3326 smmd=0.4373 ct=9.5928 rec=1.2604 | train/val/test=0.940/0.674/0.668 | c=0.998347
[Epoch 0037] loss=32.3241 cls=0.3190 smmd=0.4232 ct=9.5889 rec=1.2564 | train/val/test=0.940/0.676/0.669 | c=0.998347
[Epoch 0038] loss=32.2850 cls=0.3046 smmd=0.4291 ct=9.5935 rec=1.2517 | train/val/test=0.980/0.682/0.682 | c=0.998347
[Epoch 0039] loss=32.2062 cls=0.2923 smmd=0.4040 ct=9.5920 rec=1.2472 | train/val/test=0.940/0.674/0.679 | c=0.998347
[Epoch 0040] loss=32.1603 cls=0.2788 smmd=0.4080 ct=9.5962 rec=1.2420 | train/val/test=0.960/0.692/0.696 | c=0.998347
[Epoch 0041] loss=32.1118 cls=0.2726 smmd=0.4140 ct=9.5918 rec=1.2378 | train/val/test=0.940/0.682/0.694 | c=0.998347
[Epoch 0042] loss=32.0509 cls=0.2610 smmd=0.3813 ct=9.6091 rec=1.2321 | train/val/test=0.980/0.696/0.704 | c=0.998347
[Epoch 0043] loss=32.0006 cls=0.2581 smmd=0.3946 ct=9.5919 rec=1.2293 | train/val/test=0.940/0.674/0.689 | c=0.998347
[Epoch 0044] loss=31.9943 cls=0.2486 smmd=0.4037 ct=9.6145 rec=1.2237 | train/val/test=0.980/0.702/0.703 | c=0.998347
[Epoch 0045] loss=31.9806 cls=0.2504 smmd=0.4467 ct=9.5912 rec=1.2226 | train/val/test=0.940/0.672/0.693 | c=0.998347
[Epoch 0046] loss=31.9589 cls=0.2447 smmd=0.3954 ct=9.6356 rec=1.2170 | train/val/test=0.980/0.692/0.709 | c=0.998347
[Epoch 0047] loss=31.8900 cls=0.2315 smmd=0.4460 ct=9.5919 rec=1.2144 | train/val/test=0.960/0.682/0.704 | c=0.998347
[Epoch 0048] loss=31.7780 cls=0.2192 smmd=0.3620 ct=9.6166 rec=1.2073 | train/val/test=0.980/0.686/0.703 | c=0.998347
[Epoch 0049] loss=31.7202 cls=0.2055 smmd=0.3635 ct=9.6025 rec=1.2049 | train/val/test=0.980/0.694/0.705 | c=0.998347
[Epoch 0050] loss=31.7314 cls=0.2081 smmd=0.3920 ct=9.5894 rec=1.2056 | train/val/test=0.960/0.684/0.695 | c=0.998347
[Epoch 0051] loss=31.7836 cls=0.2145 smmd=0.3677 ct=9.6295 rec=1.2050 | train/val/test=0.960/0.684/0.705 | c=0.998347
[Epoch 0052] loss=31.7932 cls=0.2154 smmd=0.4181 ct=9.5937 rec=1.2080 | train/val/test=0.940/0.678/0.693 | c=0.998347
[Epoch 0053] loss=31.7835 cls=0.2118 smmd=0.3586 ct=9.6411 rec=1.2037 | train/val/test=0.980/0.694/0.705 | c=0.998347
[Epoch 0054] loss=31.7120 cls=0.1976 smmd=0.4168 ct=9.5918 rec=1.2013 | train/val/test=0.980/0.676/0.697 | c=0.998347
[Epoch 0055] loss=31.5995 cls=0.1795 smmd=0.3376 ct=9.6167 rec=1.1939 | train/val/test=0.980/0.672/0.700 | c=0.998347
[Epoch 0056] loss=31.5519 cls=0.1738 smmd=0.3469 ct=9.6013 rec=1.1915 | train/val/test=0.980/0.688/0.706 | c=0.998347
[Epoch 0057] loss=31.5740 cls=0.1779 smmd=0.3739 ct=9.5908 rec=1.1930 | train/val/test=0.960/0.672/0.694 | c=0.998347
[Epoch 0058] loss=31.6073 cls=0.1829 smmd=0.3286 ct=9.6311 rec=1.1925 | train/val/test=0.960/0.686/0.702 | c=0.998347
[Epoch 0059] loss=31.5973 cls=0.1805 smmd=0.3868 ct=9.5892 rec=1.1942 | train/val/test=0.980/0.682/0.694 | c=0.998347
[Epoch 0060] loss=31.5746 cls=0.1832 smmd=0.3244 ct=9.6251 rec=1.1908 | train/val/test=0.980/0.680/0.694 | c=0.998347
[Epoch 0061] loss=31.5321 cls=0.1639 smmd=0.3598 ct=9.5904 rec=1.1910 | train/val/test=0.980/0.684/0.695 | c=0.998347
[Epoch 0062] loss=31.4979 cls=0.1745 smmd=0.3083 ct=9.6125 rec=1.1877 | train/val/test=0.980/0.676/0.693 | c=0.998347
[Epoch 0063] loss=31.4765 cls=0.1530 smmd=0.3313 ct=9.5955 rec=1.1878 | train/val/test=0.980/0.682/0.694 | c=0.998347
[Epoch 0064] loss=31.4789 cls=0.1688 smmd=0.3179 ct=9.6065 rec=1.1864 | train/val/test=0.980/0.670/0.685 | c=0.998347
[Epoch 0065] loss=31.5224 cls=0.1523 smmd=0.3549 ct=9.6073 rec=1.1877 | train/val/test=0.940/0.686/0.695 | c=0.998347
[Epoch 0066] loss=31.5546 cls=0.1826 smmd=0.3589 ct=9.6123 rec=1.1880 | train/val/test=0.980/0.658/0.682 | c=0.998347
[Epoch 0067] loss=31.5862 cls=0.1491 smmd=0.4044 ct=9.6157 rec=1.1876 | train/val/test=0.960/0.684/0.696 | c=0.998347
[Epoch 0068] loss=31.4545 cls=0.1658 smmd=0.3534 ct=9.6015 rec=1.1815 | train/val/test=0.980/0.674/0.685 | c=0.998347
[Epoch 0069] loss=31.3715 cls=0.1347 smmd=0.3331 ct=9.5999 rec=1.1771 | train/val/test=0.980/0.666/0.683 | c=0.998347
[Epoch 0070] loss=31.4102 cls=0.1363 smmd=0.3533 ct=9.6000 rec=1.1789 | train/val/test=0.980/0.684/0.696 | c=0.998347
[Epoch 0071] loss=31.4738 cls=0.1586 smmd=0.3678 ct=9.6050 rec=1.1817 | train/val/test=0.980/0.664/0.679 | c=0.998347
[Epoch 0072] loss=31.4471 cls=0.1342 smmd=0.3368 ct=9.6080 rec=1.1827 | train/val/test=0.980/0.682/0.693 | c=0.998347
[Epoch 0073] loss=31.3837 cls=0.1518 smmd=0.3036 ct=9.5993 rec=1.1805 | train/val/test=0.960/0.660/0.683 | c=0.998347
[Epoch 0074] loss=31.3659 cls=0.1335 smmd=0.3051 ct=9.5900 rec=1.1814 | train/val/test=0.980/0.676/0.692 | c=0.998347
[Epoch 0075] loss=31.4391 cls=0.1557 smmd=0.3053 ct=9.6224 rec=1.1811 | train/val/test=0.960/0.660/0.683 | c=0.998347
[Epoch 0076] loss=31.5957 cls=0.1643 smmd=0.4333 ct=9.5883 rec=1.1904 | train/val/test=0.940/0.662/0.687 | c=0.998347
[Epoch 0077] loss=31.8318 cls=0.1997 smmd=0.4310 ct=9.6997 rec=1.1901 | train/val/test=0.960/0.676/0.686 | c=0.998347
[Epoch 0078] loss=31.6863 cls=0.1709 smmd=0.5443 ct=9.5952 rec=1.1866 | train/val/test=0.980/0.666/0.685 | c=0.998347
[Epoch 0079] loss=31.4152 cls=0.1203 smmd=0.4055 ct=9.6316 rec=1.1686 | train/val/test=0.960/0.656/0.685 | c=0.998347
[Epoch 0080] loss=31.4816 cls=0.1262 smmd=0.4405 ct=9.6355 rec=1.1707 | train/val/test=0.980/0.678/0.684 | c=0.998347
[Epoch 0081] loss=31.4312 cls=0.1226 smmd=0.4821 ct=9.5913 rec=1.1705 | train/val/test=0.960/0.670/0.690 | c=0.998347
[Epoch 0082] loss=31.4225 cls=0.1364 smmd=0.4283 ct=9.6166 rec=1.1693 | train/val/test=0.980/0.658/0.681 | c=0.998347
[Epoch 0083] loss=31.4790 cls=0.1169 smmd=0.4053 ct=9.6289 rec=1.1757 | train/val/test=0.980/0.672/0.688 | c=0.998347
[Epoch 0084] loss=31.3895 cls=0.1334 smmd=0.3740 ct=9.5882 rec=1.1773 | train/val/test=0.980/0.666/0.685 | c=0.998347
[Epoch 0085] loss=31.4736 cls=0.1523 smmd=0.3465 ct=9.6207 rec=1.1810 | train/val/test=0.980/0.668/0.685 | c=0.998347
[Epoch 0086] loss=31.6698 cls=0.1615 smmd=0.4779 ct=9.6241 rec=1.1863 | train/val/test=0.980/0.670/0.688 | c=0.998347
[Epoch 0087] loss=31.4092 cls=0.1528 smmd=0.3307 ct=9.6144 rec=1.1773 | train/val/test=0.960/0.658/0.676 | c=0.998347
[Epoch 0088] loss=31.3659 cls=0.1114 smmd=0.3773 ct=9.5944 rec=1.1744 | train/val/test=0.980/0.670/0.686 | c=0.998347
[Epoch 0089] loss=31.4465 cls=0.1490 smmd=0.4288 ct=9.6108 rec=1.1722 | train/val/test=0.960/0.668/0.687 | c=0.998347
[Epoch 0090] loss=31.2493 cls=0.1177 smmd=0.3259 ct=9.6004 rec=1.1664 | train/val/test=0.960/0.654/0.671 | c=0.998347
[Epoch 0091] loss=31.3604 cls=0.1166 smmd=0.4046 ct=9.5957 rec=1.1706 | train/val/test=0.980/0.668/0.685 | c=0.998347
[Epoch 0092] loss=31.4199 cls=0.1359 smmd=0.4060 ct=9.6106 rec=1.1725 | train/val/test=0.980/0.668/0.679 | c=0.998347
[Epoch 0093] loss=31.2508 cls=0.1143 smmd=0.3021 ct=9.5965 rec=1.1698 | train/val/test=0.960/0.650/0.676 | c=0.998347
[Epoch 0094] loss=31.4072 cls=0.1285 smmd=0.3683 ct=9.5974 rec=1.1780 | train/val/test=0.960/0.674/0.681 | c=0.998347
[Epoch 0095] loss=31.5602 cls=0.1657 smmd=0.4179 ct=9.6200 rec=1.1819 | train/val/test=0.980/0.656/0.679 | c=0.998347
[Epoch 0096] loss=31.3239 cls=0.1168 smmd=0.3071 ct=9.6044 rec=1.1750 | train/val/test=0.980/0.656/0.683 | c=0.998347
[Epoch 0097] loss=31.3435 cls=0.1258 smmd=0.3739 ct=9.5792 rec=1.1748 | train/val/test=0.980/0.674/0.682 | c=0.998347
[Epoch 0098] loss=31.4313 cls=0.1409 smmd=0.3780 ct=9.6267 rec=1.1729 | train/val/test=0.980/0.660/0.683 | c=0.998347
[Epoch 0099] loss=31.2272 cls=0.1134 smmd=0.3110 ct=9.5947 rec=1.1670 | train/val/test=0.960/0.654/0.681 | c=0.998347
[Epoch 0100] loss=31.3298 cls=0.1238 smmd=0.3966 ct=9.5836 rec=1.1704 | train/val/test=0.980/0.668/0.681 | c=0.998347
[Epoch 0101] loss=31.3761 cls=0.1287 smmd=0.3736 ct=9.6141 rec=1.1710 | train/val/test=0.980/0.662/0.685 | c=0.998347
[Epoch 0102] loss=31.2311 cls=0.1200 smmd=0.2784 ct=9.6080 rec=1.1677 | train/val/test=0.960/0.652/0.674 | c=0.998347
[Epoch 0103] loss=31.3982 cls=0.1252 smmd=0.4255 ct=9.5754 rec=1.1759 | train/val/test=0.980/0.672/0.685 | c=0.998347
[Epoch 0104] loss=31.3884 cls=0.1380 smmd=0.3402 ct=9.6222 rec=1.1735 | train/val/test=0.980/0.660/0.684 | c=0.998347
[Epoch 0105] loss=31.2354 cls=0.1123 smmd=0.2808 ct=9.5959 rec=1.1707 | train/val/test=0.980/0.654/0.679 | c=0.998347
[Epoch 0106] loss=31.3675 cls=0.1182 smmd=0.3966 ct=9.5801 rec=1.1752 | train/val/test=0.980/0.670/0.683 | c=0.998347
[Epoch 0107] loss=31.3839 cls=0.1361 smmd=0.3526 ct=9.6148 rec=1.1734 | train/val/test=0.980/0.660/0.689 | c=0.998347
[Epoch 0108] loss=31.2688 cls=0.1243 smmd=0.2811 ct=9.6208 rec=1.1684 | train/val/test=0.980/0.652/0.680 | c=0.998347
[Epoch 0109] loss=31.4152 cls=0.1227 smmd=0.4765 ct=9.5638 rec=1.1750 | train/val/test=0.980/0.668/0.690 | c=0.998347
[Epoch 0110] loss=31.3884 cls=0.1534 smmd=0.3393 ct=9.6362 rec=1.1700 | train/val/test=0.980/0.666/0.684 | c=0.998347
[Epoch 0111] loss=31.3747 cls=0.1184 smmd=0.3748 ct=9.6140 rec=1.1713 | train/val/test=0.980/0.654/0.679 | c=0.998347
[Epoch 0112] loss=31.3873 cls=0.1225 smmd=0.4318 ct=9.5920 rec=1.1710 | train/val/test=0.980/0.666/0.684 | c=0.998347
[Epoch 0113] loss=31.2707 cls=0.1092 smmd=0.3635 ct=9.5848 rec=1.1683 | train/val/test=0.980/0.664/0.686 | c=0.998347
[Epoch 0114] loss=31.3242 cls=0.1145 smmd=0.2954 ct=9.6427 rec=1.1686 | train/val/test=0.980/0.654/0.687 | c=0.998347
[Epoch 0115] loss=31.3382 cls=0.1125 smmd=0.4420 ct=9.5631 rec=1.1714 | train/val/test=0.980/0.660/0.685 | c=0.998347
[Epoch 0116] loss=31.2257 cls=0.1052 smmd=0.3163 ct=9.5842 rec=1.1688 | train/val/test=0.980/0.666/0.691 | c=0.998347
[Epoch 0117] loss=31.4255 cls=0.1396 smmd=0.3122 ct=9.6493 rec=1.1745 | train/val/test=1.000/0.658/0.679 | c=0.998347
[Epoch 0118] loss=31.4147 cls=0.1174 smmd=0.4813 ct=9.5571 rec=1.1760 | train/val/test=0.980/0.662/0.685 | c=0.998347
[Epoch 0119] loss=31.3495 cls=0.1405 smmd=0.3399 ct=9.6144 rec=1.1711 | train/val/test=0.980/0.662/0.686 | c=0.998347
[Epoch 0120] loss=31.6768 cls=0.1496 smmd=0.4740 ct=9.6481 rec=1.1832 | train/val/test=0.980/0.660/0.681 | c=0.998347
[Epoch 0121] loss=31.4558 cls=0.1428 smmd=0.4324 ct=9.6205 rec=1.1711 | train/val/test=1.000/0.660/0.683 | c=0.998347
[Epoch 0122] loss=31.2561 cls=0.0955 smmd=0.4449 ct=9.5613 rec=1.1641 | train/val/test=0.980/0.660/0.687 | c=0.998347
[Epoch 0123] loss=31.2808 cls=0.0927 smmd=0.3826 ct=9.6208 rec=1.1610 | train/val/test=0.980/0.664/0.689 | c=0.998347
[Epoch 0124] loss=31.2463 cls=0.1153 smmd=0.3227 ct=9.6262 rec=1.1614 | train/val/test=1.000/0.658/0.684 | c=0.998347
[Epoch 0125] loss=31.3311 cls=0.1023 smmd=0.4667 ct=9.5624 rec=1.1688 | train/val/test=0.960/0.658/0.686 | c=0.998347
[Epoch 0126] loss=31.2045 cls=0.1130 smmd=0.2961 ct=9.5920 rec=1.1668 | train/val/test=0.980/0.662/0.688 | c=0.998347
[Epoch 0127] loss=31.3178 cls=0.1231 smmd=0.2805 ct=9.6229 rec=1.1730 | train/val/test=0.980/0.656/0.683 | c=0.998347
[Epoch 0128] loss=31.3491 cls=0.1171 smmd=0.3957 ct=9.5632 rec=1.1768 | train/val/test=0.980/0.660/0.685 | c=0.998347
[Epoch 0129] loss=31.2604 cls=0.1258 smmd=0.2775 ct=9.5984 rec=1.1723 | train/val/test=1.000/0.662/0.679 | c=0.998347
[Epoch 0130] loss=31.4289 cls=0.1285 smmd=0.3478 ct=9.6278 rec=1.1761 | train/val/test=0.960/0.662/0.687 | c=0.998347
[Epoch 0131] loss=31.4056 cls=0.1524 smmd=0.3979 ct=9.6009 rec=1.1730 | train/val/test=0.980/0.656/0.680 | c=0.998347
[Epoch 0132] loss=31.3618 cls=0.1100 smmd=0.4372 ct=9.5792 rec=1.1711 | train/val/test=0.980/0.668/0.685 | c=0.998347
[Epoch 0133] loss=31.3965 cls=0.1400 smmd=0.3446 ct=9.6653 rec=1.1651 | train/val/test=0.980/0.662/0.686 | c=0.998347
[Epoch 0134] loss=31.1742 cls=0.1031 smmd=0.3680 ct=9.5801 rec=1.1594 | train/val/test=0.980/0.654/0.679 | c=0.998347
[Epoch 0135] loss=31.3661 cls=0.1160 smmd=0.4802 ct=9.5681 rec=1.1692 | train/val/test=0.980/0.664/0.688 | c=0.998347
[Epoch 0136] loss=31.3921 cls=0.1324 smmd=0.3414 ct=9.6544 rec=1.1676 | train/val/test=0.980/0.668/0.682 | c=0.998347
[Epoch 0137] loss=31.3091 cls=0.1136 smmd=0.3420 ct=9.6009 rec=1.1709 | train/val/test=1.000/0.644/0.668 | c=0.998347
[Epoch 0138] loss=31.4609 cls=0.1121 smmd=0.4398 ct=9.5896 rec=1.1786 | train/val/test=0.980/0.670/0.689 | c=0.998347
[Epoch 0139] loss=31.3937 cls=0.1516 smmd=0.3500 ct=9.6071 rec=1.1754 | train/val/test=1.000/0.660/0.675 | c=0.998347
[Epoch 0140] loss=31.4727 cls=0.1042 smmd=0.3857 ct=9.6444 rec=1.1746 | train/val/test=0.980/0.656/0.683 | c=0.998347
[Epoch 0141] loss=31.2545 cls=0.1078 smmd=0.4026 ct=9.5743 rec=1.1649 | train/val/test=0.980/0.664/0.689 | c=0.998347
[Epoch 0142] loss=31.2282 cls=0.1226 smmd=0.3777 ct=9.5773 rec=1.1635 | train/val/test=1.000/0.662/0.678 | c=0.998347
[Epoch 0143] loss=31.3633 cls=0.0977 smmd=0.3898 ct=9.6358 rec=1.1653 | train/val/test=0.960/0.660/0.680 | c=0.998347
[Epoch 0144] loss=31.1766 cls=0.1110 smmd=0.3250 ct=9.5898 rec=1.1616 | train/val/test=0.980/0.660/0.688 | c=0.998347
[Epoch 0145] loss=31.3066 cls=0.1300 smmd=0.4082 ct=9.5719 rec=1.1690 | train/val/test=1.000/0.656/0.675 | c=0.998347
[Epoch 0146] loss=31.3586 cls=0.1119 smmd=0.3519 ct=9.6112 rec=1.1728 | train/val/test=0.980/0.660/0.688 | c=0.998347
[Epoch 0147] loss=31.3668 cls=0.1328 smmd=0.3029 ct=9.6218 rec=1.1754 | train/val/test=0.980/0.652/0.678 | c=0.998347
[Epoch 0148] loss=31.3553 cls=0.1127 smmd=0.4134 ct=9.5720 rec=1.1742 | train/val/test=0.980/0.658/0.678 | c=0.998347
[Epoch 0149] loss=31.2085 cls=0.1023 smmd=0.3263 ct=9.5814 rec=1.1668 | train/val/test=0.980/0.660/0.690 | c=0.998347
[Epoch 0150] loss=31.3687 cls=0.1301 smmd=0.3112 ct=9.6560 rec=1.1681 | train/val/test=1.000/0.656/0.680 | c=0.998347
[Epoch 0151] loss=31.3091 cls=0.1078 smmd=0.4331 ct=9.5679 rec=1.1686 | train/val/test=0.980/0.658/0.684 | c=0.998347
[Epoch 0152] loss=31.2135 cls=0.1088 smmd=0.3548 ct=9.5861 rec=1.1632 | train/val/test=0.960/0.658/0.681 | c=0.998347
[Epoch 0153] loss=31.2455 cls=0.1114 smmd=0.3109 ct=9.6193 rec=1.1640 | train/val/test=0.980/0.662/0.681 | c=0.998347
[Epoch 0154] loss=31.1731 cls=0.1058 smmd=0.3144 ct=9.5831 rec=1.1640 | train/val/test=0.980/0.658/0.681 | c=0.998347
[Epoch 0155] loss=31.2732 cls=0.1167 smmd=0.3458 ct=9.5856 rec=1.1698 | train/val/test=0.980/0.658/0.682 | c=0.998347
[Epoch 0156] loss=31.3527 cls=0.1197 smmd=0.3337 ct=9.6022 rec=1.1755 | train/val/test=0.960/0.662/0.678 | c=0.998347
[Epoch 0157] loss=31.5527 cls=0.1687 smmd=0.3401 ct=9.6620 rec=1.1804 | train/val/test=0.980/0.656/0.664 | c=0.998347
[Epoch 0158] loss=31.7704 cls=0.1555 smmd=0.5811 ct=9.5852 rec=1.1941 | train/val/test=0.940/0.668/0.676 | c=0.998347
[Epoch 0159] loss=31.7729 cls=0.1831 smmd=0.4641 ct=9.7228 rec=1.1772 | train/val/test=0.980/0.662/0.680 | c=0.998347
[Epoch 0160] loss=31.2342 cls=0.0926 smmd=0.3571 ct=9.6287 rec=1.1573 | train/val/test=0.980/0.666/0.668 | c=0.998347
[Epoch 0161] loss=31.6496 cls=0.1534 smmd=0.6548 ct=9.5813 rec=1.1756 | train/val/test=0.960/0.662/0.683 | c=0.998347
[Epoch 0162] loss=31.3943 cls=0.1215 smmd=0.4999 ct=9.6269 rec=1.1580 | train/val/test=0.980/0.652/0.681 | c=0.998347
[Epoch 0163] loss=31.4664 cls=0.0903 smmd=0.4723 ct=9.6686 rec=1.1612 | train/val/test=1.000/0.662/0.677 | c=0.998347
[Epoch 0164] loss=31.3168 cls=0.0896 smmd=0.4381 ct=9.6062 rec=1.1622 | train/val/test=0.960/0.666/0.687 | c=0.998347
[Epoch 0165] loss=31.4064 cls=0.1185 smmd=0.4971 ct=9.5810 rec=1.1688 | train/val/test=0.980/0.656/0.670 | c=0.998347
[Epoch 0166] loss=31.4457 cls=0.1224 smmd=0.3997 ct=9.6258 rec=1.1733 | train/val/test=1.000/0.662/0.682 | c=0.998347
[Epoch 0167] loss=31.4922 cls=0.1144 smmd=0.4187 ct=9.6283 rec=1.1760 | train/val/test=0.980/0.662/0.688 | c=0.998347
[Epoch 0168] loss=31.2659 cls=0.1262 smmd=0.3316 ct=9.5893 rec=1.1693 | train/val/test=0.980/0.648/0.663 | c=0.998347
[Epoch 0169] loss=31.3829 cls=0.1061 smmd=0.4041 ct=9.5946 rec=1.1737 | train/val/test=0.980/0.668/0.682 | c=0.998347
[Epoch 0170] loss=31.3773 cls=0.1300 smmd=0.4005 ct=9.6105 rec=1.1691 | train/val/test=0.980/0.662/0.687 | c=0.998347
[Epoch 0171] loss=31.2300 cls=0.1194 smmd=0.2973 ct=9.6208 rec=1.1631 | train/val/test=0.980/0.648/0.670 | c=0.998347
[Epoch 0172] loss=31.3410 cls=0.1047 smmd=0.4398 ct=9.5866 rec=1.1676 | train/val/test=0.980/0.668/0.683 | c=0.998347
[Epoch 0173] loss=31.2347 cls=0.1094 smmd=0.3885 ct=9.5751 rec=1.1641 | train/val/test=0.980/0.656/0.682 | c=0.998347
[Epoch 0174] loss=31.2725 cls=0.1132 smmd=0.2928 ct=9.6356 rec=1.1652 | train/val/test=0.980/0.650/0.673 | c=0.998347
[Epoch 0175] loss=31.2299 cls=0.0974 smmd=0.3404 ct=9.5862 rec=1.1669 | train/val/test=0.980/0.660/0.683 | c=0.998347
[Epoch 0176] loss=31.2928 cls=0.1175 smmd=0.3961 ct=9.5646 rec=1.1709 | train/val/test=0.980/0.658/0.675 | c=0.998347
[Epoch 0177] loss=31.3213 cls=0.1160 smmd=0.2780 ct=9.6350 rec=1.1715 | train/val/test=0.980/0.652/0.676 | c=0.998347
[Epoch 0178] loss=31.2020 cls=0.1075 smmd=0.3033 ct=9.5778 rec=1.1689 | train/val/test=0.980/0.650/0.678 | c=0.998347
[Epoch 0179] loss=31.2294 cls=0.1225 smmd=0.3185 ct=9.5799 rec=1.1690 | train/val/test=0.980/0.650/0.679 | c=0.998347
[Epoch 0180] loss=31.2434 cls=0.1106 smmd=0.3008 ct=9.6047 rec=1.1678 | train/val/test=0.980/0.656/0.681 | c=0.998347
[Epoch 0181] loss=31.1950 cls=0.1244 smmd=0.2897 ct=9.5960 rec=1.1651 | train/val/test=0.980/0.654/0.677 | c=0.998347
[Epoch 0182] loss=31.2054 cls=0.1072 smmd=0.3352 ct=9.5759 rec=1.1665 | train/val/test=0.980/0.658/0.678 | c=0.998347
[Epoch 0183] loss=31.1640 cls=0.1135 smmd=0.2611 ct=9.5987 rec=1.1649 | train/val/test=0.980/0.658/0.677 | c=0.998347
[Epoch 0184] loss=31.1681 cls=0.1106 smmd=0.2745 ct=9.5914 rec=1.1655 | train/val/test=0.980/0.650/0.675 | c=0.998347
[Epoch 0185] loss=31.1932 cls=0.1062 smmd=0.3065 ct=9.5750 rec=1.1684 | train/val/test=0.980/0.654/0.678 | c=0.998347
[Epoch 0186] loss=31.1744 cls=0.1154 smmd=0.2456 ct=9.5942 rec=1.1683 | train/val/test=0.980/0.654/0.674 | c=0.998347
[Epoch 0187] loss=31.1785 cls=0.1076 smmd=0.2449 ct=9.5948 rec=1.1690 | train/val/test=0.980/0.652/0.677 | c=0.998347
[Epoch 0188] loss=31.2199 cls=0.1204 smmd=0.3144 ct=9.5733 rec=1.1699 | train/val/test=0.980/0.654/0.676 | c=0.998347
[Epoch 0189] loss=31.2151 cls=0.1063 smmd=0.2742 ct=9.6008 rec=1.1686 | train/val/test=0.980/0.660/0.680 | c=0.998347
[Epoch 0190] loss=31.2054 cls=0.1287 smmd=0.2658 ct=9.6015 rec=1.1672 | train/val/test=1.000/0.652/0.674 | c=0.998347
[Epoch 0191] loss=31.2231 cls=0.1057 smmd=0.3404 ct=9.5749 rec=1.1680 | train/val/test=0.980/0.658/0.683 | c=0.998347
[Epoch 0192] loss=31.2150 cls=0.1295 smmd=0.2765 ct=9.6089 rec=1.1656 | train/val/test=1.000/0.652/0.678 | c=0.998347
[Epoch 0193] loss=31.1996 cls=0.1066 smmd=0.3035 ct=9.5883 rec=1.1666 | train/val/test=0.980/0.654/0.676 | c=0.998347
[Epoch 0194] loss=31.2056 cls=0.1118 smmd=0.2859 ct=9.5996 rec=1.1665 | train/val/test=0.980/0.654/0.677 | c=0.998347
[Epoch 0195] loss=31.2057 cls=0.1081 smmd=0.3103 ct=9.5808 rec=1.1680 | train/val/test=0.980/0.654/0.674 | c=0.998347
[Epoch 0196] loss=31.2200 cls=0.1040 smmd=0.2630 ct=9.6170 rec=1.1671 | train/val/test=0.980/0.652/0.679 | c=0.998347
[Epoch 0197] loss=31.2119 cls=0.1081 smmd=0.3433 ct=9.5693 rec=1.1676 | train/val/test=0.980/0.654/0.679 | c=0.998347
[Epoch 0198] loss=31.1600 cls=0.1033 smmd=0.2552 ct=9.6028 rec=1.1647 | train/val/test=0.980/0.654/0.676 | c=0.998347
[Epoch 0199] loss=31.1459 cls=0.1047 smmd=0.2652 ct=9.5903 rec=1.1648 | train/val/test=0.980/0.656/0.679 | c=0.998347
=== Best @ epoch 44: val=0.7020, test=0.7030 ===
[2025-09-20 04:53:52] END attempt 1: exit_code=0
