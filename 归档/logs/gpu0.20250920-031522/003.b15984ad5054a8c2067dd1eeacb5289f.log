[2025-09-20 03:19:43] START attempt 1: python main.py --is_transfer True --test_dataset Photo --pretrained_model_name /mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Cora.GRACE.GAT.hyp_True.True.20250912-232536.pth --few True --shot 10 --gpu_id 0
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Cora
Split sizes | train=79, val=1514, test=6057 (mode=few, shot=10)
[Epoch 0000] loss=9.8483 cls=2.0815 smmd=5.5602 ct=10.3412 rec=1.3844 | train/val/test=0.127/0.240/0.259 | c=0.999488
[Epoch 0001] loss=7.9251 cls=2.0759 smmd=3.4639 ct=11.2342 rec=1.3844 | train/val/test=0.354/0.278/0.297 | c=0.999488
[Epoch 0002] loss=7.4115 cls=2.0716 smmd=3.1072 ct=10.4715 rec=1.3844 | train/val/test=0.291/0.146/0.146 | c=0.999488
[Epoch 0003] loss=7.6089 cls=2.0648 smmd=3.3746 ct=10.1553 rec=1.3844 | train/val/test=0.190/0.060/0.052 | c=0.999488
[Epoch 0004] loss=6.9712 cls=2.0537 smmd=2.7906 ct=9.9424 rec=1.3844 | train/val/test=0.304/0.133/0.135 | c=0.999488
[Epoch 0005] loss=6.0366 cls=2.0386 smmd=1.8855 ct=9.8704 rec=1.3843 | train/val/test=0.633/0.516/0.520 | c=0.999488
[Epoch 0006] loss=5.8849 cls=2.0190 smmd=1.7243 ct=10.0158 rec=1.3843 | train/val/test=0.582/0.481/0.480 | c=0.999488
[Epoch 0007] loss=5.8566 cls=1.9959 smmd=1.7563 ct=9.8298 rec=1.3843 | train/val/test=0.620/0.520/0.511 | c=0.999488
[Epoch 0008] loss=5.5610 cls=1.9667 smmd=1.4970 ct=9.7946 rec=1.3842 | train/val/test=0.709/0.581/0.573 | c=0.999488
[Epoch 0009] loss=5.2147 cls=1.9306 smmd=1.1889 ct=9.7842 rec=1.3840 | train/val/test=0.747/0.590/0.587 | c=0.999488
[Epoch 0010] loss=4.9374 cls=1.8895 smmd=0.9602 ct=9.7470 rec=1.3837 | train/val/test=0.734/0.606/0.601 | c=0.999488
[Epoch 0011] loss=4.7476 cls=1.8424 smmd=0.8179 ct=9.7443 rec=1.3833 | train/val/test=0.747/0.616/0.612 | c=0.999488
[Epoch 0012] loss=4.6405 cls=1.7896 smmd=0.7555 ct=9.7860 rec=1.3826 | train/val/test=0.734/0.627/0.624 | c=0.999488
[Epoch 0013] loss=4.5477 cls=1.7306 smmd=0.7159 ct=9.8157 rec=1.3817 | train/val/test=0.747/0.645/0.642 | c=0.999488
[Epoch 0014] loss=4.3778 cls=1.6662 smmd=0.6103 ct=9.8162 rec=1.3805 | train/val/test=0.797/0.659/0.661 | c=0.999488
[Epoch 0015] loss=4.1717 cls=1.5977 smmd=0.4713 ct=9.8246 rec=1.3787 | train/val/test=0.810/0.668/0.668 | c=0.999488
[Epoch 0016] loss=4.0378 cls=1.5266 smmd=0.4032 ct=9.8515 rec=1.3764 | train/val/test=0.823/0.676/0.675 | c=0.999488
[Epoch 0017] loss=3.9836 cls=1.4545 smmd=0.4196 ct=9.8610 rec=1.3735 | train/val/test=0.823/0.705/0.699 | c=0.999488
[Epoch 0018] loss=3.9204 cls=1.3815 smmd=0.4308 ct=9.8558 rec=1.3700 | train/val/test=0.861/0.739/0.728 | c=0.999488
[Epoch 0019] loss=3.8080 cls=1.3075 smmd=0.3919 ct=9.8601 rec=1.3659 | train/val/test=0.861/0.762/0.751 | c=0.999488
[Epoch 0020] loss=3.6818 cls=1.2339 smmd=0.3360 ct=9.8788 rec=1.3609 | train/val/test=0.861/0.769/0.756 | c=0.999488
[Epoch 0021] loss=3.5855 cls=1.1626 smmd=0.3062 ct=9.9061 rec=1.3550 | train/val/test=0.861/0.770/0.759 | c=0.999488
[Epoch 0022] loss=3.5274 cls=1.0946 smmd=0.3125 ct=9.9270 rec=1.3486 | train/val/test=0.873/0.779/0.767 | c=0.999488
[Epoch 0023] loss=3.4743 cls=1.0293 smmd=0.3238 ct=9.9349 rec=1.3418 | train/val/test=0.886/0.793/0.784 | c=0.999488
[Epoch 0024] loss=3.4035 cls=0.9673 smmd=0.3149 ct=9.9389 rec=1.3348 | train/val/test=0.899/0.800/0.797 | c=0.999488
[Epoch 0025] loss=3.3253 cls=0.9093 smmd=0.2939 ct=9.9468 rec=1.3276 | train/val/test=0.899/0.806/0.804 | c=0.999488
[Epoch 0026] loss=3.2614 cls=0.8553 smmd=0.2828 ct=9.9565 rec=1.3203 | train/val/test=0.899/0.809/0.809 | c=0.999488
[Epoch 0027] loss=3.2103 cls=0.8047 smmd=0.2820 ct=9.9615 rec=1.3133 | train/val/test=0.911/0.812/0.812 | c=0.999488
[Epoch 0028] loss=3.1675 cls=0.7570 smmd=0.2876 ct=9.9610 rec=1.3068 | train/val/test=0.911/0.816/0.815 | c=0.999488
[Epoch 0029] loss=3.1205 cls=0.7124 smmd=0.2856 ct=9.9626 rec=1.3004 | train/val/test=0.911/0.824/0.819 | c=0.999488
[Epoch 0030] loss=3.0621 cls=0.6708 smmd=0.2675 ct=9.9720 rec=1.2939 | train/val/test=0.911/0.826/0.822 | c=0.999488
[Epoch 0031] loss=3.0224 cls=0.6320 smmd=0.2644 ct=9.9858 rec=1.2876 | train/val/test=0.911/0.826/0.824 | c=0.999488
[Epoch 0032] loss=2.9790 cls=0.5955 smmd=0.2558 ct=9.9978 rec=1.2816 | train/val/test=0.911/0.826/0.827 | c=0.999488
[Epoch 0033] loss=2.9432 cls=0.5608 smmd=0.2544 ct=10.0018 rec=1.2760 | train/val/test=0.911/0.826/0.828 | c=0.999488
[Epoch 0034] loss=2.9023 cls=0.5284 smmd=0.2468 ct=10.0001 rec=1.2707 | train/val/test=0.911/0.832/0.832 | c=0.999488
[Epoch 0035] loss=2.8657 cls=0.4984 smmd=0.2409 ct=9.9992 rec=1.2654 | train/val/test=0.911/0.834/0.835 | c=0.999488
[Epoch 0036] loss=2.8297 cls=0.4701 smmd=0.2334 ct=10.0008 rec=1.2602 | train/val/test=0.911/0.838/0.840 | c=0.999488
[Epoch 0037] loss=2.7940 cls=0.4431 smmd=0.2245 ct=10.0043 rec=1.2553 | train/val/test=0.924/0.841/0.843 | c=0.999488
[Epoch 0038] loss=2.7635 cls=0.4175 smmd=0.2192 ct=10.0089 rec=1.2507 | train/val/test=0.924/0.845/0.845 | c=0.999488
[Epoch 0039] loss=2.7290 cls=0.3936 smmd=0.2081 ct=10.0137 rec=1.2461 | train/val/test=0.924/0.848/0.851 | c=0.999488
[Epoch 0040] loss=2.7008 cls=0.3713 smmd=0.2022 ct=10.0158 rec=1.2418 | train/val/test=0.924/0.851/0.854 | c=0.999488
[Epoch 0041] loss=2.6696 cls=0.3503 smmd=0.1923 ct=10.0162 rec=1.2377 | train/val/test=0.937/0.852/0.856 | c=0.999488
[Epoch 0042] loss=2.6442 cls=0.3307 smmd=0.1868 ct=10.0168 rec=1.2338 | train/val/test=0.949/0.854/0.857 | c=0.999488
[Epoch 0043] loss=2.6139 cls=0.3124 smmd=0.1745 ct=10.0198 rec=1.2301 | train/val/test=0.949/0.854/0.857 | c=0.999488
[Epoch 0044] loss=2.5967 cls=0.2955 smmd=0.1739 ct=10.0228 rec=1.2268 | train/val/test=0.949/0.855/0.858 | c=0.999488
[Epoch 0045] loss=2.5718 cls=0.2798 smmd=0.1649 ct=10.0237 rec=1.2237 | train/val/test=0.949/0.855/0.858 | c=0.999488
[Epoch 0046] loss=2.5473 cls=0.2651 smmd=0.1559 ct=10.0207 rec=1.2210 | train/val/test=0.949/0.859/0.866 | c=0.999488
[Epoch 0047] loss=2.5306 cls=0.2515 smmd=0.1541 ct=10.0157 rec=1.2184 | train/val/test=0.949/0.876/0.881 | c=0.999488
[Epoch 0048] loss=2.5065 cls=0.2389 smmd=0.1432 ct=10.0143 rec=1.2158 | train/val/test=0.949/0.883/0.890 | c=0.999488
[Epoch 0049] loss=2.4899 cls=0.2269 smmd=0.1385 ct=10.0155 rec=1.2135 | train/val/test=0.949/0.885/0.892 | c=0.999488
[Epoch 0050] loss=2.4713 cls=0.2158 smmd=0.1311 ct=10.0161 rec=1.2115 | train/val/test=0.962/0.887/0.892 | c=0.999488
[Epoch 0051] loss=2.4554 cls=0.2056 smmd=0.1257 ct=10.0158 rec=1.2095 | train/val/test=0.962/0.889/0.894 | c=0.999488
[Epoch 0052] loss=2.4384 cls=0.1961 smmd=0.1188 ct=10.0139 rec=1.2074 | train/val/test=0.975/0.888/0.895 | c=0.999488
[Epoch 0053] loss=2.4273 cls=0.1872 smmd=0.1174 ct=10.0106 rec=1.2056 | train/val/test=0.975/0.888/0.895 | c=0.999488
[Epoch 0054] loss=2.4161 cls=0.1788 smmd=0.1154 ct=10.0075 rec=1.2041 | train/val/test=0.975/0.892/0.895 | c=0.999488
[Epoch 0055] loss=2.4018 cls=0.1711 smmd=0.1095 ct=10.0051 rec=1.2025 | train/val/test=0.987/0.892/0.895 | c=0.999488
[Epoch 0056] loss=2.3892 cls=0.1638 smmd=0.1049 ct=10.0018 rec=1.2010 | train/val/test=0.987/0.890/0.893 | c=0.999488
[Epoch 0057] loss=2.3794 cls=0.1569 smmd=0.1025 ct=10.0000 rec=1.1998 | train/val/test=0.987/0.890/0.894 | c=0.999488
[Epoch 0058] loss=2.3708 cls=0.1504 smmd=0.1006 ct=9.9996 rec=1.1983 | train/val/test=0.987/0.892/0.895 | c=0.999488
[Epoch 0059] loss=2.3633 cls=0.1445 smmd=0.0999 ct=9.9961 rec=1.1968 | train/val/test=0.987/0.890/0.895 | c=0.999488
[Epoch 0060] loss=2.3539 cls=0.1388 smmd=0.0969 ct=9.9930 rec=1.1956 | train/val/test=1.000/0.890/0.894 | c=0.999488
[Epoch 0061] loss=2.3461 cls=0.1333 smmd=0.0952 ct=9.9903 rec=1.1946 | train/val/test=1.000/0.890/0.894 | c=0.999488
[Epoch 0062] loss=2.3381 cls=0.1283 smmd=0.0930 ct=9.9878 rec=1.1935 | train/val/test=1.000/0.890/0.894 | c=0.999488
[Epoch 0063] loss=2.3314 cls=0.1235 smmd=0.0914 ct=9.9862 rec=1.1923 | train/val/test=1.000/0.890/0.894 | c=0.999488
[Epoch 0064] loss=2.3258 cls=0.1189 smmd=0.0909 ct=9.9844 rec=1.1913 | train/val/test=1.000/0.891/0.895 | c=0.999488
[Epoch 0065] loss=2.3198 cls=0.1145 smmd=0.0900 ct=9.9809 rec=1.1903 | train/val/test=1.000/0.891/0.894 | c=0.999488
[Epoch 0066] loss=2.3151 cls=0.1104 smmd=0.0900 ct=9.9789 rec=1.1893 | train/val/test=1.000/0.892/0.894 | c=0.999488
[Epoch 0067] loss=2.3103 cls=0.1065 smmd=0.0897 ct=9.9762 rec=1.1884 | train/val/test=1.000/0.892/0.894 | c=0.999488
[Epoch 0068] loss=2.3045 cls=0.1028 smmd=0.0881 ct=9.9744 rec=1.1872 | train/val/test=1.000/0.892/0.894 | c=0.999488
[Epoch 0069] loss=2.3006 cls=0.0990 smmd=0.0883 ct=9.9732 rec=1.1865 | train/val/test=1.000/0.891/0.893 | c=0.999488
[Epoch 0070] loss=2.2973 cls=0.0957 smmd=0.0887 ct=9.9713 rec=1.1859 | train/val/test=1.000/0.891/0.894 | c=0.999488
[Epoch 0071] loss=2.2934 cls=0.0925 smmd=0.0884 ct=9.9700 rec=1.1846 | train/val/test=1.000/0.892/0.893 | c=0.999488
[Epoch 0072] loss=2.2884 cls=0.0893 smmd=0.0869 ct=9.9692 rec=1.1839 | train/val/test=1.000/0.892/0.893 | c=0.999488
[Epoch 0073] loss=2.2856 cls=0.0863 smmd=0.0876 ct=9.9664 rec=1.1834 | train/val/test=1.000/0.892/0.893 | c=0.999488
[Epoch 0074] loss=2.2834 cls=0.0836 smmd=0.0887 ct=9.9643 rec=1.1823 | train/val/test=1.000/0.892/0.893 | c=0.999488
[Epoch 0075] loss=2.2796 cls=0.0808 smmd=0.0877 ct=9.9646 rec=1.1817 | train/val/test=1.000/0.892/0.893 | c=0.999488
[Epoch 0076] loss=2.2752 cls=0.0782 smmd=0.0862 ct=9.9633 rec=1.1811 | train/val/test=1.000/0.892/0.893 | c=0.999488
[Epoch 0077] loss=2.2728 cls=0.0759 smmd=0.0868 ct=9.9598 rec=1.1802 | train/val/test=1.000/0.891/0.893 | c=0.999488
[Epoch 0078] loss=2.2716 cls=0.0735 smmd=0.0884 ct=9.9583 rec=1.1796 | train/val/test=1.000/0.892/0.892 | c=0.999488
[Epoch 0079] loss=2.2672 cls=0.0712 smmd=0.0862 ct=9.9591 rec=1.1791 | train/val/test=1.000/0.888/0.892 | c=0.999488
[Epoch 0080] loss=2.2659 cls=0.0692 smmd=0.0870 ct=9.9595 rec=1.1781 | train/val/test=1.000/0.888/0.892 | c=0.999488
[Epoch 0081] loss=2.2625 cls=0.0672 smmd=0.0860 ct=9.9574 rec=1.1777 | train/val/test=1.000/0.889/0.892 | c=0.999488
[Epoch 0082] loss=2.2612 cls=0.0652 smmd=0.0871 ct=9.9555 rec=1.1773 | train/val/test=1.000/0.889/0.891 | c=0.999488
[Epoch 0083] loss=2.2585 cls=0.0635 smmd=0.0865 ct=9.9546 rec=1.1763 | train/val/test=1.000/0.890/0.891 | c=0.999488
[Epoch 0084] loss=2.2566 cls=0.0618 smmd=0.0865 ct=9.9538 rec=1.1761 | train/val/test=1.000/0.889/0.891 | c=0.999488
[Epoch 0085] loss=2.2542 cls=0.0601 smmd=0.0861 ct=9.9521 rec=1.1756 | train/val/test=1.000/0.888/0.891 | c=0.999488
[Epoch 0086] loss=2.2527 cls=0.0587 smmd=0.0862 ct=9.9516 rec=1.1749 | train/val/test=1.000/0.889/0.891 | c=0.999488
[Epoch 0087] loss=2.2509 cls=0.0572 smmd=0.0859 ct=9.9516 rec=1.1745 | train/val/test=1.000/0.887/0.891 | c=0.999488
[Epoch 0088] loss=2.2483 cls=0.0558 smmd=0.0852 ct=9.9497 rec=1.1739 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0089] loss=2.2473 cls=0.0545 smmd=0.0858 ct=9.9481 rec=1.1735 | train/val/test=1.000/0.888/0.891 | c=0.999488
[Epoch 0090] loss=2.2467 cls=0.0534 smmd=0.0866 ct=9.9471 rec=1.1730 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0091] loss=2.2456 cls=0.0521 smmd=0.0867 ct=9.9475 rec=1.1726 | train/val/test=1.000/0.887/0.891 | c=0.999488
[Epoch 0092] loss=2.2428 cls=0.0510 smmd=0.0855 ct=9.9449 rec=1.1720 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0093] loss=2.2411 cls=0.0500 smmd=0.0850 ct=9.9445 rec=1.1717 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0094] loss=2.2381 cls=0.0490 smmd=0.0831 ct=9.9438 rec=1.1712 | train/val/test=1.000/0.888/0.891 | c=0.999488
[Epoch 0095] loss=2.2374 cls=0.0480 smmd=0.0837 ct=9.9432 rec=1.1709 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0096] loss=2.2377 cls=0.0472 smmd=0.0850 ct=9.9422 rec=1.1704 | train/val/test=1.000/0.888/0.891 | c=0.999488
[Epoch 0097] loss=2.2357 cls=0.0464 smmd=0.0844 ct=9.9395 rec=1.1700 | train/val/test=1.000/0.888/0.891 | c=0.999488
[Epoch 0098] loss=2.2333 cls=0.0455 smmd=0.0829 ct=9.9393 rec=1.1698 | train/val/test=1.000/0.887/0.891 | c=0.999488
[Epoch 0099] loss=2.2330 cls=0.0448 smmd=0.0834 ct=9.9396 rec=1.1695 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0100] loss=2.2325 cls=0.0441 smmd=0.0839 ct=9.9379 rec=1.1689 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0101] loss=2.2306 cls=0.0434 smmd=0.0831 ct=9.9361 rec=1.1690 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0102] loss=2.2296 cls=0.0428 smmd=0.0832 ct=9.9335 rec=1.1682 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0103] loss=2.2295 cls=0.0422 smmd=0.0831 ct=9.9365 rec=1.1684 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0104] loss=2.2268 cls=0.0416 smmd=0.0816 ct=9.9342 rec=1.1678 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0105] loss=2.2266 cls=0.0410 smmd=0.0826 ct=9.9313 rec=1.1676 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0106] loss=2.2258 cls=0.0405 smmd=0.0819 ct=9.9330 rec=1.1675 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0107] loss=2.2253 cls=0.0401 smmd=0.0827 ct=9.9288 rec=1.1670 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0108] loss=2.2242 cls=0.0395 smmd=0.0822 ct=9.9284 rec=1.1672 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0109] loss=2.2232 cls=0.0391 smmd=0.0817 ct=9.9289 rec=1.1665 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0110] loss=2.2218 cls=0.0386 smmd=0.0811 ct=9.9272 rec=1.1667 | train/val/test=1.000/0.885/0.891 | c=0.999488
[Epoch 0111] loss=2.2217 cls=0.0383 smmd=0.0819 ct=9.9247 rec=1.1663 | train/val/test=1.000/0.885/0.892 | c=0.999488
[Epoch 0112] loss=2.2206 cls=0.0377 smmd=0.0814 ct=9.9244 rec=1.1663 | train/val/test=1.000/0.886/0.892 | c=0.999488
[Epoch 0113] loss=2.2193 cls=0.0374 smmd=0.0807 ct=9.9232 rec=1.1658 | train/val/test=1.000/0.884/0.890 | c=0.999488
[Epoch 0114] loss=2.2195 cls=0.0370 smmd=0.0814 ct=9.9224 rec=1.1658 | train/val/test=1.000/0.885/0.891 | c=0.999488
[Epoch 0115] loss=2.2181 cls=0.0366 smmd=0.0805 ct=9.9222 rec=1.1658 | train/val/test=1.000/0.884/0.891 | c=0.999488
[Epoch 0116] loss=2.2162 cls=0.0363 smmd=0.0797 ct=9.9181 rec=1.1652 | train/val/test=1.000/0.884/0.891 | c=0.999488
[Epoch 0117] loss=2.2151 cls=0.0359 smmd=0.0786 ct=9.9200 rec=1.1655 | train/val/test=1.000/0.884/0.891 | c=0.999488
[Epoch 0118] loss=2.2156 cls=0.0355 smmd=0.0795 ct=9.9200 rec=1.1649 | train/val/test=1.000/0.884/0.891 | c=0.999488
[Epoch 0119] loss=2.2151 cls=0.0352 smmd=0.0803 ct=9.9151 rec=1.1651 | train/val/test=1.000/0.886/0.891 | c=0.999488
[Epoch 0120] loss=2.2138 cls=0.0350 smmd=0.0794 ct=9.9148 rec=1.1648 | train/val/test=1.000/0.884/0.891 | c=0.999488
[Epoch 0121] loss=2.2138 cls=0.0345 smmd=0.0796 ct=9.9160 rec=1.1647 | train/val/test=1.000/0.884/0.891 | c=0.999488
[Epoch 0122] loss=2.2113 cls=0.0343 smmd=0.0781 ct=9.9120 rec=1.1647 | train/val/test=1.000/0.882/0.891 | c=0.999488
[Epoch 0123] loss=2.2114 cls=0.0340 smmd=0.0785 ct=9.9125 rec=1.1642 | train/val/test=1.000/0.885/0.891 | c=0.999488
[Epoch 0124] loss=2.2113 cls=0.0335 smmd=0.0786 ct=9.9136 rec=1.1644 | train/val/test=1.000/0.884/0.891 | c=0.999488
[Epoch 0125] loss=2.2104 cls=0.0333 smmd=0.0789 ct=9.9091 rec=1.1641 | train/val/test=1.000/0.884/0.891 | c=0.999488
[Epoch 0126] loss=2.2084 cls=0.0331 smmd=0.0773 ct=9.9083 rec=1.1640 | train/val/test=1.000/0.883/0.891 | c=0.999488
[Epoch 0127] loss=2.2091 cls=0.0328 smmd=0.0783 ct=9.9080 rec=1.1637 | train/val/test=1.000/0.883/0.891 | c=0.999488
[Epoch 0128] loss=2.2062 cls=0.0324 smmd=0.0754 ct=9.9100 rec=1.1638 | train/val/test=1.000/0.883/0.891 | c=0.999488
[Epoch 0129] loss=2.2072 cls=0.0322 smmd=0.0772 ct=9.9070 rec=1.1634 | train/val/test=1.000/0.881/0.890 | c=0.999488
[Epoch 0130] loss=2.2063 cls=0.0319 smmd=0.0769 ct=9.9057 rec=1.1636 | train/val/test=1.000/0.885/0.892 | c=0.999488
[Epoch 0131] loss=2.2068 cls=0.0318 smmd=0.0780 ct=9.9036 rec=1.1632 | train/val/test=1.000/0.880/0.890 | c=0.999488
[Epoch 0132] loss=2.2054 cls=0.0314 smmd=0.0766 ct=9.9051 rec=1.1636 | train/val/test=1.000/0.884/0.892 | c=0.999488
[Epoch 0133] loss=2.2043 cls=0.0314 smmd=0.0765 ct=9.9002 rec=1.1626 | train/val/test=1.000/0.881/0.890 | c=0.999488
[Epoch 0134] loss=2.2040 cls=0.0308 smmd=0.0758 ct=9.9048 rec=1.1639 | train/val/test=1.000/0.882/0.891 | c=0.999488
[Epoch 0135] loss=2.2035 cls=0.0311 smmd=0.0769 ct=9.8966 rec=1.1621 | train/val/test=1.000/0.881/0.890 | c=0.999488
[Epoch 0136] loss=2.2027 cls=0.0304 smmd=0.0756 ct=9.9017 rec=1.1639 | train/val/test=1.000/0.881/0.892 | c=0.999488
[Epoch 0137] loss=2.2029 cls=0.0307 smmd=0.0772 ct=9.8943 rec=1.1617 | train/val/test=1.000/0.884/0.890 | c=0.999488
[Epoch 0138] loss=2.2014 cls=0.0302 smmd=0.0742 ct=9.9031 rec=1.1644 | train/val/test=1.000/0.883/0.890 | c=0.999488
[Epoch 0139] loss=2.2021 cls=0.0310 smmd=0.0772 ct=9.8893 rec=1.1606 | train/val/test=1.000/0.882/0.887 | c=0.999488
[Epoch 0140] loss=2.2053 cls=0.0309 smmd=0.0767 ct=9.9055 rec=1.1667 | train/val/test=1.000/0.880/0.891 | c=0.999488
[Epoch 0141] loss=2.2099 cls=0.0342 smmd=0.0826 ct=9.8863 rec=1.1587 | train/val/test=1.000/0.881/0.881 | c=0.999488
[Epoch 0142] loss=2.2234 cls=0.0381 smmd=0.0824 ct=9.9273 rec=1.1749 | train/val/test=0.987/0.874/0.884 | c=0.999488
[Epoch 0143] loss=2.2534 cls=0.0552 smmd=0.1048 ct=9.8878 rec=1.1588 | train/val/test=0.987/0.832/0.824 | c=0.999488
[Epoch 0144] loss=2.3092 cls=0.0805 smmd=0.1112 ct=9.9918 rec=1.1914 | train/val/test=0.975/0.851/0.865 | c=0.999488
[Epoch 0145] loss=2.4748 cls=0.1769 smmd=0.1916 ct=9.9421 rec=1.1792 | train/val/test=0.886/0.720/0.711 | c=0.999488
[Epoch 0146] loss=2.7018 cls=0.3168 smmd=0.2326 ct=10.1544 rec=1.2152 | train/val/test=0.835/0.666/0.682 | c=0.999488
[Epoch 0147] loss=2.8552 cls=0.4432 smmd=0.2863 ct=9.9982 rec=1.2606 | train/val/test=0.797/0.596/0.590 | c=0.999488
[Epoch 0148] loss=3.6319 cls=0.9470 smmd=0.4831 ct=10.3784 rec=1.2602 | train/val/test=0.544/0.364/0.358 | c=0.999488
[Epoch 0149] loss=4.4210 cls=1.5636 smmd=0.6312 ct=10.4669 rec=1.3280 | train/val/test=0.734/0.657/0.671 | c=0.999488
[Epoch 0150] loss=4.6153 cls=1.5170 smmd=0.9147 ct=10.2984 rec=1.2398 | train/val/test=0.747/0.649/0.664 | c=0.999488
[Epoch 0151] loss=4.6562 cls=1.4461 smmd=1.0402 ct=10.2265 rec=1.2461 | train/val/test=0.937/0.769/0.775 | c=0.999488
[Epoch 0152] loss=2.9531 cls=0.2103 smmd=0.6198 ct=10.0093 rec=1.2112 | train/val/test=0.646/0.390/0.394 | c=0.999488
[Epoch 0153] loss=4.2032 cls=1.1583 smmd=0.8392 ct=10.3597 rec=1.3371 | train/val/test=0.975/0.887/0.890 | c=0.999488
[Epoch 0154] loss=2.5297 cls=0.0628 smmd=0.3279 ct=10.1122 rec=1.1653 | train/val/test=0.924/0.839/0.851 | c=0.999488
[Epoch 0155] loss=3.0293 cls=0.3383 smmd=0.5360 ct=10.1904 rec=1.1693 | train/val/test=0.899/0.792/0.800 | c=0.999488
[Epoch 0156] loss=3.2577 cls=0.4734 smmd=0.6255 ct=10.2037 rec=1.1802 | train/val/test=0.962/0.840/0.853 | c=0.999488
[Epoch 0157] loss=2.5588 cls=0.0734 smmd=0.3630 ct=10.0361 rec=1.1523 | train/val/test=1.000/0.849/0.852 | c=0.999488
[Epoch 0158] loss=2.6379 cls=0.0349 smmd=0.4485 ct=10.1874 rec=1.1702 | train/val/test=0.911/0.696/0.689 | c=0.999488
[Epoch 0159] loss=3.0336 cls=0.2343 smmd=0.6025 ct=10.3829 rec=1.2027 | train/val/test=1.000/0.829/0.833 | c=0.999488
[Epoch 0160] loss=2.6270 cls=0.0346 smmd=0.4225 ct=10.2653 rec=1.1679 | train/val/test=0.987/0.873/0.878 | c=0.999488
[Epoch 0161] loss=2.5233 cls=0.0325 smmd=0.3546 ct=10.1058 rec=1.1502 | train/val/test=0.962/0.858/0.872 | c=0.999488
[Epoch 0162] loss=2.6883 cls=0.1311 smmd=0.4315 ct=10.0547 rec=1.1479 | train/val/test=0.962/0.859/0.878 | c=0.999488
[Epoch 0163] loss=2.6971 cls=0.1409 smmd=0.4336 ct=10.0390 rec=1.1488 | train/val/test=0.975/0.875/0.884 | c=0.999488
[Epoch 0164] loss=2.5528 cls=0.0650 smmd=0.3650 ct=10.0392 rec=1.1499 | train/val/test=1.000/0.873/0.879 | c=0.999488
[Epoch 0165] loss=2.5035 cls=0.0155 smmd=0.3516 ct=10.1068 rec=1.1506 | train/val/test=1.000/0.857/0.863 | c=0.999488
[Epoch 0166] loss=2.5570 cls=0.0154 smmd=0.3867 ct=10.1959 rec=1.1570 | train/val/test=1.000/0.839/0.850 | c=0.999488
[Epoch 0167] loss=2.5576 cls=0.0166 smmd=0.3816 ct=10.2172 rec=1.1594 | train/val/test=1.000/0.860/0.866 | c=0.999488
[Epoch 0168] loss=2.4881 cls=0.0097 smmd=0.3306 ct=10.1617 rec=1.1544 | train/val/test=1.000/0.876/0.881 | c=0.999488
[Epoch 0169] loss=2.4530 cls=0.0129 smmd=0.3086 ct=10.0827 rec=1.1495 | train/val/test=0.987/0.884/0.887 | c=0.999488
[Epoch 0170] loss=2.4556 cls=0.0266 smmd=0.3072 ct=10.0352 rec=1.1480 | train/val/test=0.987/0.884/0.890 | c=0.999488
[Epoch 0171] loss=2.4590 cls=0.0298 smmd=0.3090 ct=10.0265 rec=1.1482 | train/val/test=0.987/0.884/0.891 | c=0.999488
[Epoch 0172] loss=2.4239 cls=0.0179 smmd=0.2842 ct=10.0351 rec=1.1481 | train/val/test=1.000/0.879/0.889 | c=0.999488
[Epoch 0173] loss=2.3986 cls=0.0088 smmd=0.2649 ct=10.0502 rec=1.1484 | train/val/test=1.000/0.879/0.886 | c=0.999488
[Epoch 0174] loss=2.3889 cls=0.0073 smmd=0.2534 ct=10.0658 rec=1.1502 | train/val/test=1.000/0.879/0.885 | c=0.999488
[Epoch 0175] loss=2.3760 cls=0.0081 smmd=0.2388 ct=10.0702 rec=1.1514 | train/val/test=1.000/0.885/0.891 | c=0.999488
[Epoch 0176] loss=2.3622 cls=0.0082 smmd=0.2275 ct=10.0571 rec=1.1506 | train/val/test=1.000/0.887/0.893 | c=0.999488
[Epoch 0177] loss=2.3377 cls=0.0084 smmd=0.2073 ct=10.0355 rec=1.1491 | train/val/test=1.000/0.884/0.894 | c=0.999488
[Epoch 0178] loss=2.3259 cls=0.0088 smmd=0.1984 ct=10.0197 rec=1.1477 | train/val/test=1.000/0.882/0.890 | c=0.999488
[Epoch 0179] loss=2.3216 cls=0.0084 smmd=0.1957 ct=10.0140 rec=1.1470 | train/val/test=1.000/0.880/0.887 | c=0.999488
[Epoch 0180] loss=2.3074 cls=0.0077 smmd=0.1825 ct=10.0119 rec=1.1473 | train/val/test=1.000/0.876/0.882 | c=0.999488
[Epoch 0181] loss=2.2896 cls=0.0079 smmd=0.1652 ct=10.0081 rec=1.1485 | train/val/test=1.000/0.875/0.883 | c=0.999488
[Epoch 0182] loss=2.2825 cls=0.0088 smmd=0.1577 ct=10.0051 rec=1.1498 | train/val/test=1.000/0.878/0.885 | c=0.999488
[Epoch 0183] loss=2.2732 cls=0.0095 smmd=0.1476 ct=10.0050 rec=1.1504 | train/val/test=1.000/0.877/0.886 | c=0.999488
[Epoch 0184] loss=2.2656 cls=0.0098 smmd=0.1401 ct=10.0037 rec=1.1500 | train/val/test=1.000/0.880/0.887 | c=0.999488
[Epoch 0185] loss=2.2536 cls=0.0097 smmd=0.1294 ct=9.9980 rec=1.1492 | train/val/test=1.000/0.878/0.885 | c=0.999488
[Epoch 0186] loss=2.2479 cls=0.0098 smmd=0.1257 ct=9.9874 rec=1.1489 | train/val/test=1.000/0.873/0.881 | c=0.999488
[Epoch 0187] loss=2.2435 cls=0.0104 smmd=0.1230 ct=9.9758 rec=1.1495 | train/val/test=1.000/0.871/0.881 | c=0.999488
[Epoch 0188] loss=2.2356 cls=0.0112 smmd=0.1156 ct=9.9685 rec=1.1504 | train/val/test=1.000/0.873/0.881 | c=0.999488
[Epoch 0189] loss=2.2310 cls=0.0121 smmd=0.1102 ct=9.9680 rec=1.1513 | train/val/test=1.000/0.873/0.882 | c=0.999488
[Epoch 0190] loss=2.2265 cls=0.0129 smmd=0.1044 ct=9.9700 rec=1.1517 | train/val/test=1.000/0.873/0.881 | c=0.999488
[Epoch 0191] loss=2.2222 cls=0.0135 smmd=0.1001 ct=9.9674 rec=1.1517 | train/val/test=1.000/0.871/0.879 | c=0.999488
[Epoch 0192] loss=2.2163 cls=0.0140 smmd=0.0955 ct=9.9583 rec=1.1517 | train/val/test=1.000/0.870/0.880 | c=0.999488
[Epoch 0193] loss=2.2152 cls=0.0144 smmd=0.0961 ct=9.9481 rec=1.1520 | train/val/test=1.000/0.869/0.880 | c=0.999488
[Epoch 0194] loss=2.2105 cls=0.0147 smmd=0.0920 ct=9.9427 rec=1.1525 | train/val/test=1.000/0.872/0.880 | c=0.999488
[Epoch 0195] loss=2.2093 cls=0.0153 smmd=0.0903 ct=9.9421 rec=1.1531 | train/val/test=1.000/0.871/0.881 | c=0.999488
[Epoch 0196] loss=2.2085 cls=0.0160 smmd=0.0886 ct=9.9423 rec=1.1536 | train/val/test=1.000/0.871/0.879 | c=0.999488
[Epoch 0197] loss=2.2058 cls=0.0169 smmd=0.0859 ct=9.9382 rec=1.1538 | train/val/test=1.000/0.873/0.880 | c=0.999488
[Epoch 0198] loss=2.2047 cls=0.0175 smmd=0.0857 ct=9.9303 rec=1.1541 | train/val/test=1.000/0.874/0.880 | c=0.999488
[Epoch 0199] loss=2.2030 cls=0.0178 smmd=0.0848 ct=9.9246 rec=1.1544 | train/val/test=1.000/0.875/0.882 | c=0.999488
=== Best @ epoch 54: val=0.8923, test=0.8947 ===
[2025-09-20 03:21:42] END attempt 1: exit_code=0
