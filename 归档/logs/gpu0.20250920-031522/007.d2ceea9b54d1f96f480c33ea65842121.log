[2025-09-20 03:48:38] START attempt 1: python main.py --is_transfer True --test_dataset PubMed --pretrained_model_name /mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth --few False --gpu_id 0
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.9733 cls=1.0933 smmd=5.6214 ct=7.2531 rec=1.4136 | train/val/test=0.594/0.597/0.594 | c=0.998437
[Epoch 0001] loss=52.5307 cls=1.0624 smmd=3.6893 ct=7.1995 rec=1.4154 | train/val/test=0.628/0.628/0.625 | c=0.998437
[Epoch 0002] loss=37.6234 cls=1.0640 smmd=2.2160 ct=7.1120 rec=1.4141 | train/val/test=0.597/0.607/0.607 | c=0.998437
[Epoch 0003] loss=40.1457 cls=1.0539 smmd=2.4786 ct=7.0628 rec=1.4136 | train/val/test=0.580/0.588/0.587 | c=0.998437
[Epoch 0004] loss=39.4336 cls=1.0137 smmd=2.4199 ct=7.0105 rec=1.4144 | train/val/test=0.561/0.568/0.569 | c=0.998437
[Epoch 0005] loss=35.2422 cls=0.9708 smmd=2.0153 ct=6.9478 rec=1.4162 | train/val/test=0.535/0.538/0.538 | c=0.998437
[Epoch 0006] loss=30.4195 cls=0.9335 smmd=1.5403 ct=6.9213 rec=1.4150 | train/val/test=0.530/0.533/0.529 | c=0.998437
[Epoch 0007] loss=34.2078 cls=0.8919 smmd=1.7794 ct=7.6316 rec=1.4097 | train/val/test=0.549/0.554/0.548 | c=0.998437
[Epoch 0008] loss=34.9882 cls=0.8514 smmd=1.8789 ct=7.5360 rec=1.4028 | train/val/test=0.610/0.613/0.608 | c=0.998437
[Epoch 0009] loss=29.1912 cls=0.8049 smmd=1.3146 ct=7.4731 rec=1.3921 | train/val/test=0.644/0.658/0.647 | c=0.998437
[Epoch 0010] loss=28.2049 cls=0.7721 smmd=1.2126 ct=7.5007 rec=1.3827 | train/val/test=0.658/0.674/0.660 | c=0.998437
[Epoch 0011] loss=29.6011 cls=0.7492 smmd=1.3530 ct=7.5043 rec=1.3758 | train/val/test=0.688/0.699/0.683 | c=0.998437
[Epoch 0012] loss=27.1599 cls=0.7283 smmd=1.1143 ct=7.4847 rec=1.3662 | train/val/test=0.694/0.708/0.689 | c=0.998437
[Epoch 0013] loss=26.8707 cls=0.7123 smmd=1.0751 ct=7.5416 rec=1.3598 | train/val/test=0.697/0.709/0.693 | c=0.998437
[Epoch 0014] loss=24.9849 cls=0.6955 smmd=0.8834 ct=7.5611 rec=1.3613 | train/val/test=0.709/0.726/0.697 | c=0.998437
[Epoch 0015] loss=25.4436 cls=0.6722 smmd=0.9407 ct=7.5114 rec=1.3554 | train/val/test=0.718/0.731/0.708 | c=0.998437
[Epoch 0016] loss=25.1328 cls=0.6549 smmd=0.9103 ct=7.5150 rec=1.3456 | train/val/test=0.738/0.754/0.730 | c=0.998437
[Epoch 0017] loss=22.9660 cls=0.6426 smmd=0.6886 ct=7.5451 rec=1.3373 | train/val/test=0.755/0.768/0.741 | c=0.998437
[Epoch 0018] loss=23.3211 cls=0.6161 smmd=0.7286 ct=7.5301 rec=1.3339 | train/val/test=0.766/0.777/0.753 | c=0.998437
[Epoch 0019] loss=22.8988 cls=0.5948 smmd=0.6911 ct=7.5127 rec=1.3308 | train/val/test=0.769/0.780/0.758 | c=0.998437
[Epoch 0020] loss=22.1023 cls=0.5901 smmd=0.6134 ct=7.5058 rec=1.3240 | train/val/test=0.778/0.790/0.764 | c=0.998437
[Epoch 0021] loss=21.6390 cls=0.5766 smmd=0.5643 ct=7.5231 rec=1.3220 | train/val/test=0.790/0.796/0.777 | c=0.998437
[Epoch 0022] loss=21.4676 cls=0.5484 smmd=0.5473 ct=7.5293 rec=1.3226 | train/val/test=0.795/0.798/0.785 | c=0.998437
[Epoch 0023] loss=21.0606 cls=0.5371 smmd=0.5103 ct=7.5147 rec=1.3199 | train/val/test=0.799/0.800/0.784 | c=0.998437
[Epoch 0024] loss=20.5039 cls=0.5333 smmd=0.4541 ct=7.5187 rec=1.3170 | train/val/test=0.803/0.808/0.793 | c=0.998437
[Epoch 0025] loss=20.3942 cls=0.5188 smmd=0.4436 ct=7.5203 rec=1.3171 | train/val/test=0.812/0.815/0.802 | c=0.998437
[Epoch 0026] loss=20.0458 cls=0.5050 smmd=0.4126 ct=7.5039 rec=1.3200 | train/val/test=0.817/0.818/0.810 | c=0.998437
[Epoch 0027] loss=19.8791 cls=0.4966 smmd=0.3941 ct=7.5158 rec=1.3170 | train/val/test=0.817/0.818/0.809 | c=0.998437
[Epoch 0028] loss=19.5805 cls=0.4902 smmd=0.3614 ct=7.5319 rec=1.3156 | train/val/test=0.825/0.821/0.809 | c=0.998437
[Epoch 0029] loss=19.3929 cls=0.4801 smmd=0.3466 ct=7.5143 rec=1.3163 | train/val/test=0.826/0.825/0.819 | c=0.998437
[Epoch 0030] loss=19.1818 cls=0.4746 smmd=0.3292 ct=7.4977 rec=1.3131 | train/val/test=0.828/0.824/0.817 | c=0.998437
[Epoch 0031] loss=18.8950 cls=0.4675 smmd=0.3005 ct=7.4996 rec=1.3133 | train/val/test=0.830/0.827/0.819 | c=0.998437
[Epoch 0032] loss=18.8399 cls=0.4620 smmd=0.2918 ct=7.5173 rec=1.3119 | train/val/test=0.830/0.830/0.823 | c=0.998437
[Epoch 0033] loss=18.5427 cls=0.4590 smmd=0.2637 ct=7.5107 rec=1.3103 | train/val/test=0.834/0.830/0.826 | c=0.998437
[Epoch 0034] loss=18.4487 cls=0.4577 smmd=0.2590 ct=7.4871 rec=1.3120 | train/val/test=0.834/0.837/0.827 | c=0.998437
[Epoch 0035] loss=18.3457 cls=0.4544 smmd=0.2480 ct=7.4922 rec=1.3090 | train/val/test=0.832/0.829/0.823 | c=0.998437
[Epoch 0036] loss=18.1487 cls=0.4550 smmd=0.2253 ct=7.5067 rec=1.3106 | train/val/test=0.837/0.835/0.826 | c=0.998437
[Epoch 0037] loss=18.1268 cls=0.4523 smmd=0.2246 ct=7.4991 rec=1.3124 | train/val/test=0.836/0.836/0.828 | c=0.998437
[Epoch 0038] loss=17.9333 cls=0.4536 smmd=0.2064 ct=7.4932 rec=1.3117 | train/val/test=0.837/0.836/0.827 | c=0.998437
[Epoch 0039] loss=17.9177 cls=0.4551 smmd=0.2046 ct=7.4941 rec=1.3131 | train/val/test=0.834/0.833/0.822 | c=0.998437
[Epoch 0040] loss=17.7605 cls=0.4581 smmd=0.1883 ct=7.4961 rec=1.3131 | train/val/test=0.838/0.836/0.827 | c=0.998437
[Epoch 0041] loss=17.7625 cls=0.4564 smmd=0.1894 ct=7.4913 rec=1.3149 | train/val/test=0.837/0.837/0.828 | c=0.998437
[Epoch 0042] loss=17.6371 cls=0.4589 smmd=0.1764 ct=7.4935 rec=1.3137 | train/val/test=0.837/0.835/0.827 | c=0.998437
[Epoch 0043] loss=17.5922 cls=0.4580 smmd=0.1727 ct=7.4892 rec=1.3154 | train/val/test=0.837/0.837/0.829 | c=0.998437
[Epoch 0044] loss=17.3938 cls=0.4598 smmd=0.1540 ct=7.4832 rec=1.3147 | train/val/test=0.833/0.833/0.824 | c=0.998437
[Epoch 0045] loss=17.3822 cls=0.4630 smmd=0.1524 ct=7.4849 rec=1.3142 | train/val/test=0.837/0.837/0.830 | c=0.998437
[Epoch 0046] loss=17.2721 cls=0.4593 smmd=0.1431 ct=7.4769 rec=1.3161 | train/val/test=0.835/0.835/0.826 | c=0.998437
[Epoch 0047] loss=17.2706 cls=0.4612 smmd=0.1426 ct=7.4783 rec=1.3144 | train/val/test=0.839/0.837/0.832 | c=0.998437
[Epoch 0048] loss=17.2139 cls=0.4595 smmd=0.1376 ct=7.4751 rec=1.3170 | train/val/test=0.839/0.838/0.830 | c=0.998437
[Epoch 0049] loss=17.1879 cls=0.4638 smmd=0.1344 ct=7.4769 rec=1.3160 | train/val/test=0.838/0.838/0.829 | c=0.998437
[Epoch 0050] loss=17.1156 cls=0.4631 smmd=0.1287 ct=7.4692 rec=1.3175 | train/val/test=0.841/0.838/0.833 | c=0.998437
[Epoch 0051] loss=17.0476 cls=0.4637 smmd=0.1228 ct=7.4637 rec=1.3197 | train/val/test=0.836/0.835/0.829 | c=0.998437
[Epoch 0052] loss=17.0577 cls=0.4664 smmd=0.1216 ct=7.4748 rec=1.3183 | train/val/test=0.842/0.840/0.834 | c=0.998437
[Epoch 0053] loss=17.0971 cls=0.4649 smmd=0.1271 ct=7.4665 rec=1.3210 | train/val/test=0.837/0.837/0.832 | c=0.998437
[Epoch 0054] loss=17.0788 cls=0.4675 smmd=0.1260 ct=7.4626 rec=1.3194 | train/val/test=0.841/0.840/0.833 | c=0.998437
[Epoch 0055] loss=17.0638 cls=0.4659 smmd=0.1257 ct=7.4563 rec=1.3226 | train/val/test=0.834/0.835/0.824 | c=0.998437
[Epoch 0056] loss=17.0145 cls=0.4709 smmd=0.1185 ct=7.4664 rec=1.3215 | train/val/test=0.843/0.840/0.835 | c=0.998437
[Epoch 0057] loss=16.9781 cls=0.4688 smmd=0.1181 ct=7.4509 rec=1.3223 | train/val/test=0.835/0.834/0.824 | c=0.998437
[Epoch 0058] loss=17.0113 cls=0.4676 smmd=0.1201 ct=7.4576 rec=1.3228 | train/val/test=0.841/0.840/0.835 | c=0.998437
[Epoch 0059] loss=17.0095 cls=0.4704 smmd=0.1230 ct=7.4417 rec=1.3215 | train/val/test=0.829/0.828/0.820 | c=0.998437
[Epoch 0060] loss=17.0691 cls=0.4756 smmd=0.1261 ct=7.4537 rec=1.3254 | train/val/test=0.836/0.836/0.826 | c=0.998437
[Epoch 0061] loss=17.1135 cls=0.4827 smmd=0.1328 ct=7.4406 rec=1.3269 | train/val/test=0.819/0.822/0.813 | c=0.998437
[Epoch 0062] loss=17.1076 cls=0.4907 smmd=0.1286 ct=7.4558 rec=1.3298 | train/val/test=0.834/0.832/0.820 | c=0.998437
[Epoch 0063] loss=17.1121 cls=0.4873 smmd=0.1340 ct=7.4322 rec=1.3289 | train/val/test=0.821/0.823/0.813 | c=0.998437
[Epoch 0064] loss=17.1363 cls=0.4864 smmd=0.1322 ct=7.4533 rec=1.3288 | train/val/test=0.838/0.837/0.827 | c=0.998437
[Epoch 0065] loss=17.0771 cls=0.4784 smmd=0.1331 ct=7.4218 rec=1.3262 | train/val/test=0.830/0.831/0.820 | c=0.998437
[Epoch 0066] loss=17.0200 cls=0.4725 smmd=0.1237 ct=7.4422 rec=1.3250 | train/val/test=0.841/0.839/0.832 | c=0.998437
[Epoch 0067] loss=16.9963 cls=0.4680 smmd=0.1253 ct=7.4240 rec=1.3233 | train/val/test=0.837/0.835/0.829 | c=0.998437
[Epoch 0068] loss=16.9133 cls=0.4657 smmd=0.1166 ct=7.4260 rec=1.3243 | train/val/test=0.842/0.838/0.831 | c=0.998437
[Epoch 0069] loss=16.9119 cls=0.4691 smmd=0.1172 ct=7.4217 rec=1.3233 | train/val/test=0.842/0.840/0.831 | c=0.998437
[Epoch 0070] loss=16.8955 cls=0.4683 smmd=0.1140 ct=7.4288 rec=1.3275 | train/val/test=0.841/0.840/0.834 | c=0.998437
[Epoch 0071] loss=16.8383 cls=0.4744 smmd=0.1101 ct=7.4188 rec=1.3254 | train/val/test=0.842/0.841/0.831 | c=0.998437
[Epoch 0072] loss=16.8160 cls=0.4716 smmd=0.1074 ct=7.4210 rec=1.3290 | train/val/test=0.843/0.839/0.833 | c=0.998437
[Epoch 0073] loss=16.8465 cls=0.4761 smmd=0.1104 ct=7.4208 rec=1.3262 | train/val/test=0.842/0.840/0.830 | c=0.998437
[Epoch 0074] loss=16.8677 cls=0.4718 smmd=0.1123 ct=7.4223 rec=1.3293 | train/val/test=0.841/0.839/0.834 | c=0.998437
[Epoch 0075] loss=16.9125 cls=0.4778 smmd=0.1182 ct=7.4147 rec=1.3245 | train/val/test=0.841/0.838/0.829 | c=0.998437
[Epoch 0076] loss=16.8818 cls=0.4703 smmd=0.1133 ct=7.4246 rec=1.3290 | train/val/test=0.838/0.839/0.828 | c=0.998437
[Epoch 0077] loss=16.8907 cls=0.4801 smmd=0.1163 ct=7.4134 rec=1.3219 | train/val/test=0.833/0.833/0.821 | c=0.998437
[Epoch 0078] loss=16.9837 cls=0.4718 smmd=0.1232 ct=7.4259 rec=1.3282 | train/val/test=0.835/0.837/0.828 | c=0.998437
[Epoch 0079] loss=16.9763 cls=0.4858 smmd=0.1247 ct=7.4129 rec=1.3219 | train/val/test=0.819/0.822/0.812 | c=0.998437
[Epoch 0080] loss=16.9835 cls=0.4841 smmd=0.1219 ct=7.4285 rec=1.3299 | train/val/test=0.832/0.834/0.820 | c=0.998437
[Epoch 0081] loss=16.9541 cls=0.4904 smmd=0.1229 ct=7.4088 rec=1.3245 | train/val/test=0.814/0.817/0.806 | c=0.998437
[Epoch 0082] loss=17.0237 cls=0.4922 smmd=0.1250 ct=7.4313 rec=1.3303 | train/val/test=0.824/0.822/0.806 | c=0.998437
[Epoch 0083] loss=17.0957 cls=0.5017 smmd=0.1376 ct=7.4019 rec=1.3301 | train/val/test=0.807/0.812/0.799 | c=0.998437
[Epoch 0084] loss=17.0915 cls=0.5069 smmd=0.1290 ct=7.4403 rec=1.3341 | train/val/test=0.826/0.821/0.808 | c=0.998437
[Epoch 0085] loss=17.0442 cls=0.4973 smmd=0.1324 ct=7.4028 rec=1.3319 | train/val/test=0.818/0.820/0.810 | c=0.998437
[Epoch 0086] loss=17.0070 cls=0.4911 smmd=0.1251 ct=7.4230 rec=1.3282 | train/val/test=0.840/0.838/0.823 | c=0.998437
[Epoch 0087] loss=16.9219 cls=0.4767 smmd=0.1206 ct=7.4066 rec=1.3279 | train/val/test=0.830/0.834/0.828 | c=0.998437
[Epoch 0088] loss=16.8281 cls=0.4752 smmd=0.1106 ct=7.4113 rec=1.3234 | train/val/test=0.841/0.839/0.828 | c=0.998437
[Epoch 0089] loss=16.7819 cls=0.4708 smmd=0.1071 ct=7.4059 rec=1.3275 | train/val/test=0.838/0.837/0.835 | c=0.998437
[Epoch 0090] loss=16.8060 cls=0.4790 smmd=0.1092 ct=7.4061 rec=1.3246 | train/val/test=0.839/0.838/0.827 | c=0.998437
[Epoch 0091] loss=16.8703 cls=0.4784 smmd=0.1134 ct=7.4154 rec=1.3315 | train/val/test=0.839/0.842/0.830 | c=0.998437
[Epoch 0092] loss=16.8928 cls=0.4892 smmd=0.1183 ct=7.4006 rec=1.3271 | train/val/test=0.837/0.836/0.824 | c=0.998437
[Epoch 0093] loss=16.9387 cls=0.4840 smmd=0.1178 ct=7.4257 rec=1.3347 | train/val/test=0.835/0.837/0.822 | c=0.998437
[Epoch 0094] loss=17.0125 cls=0.5073 smmd=0.1284 ct=7.4053 rec=1.3279 | train/val/test=0.820/0.821/0.814 | c=0.998437
[Epoch 0095] loss=17.0938 cls=0.4943 smmd=0.1305 ct=7.4363 rec=1.3381 | train/val/test=0.824/0.823/0.808 | c=0.998437
[Epoch 0096] loss=17.1668 cls=0.5319 smmd=0.1400 ct=7.4182 rec=1.3289 | train/val/test=0.808/0.813/0.799 | c=0.998437
[Epoch 0097] loss=17.2633 cls=0.4999 smmd=0.1473 ct=7.4360 rec=1.3364 | train/val/test=0.823/0.824/0.811 | c=0.998437
[Epoch 0098] loss=17.1113 cls=0.5139 smmd=0.1371 ct=7.4099 rec=1.3267 | train/val/test=0.820/0.824/0.813 | c=0.998437
[Epoch 0099] loss=16.9058 cls=0.4766 smmd=0.1176 ct=7.4151 rec=1.3231 | train/val/test=0.838/0.839/0.825 | c=0.998437
=== Best @ epoch 91: val=0.8417, test=0.8299 ===
[2025-09-20 03:51:58] END attempt 1: exit_code=0
