Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-4 - 2025-09-21 06:25:27:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-4...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.8223 cls=1.7955 smmd=4.0506 ct=9.4785 rec=1.3917 | train/val/test=0.180/0.058/0.077 | c=0.998347
[Epoch 0001] loss=37.7601 cls=1.7870 smmd=3.9759 ct=9.4869 rec=1.3917 | train/val/test=0.200/0.056/0.075 | c=0.998347
[Epoch 0002] loss=36.7376 cls=1.7781 smmd=3.0838 ct=9.4240 rec=1.3917 | train/val/test=0.340/0.312/0.280 | c=0.998347
[Epoch 0003] loss=36.0704 cls=1.7658 smmd=2.4641 ct=9.4034 rec=1.3917 | train/val/test=0.440/0.270/0.249 | c=0.998347
[Epoch 0004] loss=35.2323 cls=1.7401 smmd=2.1156 ct=9.1654 rec=1.3916 | train/val/test=0.420/0.208/0.202 | c=0.998347
[Epoch 0005] loss=35.1073 cls=1.7071 smmd=1.9251 ct=9.2074 rec=1.3914 | train/val/test=0.500/0.326/0.318 | c=0.998347
[Epoch 0006] loss=34.7257 cls=1.6644 smmd=1.8694 ct=9.0579 rec=1.3908 | train/val/test=0.480/0.476/0.435 | c=0.998347
[Epoch 0007] loss=34.5347 cls=1.6209 smmd=1.7444 ct=9.0403 rec=1.3899 | train/val/test=0.540/0.482/0.437 | c=0.998347
[Epoch 0008] loss=34.1157 cls=1.5712 smmd=1.4085 ct=9.0165 rec=1.3889 | train/val/test=0.620/0.486/0.465 | c=0.998347
[Epoch 0009] loss=34.0977 cls=1.5207 smmd=1.4712 ct=8.9938 rec=1.3878 | train/val/test=0.680/0.494/0.481 | c=0.998347
[Epoch 0010] loss=34.0316 cls=1.4747 smmd=1.4426 ct=8.9920 rec=1.3868 | train/val/test=0.700/0.524/0.506 | c=0.998347
[Epoch 0011] loss=33.7347 cls=1.4316 smmd=1.2046 ct=8.9797 rec=1.3855 | train/val/test=0.700/0.554/0.526 | c=0.998347
[Epoch 0012] loss=33.6324 cls=1.3906 smmd=1.1305 ct=8.9807 rec=1.3845 | train/val/test=0.740/0.544/0.555 | c=0.998347
[Epoch 0013] loss=33.6146 cls=1.3465 smmd=1.1363 ct=8.9826 rec=1.3840 | train/val/test=0.860/0.542/0.574 | c=0.998347
[Epoch 0014] loss=33.4195 cls=1.3022 smmd=0.9617 ct=8.9871 rec=1.3833 | train/val/test=0.820/0.564/0.566 | c=0.998347
[Epoch 0015] loss=33.2583 cls=1.2600 smmd=0.8345 ct=8.9878 rec=1.3818 | train/val/test=0.800/0.570/0.570 | c=0.998347
[Epoch 0016] loss=33.2516 cls=1.2124 smmd=0.8438 ct=8.9987 rec=1.3804 | train/val/test=0.880/0.560/0.602 | c=0.998347
[Epoch 0017] loss=33.0856 cls=1.1517 smmd=0.7255 ct=8.9982 rec=1.3788 | train/val/test=0.900/0.574/0.606 | c=0.998347
[Epoch 0018] loss=32.9488 cls=1.0930 smmd=0.6687 ct=8.9913 rec=1.3751 | train/val/test=0.880/0.580/0.610 | c=0.998347
[Epoch 0019] loss=32.8920 cls=1.0371 smmd=0.6952 ct=8.9915 rec=1.3695 | train/val/test=0.900/0.588/0.607 | c=0.998347
[Epoch 0020] loss=32.6867 cls=0.9696 smmd=0.5827 ct=8.9932 rec=1.3633 | train/val/test=0.920/0.598/0.609 | c=0.998347
[Epoch 0021] loss=32.5259 cls=0.9081 smmd=0.5460 ct=8.9900 rec=1.3546 | train/val/test=0.900/0.600/0.611 | c=0.998347
[Epoch 0022] loss=32.3901 cls=0.8605 smmd=0.5548 ct=8.9864 rec=1.3432 | train/val/test=0.900/0.598/0.614 | c=0.998347
[Epoch 0023] loss=32.2277 cls=0.8098 smmd=0.5401 ct=8.9831 rec=1.3317 | train/val/test=0.900/0.604/0.616 | c=0.998347
[Epoch 0024] loss=32.0677 cls=0.7638 smmd=0.5141 ct=8.9831 rec=1.3206 | train/val/test=0.900/0.600/0.613 | c=0.998347
[Epoch 0025] loss=31.9323 cls=0.7345 smmd=0.5013 ct=8.9819 rec=1.3100 | train/val/test=0.880/0.614/0.611 | c=0.998347
[Epoch 0026] loss=31.8172 cls=0.7090 smmd=0.4905 ct=8.9829 rec=1.3006 | train/val/test=0.900/0.626/0.621 | c=0.998347
[Epoch 0027] loss=31.6961 cls=0.6771 smmd=0.4625 ct=8.9833 rec=1.2928 | train/val/test=0.900/0.616/0.624 | c=0.998347
[Epoch 0028] loss=31.6070 cls=0.6520 smmd=0.4504 ct=8.9820 rec=1.2867 | train/val/test=0.900/0.628/0.629 | c=0.998347
[Epoch 0029] loss=31.5279 cls=0.6328 smmd=0.4334 ct=8.9814 rec=1.2815 | train/val/test=0.900/0.636/0.638 | c=0.998347
[Epoch 0030] loss=31.4460 cls=0.6027 smmd=0.4085 ct=8.9833 rec=1.2769 | train/val/test=0.920/0.634/0.640 | c=0.998347
[Epoch 0031] loss=31.3724 cls=0.5734 smmd=0.3862 ct=8.9842 rec=1.2731 | train/val/test=0.920/0.640/0.650 | c=0.998347
[Epoch 0032] loss=31.2934 cls=0.5531 smmd=0.3581 ct=8.9826 rec=1.2694 | train/val/test=0.920/0.650/0.659 | c=0.998347
[Epoch 0033] loss=31.2337 cls=0.5250 smmd=0.3532 ct=8.9822 rec=1.2654 | train/val/test=0.940/0.658/0.665 | c=0.998347
[Epoch 0034] loss=31.1653 cls=0.4985 smmd=0.3382 ct=8.9823 rec=1.2613 | train/val/test=0.940/0.668/0.676 | c=0.998347
[Epoch 0035] loss=31.1032 cls=0.4789 smmd=0.3320 ct=8.9820 rec=1.2568 | train/val/test=0.940/0.666/0.684 | c=0.998347
[Epoch 0036] loss=31.0181 cls=0.4530 smmd=0.3136 ct=8.9809 rec=1.2516 | train/val/test=0.940/0.662/0.692 | c=0.998347
[Epoch 0037] loss=30.9669 cls=0.4364 smmd=0.3297 ct=8.9804 rec=1.2458 | train/val/test=0.940/0.672/0.698 | c=0.998347
[Epoch 0038] loss=30.9082 cls=0.4200 smmd=0.3359 ct=8.9799 rec=1.2403 | train/val/test=0.960/0.664/0.696 | c=0.998347
[Epoch 0039] loss=30.8194 cls=0.4002 smmd=0.3089 ct=8.9798 rec=1.2351 | train/val/test=0.960/0.678/0.702 | c=0.998347
[Epoch 0040] loss=30.7740 cls=0.3913 smmd=0.3163 ct=8.9797 rec=1.2303 | train/val/test=0.960/0.678/0.708 | c=0.998347
[Epoch 0041] loss=30.7119 cls=0.3724 smmd=0.3021 ct=8.9798 rec=1.2264 | train/val/test=0.960/0.692/0.708 | c=0.998347
[Epoch 0042] loss=30.6772 cls=0.3618 smmd=0.3073 ct=8.9799 rec=1.2229 | train/val/test=0.960/0.688/0.709 | c=0.998347
[Epoch 0043] loss=30.6352 cls=0.3479 smmd=0.2994 ct=8.9798 rec=1.2202 | train/val/test=0.960/0.690/0.709 | c=0.998347
[Epoch 0044] loss=30.5818 cls=0.3342 smmd=0.2718 ct=8.9813 rec=1.2180 | train/val/test=0.960/0.694/0.715 | c=0.998347
[Epoch 0045] loss=30.5503 cls=0.3265 smmd=0.2673 ct=8.9812 rec=1.2157 | train/val/test=0.960/0.694/0.713 | c=0.998347
[Epoch 0046] loss=30.5187 cls=0.3076 smmd=0.2646 ct=8.9816 rec=1.2137 | train/val/test=0.960/0.696/0.715 | c=0.998347
[Epoch 0047] loss=30.4784 cls=0.3059 smmd=0.2533 ct=8.9812 rec=1.2110 | train/val/test=0.980/0.704/0.713 | c=0.998347
[Epoch 0048] loss=30.4616 cls=0.2833 smmd=0.2650 ct=8.9827 rec=1.2090 | train/val/test=0.960/0.698/0.716 | c=0.998347
[Epoch 0049] loss=30.4457 cls=0.2932 smmd=0.2729 ct=8.9823 rec=1.2062 | train/val/test=0.980/0.692/0.714 | c=0.998347
[Epoch 0050] loss=30.4372 cls=0.2610 smmd=0.2756 ct=8.9868 rec=1.2057 | train/val/test=0.940/0.702/0.718 | c=0.998347
[Epoch 0051] loss=30.4569 cls=0.2945 smmd=0.2982 ct=8.9875 rec=1.2037 | train/val/test=0.960/0.684/0.709 | c=0.998347
[Epoch 0052] loss=30.5190 cls=0.2478 smmd=0.3327 ct=9.0001 rec=1.2062 | train/val/test=0.920/0.698/0.716 | c=0.998347
[Epoch 0053] loss=30.5209 cls=0.3030 smmd=0.3525 ct=8.9991 rec=1.2019 | train/val/test=0.960/0.682/0.713 | c=0.998347
[Epoch 0054] loss=30.4350 cls=0.2339 smmd=0.3317 ct=8.9977 rec=1.1991 | train/val/test=0.980/0.706/0.720 | c=0.998347
[Epoch 0055] loss=30.2694 cls=0.2232 smmd=0.2962 ct=8.9788 rec=1.1904 | train/val/test=0.960/0.702/0.719 | c=0.998347
[Epoch 0056] loss=30.2783 cls=0.2423 smmd=0.2980 ct=8.9832 rec=1.1893 | train/val/test=0.960/0.688/0.713 | c=0.998347
[Epoch 0057] loss=30.3676 cls=0.2050 smmd=0.3326 ct=8.9938 rec=1.1945 | train/val/test=0.960/0.704/0.721 | c=0.998347
[Epoch 0058] loss=30.2950 cls=0.2406 smmd=0.3059 ct=8.9869 rec=1.1895 | train/val/test=0.980/0.702/0.723 | c=0.998347
[Epoch 0059] loss=30.2020 cls=0.1971 smmd=0.2552 ct=8.9810 rec=1.1886 | train/val/test=0.980/0.708/0.724 | c=0.998347
[Epoch 0060] loss=30.2177 cls=0.1982 smmd=0.2548 ct=8.9839 rec=1.1896 | train/val/test=0.960/0.704/0.720 | c=0.998347
[Epoch 0061] loss=30.2956 cls=0.2316 smmd=0.2844 ct=8.9927 rec=1.1910 | train/val/test=0.960/0.694/0.718 | c=0.998347
[Epoch 0062] loss=30.4479 cls=0.2050 smmd=0.3308 ct=9.0086 rec=1.1997 | train/val/test=0.940/0.700/0.725 | c=0.998347
[Epoch 0063] loss=30.4853 cls=0.2685 smmd=0.3898 ct=9.0125 rec=1.1936 | train/val/test=0.960/0.692/0.720 | c=0.998347
[Epoch 0064] loss=30.3044 cls=0.1833 smmd=0.3352 ct=9.0031 rec=1.1871 | train/val/test=0.980/0.704/0.729 | c=0.998347
[Epoch 0065] loss=30.0718 cls=0.1697 smmd=0.2723 ct=8.9792 rec=1.1756 | train/val/test=0.960/0.714/0.726 | c=0.998347
[Epoch 0066] loss=30.2362 cls=0.2057 smmd=0.3591 ct=8.9925 rec=1.1789 | train/val/test=0.960/0.692/0.726 | c=0.998347
[Epoch 0067] loss=30.2081 cls=0.1711 smmd=0.3542 ct=8.9940 rec=1.1780 | train/val/test=0.980/0.702/0.728 | c=0.998347
[Epoch 0068] loss=30.0651 cls=0.1595 smmd=0.2733 ct=8.9809 rec=1.1750 | train/val/test=0.980/0.716/0.721 | c=0.998347
[Epoch 0069] loss=30.2718 cls=0.1964 smmd=0.3564 ct=8.9992 rec=1.1819 | train/val/test=0.960/0.696/0.727 | c=0.998347
[Epoch 0070] loss=30.3224 cls=0.1846 smmd=0.3288 ct=9.0064 rec=1.1889 | train/val/test=0.980/0.702/0.721 | c=0.998347
[Epoch 0071] loss=30.0992 cls=0.1620 smmd=0.2645 ct=8.9842 rec=1.1785 | train/val/test=0.980/0.714/0.726 | c=0.998347
[Epoch 0072] loss=30.1080 cls=0.1942 smmd=0.2609 ct=8.9875 rec=1.1775 | train/val/test=0.960/0.684/0.722 | c=0.998347
[Epoch 0073] loss=30.3315 cls=0.1559 smmd=0.3665 ct=9.0069 rec=1.1873 | train/val/test=0.900/0.722/0.726 | c=0.998347
[Epoch 0074] loss=30.3643 cls=0.2624 smmd=0.3791 ct=9.0108 rec=1.1832 | train/val/test=0.980/0.680/0.723 | c=0.998347
[Epoch 0075] loss=30.2690 cls=0.1394 smmd=0.3914 ct=8.9998 rec=1.1808 | train/val/test=0.960/0.704/0.726 | c=0.998347
[Epoch 0076] loss=30.1037 cls=0.1768 smmd=0.3207 ct=8.9928 rec=1.1709 | train/val/test=0.980/0.708/0.728 | c=0.998347
[Epoch 0077] loss=30.0523 cls=0.1788 smmd=0.3216 ct=8.9846 rec=1.1672 | train/val/test=0.980/0.682/0.722 | c=0.998347
[Epoch 0078] loss=30.1332 cls=0.1329 smmd=0.3677 ct=8.9912 rec=1.1717 | train/val/test=0.960/0.702/0.723 | c=0.998347
[Epoch 0079] loss=30.1043 cls=0.1689 smmd=0.3169 ct=8.9935 rec=1.1716 | train/val/test=0.980/0.704/0.724 | c=0.998347
[Epoch 0080] loss=30.0418 cls=0.1648 smmd=0.2867 ct=8.9852 rec=1.1702 | train/val/test=0.980/0.684/0.722 | c=0.998347
[Epoch 0081] loss=30.1343 cls=0.1361 smmd=0.3003 ct=8.9929 rec=1.1780 | train/val/test=0.960/0.710/0.724 | c=0.998347
[Epoch 0082] loss=30.2090 cls=0.1905 smmd=0.2986 ct=9.0059 rec=1.1803 | train/val/test=0.980/0.692/0.723 | c=0.998347
[Epoch 0083] loss=30.1418 cls=0.1379 smmd=0.2985 ct=8.9945 rec=1.1785 | train/val/test=0.980/0.700/0.721 | c=0.998347
[Epoch 0084] loss=30.0381 cls=0.1719 smmd=0.2700 ct=8.9886 rec=1.1705 | train/val/test=0.980/0.702/0.722 | c=0.998347
[Epoch 0085] loss=30.0155 cls=0.1559 smmd=0.2803 ct=8.9870 rec=1.1683 | train/val/test=0.980/0.690/0.721 | c=0.998347
[Epoch 0086] loss=30.0093 cls=0.1334 smmd=0.2784 ct=8.9870 rec=1.1690 | train/val/test=0.980/0.702/0.720 | c=0.998347
[Epoch 0087] loss=29.9930 cls=0.1672 smmd=0.2670 ct=8.9867 rec=1.1669 | train/val/test=0.980/0.698/0.723 | c=0.998347
[Epoch 0088] loss=29.9620 cls=0.1428 smmd=0.2423 ct=8.9838 rec=1.1681 | train/val/test=0.980/0.694/0.723 | c=0.998347
[Epoch 0089] loss=29.9936 cls=0.1355 smmd=0.2449 ct=8.9878 rec=1.1705 | train/val/test=0.980/0.704/0.721 | c=0.998347
[Epoch 0090] loss=30.0606 cls=0.1676 smmd=0.2498 ct=8.9951 rec=1.1737 | train/val/test=0.980/0.692/0.723 | c=0.998347
[Epoch 0091] loss=30.0881 cls=0.1315 smmd=0.2643 ct=8.9942 rec=1.1770 | train/val/test=0.960/0.700/0.725 | c=0.998347
[Epoch 0092] loss=30.0686 cls=0.1895 smmd=0.2557 ct=8.9974 rec=1.1723 | train/val/test=0.980/0.688/0.725 | c=0.998347
[Epoch 0093] loss=30.0266 cls=0.1312 smmd=0.2673 ct=8.9905 rec=1.1713 | train/val/test=0.980/0.700/0.721 | c=0.998347
[Epoch 0094] loss=30.0412 cls=0.1768 smmd=0.2813 ct=8.9931 rec=1.1685 | train/val/test=0.960/0.694/0.722 | c=0.998347
[Epoch 0095] loss=30.0880 cls=0.1606 smmd=0.2957 ct=9.0014 rec=1.1709 | train/val/test=0.980/0.702/0.722 | c=0.998347
[Epoch 0096] loss=29.9967 cls=0.1527 smmd=0.2857 ct=8.9893 rec=1.1656 | train/val/test=0.980/0.690/0.724 | c=0.998347
[Epoch 0097] loss=29.9054 cls=0.1268 smmd=0.2418 ct=8.9818 rec=1.1637 | train/val/test=0.980/0.698/0.724 | c=0.998347
[Epoch 0098] loss=29.9645 cls=0.1450 smmd=0.2436 ct=8.9903 rec=1.1668 | train/val/test=0.980/0.698/0.718 | c=0.998347
[Epoch 0099] loss=30.0158 cls=0.1374 smmd=0.2714 ct=8.9922 rec=1.1691 | train/val/test=0.980/0.696/0.726 | c=0.998347
[Epoch 0100] loss=29.9800 cls=0.1327 smmd=0.2237 ct=8.9906 rec=1.1709 | train/val/test=0.980/0.700/0.720 | c=0.998347
[Epoch 0101] loss=29.9850 cls=0.1628 smmd=0.2307 ct=8.9908 rec=1.1691 | train/val/test=0.980/0.684/0.725 | c=0.998347
[Epoch 0102] loss=30.0766 cls=0.1287 smmd=0.2592 ct=8.9956 rec=1.1762 | train/val/test=0.940/0.706/0.725 | c=0.998347
[Epoch 0103] loss=30.2319 cls=0.2350 smmd=0.3230 ct=9.0132 rec=1.1765 | train/val/test=0.960/0.680/0.719 | c=0.998347
[Epoch 0104] loss=30.2484 cls=0.1461 smmd=0.3515 ct=9.0092 rec=1.1805 | train/val/test=0.980/0.708/0.719 | c=0.998347
[Epoch 0105] loss=30.1547 cls=0.2079 smmd=0.3591 ct=9.0032 rec=1.1685 | train/val/test=0.960/0.698/0.724 | c=0.998347
[Epoch 0106] loss=30.0133 cls=0.1553 smmd=0.3371 ct=8.9940 rec=1.1611 | train/val/test=0.980/0.688/0.725 | c=0.998347
[Epoch 0107] loss=29.9034 cls=0.1167 smmd=0.3057 ct=8.9802 rec=1.1579 | train/val/test=0.980/0.702/0.717 | c=0.998347
[Epoch 0108] loss=30.0511 cls=0.1462 smmd=0.3734 ct=8.9924 rec=1.1620 | train/val/test=0.960/0.694/0.727 | c=0.998347
[Epoch 0109] loss=29.9674 cls=0.1349 smmd=0.2794 ct=8.9904 rec=1.1640 | train/val/test=0.980/0.690/0.726 | c=0.998347
[Epoch 0110] loss=29.9463 cls=0.1189 smmd=0.2499 ct=8.9841 rec=1.1669 | train/val/test=0.980/0.704/0.720 | c=0.998347
[Epoch 0111] loss=30.0883 cls=0.1515 smmd=0.2793 ct=9.0000 rec=1.1733 | train/val/test=0.960/0.694/0.724 | c=0.998347
[Epoch 0112] loss=30.1647 cls=0.1469 smmd=0.2593 ct=9.0076 rec=1.1817 | train/val/test=0.900/0.696/0.718 | c=0.998347
[Epoch 0113] loss=30.3380 cls=0.2455 smmd=0.3648 ct=9.0213 rec=1.1808 | train/val/test=0.960/0.678/0.719 | c=0.998347
[Epoch 0114] loss=30.4350 cls=0.1621 smmd=0.4304 ct=9.0297 rec=1.1864 | train/val/test=0.960/0.692/0.719 | c=0.998347
[Epoch 0115] loss=30.0826 cls=0.2085 smmd=0.3618 ct=8.9985 rec=1.1620 | train/val/test=0.980/0.694/0.717 | c=0.998347
[Epoch 0116] loss=29.9944 cls=0.1672 smmd=0.3653 ct=8.9870 rec=1.1571 | train/val/test=0.960/0.686/0.724 | c=0.998347
[Epoch 0117] loss=30.1365 cls=0.1287 smmd=0.4511 ct=8.9989 rec=1.1623 | train/val/test=0.960/0.698/0.729 | c=0.998347
[Epoch 0118] loss=29.9292 cls=0.1331 smmd=0.3399 ct=8.9860 rec=1.1551 | train/val/test=0.980/0.692/0.719 | c=0.998347
[Epoch 0119] loss=30.1084 cls=0.1741 smmd=0.4012 ct=8.9995 rec=1.1621 | train/val/test=0.980/0.694/0.727 | c=0.998347
[Epoch 0120] loss=29.9015 cls=0.1210 smmd=0.2620 ct=8.9817 rec=1.1616 | train/val/test=0.960/0.692/0.726 | c=0.998347
[Epoch 0121] loss=30.1071 cls=0.1306 smmd=0.2982 ct=8.9988 rec=1.1746 | train/val/test=0.940/0.688/0.715 | c=0.998347
[Epoch 0122] loss=30.3575 cls=0.2159 smmd=0.3972 ct=9.0223 rec=1.1808 | train/val/test=0.960/0.694/0.730 | c=0.998347
[Epoch 0123] loss=30.3237 cls=0.1626 smmd=0.3339 ct=9.0217 rec=1.1865 | train/val/test=0.980/0.700/0.717 | c=0.998347
[Epoch 0124] loss=30.2745 cls=0.1827 smmd=0.4176 ct=9.0136 rec=1.1738 | train/val/test=0.980/0.690/0.726 | c=0.998347
[Epoch 0125] loss=31.3590 cls=0.1319 smmd=0.3139 ct=9.6931 rec=1.1593 | train/val/test=0.980/0.702/0.726 | c=0.998347
[Epoch 0126] loss=31.3848 cls=0.1386 smmd=0.4735 ct=9.6333 rec=1.1575 | train/val/test=0.980/0.700/0.724 | c=0.998347
[Epoch 0127] loss=31.3570 cls=0.1342 smmd=0.5693 ct=9.5717 rec=1.1577 | train/val/test=0.980/0.690/0.722 | c=0.998347
[Epoch 0128] loss=31.3423 cls=0.1167 smmd=0.4433 ct=9.6202 rec=1.1600 | train/val/test=0.960/0.706/0.726 | c=0.998347
[Epoch 0129] loss=31.4014 cls=0.1430 smmd=0.3371 ct=9.6901 rec=1.1613 | train/val/test=0.980/0.702/0.723 | c=0.998347
[Epoch 0130] loss=31.2530 cls=0.1272 smmd=0.2877 ct=9.6323 rec=1.1637 | train/val/test=0.980/0.692/0.722 | c=0.998347
[Epoch 0131] loss=31.4681 cls=0.1248 smmd=0.4614 ct=9.5928 rec=1.1759 | train/val/test=0.960/0.704/0.729 | c=0.998347
[Epoch 0132] loss=31.5685 cls=0.1717 smmd=0.3753 ct=9.6386 rec=1.1830 | train/val/test=0.980/0.686/0.716 | c=0.998347
[Epoch 0133] loss=31.6995 cls=0.1593 smmd=0.4176 ct=9.6648 rec=1.1873 | train/val/test=0.960/0.716/0.720 | c=0.998347
[Epoch 0134] loss=31.7885 cls=0.2005 smmd=0.4988 ct=9.6921 rec=1.1805 | train/val/test=0.980/0.698/0.725 | c=0.998347
[Epoch 0135] loss=31.2856 cls=0.1243 smmd=0.3975 ct=9.6350 rec=1.1556 | train/val/test=0.940/0.682/0.701 | c=0.998347
[Epoch 0136] loss=31.6210 cls=0.1856 smmd=0.5717 ct=9.6244 rec=1.1708 | train/val/test=0.980/0.698/0.722 | c=0.998347
[Epoch 0137] loss=31.3097 cls=0.1194 smmd=0.4608 ct=9.6369 rec=1.1515 | train/val/test=0.960/0.702/0.724 | c=0.998347
[Epoch 0138] loss=31.4837 cls=0.1520 smmd=0.5012 ct=9.6676 rec=1.1571 | train/val/test=0.980/0.692/0.717 | c=0.998347
[Epoch 0139] loss=31.2331 cls=0.1108 smmd=0.4018 ct=9.6100 rec=1.1556 | train/val/test=0.980/0.686/0.715 | c=0.998347
[Epoch 0140] loss=31.4724 cls=0.1134 smmd=0.4555 ct=9.6261 rec=1.1708 | train/val/test=0.960/0.702/0.725 | c=0.998347
[Epoch 0141] loss=31.5851 cls=0.1563 smmd=0.4320 ct=9.6599 rec=1.1755 | train/val/test=0.980/0.694/0.719 | c=0.998347
[Epoch 0142] loss=31.2903 cls=0.1103 smmd=0.3160 ct=9.6159 rec=1.1687 | train/val/test=0.940/0.694/0.708 | c=0.998347
[Epoch 0143] loss=31.6830 cls=0.1959 smmd=0.4814 ct=9.6267 rec=1.1850 | train/val/test=0.960/0.704/0.732 | c=0.998347
[Epoch 0144] loss=32.0171 cls=0.1885 smmd=0.5375 ct=9.7397 rec=1.1906 | train/val/test=0.960/0.702/0.725 | c=0.998347
[Epoch 0145] loss=31.3646 cls=0.1680 smmd=0.4288 ct=9.6125 rec=1.1627 | train/val/test=0.920/0.680/0.698 | c=0.998347
[Epoch 0146] loss=31.8201 cls=0.1957 smmd=0.6379 ct=9.6397 rec=1.1805 | train/val/test=0.960/0.704/0.728 | c=0.998347
[Epoch 0147] loss=31.4456 cls=0.1230 smmd=0.5086 ct=9.6671 rec=1.1541 | train/val/test=0.940/0.708/0.723 | c=0.998347
[Epoch 0148] loss=31.6666 cls=0.1796 smmd=0.6078 ct=9.6869 rec=1.1595 | train/val/test=0.980/0.696/0.722 | c=0.998347
[Epoch 0149] loss=31.2628 cls=0.1100 smmd=0.4660 ct=9.6177 rec=1.1506 | train/val/test=0.980/0.680/0.705 | c=0.998347
[Epoch 0150] loss=31.6551 cls=0.1063 smmd=0.6328 ct=9.6327 rec=1.1704 | train/val/test=0.980/0.698/0.726 | c=0.998347
[Epoch 0151] loss=31.2590 cls=0.1085 smmd=0.4245 ct=9.6141 rec=1.1552 | train/val/test=0.960/0.708/0.724 | c=0.998347
[Epoch 0152] loss=31.5837 cls=0.1548 smmd=0.4867 ct=9.6618 rec=1.1696 | train/val/test=0.980/0.692/0.717 | c=0.998347
[Epoch 0153] loss=31.3269 cls=0.0975 smmd=0.3533 ct=9.6265 rec=1.1672 | train/val/test=0.940/0.688/0.705 | c=0.998347
[Epoch 0154] loss=31.6797 cls=0.1880 smmd=0.5165 ct=9.6223 rec=1.1825 | train/val/test=0.960/0.704/0.727 | c=0.998347
[Epoch 0155] loss=31.8280 cls=0.1728 smmd=0.4844 ct=9.7026 rec=1.1852 | train/val/test=0.960/0.706/0.728 | c=0.998347
[Epoch 0156] loss=31.4280 cls=0.1710 smmd=0.4274 ct=9.6152 rec=1.1685 | train/val/test=0.960/0.680/0.708 | c=0.998347
[Epoch 0157] loss=31.7533 cls=0.1575 smmd=0.5963 ct=9.6476 rec=1.1783 | train/val/test=0.980/0.704/0.728 | c=0.998347
[Epoch 0158] loss=31.3022 cls=0.1283 smmd=0.4235 ct=9.6362 rec=1.1542 | train/val/test=0.940/0.710/0.721 | c=0.998347
[Epoch 0159] loss=31.5417 cls=0.1733 smmd=0.5317 ct=9.6588 rec=1.1606 | train/val/test=0.960/0.696/0.720 | c=0.998347
[Epoch 0160] loss=31.2760 cls=0.1031 smmd=0.4507 ct=9.6230 rec=1.1528 | train/val/test=0.980/0.684/0.710 | c=0.998347
[Epoch 0161] loss=31.4964 cls=0.1119 smmd=0.5528 ct=9.6218 rec=1.1644 | train/val/test=0.980/0.696/0.725 | c=0.998347
[Epoch 0162] loss=31.2473 cls=0.1197 smmd=0.3980 ct=9.6099 rec=1.1570 | train/val/test=0.960/0.704/0.726 | c=0.998347
[Epoch 0163] loss=31.4611 cls=0.1379 smmd=0.4114 ct=9.6576 rec=1.1665 | train/val/test=0.980/0.694/0.720 | c=0.998347
[Epoch 0164] loss=31.2650 cls=0.1088 smmd=0.3322 ct=9.6068 rec=1.1665 | train/val/test=0.980/0.690/0.719 | c=0.998347
[Epoch 0165] loss=31.5080 cls=0.1475 smmd=0.4176 ct=9.6210 rec=1.1775 | train/val/test=0.960/0.704/0.729 | c=0.998347
[Epoch 0166] loss=31.6129 cls=0.1562 smmd=0.3780 ct=9.6695 rec=1.1818 | train/val/test=0.960/0.704/0.725 | c=0.998347
[Epoch 0167] loss=31.3438 cls=0.1659 smmd=0.3597 ct=9.6010 rec=1.1699 | train/val/test=0.980/0.680/0.716 | c=0.998347
[Epoch 0168] loss=31.6392 cls=0.1406 smmd=0.4949 ct=9.6498 rec=1.1774 | train/val/test=0.980/0.710/0.730 | c=0.998347
[Epoch 0169] loss=31.3585 cls=0.1663 smmd=0.3994 ct=9.6329 rec=1.1610 | train/val/test=0.960/0.704/0.722 | c=0.998347
[Epoch 0170] loss=31.3595 cls=0.1433 smmd=0.4293 ct=9.6392 rec=1.1580 | train/val/test=0.980/0.686/0.722 | c=0.998347
[Epoch 0171] loss=31.2692 cls=0.1039 smmd=0.4246 ct=9.6153 rec=1.1562 | train/val/test=0.980/0.692/0.719 | c=0.998347
[Epoch 0172] loss=31.3787 cls=0.1360 smmd=0.4843 ct=9.6088 rec=1.1609 | train/val/test=0.960/0.704/0.729 | c=0.998347
[Epoch 0173] loss=31.3033 cls=0.1236 smmd=0.3779 ct=9.6384 rec=1.1587 | train/val/test=0.960/0.698/0.725 | c=0.998347
[Epoch 0174] loss=31.3679 cls=0.1243 smmd=0.3780 ct=9.6364 rec=1.1655 | train/val/test=0.980/0.692/0.718 | c=0.998347
[Epoch 0175] loss=31.3798 cls=0.1262 smmd=0.3983 ct=9.6050 rec=1.1708 | train/val/test=0.980/0.702/0.724 | c=0.998347
[Epoch 0176] loss=31.3366 cls=0.1179 smmd=0.3132 ct=9.6281 rec=1.1708 | train/val/test=0.960/0.706/0.723 | c=0.998347
[Epoch 0177] loss=31.5299 cls=0.1897 smmd=0.3893 ct=9.6186 rec=1.1808 | train/val/test=0.980/0.678/0.708 | c=0.998347
[Epoch 0178] loss=31.7561 cls=0.1449 smmd=0.4239 ct=9.6748 rec=1.1910 | train/val/test=0.880/0.692/0.720 | c=0.998347
[Epoch 0179] loss=31.8272 cls=0.3423 smmd=0.5756 ct=9.6198 rec=1.1841 | train/val/test=0.960/0.690/0.726 | c=0.998347
[Epoch 0180] loss=31.3380 cls=0.1373 smmd=0.3808 ct=9.6489 rec=1.1591 | train/val/test=0.960/0.682/0.724 | c=0.998347
[Epoch 0181] loss=31.3145 cls=0.1129 smmd=0.4338 ct=9.6348 rec=1.1555 | train/val/test=0.940/0.704/0.719 | c=0.998347
[Epoch 0182] loss=31.4409 cls=0.1814 smmd=0.5483 ct=9.6009 rec=1.1600 | train/val/test=0.980/0.702/0.732 | c=0.998347
[Epoch 0183] loss=31.2193 cls=0.1238 smmd=0.4089 ct=9.6120 rec=1.1524 | train/val/test=0.960/0.692/0.723 | c=0.998347
[Epoch 0184] loss=31.3859 cls=0.1209 smmd=0.3881 ct=9.6553 rec=1.1627 | train/val/test=0.980/0.704/0.726 | c=0.998347
[Epoch 0185] loss=31.3293 cls=0.1289 smmd=0.4171 ct=9.5973 rec=1.1653 | train/val/test=0.980/0.694/0.724 | c=0.998347
[Epoch 0186] loss=31.2757 cls=0.1177 smmd=0.3453 ct=9.6013 rec=1.1669 | train/val/test=0.960/0.696/0.723 | c=0.998347
[Epoch 0187] loss=31.5313 cls=0.1317 smmd=0.3416 ct=9.6631 rec=1.1798 | train/val/test=0.960/0.704/0.722 | c=0.998347
[Epoch 0188] loss=31.5537 cls=0.2089 smmd=0.4067 ct=9.6077 rec=1.1827 | train/val/test=0.980/0.682/0.716 | c=0.998347
[Epoch 0189] loss=31.5982 cls=0.1279 smmd=0.4008 ct=9.6543 rec=1.1825 | train/val/test=0.980/0.704/0.733 | c=0.998347
[Epoch 0190] loss=31.4968 cls=0.2047 smmd=0.4438 ct=9.6262 rec=1.1698 | train/val/test=0.980/0.698/0.724 | c=0.998347
[Epoch 0191] loss=31.1756 cls=0.1458 smmd=0.3310 ct=9.6063 rec=1.1559 | train/val/test=0.980/0.684/0.721 | c=0.998347
[Epoch 0192] loss=31.3696 cls=0.1084 smmd=0.4578 ct=9.6319 rec=1.1594 | train/val/test=0.980/0.696/0.725 | c=0.998347
[Epoch 0193] loss=31.1847 cls=0.1272 smmd=0.3802 ct=9.6024 rec=1.1536 | train/val/test=0.980/0.708/0.731 | c=0.998347
[Epoch 0194] loss=31.3229 cls=0.1515 smmd=0.4096 ct=9.6211 rec=1.1595 | train/val/test=0.980/0.696/0.731 | c=0.998347
[Epoch 0195] loss=31.1980 cls=0.1137 smmd=0.3140 ct=9.6161 rec=1.1595 | train/val/test=0.980/0.690/0.725 | c=0.998347
[Epoch 0196] loss=31.3543 cls=0.1105 smmd=0.3788 ct=9.6104 rec=1.1699 | train/val/test=0.980/0.702/0.731 | c=0.998347
[Epoch 0197] loss=31.2228 cls=0.1306 smmd=0.2668 ct=9.6080 rec=1.1675 | train/val/test=0.980/0.700/0.733 | c=0.998347
[Epoch 0198] loss=31.2826 cls=0.1333 smmd=0.2584 ct=9.6202 rec=1.1717 | train/val/test=0.980/0.688/0.723 | c=0.998347
[Epoch 0199] loss=31.4102 cls=0.1403 smmd=0.3437 ct=9.6129 rec=1.1770 | train/val/test=0.980/0.698/0.732 | c=0.998347
=== Best @ epoch 73: val=0.7220, test=0.7260 ===

==================================================
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-4 - 2025-09-21 06:25:27:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-4...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-4 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.8223 cls=1.7955 smmd=4.0506 ct=9.4785 rec=1.3917 | train/val/test=0.180/0.058/0.077 | c=0.998347
[Epoch 0001] loss=37.7601 cls=1.7870 smmd=3.9759 ct=9.4869 rec=1.3917 | train/val/test=0.200/0.056/0.075 | c=0.998347
[Epoch 0002] loss=36.7376 cls=1.7781 smmd=3.0838 ct=9.4240 rec=1.3917 | train/val/test=0.340/0.312/0.280 | c=0.998347
[Epoch 0003] loss=36.0704 cls=1.7658 smmd=2.4641 ct=9.4034 rec=1.3917 | train/val/test=0.440/0.270/0.249 | c=0.998347
[Epoch 0004] loss=35.2323 cls=1.7401 smmd=2.1156 ct=9.1654 rec=1.3916 | train/val/test=0.420/0.208/0.202 | c=0.998347
[Epoch 0005] loss=35.1073 cls=1.7071 smmd=1.9251 ct=9.2074 rec=1.3914 | train/val/test=0.500/0.326/0.318 | c=0.998347
[Epoch 0006] loss=34.7257 cls=1.6644 smmd=1.8694 ct=9.0579 rec=1.3908 | train/val/test=0.480/0.476/0.435 | c=0.998347
[Epoch 0007] loss=34.5347 cls=1.6209 smmd=1.7444 ct=9.0403 rec=1.3899 | train/val/test=0.540/0.482/0.437 | c=0.998347
[Epoch 0008] loss=34.1157 cls=1.5712 smmd=1.4085 ct=9.0165 rec=1.3889 | train/val/test=0.620/0.486/0.465 | c=0.998347
[Epoch 0009] loss=34.0977 cls=1.5207 smmd=1.4712 ct=8.9938 rec=1.3878 | train/val/test=0.680/0.494/0.481 | c=0.998347
[Epoch 0010] loss=34.0316 cls=1.4747 smmd=1.4426 ct=8.9920 rec=1.3868 | train/val/test=0.700/0.524/0.506 | c=0.998347
[Epoch 0011] loss=33.7347 cls=1.4316 smmd=1.2046 ct=8.9797 rec=1.3855 | train/val/test=0.700/0.554/0.526 | c=0.998347
[Epoch 0012] loss=33.6324 cls=1.3906 smmd=1.1305 ct=8.9807 rec=1.3845 | train/val/test=0.740/0.544/0.555 | c=0.998347
[Epoch 0013] loss=33.6146 cls=1.3465 smmd=1.1363 ct=8.9826 rec=1.3840 | train/val/test=0.860/0.542/0.574 | c=0.998347
[Epoch 0014] loss=33.4195 cls=1.3022 smmd=0.9617 ct=8.9871 rec=1.3833 | train/val/test=0.820/0.564/0.566 | c=0.998347
[Epoch 0015] loss=33.2583 cls=1.2600 smmd=0.8345 ct=8.9878 rec=1.3818 | train/val/test=0.800/0.570/0.570 | c=0.998347
[Epoch 0016] loss=33.2516 cls=1.2124 smmd=0.8438 ct=8.9987 rec=1.3804 | train/val/test=0.880/0.560/0.602 | c=0.998347
[Epoch 0017] loss=33.0856 cls=1.1517 smmd=0.7255 ct=8.9982 rec=1.3788 | train/val/test=0.900/0.574/0.606 | c=0.998347
[Epoch 0018] loss=32.9488 cls=1.0930 smmd=0.6687 ct=8.9913 rec=1.3751 | train/val/test=0.880/0.580/0.610 | c=0.998347
[Epoch 0019] loss=32.8920 cls=1.0371 smmd=0.6952 ct=8.9915 rec=1.3695 | train/val/test=0.900/0.588/0.607 | c=0.998347
[Epoch 0020] loss=32.6867 cls=0.9696 smmd=0.5827 ct=8.9932 rec=1.3633 | train/val/test=0.920/0.598/0.609 | c=0.998347
[Epoch 0021] loss=32.5259 cls=0.9081 smmd=0.5460 ct=8.9900 rec=1.3546 | train/val/test=0.900/0.600/0.611 | c=0.998347
[Epoch 0022] loss=32.3901 cls=0.8605 smmd=0.5548 ct=8.9864 rec=1.3432 | train/val/test=0.900/0.598/0.614 | c=0.998347
[Epoch 0023] loss=32.2277 cls=0.8098 smmd=0.5401 ct=8.9831 rec=1.3317 | train/val/test=0.900/0.604/0.616 | c=0.998347
[Epoch 0024] loss=32.0677 cls=0.7638 smmd=0.5141 ct=8.9831 rec=1.3206 | train/val/test=0.900/0.600/0.613 | c=0.998347
[Epoch 0025] loss=31.9323 cls=0.7345 smmd=0.5013 ct=8.9819 rec=1.3100 | train/val/test=0.880/0.614/0.611 | c=0.998347
[Epoch 0026] loss=31.8172 cls=0.7090 smmd=0.4905 ct=8.9829 rec=1.3006 | train/val/test=0.900/0.626/0.621 | c=0.998347
[Epoch 0027] loss=31.6961 cls=0.6771 smmd=0.4625 ct=8.9833 rec=1.2928 | train/val/test=0.900/0.616/0.624 | c=0.998347
[Epoch 0028] loss=31.6070 cls=0.6520 smmd=0.4504 ct=8.9820 rec=1.2867 | train/val/test=0.900/0.628/0.629 | c=0.998347
[Epoch 0029] loss=31.5279 cls=0.6328 smmd=0.4334 ct=8.9814 rec=1.2815 | train/val/test=0.900/0.636/0.638 | c=0.998347
[Epoch 0030] loss=31.4460 cls=0.6027 smmd=0.4085 ct=8.9833 rec=1.2769 | train/val/test=0.920/0.634/0.640 | c=0.998347
[Epoch 0031] loss=31.3724 cls=0.5734 smmd=0.3862 ct=8.9842 rec=1.2731 | train/val/test=0.920/0.640/0.650 | c=0.998347
[Epoch 0032] loss=31.2934 cls=0.5531 smmd=0.3581 ct=8.9826 rec=1.2694 | train/val/test=0.920/0.650/0.659 | c=0.998347
[Epoch 0033] loss=31.2337 cls=0.5250 smmd=0.3532 ct=8.9822 rec=1.2654 | train/val/test=0.940/0.658/0.665 | c=0.998347
[Epoch 0034] loss=31.1653 cls=0.4985 smmd=0.3382 ct=8.9823 rec=1.2613 | train/val/test=0.940/0.668/0.676 | c=0.998347
[Epoch 0035] loss=31.1032 cls=0.4789 smmd=0.3320 ct=8.9820 rec=1.2568 | train/val/test=0.940/0.666/0.684 | c=0.998347
[Epoch 0036] loss=31.0181 cls=0.4530 smmd=0.3136 ct=8.9809 rec=1.2516 | train/val/test=0.940/0.662/0.692 | c=0.998347
[Epoch 0037] loss=30.9669 cls=0.4364 smmd=0.3297 ct=8.9804 rec=1.2458 | train/val/test=0.940/0.672/0.698 | c=0.998347
[Epoch 0038] loss=30.9082 cls=0.4200 smmd=0.3359 ct=8.9799 rec=1.2403 | train/val/test=0.960/0.664/0.696 | c=0.998347
[Epoch 0039] loss=30.8194 cls=0.4002 smmd=0.3089 ct=8.9798 rec=1.2351 | train/val/test=0.960/0.678/0.702 | c=0.998347
[Epoch 0040] loss=30.7740 cls=0.3913 smmd=0.3163 ct=8.9797 rec=1.2303 | train/val/test=0.960/0.678/0.708 | c=0.998347
[Epoch 0041] loss=30.7119 cls=0.3724 smmd=0.3021 ct=8.9798 rec=1.2264 | train/val/test=0.960/0.692/0.708 | c=0.998347
[Epoch 0042] loss=30.6772 cls=0.3618 smmd=0.3073 ct=8.9799 rec=1.2229 | train/val/test=0.960/0.688/0.709 | c=0.998347
[Epoch 0043] loss=30.6352 cls=0.3479 smmd=0.2994 ct=8.9798 rec=1.2202 | train/val/test=0.960/0.690/0.709 | c=0.998347
[Epoch 0044] loss=30.5818 cls=0.3342 smmd=0.2718 ct=8.9813 rec=1.2180 | train/val/test=0.960/0.694/0.715 | c=0.998347
[Epoch 0045] loss=30.5503 cls=0.3265 smmd=0.2673 ct=8.9812 rec=1.2157 | train/val/test=0.960/0.694/0.713 | c=0.998347
[Epoch 0046] loss=30.5187 cls=0.3076 smmd=0.2646 ct=8.9816 rec=1.2137 | train/val/test=0.960/0.696/0.715 | c=0.998347
[Epoch 0047] loss=30.4784 cls=0.3059 smmd=0.2533 ct=8.9812 rec=1.2110 | train/val/test=0.980/0.704/0.713 | c=0.998347
[Epoch 0048] loss=30.4616 cls=0.2833 smmd=0.2650 ct=8.9827 rec=1.2090 | train/val/test=0.960/0.698/0.716 | c=0.998347
[Epoch 0049] loss=30.4457 cls=0.2932 smmd=0.2729 ct=8.9823 rec=1.2062 | train/val/test=0.980/0.692/0.714 | c=0.998347
[Epoch 0050] loss=30.4372 cls=0.2610 smmd=0.2756 ct=8.9868 rec=1.2057 | train/val/test=0.940/0.702/0.718 | c=0.998347
[Epoch 0051] loss=30.4569 cls=0.2945 smmd=0.2982 ct=8.9875 rec=1.2037 | train/val/test=0.960/0.684/0.709 | c=0.998347
[Epoch 0052] loss=30.5190 cls=0.2478 smmd=0.3327 ct=9.0001 rec=1.2062 | train/val/test=0.920/0.698/0.716 | c=0.998347
[Epoch 0053] loss=30.5209 cls=0.3030 smmd=0.3525 ct=8.9991 rec=1.2019 | train/val/test=0.960/0.682/0.713 | c=0.998347
[Epoch 0054] loss=30.4350 cls=0.2339 smmd=0.3317 ct=8.9977 rec=1.1991 | train/val/test=0.980/0.706/0.720 | c=0.998347
[Epoch 0055] loss=30.2694 cls=0.2232 smmd=0.2962 ct=8.9788 rec=1.1904 | train/val/test=0.960/0.702/0.719 | c=0.998347
[Epoch 0056] loss=30.2783 cls=0.2423 smmd=0.2980 ct=8.9832 rec=1.1893 | train/val/test=0.960/0.688/0.713 | c=0.998347
[Epoch 0057] loss=30.3676 cls=0.2050 smmd=0.3326 ct=8.9938 rec=1.1945 | train/val/test=0.960/0.704/0.721 | c=0.998347
[Epoch 0058] loss=30.2950 cls=0.2406 smmd=0.3059 ct=8.9869 rec=1.1895 | train/val/test=0.980/0.702/0.723 | c=0.998347
[Epoch 0059] loss=30.2020 cls=0.1971 smmd=0.2552 ct=8.9810 rec=1.1886 | train/val/test=0.980/0.708/0.724 | c=0.998347
[Epoch 0060] loss=30.2177 cls=0.1982 smmd=0.2548 ct=8.9839 rec=1.1896 | train/val/test=0.960/0.704/0.720 | c=0.998347
[Epoch 0061] loss=30.2956 cls=0.2316 smmd=0.2844 ct=8.9927 rec=1.1910 | train/val/test=0.960/0.694/0.718 | c=0.998347
[Epoch 0062] loss=30.4479 cls=0.2050 smmd=0.3308 ct=9.0086 rec=1.1997 | train/val/test=0.940/0.700/0.725 | c=0.998347
[Epoch 0063] loss=30.4853 cls=0.2685 smmd=0.3898 ct=9.0125 rec=1.1936 | train/val/test=0.960/0.692/0.720 | c=0.998347
[Epoch 0064] loss=30.3044 cls=0.1833 smmd=0.3352 ct=9.0031 rec=1.1871 | train/val/test=0.980/0.704/0.729 | c=0.998347
[Epoch 0065] loss=30.0718 cls=0.1697 smmd=0.2723 ct=8.9792 rec=1.1756 | train/val/test=0.960/0.714/0.726 | c=0.998347
[Epoch 0066] loss=30.2362 cls=0.2057 smmd=0.3591 ct=8.9925 rec=1.1789 | train/val/test=0.960/0.692/0.726 | c=0.998347
[Epoch 0067] loss=30.2081 cls=0.1711 smmd=0.3542 ct=8.9940 rec=1.1780 | train/val/test=0.980/0.702/0.728 | c=0.998347
[Epoch 0068] loss=30.0651 cls=0.1595 smmd=0.2733 ct=8.9809 rec=1.1750 | train/val/test=0.980/0.716/0.721 | c=0.998347
[Epoch 0069] loss=30.2718 cls=0.1964 smmd=0.3564 ct=8.9992 rec=1.1819 | train/val/test=0.960/0.696/0.727 | c=0.998347
[Epoch 0070] loss=30.3224 cls=0.1846 smmd=0.3288 ct=9.0064 rec=1.1889 | train/val/test=0.980/0.702/0.721 | c=0.998347
[Epoch 0071] loss=30.0992 cls=0.1620 smmd=0.2645 ct=8.9842 rec=1.1785 | train/val/test=0.980/0.714/0.726 | c=0.998347
[Epoch 0072] loss=30.1080 cls=0.1942 smmd=0.2609 ct=8.9875 rec=1.1775 | train/val/test=0.960/0.684/0.722 | c=0.998347
[Epoch 0073] loss=30.3315 cls=0.1559 smmd=0.3665 ct=9.0069 rec=1.1873 | train/val/test=0.900/0.722/0.726 | c=0.998347
[Epoch 0074] loss=30.3643 cls=0.2624 smmd=0.3791 ct=9.0108 rec=1.1832 | train/val/test=0.980/0.680/0.723 | c=0.998347
[Epoch 0075] loss=30.2690 cls=0.1394 smmd=0.3914 ct=8.9998 rec=1.1808 | train/val/test=0.960/0.704/0.726 | c=0.998347
[Epoch 0076] loss=30.1037 cls=0.1768 smmd=0.3207 ct=8.9928 rec=1.1709 | train/val/test=0.980/0.708/0.728 | c=0.998347
[Epoch 0077] loss=30.0523 cls=0.1788 smmd=0.3216 ct=8.9846 rec=1.1672 | train/val/test=0.980/0.682/0.722 | c=0.998347
[Epoch 0078] loss=30.1332 cls=0.1329 smmd=0.3677 ct=8.9912 rec=1.1717 | train/val/test=0.960/0.702/0.723 | c=0.998347
[Epoch 0079] loss=30.1043 cls=0.1689 smmd=0.3169 ct=8.9935 rec=1.1716 | train/val/test=0.980/0.704/0.724 | c=0.998347
[Epoch 0080] loss=30.0418 cls=0.1648 smmd=0.2867 ct=8.9852 rec=1.1702 | train/val/test=0.980/0.684/0.722 | c=0.998347
[Epoch 0081] loss=30.1343 cls=0.1361 smmd=0.3003 ct=8.9929 rec=1.1780 | train/val/test=0.960/0.710/0.724 | c=0.998347
[Epoch 0082] loss=30.2090 cls=0.1905 smmd=0.2986 ct=9.0059 rec=1.1803 | train/val/test=0.980/0.692/0.723 | c=0.998347
[Epoch 0083] loss=30.1418 cls=0.1379 smmd=0.2985 ct=8.9945 rec=1.1785 | train/val/test=0.980/0.700/0.721 | c=0.998347
[Epoch 0084] loss=30.0381 cls=0.1719 smmd=0.2700 ct=8.9886 rec=1.1705 | train/val/test=0.980/0.702/0.722 | c=0.998347
[Epoch 0085] loss=30.0155 cls=0.1559 smmd=0.2803 ct=8.9870 rec=1.1683 | train/val/test=0.980/0.690/0.721 | c=0.998347
[Epoch 0086] loss=30.0093 cls=0.1334 smmd=0.2784 ct=8.9870 rec=1.1690 | train/val/test=0.980/0.702/0.720 | c=0.998347
[Epoch 0087] loss=29.9930 cls=0.1672 smmd=0.2670 ct=8.9867 rec=1.1669 | train/val/test=0.980/0.698/0.723 | c=0.998347
[Epoch 0088] loss=29.9620 cls=0.1428 smmd=0.2423 ct=8.9838 rec=1.1681 | train/val/test=0.980/0.694/0.723 | c=0.998347
[Epoch 0089] loss=29.9936 cls=0.1355 smmd=0.2449 ct=8.9878 rec=1.1705 | train/val/test=0.980/0.704/0.721 | c=0.998347
[Epoch 0090] loss=30.0606 cls=0.1676 smmd=0.2498 ct=8.9951 rec=1.1737 | train/val/test=0.980/0.692/0.723 | c=0.998347
[Epoch 0091] loss=30.0881 cls=0.1315 smmd=0.2643 ct=8.9942 rec=1.1770 | train/val/test=0.960/0.700/0.725 | c=0.998347
[Epoch 0092] loss=30.0686 cls=0.1895 smmd=0.2557 ct=8.9974 rec=1.1723 | train/val/test=0.980/0.688/0.725 | c=0.998347
[Epoch 0093] loss=30.0266 cls=0.1312 smmd=0.2673 ct=8.9905 rec=1.1713 | train/val/test=0.980/0.700/0.721 | c=0.998347
[Epoch 0094] loss=30.0412 cls=0.1768 smmd=0.2813 ct=8.9931 rec=1.1685 | train/val/test=0.960/0.694/0.722 | c=0.998347
[Epoch 0095] loss=30.0880 cls=0.1606 smmd=0.2957 ct=9.0014 rec=1.1709 | train/val/test=0.980/0.702/0.722 | c=0.998347
[Epoch 0096] loss=29.9967 cls=0.1527 smmd=0.2857 ct=8.9893 rec=1.1656 | train/val/test=0.980/0.690/0.724 | c=0.998347
[Epoch 0097] loss=29.9054 cls=0.1268 smmd=0.2418 ct=8.9818 rec=1.1637 | train/val/test=0.980/0.698/0.724 | c=0.998347
[Epoch 0098] loss=29.9645 cls=0.1450 smmd=0.2436 ct=8.9903 rec=1.1668 | train/val/test=0.980/0.698/0.718 | c=0.998347
[Epoch 0099] loss=30.0158 cls=0.1374 smmd=0.2714 ct=8.9922 rec=1.1691 | train/val/test=0.980/0.696/0.726 | c=0.998347
[Epoch 0100] loss=29.9800 cls=0.1327 smmd=0.2237 ct=8.9906 rec=1.1709 | train/val/test=0.980/0.700/0.720 | c=0.998347
[Epoch 0101] loss=29.9850 cls=0.1628 smmd=0.2307 ct=8.9908 rec=1.1691 | train/val/test=0.980/0.684/0.725 | c=0.998347
[Epoch 0102] loss=30.0766 cls=0.1287 smmd=0.2592 ct=8.9956 rec=1.1762 | train/val/test=0.940/0.706/0.725 | c=0.998347
[Epoch 0103] loss=30.2319 cls=0.2350 smmd=0.3230 ct=9.0132 rec=1.1765 | train/val/test=0.960/0.680/0.719 | c=0.998347
[Epoch 0104] loss=30.2484 cls=0.1461 smmd=0.3515 ct=9.0092 rec=1.1805 | train/val/test=0.980/0.708/0.719 | c=0.998347
[Epoch 0105] loss=30.1547 cls=0.2079 smmd=0.3591 ct=9.0032 rec=1.1685 | train/val/test=0.960/0.698/0.724 | c=0.998347
[Epoch 0106] loss=30.0133 cls=0.1553 smmd=0.3371 ct=8.9940 rec=1.1611 | train/val/test=0.980/0.688/0.725 | c=0.998347
[Epoch 0107] loss=29.9034 cls=0.1167 smmd=0.3057 ct=8.9802 rec=1.1579 | train/val/test=0.980/0.702/0.717 | c=0.998347
[Epoch 0108] loss=30.0511 cls=0.1462 smmd=0.3734 ct=8.9924 rec=1.1620 | train/val/test=0.960/0.694/0.727 | c=0.998347
[Epoch 0109] loss=29.9674 cls=0.1349 smmd=0.2794 ct=8.9904 rec=1.1640 | train/val/test=0.980/0.690/0.726 | c=0.998347
[Epoch 0110] loss=29.9463 cls=0.1189 smmd=0.2499 ct=8.9841 rec=1.1669 | train/val/test=0.980/0.704/0.720 | c=0.998347
[Epoch 0111] loss=30.0883 cls=0.1515 smmd=0.2793 ct=9.0000 rec=1.1733 | train/val/test=0.960/0.694/0.724 | c=0.998347
[Epoch 0112] loss=30.1647 cls=0.1469 smmd=0.2593 ct=9.0076 rec=1.1817 | train/val/test=0.900/0.696/0.718 | c=0.998347
[Epoch 0113] loss=30.3380 cls=0.2455 smmd=0.3648 ct=9.0213 rec=1.1808 | train/val/test=0.960/0.678/0.719 | c=0.998347
[Epoch 0114] loss=30.4350 cls=0.1621 smmd=0.4304 ct=9.0297 rec=1.1864 | train/val/test=0.960/0.692/0.719 | c=0.998347
[Epoch 0115] loss=30.0826 cls=0.2085 smmd=0.3618 ct=8.9985 rec=1.1620 | train/val/test=0.980/0.694/0.717 | c=0.998347
[Epoch 0116] loss=29.9944 cls=0.1672 smmd=0.3653 ct=8.9870 rec=1.1571 | train/val/test=0.960/0.686/0.724 | c=0.998347
[Epoch 0117] loss=30.1365 cls=0.1287 smmd=0.4511 ct=8.9989 rec=1.1623 | train/val/test=0.960/0.698/0.729 | c=0.998347
[Epoch 0118] loss=29.9292 cls=0.1331 smmd=0.3399 ct=8.9860 rec=1.1551 | train/val/test=0.980/0.692/0.719 | c=0.998347
[Epoch 0119] loss=30.1084 cls=0.1741 smmd=0.4012 ct=8.9995 rec=1.1621 | train/val/test=0.980/0.694/0.727 | c=0.998347
[Epoch 0120] loss=29.9015 cls=0.1210 smmd=0.2620 ct=8.9817 rec=1.1616 | train/val/test=0.960/0.692/0.726 | c=0.998347
[Epoch 0121] loss=30.1071 cls=0.1306 smmd=0.2982 ct=8.9988 rec=1.1746 | train/val/test=0.940/0.688/0.715 | c=0.998347
[Epoch 0122] loss=30.3575 cls=0.2159 smmd=0.3972 ct=9.0223 rec=1.1808 | train/val/test=0.960/0.694/0.730 | c=0.998347
[Epoch 0123] loss=30.3237 cls=0.1626 smmd=0.3339 ct=9.0217 rec=1.1865 | train/val/test=0.980/0.700/0.717 | c=0.998347
[Epoch 0124] loss=30.2745 cls=0.1827 smmd=0.4176 ct=9.0136 rec=1.1738 | train/val/test=0.980/0.690/0.726 | c=0.998347
[Epoch 0125] loss=31.3590 cls=0.1319 smmd=0.3139 ct=9.6931 rec=1.1593 | train/val/test=0.980/0.702/0.726 | c=0.998347
[Epoch 0126] loss=31.3848 cls=0.1386 smmd=0.4735 ct=9.6333 rec=1.1575 | train/val/test=0.980/0.700/0.724 | c=0.998347
[Epoch 0127] loss=31.3570 cls=0.1342 smmd=0.5693 ct=9.5717 rec=1.1577 | train/val/test=0.980/0.690/0.722 | c=0.998347
[Epoch 0128] loss=31.3423 cls=0.1167 smmd=0.4433 ct=9.6202 rec=1.1600 | train/val/test=0.960/0.706/0.726 | c=0.998347
[Epoch 0129] loss=31.4014 cls=0.1430 smmd=0.3371 ct=9.6901 rec=1.1613 | train/val/test=0.980/0.702/0.723 | c=0.998347
[Epoch 0130] loss=31.2530 cls=0.1272 smmd=0.2877 ct=9.6323 rec=1.1637 | train/val/test=0.980/0.692/0.722 | c=0.998347
[Epoch 0131] loss=31.4681 cls=0.1248 smmd=0.4614 ct=9.5928 rec=1.1759 | train/val/test=0.960/0.704/0.729 | c=0.998347
[Epoch 0132] loss=31.5685 cls=0.1717 smmd=0.3753 ct=9.6386 rec=1.1830 | train/val/test=0.980/0.686/0.716 | c=0.998347
[Epoch 0133] loss=31.6995 cls=0.1593 smmd=0.4176 ct=9.6648 rec=1.1873 | train/val/test=0.960/0.716/0.720 | c=0.998347
[Epoch 0134] loss=31.7885 cls=0.2005 smmd=0.4988 ct=9.6921 rec=1.1805 | train/val/test=0.980/0.698/0.725 | c=0.998347
[Epoch 0135] loss=31.2856 cls=0.1243 smmd=0.3975 ct=9.6350 rec=1.1556 | train/val/test=0.940/0.682/0.701 | c=0.998347
[Epoch 0136] loss=31.6210 cls=0.1856 smmd=0.5717 ct=9.6244 rec=1.1708 | train/val/test=0.980/0.698/0.722 | c=0.998347
[Epoch 0137] loss=31.3097 cls=0.1194 smmd=0.4608 ct=9.6369 rec=1.1515 | train/val/test=0.960/0.702/0.724 | c=0.998347
[Epoch 0138] loss=31.4837 cls=0.1520 smmd=0.5012 ct=9.6676 rec=1.1571 | train/val/test=0.980/0.692/0.717 | c=0.998347
[Epoch 0139] loss=31.2331 cls=0.1108 smmd=0.4018 ct=9.6100 rec=1.1556 | train/val/test=0.980/0.686/0.715 | c=0.998347
[Epoch 0140] loss=31.4724 cls=0.1134 smmd=0.4555 ct=9.6261 rec=1.1708 | train/val/test=0.960/0.702/0.725 | c=0.998347
[Epoch 0141] loss=31.5851 cls=0.1563 smmd=0.4320 ct=9.6599 rec=1.1755 | train/val/test=0.980/0.694/0.719 | c=0.998347
[Epoch 0142] loss=31.2903 cls=0.1103 smmd=0.3160 ct=9.6159 rec=1.1687 | train/val/test=0.940/0.694/0.708 | c=0.998347
[Epoch 0143] loss=31.6830 cls=0.1959 smmd=0.4814 ct=9.6267 rec=1.1850 | train/val/test=0.960/0.704/0.732 | c=0.998347
[Epoch 0144] loss=32.0171 cls=0.1885 smmd=0.5375 ct=9.7397 rec=1.1906 | train/val/test=0.960/0.702/0.725 | c=0.998347
[Epoch 0145] loss=31.3646 cls=0.1680 smmd=0.4288 ct=9.6125 rec=1.1627 | train/val/test=0.920/0.680/0.698 | c=0.998347
[Epoch 0146] loss=31.8201 cls=0.1957 smmd=0.6379 ct=9.6397 rec=1.1805 | train/val/test=0.960/0.704/0.728 | c=0.998347
[Epoch 0147] loss=31.4456 cls=0.1230 smmd=0.5086 ct=9.6671 rec=1.1541 | train/val/test=0.940/0.708/0.723 | c=0.998347
[Epoch 0148] loss=31.6666 cls=0.1796 smmd=0.6078 ct=9.6869 rec=1.1595 | train/val/test=0.980/0.696/0.722 | c=0.998347
[Epoch 0149] loss=31.2628 cls=0.1100 smmd=0.4660 ct=9.6177 rec=1.1506 | train/val/test=0.980/0.680/0.705 | c=0.998347
[Epoch 0150] loss=31.6551 cls=0.1063 smmd=0.6328 ct=9.6327 rec=1.1704 | train/val/test=0.980/0.698/0.726 | c=0.998347
[Epoch 0151] loss=31.2590 cls=0.1085 smmd=0.4245 ct=9.6141 rec=1.1552 | train/val/test=0.960/0.708/0.724 | c=0.998347
[Epoch 0152] loss=31.5837 cls=0.1548 smmd=0.4867 ct=9.6618 rec=1.1696 | train/val/test=0.980/0.692/0.717 | c=0.998347
[Epoch 0153] loss=31.3269 cls=0.0975 smmd=0.3533 ct=9.6265 rec=1.1672 | train/val/test=0.940/0.688/0.705 | c=0.998347
[Epoch 0154] loss=31.6797 cls=0.1880 smmd=0.5165 ct=9.6223 rec=1.1825 | train/val/test=0.960/0.704/0.727 | c=0.998347
[Epoch 0155] loss=31.8280 cls=0.1728 smmd=0.4844 ct=9.7026 rec=1.1852 | train/val/test=0.960/0.706/0.728 | c=0.998347
[Epoch 0156] loss=31.4280 cls=0.1710 smmd=0.4274 ct=9.6152 rec=1.1685 | train/val/test=0.960/0.680/0.708 | c=0.998347
[Epoch 0157] loss=31.7533 cls=0.1575 smmd=0.5963 ct=9.6476 rec=1.1783 | train/val/test=0.980/0.704/0.728 | c=0.998347
[Epoch 0158] loss=31.3022 cls=0.1283 smmd=0.4235 ct=9.6362 rec=1.1542 | train/val/test=0.940/0.710/0.721 | c=0.998347
[Epoch 0159] loss=31.5417 cls=0.1733 smmd=0.5317 ct=9.6588 rec=1.1606 | train/val/test=0.960/0.696/0.720 | c=0.998347
[Epoch 0160] loss=31.2760 cls=0.1031 smmd=0.4507 ct=9.6230 rec=1.1528 | train/val/test=0.980/0.684/0.710 | c=0.998347
[Epoch 0161] loss=31.4964 cls=0.1119 smmd=0.5528 ct=9.6218 rec=1.1644 | train/val/test=0.980/0.696/0.725 | c=0.998347
[Epoch 0162] loss=31.2473 cls=0.1197 smmd=0.3980 ct=9.6099 rec=1.1570 | train/val/test=0.960/0.704/0.726 | c=0.998347
[Epoch 0163] loss=31.4611 cls=0.1379 smmd=0.4114 ct=9.6576 rec=1.1665 | train/val/test=0.980/0.694/0.720 | c=0.998347
[Epoch 0164] loss=31.2650 cls=0.1088 smmd=0.3322 ct=9.6068 rec=1.1665 | train/val/test=0.980/0.690/0.719 | c=0.998347
[Epoch 0165] loss=31.5080 cls=0.1475 smmd=0.4176 ct=9.6210 rec=1.1775 | train/val/test=0.960/0.704/0.729 | c=0.998347
[Epoch 0166] loss=31.6129 cls=0.1562 smmd=0.3780 ct=9.6695 rec=1.1818 | train/val/test=0.960/0.704/0.725 | c=0.998347
[Epoch 0167] loss=31.3438 cls=0.1659 smmd=0.3597 ct=9.6010 rec=1.1699 | train/val/test=0.980/0.680/0.716 | c=0.998347
[Epoch 0168] loss=31.6392 cls=0.1406 smmd=0.4949 ct=9.6498 rec=1.1774 | train/val/test=0.980/0.710/0.730 | c=0.998347
[Epoch 0169] loss=31.3585 cls=0.1663 smmd=0.3994 ct=9.6329 rec=1.1610 | train/val/test=0.960/0.704/0.722 | c=0.998347
[Epoch 0170] loss=31.3595 cls=0.1433 smmd=0.4293 ct=9.6392 rec=1.1580 | train/val/test=0.980/0.686/0.722 | c=0.998347
[Epoch 0171] loss=31.2692 cls=0.1039 smmd=0.4246 ct=9.6153 rec=1.1562 | train/val/test=0.980/0.692/0.719 | c=0.998347
[Epoch 0172] loss=31.3787 cls=0.1360 smmd=0.4843 ct=9.6088 rec=1.1609 | train/val/test=0.960/0.704/0.729 | c=0.998347
[Epoch 0173] loss=31.3033 cls=0.1236 smmd=0.3779 ct=9.6384 rec=1.1587 | train/val/test=0.960/0.698/0.725 | c=0.998347
[Epoch 0174] loss=31.3679 cls=0.1243 smmd=0.3780 ct=9.6364 rec=1.1655 | train/val/test=0.980/0.692/0.718 | c=0.998347
[Epoch 0175] loss=31.3798 cls=0.1262 smmd=0.3983 ct=9.6050 rec=1.1708 | train/val/test=0.980/0.702/0.724 | c=0.998347
[Epoch 0176] loss=31.3366 cls=0.1179 smmd=0.3132 ct=9.6281 rec=1.1708 | train/val/test=0.960/0.706/0.723 | c=0.998347
[Epoch 0177] loss=31.5299 cls=0.1897 smmd=0.3893 ct=9.6186 rec=1.1808 | train/val/test=0.980/0.678/0.708 | c=0.998347
[Epoch 0178] loss=31.7561 cls=0.1449 smmd=0.4239 ct=9.6748 rec=1.1910 | train/val/test=0.880/0.692/0.720 | c=0.998347
[Epoch 0179] loss=31.8272 cls=0.3423 smmd=0.5756 ct=9.6198 rec=1.1841 | train/val/test=0.960/0.690/0.726 | c=0.998347
[Epoch 0180] loss=31.3380 cls=0.1373 smmd=0.3808 ct=9.6489 rec=1.1591 | train/val/test=0.960/0.682/0.724 | c=0.998347
[Epoch 0181] loss=31.3145 cls=0.1129 smmd=0.4338 ct=9.6348 rec=1.1555 | train/val/test=0.940/0.704/0.719 | c=0.998347
[Epoch 0182] loss=31.4409 cls=0.1814 smmd=0.5483 ct=9.6009 rec=1.1600 | train/val/test=0.980/0.702/0.732 | c=0.998347
[Epoch 0183] loss=31.2193 cls=0.1238 smmd=0.4089 ct=9.6120 rec=1.1524 | train/val/test=0.960/0.692/0.723 | c=0.998347
[Epoch 0184] loss=31.3859 cls=0.1209 smmd=0.3881 ct=9.6553 rec=1.1627 | train/val/test=0.980/0.704/0.726 | c=0.998347
[Epoch 0185] loss=31.3293 cls=0.1289 smmd=0.4171 ct=9.5973 rec=1.1653 | train/val/test=0.980/0.694/0.724 | c=0.998347
[Epoch 0186] loss=31.2757 cls=0.1177 smmd=0.3453 ct=9.6013 rec=1.1669 | train/val/test=0.960/0.696/0.723 | c=0.998347
[Epoch 0187] loss=31.5313 cls=0.1317 smmd=0.3416 ct=9.6631 rec=1.1798 | train/val/test=0.960/0.704/0.722 | c=0.998347
[Epoch 0188] loss=31.5537 cls=0.2089 smmd=0.4067 ct=9.6077 rec=1.1827 | train/val/test=0.980/0.682/0.716 | c=0.998347
[Epoch 0189] loss=31.5982 cls=0.1279 smmd=0.4008 ct=9.6543 rec=1.1825 | train/val/test=0.980/0.704/0.733 | c=0.998347
[Epoch 0190] loss=31.4968 cls=0.2047 smmd=0.4438 ct=9.6262 rec=1.1698 | train/val/test=0.980/0.698/0.724 | c=0.998347
[Epoch 0191] loss=31.1756 cls=0.1458 smmd=0.3310 ct=9.6063 rec=1.1559 | train/val/test=0.980/0.684/0.721 | c=0.998347
[Epoch 0192] loss=31.3696 cls=0.1084 smmd=0.4578 ct=9.6319 rec=1.1594 | train/val/test=0.980/0.696/0.725 | c=0.998347
[Epoch 0193] loss=31.1847 cls=0.1272 smmd=0.3802 ct=9.6024 rec=1.1536 | train/val/test=0.980/0.708/0.731 | c=0.998347
[Epoch 0194] loss=31.3229 cls=0.1515 smmd=0.4096 ct=9.6211 rec=1.1595 | train/val/test=0.980/0.696/0.731 | c=0.998347
[Epoch 0195] loss=31.1980 cls=0.1137 smmd=0.3140 ct=9.6161 rec=1.1595 | train/val/test=0.980/0.690/0.725 | c=0.998347
[Epoch 0196] loss=31.3543 cls=0.1105 smmd=0.3788 ct=9.6104 rec=1.1699 | train/val/test=0.980/0.702/0.731 | c=0.998347
[Epoch 0197] loss=31.2228 cls=0.1306 smmd=0.2668 ct=9.6080 rec=1.1675 | train/val/test=0.980/0.700/0.733 | c=0.998347
[Epoch 0198] loss=31.2826 cls=0.1333 smmd=0.2584 ct=9.6202 rec=1.1717 | train/val/test=0.980/0.688/0.723 | c=0.998347
[Epoch 0199] loss=31.4102 cls=0.1403 smmd=0.3437 ct=9.6129 rec=1.1770 | train/val/test=0.980/0.698/0.732 | c=0.998347
=== Best @ epoch 73: val=0.7220, test=0.7260 ===

Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-4 completed in 55.50 seconds.
==================================================
