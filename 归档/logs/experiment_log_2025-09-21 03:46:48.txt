Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3 - 2025-09-21 03:46:48:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.6705 cls=1.0950 smmd=5.6561 ct=11.2758 rec=1.4137 | train/val/test=0.385/0.388/0.413 | c=0.998437
[Epoch 0001] loss=22.6106 cls=1.0888 smmd=4.0446 ct=11.2478 rec=1.4137 | train/val/test=0.692/0.558/0.589 | c=0.998437
[Epoch 0002] loss=24.6083 cls=1.0833 smmd=4.8388 ct=11.2629 rec=1.4136 | train/val/test=0.538/0.468/0.501 | c=0.998437
[Epoch 0003] loss=23.5749 cls=1.0672 smmd=4.4473 ct=11.2163 rec=1.4136 | train/val/test=0.538/0.470/0.503 | c=0.998437
[Epoch 0004] loss=18.1213 cls=1.0381 smmd=2.3460 ct=11.0304 rec=1.4136 | train/val/test=0.615/0.548/0.576 | c=0.998437
[Epoch 0005] loss=20.0986 cls=1.0065 smmd=3.1491 ct=11.0162 rec=1.4129 | train/val/test=0.538/0.542/0.571 | c=0.998437
[Epoch 0006] loss=20.6004 cls=0.9632 smmd=3.3858 ct=10.9483 rec=1.4123 | train/val/test=0.692/0.570/0.601 | c=0.998437
[Epoch 0007] loss=18.9425 cls=0.9183 smmd=2.5029 ct=11.5211 rec=1.4100 | train/val/test=0.692/0.578/0.600 | c=0.998437
[Epoch 0008] loss=17.2204 cls=0.8853 smmd=1.8770 ct=11.3815 rec=1.4074 | train/val/test=0.692/0.570/0.597 | c=0.998437
[Epoch 0009] loss=19.0132 cls=0.8511 smmd=2.5748 ct=11.4472 rec=1.4070 | train/val/test=0.769/0.576/0.602 | c=0.998437
[Epoch 0010] loss=18.8524 cls=0.8288 smmd=2.5191 ct=11.4376 rec=1.4055 | train/val/test=0.769/0.590/0.630 | c=0.998437
[Epoch 0011] loss=16.4451 cls=0.8095 smmd=1.5734 ct=11.4052 rec=1.4032 | train/val/test=0.769/0.578/0.608 | c=0.998437
[Epoch 0012] loss=18.4606 cls=0.7880 smmd=2.3133 ct=11.5814 rec=1.4039 | train/val/test=0.769/0.636/0.669 | c=0.998437
[Epoch 0013] loss=18.0094 cls=0.7550 smmd=2.1659 ct=11.5173 rec=1.3997 | train/val/test=0.846/0.650/0.682 | c=0.998437
[Epoch 0014] loss=16.4466 cls=0.6999 smmd=1.5908 ct=11.4226 rec=1.3942 | train/val/test=0.923/0.672/0.687 | c=0.998437
[Epoch 0015] loss=16.6939 cls=0.6474 smmd=1.6913 ct=11.4474 rec=1.3893 | train/val/test=0.923/0.684/0.701 | c=0.998437
[Epoch 0016] loss=16.2085 cls=0.6085 smmd=1.5105 ct=11.4364 rec=1.3834 | train/val/test=0.923/0.702/0.715 | c=0.998437
[Epoch 0017] loss=15.9722 cls=0.5882 smmd=1.4216 ct=11.4342 rec=1.3798 | train/val/test=0.923/0.716/0.719 | c=0.998437
[Epoch 0018] loss=15.6159 cls=0.5684 smmd=1.2812 ct=11.4391 rec=1.3791 | train/val/test=0.923/0.726/0.725 | c=0.998437
[Epoch 0019] loss=15.4216 cls=0.5532 smmd=1.1939 ct=11.4695 rec=1.3813 | train/val/test=0.923/0.692/0.713 | c=0.998437
[Epoch 0020] loss=15.7077 cls=0.5530 smmd=1.3025 ct=11.4826 rec=1.3846 | train/val/test=0.923/0.702/0.724 | c=0.998437
[Epoch 0021] loss=15.2300 cls=0.5546 smmd=1.1297 ct=11.4352 rec=1.3865 | train/val/test=0.923/0.728/0.719 | c=0.998437
[Epoch 0022] loss=15.6714 cls=0.5405 smmd=1.2950 ct=11.4689 rec=1.3897 | train/val/test=0.923/0.734/0.740 | c=0.998437
[Epoch 0023] loss=15.3100 cls=0.5076 smmd=1.1670 ct=11.4467 rec=1.3838 | train/val/test=0.923/0.714/0.724 | c=0.998437
[Epoch 0024] loss=15.0379 cls=0.4624 smmd=1.0629 ct=11.4601 rec=1.3787 | train/val/test=0.923/0.726/0.729 | c=0.998437
[Epoch 0025] loss=14.7129 cls=0.4215 smmd=0.9403 ct=11.4653 rec=1.3719 | train/val/test=1.000/0.736/0.728 | c=0.998437
[Epoch 0026] loss=14.6539 cls=0.3902 smmd=0.9386 ct=11.4286 rec=1.3674 | train/val/test=1.000/0.736/0.743 | c=0.998437
[Epoch 0027] loss=14.3514 cls=0.3698 smmd=0.8223 ct=11.4288 rec=1.3639 | train/val/test=0.923/0.726/0.737 | c=0.998437
[Epoch 0028] loss=14.4100 cls=0.3606 smmd=0.8326 ct=11.4662 rec=1.3640 | train/val/test=1.000/0.740/0.727 | c=0.998437
[Epoch 0029] loss=14.3373 cls=0.3533 smmd=0.8116 ct=11.4486 rec=1.3661 | train/val/test=1.000/0.746/0.727 | c=0.998437
[Epoch 0030] loss=14.4905 cls=0.3536 smmd=0.8684 ct=11.4586 rec=1.3681 | train/val/test=1.000/0.730/0.727 | c=0.998437
[Epoch 0031] loss=14.5668 cls=0.3481 smmd=0.8912 ct=11.4812 rec=1.3674 | train/val/test=1.000/0.734/0.728 | c=0.998437
[Epoch 0032] loss=14.5801 cls=0.3266 smmd=0.9109 ct=11.4573 rec=1.3646 | train/val/test=1.000/0.724/0.727 | c=0.998437
[Epoch 0033] loss=14.2379 cls=0.2996 smmd=0.7815 ct=11.4557 rec=1.3575 | train/val/test=1.000/0.732/0.722 | c=0.998437
[Epoch 0034] loss=14.0581 cls=0.2713 smmd=0.7168 ct=11.4544 rec=1.3520 | train/val/test=1.000/0.728/0.726 | c=0.998437
[Epoch 0035] loss=13.9390 cls=0.2545 smmd=0.6765 ct=11.4474 rec=1.3463 | train/val/test=1.000/0.726/0.724 | c=0.998437
[Epoch 0036] loss=13.7422 cls=0.2447 smmd=0.6068 ct=11.4307 rec=1.3446 | train/val/test=1.000/0.732/0.725 | c=0.998437
[Epoch 0037] loss=13.7410 cls=0.2422 smmd=0.6006 ct=11.4452 rec=1.3465 | train/val/test=1.000/0.724/0.726 | c=0.998437
[Epoch 0038] loss=13.8658 cls=0.2483 smmd=0.6451 ct=11.4537 rec=1.3504 | train/val/test=1.000/0.730/0.730 | c=0.998437
[Epoch 0039] loss=14.0653 cls=0.2561 smmd=0.7190 ct=11.4633 rec=1.3529 | train/val/test=1.000/0.714/0.717 | c=0.998437
[Epoch 0040] loss=14.1244 cls=0.2529 smmd=0.7476 ct=11.4503 rec=1.3575 | train/val/test=1.000/0.728/0.731 | c=0.998437
[Epoch 0041] loss=14.2410 cls=0.2425 smmd=0.7868 ct=11.4781 rec=1.3492 | train/val/test=1.000/0.712/0.709 | c=0.998437
[Epoch 0042] loss=13.8681 cls=0.2138 smmd=0.6486 ct=11.4653 rec=1.3491 | train/val/test=1.000/0.724/0.720 | c=0.998437
[Epoch 0043] loss=13.6814 cls=0.2000 smmd=0.5862 ct=11.4475 rec=1.3369 | train/val/test=1.000/0.720/0.719 | c=0.998437
[Epoch 0044] loss=13.6996 cls=0.1740 smmd=0.6021 ct=11.4413 rec=1.3324 | train/val/test=1.000/0.732/0.729 | c=0.998437
[Epoch 0045] loss=13.5288 cls=0.1728 smmd=0.5281 ct=11.4576 rec=1.3293 | train/val/test=1.000/0.722/0.723 | c=0.998437
[Epoch 0046] loss=13.5636 cls=0.1711 smmd=0.5516 ct=11.4321 rec=1.3340 | train/val/test=1.000/0.734/0.734 | c=0.998437
[Epoch 0047] loss=13.6649 cls=0.1871 smmd=0.5740 ct=11.4680 rec=1.3367 | train/val/test=1.000/0.706/0.703 | c=0.998437
[Epoch 0048] loss=13.9397 cls=0.2004 smmd=0.6724 ct=11.4820 rec=1.3530 | train/val/test=1.000/0.700/0.729 | c=0.998437
[Epoch 0049] loss=14.1496 cls=0.2169 smmd=0.7493 ct=11.4945 rec=1.3469 | train/val/test=1.000/0.666/0.672 | c=0.998437
[Epoch 0050] loss=14.1889 cls=0.2342 smmd=0.7493 ct=11.5115 rec=1.3743 | train/val/test=1.000/0.678/0.709 | c=0.998437
[Epoch 0051] loss=13.6983 cls=0.1879 smmd=0.5664 ct=11.5194 rec=1.3379 | train/val/test=1.000/0.710/0.722 | c=0.998437
[Epoch 0052] loss=13.8520 cls=0.1343 smmd=0.6763 ct=11.4337 rec=1.3208 | train/val/test=1.000/0.724/0.717 | c=0.998437
[Epoch 0053] loss=13.2344 cls=0.1138 smmd=0.4333 ct=11.4396 rec=1.3093 | train/val/test=1.000/0.716/0.719 | c=0.998437
[Epoch 0054] loss=13.4632 cls=0.1214 smmd=0.5115 ct=11.4664 rec=1.3148 | train/val/test=1.000/0.726/0.725 | c=0.998437
[Epoch 0055] loss=13.5033 cls=0.1293 smmd=0.5375 ct=11.4333 rec=1.3233 | train/val/test=1.000/0.738/0.738 | c=0.998437
[Epoch 0056] loss=13.5510 cls=0.1515 smmd=0.5314 ct=11.4818 rec=1.3300 | train/val/test=1.000/0.700/0.690 | c=0.998437
[Epoch 0057] loss=14.1971 cls=0.1858 smmd=0.7724 ct=11.4935 rec=1.3596 | train/val/test=1.000/0.680/0.705 | c=0.998437
[Epoch 0058] loss=14.2453 cls=0.2306 smmd=0.7691 ct=11.5298 rec=1.3549 | train/val/test=0.923/0.590/0.592 | c=0.998437
[Epoch 0059] loss=14.4396 cls=0.2923 smmd=0.8011 ct=11.5834 rec=1.4144 | train/val/test=1.000/0.660/0.670 | c=0.998437
[Epoch 0060] loss=13.6222 cls=0.1744 smmd=0.5458 ct=11.5029 rec=1.3355 | train/val/test=1.000/0.732/0.723 | c=0.998437
[Epoch 0061] loss=13.4893 cls=0.0877 smmd=0.5519 ct=11.4151 rec=1.3011 | train/val/test=1.000/0.716/0.726 | c=0.998437
[Epoch 0062] loss=13.2279 cls=0.0900 smmd=0.4312 ct=11.4534 rec=1.3028 | train/val/test=1.000/0.708/0.710 | c=0.998437
[Epoch 0063] loss=13.3434 cls=0.0916 smmd=0.4693 ct=11.4712 rec=1.3064 | train/val/test=1.000/0.742/0.730 | c=0.998437
[Epoch 0064] loss=13.4318 cls=0.0938 smmd=0.5214 ct=11.4281 rec=1.3068 | train/val/test=1.000/0.712/0.731 | c=0.998437
[Epoch 0065] loss=13.4932 cls=0.1107 smmd=0.5188 ct=11.4813 rec=1.3190 | train/val/test=1.000/0.732/0.725 | c=0.998437
[Epoch 0066] loss=13.9852 cls=0.1387 smmd=0.6946 ct=11.5133 rec=1.3320 | train/val/test=1.000/0.736/0.730 | c=0.998437
[Epoch 0067] loss=14.5598 cls=0.1476 smmd=0.9486 ct=11.4466 rec=1.3360 | train/val/test=1.000/0.738/0.721 | c=0.998437
[Epoch 0068] loss=13.6751 cls=0.1388 smmd=0.5871 ct=11.4711 rec=1.3337 | train/val/test=1.000/0.760/0.748 | c=0.998437
[Epoch 0069] loss=13.5734 cls=0.1286 smmd=0.5546 ct=11.4600 rec=1.3255 | train/val/test=1.000/0.746/0.728 | c=0.998437
[Epoch 0070] loss=13.2889 cls=0.1108 smmd=0.4696 ct=11.3990 rec=1.3207 | train/val/test=1.000/0.764/0.764 | c=0.998437
[Epoch 0071] loss=13.2005 cls=0.1057 smmd=0.4246 ct=11.4284 rec=1.3154 | train/val/test=1.000/0.742/0.730 | c=0.998437
[Epoch 0072] loss=13.1876 cls=0.1118 smmd=0.4098 ct=11.4455 rec=1.3232 | train/val/test=1.000/0.754/0.756 | c=0.998437
[Epoch 0073] loss=13.2437 cls=0.1277 smmd=0.4354 ct=11.4278 rec=1.3271 | train/val/test=1.000/0.698/0.699 | c=0.998437
[Epoch 0074] loss=13.5874 cls=0.1541 smmd=0.5342 ct=11.4999 rec=1.3499 | train/val/test=1.000/0.618/0.610 | c=0.998437
[Epoch 0075] loss=14.0487 cls=0.2206 smmd=0.6779 ct=11.5671 rec=1.3529 | train/val/test=0.769/0.502/0.521 | c=0.998437
[Epoch 0076] loss=15.2911 cls=0.4369 smmd=1.0726 ct=11.6571 rec=1.4683 | train/val/test=1.000/0.600/0.615 | c=0.998437
[Epoch 0077] loss=13.8157 cls=0.1516 smmd=0.6039 ct=11.5605 rec=1.3393 | train/val/test=1.000/0.726/0.721 | c=0.998437
[Epoch 0078] loss=13.5478 cls=0.0562 smmd=0.5800 ct=11.4249 rec=1.2892 | train/val/test=1.000/0.716/0.727 | c=0.998437
[Epoch 0079] loss=13.3297 cls=0.0583 smmd=0.4746 ct=11.4689 rec=1.2901 | train/val/test=1.000/0.722/0.707 | c=0.998437
[Epoch 0080] loss=13.3695 cls=0.0357 smmd=0.4925 ct=11.4776 rec=1.2855 | train/val/test=1.000/0.750/0.733 | c=0.998437
[Epoch 0081] loss=13.2640 cls=0.0456 smmd=0.4616 ct=11.4396 rec=1.2951 | train/val/test=1.000/0.716/0.731 | c=0.998437
[Epoch 0082] loss=13.2328 cls=0.0473 smmd=0.4441 ct=11.4497 rec=1.2985 | train/val/test=1.000/0.716/0.723 | c=0.998437
[Epoch 0083] loss=13.5455 cls=0.0785 smmd=0.5302 ct=11.5239 rec=1.3139 | train/val/test=1.000/0.726/0.722 | c=0.998437
[Epoch 0084] loss=14.1427 cls=0.1131 smmd=0.7893 ct=11.4456 rec=1.3346 | train/val/test=1.000/0.670/0.668 | c=0.998437
[Epoch 0085] loss=14.2105 cls=0.1932 smmd=0.7621 ct=11.5347 rec=1.3476 | train/val/test=1.000/0.586/0.589 | c=0.998437
[Epoch 0086] loss=14.2559 cls=0.2261 smmd=0.7601 ct=11.5450 rec=1.3955 | train/val/test=0.769/0.578/0.583 | c=0.998437
[Epoch 0087] loss=14.0224 cls=0.4114 smmd=0.6361 ct=11.5430 rec=1.3668 | train/val/test=1.000/0.570/0.580 | c=0.998437
[Epoch 0088] loss=14.0293 cls=0.2123 smmd=0.6686 ct=11.5503 rec=1.4028 | train/val/test=1.000/0.740/0.733 | c=0.998437
[Epoch 0089] loss=13.3154 cls=0.0672 smmd=0.4813 ct=11.4264 rec=1.3043 | train/val/test=1.000/0.708/0.686 | c=0.998437
[Epoch 0090] loss=13.4531 cls=0.1070 smmd=0.5038 ct=11.4751 rec=1.3298 | train/val/test=0.923/0.684/0.682 | c=0.998437
[Epoch 0091] loss=13.6651 cls=0.0993 smmd=0.5864 ct=11.4860 rec=1.3268 | train/val/test=1.000/0.730/0.728 | c=0.998437
[Epoch 0092] loss=13.1777 cls=0.0526 smmd=0.4167 ct=11.4604 rec=1.2987 | train/val/test=1.000/0.750/0.749 | c=0.998437
[Epoch 0093] loss=13.7064 cls=0.0786 smmd=0.5938 ct=11.5231 rec=1.3191 | train/val/test=1.000/0.660/0.664 | c=0.998437
[Epoch 0094] loss=14.2259 cls=0.1211 smmd=0.7751 ct=11.5562 rec=1.3428 | train/val/test=1.000/0.718/0.720 | c=0.998437
[Epoch 0095] loss=13.8417 cls=0.0778 smmd=0.6395 ct=11.5451 rec=1.3179 | train/val/test=1.000/0.730/0.742 | c=0.998437
[Epoch 0096] loss=13.9804 cls=0.0597 smmd=0.7272 ct=11.4831 rec=1.2990 | train/val/test=1.000/0.742/0.739 | c=0.998437
[Epoch 0097] loss=13.2758 cls=0.0505 smmd=0.4559 ct=11.4645 rec=1.2927 | train/val/test=1.000/0.712/0.701 | c=0.998437
[Epoch 0098] loss=13.3156 cls=0.0873 smmd=0.4538 ct=11.4853 rec=1.3045 | train/val/test=1.000/0.744/0.741 | c=0.998437
[Epoch 0099] loss=13.1121 cls=0.0592 smmd=0.3975 ct=11.4415 rec=1.2943 | train/val/test=1.000/0.742/0.742 | c=0.998437
=== Best @ epoch 70: val=0.7640, test=0.7640 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3 - 2025-09-21 03:46:48:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.6705 cls=1.0950 smmd=5.6561 ct=11.2758 rec=1.4137 | train/val/test=0.385/0.388/0.413 | c=0.998437
[Epoch 0001] loss=22.6106 cls=1.0888 smmd=4.0446 ct=11.2478 rec=1.4137 | train/val/test=0.692/0.558/0.589 | c=0.998437
[Epoch 0002] loss=24.6083 cls=1.0833 smmd=4.8388 ct=11.2629 rec=1.4136 | train/val/test=0.538/0.468/0.501 | c=0.998437
[Epoch 0003] loss=23.5749 cls=1.0672 smmd=4.4473 ct=11.2163 rec=1.4136 | train/val/test=0.538/0.470/0.503 | c=0.998437
[Epoch 0004] loss=18.1213 cls=1.0381 smmd=2.3460 ct=11.0304 rec=1.4136 | train/val/test=0.615/0.548/0.576 | c=0.998437
[Epoch 0005] loss=20.0986 cls=1.0065 smmd=3.1491 ct=11.0162 rec=1.4129 | train/val/test=0.538/0.542/0.571 | c=0.998437
[Epoch 0006] loss=20.6004 cls=0.9632 smmd=3.3858 ct=10.9483 rec=1.4123 | train/val/test=0.692/0.570/0.601 | c=0.998437
[Epoch 0007] loss=18.9425 cls=0.9183 smmd=2.5029 ct=11.5211 rec=1.4100 | train/val/test=0.692/0.578/0.600 | c=0.998437
[Epoch 0008] loss=17.2204 cls=0.8853 smmd=1.8770 ct=11.3815 rec=1.4074 | train/val/test=0.692/0.570/0.597 | c=0.998437
[Epoch 0009] loss=19.0132 cls=0.8511 smmd=2.5748 ct=11.4472 rec=1.4070 | train/val/test=0.769/0.576/0.602 | c=0.998437
[Epoch 0010] loss=18.8524 cls=0.8288 smmd=2.5191 ct=11.4376 rec=1.4055 | train/val/test=0.769/0.590/0.630 | c=0.998437
[Epoch 0011] loss=16.4451 cls=0.8095 smmd=1.5734 ct=11.4052 rec=1.4032 | train/val/test=0.769/0.578/0.608 | c=0.998437
[Epoch 0012] loss=18.4606 cls=0.7880 smmd=2.3133 ct=11.5814 rec=1.4039 | train/val/test=0.769/0.636/0.669 | c=0.998437
[Epoch 0013] loss=18.0094 cls=0.7550 smmd=2.1659 ct=11.5173 rec=1.3997 | train/val/test=0.846/0.650/0.682 | c=0.998437
[Epoch 0014] loss=16.4466 cls=0.6999 smmd=1.5908 ct=11.4226 rec=1.3942 | train/val/test=0.923/0.672/0.687 | c=0.998437
[Epoch 0015] loss=16.6939 cls=0.6474 smmd=1.6913 ct=11.4474 rec=1.3893 | train/val/test=0.923/0.684/0.701 | c=0.998437
[Epoch 0016] loss=16.2085 cls=0.6085 smmd=1.5105 ct=11.4364 rec=1.3834 | train/val/test=0.923/0.702/0.715 | c=0.998437
[Epoch 0017] loss=15.9722 cls=0.5882 smmd=1.4216 ct=11.4342 rec=1.3798 | train/val/test=0.923/0.716/0.719 | c=0.998437
[Epoch 0018] loss=15.6159 cls=0.5684 smmd=1.2812 ct=11.4391 rec=1.3791 | train/val/test=0.923/0.726/0.725 | c=0.998437
[Epoch 0019] loss=15.4216 cls=0.5532 smmd=1.1939 ct=11.4695 rec=1.3813 | train/val/test=0.923/0.692/0.713 | c=0.998437
[Epoch 0020] loss=15.7077 cls=0.5530 smmd=1.3025 ct=11.4826 rec=1.3846 | train/val/test=0.923/0.702/0.724 | c=0.998437
[Epoch 0021] loss=15.2300 cls=0.5546 smmd=1.1297 ct=11.4352 rec=1.3865 | train/val/test=0.923/0.728/0.719 | c=0.998437
[Epoch 0022] loss=15.6714 cls=0.5405 smmd=1.2950 ct=11.4689 rec=1.3897 | train/val/test=0.923/0.734/0.740 | c=0.998437
[Epoch 0023] loss=15.3100 cls=0.5076 smmd=1.1670 ct=11.4467 rec=1.3838 | train/val/test=0.923/0.714/0.724 | c=0.998437
[Epoch 0024] loss=15.0379 cls=0.4624 smmd=1.0629 ct=11.4601 rec=1.3787 | train/val/test=0.923/0.726/0.729 | c=0.998437
[Epoch 0025] loss=14.7129 cls=0.4215 smmd=0.9403 ct=11.4653 rec=1.3719 | train/val/test=1.000/0.736/0.728 | c=0.998437
[Epoch 0026] loss=14.6539 cls=0.3902 smmd=0.9386 ct=11.4286 rec=1.3674 | train/val/test=1.000/0.736/0.743 | c=0.998437
[Epoch 0027] loss=14.3514 cls=0.3698 smmd=0.8223 ct=11.4288 rec=1.3639 | train/val/test=0.923/0.726/0.737 | c=0.998437
[Epoch 0028] loss=14.4100 cls=0.3606 smmd=0.8326 ct=11.4662 rec=1.3640 | train/val/test=1.000/0.740/0.727 | c=0.998437
[Epoch 0029] loss=14.3373 cls=0.3533 smmd=0.8116 ct=11.4486 rec=1.3661 | train/val/test=1.000/0.746/0.727 | c=0.998437
[Epoch 0030] loss=14.4905 cls=0.3536 smmd=0.8684 ct=11.4586 rec=1.3681 | train/val/test=1.000/0.730/0.727 | c=0.998437
[Epoch 0031] loss=14.5668 cls=0.3481 smmd=0.8912 ct=11.4812 rec=1.3674 | train/val/test=1.000/0.734/0.728 | c=0.998437
[Epoch 0032] loss=14.5801 cls=0.3266 smmd=0.9109 ct=11.4573 rec=1.3646 | train/val/test=1.000/0.724/0.727 | c=0.998437
[Epoch 0033] loss=14.2379 cls=0.2996 smmd=0.7815 ct=11.4557 rec=1.3575 | train/val/test=1.000/0.732/0.722 | c=0.998437
[Epoch 0034] loss=14.0581 cls=0.2713 smmd=0.7168 ct=11.4544 rec=1.3520 | train/val/test=1.000/0.728/0.726 | c=0.998437
[Epoch 0035] loss=13.9390 cls=0.2545 smmd=0.6765 ct=11.4474 rec=1.3463 | train/val/test=1.000/0.726/0.724 | c=0.998437
[Epoch 0036] loss=13.7422 cls=0.2447 smmd=0.6068 ct=11.4307 rec=1.3446 | train/val/test=1.000/0.732/0.725 | c=0.998437
[Epoch 0037] loss=13.7410 cls=0.2422 smmd=0.6006 ct=11.4452 rec=1.3465 | train/val/test=1.000/0.724/0.726 | c=0.998437
[Epoch 0038] loss=13.8658 cls=0.2483 smmd=0.6451 ct=11.4537 rec=1.3504 | train/val/test=1.000/0.730/0.730 | c=0.998437
[Epoch 0039] loss=14.0653 cls=0.2561 smmd=0.7190 ct=11.4633 rec=1.3529 | train/val/test=1.000/0.714/0.717 | c=0.998437
[Epoch 0040] loss=14.1244 cls=0.2529 smmd=0.7476 ct=11.4503 rec=1.3575 | train/val/test=1.000/0.728/0.731 | c=0.998437
[Epoch 0041] loss=14.2410 cls=0.2425 smmd=0.7868 ct=11.4781 rec=1.3492 | train/val/test=1.000/0.712/0.709 | c=0.998437
[Epoch 0042] loss=13.8681 cls=0.2138 smmd=0.6486 ct=11.4653 rec=1.3491 | train/val/test=1.000/0.724/0.720 | c=0.998437
[Epoch 0043] loss=13.6814 cls=0.2000 smmd=0.5862 ct=11.4475 rec=1.3369 | train/val/test=1.000/0.720/0.719 | c=0.998437
[Epoch 0044] loss=13.6996 cls=0.1740 smmd=0.6021 ct=11.4413 rec=1.3324 | train/val/test=1.000/0.732/0.729 | c=0.998437
[Epoch 0045] loss=13.5288 cls=0.1728 smmd=0.5281 ct=11.4576 rec=1.3293 | train/val/test=1.000/0.722/0.723 | c=0.998437
[Epoch 0046] loss=13.5636 cls=0.1711 smmd=0.5516 ct=11.4321 rec=1.3340 | train/val/test=1.000/0.734/0.734 | c=0.998437
[Epoch 0047] loss=13.6649 cls=0.1871 smmd=0.5740 ct=11.4680 rec=1.3367 | train/val/test=1.000/0.706/0.703 | c=0.998437
[Epoch 0048] loss=13.9397 cls=0.2004 smmd=0.6724 ct=11.4820 rec=1.3530 | train/val/test=1.000/0.700/0.729 | c=0.998437
[Epoch 0049] loss=14.1496 cls=0.2169 smmd=0.7493 ct=11.4945 rec=1.3469 | train/val/test=1.000/0.666/0.672 | c=0.998437
[Epoch 0050] loss=14.1889 cls=0.2342 smmd=0.7493 ct=11.5115 rec=1.3743 | train/val/test=1.000/0.678/0.709 | c=0.998437
[Epoch 0051] loss=13.6983 cls=0.1879 smmd=0.5664 ct=11.5194 rec=1.3379 | train/val/test=1.000/0.710/0.722 | c=0.998437
[Epoch 0052] loss=13.8520 cls=0.1343 smmd=0.6763 ct=11.4337 rec=1.3208 | train/val/test=1.000/0.724/0.717 | c=0.998437
[Epoch 0053] loss=13.2344 cls=0.1138 smmd=0.4333 ct=11.4396 rec=1.3093 | train/val/test=1.000/0.716/0.719 | c=0.998437
[Epoch 0054] loss=13.4632 cls=0.1214 smmd=0.5115 ct=11.4664 rec=1.3148 | train/val/test=1.000/0.726/0.725 | c=0.998437
[Epoch 0055] loss=13.5033 cls=0.1293 smmd=0.5375 ct=11.4333 rec=1.3233 | train/val/test=1.000/0.738/0.738 | c=0.998437
[Epoch 0056] loss=13.5510 cls=0.1515 smmd=0.5314 ct=11.4818 rec=1.3300 | train/val/test=1.000/0.700/0.690 | c=0.998437
[Epoch 0057] loss=14.1971 cls=0.1858 smmd=0.7724 ct=11.4935 rec=1.3596 | train/val/test=1.000/0.680/0.705 | c=0.998437
[Epoch 0058] loss=14.2453 cls=0.2306 smmd=0.7691 ct=11.5298 rec=1.3549 | train/val/test=0.923/0.590/0.592 | c=0.998437
[Epoch 0059] loss=14.4396 cls=0.2923 smmd=0.8011 ct=11.5834 rec=1.4144 | train/val/test=1.000/0.660/0.670 | c=0.998437
[Epoch 0060] loss=13.6222 cls=0.1744 smmd=0.5458 ct=11.5029 rec=1.3355 | train/val/test=1.000/0.732/0.723 | c=0.998437
[Epoch 0061] loss=13.4893 cls=0.0877 smmd=0.5519 ct=11.4151 rec=1.3011 | train/val/test=1.000/0.716/0.726 | c=0.998437
[Epoch 0062] loss=13.2279 cls=0.0900 smmd=0.4312 ct=11.4534 rec=1.3028 | train/val/test=1.000/0.708/0.710 | c=0.998437
[Epoch 0063] loss=13.3434 cls=0.0916 smmd=0.4693 ct=11.4712 rec=1.3064 | train/val/test=1.000/0.742/0.730 | c=0.998437
[Epoch 0064] loss=13.4318 cls=0.0938 smmd=0.5214 ct=11.4281 rec=1.3068 | train/val/test=1.000/0.712/0.731 | c=0.998437
[Epoch 0065] loss=13.4932 cls=0.1107 smmd=0.5188 ct=11.4813 rec=1.3190 | train/val/test=1.000/0.732/0.725 | c=0.998437
[Epoch 0066] loss=13.9852 cls=0.1387 smmd=0.6946 ct=11.5133 rec=1.3320 | train/val/test=1.000/0.736/0.730 | c=0.998437
[Epoch 0067] loss=14.5598 cls=0.1476 smmd=0.9486 ct=11.4466 rec=1.3360 | train/val/test=1.000/0.738/0.721 | c=0.998437
[Epoch 0068] loss=13.6751 cls=0.1388 smmd=0.5871 ct=11.4711 rec=1.3337 | train/val/test=1.000/0.760/0.748 | c=0.998437
[Epoch 0069] loss=13.5734 cls=0.1286 smmd=0.5546 ct=11.4600 rec=1.3255 | train/val/test=1.000/0.746/0.728 | c=0.998437
[Epoch 0070] loss=13.2889 cls=0.1108 smmd=0.4696 ct=11.3990 rec=1.3207 | train/val/test=1.000/0.764/0.764 | c=0.998437
[Epoch 0071] loss=13.2005 cls=0.1057 smmd=0.4246 ct=11.4284 rec=1.3154 | train/val/test=1.000/0.742/0.730 | c=0.998437
[Epoch 0072] loss=13.1876 cls=0.1118 smmd=0.4098 ct=11.4455 rec=1.3232 | train/val/test=1.000/0.754/0.756 | c=0.998437
[Epoch 0073] loss=13.2437 cls=0.1277 smmd=0.4354 ct=11.4278 rec=1.3271 | train/val/test=1.000/0.698/0.699 | c=0.998437
[Epoch 0074] loss=13.5874 cls=0.1541 smmd=0.5342 ct=11.4999 rec=1.3499 | train/val/test=1.000/0.618/0.610 | c=0.998437
[Epoch 0075] loss=14.0487 cls=0.2206 smmd=0.6779 ct=11.5671 rec=1.3529 | train/val/test=0.769/0.502/0.521 | c=0.998437
[Epoch 0076] loss=15.2911 cls=0.4369 smmd=1.0726 ct=11.6571 rec=1.4683 | train/val/test=1.000/0.600/0.615 | c=0.998437
[Epoch 0077] loss=13.8157 cls=0.1516 smmd=0.6039 ct=11.5605 rec=1.3393 | train/val/test=1.000/0.726/0.721 | c=0.998437
[Epoch 0078] loss=13.5478 cls=0.0562 smmd=0.5800 ct=11.4249 rec=1.2892 | train/val/test=1.000/0.716/0.727 | c=0.998437
[Epoch 0079] loss=13.3297 cls=0.0583 smmd=0.4746 ct=11.4689 rec=1.2901 | train/val/test=1.000/0.722/0.707 | c=0.998437
[Epoch 0080] loss=13.3695 cls=0.0357 smmd=0.4925 ct=11.4776 rec=1.2855 | train/val/test=1.000/0.750/0.733 | c=0.998437
[Epoch 0081] loss=13.2640 cls=0.0456 smmd=0.4616 ct=11.4396 rec=1.2951 | train/val/test=1.000/0.716/0.731 | c=0.998437
[Epoch 0082] loss=13.2328 cls=0.0473 smmd=0.4441 ct=11.4497 rec=1.2985 | train/val/test=1.000/0.716/0.723 | c=0.998437
[Epoch 0083] loss=13.5455 cls=0.0785 smmd=0.5302 ct=11.5239 rec=1.3139 | train/val/test=1.000/0.726/0.722 | c=0.998437
[Epoch 0084] loss=14.1427 cls=0.1131 smmd=0.7893 ct=11.4456 rec=1.3346 | train/val/test=1.000/0.670/0.668 | c=0.998437
[Epoch 0085] loss=14.2105 cls=0.1932 smmd=0.7621 ct=11.5347 rec=1.3476 | train/val/test=1.000/0.586/0.589 | c=0.998437
[Epoch 0086] loss=14.2559 cls=0.2261 smmd=0.7601 ct=11.5450 rec=1.3955 | train/val/test=0.769/0.578/0.583 | c=0.998437
[Epoch 0087] loss=14.0224 cls=0.4114 smmd=0.6361 ct=11.5430 rec=1.3668 | train/val/test=1.000/0.570/0.580 | c=0.998437
[Epoch 0088] loss=14.0293 cls=0.2123 smmd=0.6686 ct=11.5503 rec=1.4028 | train/val/test=1.000/0.740/0.733 | c=0.998437
[Epoch 0089] loss=13.3154 cls=0.0672 smmd=0.4813 ct=11.4264 rec=1.3043 | train/val/test=1.000/0.708/0.686 | c=0.998437
[Epoch 0090] loss=13.4531 cls=0.1070 smmd=0.5038 ct=11.4751 rec=1.3298 | train/val/test=0.923/0.684/0.682 | c=0.998437
[Epoch 0091] loss=13.6651 cls=0.0993 smmd=0.5864 ct=11.4860 rec=1.3268 | train/val/test=1.000/0.730/0.728 | c=0.998437
[Epoch 0092] loss=13.1777 cls=0.0526 smmd=0.4167 ct=11.4604 rec=1.2987 | train/val/test=1.000/0.750/0.749 | c=0.998437
[Epoch 0093] loss=13.7064 cls=0.0786 smmd=0.5938 ct=11.5231 rec=1.3191 | train/val/test=1.000/0.660/0.664 | c=0.998437
[Epoch 0094] loss=14.2259 cls=0.1211 smmd=0.7751 ct=11.5562 rec=1.3428 | train/val/test=1.000/0.718/0.720 | c=0.998437
[Epoch 0095] loss=13.8417 cls=0.0778 smmd=0.6395 ct=11.5451 rec=1.3179 | train/val/test=1.000/0.730/0.742 | c=0.998437
[Epoch 0096] loss=13.9804 cls=0.0597 smmd=0.7272 ct=11.4831 rec=1.2990 | train/val/test=1.000/0.742/0.739 | c=0.998437
[Epoch 0097] loss=13.2758 cls=0.0505 smmd=0.4559 ct=11.4645 rec=1.2927 | train/val/test=1.000/0.712/0.701 | c=0.998437
[Epoch 0098] loss=13.3156 cls=0.0873 smmd=0.4538 ct=11.4853 rec=1.3045 | train/val/test=1.000/0.744/0.741 | c=0.998437
[Epoch 0099] loss=13.1121 cls=0.0592 smmd=0.3975 ct=11.4415 rec=1.2943 | train/val/test=1.000/0.742/0.742 | c=0.998437
=== Best @ epoch 70: val=0.7640, test=0.7640 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-3 completed in 140.84 seconds.
==================================================
