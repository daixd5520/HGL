Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-1 - 2025-09-21 03:42:09:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-1...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.4738 cls=1.0994 smmd=5.5746 ct=11.2809 rec=1.4136 | train/val/test=0.692/0.444/0.454 | c=0.998437
[Epoch 0001] loss=22.4281 cls=1.0908 smmd=3.9704 ct=11.2500 rec=1.4136 | train/val/test=0.846/0.594/0.618 | c=0.998437
[Epoch 0002] loss=24.5408 cls=1.0829 smmd=4.8128 ct=11.2608 rec=1.4135 | train/val/test=0.462/0.416/0.450 | c=0.998437
[Epoch 0003] loss=23.4333 cls=1.0601 smmd=4.4111 ct=11.1687 rec=1.4135 | train/val/test=0.538/0.448/0.459 | c=0.998437
[Epoch 0004] loss=18.0888 cls=1.0214 smmd=2.3420 ct=11.0165 rec=1.4133 | train/val/test=0.769/0.628/0.642 | c=0.998437
[Epoch 0005] loss=19.9198 cls=0.9825 smmd=3.0956 ct=10.9837 rec=1.4119 | train/val/test=0.846/0.646/0.649 | c=0.998437
[Epoch 0006] loss=20.4110 cls=0.9385 smmd=3.3194 ct=10.9383 rec=1.4100 | train/val/test=0.846/0.648/0.649 | c=0.998437
[Epoch 0007] loss=18.1623 cls=0.8936 smmd=2.4471 ct=10.8939 rec=1.4078 | train/val/test=0.846/0.630/0.645 | c=0.998437
[Epoch 0008] loss=16.4997 cls=0.8599 smmd=1.7971 ct=10.8744 rec=1.4053 | train/val/test=0.846/0.620/0.642 | c=0.998437
[Epoch 0009] loss=18.2781 cls=0.8445 smmd=2.4993 ct=10.9055 rec=1.4041 | train/val/test=0.846/0.628/0.646 | c=0.998437
[Epoch 0010] loss=18.0310 cls=0.8280 smmd=2.4067 ct=10.8982 rec=1.4040 | train/val/test=0.846/0.632/0.635 | c=0.998437
[Epoch 0011] loss=15.7016 cls=0.8105 smmd=1.4805 ct=10.8930 rec=1.4043 | train/val/test=0.846/0.614/0.618 | c=0.998437
[Epoch 0012] loss=17.8418 cls=0.8031 smmd=2.3418 ct=10.8841 rec=1.4034 | train/val/test=0.846/0.622/0.634 | c=0.998437
[Epoch 0013] loss=17.2330 cls=0.7695 smmd=2.1122 ct=10.8675 rec=1.4007 | train/val/test=0.846/0.648/0.653 | c=0.998437
[Epoch 0014] loss=15.6921 cls=0.7149 smmd=1.5158 ct=10.8472 rec=1.3959 | train/val/test=0.846/0.654/0.661 | c=0.998437
[Epoch 0015] loss=15.8923 cls=0.6686 smmd=1.6083 ct=10.8427 rec=1.3891 | train/val/test=0.846/0.656/0.660 | c=0.998437
[Epoch 0016] loss=15.8032 cls=0.6334 smmd=1.5836 ct=10.8359 rec=1.3833 | train/val/test=0.923/0.660/0.668 | c=0.998437
[Epoch 0017] loss=15.0012 cls=0.6072 smmd=1.2749 ct=10.8205 rec=1.3799 | train/val/test=0.923/0.672/0.676 | c=0.998437
[Epoch 0018] loss=15.6817 cls=0.5941 smmd=1.2692 ct=11.5220 rec=1.3793 | train/val/test=0.923/0.672/0.669 | c=0.998437
[Epoch 0019] loss=15.6536 cls=0.5980 smmd=1.2941 ct=11.4293 rec=1.3803 | train/val/test=0.846/0.666/0.674 | c=0.998437
[Epoch 0020] loss=15.6055 cls=0.5804 smmd=1.2445 ct=11.5121 rec=1.3840 | train/val/test=0.846/0.672/0.678 | c=0.998437
[Epoch 0021] loss=15.3489 cls=0.5830 smmd=1.1440 ct=11.5048 rec=1.3850 | train/val/test=0.923/0.708/0.701 | c=0.998437
[Epoch 0022] loss=15.6666 cls=0.5737 smmd=1.2776 ct=11.4935 rec=1.3847 | train/val/test=0.923/0.694/0.717 | c=0.998437
[Epoch 0023] loss=15.1269 cls=0.5409 smmd=1.0642 ct=11.5038 rec=1.3841 | train/val/test=0.923/0.698/0.713 | c=0.998437
[Epoch 0024] loss=15.2728 cls=0.5248 smmd=1.1203 ct=11.5208 rec=1.3779 | train/val/test=0.923/0.702/0.718 | c=0.998437
[Epoch 0025] loss=14.8472 cls=0.4716 smmd=0.9694 ct=11.4993 rec=1.3774 | train/val/test=1.000/0.714/0.725 | c=0.998437
[Epoch 0026] loss=14.7705 cls=0.4516 smmd=0.9503 ct=11.4855 rec=1.3666 | train/val/test=0.923/0.710/0.718 | c=0.998437
[Epoch 0027] loss=14.5027 cls=0.4198 smmd=0.8539 ct=11.4765 rec=1.3630 | train/val/test=1.000/0.712/0.716 | c=0.998437
[Epoch 0028] loss=14.4194 cls=0.4004 smmd=0.8256 ct=11.4745 rec=1.3616 | train/val/test=1.000/0.710/0.718 | c=0.998437
[Epoch 0029] loss=14.4222 cls=0.3925 smmd=0.8335 ct=11.4608 rec=1.3629 | train/val/test=1.000/0.714/0.716 | c=0.998437
[Epoch 0030] loss=14.4006 cls=0.3907 smmd=0.8127 ct=11.4913 rec=1.3643 | train/val/test=1.000/0.710/0.721 | c=0.998437
[Epoch 0031] loss=14.5212 cls=0.3870 smmd=0.8604 ct=11.4938 rec=1.3656 | train/val/test=1.000/0.710/0.720 | c=0.998437
[Epoch 0032] loss=14.4761 cls=0.3693 smmd=0.8571 ct=11.4660 rec=1.3652 | train/val/test=1.000/0.716/0.722 | c=0.998437
[Epoch 0033] loss=14.3558 cls=0.3486 smmd=0.8065 ct=11.4853 rec=1.3599 | train/val/test=1.000/0.708/0.715 | c=0.998437
[Epoch 0034] loss=14.1533 cls=0.3229 smmd=0.7399 ct=11.4648 rec=1.3547 | train/val/test=1.000/0.716/0.720 | c=0.998437
[Epoch 0035] loss=14.0054 cls=0.2966 smmd=0.6827 ct=11.4753 rec=1.3499 | train/val/test=1.000/0.718/0.719 | c=0.998437
[Epoch 0036] loss=13.8771 cls=0.2859 smmd=0.6437 ct=11.4517 rec=1.3466 | train/val/test=1.000/0.712/0.721 | c=0.998437
[Epoch 0037] loss=13.7609 cls=0.2759 smmd=0.5930 ct=11.4672 rec=1.3467 | train/val/test=1.000/0.720/0.723 | c=0.998437
[Epoch 0038] loss=13.9787 cls=0.2852 smmd=0.6759 ct=11.4716 rec=1.3497 | train/val/test=1.000/0.706/0.725 | c=0.998437
[Epoch 0039] loss=13.8717 cls=0.2787 smmd=0.6266 ct=11.4891 rec=1.3535 | train/val/test=1.000/0.712/0.720 | c=0.998437
[Epoch 0040] loss=14.2258 cls=0.2864 smmd=0.7807 ct=11.4543 rec=1.3531 | train/val/test=1.000/0.708/0.709 | c=0.998437
[Epoch 0041] loss=14.0660 cls=0.2672 smmd=0.6829 ct=11.5466 rec=1.3569 | train/val/test=1.000/0.704/0.724 | c=0.998437
[Epoch 0042] loss=14.0360 cls=0.2661 smmd=0.7010 ct=11.4763 rec=1.3485 | train/val/test=1.000/0.708/0.713 | c=0.998437
[Epoch 0043] loss=13.8555 cls=0.2193 smmd=0.6365 ct=11.4834 rec=1.3426 | train/val/test=1.000/0.712/0.721 | c=0.998437
[Epoch 0044] loss=13.6340 cls=0.2113 smmd=0.5569 ct=11.4694 rec=1.3335 | train/val/test=1.000/0.714/0.717 | c=0.998437
[Epoch 0045] loss=13.6406 cls=0.1916 smmd=0.5672 ct=11.4615 rec=1.3306 | train/val/test=1.000/0.724/0.714 | c=0.998437
[Epoch 0046] loss=13.5178 cls=0.1951 smmd=0.5202 ct=11.4536 rec=1.3321 | train/val/test=1.000/0.724/0.728 | c=0.998437
[Epoch 0047] loss=13.6512 cls=0.2006 smmd=0.5508 ct=11.5050 rec=1.3378 | train/val/test=1.000/0.722/0.721 | c=0.998437
[Epoch 0048] loss=13.8871 cls=0.2139 smmd=0.6640 ct=11.4488 rec=1.3426 | train/val/test=1.000/0.716/0.710 | c=0.998437
[Epoch 0049] loss=13.9380 cls=0.2157 smmd=0.6567 ct=11.5127 rec=1.3514 | train/val/test=1.000/0.732/0.737 | c=0.998437
[Epoch 0050] loss=13.9800 cls=0.2184 smmd=0.6780 ct=11.5038 rec=1.3441 | train/val/test=1.000/0.712/0.688 | c=0.998437
[Epoch 0051] loss=13.9186 cls=0.1978 smmd=0.6534 ct=11.5105 rec=1.3512 | train/val/test=1.000/0.718/0.733 | c=0.998437
[Epoch 0052] loss=13.5157 cls=0.1737 smmd=0.5121 ct=11.4842 rec=1.3291 | train/val/test=1.000/0.720/0.727 | c=0.998437
[Epoch 0053] loss=13.5252 cls=0.1423 smmd=0.5287 ct=11.4723 rec=1.3199 | train/val/test=1.000/0.724/0.716 | c=0.998437
[Epoch 0054] loss=13.3482 cls=0.1415 smmd=0.4728 ct=11.4363 rec=1.3183 | train/val/test=1.000/0.726/0.725 | c=0.998437
[Epoch 0055] loss=13.3403 cls=0.1446 smmd=0.4454 ct=11.4940 rec=1.3213 | train/val/test=1.000/0.732/0.725 | c=0.998437
[Epoch 0056] loss=13.5439 cls=0.1567 smmd=0.5373 ct=11.4582 rec=1.3286 | train/val/test=1.000/0.730/0.730 | c=0.998437
[Epoch 0057] loss=13.7548 cls=0.1696 smmd=0.6007 ct=11.5006 rec=1.3354 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0058] loss=14.0144 cls=0.1739 smmd=0.7081 ct=11.4871 rec=1.3402 | train/val/test=1.000/0.736/0.739 | c=0.998437
[Epoch 0059] loss=13.8677 cls=0.1635 smmd=0.6623 ct=11.4637 rec=1.3329 | train/val/test=1.000/0.718/0.737 | c=0.998437
[Epoch 0060] loss=13.4432 cls=0.1441 smmd=0.4910 ct=11.4797 rec=1.3277 | train/val/test=1.000/0.726/0.733 | c=0.998437
[Epoch 0061] loss=13.3569 cls=0.1345 smmd=0.4716 ct=11.4508 rec=1.3194 | train/val/test=1.000/0.720/0.734 | c=0.998437
[Epoch 0062] loss=13.2460 cls=0.1238 smmd=0.4318 ct=11.4455 rec=1.3182 | train/val/test=1.000/0.726/0.731 | c=0.998437
[Epoch 0063] loss=13.2058 cls=0.1280 smmd=0.4095 ct=11.4591 rec=1.3182 | train/val/test=1.000/0.718/0.729 | c=0.998437
[Epoch 0064] loss=13.3032 cls=0.1327 smmd=0.4388 ct=11.4771 rec=1.3258 | train/val/test=1.000/0.748/0.744 | c=0.998437
[Epoch 0065] loss=13.6555 cls=0.1544 smmd=0.5732 ct=11.4799 rec=1.3306 | train/val/test=1.000/0.680/0.665 | c=0.998437
[Epoch 0066] loss=14.1316 cls=0.1833 smmd=0.7163 ct=11.5690 rec=1.3606 | train/val/test=1.000/0.662/0.693 | c=0.998437
[Epoch 0067] loss=14.1295 cls=0.2139 smmd=0.7143 ct=11.5576 rec=1.3581 | train/val/test=1.000/0.692/0.673 | c=0.998437
[Epoch 0068] loss=14.0526 cls=0.1470 smmd=0.6884 ct=11.5848 rec=1.3467 | train/val/test=1.000/0.720/0.730 | c=0.998437
[Epoch 0069] loss=13.1815 cls=0.0823 smmd=0.4105 ct=11.4656 rec=1.2972 | train/val/test=1.000/0.720/0.721 | c=0.998437
[Epoch 0070] loss=13.7021 cls=0.1160 smmd=0.6003 ct=11.4813 rec=1.3240 | train/val/test=1.000/0.718/0.725 | c=0.998437
[Epoch 0071] loss=13.2228 cls=0.0762 smmd=0.4141 ct=11.5004 rec=1.2981 | train/val/test=1.000/0.728/0.720 | c=0.998437
[Epoch 0072] loss=13.5056 cls=0.0779 smmd=0.5186 ct=11.5212 rec=1.2980 | train/val/test=1.000/0.738/0.747 | c=0.998437
[Epoch 0073] loss=13.3978 cls=0.1120 smmd=0.4793 ct=11.4845 rec=1.3181 | train/val/test=1.000/0.730/0.727 | c=0.998437
[Epoch 0074] loss=13.5199 cls=0.1241 smmd=0.5165 ct=11.5006 rec=1.3319 | train/val/test=1.000/0.744/0.745 | c=0.998437
[Epoch 0075] loss=14.1876 cls=0.1391 smmd=0.7686 ct=11.5294 rec=1.3342 | train/val/test=1.000/0.736/0.722 | c=0.998437
[Epoch 0076] loss=13.9893 cls=0.1675 smmd=0.6929 ct=11.4995 rec=1.3473 | train/val/test=1.000/0.770/0.771 | c=0.998437
[Epoch 0077] loss=13.7920 cls=0.1454 smmd=0.6398 ct=11.4533 rec=1.3330 | train/val/test=1.000/0.676/0.667 | c=0.998437
[Epoch 0078] loss=13.5867 cls=0.1684 smmd=0.5022 ct=11.5727 rec=1.3489 | train/val/test=1.000/0.782/0.770 | c=0.998437
[Epoch 0079] loss=13.4249 cls=0.1115 smmd=0.5110 ct=11.4323 rec=1.3186 | train/val/test=1.000/0.730/0.721 | c=0.998437
[Epoch 0080] loss=13.3578 cls=0.0848 smmd=0.4887 ct=11.4370 rec=1.3130 | train/val/test=1.000/0.744/0.745 | c=0.998437
[Epoch 0081] loss=13.0933 cls=0.0903 smmd=0.3725 ct=11.4629 rec=1.3082 | train/val/test=1.000/0.732/0.737 | c=0.998437
[Epoch 0082] loss=13.3211 cls=0.0927 smmd=0.4637 ct=11.4584 rec=1.3141 | train/val/test=1.000/0.718/0.706 | c=0.998437
[Epoch 0083] loss=13.4509 cls=0.1018 smmd=0.4967 ct=11.4965 rec=1.3236 | train/val/test=1.000/0.764/0.754 | c=0.998437
[Epoch 0084] loss=14.2010 cls=0.1655 smmd=0.7715 ct=11.5209 rec=1.3375 | train/val/test=1.000/0.626/0.605 | c=0.998437
[Epoch 0085] loss=14.4764 cls=0.1490 smmd=0.8259 ct=11.6575 rec=1.3593 | train/val/test=1.000/0.754/0.741 | c=0.998437
[Epoch 0086] loss=13.6879 cls=0.1252 smmd=0.5938 ct=11.4790 rec=1.3233 | train/val/test=1.000/0.726/0.718 | c=0.998437
[Epoch 0087] loss=13.3545 cls=0.0558 smmd=0.4852 ct=11.4683 rec=1.2906 | train/val/test=1.000/0.714/0.709 | c=0.998437
[Epoch 0088] loss=13.1693 cls=0.0535 smmd=0.4102 ct=11.4735 rec=1.2873 | train/val/test=1.000/0.746/0.741 | c=0.998437
[Epoch 0089] loss=13.1676 cls=0.0532 smmd=0.4220 ct=11.4410 rec=1.2898 | train/val/test=1.000/0.754/0.738 | c=0.998437
[Epoch 0090] loss=13.2008 cls=0.0610 smmd=0.4286 ct=11.4519 rec=1.2936 | train/val/test=1.000/0.750/0.733 | c=0.998437
[Epoch 0091] loss=13.1903 cls=0.0860 smmd=0.4081 ct=11.4728 rec=1.3086 | train/val/test=1.000/0.748/0.743 | c=0.998437
[Epoch 0092] loss=13.5878 cls=0.1258 smmd=0.5439 ct=11.5006 rec=1.3289 | train/val/test=1.000/0.780/0.768 | c=0.998437
[Epoch 0093] loss=14.1598 cls=0.1500 smmd=0.7682 ct=11.4975 rec=1.3335 | train/val/test=0.923/0.640/0.629 | c=0.998437
[Epoch 0094] loss=14.3394 cls=0.2550 smmd=0.7854 ct=11.5574 rec=1.3818 | train/val/test=0.923/0.570/0.565 | c=0.998437
[Epoch 0095] loss=14.4794 cls=0.3281 smmd=0.8037 ct=11.6038 rec=1.4046 | train/val/test=0.923/0.662/0.657 | c=0.998437
[Epoch 0096] loss=14.2322 cls=0.1696 smmd=0.7483 ct=11.6035 rec=1.3461 | train/val/test=1.000/0.714/0.725 | c=0.998437
[Epoch 0097] loss=13.4111 cls=0.0520 smmd=0.5064 ct=11.4756 rec=1.2867 | train/val/test=1.000/0.626/0.655 | c=0.998437
[Epoch 0098] loss=14.0816 cls=0.1445 smmd=0.7107 ct=11.5421 rec=1.3808 | train/val/test=1.000/0.728/0.724 | c=0.998437
[Epoch 0099] loss=13.3697 cls=0.0289 smmd=0.5084 ct=11.4463 rec=1.2760 | train/val/test=1.000/0.708/0.712 | c=0.998437
=== Best @ epoch 78: val=0.7820, test=0.7700 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-1 - 2025-09-21 03:42:09:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-1...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.4738 cls=1.0994 smmd=5.5746 ct=11.2809 rec=1.4136 | train/val/test=0.692/0.444/0.454 | c=0.998437
[Epoch 0001] loss=22.4281 cls=1.0908 smmd=3.9704 ct=11.2500 rec=1.4136 | train/val/test=0.846/0.594/0.618 | c=0.998437
[Epoch 0002] loss=24.5408 cls=1.0829 smmd=4.8128 ct=11.2608 rec=1.4135 | train/val/test=0.462/0.416/0.450 | c=0.998437
[Epoch 0003] loss=23.4333 cls=1.0601 smmd=4.4111 ct=11.1687 rec=1.4135 | train/val/test=0.538/0.448/0.459 | c=0.998437
[Epoch 0004] loss=18.0888 cls=1.0214 smmd=2.3420 ct=11.0165 rec=1.4133 | train/val/test=0.769/0.628/0.642 | c=0.998437
[Epoch 0005] loss=19.9198 cls=0.9825 smmd=3.0956 ct=10.9837 rec=1.4119 | train/val/test=0.846/0.646/0.649 | c=0.998437
[Epoch 0006] loss=20.4110 cls=0.9385 smmd=3.3194 ct=10.9383 rec=1.4100 | train/val/test=0.846/0.648/0.649 | c=0.998437
[Epoch 0007] loss=18.1623 cls=0.8936 smmd=2.4471 ct=10.8939 rec=1.4078 | train/val/test=0.846/0.630/0.645 | c=0.998437
[Epoch 0008] loss=16.4997 cls=0.8599 smmd=1.7971 ct=10.8744 rec=1.4053 | train/val/test=0.846/0.620/0.642 | c=0.998437
[Epoch 0009] loss=18.2781 cls=0.8445 smmd=2.4993 ct=10.9055 rec=1.4041 | train/val/test=0.846/0.628/0.646 | c=0.998437
[Epoch 0010] loss=18.0310 cls=0.8280 smmd=2.4067 ct=10.8982 rec=1.4040 | train/val/test=0.846/0.632/0.635 | c=0.998437
[Epoch 0011] loss=15.7016 cls=0.8105 smmd=1.4805 ct=10.8930 rec=1.4043 | train/val/test=0.846/0.614/0.618 | c=0.998437
[Epoch 0012] loss=17.8418 cls=0.8031 smmd=2.3418 ct=10.8841 rec=1.4034 | train/val/test=0.846/0.622/0.634 | c=0.998437
[Epoch 0013] loss=17.2330 cls=0.7695 smmd=2.1122 ct=10.8675 rec=1.4007 | train/val/test=0.846/0.648/0.653 | c=0.998437
[Epoch 0014] loss=15.6921 cls=0.7149 smmd=1.5158 ct=10.8472 rec=1.3959 | train/val/test=0.846/0.654/0.661 | c=0.998437
[Epoch 0015] loss=15.8923 cls=0.6686 smmd=1.6083 ct=10.8427 rec=1.3891 | train/val/test=0.846/0.656/0.660 | c=0.998437
[Epoch 0016] loss=15.8032 cls=0.6334 smmd=1.5836 ct=10.8359 rec=1.3833 | train/val/test=0.923/0.660/0.668 | c=0.998437
[Epoch 0017] loss=15.0012 cls=0.6072 smmd=1.2749 ct=10.8205 rec=1.3799 | train/val/test=0.923/0.672/0.676 | c=0.998437
[Epoch 0018] loss=15.6817 cls=0.5941 smmd=1.2692 ct=11.5220 rec=1.3793 | train/val/test=0.923/0.672/0.669 | c=0.998437
[Epoch 0019] loss=15.6536 cls=0.5980 smmd=1.2941 ct=11.4293 rec=1.3803 | train/val/test=0.846/0.666/0.674 | c=0.998437
[Epoch 0020] loss=15.6055 cls=0.5804 smmd=1.2445 ct=11.5121 rec=1.3840 | train/val/test=0.846/0.672/0.678 | c=0.998437
[Epoch 0021] loss=15.3489 cls=0.5830 smmd=1.1440 ct=11.5048 rec=1.3850 | train/val/test=0.923/0.708/0.701 | c=0.998437
[Epoch 0022] loss=15.6666 cls=0.5737 smmd=1.2776 ct=11.4935 rec=1.3847 | train/val/test=0.923/0.694/0.717 | c=0.998437
[Epoch 0023] loss=15.1269 cls=0.5409 smmd=1.0642 ct=11.5038 rec=1.3841 | train/val/test=0.923/0.698/0.713 | c=0.998437
[Epoch 0024] loss=15.2728 cls=0.5248 smmd=1.1203 ct=11.5208 rec=1.3779 | train/val/test=0.923/0.702/0.718 | c=0.998437
[Epoch 0025] loss=14.8472 cls=0.4716 smmd=0.9694 ct=11.4993 rec=1.3774 | train/val/test=1.000/0.714/0.725 | c=0.998437
[Epoch 0026] loss=14.7705 cls=0.4516 smmd=0.9503 ct=11.4855 rec=1.3666 | train/val/test=0.923/0.710/0.718 | c=0.998437
[Epoch 0027] loss=14.5027 cls=0.4198 smmd=0.8539 ct=11.4765 rec=1.3630 | train/val/test=1.000/0.712/0.716 | c=0.998437
[Epoch 0028] loss=14.4194 cls=0.4004 smmd=0.8256 ct=11.4745 rec=1.3616 | train/val/test=1.000/0.710/0.718 | c=0.998437
[Epoch 0029] loss=14.4222 cls=0.3925 smmd=0.8335 ct=11.4608 rec=1.3629 | train/val/test=1.000/0.714/0.716 | c=0.998437
[Epoch 0030] loss=14.4006 cls=0.3907 smmd=0.8127 ct=11.4913 rec=1.3643 | train/val/test=1.000/0.710/0.721 | c=0.998437
[Epoch 0031] loss=14.5212 cls=0.3870 smmd=0.8604 ct=11.4938 rec=1.3656 | train/val/test=1.000/0.710/0.720 | c=0.998437
[Epoch 0032] loss=14.4761 cls=0.3693 smmd=0.8571 ct=11.4660 rec=1.3652 | train/val/test=1.000/0.716/0.722 | c=0.998437
[Epoch 0033] loss=14.3558 cls=0.3486 smmd=0.8065 ct=11.4853 rec=1.3599 | train/val/test=1.000/0.708/0.715 | c=0.998437
[Epoch 0034] loss=14.1533 cls=0.3229 smmd=0.7399 ct=11.4648 rec=1.3547 | train/val/test=1.000/0.716/0.720 | c=0.998437
[Epoch 0035] loss=14.0054 cls=0.2966 smmd=0.6827 ct=11.4753 rec=1.3499 | train/val/test=1.000/0.718/0.719 | c=0.998437
[Epoch 0036] loss=13.8771 cls=0.2859 smmd=0.6437 ct=11.4517 rec=1.3466 | train/val/test=1.000/0.712/0.721 | c=0.998437
[Epoch 0037] loss=13.7609 cls=0.2759 smmd=0.5930 ct=11.4672 rec=1.3467 | train/val/test=1.000/0.720/0.723 | c=0.998437
[Epoch 0038] loss=13.9787 cls=0.2852 smmd=0.6759 ct=11.4716 rec=1.3497 | train/val/test=1.000/0.706/0.725 | c=0.998437
[Epoch 0039] loss=13.8717 cls=0.2787 smmd=0.6266 ct=11.4891 rec=1.3535 | train/val/test=1.000/0.712/0.720 | c=0.998437
[Epoch 0040] loss=14.2258 cls=0.2864 smmd=0.7807 ct=11.4543 rec=1.3531 | train/val/test=1.000/0.708/0.709 | c=0.998437
[Epoch 0041] loss=14.0660 cls=0.2672 smmd=0.6829 ct=11.5466 rec=1.3569 | train/val/test=1.000/0.704/0.724 | c=0.998437
[Epoch 0042] loss=14.0360 cls=0.2661 smmd=0.7010 ct=11.4763 rec=1.3485 | train/val/test=1.000/0.708/0.713 | c=0.998437
[Epoch 0043] loss=13.8555 cls=0.2193 smmd=0.6365 ct=11.4834 rec=1.3426 | train/val/test=1.000/0.712/0.721 | c=0.998437
[Epoch 0044] loss=13.6340 cls=0.2113 smmd=0.5569 ct=11.4694 rec=1.3335 | train/val/test=1.000/0.714/0.717 | c=0.998437
[Epoch 0045] loss=13.6406 cls=0.1916 smmd=0.5672 ct=11.4615 rec=1.3306 | train/val/test=1.000/0.724/0.714 | c=0.998437
[Epoch 0046] loss=13.5178 cls=0.1951 smmd=0.5202 ct=11.4536 rec=1.3321 | train/val/test=1.000/0.724/0.728 | c=0.998437
[Epoch 0047] loss=13.6512 cls=0.2006 smmd=0.5508 ct=11.5050 rec=1.3378 | train/val/test=1.000/0.722/0.721 | c=0.998437
[Epoch 0048] loss=13.8871 cls=0.2139 smmd=0.6640 ct=11.4488 rec=1.3426 | train/val/test=1.000/0.716/0.710 | c=0.998437
[Epoch 0049] loss=13.9380 cls=0.2157 smmd=0.6567 ct=11.5127 rec=1.3514 | train/val/test=1.000/0.732/0.737 | c=0.998437
[Epoch 0050] loss=13.9800 cls=0.2184 smmd=0.6780 ct=11.5038 rec=1.3441 | train/val/test=1.000/0.712/0.688 | c=0.998437
[Epoch 0051] loss=13.9186 cls=0.1978 smmd=0.6534 ct=11.5105 rec=1.3512 | train/val/test=1.000/0.718/0.733 | c=0.998437
[Epoch 0052] loss=13.5157 cls=0.1737 smmd=0.5121 ct=11.4842 rec=1.3291 | train/val/test=1.000/0.720/0.727 | c=0.998437
[Epoch 0053] loss=13.5252 cls=0.1423 smmd=0.5287 ct=11.4723 rec=1.3199 | train/val/test=1.000/0.724/0.716 | c=0.998437
[Epoch 0054] loss=13.3482 cls=0.1415 smmd=0.4728 ct=11.4363 rec=1.3183 | train/val/test=1.000/0.726/0.725 | c=0.998437
[Epoch 0055] loss=13.3403 cls=0.1446 smmd=0.4454 ct=11.4940 rec=1.3213 | train/val/test=1.000/0.732/0.725 | c=0.998437
[Epoch 0056] loss=13.5439 cls=0.1567 smmd=0.5373 ct=11.4582 rec=1.3286 | train/val/test=1.000/0.730/0.730 | c=0.998437
[Epoch 0057] loss=13.7548 cls=0.1696 smmd=0.6007 ct=11.5006 rec=1.3354 | train/val/test=1.000/0.722/0.728 | c=0.998437
[Epoch 0058] loss=14.0144 cls=0.1739 smmd=0.7081 ct=11.4871 rec=1.3402 | train/val/test=1.000/0.736/0.739 | c=0.998437
[Epoch 0059] loss=13.8677 cls=0.1635 smmd=0.6623 ct=11.4637 rec=1.3329 | train/val/test=1.000/0.718/0.737 | c=0.998437
[Epoch 0060] loss=13.4432 cls=0.1441 smmd=0.4910 ct=11.4797 rec=1.3277 | train/val/test=1.000/0.726/0.733 | c=0.998437
[Epoch 0061] loss=13.3569 cls=0.1345 smmd=0.4716 ct=11.4508 rec=1.3194 | train/val/test=1.000/0.720/0.734 | c=0.998437
[Epoch 0062] loss=13.2460 cls=0.1238 smmd=0.4318 ct=11.4455 rec=1.3182 | train/val/test=1.000/0.726/0.731 | c=0.998437
[Epoch 0063] loss=13.2058 cls=0.1280 smmd=0.4095 ct=11.4591 rec=1.3182 | train/val/test=1.000/0.718/0.729 | c=0.998437
[Epoch 0064] loss=13.3032 cls=0.1327 smmd=0.4388 ct=11.4771 rec=1.3258 | train/val/test=1.000/0.748/0.744 | c=0.998437
[Epoch 0065] loss=13.6555 cls=0.1544 smmd=0.5732 ct=11.4799 rec=1.3306 | train/val/test=1.000/0.680/0.665 | c=0.998437
[Epoch 0066] loss=14.1316 cls=0.1833 smmd=0.7163 ct=11.5690 rec=1.3606 | train/val/test=1.000/0.662/0.693 | c=0.998437
[Epoch 0067] loss=14.1295 cls=0.2139 smmd=0.7143 ct=11.5576 rec=1.3581 | train/val/test=1.000/0.692/0.673 | c=0.998437
[Epoch 0068] loss=14.0526 cls=0.1470 smmd=0.6884 ct=11.5848 rec=1.3467 | train/val/test=1.000/0.720/0.730 | c=0.998437
[Epoch 0069] loss=13.1815 cls=0.0823 smmd=0.4105 ct=11.4656 rec=1.2972 | train/val/test=1.000/0.720/0.721 | c=0.998437
[Epoch 0070] loss=13.7021 cls=0.1160 smmd=0.6003 ct=11.4813 rec=1.3240 | train/val/test=1.000/0.718/0.725 | c=0.998437
[Epoch 0071] loss=13.2228 cls=0.0762 smmd=0.4141 ct=11.5004 rec=1.2981 | train/val/test=1.000/0.728/0.720 | c=0.998437
[Epoch 0072] loss=13.5056 cls=0.0779 smmd=0.5186 ct=11.5212 rec=1.2980 | train/val/test=1.000/0.738/0.747 | c=0.998437
[Epoch 0073] loss=13.3978 cls=0.1120 smmd=0.4793 ct=11.4845 rec=1.3181 | train/val/test=1.000/0.730/0.727 | c=0.998437
[Epoch 0074] loss=13.5199 cls=0.1241 smmd=0.5165 ct=11.5006 rec=1.3319 | train/val/test=1.000/0.744/0.745 | c=0.998437
[Epoch 0075] loss=14.1876 cls=0.1391 smmd=0.7686 ct=11.5294 rec=1.3342 | train/val/test=1.000/0.736/0.722 | c=0.998437
[Epoch 0076] loss=13.9893 cls=0.1675 smmd=0.6929 ct=11.4995 rec=1.3473 | train/val/test=1.000/0.770/0.771 | c=0.998437
[Epoch 0077] loss=13.7920 cls=0.1454 smmd=0.6398 ct=11.4533 rec=1.3330 | train/val/test=1.000/0.676/0.667 | c=0.998437
[Epoch 0078] loss=13.5867 cls=0.1684 smmd=0.5022 ct=11.5727 rec=1.3489 | train/val/test=1.000/0.782/0.770 | c=0.998437
[Epoch 0079] loss=13.4249 cls=0.1115 smmd=0.5110 ct=11.4323 rec=1.3186 | train/val/test=1.000/0.730/0.721 | c=0.998437
[Epoch 0080] loss=13.3578 cls=0.0848 smmd=0.4887 ct=11.4370 rec=1.3130 | train/val/test=1.000/0.744/0.745 | c=0.998437
[Epoch 0081] loss=13.0933 cls=0.0903 smmd=0.3725 ct=11.4629 rec=1.3082 | train/val/test=1.000/0.732/0.737 | c=0.998437
[Epoch 0082] loss=13.3211 cls=0.0927 smmd=0.4637 ct=11.4584 rec=1.3141 | train/val/test=1.000/0.718/0.706 | c=0.998437
[Epoch 0083] loss=13.4509 cls=0.1018 smmd=0.4967 ct=11.4965 rec=1.3236 | train/val/test=1.000/0.764/0.754 | c=0.998437
[Epoch 0084] loss=14.2010 cls=0.1655 smmd=0.7715 ct=11.5209 rec=1.3375 | train/val/test=1.000/0.626/0.605 | c=0.998437
[Epoch 0085] loss=14.4764 cls=0.1490 smmd=0.8259 ct=11.6575 rec=1.3593 | train/val/test=1.000/0.754/0.741 | c=0.998437
[Epoch 0086] loss=13.6879 cls=0.1252 smmd=0.5938 ct=11.4790 rec=1.3233 | train/val/test=1.000/0.726/0.718 | c=0.998437
[Epoch 0087] loss=13.3545 cls=0.0558 smmd=0.4852 ct=11.4683 rec=1.2906 | train/val/test=1.000/0.714/0.709 | c=0.998437
[Epoch 0088] loss=13.1693 cls=0.0535 smmd=0.4102 ct=11.4735 rec=1.2873 | train/val/test=1.000/0.746/0.741 | c=0.998437
[Epoch 0089] loss=13.1676 cls=0.0532 smmd=0.4220 ct=11.4410 rec=1.2898 | train/val/test=1.000/0.754/0.738 | c=0.998437
[Epoch 0090] loss=13.2008 cls=0.0610 smmd=0.4286 ct=11.4519 rec=1.2936 | train/val/test=1.000/0.750/0.733 | c=0.998437
[Epoch 0091] loss=13.1903 cls=0.0860 smmd=0.4081 ct=11.4728 rec=1.3086 | train/val/test=1.000/0.748/0.743 | c=0.998437
[Epoch 0092] loss=13.5878 cls=0.1258 smmd=0.5439 ct=11.5006 rec=1.3289 | train/val/test=1.000/0.780/0.768 | c=0.998437
[Epoch 0093] loss=14.1598 cls=0.1500 smmd=0.7682 ct=11.4975 rec=1.3335 | train/val/test=0.923/0.640/0.629 | c=0.998437
[Epoch 0094] loss=14.3394 cls=0.2550 smmd=0.7854 ct=11.5574 rec=1.3818 | train/val/test=0.923/0.570/0.565 | c=0.998437
[Epoch 0095] loss=14.4794 cls=0.3281 smmd=0.8037 ct=11.6038 rec=1.4046 | train/val/test=0.923/0.662/0.657 | c=0.998437
[Epoch 0096] loss=14.2322 cls=0.1696 smmd=0.7483 ct=11.6035 rec=1.3461 | train/val/test=1.000/0.714/0.725 | c=0.998437
[Epoch 0097] loss=13.4111 cls=0.0520 smmd=0.5064 ct=11.4756 rec=1.2867 | train/val/test=1.000/0.626/0.655 | c=0.998437
[Epoch 0098] loss=14.0816 cls=0.1445 smmd=0.7107 ct=11.5421 rec=1.3808 | train/val/test=1.000/0.728/0.724 | c=0.998437
[Epoch 0099] loss=13.3697 cls=0.0289 smmd=0.5084 ct=11.4463 rec=1.2760 | train/val/test=1.000/0.708/0.712 | c=0.998437
=== Best @ epoch 78: val=0.7820, test=0.7700 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-1 completed in 139.82 seconds.
==================================================
