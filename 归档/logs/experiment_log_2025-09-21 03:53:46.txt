Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1 - 2025-09-21 03:53:46:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=40.0044 cls=1.0976 smmd=5.6057 ct=11.2856 rec=1.4136 | train/val/test=0.346/0.196/0.180 | c=0.998437
[Epoch 0001] loss=30.2862 cls=1.0807 smmd=3.6721 ct=11.2439 rec=1.4139 | train/val/test=0.692/0.490/0.486 | c=0.998437
[Epoch 0002] loss=35.1670 cls=1.0518 smmd=4.6470 ct=11.2648 rec=1.4138 | train/val/test=0.577/0.366/0.358 | c=0.998437
[Epoch 0003] loss=34.0982 cls=0.9822 smmd=4.4484 ct=11.2238 rec=1.4133 | train/val/test=0.577/0.476/0.469 | c=0.998437
[Epoch 0004] loss=24.4698 cls=0.8734 smmd=2.5689 ct=11.0474 rec=1.4103 | train/val/test=0.731/0.570/0.531 | c=0.998437
[Epoch 0005] loss=26.6112 cls=0.7552 smmd=3.0083 ct=11.0516 rec=1.4034 | train/val/test=0.731/0.588/0.596 | c=0.998437
[Epoch 0006] loss=28.6564 cls=0.6786 smmd=3.4319 ct=11.0181 rec=1.3937 | train/val/test=0.769/0.634/0.630 | c=0.998437
[Epoch 0007] loss=26.2177 cls=0.5939 smmd=2.9690 ct=10.9375 rec=1.3813 | train/val/test=0.885/0.718/0.687 | c=0.998437
[Epoch 0008] loss=21.4994 cls=0.4833 smmd=2.0453 ct=10.8947 rec=1.3664 | train/val/test=0.962/0.734/0.713 | c=0.998437
[Epoch 0009] loss=22.3463 cls=0.4151 smmd=2.2250 ct=10.8777 rec=1.3594 | train/val/test=1.000/0.736/0.718 | c=0.998437
[Epoch 0010] loss=24.2922 cls=0.3566 smmd=2.6166 ct=10.8956 rec=1.3558 | train/val/test=1.000/0.748/0.723 | c=0.998437
[Epoch 0011] loss=22.1674 cls=0.2972 smmd=2.2003 ct=10.8819 rec=1.3535 | train/val/test=1.000/0.752/0.735 | c=0.998437
[Epoch 0012] loss=19.7861 cls=0.2487 smmd=1.7311 ct=10.8711 rec=1.3507 | train/val/test=1.000/0.782/0.754 | c=0.998437
[Epoch 0013] loss=22.1970 cls=0.2115 smmd=2.2174 ct=10.8699 rec=1.3442 | train/val/test=1.000/0.758/0.730 | c=0.998437
[Epoch 0014] loss=21.5676 cls=0.1728 smmd=2.0963 ct=10.8662 rec=1.3341 | train/val/test=1.000/0.770/0.754 | c=0.998437
[Epoch 0015] loss=18.6218 cls=0.1282 smmd=1.5172 ct=10.8402 rec=1.3156 | train/val/test=1.000/0.784/0.761 | c=0.998437
[Epoch 0016] loss=19.3047 cls=0.1155 smmd=1.6577 ct=10.8275 rec=1.3085 | train/val/test=1.000/0.768/0.749 | c=0.998437
[Epoch 0017] loss=19.6674 cls=0.1102 smmd=1.7321 ct=10.8214 rec=1.3053 | train/val/test=1.000/0.778/0.757 | c=0.998437
[Epoch 0018] loss=17.9691 cls=0.0773 smmd=1.3956 ct=10.8229 rec=1.2970 | train/val/test=1.000/0.790/0.752 | c=0.998437
[Epoch 0019] loss=17.3838 cls=0.0717 smmd=1.2802 ct=10.8172 rec=1.2994 | train/val/test=1.000/0.794/0.761 | c=0.998437
[Epoch 0020] loss=18.0746 cls=0.0776 smmd=1.4159 ct=10.8262 rec=1.3029 | train/val/test=1.000/0.792/0.755 | c=0.998437
[Epoch 0021] loss=17.1970 cls=0.0806 smmd=1.2370 ct=10.8413 rec=1.3031 | train/val/test=1.000/0.800/0.755 | c=0.998437
[Epoch 0022] loss=17.0960 cls=0.0864 smmd=1.2131 ct=10.8568 rec=1.3061 | train/val/test=1.000/0.792/0.754 | c=0.998437
[Epoch 0023] loss=17.2926 cls=0.0956 smmd=1.2515 ct=10.8565 rec=1.3100 | train/val/test=1.000/0.784/0.743 | c=0.998437
[Epoch 0024] loss=16.7733 cls=0.0965 smmd=1.1492 ct=10.8486 rec=1.3049 | train/val/test=1.000/0.802/0.758 | c=0.998437
[Epoch 0025] loss=16.0301 cls=0.0832 smmd=1.0016 ct=10.8506 rec=1.3019 | train/val/test=1.000/0.790/0.750 | c=0.998437
[Epoch 0026] loss=16.3427 cls=0.0814 smmd=1.0676 ct=10.8342 rec=1.3010 | train/val/test=1.000/0.780/0.752 | c=0.998437
[Epoch 0027] loss=15.5040 cls=0.0765 smmd=0.9006 ct=10.8337 rec=1.2924 | train/val/test=1.000/0.804/0.763 | c=0.998437
[Epoch 0028] loss=15.4604 cls=0.0668 smmd=0.8928 ct=10.8336 rec=1.2939 | train/val/test=1.000/0.798/0.755 | c=0.998437
[Epoch 0029] loss=15.0791 cls=0.0681 smmd=0.8182 ct=10.8246 rec=1.2970 | train/val/test=1.000/0.786/0.758 | c=0.998437
[Epoch 0030] loss=15.1188 cls=0.0761 smmd=0.8228 ct=10.8374 rec=1.2956 | train/val/test=1.000/0.790/0.745 | c=0.998437
[Epoch 0031] loss=15.2053 cls=0.0806 smmd=0.8355 ct=10.8568 rec=1.3079 | train/val/test=1.000/0.790/0.750 | c=0.998437
[Epoch 0032] loss=15.1539 cls=0.0794 smmd=0.8254 ct=10.8569 rec=1.3030 | train/val/test=1.000/0.796/0.750 | c=0.998437
[Epoch 0033] loss=15.4025 cls=0.0841 smmd=0.8747 ct=10.8566 rec=1.3037 | train/val/test=1.000/0.802/0.750 | c=0.998437
[Epoch 0034] loss=14.7255 cls=0.0751 smmd=0.7415 ct=10.8499 rec=1.3051 | train/val/test=1.000/0.792/0.755 | c=0.998437
[Epoch 0035] loss=14.7015 cls=0.0701 smmd=0.7389 ct=10.8420 rec=1.2973 | train/val/test=1.000/0.786/0.743 | c=0.998437
[Epoch 0036] loss=14.6139 cls=0.0674 smmd=0.7227 ct=10.8361 rec=1.3056 | train/val/test=1.000/0.798/0.758 | c=0.998437
[Epoch 0037] loss=13.9715 cls=0.0631 smmd=0.5967 ct=10.8270 rec=1.2943 | train/val/test=1.000/0.804/0.757 | c=0.998437
[Epoch 0038] loss=14.1289 cls=0.0645 smmd=0.6275 ct=10.8296 rec=1.2960 | train/val/test=1.000/0.800/0.745 | c=0.998437
[Epoch 0039] loss=14.0480 cls=0.0715 smmd=0.6085 ct=10.8393 rec=1.3046 | train/val/test=1.000/0.790/0.759 | c=0.998437
[Epoch 0040] loss=13.8450 cls=0.0807 smmd=0.5666 ct=10.8414 rec=1.3030 | train/val/test=1.000/0.790/0.747 | c=0.998437
[Epoch 0041] loss=14.3456 cls=0.0906 smmd=0.6615 ct=10.8616 rec=1.3106 | train/val/test=1.000/0.800/0.765 | c=0.998437
[Epoch 0042] loss=15.0370 cls=0.0941 smmd=0.6618 ct=11.5496 rec=1.3114 | train/val/test=1.000/0.772/0.742 | c=0.998437
[Epoch 0043] loss=15.1540 cls=0.1058 smmd=0.7023 ct=11.4577 rec=1.3206 | train/val/test=1.000/0.778/0.755 | c=0.998437
[Epoch 0044] loss=14.7814 cls=0.1037 smmd=0.6017 ct=11.5903 rec=1.3082 | train/val/test=1.000/0.746/0.722 | c=0.998437
[Epoch 0045] loss=14.4885 cls=0.1024 smmd=0.5667 ct=11.4712 rec=1.3260 | train/val/test=1.000/0.784/0.757 | c=0.998437
[Epoch 0046] loss=14.4543 cls=0.0894 smmd=0.5545 ct=11.5069 rec=1.3007 | train/val/test=1.000/0.794/0.746 | c=0.998437
[Epoch 0047] loss=14.0187 cls=0.0820 smmd=0.4691 ct=11.5014 rec=1.3075 | train/val/test=1.000/0.804/0.752 | c=0.998437
[Epoch 0048] loss=14.2258 cls=0.0854 smmd=0.5150 ct=11.4775 rec=1.3062 | train/val/test=1.000/0.794/0.739 | c=0.998437
[Epoch 0049] loss=14.1612 cls=0.0907 smmd=0.4959 ct=11.5054 rec=1.3111 | train/val/test=1.000/0.784/0.760 | c=0.998437
[Epoch 0050] loss=14.4451 cls=0.1037 smmd=0.5492 ct=11.5159 rec=1.3119 | train/val/test=1.000/0.746/0.713 | c=0.998437
[Epoch 0051] loss=14.8767 cls=0.1186 smmd=0.6381 ct=11.4935 rec=1.3337 | train/val/test=1.000/0.764/0.737 | c=0.998437
[Epoch 0052] loss=14.5720 cls=0.1267 smmd=0.5623 ct=11.5652 rec=1.3214 | train/val/test=1.000/0.730/0.701 | c=0.998437
[Epoch 0053] loss=14.4351 cls=0.1158 smmd=0.5550 ct=11.4686 rec=1.3364 | train/val/test=1.000/0.770/0.740 | c=0.998437
[Epoch 0054] loss=14.3374 cls=0.1067 smmd=0.5237 ct=11.5345 rec=1.3119 | train/val/test=1.000/0.770/0.729 | c=0.998437
[Epoch 0055] loss=13.8425 cls=0.0865 smmd=0.4417 ct=11.4591 rec=1.3174 | train/val/test=1.000/0.782/0.759 | c=0.998437
[Epoch 0056] loss=13.8374 cls=0.0842 smmd=0.4346 ct=11.4919 rec=1.3048 | train/val/test=1.000/0.770/0.738 | c=0.998437
[Epoch 0057] loss=13.9303 cls=0.0861 smmd=0.4548 ct=11.4819 rec=1.3139 | train/val/test=1.000/0.780/0.761 | c=0.998437
[Epoch 0058] loss=13.8808 cls=0.0951 smmd=0.4422 ct=11.4910 rec=1.3115 | train/val/test=1.000/0.754/0.729 | c=0.998437
[Epoch 0059] loss=14.2962 cls=0.1064 smmd=0.5241 ct=11.4899 rec=1.3276 | train/val/test=1.000/0.750/0.732 | c=0.998437
[Epoch 0060] loss=14.7279 cls=0.1254 smmd=0.5990 ct=11.5374 rec=1.3258 | train/val/test=1.000/0.714/0.682 | c=0.998437
[Epoch 0061] loss=14.5410 cls=0.1336 smmd=0.5678 ct=11.5009 rec=1.3443 | train/val/test=1.000/0.732/0.720 | c=0.998437
[Epoch 0062] loss=14.3124 cls=0.1420 smmd=0.5099 ct=11.5588 rec=1.3325 | train/val/test=1.000/0.696/0.668 | c=0.998437
[Epoch 0063] loss=14.1814 cls=0.1257 smmd=0.5036 ct=11.4663 rec=1.3435 | train/val/test=1.000/0.758/0.734 | c=0.998437
[Epoch 0064] loss=13.8212 cls=0.0965 smmd=0.4236 ct=11.5238 rec=1.3103 | train/val/test=1.000/0.772/0.727 | c=0.998437
[Epoch 0065] loss=13.7411 cls=0.0771 smmd=0.4262 ct=11.4404 rec=1.3137 | train/val/test=1.000/0.794/0.754 | c=0.998437
[Epoch 0066] loss=13.6821 cls=0.0747 smmd=0.4078 ct=11.4751 rec=1.3052 | train/val/test=1.000/0.796/0.751 | c=0.998437
[Epoch 0067] loss=13.7790 cls=0.0808 smmd=0.4238 ct=11.4883 rec=1.3121 | train/val/test=1.000/0.788/0.746 | c=0.998437
[Epoch 0068] loss=14.0695 cls=0.0916 smmd=0.4820 ct=11.4820 rec=1.3149 | train/val/test=1.000/0.776/0.731 | c=0.998437
[Epoch 0069] loss=14.5161 cls=0.1020 smmd=0.5665 ct=11.5004 rec=1.3250 | train/val/test=1.000/0.772/0.746 | c=0.998437
[Epoch 0070] loss=14.6808 cls=0.1056 smmd=0.5944 ct=11.5240 rec=1.3208 | train/val/test=1.000/0.742/0.717 | c=0.998437
[Epoch 0071] loss=14.2626 cls=0.1035 smmd=0.5218 ct=11.4692 rec=1.3258 | train/val/test=1.000/0.778/0.740 | c=0.998437
[Epoch 0072] loss=13.9003 cls=0.0970 smmd=0.4414 ct=11.5133 rec=1.3142 | train/val/test=1.000/0.742/0.713 | c=0.998437
[Epoch 0073] loss=13.5545 cls=0.0978 smmd=0.3859 ct=11.4440 rec=1.3233 | train/val/test=1.000/0.780/0.745 | c=0.998437
[Epoch 0074] loss=13.5762 cls=0.0962 smmd=0.3823 ct=11.4854 rec=1.3112 | train/val/test=1.000/0.758/0.727 | c=0.998437
[Epoch 0075] loss=13.5636 cls=0.0977 smmd=0.3828 ct=11.4687 rec=1.3227 | train/val/test=1.000/0.780/0.749 | c=0.998437
[Epoch 0076] loss=13.6106 cls=0.1063 smmd=0.3873 ct=11.4892 rec=1.3171 | train/val/test=1.000/0.736/0.701 | c=0.998437
[Epoch 0077] loss=14.0893 cls=0.1244 smmd=0.4826 ct=11.4804 rec=1.3375 | train/val/test=1.000/0.698/0.684 | c=0.998437
[Epoch 0078] loss=14.8596 cls=0.1915 smmd=0.6023 ct=11.6170 rec=1.3552 | train/val/test=0.923/0.570/0.575 | c=0.998437
[Epoch 0079] loss=15.0887 cls=0.2514 smmd=0.6612 ct=11.5187 rec=1.3837 | train/val/test=0.885/0.644/0.640 | c=0.998437
[Epoch 0080] loss=14.6334 cls=0.2697 smmd=0.5391 ct=11.6648 rec=1.3843 | train/val/test=1.000/0.684/0.660 | c=0.998437
[Epoch 0081] loss=13.8185 cls=0.1011 smmd=0.4330 ct=11.4689 rec=1.3388 | train/val/test=1.000/0.804/0.762 | c=0.998437
[Epoch 0082] loss=13.6680 cls=0.0494 smmd=0.4157 ct=11.4353 rec=1.2942 | train/val/test=1.000/0.764/0.744 | c=0.998437
[Epoch 0083] loss=13.4403 cls=0.0634 smmd=0.3550 ct=11.5043 rec=1.2948 | train/val/test=1.000/0.762/0.721 | c=0.998437
[Epoch 0084] loss=13.1878 cls=0.0572 smmd=0.3127 ct=11.4649 rec=1.3098 | train/val/test=1.000/0.802/0.752 | c=0.998437
[Epoch 0085] loss=13.7428 cls=0.0586 smmd=0.4266 ct=11.4497 rec=1.3053 | train/val/test=1.000/0.794/0.757 | c=0.998437
[Epoch 0086] loss=14.0194 cls=0.0746 smmd=0.4632 ct=11.5345 rec=1.3131 | train/val/test=1.000/0.790/0.740 | c=0.998437
[Epoch 0087] loss=14.2975 cls=0.0921 smmd=0.5226 ct=11.5060 rec=1.3263 | train/val/test=1.000/0.740/0.713 | c=0.998437
[Epoch 0088] loss=15.4011 cls=0.1192 smmd=0.7423 ct=11.4952 rec=1.3450 | train/val/test=1.000/0.724/0.701 | c=0.998437
[Epoch 0089] loss=14.8391 cls=0.1353 smmd=0.6063 ct=11.6050 rec=1.3476 | train/val/test=1.000/0.634/0.623 | c=0.998437
[Epoch 0090] loss=13.9713 cls=0.1639 smmd=0.4580 ct=11.4639 rec=1.3547 | train/val/test=1.000/0.770/0.744 | c=0.998437
[Epoch 0091] loss=13.7533 cls=0.0965 smmd=0.4144 ct=11.5005 rec=1.3263 | train/val/test=1.000/0.780/0.735 | c=0.998437
[Epoch 0092] loss=13.2917 cls=0.0894 smmd=0.3351 ct=11.4392 rec=1.3205 | train/val/test=1.000/0.754/0.714 | c=0.998437
[Epoch 0093] loss=13.4689 cls=0.0996 smmd=0.3700 ct=11.4365 rec=1.3262 | train/val/test=1.000/0.778/0.749 | c=0.998437
[Epoch 0094] loss=13.4084 cls=0.1125 smmd=0.3444 ct=11.4976 rec=1.3263 | train/val/test=1.000/0.700/0.672 | c=0.998437
[Epoch 0095] loss=13.6491 cls=0.1470 smmd=0.3926 ct=11.4777 rec=1.3484 | train/val/test=1.000/0.704/0.695 | c=0.998437
[Epoch 0096] loss=14.8223 cls=0.1998 smmd=0.5964 ct=11.6048 rec=1.3583 | train/val/test=1.000/0.574/0.577 | c=0.998437
[Epoch 0097] loss=15.5430 cls=0.2289 smmd=0.7462 ct=11.5590 rec=1.3828 | train/val/test=0.846/0.660/0.653 | c=0.998437
[Epoch 0098] loss=15.2094 cls=0.2780 smmd=0.6573 ct=11.6461 rec=1.3811 | train/val/test=1.000/0.676/0.658 | c=0.998437
[Epoch 0099] loss=14.1871 cls=0.1167 smmd=0.5010 ct=11.4889 rec=1.3495 | train/val/test=1.000/0.800/0.774 | c=0.998437
=== Best @ epoch 27: val=0.8040, test=0.7630 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1 - 2025-09-21 03:53:46:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=26, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=40.0044 cls=1.0976 smmd=5.6057 ct=11.2856 rec=1.4136 | train/val/test=0.346/0.196/0.180 | c=0.998437
[Epoch 0001] loss=30.2862 cls=1.0807 smmd=3.6721 ct=11.2439 rec=1.4139 | train/val/test=0.692/0.490/0.486 | c=0.998437
[Epoch 0002] loss=35.1670 cls=1.0518 smmd=4.6470 ct=11.2648 rec=1.4138 | train/val/test=0.577/0.366/0.358 | c=0.998437
[Epoch 0003] loss=34.0982 cls=0.9822 smmd=4.4484 ct=11.2238 rec=1.4133 | train/val/test=0.577/0.476/0.469 | c=0.998437
[Epoch 0004] loss=24.4698 cls=0.8734 smmd=2.5689 ct=11.0474 rec=1.4103 | train/val/test=0.731/0.570/0.531 | c=0.998437
[Epoch 0005] loss=26.6112 cls=0.7552 smmd=3.0083 ct=11.0516 rec=1.4034 | train/val/test=0.731/0.588/0.596 | c=0.998437
[Epoch 0006] loss=28.6564 cls=0.6786 smmd=3.4319 ct=11.0181 rec=1.3937 | train/val/test=0.769/0.634/0.630 | c=0.998437
[Epoch 0007] loss=26.2177 cls=0.5939 smmd=2.9690 ct=10.9375 rec=1.3813 | train/val/test=0.885/0.718/0.687 | c=0.998437
[Epoch 0008] loss=21.4994 cls=0.4833 smmd=2.0453 ct=10.8947 rec=1.3664 | train/val/test=0.962/0.734/0.713 | c=0.998437
[Epoch 0009] loss=22.3463 cls=0.4151 smmd=2.2250 ct=10.8777 rec=1.3594 | train/val/test=1.000/0.736/0.718 | c=0.998437
[Epoch 0010] loss=24.2922 cls=0.3566 smmd=2.6166 ct=10.8956 rec=1.3558 | train/val/test=1.000/0.748/0.723 | c=0.998437
[Epoch 0011] loss=22.1674 cls=0.2972 smmd=2.2003 ct=10.8819 rec=1.3535 | train/val/test=1.000/0.752/0.735 | c=0.998437
[Epoch 0012] loss=19.7861 cls=0.2487 smmd=1.7311 ct=10.8711 rec=1.3507 | train/val/test=1.000/0.782/0.754 | c=0.998437
[Epoch 0013] loss=22.1970 cls=0.2115 smmd=2.2174 ct=10.8699 rec=1.3442 | train/val/test=1.000/0.758/0.730 | c=0.998437
[Epoch 0014] loss=21.5676 cls=0.1728 smmd=2.0963 ct=10.8662 rec=1.3341 | train/val/test=1.000/0.770/0.754 | c=0.998437
[Epoch 0015] loss=18.6218 cls=0.1282 smmd=1.5172 ct=10.8402 rec=1.3156 | train/val/test=1.000/0.784/0.761 | c=0.998437
[Epoch 0016] loss=19.3047 cls=0.1155 smmd=1.6577 ct=10.8275 rec=1.3085 | train/val/test=1.000/0.768/0.749 | c=0.998437
[Epoch 0017] loss=19.6674 cls=0.1102 smmd=1.7321 ct=10.8214 rec=1.3053 | train/val/test=1.000/0.778/0.757 | c=0.998437
[Epoch 0018] loss=17.9691 cls=0.0773 smmd=1.3956 ct=10.8229 rec=1.2970 | train/val/test=1.000/0.790/0.752 | c=0.998437
[Epoch 0019] loss=17.3838 cls=0.0717 smmd=1.2802 ct=10.8172 rec=1.2994 | train/val/test=1.000/0.794/0.761 | c=0.998437
[Epoch 0020] loss=18.0746 cls=0.0776 smmd=1.4159 ct=10.8262 rec=1.3029 | train/val/test=1.000/0.792/0.755 | c=0.998437
[Epoch 0021] loss=17.1970 cls=0.0806 smmd=1.2370 ct=10.8413 rec=1.3031 | train/val/test=1.000/0.800/0.755 | c=0.998437
[Epoch 0022] loss=17.0960 cls=0.0864 smmd=1.2131 ct=10.8568 rec=1.3061 | train/val/test=1.000/0.792/0.754 | c=0.998437
[Epoch 0023] loss=17.2926 cls=0.0956 smmd=1.2515 ct=10.8565 rec=1.3100 | train/val/test=1.000/0.784/0.743 | c=0.998437
[Epoch 0024] loss=16.7733 cls=0.0965 smmd=1.1492 ct=10.8486 rec=1.3049 | train/val/test=1.000/0.802/0.758 | c=0.998437
[Epoch 0025] loss=16.0301 cls=0.0832 smmd=1.0016 ct=10.8506 rec=1.3019 | train/val/test=1.000/0.790/0.750 | c=0.998437
[Epoch 0026] loss=16.3427 cls=0.0814 smmd=1.0676 ct=10.8342 rec=1.3010 | train/val/test=1.000/0.780/0.752 | c=0.998437
[Epoch 0027] loss=15.5040 cls=0.0765 smmd=0.9006 ct=10.8337 rec=1.2924 | train/val/test=1.000/0.804/0.763 | c=0.998437
[Epoch 0028] loss=15.4604 cls=0.0668 smmd=0.8928 ct=10.8336 rec=1.2939 | train/val/test=1.000/0.798/0.755 | c=0.998437
[Epoch 0029] loss=15.0791 cls=0.0681 smmd=0.8182 ct=10.8246 rec=1.2970 | train/val/test=1.000/0.786/0.758 | c=0.998437
[Epoch 0030] loss=15.1188 cls=0.0761 smmd=0.8228 ct=10.8374 rec=1.2956 | train/val/test=1.000/0.790/0.745 | c=0.998437
[Epoch 0031] loss=15.2053 cls=0.0806 smmd=0.8355 ct=10.8568 rec=1.3079 | train/val/test=1.000/0.790/0.750 | c=0.998437
[Epoch 0032] loss=15.1539 cls=0.0794 smmd=0.8254 ct=10.8569 rec=1.3030 | train/val/test=1.000/0.796/0.750 | c=0.998437
[Epoch 0033] loss=15.4025 cls=0.0841 smmd=0.8747 ct=10.8566 rec=1.3037 | train/val/test=1.000/0.802/0.750 | c=0.998437
[Epoch 0034] loss=14.7255 cls=0.0751 smmd=0.7415 ct=10.8499 rec=1.3051 | train/val/test=1.000/0.792/0.755 | c=0.998437
[Epoch 0035] loss=14.7015 cls=0.0701 smmd=0.7389 ct=10.8420 rec=1.2973 | train/val/test=1.000/0.786/0.743 | c=0.998437
[Epoch 0036] loss=14.6139 cls=0.0674 smmd=0.7227 ct=10.8361 rec=1.3056 | train/val/test=1.000/0.798/0.758 | c=0.998437
[Epoch 0037] loss=13.9715 cls=0.0631 smmd=0.5967 ct=10.8270 rec=1.2943 | train/val/test=1.000/0.804/0.757 | c=0.998437
[Epoch 0038] loss=14.1289 cls=0.0645 smmd=0.6275 ct=10.8296 rec=1.2960 | train/val/test=1.000/0.800/0.745 | c=0.998437
[Epoch 0039] loss=14.0480 cls=0.0715 smmd=0.6085 ct=10.8393 rec=1.3046 | train/val/test=1.000/0.790/0.759 | c=0.998437
[Epoch 0040] loss=13.8450 cls=0.0807 smmd=0.5666 ct=10.8414 rec=1.3030 | train/val/test=1.000/0.790/0.747 | c=0.998437
[Epoch 0041] loss=14.3456 cls=0.0906 smmd=0.6615 ct=10.8616 rec=1.3106 | train/val/test=1.000/0.800/0.765 | c=0.998437
[Epoch 0042] loss=15.0370 cls=0.0941 smmd=0.6618 ct=11.5496 rec=1.3114 | train/val/test=1.000/0.772/0.742 | c=0.998437
[Epoch 0043] loss=15.1540 cls=0.1058 smmd=0.7023 ct=11.4577 rec=1.3206 | train/val/test=1.000/0.778/0.755 | c=0.998437
[Epoch 0044] loss=14.7814 cls=0.1037 smmd=0.6017 ct=11.5903 rec=1.3082 | train/val/test=1.000/0.746/0.722 | c=0.998437
[Epoch 0045] loss=14.4885 cls=0.1024 smmd=0.5667 ct=11.4712 rec=1.3260 | train/val/test=1.000/0.784/0.757 | c=0.998437
[Epoch 0046] loss=14.4543 cls=0.0894 smmd=0.5545 ct=11.5069 rec=1.3007 | train/val/test=1.000/0.794/0.746 | c=0.998437
[Epoch 0047] loss=14.0187 cls=0.0820 smmd=0.4691 ct=11.5014 rec=1.3075 | train/val/test=1.000/0.804/0.752 | c=0.998437
[Epoch 0048] loss=14.2258 cls=0.0854 smmd=0.5150 ct=11.4775 rec=1.3062 | train/val/test=1.000/0.794/0.739 | c=0.998437
[Epoch 0049] loss=14.1612 cls=0.0907 smmd=0.4959 ct=11.5054 rec=1.3111 | train/val/test=1.000/0.784/0.760 | c=0.998437
[Epoch 0050] loss=14.4451 cls=0.1037 smmd=0.5492 ct=11.5159 rec=1.3119 | train/val/test=1.000/0.746/0.713 | c=0.998437
[Epoch 0051] loss=14.8767 cls=0.1186 smmd=0.6381 ct=11.4935 rec=1.3337 | train/val/test=1.000/0.764/0.737 | c=0.998437
[Epoch 0052] loss=14.5720 cls=0.1267 smmd=0.5623 ct=11.5652 rec=1.3214 | train/val/test=1.000/0.730/0.701 | c=0.998437
[Epoch 0053] loss=14.4351 cls=0.1158 smmd=0.5550 ct=11.4686 rec=1.3364 | train/val/test=1.000/0.770/0.740 | c=0.998437
[Epoch 0054] loss=14.3374 cls=0.1067 smmd=0.5237 ct=11.5345 rec=1.3119 | train/val/test=1.000/0.770/0.729 | c=0.998437
[Epoch 0055] loss=13.8425 cls=0.0865 smmd=0.4417 ct=11.4591 rec=1.3174 | train/val/test=1.000/0.782/0.759 | c=0.998437
[Epoch 0056] loss=13.8374 cls=0.0842 smmd=0.4346 ct=11.4919 rec=1.3048 | train/val/test=1.000/0.770/0.738 | c=0.998437
[Epoch 0057] loss=13.9303 cls=0.0861 smmd=0.4548 ct=11.4819 rec=1.3139 | train/val/test=1.000/0.780/0.761 | c=0.998437
[Epoch 0058] loss=13.8808 cls=0.0951 smmd=0.4422 ct=11.4910 rec=1.3115 | train/val/test=1.000/0.754/0.729 | c=0.998437
[Epoch 0059] loss=14.2962 cls=0.1064 smmd=0.5241 ct=11.4899 rec=1.3276 | train/val/test=1.000/0.750/0.732 | c=0.998437
[Epoch 0060] loss=14.7279 cls=0.1254 smmd=0.5990 ct=11.5374 rec=1.3258 | train/val/test=1.000/0.714/0.682 | c=0.998437
[Epoch 0061] loss=14.5410 cls=0.1336 smmd=0.5678 ct=11.5009 rec=1.3443 | train/val/test=1.000/0.732/0.720 | c=0.998437
[Epoch 0062] loss=14.3124 cls=0.1420 smmd=0.5099 ct=11.5588 rec=1.3325 | train/val/test=1.000/0.696/0.668 | c=0.998437
[Epoch 0063] loss=14.1814 cls=0.1257 smmd=0.5036 ct=11.4663 rec=1.3435 | train/val/test=1.000/0.758/0.734 | c=0.998437
[Epoch 0064] loss=13.8212 cls=0.0965 smmd=0.4236 ct=11.5238 rec=1.3103 | train/val/test=1.000/0.772/0.727 | c=0.998437
[Epoch 0065] loss=13.7411 cls=0.0771 smmd=0.4262 ct=11.4404 rec=1.3137 | train/val/test=1.000/0.794/0.754 | c=0.998437
[Epoch 0066] loss=13.6821 cls=0.0747 smmd=0.4078 ct=11.4751 rec=1.3052 | train/val/test=1.000/0.796/0.751 | c=0.998437
[Epoch 0067] loss=13.7790 cls=0.0808 smmd=0.4238 ct=11.4883 rec=1.3121 | train/val/test=1.000/0.788/0.746 | c=0.998437
[Epoch 0068] loss=14.0695 cls=0.0916 smmd=0.4820 ct=11.4820 rec=1.3149 | train/val/test=1.000/0.776/0.731 | c=0.998437
[Epoch 0069] loss=14.5161 cls=0.1020 smmd=0.5665 ct=11.5004 rec=1.3250 | train/val/test=1.000/0.772/0.746 | c=0.998437
[Epoch 0070] loss=14.6808 cls=0.1056 smmd=0.5944 ct=11.5240 rec=1.3208 | train/val/test=1.000/0.742/0.717 | c=0.998437
[Epoch 0071] loss=14.2626 cls=0.1035 smmd=0.5218 ct=11.4692 rec=1.3258 | train/val/test=1.000/0.778/0.740 | c=0.998437
[Epoch 0072] loss=13.9003 cls=0.0970 smmd=0.4414 ct=11.5133 rec=1.3142 | train/val/test=1.000/0.742/0.713 | c=0.998437
[Epoch 0073] loss=13.5545 cls=0.0978 smmd=0.3859 ct=11.4440 rec=1.3233 | train/val/test=1.000/0.780/0.745 | c=0.998437
[Epoch 0074] loss=13.5762 cls=0.0962 smmd=0.3823 ct=11.4854 rec=1.3112 | train/val/test=1.000/0.758/0.727 | c=0.998437
[Epoch 0075] loss=13.5636 cls=0.0977 smmd=0.3828 ct=11.4687 rec=1.3227 | train/val/test=1.000/0.780/0.749 | c=0.998437
[Epoch 0076] loss=13.6106 cls=0.1063 smmd=0.3873 ct=11.4892 rec=1.3171 | train/val/test=1.000/0.736/0.701 | c=0.998437
[Epoch 0077] loss=14.0893 cls=0.1244 smmd=0.4826 ct=11.4804 rec=1.3375 | train/val/test=1.000/0.698/0.684 | c=0.998437
[Epoch 0078] loss=14.8596 cls=0.1915 smmd=0.6023 ct=11.6170 rec=1.3552 | train/val/test=0.923/0.570/0.575 | c=0.998437
[Epoch 0079] loss=15.0887 cls=0.2514 smmd=0.6612 ct=11.5187 rec=1.3837 | train/val/test=0.885/0.644/0.640 | c=0.998437
[Epoch 0080] loss=14.6334 cls=0.2697 smmd=0.5391 ct=11.6648 rec=1.3843 | train/val/test=1.000/0.684/0.660 | c=0.998437
[Epoch 0081] loss=13.8185 cls=0.1011 smmd=0.4330 ct=11.4689 rec=1.3388 | train/val/test=1.000/0.804/0.762 | c=0.998437
[Epoch 0082] loss=13.6680 cls=0.0494 smmd=0.4157 ct=11.4353 rec=1.2942 | train/val/test=1.000/0.764/0.744 | c=0.998437
[Epoch 0083] loss=13.4403 cls=0.0634 smmd=0.3550 ct=11.5043 rec=1.2948 | train/val/test=1.000/0.762/0.721 | c=0.998437
[Epoch 0084] loss=13.1878 cls=0.0572 smmd=0.3127 ct=11.4649 rec=1.3098 | train/val/test=1.000/0.802/0.752 | c=0.998437
[Epoch 0085] loss=13.7428 cls=0.0586 smmd=0.4266 ct=11.4497 rec=1.3053 | train/val/test=1.000/0.794/0.757 | c=0.998437
[Epoch 0086] loss=14.0194 cls=0.0746 smmd=0.4632 ct=11.5345 rec=1.3131 | train/val/test=1.000/0.790/0.740 | c=0.998437
[Epoch 0087] loss=14.2975 cls=0.0921 smmd=0.5226 ct=11.5060 rec=1.3263 | train/val/test=1.000/0.740/0.713 | c=0.998437
[Epoch 0088] loss=15.4011 cls=0.1192 smmd=0.7423 ct=11.4952 rec=1.3450 | train/val/test=1.000/0.724/0.701 | c=0.998437
[Epoch 0089] loss=14.8391 cls=0.1353 smmd=0.6063 ct=11.6050 rec=1.3476 | train/val/test=1.000/0.634/0.623 | c=0.998437
[Epoch 0090] loss=13.9713 cls=0.1639 smmd=0.4580 ct=11.4639 rec=1.3547 | train/val/test=1.000/0.770/0.744 | c=0.998437
[Epoch 0091] loss=13.7533 cls=0.0965 smmd=0.4144 ct=11.5005 rec=1.3263 | train/val/test=1.000/0.780/0.735 | c=0.998437
[Epoch 0092] loss=13.2917 cls=0.0894 smmd=0.3351 ct=11.4392 rec=1.3205 | train/val/test=1.000/0.754/0.714 | c=0.998437
[Epoch 0093] loss=13.4689 cls=0.0996 smmd=0.3700 ct=11.4365 rec=1.3262 | train/val/test=1.000/0.778/0.749 | c=0.998437
[Epoch 0094] loss=13.4084 cls=0.1125 smmd=0.3444 ct=11.4976 rec=1.3263 | train/val/test=1.000/0.700/0.672 | c=0.998437
[Epoch 0095] loss=13.6491 cls=0.1470 smmd=0.3926 ct=11.4777 rec=1.3484 | train/val/test=1.000/0.704/0.695 | c=0.998437
[Epoch 0096] loss=14.8223 cls=0.1998 smmd=0.5964 ct=11.6048 rec=1.3583 | train/val/test=1.000/0.574/0.577 | c=0.998437
[Epoch 0097] loss=15.5430 cls=0.2289 smmd=0.7462 ct=11.5590 rec=1.3828 | train/val/test=0.846/0.660/0.653 | c=0.998437
[Epoch 0098] loss=15.2094 cls=0.2780 smmd=0.6573 ct=11.6461 rec=1.3811 | train/val/test=1.000/0.676/0.658 | c=0.998437
[Epoch 0099] loss=14.1871 cls=0.1167 smmd=0.5010 ct=11.4889 rec=1.3495 | train/val/test=1.000/0.800/0.774 | c=0.998437
=== Best @ epoch 27: val=0.8040, test=0.7630 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-10-1 completed in 140.54 seconds.
==================================================
