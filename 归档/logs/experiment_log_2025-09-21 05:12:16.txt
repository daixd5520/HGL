Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-1 - 2025-09-21 05:12:16:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-1...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.5482 cls=1.1082 smmd=5.6784 ct=7.2518 rec=1.4137 | train/val/test=0.391/0.383/0.390 | c=0.998347
[Epoch 0001] loss=53.1988 cls=1.0652 smmd=3.7544 ct=7.2075 rec=1.4150 | train/val/test=0.536/0.542/0.537 | c=0.998347
[Epoch 0002] loss=38.1833 cls=1.0751 smmd=2.2662 ct=7.1382 rec=1.4137 | train/val/test=0.575/0.574/0.585 | c=0.998347
[Epoch 0003] loss=41.1972 cls=1.0695 smmd=2.5699 ct=7.1285 rec=1.4135 | train/val/test=0.581/0.580/0.589 | c=0.998347
[Epoch 0004] loss=41.7765 cls=1.0315 smmd=2.5511 ct=7.5213 rec=1.4151 | train/val/test=0.467/0.458/0.479 | c=0.998347
[Epoch 0005] loss=37.1016 cls=1.0070 smmd=2.1288 ct=7.3003 rec=1.4186 | train/val/test=0.540/0.547/0.541 | c=0.998347
[Epoch 0006] loss=31.8284 cls=0.9871 smmd=1.5914 ct=7.3556 rec=1.4202 | train/val/test=0.558/0.566/0.552 | c=0.998347
[Epoch 0007] loss=35.0766 cls=0.9530 smmd=1.8906 ct=7.4929 rec=1.4169 | train/val/test=0.566/0.565/0.556 | c=0.998347
[Epoch 0008] loss=36.0107 cls=0.9188 smmd=1.9886 ct=7.4795 rec=1.4127 | train/val/test=0.569/0.570/0.559 | c=0.998347
[Epoch 0009] loss=29.5517 cls=0.8881 smmd=1.3611 ct=7.3958 rec=1.4091 | train/val/test=0.558/0.558/0.551 | c=0.998347
[Epoch 0010] loss=28.2548 cls=0.8652 smmd=1.2330 ct=7.3944 rec=1.4062 | train/val/test=0.613/0.611/0.602 | c=0.998347
[Epoch 0011] loss=30.7106 cls=0.8340 smmd=1.4801 ct=7.3959 rec=1.4006 | train/val/test=0.680/0.681/0.682 | c=0.998347
[Epoch 0012] loss=27.6184 cls=0.8094 smmd=1.1700 ct=7.4077 rec=1.3960 | train/val/test=0.667/0.661/0.661 | c=0.998347
[Epoch 0013] loss=26.5216 cls=0.7842 smmd=1.0443 ct=7.4949 rec=1.3925 | train/val/test=0.668/0.662/0.662 | c=0.998347
[Epoch 0014] loss=26.2718 cls=0.7630 smmd=1.0217 ct=7.4899 rec=1.3878 | train/val/test=0.722/0.724/0.723 | c=0.998347
[Epoch 0015] loss=25.2544 cls=0.7277 smmd=0.9425 ct=7.3884 rec=1.3779 | train/val/test=0.764/0.768/0.767 | c=0.998347
[Epoch 0016] loss=24.8851 cls=0.7012 smmd=0.9092 ct=7.3787 rec=1.3702 | train/val/test=0.767/0.770/0.772 | c=0.998347
[Epoch 0017] loss=23.8028 cls=0.6634 smmd=0.7948 ct=7.4211 rec=1.3623 | train/val/test=0.753/0.751/0.755 | c=0.998347
[Epoch 0018] loss=23.0360 cls=0.6374 smmd=0.7131 ct=7.4544 rec=1.3553 | train/val/test=0.785/0.784/0.788 | c=0.998347
[Epoch 0019] loss=22.8497 cls=0.6070 smmd=0.6995 ct=7.4390 rec=1.3464 | train/val/test=0.793/0.793/0.794 | c=0.998347
[Epoch 0020] loss=22.3324 cls=0.5949 smmd=0.6576 ct=7.3948 rec=1.3389 | train/val/test=0.793/0.788/0.795 | c=0.998347
[Epoch 0021] loss=21.3551 cls=0.5768 smmd=0.5649 ct=7.3758 rec=1.3320 | train/val/test=0.806/0.803/0.806 | c=0.998347
[Epoch 0022] loss=21.5910 cls=0.5514 smmd=0.5812 ct=7.4196 rec=1.3282 | train/val/test=0.813/0.805/0.815 | c=0.998347
[Epoch 0023] loss=20.9449 cls=0.5307 smmd=0.5172 ct=7.4226 rec=1.3255 | train/val/test=0.806/0.804/0.808 | c=0.998347
[Epoch 0024] loss=20.5280 cls=0.5210 smmd=0.4826 ct=7.3901 rec=1.3232 | train/val/test=0.819/0.811/0.817 | c=0.998347
[Epoch 0025] loss=20.3593 cls=0.5120 smmd=0.4630 ct=7.4065 rec=1.3195 | train/val/test=0.820/0.810/0.822 | c=0.998347
[Epoch 0026] loss=19.9506 cls=0.5193 smmd=0.4200 ct=7.4150 rec=1.3213 | train/val/test=0.827/0.820/0.830 | c=0.998347
[Epoch 0027] loss=19.9281 cls=0.4938 smmd=0.4229 ct=7.3966 rec=1.3186 | train/val/test=0.828/0.823/0.832 | c=0.998347
[Epoch 0028] loss=19.3520 cls=0.4824 smmd=0.3618 ct=7.4168 rec=1.3181 | train/val/test=0.826/0.821/0.832 | c=0.998347
[Epoch 0029] loss=19.4202 cls=0.4768 smmd=0.3723 ct=7.4002 rec=1.3163 | train/val/test=0.834/0.823/0.834 | c=0.998347
[Epoch 0030] loss=19.0740 cls=0.4747 smmd=0.3418 ct=7.3813 rec=1.3127 | train/val/test=0.837/0.830/0.839 | c=0.998347
[Epoch 0031] loss=18.8599 cls=0.4658 smmd=0.3174 ct=7.3982 rec=1.3137 | train/val/test=0.835/0.832/0.840 | c=0.998347
[Epoch 0032] loss=18.6486 cls=0.4570 smmd=0.2942 ct=7.4112 rec=1.3113 | train/val/test=0.836/0.832/0.840 | c=0.998347
[Epoch 0033] loss=18.4366 cls=0.4531 smmd=0.2809 ct=7.3730 rec=1.3106 | train/val/test=0.838/0.833/0.843 | c=0.998347
[Epoch 0034] loss=18.3114 cls=0.4515 smmd=0.2679 ct=7.3756 rec=1.3101 | train/val/test=0.838/0.834/0.841 | c=0.998347
[Epoch 0035] loss=18.1912 cls=0.4543 smmd=0.2522 ct=7.3937 rec=1.3094 | train/val/test=0.837/0.834/0.841 | c=0.998347
[Epoch 0036] loss=17.9531 cls=0.4517 smmd=0.2336 ct=7.3672 rec=1.3143 | train/val/test=0.840/0.838/0.842 | c=0.998347
[Epoch 0037] loss=17.9148 cls=0.4532 smmd=0.2267 ct=7.3821 rec=1.3139 | train/val/test=0.839/0.836/0.841 | c=0.998347
[Epoch 0038] loss=17.7412 cls=0.4559 smmd=0.2109 ct=7.3731 rec=1.3154 | train/val/test=0.838/0.838/0.841 | c=0.998347
[Epoch 0039] loss=17.7100 cls=0.4584 smmd=0.2093 ct=7.3641 rec=1.3186 | train/val/test=0.841/0.838/0.843 | c=0.998347
[Epoch 0040] loss=17.5948 cls=0.4625 smmd=0.1949 ct=7.3775 rec=1.3187 | train/val/test=0.840/0.836/0.844 | c=0.998347
[Epoch 0041] loss=17.5965 cls=0.4636 smmd=0.1988 ct=7.3574 rec=1.3242 | train/val/test=0.840/0.835/0.839 | c=0.998347
[Epoch 0042] loss=17.4161 cls=0.4703 smmd=0.1795 ct=7.3625 rec=1.3227 | train/val/test=0.843/0.838/0.846 | c=0.998347
[Epoch 0043] loss=17.3578 cls=0.4680 smmd=0.1752 ct=7.3547 rec=1.3254 | train/val/test=0.842/0.839/0.843 | c=0.998347
[Epoch 0044] loss=17.2118 cls=0.4708 smmd=0.1601 ct=7.3565 rec=1.3254 | train/val/test=0.842/0.838/0.843 | c=0.998347
[Epoch 0045] loss=17.2220 cls=0.4707 smmd=0.1624 ct=7.3495 rec=1.3266 | train/val/test=0.841/0.839/0.844 | c=0.998347
[Epoch 0046] loss=17.1234 cls=0.4717 smmd=0.1543 ct=7.3406 rec=1.3272 | train/val/test=0.843/0.838/0.843 | c=0.998347
[Epoch 0047] loss=17.0725 cls=0.4741 smmd=0.1471 ct=7.3503 rec=1.3267 | train/val/test=0.841/0.839/0.844 | c=0.998347
[Epoch 0048] loss=16.9969 cls=0.4725 smmd=0.1428 ct=7.3344 rec=1.3276 | train/val/test=0.841/0.840/0.844 | c=0.998347
[Epoch 0049] loss=16.9769 cls=0.4744 smmd=0.1392 ct=7.3422 rec=1.3272 | train/val/test=0.841/0.837/0.845 | c=0.998347
[Epoch 0050] loss=16.9616 cls=0.4746 smmd=0.1378 ct=7.3412 rec=1.3279 | train/val/test=0.840/0.837/0.843 | c=0.998347
[Epoch 0051] loss=16.9368 cls=0.4757 smmd=0.1371 ct=7.3323 rec=1.3273 | train/val/test=0.840/0.837/0.844 | c=0.998347
[Epoch 0052] loss=16.8967 cls=0.4744 smmd=0.1325 ct=7.3356 rec=1.3273 | train/val/test=0.840/0.835/0.845 | c=0.998347
[Epoch 0053] loss=16.8836 cls=0.4739 smmd=0.1324 ct=7.3297 rec=1.3271 | train/val/test=0.839/0.837/0.844 | c=0.998347
[Epoch 0054] loss=16.8520 cls=0.4754 smmd=0.1285 ct=7.3334 rec=1.3256 | train/val/test=0.839/0.835/0.843 | c=0.998347
[Epoch 0055] loss=16.8643 cls=0.4733 smmd=0.1309 ct=7.3277 rec=1.3263 | train/val/test=0.840/0.837/0.843 | c=0.998347
[Epoch 0056] loss=16.8113 cls=0.4751 smmd=0.1266 ct=7.3225 rec=1.3258 | train/val/test=0.839/0.833/0.843 | c=0.998347
[Epoch 0057] loss=16.7610 cls=0.4735 smmd=0.1207 ct=7.3272 rec=1.3264 | train/val/test=0.837/0.833/0.840 | c=0.998347
[Epoch 0058] loss=16.7860 cls=0.4803 smmd=0.1237 ct=7.3232 rec=1.3257 | train/val/test=0.838/0.832/0.843 | c=0.998347
[Epoch 0059] loss=16.8098 cls=0.4766 smmd=0.1266 ct=7.3206 rec=1.3281 | train/val/test=0.834/0.831/0.834 | c=0.998347
[Epoch 0060] loss=16.8211 cls=0.4867 smmd=0.1259 ct=7.3275 rec=1.3274 | train/val/test=0.835/0.830/0.838 | c=0.998347
[Epoch 0061] loss=16.7820 cls=0.4843 smmd=0.1225 ct=7.3245 rec=1.3310 | train/val/test=0.823/0.818/0.823 | c=0.998347
[Epoch 0062] loss=16.8769 cls=0.5066 smmd=0.1298 ct=7.3300 rec=1.3303 | train/val/test=0.817/0.809/0.816 | c=0.998347
[Epoch 0063] loss=17.1217 cls=0.5097 smmd=0.1540 ct=7.3283 rec=1.3407 | train/val/test=0.808/0.804/0.801 | c=0.998347
[Epoch 0064] loss=17.2535 cls=0.5397 smmd=0.1600 ct=7.3582 rec=1.3349 | train/val/test=0.813/0.807/0.812 | c=0.998347
[Epoch 0065] loss=17.1254 cls=0.5108 smmd=0.1555 ct=7.3227 rec=1.3395 | train/val/test=0.819/0.814/0.817 | c=0.998347
[Epoch 0066] loss=17.0116 cls=0.5038 smmd=0.1432 ct=7.3324 rec=1.3249 | train/val/test=0.836/0.831/0.836 | c=0.998347
[Epoch 0067] loss=16.8332 cls=0.4717 smmd=0.1318 ct=7.3092 rec=1.3215 | train/val/test=0.837/0.833/0.838 | c=0.998347
[Epoch 0068] loss=16.7408 cls=0.4706 smmd=0.1228 ct=7.3087 rec=1.3200 | train/val/test=0.833/0.832/0.836 | c=0.998347
[Epoch 0069] loss=16.7504 cls=0.4809 smmd=0.1215 ct=7.3168 rec=1.3222 | train/val/test=0.836/0.831/0.837 | c=0.998347
[Epoch 0070] loss=16.7036 cls=0.4799 smmd=0.1177 ct=7.3114 rec=1.3280 | train/val/test=0.831/0.829/0.834 | c=0.998347
[Epoch 0071] loss=16.7126 cls=0.4945 smmd=0.1161 ct=7.3195 rec=1.3306 | train/val/test=0.836/0.830/0.838 | c=0.998347
[Epoch 0072] loss=16.8260 cls=0.4907 smmd=0.1288 ct=7.3126 rec=1.3348 | train/val/test=0.834/0.832/0.838 | c=0.998347
[Epoch 0073] loss=16.8564 cls=0.5013 smmd=0.1296 ct=7.3212 rec=1.3350 | train/val/test=0.836/0.831/0.841 | c=0.998347
[Epoch 0074] loss=16.8141 cls=0.4950 smmd=0.1264 ct=7.3167 rec=1.3382 | train/val/test=0.837/0.830/0.839 | c=0.998347
[Epoch 0075] loss=16.8776 cls=0.5018 smmd=0.1323 ct=7.3185 rec=1.3335 | train/val/test=0.833/0.829/0.839 | c=0.998347
[Epoch 0076] loss=16.8720 cls=0.4916 smmd=0.1327 ct=7.3153 rec=1.3374 | train/val/test=0.834/0.827/0.835 | c=0.998347
[Epoch 0077] loss=16.8713 cls=0.5031 smmd=0.1311 ct=7.3220 rec=1.3287 | train/val/test=0.834/0.829/0.840 | c=0.998347
[Epoch 0078] loss=16.8412 cls=0.4847 smmd=0.1310 ct=7.3110 rec=1.3333 | train/val/test=0.834/0.825/0.833 | c=0.998347
[Epoch 0079] loss=16.7718 cls=0.4969 smmd=0.1224 ct=7.3185 rec=1.3240 | train/val/test=0.834/0.833/0.841 | c=0.998347
[Epoch 0080] loss=16.7754 cls=0.4779 smmd=0.1261 ct=7.3057 rec=1.3287 | train/val/test=0.835/0.827/0.835 | c=0.998347
[Epoch 0081] loss=16.7215 cls=0.4875 smmd=0.1193 ct=7.3115 rec=1.3229 | train/val/test=0.836/0.835/0.841 | c=0.998347
[Epoch 0082] loss=16.6861 cls=0.4788 smmd=0.1175 ct=7.3035 rec=1.3284 | train/val/test=0.837/0.831/0.836 | c=0.998347
[Epoch 0083] loss=16.6151 cls=0.4862 smmd=0.1087 ct=7.3108 rec=1.3265 | train/val/test=0.831/0.831/0.836 | c=0.998347
[Epoch 0084] loss=16.6442 cls=0.4878 smmd=0.1118 ct=7.3079 rec=1.3328 | train/val/test=0.836/0.835/0.835 | c=0.998347
[Epoch 0085] loss=16.7111 cls=0.4943 smmd=0.1184 ct=7.3069 rec=1.3331 | train/val/test=0.817/0.818/0.825 | c=0.998347
[Epoch 0086] loss=16.8291 cls=0.5079 smmd=0.1252 ct=7.3265 rec=1.3408 | train/val/test=0.816/0.814/0.821 | c=0.998347
[Epoch 0087] loss=16.9800 cls=0.5176 smmd=0.1432 ct=7.3092 rec=1.3414 | train/val/test=0.783/0.780/0.790 | c=0.998347
[Epoch 0088] loss=17.1900 cls=0.5568 smmd=0.1537 ct=7.3487 rec=1.3541 | train/val/test=0.741/0.734/0.744 | c=0.998347
[Epoch 0089] loss=17.5898 cls=0.5844 smmd=0.1938 ct=7.3402 rec=1.3581 | train/val/test=0.763/0.761/0.766 | c=0.998347
[Epoch 0090] loss=17.6593 cls=0.5941 smmd=0.1968 ct=7.3583 rec=1.3555 | train/val/test=0.799/0.793/0.803 | c=0.998347
[Epoch 0091] loss=17.1804 cls=0.5210 smmd=0.1587 ct=7.3318 rec=1.3379 | train/val/test=0.827/0.822/0.827 | c=0.998347
[Epoch 0092] loss=16.7698 cls=0.4765 smmd=0.1269 ct=7.3037 rec=1.3104 | train/val/test=0.825/0.825/0.829 | c=0.998347
[Epoch 0093] loss=16.7314 cls=0.4667 smmd=0.1234 ct=7.3033 rec=1.3142 | train/val/test=0.825/0.821/0.821 | c=0.998347
[Epoch 0094] loss=16.7776 cls=0.4954 smmd=0.1232 ct=7.3192 rec=1.3198 | train/val/test=0.820/0.816/0.821 | c=0.998347
[Epoch 0095] loss=16.7659 cls=0.4934 smmd=0.1247 ct=7.3048 rec=1.3242 | train/val/test=0.834/0.829/0.834 | c=0.998347
[Epoch 0096] loss=16.7895 cls=0.4854 smmd=0.1274 ct=7.3043 rec=1.3272 | train/val/test=0.834/0.832/0.834 | c=0.998347
[Epoch 0097] loss=16.7427 cls=0.5032 smmd=0.1200 ct=7.3125 rec=1.3330 | train/val/test=0.829/0.828/0.836 | c=0.998347
[Epoch 0098] loss=16.7908 cls=0.5121 smmd=0.1248 ct=7.3074 rec=1.3437 | train/val/test=0.837/0.831/0.836 | c=0.998347
[Epoch 0099] loss=16.9684 cls=0.5245 smmd=0.1394 ct=7.3209 rec=1.3418 | train/val/test=0.822/0.822/0.832 | c=0.998347
=== Best @ epoch 48: val=0.8400, test=0.8436 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-1 - 2025-09-21 05:12:16:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-1...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-1 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.5482 cls=1.1082 smmd=5.6784 ct=7.2518 rec=1.4137 | train/val/test=0.391/0.383/0.390 | c=0.998347
[Epoch 0001] loss=53.1988 cls=1.0652 smmd=3.7544 ct=7.2075 rec=1.4150 | train/val/test=0.536/0.542/0.537 | c=0.998347
[Epoch 0002] loss=38.1833 cls=1.0751 smmd=2.2662 ct=7.1382 rec=1.4137 | train/val/test=0.575/0.574/0.585 | c=0.998347
[Epoch 0003] loss=41.1972 cls=1.0695 smmd=2.5699 ct=7.1285 rec=1.4135 | train/val/test=0.581/0.580/0.589 | c=0.998347
[Epoch 0004] loss=41.7765 cls=1.0315 smmd=2.5511 ct=7.5213 rec=1.4151 | train/val/test=0.467/0.458/0.479 | c=0.998347
[Epoch 0005] loss=37.1016 cls=1.0070 smmd=2.1288 ct=7.3003 rec=1.4186 | train/val/test=0.540/0.547/0.541 | c=0.998347
[Epoch 0006] loss=31.8284 cls=0.9871 smmd=1.5914 ct=7.3556 rec=1.4202 | train/val/test=0.558/0.566/0.552 | c=0.998347
[Epoch 0007] loss=35.0766 cls=0.9530 smmd=1.8906 ct=7.4929 rec=1.4169 | train/val/test=0.566/0.565/0.556 | c=0.998347
[Epoch 0008] loss=36.0107 cls=0.9188 smmd=1.9886 ct=7.4795 rec=1.4127 | train/val/test=0.569/0.570/0.559 | c=0.998347
[Epoch 0009] loss=29.5517 cls=0.8881 smmd=1.3611 ct=7.3958 rec=1.4091 | train/val/test=0.558/0.558/0.551 | c=0.998347
[Epoch 0010] loss=28.2548 cls=0.8652 smmd=1.2330 ct=7.3944 rec=1.4062 | train/val/test=0.613/0.611/0.602 | c=0.998347
[Epoch 0011] loss=30.7106 cls=0.8340 smmd=1.4801 ct=7.3959 rec=1.4006 | train/val/test=0.680/0.681/0.682 | c=0.998347
[Epoch 0012] loss=27.6184 cls=0.8094 smmd=1.1700 ct=7.4077 rec=1.3960 | train/val/test=0.667/0.661/0.661 | c=0.998347
[Epoch 0013] loss=26.5216 cls=0.7842 smmd=1.0443 ct=7.4949 rec=1.3925 | train/val/test=0.668/0.662/0.662 | c=0.998347
[Epoch 0014] loss=26.2718 cls=0.7630 smmd=1.0217 ct=7.4899 rec=1.3878 | train/val/test=0.722/0.724/0.723 | c=0.998347
[Epoch 0015] loss=25.2544 cls=0.7277 smmd=0.9425 ct=7.3884 rec=1.3779 | train/val/test=0.764/0.768/0.767 | c=0.998347
[Epoch 0016] loss=24.8851 cls=0.7012 smmd=0.9092 ct=7.3787 rec=1.3702 | train/val/test=0.767/0.770/0.772 | c=0.998347
[Epoch 0017] loss=23.8028 cls=0.6634 smmd=0.7948 ct=7.4211 rec=1.3623 | train/val/test=0.753/0.751/0.755 | c=0.998347
[Epoch 0018] loss=23.0360 cls=0.6374 smmd=0.7131 ct=7.4544 rec=1.3553 | train/val/test=0.785/0.784/0.788 | c=0.998347
[Epoch 0019] loss=22.8497 cls=0.6070 smmd=0.6995 ct=7.4390 rec=1.3464 | train/val/test=0.793/0.793/0.794 | c=0.998347
[Epoch 0020] loss=22.3324 cls=0.5949 smmd=0.6576 ct=7.3948 rec=1.3389 | train/val/test=0.793/0.788/0.795 | c=0.998347
[Epoch 0021] loss=21.3551 cls=0.5768 smmd=0.5649 ct=7.3758 rec=1.3320 | train/val/test=0.806/0.803/0.806 | c=0.998347
[Epoch 0022] loss=21.5910 cls=0.5514 smmd=0.5812 ct=7.4196 rec=1.3282 | train/val/test=0.813/0.805/0.815 | c=0.998347
[Epoch 0023] loss=20.9449 cls=0.5307 smmd=0.5172 ct=7.4226 rec=1.3255 | train/val/test=0.806/0.804/0.808 | c=0.998347
[Epoch 0024] loss=20.5280 cls=0.5210 smmd=0.4826 ct=7.3901 rec=1.3232 | train/val/test=0.819/0.811/0.817 | c=0.998347
[Epoch 0025] loss=20.3593 cls=0.5120 smmd=0.4630 ct=7.4065 rec=1.3195 | train/val/test=0.820/0.810/0.822 | c=0.998347
[Epoch 0026] loss=19.9506 cls=0.5193 smmd=0.4200 ct=7.4150 rec=1.3213 | train/val/test=0.827/0.820/0.830 | c=0.998347
[Epoch 0027] loss=19.9281 cls=0.4938 smmd=0.4229 ct=7.3966 rec=1.3186 | train/val/test=0.828/0.823/0.832 | c=0.998347
[Epoch 0028] loss=19.3520 cls=0.4824 smmd=0.3618 ct=7.4168 rec=1.3181 | train/val/test=0.826/0.821/0.832 | c=0.998347
[Epoch 0029] loss=19.4202 cls=0.4768 smmd=0.3723 ct=7.4002 rec=1.3163 | train/val/test=0.834/0.823/0.834 | c=0.998347
[Epoch 0030] loss=19.0740 cls=0.4747 smmd=0.3418 ct=7.3813 rec=1.3127 | train/val/test=0.837/0.830/0.839 | c=0.998347
[Epoch 0031] loss=18.8599 cls=0.4658 smmd=0.3174 ct=7.3982 rec=1.3137 | train/val/test=0.835/0.832/0.840 | c=0.998347
[Epoch 0032] loss=18.6486 cls=0.4570 smmd=0.2942 ct=7.4112 rec=1.3113 | train/val/test=0.836/0.832/0.840 | c=0.998347
[Epoch 0033] loss=18.4366 cls=0.4531 smmd=0.2809 ct=7.3730 rec=1.3106 | train/val/test=0.838/0.833/0.843 | c=0.998347
[Epoch 0034] loss=18.3114 cls=0.4515 smmd=0.2679 ct=7.3756 rec=1.3101 | train/val/test=0.838/0.834/0.841 | c=0.998347
[Epoch 0035] loss=18.1912 cls=0.4543 smmd=0.2522 ct=7.3937 rec=1.3094 | train/val/test=0.837/0.834/0.841 | c=0.998347
[Epoch 0036] loss=17.9531 cls=0.4517 smmd=0.2336 ct=7.3672 rec=1.3143 | train/val/test=0.840/0.838/0.842 | c=0.998347
[Epoch 0037] loss=17.9148 cls=0.4532 smmd=0.2267 ct=7.3821 rec=1.3139 | train/val/test=0.839/0.836/0.841 | c=0.998347
[Epoch 0038] loss=17.7412 cls=0.4559 smmd=0.2109 ct=7.3731 rec=1.3154 | train/val/test=0.838/0.838/0.841 | c=0.998347
[Epoch 0039] loss=17.7100 cls=0.4584 smmd=0.2093 ct=7.3641 rec=1.3186 | train/val/test=0.841/0.838/0.843 | c=0.998347
[Epoch 0040] loss=17.5948 cls=0.4625 smmd=0.1949 ct=7.3775 rec=1.3187 | train/val/test=0.840/0.836/0.844 | c=0.998347
[Epoch 0041] loss=17.5965 cls=0.4636 smmd=0.1988 ct=7.3574 rec=1.3242 | train/val/test=0.840/0.835/0.839 | c=0.998347
[Epoch 0042] loss=17.4161 cls=0.4703 smmd=0.1795 ct=7.3625 rec=1.3227 | train/val/test=0.843/0.838/0.846 | c=0.998347
[Epoch 0043] loss=17.3578 cls=0.4680 smmd=0.1752 ct=7.3547 rec=1.3254 | train/val/test=0.842/0.839/0.843 | c=0.998347
[Epoch 0044] loss=17.2118 cls=0.4708 smmd=0.1601 ct=7.3565 rec=1.3254 | train/val/test=0.842/0.838/0.843 | c=0.998347
[Epoch 0045] loss=17.2220 cls=0.4707 smmd=0.1624 ct=7.3495 rec=1.3266 | train/val/test=0.841/0.839/0.844 | c=0.998347
[Epoch 0046] loss=17.1234 cls=0.4717 smmd=0.1543 ct=7.3406 rec=1.3272 | train/val/test=0.843/0.838/0.843 | c=0.998347
[Epoch 0047] loss=17.0725 cls=0.4741 smmd=0.1471 ct=7.3503 rec=1.3267 | train/val/test=0.841/0.839/0.844 | c=0.998347
[Epoch 0048] loss=16.9969 cls=0.4725 smmd=0.1428 ct=7.3344 rec=1.3276 | train/val/test=0.841/0.840/0.844 | c=0.998347
[Epoch 0049] loss=16.9769 cls=0.4744 smmd=0.1392 ct=7.3422 rec=1.3272 | train/val/test=0.841/0.837/0.845 | c=0.998347
[Epoch 0050] loss=16.9616 cls=0.4746 smmd=0.1378 ct=7.3412 rec=1.3279 | train/val/test=0.840/0.837/0.843 | c=0.998347
[Epoch 0051] loss=16.9368 cls=0.4757 smmd=0.1371 ct=7.3323 rec=1.3273 | train/val/test=0.840/0.837/0.844 | c=0.998347
[Epoch 0052] loss=16.8967 cls=0.4744 smmd=0.1325 ct=7.3356 rec=1.3273 | train/val/test=0.840/0.835/0.845 | c=0.998347
[Epoch 0053] loss=16.8836 cls=0.4739 smmd=0.1324 ct=7.3297 rec=1.3271 | train/val/test=0.839/0.837/0.844 | c=0.998347
[Epoch 0054] loss=16.8520 cls=0.4754 smmd=0.1285 ct=7.3334 rec=1.3256 | train/val/test=0.839/0.835/0.843 | c=0.998347
[Epoch 0055] loss=16.8643 cls=0.4733 smmd=0.1309 ct=7.3277 rec=1.3263 | train/val/test=0.840/0.837/0.843 | c=0.998347
[Epoch 0056] loss=16.8113 cls=0.4751 smmd=0.1266 ct=7.3225 rec=1.3258 | train/val/test=0.839/0.833/0.843 | c=0.998347
[Epoch 0057] loss=16.7610 cls=0.4735 smmd=0.1207 ct=7.3272 rec=1.3264 | train/val/test=0.837/0.833/0.840 | c=0.998347
[Epoch 0058] loss=16.7860 cls=0.4803 smmd=0.1237 ct=7.3232 rec=1.3257 | train/val/test=0.838/0.832/0.843 | c=0.998347
[Epoch 0059] loss=16.8098 cls=0.4766 smmd=0.1266 ct=7.3206 rec=1.3281 | train/val/test=0.834/0.831/0.834 | c=0.998347
[Epoch 0060] loss=16.8211 cls=0.4867 smmd=0.1259 ct=7.3275 rec=1.3274 | train/val/test=0.835/0.830/0.838 | c=0.998347
[Epoch 0061] loss=16.7820 cls=0.4843 smmd=0.1225 ct=7.3245 rec=1.3310 | train/val/test=0.823/0.818/0.823 | c=0.998347
[Epoch 0062] loss=16.8769 cls=0.5066 smmd=0.1298 ct=7.3300 rec=1.3303 | train/val/test=0.817/0.809/0.816 | c=0.998347
[Epoch 0063] loss=17.1217 cls=0.5097 smmd=0.1540 ct=7.3283 rec=1.3407 | train/val/test=0.808/0.804/0.801 | c=0.998347
[Epoch 0064] loss=17.2535 cls=0.5397 smmd=0.1600 ct=7.3582 rec=1.3349 | train/val/test=0.813/0.807/0.812 | c=0.998347
[Epoch 0065] loss=17.1254 cls=0.5108 smmd=0.1555 ct=7.3227 rec=1.3395 | train/val/test=0.819/0.814/0.817 | c=0.998347
[Epoch 0066] loss=17.0116 cls=0.5038 smmd=0.1432 ct=7.3324 rec=1.3249 | train/val/test=0.836/0.831/0.836 | c=0.998347
[Epoch 0067] loss=16.8332 cls=0.4717 smmd=0.1318 ct=7.3092 rec=1.3215 | train/val/test=0.837/0.833/0.838 | c=0.998347
[Epoch 0068] loss=16.7408 cls=0.4706 smmd=0.1228 ct=7.3087 rec=1.3200 | train/val/test=0.833/0.832/0.836 | c=0.998347
[Epoch 0069] loss=16.7504 cls=0.4809 smmd=0.1215 ct=7.3168 rec=1.3222 | train/val/test=0.836/0.831/0.837 | c=0.998347
[Epoch 0070] loss=16.7036 cls=0.4799 smmd=0.1177 ct=7.3114 rec=1.3280 | train/val/test=0.831/0.829/0.834 | c=0.998347
[Epoch 0071] loss=16.7126 cls=0.4945 smmd=0.1161 ct=7.3195 rec=1.3306 | train/val/test=0.836/0.830/0.838 | c=0.998347
[Epoch 0072] loss=16.8260 cls=0.4907 smmd=0.1288 ct=7.3126 rec=1.3348 | train/val/test=0.834/0.832/0.838 | c=0.998347
[Epoch 0073] loss=16.8564 cls=0.5013 smmd=0.1296 ct=7.3212 rec=1.3350 | train/val/test=0.836/0.831/0.841 | c=0.998347
[Epoch 0074] loss=16.8141 cls=0.4950 smmd=0.1264 ct=7.3167 rec=1.3382 | train/val/test=0.837/0.830/0.839 | c=0.998347
[Epoch 0075] loss=16.8776 cls=0.5018 smmd=0.1323 ct=7.3185 rec=1.3335 | train/val/test=0.833/0.829/0.839 | c=0.998347
[Epoch 0076] loss=16.8720 cls=0.4916 smmd=0.1327 ct=7.3153 rec=1.3374 | train/val/test=0.834/0.827/0.835 | c=0.998347
[Epoch 0077] loss=16.8713 cls=0.5031 smmd=0.1311 ct=7.3220 rec=1.3287 | train/val/test=0.834/0.829/0.840 | c=0.998347
[Epoch 0078] loss=16.8412 cls=0.4847 smmd=0.1310 ct=7.3110 rec=1.3333 | train/val/test=0.834/0.825/0.833 | c=0.998347
[Epoch 0079] loss=16.7718 cls=0.4969 smmd=0.1224 ct=7.3185 rec=1.3240 | train/val/test=0.834/0.833/0.841 | c=0.998347
[Epoch 0080] loss=16.7754 cls=0.4779 smmd=0.1261 ct=7.3057 rec=1.3287 | train/val/test=0.835/0.827/0.835 | c=0.998347
[Epoch 0081] loss=16.7215 cls=0.4875 smmd=0.1193 ct=7.3115 rec=1.3229 | train/val/test=0.836/0.835/0.841 | c=0.998347
[Epoch 0082] loss=16.6861 cls=0.4788 smmd=0.1175 ct=7.3035 rec=1.3284 | train/val/test=0.837/0.831/0.836 | c=0.998347
[Epoch 0083] loss=16.6151 cls=0.4862 smmd=0.1087 ct=7.3108 rec=1.3265 | train/val/test=0.831/0.831/0.836 | c=0.998347
[Epoch 0084] loss=16.6442 cls=0.4878 smmd=0.1118 ct=7.3079 rec=1.3328 | train/val/test=0.836/0.835/0.835 | c=0.998347
[Epoch 0085] loss=16.7111 cls=0.4943 smmd=0.1184 ct=7.3069 rec=1.3331 | train/val/test=0.817/0.818/0.825 | c=0.998347
[Epoch 0086] loss=16.8291 cls=0.5079 smmd=0.1252 ct=7.3265 rec=1.3408 | train/val/test=0.816/0.814/0.821 | c=0.998347
[Epoch 0087] loss=16.9800 cls=0.5176 smmd=0.1432 ct=7.3092 rec=1.3414 | train/val/test=0.783/0.780/0.790 | c=0.998347
[Epoch 0088] loss=17.1900 cls=0.5568 smmd=0.1537 ct=7.3487 rec=1.3541 | train/val/test=0.741/0.734/0.744 | c=0.998347
[Epoch 0089] loss=17.5898 cls=0.5844 smmd=0.1938 ct=7.3402 rec=1.3581 | train/val/test=0.763/0.761/0.766 | c=0.998347
[Epoch 0090] loss=17.6593 cls=0.5941 smmd=0.1968 ct=7.3583 rec=1.3555 | train/val/test=0.799/0.793/0.803 | c=0.998347
[Epoch 0091] loss=17.1804 cls=0.5210 smmd=0.1587 ct=7.3318 rec=1.3379 | train/val/test=0.827/0.822/0.827 | c=0.998347
[Epoch 0092] loss=16.7698 cls=0.4765 smmd=0.1269 ct=7.3037 rec=1.3104 | train/val/test=0.825/0.825/0.829 | c=0.998347
[Epoch 0093] loss=16.7314 cls=0.4667 smmd=0.1234 ct=7.3033 rec=1.3142 | train/val/test=0.825/0.821/0.821 | c=0.998347
[Epoch 0094] loss=16.7776 cls=0.4954 smmd=0.1232 ct=7.3192 rec=1.3198 | train/val/test=0.820/0.816/0.821 | c=0.998347
[Epoch 0095] loss=16.7659 cls=0.4934 smmd=0.1247 ct=7.3048 rec=1.3242 | train/val/test=0.834/0.829/0.834 | c=0.998347
[Epoch 0096] loss=16.7895 cls=0.4854 smmd=0.1274 ct=7.3043 rec=1.3272 | train/val/test=0.834/0.832/0.834 | c=0.998347
[Epoch 0097] loss=16.7427 cls=0.5032 smmd=0.1200 ct=7.3125 rec=1.3330 | train/val/test=0.829/0.828/0.836 | c=0.998347
[Epoch 0098] loss=16.7908 cls=0.5121 smmd=0.1248 ct=7.3074 rec=1.3437 | train/val/test=0.837/0.831/0.836 | c=0.998347
[Epoch 0099] loss=16.9684 cls=0.5245 smmd=0.1394 ct=7.3209 rec=1.3418 | train/val/test=0.822/0.822/0.832 | c=0.998347
=== Best @ epoch 48: val=0.8400, test=0.8436 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-1 completed in 187.86 seconds.
==================================================
