Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-2 - 2025-09-21 03:44:27:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-2...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-2 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.5448 cls=1.0980 smmd=5.6038 ct=11.2795 rec=1.4137 | train/val/test=0.385/0.420/0.445 | c=0.998437
[Epoch 0001] loss=22.3200 cls=1.0907 smmd=3.9250 ct=11.2554 rec=1.4136 | train/val/test=0.692/0.530/0.561 | c=0.998437
[Epoch 0002] loss=24.6690 cls=1.0837 smmd=4.8678 ct=11.2509 rec=1.4136 | train/val/test=0.538/0.468/0.495 | c=0.998437
[Epoch 0003] loss=23.5866 cls=1.0673 smmd=4.4640 ct=11.1862 rec=1.4135 | train/val/test=0.538/0.500/0.542 | c=0.998437
[Epoch 0004] loss=18.3223 cls=1.0410 smmd=2.4383 ct=10.9993 rec=1.4133 | train/val/test=0.538/0.532/0.572 | c=0.998437
[Epoch 0005] loss=19.7675 cls=1.0138 smmd=3.0242 ct=10.9937 rec=1.4127 | train/val/test=0.538/0.536/0.568 | c=0.998437
[Epoch 0006] loss=20.3235 cls=0.9805 smmd=3.2819 ct=10.9225 rec=1.4116 | train/val/test=0.692/0.544/0.566 | c=0.998437
[Epoch 0007] loss=19.2787 cls=0.9458 smmd=2.5930 ct=11.6183 rec=1.4098 | train/val/test=0.769/0.530/0.567 | c=0.998437
[Epoch 0008] loss=17.1346 cls=0.9236 smmd=1.8310 ct=11.3915 rec=1.4073 | train/val/test=0.846/0.562/0.592 | c=0.998437
[Epoch 0009] loss=18.8917 cls=0.9059 smmd=2.5399 ct=11.3857 rec=1.4065 | train/val/test=0.769/0.570/0.584 | c=0.998437
[Epoch 0010] loss=19.0405 cls=0.8825 smmd=2.5820 ct=11.4411 rec=1.4065 | train/val/test=0.769/0.564/0.591 | c=0.998437
[Epoch 0011] loss=16.7194 cls=0.8568 smmd=1.6464 ct=11.4718 rec=1.4064 | train/val/test=0.846/0.612/0.630 | c=0.998437
[Epoch 0012] loss=18.3204 cls=0.8383 smmd=2.2597 ct=11.5489 rec=1.4064 | train/val/test=0.846/0.632/0.640 | c=0.998437
[Epoch 0013] loss=18.0581 cls=0.8031 smmd=2.1858 ct=11.4901 rec=1.4043 | train/val/test=0.846/0.660/0.657 | c=0.998437
[Epoch 0014] loss=16.6168 cls=0.7530 smmd=1.6520 ct=11.4104 rec=1.3999 | train/val/test=0.923/0.674/0.672 | c=0.998437
[Epoch 0015] loss=16.5147 cls=0.7008 smmd=1.6117 ct=11.4377 rec=1.3949 | train/val/test=0.923/0.678/0.674 | c=0.998437
[Epoch 0016] loss=16.3698 cls=0.6565 smmd=1.5521 ct=11.4662 rec=1.3903 | train/val/test=0.923/0.680/0.677 | c=0.998437
[Epoch 0017] loss=16.0376 cls=0.6258 smmd=1.4348 ct=11.4441 rec=1.3872 | train/val/test=0.923/0.664/0.679 | c=0.998437
[Epoch 0018] loss=15.6098 cls=0.6116 smmd=1.2769 ct=11.4189 rec=1.3857 | train/val/test=0.923/0.670/0.682 | c=0.998437
[Epoch 0019] loss=15.5143 cls=0.6024 smmd=1.2309 ct=11.4425 rec=1.3869 | train/val/test=0.923/0.680/0.688 | c=0.998437
[Epoch 0020] loss=15.7931 cls=0.6001 smmd=1.3288 ct=11.4763 rec=1.3895 | train/val/test=0.923/0.694/0.690 | c=0.998437
[Epoch 0021] loss=15.3151 cls=0.5896 smmd=1.1450 ct=11.4620 rec=1.3918 | train/val/test=0.923/0.684/0.696 | c=0.998437
[Epoch 0022] loss=15.8451 cls=0.5737 smmd=1.3486 ct=11.4915 rec=1.3905 | train/val/test=0.923/0.686/0.701 | c=0.998437
[Epoch 0023] loss=15.3422 cls=0.5359 smmd=1.1809 ct=11.4286 rec=1.3864 | train/val/test=1.000/0.692/0.698 | c=0.998437
[Epoch 0024] loss=15.0531 cls=0.4879 smmd=1.0578 ct=11.4739 rec=1.3812 | train/val/test=1.000/0.696/0.699 | c=0.998437
[Epoch 0025] loss=14.8036 cls=0.4436 smmd=0.9712 ct=11.4664 rec=1.3752 | train/val/test=1.000/0.692/0.702 | c=0.998437
[Epoch 0026] loss=14.6180 cls=0.4112 smmd=0.9206 ct=11.4261 rec=1.3693 | train/val/test=1.000/0.692/0.704 | c=0.998437
[Epoch 0027] loss=14.3903 cls=0.3897 smmd=0.8374 ct=11.4190 rec=1.3660 | train/val/test=1.000/0.700/0.706 | c=0.998437
[Epoch 0028] loss=14.3724 cls=0.3725 smmd=0.8208 ct=11.4508 rec=1.3666 | train/val/test=1.000/0.708/0.710 | c=0.998437
[Epoch 0029] loss=14.3345 cls=0.3698 smmd=0.8010 ct=11.4623 rec=1.3697 | train/val/test=1.000/0.712/0.712 | c=0.998437
[Epoch 0030] loss=14.4135 cls=0.3760 smmd=0.8360 ct=11.4497 rec=1.3717 | train/val/test=1.000/0.720/0.711 | c=0.998437
[Epoch 0031] loss=14.8035 cls=0.3731 smmd=0.9899 ct=11.4552 rec=1.3739 | train/val/test=1.000/0.710/0.717 | c=0.998437
[Epoch 0032] loss=14.5489 cls=0.3516 smmd=0.8883 ct=11.4668 rec=1.3714 | train/val/test=1.000/0.722/0.717 | c=0.998437
[Epoch 0033] loss=14.3258 cls=0.3235 smmd=0.8121 ct=11.4518 rec=1.3641 | train/val/test=1.000/0.712/0.714 | c=0.998437
[Epoch 0034] loss=14.0462 cls=0.2914 smmd=0.7135 ct=11.4382 rec=1.3573 | train/val/test=1.000/0.712/0.713 | c=0.998437
[Epoch 0035] loss=14.0512 cls=0.2680 smmd=0.7198 ct=11.4421 rec=1.3511 | train/val/test=1.000/0.716/0.711 | c=0.998437
[Epoch 0036] loss=13.7293 cls=0.2550 smmd=0.5965 ct=11.4366 rec=1.3478 | train/val/test=1.000/0.712/0.716 | c=0.998437
[Epoch 0037] loss=13.8086 cls=0.2500 smmd=0.6309 ct=11.4321 rec=1.3484 | train/val/test=1.000/0.720/0.717 | c=0.998437
[Epoch 0038] loss=13.7267 cls=0.2527 smmd=0.5935 ct=11.4413 rec=1.3508 | train/val/test=1.000/0.722/0.721 | c=0.998437
[Epoch 0039] loss=13.9012 cls=0.2600 smmd=0.6604 ct=11.4429 rec=1.3546 | train/val/test=1.000/0.718/0.720 | c=0.998437
[Epoch 0040] loss=14.1944 cls=0.2612 smmd=0.7611 ct=11.4819 rec=1.3581 | train/val/test=1.000/0.728/0.720 | c=0.998437
[Epoch 0041] loss=14.1785 cls=0.2506 smmd=0.7694 ct=11.4522 rec=1.3547 | train/val/test=1.000/0.726/0.720 | c=0.998437
[Epoch 0042] loss=14.1306 cls=0.2280 smmd=0.7601 ct=11.4420 rec=1.3486 | train/val/test=1.000/0.722/0.719 | c=0.998437
[Epoch 0043] loss=13.5377 cls=0.2012 smmd=0.5266 ct=11.4505 rec=1.3405 | train/val/test=1.000/0.718/0.715 | c=0.998437
[Epoch 0044] loss=13.6423 cls=0.1880 smmd=0.5813 ct=11.4276 rec=1.3352 | train/val/test=1.000/0.720/0.715 | c=0.998437
[Epoch 0045] loss=13.4685 cls=0.1778 smmd=0.5126 ct=11.4317 rec=1.3330 | train/val/test=1.000/0.728/0.719 | c=0.998437
[Epoch 0046] loss=13.3600 cls=0.1784 smmd=0.4638 ct=11.4438 rec=1.3350 | train/val/test=1.000/0.726/0.723 | c=0.998437
[Epoch 0047] loss=13.5722 cls=0.1883 smmd=0.5487 ct=11.4366 rec=1.3391 | train/val/test=1.000/0.722/0.723 | c=0.998437
[Epoch 0048] loss=13.7817 cls=0.1968 smmd=0.6254 ct=11.4474 rec=1.3448 | train/val/test=1.000/0.726/0.721 | c=0.998437
[Epoch 0049] loss=13.8536 cls=0.1980 smmd=0.6363 ct=11.4907 rec=1.3464 | train/val/test=1.000/0.730/0.724 | c=0.998437
[Epoch 0050] loss=13.9629 cls=0.1893 smmd=0.7069 ct=11.4301 rec=1.3418 | train/val/test=1.000/0.710/0.713 | c=0.998437
[Epoch 0051] loss=13.7025 cls=0.1680 smmd=0.5912 ct=11.4714 rec=1.3384 | train/val/test=1.000/0.716/0.720 | c=0.998437
[Epoch 0052] loss=13.4384 cls=0.1589 smmd=0.4972 ct=11.4516 rec=1.3289 | train/val/test=1.000/0.726/0.717 | c=0.998437
[Epoch 0053] loss=13.5269 cls=0.1405 smmd=0.5467 ct=11.4266 rec=1.3266 | train/val/test=1.000/0.724/0.721 | c=0.998437
[Epoch 0054] loss=13.2797 cls=0.1403 smmd=0.4416 ct=11.4440 rec=1.3228 | train/val/test=1.000/0.726/0.718 | c=0.998437
[Epoch 0055] loss=13.3597 cls=0.1391 smmd=0.4674 ct=11.4583 rec=1.3267 | train/val/test=1.000/0.726/0.723 | c=0.998437
[Epoch 0056] loss=13.6465 cls=0.1528 smmd=0.5856 ct=11.4412 rec=1.3299 | train/val/test=1.000/0.712/0.706 | c=0.998437
[Epoch 0057] loss=13.7270 cls=0.1610 smmd=0.5908 ct=11.4985 rec=1.3419 | train/val/test=1.000/0.748/0.741 | c=0.998437
[Epoch 0058] loss=13.9333 cls=0.1830 smmd=0.6670 ct=11.5039 rec=1.3409 | train/val/test=1.000/0.708/0.684 | c=0.998437
[Epoch 0059] loss=14.0459 cls=0.1788 smmd=0.6930 ct=11.5474 rec=1.3534 | train/val/test=1.000/0.736/0.744 | c=0.998437
[Epoch 0060] loss=13.4372 cls=0.1403 smmd=0.4891 ct=11.4820 rec=1.3247 | train/val/test=1.000/0.724/0.714 | c=0.998437
[Epoch 0061] loss=13.3979 cls=0.1040 smmd=0.5054 ct=11.4280 rec=1.3088 | train/val/test=1.000/0.724/0.718 | c=0.998437
[Epoch 0062] loss=13.2155 cls=0.0968 smmd=0.4317 ct=11.4347 rec=1.3060 | train/val/test=1.000/0.728/0.725 | c=0.998437
[Epoch 0063] loss=13.1303 cls=0.1043 smmd=0.3876 ct=11.4545 rec=1.3095 | train/val/test=1.000/0.730/0.721 | c=0.998437
[Epoch 0064] loss=13.3237 cls=0.1171 smmd=0.4711 ct=11.4285 rec=1.3175 | train/val/test=1.000/0.730/0.730 | c=0.998437
[Epoch 0065] loss=13.5822 cls=0.1374 smmd=0.5468 ct=11.4818 rec=1.3295 | train/val/test=1.000/0.718/0.706 | c=0.998437
[Epoch 0066] loss=13.9266 cls=0.1638 smmd=0.6760 ct=11.4824 rec=1.3443 | train/val/test=1.000/0.726/0.734 | c=0.998437
[Epoch 0067] loss=14.3674 cls=0.1890 smmd=0.8256 ct=11.5374 rec=1.3431 | train/val/test=1.000/0.646/0.646 | c=0.998437
[Epoch 0068] loss=13.8361 cls=0.1857 smmd=0.5919 ct=11.5838 rec=1.3591 | train/val/test=1.000/0.740/0.746 | c=0.998437
[Epoch 0069] loss=13.5471 cls=0.1113 smmd=0.5517 ct=11.4536 rec=1.3173 | train/val/test=1.000/0.730/0.719 | c=0.998437
[Epoch 0070] loss=13.2837 cls=0.0725 smmd=0.4744 ct=11.4115 rec=1.3000 | train/val/test=1.000/0.714/0.709 | c=0.998437
[Epoch 0071] loss=13.1097 cls=0.0754 smmd=0.3896 ct=11.4471 rec=1.3017 | train/val/test=1.000/0.736/0.734 | c=0.998437
[Epoch 0072] loss=13.3051 cls=0.0862 smmd=0.4652 ct=11.4450 rec=1.3081 | train/val/test=1.000/0.720/0.720 | c=0.998437
[Epoch 0073] loss=13.4709 cls=0.0903 smmd=0.5262 ct=11.4520 rec=1.3163 | train/val/test=1.000/0.732/0.734 | c=0.998437
[Epoch 0074] loss=13.6895 cls=0.1162 smmd=0.5869 ct=11.5026 rec=1.3234 | train/val/test=1.000/0.714/0.713 | c=0.998437
[Epoch 0075] loss=14.1221 cls=0.1240 smmd=0.7640 ct=11.4824 rec=1.3353 | train/val/test=1.000/0.744/0.738 | c=0.998437
[Epoch 0076] loss=14.1667 cls=0.1415 smmd=0.7668 ct=11.5135 rec=1.3311 | train/val/test=1.000/0.714/0.693 | c=0.998437
[Epoch 0077] loss=13.7270 cls=0.1168 smmd=0.5914 ct=11.5255 rec=1.3295 | train/val/test=1.000/0.738/0.739 | c=0.998437
[Epoch 0078] loss=13.2588 cls=0.0902 smmd=0.4512 ct=11.4323 rec=1.3070 | train/val/test=1.000/0.734/0.727 | c=0.998437
[Epoch 0079] loss=13.1493 cls=0.0696 smmd=0.4192 ct=11.4187 rec=1.2957 | train/val/test=1.000/0.726/0.705 | c=0.998437
[Epoch 0080] loss=13.1022 cls=0.0787 smmd=0.3853 ct=11.4488 rec=1.3017 | train/val/test=1.000/0.734/0.733 | c=0.998437
[Epoch 0081] loss=13.1267 cls=0.0838 smmd=0.4009 ct=11.4301 rec=1.3050 | train/val/test=1.000/0.740/0.722 | c=0.998437
[Epoch 0082] loss=13.2349 cls=0.1009 smmd=0.4336 ct=11.4424 rec=1.3164 | train/val/test=1.000/0.744/0.736 | c=0.998437
[Epoch 0083] loss=13.5430 cls=0.1195 smmd=0.5364 ct=11.4787 rec=1.3271 | train/val/test=1.000/0.730/0.727 | c=0.998437
[Epoch 0084] loss=13.9883 cls=0.1333 smmd=0.7203 ct=11.4525 rec=1.3369 | train/val/test=1.000/0.746/0.750 | c=0.998437
[Epoch 0085] loss=13.9651 cls=0.1224 smmd=0.6989 ct=11.4938 rec=1.3260 | train/val/test=1.000/0.704/0.684 | c=0.998437
[Epoch 0086] loss=13.9598 cls=0.1391 smmd=0.6605 ct=11.5677 rec=1.3425 | train/val/test=1.000/0.740/0.738 | c=0.998437
[Epoch 0087] loss=13.3322 cls=0.1025 smmd=0.4597 ct=11.4722 rec=1.3190 | train/val/test=1.000/0.722/0.709 | c=0.998437
[Epoch 0088] loss=13.1886 cls=0.0513 smmd=0.4369 ct=11.4263 rec=1.2884 | train/val/test=1.000/0.712/0.693 | c=0.998437
[Epoch 0089] loss=13.0552 cls=0.0559 smmd=0.3755 ct=11.4436 rec=1.2897 | train/val/test=1.000/0.726/0.725 | c=0.998437
[Epoch 0090] loss=13.0555 cls=0.0740 smmd=0.3644 ct=11.4567 rec=1.3016 | train/val/test=1.000/0.730/0.716 | c=0.998437
[Epoch 0091] loss=13.3315 cls=0.0676 smmd=0.4778 ct=11.4516 rec=1.3032 | train/val/test=1.000/0.732/0.725 | c=0.998437
[Epoch 0092] loss=13.4849 cls=0.0926 smmd=0.5178 ct=11.4869 rec=1.3142 | train/val/test=1.000/0.690/0.695 | c=0.998437
[Epoch 0093] loss=13.9816 cls=0.1214 smmd=0.6900 ct=11.5232 rec=1.3457 | train/val/test=1.000/0.646/0.677 | c=0.998437
[Epoch 0094] loss=14.5275 cls=0.1820 smmd=0.8972 ct=11.5221 rec=1.3429 | train/val/test=0.923/0.634/0.627 | c=0.998437
[Epoch 0095] loss=14.0311 cls=0.2174 smmd=0.6450 ct=11.6127 rec=1.3946 | train/val/test=1.000/0.698/0.703 | c=0.998437
[Epoch 0096] loss=13.5016 cls=0.1041 smmd=0.5401 ct=11.4400 rec=1.3185 | train/val/test=1.000/0.740/0.715 | c=0.998437
[Epoch 0097] loss=13.2348 cls=0.0349 smmd=0.4695 ct=11.4025 rec=1.2825 | train/val/test=1.000/0.730/0.709 | c=0.998437
[Epoch 0098] loss=13.1802 cls=0.0412 smmd=0.4243 ct=11.4543 rec=1.2894 | train/val/test=1.000/0.738/0.727 | c=0.998437
[Epoch 0099] loss=13.1413 cls=0.0337 smmd=0.4178 ct=11.4376 rec=1.2847 | train/val/test=1.000/0.740/0.740 | c=0.998437
=== Best @ epoch 57: val=0.7480, test=0.7410 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-2 - 2025-09-21 03:44:27:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-2...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-2 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=13, val=500, test=1000 (mode=few, shot=5)
[Epoch 0000] loss=26.5448 cls=1.0980 smmd=5.6038 ct=11.2795 rec=1.4137 | train/val/test=0.385/0.420/0.445 | c=0.998437
[Epoch 0001] loss=22.3200 cls=1.0907 smmd=3.9250 ct=11.2554 rec=1.4136 | train/val/test=0.692/0.530/0.561 | c=0.998437
[Epoch 0002] loss=24.6690 cls=1.0837 smmd=4.8678 ct=11.2509 rec=1.4136 | train/val/test=0.538/0.468/0.495 | c=0.998437
[Epoch 0003] loss=23.5866 cls=1.0673 smmd=4.4640 ct=11.1862 rec=1.4135 | train/val/test=0.538/0.500/0.542 | c=0.998437
[Epoch 0004] loss=18.3223 cls=1.0410 smmd=2.4383 ct=10.9993 rec=1.4133 | train/val/test=0.538/0.532/0.572 | c=0.998437
[Epoch 0005] loss=19.7675 cls=1.0138 smmd=3.0242 ct=10.9937 rec=1.4127 | train/val/test=0.538/0.536/0.568 | c=0.998437
[Epoch 0006] loss=20.3235 cls=0.9805 smmd=3.2819 ct=10.9225 rec=1.4116 | train/val/test=0.692/0.544/0.566 | c=0.998437
[Epoch 0007] loss=19.2787 cls=0.9458 smmd=2.5930 ct=11.6183 rec=1.4098 | train/val/test=0.769/0.530/0.567 | c=0.998437
[Epoch 0008] loss=17.1346 cls=0.9236 smmd=1.8310 ct=11.3915 rec=1.4073 | train/val/test=0.846/0.562/0.592 | c=0.998437
[Epoch 0009] loss=18.8917 cls=0.9059 smmd=2.5399 ct=11.3857 rec=1.4065 | train/val/test=0.769/0.570/0.584 | c=0.998437
[Epoch 0010] loss=19.0405 cls=0.8825 smmd=2.5820 ct=11.4411 rec=1.4065 | train/val/test=0.769/0.564/0.591 | c=0.998437
[Epoch 0011] loss=16.7194 cls=0.8568 smmd=1.6464 ct=11.4718 rec=1.4064 | train/val/test=0.846/0.612/0.630 | c=0.998437
[Epoch 0012] loss=18.3204 cls=0.8383 smmd=2.2597 ct=11.5489 rec=1.4064 | train/val/test=0.846/0.632/0.640 | c=0.998437
[Epoch 0013] loss=18.0581 cls=0.8031 smmd=2.1858 ct=11.4901 rec=1.4043 | train/val/test=0.846/0.660/0.657 | c=0.998437
[Epoch 0014] loss=16.6168 cls=0.7530 smmd=1.6520 ct=11.4104 rec=1.3999 | train/val/test=0.923/0.674/0.672 | c=0.998437
[Epoch 0015] loss=16.5147 cls=0.7008 smmd=1.6117 ct=11.4377 rec=1.3949 | train/val/test=0.923/0.678/0.674 | c=0.998437
[Epoch 0016] loss=16.3698 cls=0.6565 smmd=1.5521 ct=11.4662 rec=1.3903 | train/val/test=0.923/0.680/0.677 | c=0.998437
[Epoch 0017] loss=16.0376 cls=0.6258 smmd=1.4348 ct=11.4441 rec=1.3872 | train/val/test=0.923/0.664/0.679 | c=0.998437
[Epoch 0018] loss=15.6098 cls=0.6116 smmd=1.2769 ct=11.4189 rec=1.3857 | train/val/test=0.923/0.670/0.682 | c=0.998437
[Epoch 0019] loss=15.5143 cls=0.6024 smmd=1.2309 ct=11.4425 rec=1.3869 | train/val/test=0.923/0.680/0.688 | c=0.998437
[Epoch 0020] loss=15.7931 cls=0.6001 smmd=1.3288 ct=11.4763 rec=1.3895 | train/val/test=0.923/0.694/0.690 | c=0.998437
[Epoch 0021] loss=15.3151 cls=0.5896 smmd=1.1450 ct=11.4620 rec=1.3918 | train/val/test=0.923/0.684/0.696 | c=0.998437
[Epoch 0022] loss=15.8451 cls=0.5737 smmd=1.3486 ct=11.4915 rec=1.3905 | train/val/test=0.923/0.686/0.701 | c=0.998437
[Epoch 0023] loss=15.3422 cls=0.5359 smmd=1.1809 ct=11.4286 rec=1.3864 | train/val/test=1.000/0.692/0.698 | c=0.998437
[Epoch 0024] loss=15.0531 cls=0.4879 smmd=1.0578 ct=11.4739 rec=1.3812 | train/val/test=1.000/0.696/0.699 | c=0.998437
[Epoch 0025] loss=14.8036 cls=0.4436 smmd=0.9712 ct=11.4664 rec=1.3752 | train/val/test=1.000/0.692/0.702 | c=0.998437
[Epoch 0026] loss=14.6180 cls=0.4112 smmd=0.9206 ct=11.4261 rec=1.3693 | train/val/test=1.000/0.692/0.704 | c=0.998437
[Epoch 0027] loss=14.3903 cls=0.3897 smmd=0.8374 ct=11.4190 rec=1.3660 | train/val/test=1.000/0.700/0.706 | c=0.998437
[Epoch 0028] loss=14.3724 cls=0.3725 smmd=0.8208 ct=11.4508 rec=1.3666 | train/val/test=1.000/0.708/0.710 | c=0.998437
[Epoch 0029] loss=14.3345 cls=0.3698 smmd=0.8010 ct=11.4623 rec=1.3697 | train/val/test=1.000/0.712/0.712 | c=0.998437
[Epoch 0030] loss=14.4135 cls=0.3760 smmd=0.8360 ct=11.4497 rec=1.3717 | train/val/test=1.000/0.720/0.711 | c=0.998437
[Epoch 0031] loss=14.8035 cls=0.3731 smmd=0.9899 ct=11.4552 rec=1.3739 | train/val/test=1.000/0.710/0.717 | c=0.998437
[Epoch 0032] loss=14.5489 cls=0.3516 smmd=0.8883 ct=11.4668 rec=1.3714 | train/val/test=1.000/0.722/0.717 | c=0.998437
[Epoch 0033] loss=14.3258 cls=0.3235 smmd=0.8121 ct=11.4518 rec=1.3641 | train/val/test=1.000/0.712/0.714 | c=0.998437
[Epoch 0034] loss=14.0462 cls=0.2914 smmd=0.7135 ct=11.4382 rec=1.3573 | train/val/test=1.000/0.712/0.713 | c=0.998437
[Epoch 0035] loss=14.0512 cls=0.2680 smmd=0.7198 ct=11.4421 rec=1.3511 | train/val/test=1.000/0.716/0.711 | c=0.998437
[Epoch 0036] loss=13.7293 cls=0.2550 smmd=0.5965 ct=11.4366 rec=1.3478 | train/val/test=1.000/0.712/0.716 | c=0.998437
[Epoch 0037] loss=13.8086 cls=0.2500 smmd=0.6309 ct=11.4321 rec=1.3484 | train/val/test=1.000/0.720/0.717 | c=0.998437
[Epoch 0038] loss=13.7267 cls=0.2527 smmd=0.5935 ct=11.4413 rec=1.3508 | train/val/test=1.000/0.722/0.721 | c=0.998437
[Epoch 0039] loss=13.9012 cls=0.2600 smmd=0.6604 ct=11.4429 rec=1.3546 | train/val/test=1.000/0.718/0.720 | c=0.998437
[Epoch 0040] loss=14.1944 cls=0.2612 smmd=0.7611 ct=11.4819 rec=1.3581 | train/val/test=1.000/0.728/0.720 | c=0.998437
[Epoch 0041] loss=14.1785 cls=0.2506 smmd=0.7694 ct=11.4522 rec=1.3547 | train/val/test=1.000/0.726/0.720 | c=0.998437
[Epoch 0042] loss=14.1306 cls=0.2280 smmd=0.7601 ct=11.4420 rec=1.3486 | train/val/test=1.000/0.722/0.719 | c=0.998437
[Epoch 0043] loss=13.5377 cls=0.2012 smmd=0.5266 ct=11.4505 rec=1.3405 | train/val/test=1.000/0.718/0.715 | c=0.998437
[Epoch 0044] loss=13.6423 cls=0.1880 smmd=0.5813 ct=11.4276 rec=1.3352 | train/val/test=1.000/0.720/0.715 | c=0.998437
[Epoch 0045] loss=13.4685 cls=0.1778 smmd=0.5126 ct=11.4317 rec=1.3330 | train/val/test=1.000/0.728/0.719 | c=0.998437
[Epoch 0046] loss=13.3600 cls=0.1784 smmd=0.4638 ct=11.4438 rec=1.3350 | train/val/test=1.000/0.726/0.723 | c=0.998437
[Epoch 0047] loss=13.5722 cls=0.1883 smmd=0.5487 ct=11.4366 rec=1.3391 | train/val/test=1.000/0.722/0.723 | c=0.998437
[Epoch 0048] loss=13.7817 cls=0.1968 smmd=0.6254 ct=11.4474 rec=1.3448 | train/val/test=1.000/0.726/0.721 | c=0.998437
[Epoch 0049] loss=13.8536 cls=0.1980 smmd=0.6363 ct=11.4907 rec=1.3464 | train/val/test=1.000/0.730/0.724 | c=0.998437
[Epoch 0050] loss=13.9629 cls=0.1893 smmd=0.7069 ct=11.4301 rec=1.3418 | train/val/test=1.000/0.710/0.713 | c=0.998437
[Epoch 0051] loss=13.7025 cls=0.1680 smmd=0.5912 ct=11.4714 rec=1.3384 | train/val/test=1.000/0.716/0.720 | c=0.998437
[Epoch 0052] loss=13.4384 cls=0.1589 smmd=0.4972 ct=11.4516 rec=1.3289 | train/val/test=1.000/0.726/0.717 | c=0.998437
[Epoch 0053] loss=13.5269 cls=0.1405 smmd=0.5467 ct=11.4266 rec=1.3266 | train/val/test=1.000/0.724/0.721 | c=0.998437
[Epoch 0054] loss=13.2797 cls=0.1403 smmd=0.4416 ct=11.4440 rec=1.3228 | train/val/test=1.000/0.726/0.718 | c=0.998437
[Epoch 0055] loss=13.3597 cls=0.1391 smmd=0.4674 ct=11.4583 rec=1.3267 | train/val/test=1.000/0.726/0.723 | c=0.998437
[Epoch 0056] loss=13.6465 cls=0.1528 smmd=0.5856 ct=11.4412 rec=1.3299 | train/val/test=1.000/0.712/0.706 | c=0.998437
[Epoch 0057] loss=13.7270 cls=0.1610 smmd=0.5908 ct=11.4985 rec=1.3419 | train/val/test=1.000/0.748/0.741 | c=0.998437
[Epoch 0058] loss=13.9333 cls=0.1830 smmd=0.6670 ct=11.5039 rec=1.3409 | train/val/test=1.000/0.708/0.684 | c=0.998437
[Epoch 0059] loss=14.0459 cls=0.1788 smmd=0.6930 ct=11.5474 rec=1.3534 | train/val/test=1.000/0.736/0.744 | c=0.998437
[Epoch 0060] loss=13.4372 cls=0.1403 smmd=0.4891 ct=11.4820 rec=1.3247 | train/val/test=1.000/0.724/0.714 | c=0.998437
[Epoch 0061] loss=13.3979 cls=0.1040 smmd=0.5054 ct=11.4280 rec=1.3088 | train/val/test=1.000/0.724/0.718 | c=0.998437
[Epoch 0062] loss=13.2155 cls=0.0968 smmd=0.4317 ct=11.4347 rec=1.3060 | train/val/test=1.000/0.728/0.725 | c=0.998437
[Epoch 0063] loss=13.1303 cls=0.1043 smmd=0.3876 ct=11.4545 rec=1.3095 | train/val/test=1.000/0.730/0.721 | c=0.998437
[Epoch 0064] loss=13.3237 cls=0.1171 smmd=0.4711 ct=11.4285 rec=1.3175 | train/val/test=1.000/0.730/0.730 | c=0.998437
[Epoch 0065] loss=13.5822 cls=0.1374 smmd=0.5468 ct=11.4818 rec=1.3295 | train/val/test=1.000/0.718/0.706 | c=0.998437
[Epoch 0066] loss=13.9266 cls=0.1638 smmd=0.6760 ct=11.4824 rec=1.3443 | train/val/test=1.000/0.726/0.734 | c=0.998437
[Epoch 0067] loss=14.3674 cls=0.1890 smmd=0.8256 ct=11.5374 rec=1.3431 | train/val/test=1.000/0.646/0.646 | c=0.998437
[Epoch 0068] loss=13.8361 cls=0.1857 smmd=0.5919 ct=11.5838 rec=1.3591 | train/val/test=1.000/0.740/0.746 | c=0.998437
[Epoch 0069] loss=13.5471 cls=0.1113 smmd=0.5517 ct=11.4536 rec=1.3173 | train/val/test=1.000/0.730/0.719 | c=0.998437
[Epoch 0070] loss=13.2837 cls=0.0725 smmd=0.4744 ct=11.4115 rec=1.3000 | train/val/test=1.000/0.714/0.709 | c=0.998437
[Epoch 0071] loss=13.1097 cls=0.0754 smmd=0.3896 ct=11.4471 rec=1.3017 | train/val/test=1.000/0.736/0.734 | c=0.998437
[Epoch 0072] loss=13.3051 cls=0.0862 smmd=0.4652 ct=11.4450 rec=1.3081 | train/val/test=1.000/0.720/0.720 | c=0.998437
[Epoch 0073] loss=13.4709 cls=0.0903 smmd=0.5262 ct=11.4520 rec=1.3163 | train/val/test=1.000/0.732/0.734 | c=0.998437
[Epoch 0074] loss=13.6895 cls=0.1162 smmd=0.5869 ct=11.5026 rec=1.3234 | train/val/test=1.000/0.714/0.713 | c=0.998437
[Epoch 0075] loss=14.1221 cls=0.1240 smmd=0.7640 ct=11.4824 rec=1.3353 | train/val/test=1.000/0.744/0.738 | c=0.998437
[Epoch 0076] loss=14.1667 cls=0.1415 smmd=0.7668 ct=11.5135 rec=1.3311 | train/val/test=1.000/0.714/0.693 | c=0.998437
[Epoch 0077] loss=13.7270 cls=0.1168 smmd=0.5914 ct=11.5255 rec=1.3295 | train/val/test=1.000/0.738/0.739 | c=0.998437
[Epoch 0078] loss=13.2588 cls=0.0902 smmd=0.4512 ct=11.4323 rec=1.3070 | train/val/test=1.000/0.734/0.727 | c=0.998437
[Epoch 0079] loss=13.1493 cls=0.0696 smmd=0.4192 ct=11.4187 rec=1.2957 | train/val/test=1.000/0.726/0.705 | c=0.998437
[Epoch 0080] loss=13.1022 cls=0.0787 smmd=0.3853 ct=11.4488 rec=1.3017 | train/val/test=1.000/0.734/0.733 | c=0.998437
[Epoch 0081] loss=13.1267 cls=0.0838 smmd=0.4009 ct=11.4301 rec=1.3050 | train/val/test=1.000/0.740/0.722 | c=0.998437
[Epoch 0082] loss=13.2349 cls=0.1009 smmd=0.4336 ct=11.4424 rec=1.3164 | train/val/test=1.000/0.744/0.736 | c=0.998437
[Epoch 0083] loss=13.5430 cls=0.1195 smmd=0.5364 ct=11.4787 rec=1.3271 | train/val/test=1.000/0.730/0.727 | c=0.998437
[Epoch 0084] loss=13.9883 cls=0.1333 smmd=0.7203 ct=11.4525 rec=1.3369 | train/val/test=1.000/0.746/0.750 | c=0.998437
[Epoch 0085] loss=13.9651 cls=0.1224 smmd=0.6989 ct=11.4938 rec=1.3260 | train/val/test=1.000/0.704/0.684 | c=0.998437
[Epoch 0086] loss=13.9598 cls=0.1391 smmd=0.6605 ct=11.5677 rec=1.3425 | train/val/test=1.000/0.740/0.738 | c=0.998437
[Epoch 0087] loss=13.3322 cls=0.1025 smmd=0.4597 ct=11.4722 rec=1.3190 | train/val/test=1.000/0.722/0.709 | c=0.998437
[Epoch 0088] loss=13.1886 cls=0.0513 smmd=0.4369 ct=11.4263 rec=1.2884 | train/val/test=1.000/0.712/0.693 | c=0.998437
[Epoch 0089] loss=13.0552 cls=0.0559 smmd=0.3755 ct=11.4436 rec=1.2897 | train/val/test=1.000/0.726/0.725 | c=0.998437
[Epoch 0090] loss=13.0555 cls=0.0740 smmd=0.3644 ct=11.4567 rec=1.3016 | train/val/test=1.000/0.730/0.716 | c=0.998437
[Epoch 0091] loss=13.3315 cls=0.0676 smmd=0.4778 ct=11.4516 rec=1.3032 | train/val/test=1.000/0.732/0.725 | c=0.998437
[Epoch 0092] loss=13.4849 cls=0.0926 smmd=0.5178 ct=11.4869 rec=1.3142 | train/val/test=1.000/0.690/0.695 | c=0.998437
[Epoch 0093] loss=13.9816 cls=0.1214 smmd=0.6900 ct=11.5232 rec=1.3457 | train/val/test=1.000/0.646/0.677 | c=0.998437
[Epoch 0094] loss=14.5275 cls=0.1820 smmd=0.8972 ct=11.5221 rec=1.3429 | train/val/test=0.923/0.634/0.627 | c=0.998437
[Epoch 0095] loss=14.0311 cls=0.2174 smmd=0.6450 ct=11.6127 rec=1.3946 | train/val/test=1.000/0.698/0.703 | c=0.998437
[Epoch 0096] loss=13.5016 cls=0.1041 smmd=0.5401 ct=11.4400 rec=1.3185 | train/val/test=1.000/0.740/0.715 | c=0.998437
[Epoch 0097] loss=13.2348 cls=0.0349 smmd=0.4695 ct=11.4025 rec=1.2825 | train/val/test=1.000/0.730/0.709 | c=0.998437
[Epoch 0098] loss=13.1802 cls=0.0412 smmd=0.4243 ct=11.4543 rec=1.2894 | train/val/test=1.000/0.738/0.727 | c=0.998437
[Epoch 0099] loss=13.1413 cls=0.0337 smmd=0.4178 ct=11.4376 rec=1.2847 | train/val/test=1.000/0.740/0.740 | c=0.998437
=== Best @ epoch 57: val=0.7480, test=0.7410 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-True-5-2 completed in 137.33 seconds.
==================================================
