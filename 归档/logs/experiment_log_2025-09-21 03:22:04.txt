Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-3 - 2025-09-21 03:22:04:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.6458 cls=1.1186 smmd=5.5864 ct=7.2579 rec=1.4138 | train/val/test=0.396/0.401/0.400 | c=0.998437
[Epoch 0001] loss=51.9751 cls=1.0662 smmd=3.6325 ct=7.2047 rec=1.4146 | train/val/test=0.354/0.353/0.353 | c=0.998437
[Epoch 0002] loss=38.1529 cls=1.0926 smmd=2.2585 ct=7.1576 rec=1.4135 | train/val/test=0.586/0.592/0.585 | c=0.998437
[Epoch 0003] loss=40.4399 cls=1.0603 smmd=2.4977 ct=7.1131 rec=1.4136 | train/val/test=0.560/0.558/0.559 | c=0.998437
[Epoch 0004] loss=39.8065 cls=1.0233 smmd=2.4437 ct=7.0750 rec=1.4159 | train/val/test=0.558/0.560/0.559 | c=0.998437
[Epoch 0005] loss=35.3142 cls=1.0016 smmd=2.0064 ct=7.0200 rec=1.4182 | train/val/test=0.550/0.555/0.554 | c=0.998437
[Epoch 0006] loss=30.5562 cls=0.9773 smmd=1.5423 ct=6.9676 rec=1.4180 | train/val/test=0.555/0.555/0.557 | c=0.998437
[Epoch 0007] loss=33.2225 cls=0.9403 smmd=1.8170 ct=6.9375 rec=1.4137 | train/val/test=0.562/0.564/0.562 | c=0.998437
[Epoch 0008] loss=34.0070 cls=0.8979 smmd=1.9023 ct=6.9157 rec=1.4063 | train/val/test=0.596/0.602/0.605 | c=0.998437
[Epoch 0009] loss=27.8579 cls=0.8579 smmd=1.2965 ct=6.8826 rec=1.3980 | train/val/test=0.595/0.592/0.599 | c=0.998437
[Epoch 0010] loss=27.8049 cls=0.8304 smmd=1.1509 ct=7.5922 rec=1.3918 | train/val/test=0.630/0.636/0.633 | c=0.998437
[Epoch 0011] loss=30.4051 cls=0.8007 smmd=1.4218 ct=7.5475 rec=1.3839 | train/val/test=0.686/0.693/0.695 | c=0.998437
[Epoch 0012] loss=27.2518 cls=0.7635 smmd=1.1206 ct=7.4895 rec=1.3706 | train/val/test=0.693/0.699/0.703 | c=0.998437
[Epoch 0013] loss=26.0549 cls=0.7442 smmd=0.9945 ct=7.5286 rec=1.3620 | train/val/test=0.705/0.711/0.710 | c=0.998437
[Epoch 0014] loss=25.6205 cls=0.7157 smmd=0.9439 ct=7.5726 rec=1.3572 | train/val/test=0.710/0.712/0.711 | c=0.998437
[Epoch 0015] loss=25.3693 cls=0.7002 smmd=0.9253 ct=7.5442 rec=1.3559 | train/val/test=0.722/0.725/0.725 | c=0.998437
[Epoch 0016] loss=24.6891 cls=0.6818 smmd=0.8607 ct=7.5329 rec=1.3504 | train/val/test=0.727/0.735/0.736 | c=0.998437
[Epoch 0017] loss=22.9385 cls=0.6698 smmd=0.6897 ct=7.5177 rec=1.3413 | train/val/test=0.730/0.732/0.736 | c=0.998437
[Epoch 0018] loss=23.9039 cls=0.6554 smmd=0.7828 ct=7.5392 rec=1.3387 | train/val/test=0.746/0.751/0.755 | c=0.998437
[Epoch 0019] loss=22.6298 cls=0.6224 smmd=0.6510 ct=7.5695 rec=1.3384 | train/val/test=0.757/0.759/0.761 | c=0.998437
[Epoch 0020] loss=21.9469 cls=0.6114 smmd=0.5809 ct=7.5819 rec=1.3367 | train/val/test=0.769/0.767/0.775 | c=0.998437
[Epoch 0021] loss=22.1168 cls=0.6004 smmd=0.6073 ct=7.5390 rec=1.3318 | train/val/test=0.778/0.780/0.781 | c=0.998437
[Epoch 0022] loss=21.3459 cls=0.5848 smmd=0.5400 ct=7.4949 rec=1.3283 | train/val/test=0.787/0.791/0.796 | c=0.998437
[Epoch 0023] loss=20.9651 cls=0.5673 smmd=0.4946 ct=7.5358 rec=1.3268 | train/val/test=0.800/0.803/0.809 | c=0.998437
[Epoch 0024] loss=20.7384 cls=0.5479 smmd=0.4682 ct=7.5595 rec=1.3264 | train/val/test=0.802/0.802/0.807 | c=0.998437
[Epoch 0025] loss=20.3557 cls=0.5335 smmd=0.4296 ct=7.5656 rec=1.3230 | train/val/test=0.801/0.803/0.809 | c=0.998437
[Epoch 0026] loss=20.0739 cls=0.5261 smmd=0.4040 ct=7.5554 rec=1.3209 | train/val/test=0.815/0.818/0.825 | c=0.998437
[Epoch 0027] loss=19.8166 cls=0.5139 smmd=0.3873 ct=7.5132 rec=1.3197 | train/val/test=0.818/0.824/0.823 | c=0.998437
[Epoch 0028] loss=19.6456 cls=0.5133 smmd=0.3701 ct=7.5143 rec=1.3194 | train/val/test=0.820/0.825/0.828 | c=0.998437
[Epoch 0029] loss=19.2615 cls=0.4924 smmd=0.3271 ct=7.5430 rec=1.3165 | train/val/test=0.819/0.824/0.829 | c=0.998437
[Epoch 0030] loss=19.1623 cls=0.4869 smmd=0.3153 ct=7.5543 rec=1.3142 | train/val/test=0.823/0.830/0.833 | c=0.998437
[Epoch 0031] loss=18.9068 cls=0.4802 smmd=0.2938 ct=7.5359 rec=1.3126 | train/val/test=0.829/0.837/0.834 | c=0.998437
[Epoch 0032] loss=18.7402 cls=0.4750 smmd=0.2803 ct=7.5213 rec=1.3143 | train/val/test=0.826/0.833/0.834 | c=0.998437
[Epoch 0033] loss=18.6818 cls=0.4737 smmd=0.2764 ct=7.5132 rec=1.3098 | train/val/test=0.828/0.835/0.836 | c=0.998437
[Epoch 0034] loss=18.3933 cls=0.4662 smmd=0.2463 ct=7.5209 rec=1.3100 | train/val/test=0.826/0.832/0.836 | c=0.998437
[Epoch 0035] loss=18.3462 cls=0.4625 smmd=0.2379 ct=7.5404 rec=1.3107 | train/val/test=0.832/0.839/0.840 | c=0.998437
[Epoch 0036] loss=18.0447 cls=0.4623 smmd=0.2140 ct=7.5092 rec=1.3096 | train/val/test=0.833/0.839/0.842 | c=0.998437
[Epoch 0037] loss=18.1213 cls=0.4610 smmd=0.2227 ct=7.5044 rec=1.3099 | train/val/test=0.831/0.836/0.843 | c=0.998437
[Epoch 0038] loss=17.9694 cls=0.4575 smmd=0.2028 ct=7.5289 rec=1.3105 | train/val/test=0.833/0.837/0.843 | c=0.998437
[Epoch 0039] loss=17.9418 cls=0.4584 smmd=0.2030 ct=7.5137 rec=1.3106 | train/val/test=0.832/0.836/0.844 | c=0.998437
[Epoch 0040] loss=17.7051 cls=0.4584 smmd=0.1805 ct=7.5073 rec=1.3120 | train/val/test=0.839/0.840/0.843 | c=0.998437
[Epoch 0041] loss=17.7263 cls=0.4622 smmd=0.1831 ct=7.5041 rec=1.3131 | train/val/test=0.835/0.837/0.845 | c=0.998437
[Epoch 0042] loss=17.5640 cls=0.4597 smmd=0.1643 ct=7.5170 rec=1.3135 | train/val/test=0.834/0.841/0.841 | c=0.998437
[Epoch 0043] loss=17.5819 cls=0.4599 smmd=0.1650 ct=7.5219 rec=1.3154 | train/val/test=0.837/0.842/0.845 | c=0.998437
[Epoch 0044] loss=17.4938 cls=0.4611 smmd=0.1612 ct=7.4968 rec=1.3143 | train/val/test=0.835/0.837/0.843 | c=0.998437
[Epoch 0045] loss=17.3873 cls=0.4623 smmd=0.1498 ct=7.5006 rec=1.3141 | train/val/test=0.839/0.846/0.841 | c=0.998437
[Epoch 0046] loss=17.3539 cls=0.4606 smmd=0.1447 ct=7.5091 rec=1.3168 | train/val/test=0.832/0.834/0.841 | c=0.998437
[Epoch 0047] loss=17.2717 cls=0.4616 smmd=0.1365 ct=7.5091 rec=1.3152 | train/val/test=0.839/0.845/0.844 | c=0.998437
[Epoch 0048] loss=17.2914 cls=0.4604 smmd=0.1409 ct=7.4969 rec=1.3166 | train/val/test=0.833/0.833/0.842 | c=0.998437
[Epoch 0049] loss=17.2143 cls=0.4647 smmd=0.1337 ct=7.4938 rec=1.3147 | train/val/test=0.840/0.845/0.843 | c=0.998437
[Epoch 0050] loss=17.1865 cls=0.4615 smmd=0.1293 ct=7.5020 rec=1.3185 | train/val/test=0.835/0.840/0.843 | c=0.998437
[Epoch 0051] loss=17.1337 cls=0.4627 smmd=0.1250 ct=7.4969 rec=1.3164 | train/val/test=0.838/0.841/0.844 | c=0.998437
[Epoch 0052] loss=17.0866 cls=0.4628 smmd=0.1200 ct=7.4982 rec=1.3178 | train/val/test=0.837/0.842/0.844 | c=0.998437
[Epoch 0053] loss=17.0683 cls=0.4643 smmd=0.1195 ct=7.4913 rec=1.3177 | train/val/test=0.835/0.842/0.843 | c=0.998437
[Epoch 0054] loss=17.1279 cls=0.4645 smmd=0.1248 ct=7.4943 rec=1.3186 | train/val/test=0.838/0.842/0.845 | c=0.998437
[Epoch 0055] loss=17.0924 cls=0.4660 smmd=0.1213 ct=7.4933 rec=1.3192 | train/val/test=0.835/0.842/0.842 | c=0.998437
[Epoch 0056] loss=16.9879 cls=0.4669 smmd=0.1112 ct=7.4917 rec=1.3188 | train/val/test=0.839/0.845/0.847 | c=0.998437
[Epoch 0057] loss=16.9606 cls=0.4671 smmd=0.1101 ct=7.4830 rec=1.3204 | train/val/test=0.835/0.839/0.843 | c=0.998437
[Epoch 0058] loss=16.9976 cls=0.4703 smmd=0.1119 ct=7.4921 rec=1.3191 | train/val/test=0.840/0.846/0.847 | c=0.998437
[Epoch 0059] loss=16.9876 cls=0.4684 smmd=0.1122 ct=7.4853 rec=1.3218 | train/val/test=0.835/0.839/0.842 | c=0.998437
[Epoch 0060] loss=17.0362 cls=0.4721 smmd=0.1186 ct=7.4769 rec=1.3203 | train/val/test=0.840/0.845/0.847 | c=0.998437
[Epoch 0061] loss=17.0842 cls=0.4705 smmd=0.1199 ct=7.4943 rec=1.3230 | train/val/test=0.832/0.837/0.842 | c=0.998437
[Epoch 0062] loss=17.0719 cls=0.4764 smmd=0.1223 ct=7.4753 rec=1.3209 | train/val/test=0.838/0.845/0.841 | c=0.998437
[Epoch 0063] loss=17.0433 cls=0.4738 smmd=0.1187 ct=7.4785 rec=1.3251 | train/val/test=0.825/0.829/0.839 | c=0.998437
[Epoch 0064] loss=17.0591 cls=0.4856 smmd=0.1197 ct=7.4793 rec=1.3226 | train/val/test=0.832/0.839/0.829 | c=0.998437
[Epoch 0065] loss=17.1677 cls=0.4874 smmd=0.1305 ct=7.4772 rec=1.3298 | train/val/test=0.813/0.813/0.822 | c=0.998437
[Epoch 0066] loss=17.2203 cls=0.5067 smmd=0.1344 ct=7.4796 rec=1.3282 | train/val/test=0.811/0.815/0.811 | c=0.998437
[Epoch 0067] loss=17.3053 cls=0.5147 smmd=0.1432 ct=7.4733 rec=1.3377 | train/val/test=0.801/0.804/0.809 | c=0.998437
[Epoch 0068] loss=17.4357 cls=0.5317 smmd=0.1540 ct=7.4815 rec=1.3332 | train/val/test=0.812/0.821/0.814 | c=0.998437
[Epoch 0069] loss=17.3520 cls=0.5090 smmd=0.1489 ct=7.4700 rec=1.3361 | train/val/test=0.816/0.816/0.830 | c=0.998437
[Epoch 0070] loss=17.2336 cls=0.4994 smmd=0.1392 ct=7.4649 rec=1.3240 | train/val/test=0.835/0.842/0.838 | c=0.998437
[Epoch 0071] loss=17.1162 cls=0.4707 smmd=0.1311 ct=7.4543 rec=1.3222 | train/val/test=0.835/0.837/0.842 | c=0.998437
[Epoch 0072] loss=16.9578 cls=0.4704 smmd=0.1164 ct=7.4496 rec=1.3193 | train/val/test=0.834/0.839/0.842 | c=0.998437
[Epoch 0073] loss=16.9173 cls=0.4719 smmd=0.1114 ct=7.4531 rec=1.3225 | train/val/test=0.839/0.843/0.844 | c=0.998437
[Epoch 0074] loss=16.9771 cls=0.4755 smmd=0.1176 ct=7.4504 rec=1.3260 | train/val/test=0.830/0.836/0.840 | c=0.998437
[Epoch 0075] loss=17.0074 cls=0.4913 smmd=0.1192 ct=7.4526 rec=1.3297 | train/val/test=0.836/0.842/0.841 | c=0.998437
[Epoch 0076] loss=17.0149 cls=0.4884 smmd=0.1196 ct=7.4542 rec=1.3336 | train/val/test=0.822/0.823/0.833 | c=0.998437
[Epoch 0077] loss=17.1000 cls=0.5097 smmd=0.1260 ct=7.4583 rec=1.3368 | train/val/test=0.829/0.837/0.828 | c=0.998437
[Epoch 0078] loss=17.1936 cls=0.5040 smmd=0.1368 ct=7.4518 rec=1.3392 | train/val/test=0.812/0.813/0.819 | c=0.998437
[Epoch 0079] loss=17.2228 cls=0.5231 smmd=0.1367 ct=7.4627 rec=1.3388 | train/val/test=0.813/0.819/0.814 | c=0.998437
[Epoch 0080] loss=17.2809 cls=0.5170 smmd=0.1455 ct=7.4485 rec=1.3417 | train/val/test=0.809/0.809/0.818 | c=0.998437
[Epoch 0081] loss=17.2465 cls=0.5206 smmd=0.1396 ct=7.4614 rec=1.3340 | train/val/test=0.823/0.829/0.818 | c=0.998437
[Epoch 0082] loss=17.1224 cls=0.5004 smmd=0.1326 ct=7.4399 rec=1.3334 | train/val/test=0.824/0.824/0.833 | c=0.998437
[Epoch 0083] loss=16.9797 cls=0.4846 smmd=0.1202 ct=7.4372 rec=1.3215 | train/val/test=0.837/0.843/0.837 | c=0.998437
[Epoch 0084] loss=16.8816 cls=0.4714 smmd=0.1107 ct=7.4391 rec=1.3217 | train/val/test=0.838/0.841/0.843 | c=0.998437
[Epoch 0085] loss=16.8485 cls=0.4736 smmd=0.1102 ct=7.4246 rec=1.3217 | train/val/test=0.833/0.838/0.842 | c=0.998437
[Epoch 0086] loss=16.8433 cls=0.4810 smmd=0.1049 ct=7.4451 rec=1.3267 | train/val/test=0.836/0.842/0.837 | c=0.998437
[Epoch 0087] loss=16.8893 cls=0.4876 smmd=0.1114 ct=7.4329 rec=1.3317 | train/val/test=0.827/0.829/0.832 | c=0.998437
[Epoch 0088] loss=16.9475 cls=0.5025 smmd=0.1137 ct=7.4458 rec=1.3358 | train/val/test=0.834/0.840/0.834 | c=0.998437
[Epoch 0089] loss=17.0480 cls=0.4990 smmd=0.1247 ct=7.4412 rec=1.3388 | train/val/test=0.817/0.816/0.826 | c=0.998437
[Epoch 0090] loss=17.1589 cls=0.5214 smmd=0.1329 ct=7.4495 rec=1.3402 | train/val/test=0.818/0.826/0.815 | c=0.998437
[Epoch 0091] loss=17.2263 cls=0.5152 smmd=0.1402 ct=7.4474 rec=1.3431 | train/val/test=0.798/0.801/0.805 | c=0.998437
[Epoch 0092] loss=17.2930 cls=0.5413 smmd=0.1444 ct=7.4535 rec=1.3420 | train/val/test=0.800/0.804/0.800 | c=0.998437
[Epoch 0093] loss=17.3041 cls=0.5279 smmd=0.1474 ct=7.4474 rec=1.3420 | train/val/test=0.805/0.807/0.813 | c=0.998437
[Epoch 0094] loss=17.2158 cls=0.5189 smmd=0.1406 ct=7.4430 rec=1.3297 | train/val/test=0.829/0.837/0.828 | c=0.998437
[Epoch 0095] loss=16.8759 cls=0.4808 smmd=0.1118 ct=7.4280 rec=1.3232 | train/val/test=0.831/0.836/0.839 | c=0.998437
[Epoch 0096] loss=16.7084 cls=0.4677 smmd=0.0965 ct=7.4263 rec=1.3147 | train/val/test=0.829/0.831/0.837 | c=0.998437
[Epoch 0097] loss=16.7995 cls=0.4737 smmd=0.1056 ct=7.4237 rec=1.3190 | train/val/test=0.833/0.841/0.830 | c=0.998437
[Epoch 0098] loss=16.8748 cls=0.4861 smmd=0.1104 ct=7.4317 rec=1.3278 | train/val/test=0.813/0.812/0.821 | c=0.998437
[Epoch 0099] loss=16.9841 cls=0.5177 smmd=0.1165 ct=7.4456 rec=1.3376 | train/val/test=0.821/0.829/0.820 | c=0.998437
=== Best @ epoch 45: val=0.8463, test=0.8410 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-3 - 2025-09-21 03:22:04:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-3...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-3 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Photo
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=71.6458 cls=1.1186 smmd=5.5864 ct=7.2579 rec=1.4138 | train/val/test=0.396/0.401/0.400 | c=0.998437
[Epoch 0001] loss=51.9751 cls=1.0662 smmd=3.6325 ct=7.2047 rec=1.4146 | train/val/test=0.354/0.353/0.353 | c=0.998437
[Epoch 0002] loss=38.1529 cls=1.0926 smmd=2.2585 ct=7.1576 rec=1.4135 | train/val/test=0.586/0.592/0.585 | c=0.998437
[Epoch 0003] loss=40.4399 cls=1.0603 smmd=2.4977 ct=7.1131 rec=1.4136 | train/val/test=0.560/0.558/0.559 | c=0.998437
[Epoch 0004] loss=39.8065 cls=1.0233 smmd=2.4437 ct=7.0750 rec=1.4159 | train/val/test=0.558/0.560/0.559 | c=0.998437
[Epoch 0005] loss=35.3142 cls=1.0016 smmd=2.0064 ct=7.0200 rec=1.4182 | train/val/test=0.550/0.555/0.554 | c=0.998437
[Epoch 0006] loss=30.5562 cls=0.9773 smmd=1.5423 ct=6.9676 rec=1.4180 | train/val/test=0.555/0.555/0.557 | c=0.998437
[Epoch 0007] loss=33.2225 cls=0.9403 smmd=1.8170 ct=6.9375 rec=1.4137 | train/val/test=0.562/0.564/0.562 | c=0.998437
[Epoch 0008] loss=34.0070 cls=0.8979 smmd=1.9023 ct=6.9157 rec=1.4063 | train/val/test=0.596/0.602/0.605 | c=0.998437
[Epoch 0009] loss=27.8579 cls=0.8579 smmd=1.2965 ct=6.8826 rec=1.3980 | train/val/test=0.595/0.592/0.599 | c=0.998437
[Epoch 0010] loss=27.8049 cls=0.8304 smmd=1.1509 ct=7.5922 rec=1.3918 | train/val/test=0.630/0.636/0.633 | c=0.998437
[Epoch 0011] loss=30.4051 cls=0.8007 smmd=1.4218 ct=7.5475 rec=1.3839 | train/val/test=0.686/0.693/0.695 | c=0.998437
[Epoch 0012] loss=27.2518 cls=0.7635 smmd=1.1206 ct=7.4895 rec=1.3706 | train/val/test=0.693/0.699/0.703 | c=0.998437
[Epoch 0013] loss=26.0549 cls=0.7442 smmd=0.9945 ct=7.5286 rec=1.3620 | train/val/test=0.705/0.711/0.710 | c=0.998437
[Epoch 0014] loss=25.6205 cls=0.7157 smmd=0.9439 ct=7.5726 rec=1.3572 | train/val/test=0.710/0.712/0.711 | c=0.998437
[Epoch 0015] loss=25.3693 cls=0.7002 smmd=0.9253 ct=7.5442 rec=1.3559 | train/val/test=0.722/0.725/0.725 | c=0.998437
[Epoch 0016] loss=24.6891 cls=0.6818 smmd=0.8607 ct=7.5329 rec=1.3504 | train/val/test=0.727/0.735/0.736 | c=0.998437
[Epoch 0017] loss=22.9385 cls=0.6698 smmd=0.6897 ct=7.5177 rec=1.3413 | train/val/test=0.730/0.732/0.736 | c=0.998437
[Epoch 0018] loss=23.9039 cls=0.6554 smmd=0.7828 ct=7.5392 rec=1.3387 | train/val/test=0.746/0.751/0.755 | c=0.998437
[Epoch 0019] loss=22.6298 cls=0.6224 smmd=0.6510 ct=7.5695 rec=1.3384 | train/val/test=0.757/0.759/0.761 | c=0.998437
[Epoch 0020] loss=21.9469 cls=0.6114 smmd=0.5809 ct=7.5819 rec=1.3367 | train/val/test=0.769/0.767/0.775 | c=0.998437
[Epoch 0021] loss=22.1168 cls=0.6004 smmd=0.6073 ct=7.5390 rec=1.3318 | train/val/test=0.778/0.780/0.781 | c=0.998437
[Epoch 0022] loss=21.3459 cls=0.5848 smmd=0.5400 ct=7.4949 rec=1.3283 | train/val/test=0.787/0.791/0.796 | c=0.998437
[Epoch 0023] loss=20.9651 cls=0.5673 smmd=0.4946 ct=7.5358 rec=1.3268 | train/val/test=0.800/0.803/0.809 | c=0.998437
[Epoch 0024] loss=20.7384 cls=0.5479 smmd=0.4682 ct=7.5595 rec=1.3264 | train/val/test=0.802/0.802/0.807 | c=0.998437
[Epoch 0025] loss=20.3557 cls=0.5335 smmd=0.4296 ct=7.5656 rec=1.3230 | train/val/test=0.801/0.803/0.809 | c=0.998437
[Epoch 0026] loss=20.0739 cls=0.5261 smmd=0.4040 ct=7.5554 rec=1.3209 | train/val/test=0.815/0.818/0.825 | c=0.998437
[Epoch 0027] loss=19.8166 cls=0.5139 smmd=0.3873 ct=7.5132 rec=1.3197 | train/val/test=0.818/0.824/0.823 | c=0.998437
[Epoch 0028] loss=19.6456 cls=0.5133 smmd=0.3701 ct=7.5143 rec=1.3194 | train/val/test=0.820/0.825/0.828 | c=0.998437
[Epoch 0029] loss=19.2615 cls=0.4924 smmd=0.3271 ct=7.5430 rec=1.3165 | train/val/test=0.819/0.824/0.829 | c=0.998437
[Epoch 0030] loss=19.1623 cls=0.4869 smmd=0.3153 ct=7.5543 rec=1.3142 | train/val/test=0.823/0.830/0.833 | c=0.998437
[Epoch 0031] loss=18.9068 cls=0.4802 smmd=0.2938 ct=7.5359 rec=1.3126 | train/val/test=0.829/0.837/0.834 | c=0.998437
[Epoch 0032] loss=18.7402 cls=0.4750 smmd=0.2803 ct=7.5213 rec=1.3143 | train/val/test=0.826/0.833/0.834 | c=0.998437
[Epoch 0033] loss=18.6818 cls=0.4737 smmd=0.2764 ct=7.5132 rec=1.3098 | train/val/test=0.828/0.835/0.836 | c=0.998437
[Epoch 0034] loss=18.3933 cls=0.4662 smmd=0.2463 ct=7.5209 rec=1.3100 | train/val/test=0.826/0.832/0.836 | c=0.998437
[Epoch 0035] loss=18.3462 cls=0.4625 smmd=0.2379 ct=7.5404 rec=1.3107 | train/val/test=0.832/0.839/0.840 | c=0.998437
[Epoch 0036] loss=18.0447 cls=0.4623 smmd=0.2140 ct=7.5092 rec=1.3096 | train/val/test=0.833/0.839/0.842 | c=0.998437
[Epoch 0037] loss=18.1213 cls=0.4610 smmd=0.2227 ct=7.5044 rec=1.3099 | train/val/test=0.831/0.836/0.843 | c=0.998437
[Epoch 0038] loss=17.9694 cls=0.4575 smmd=0.2028 ct=7.5289 rec=1.3105 | train/val/test=0.833/0.837/0.843 | c=0.998437
[Epoch 0039] loss=17.9418 cls=0.4584 smmd=0.2030 ct=7.5137 rec=1.3106 | train/val/test=0.832/0.836/0.844 | c=0.998437
[Epoch 0040] loss=17.7051 cls=0.4584 smmd=0.1805 ct=7.5073 rec=1.3120 | train/val/test=0.839/0.840/0.843 | c=0.998437
[Epoch 0041] loss=17.7263 cls=0.4622 smmd=0.1831 ct=7.5041 rec=1.3131 | train/val/test=0.835/0.837/0.845 | c=0.998437
[Epoch 0042] loss=17.5640 cls=0.4597 smmd=0.1643 ct=7.5170 rec=1.3135 | train/val/test=0.834/0.841/0.841 | c=0.998437
[Epoch 0043] loss=17.5819 cls=0.4599 smmd=0.1650 ct=7.5219 rec=1.3154 | train/val/test=0.837/0.842/0.845 | c=0.998437
[Epoch 0044] loss=17.4938 cls=0.4611 smmd=0.1612 ct=7.4968 rec=1.3143 | train/val/test=0.835/0.837/0.843 | c=0.998437
[Epoch 0045] loss=17.3873 cls=0.4623 smmd=0.1498 ct=7.5006 rec=1.3141 | train/val/test=0.839/0.846/0.841 | c=0.998437
[Epoch 0046] loss=17.3539 cls=0.4606 smmd=0.1447 ct=7.5091 rec=1.3168 | train/val/test=0.832/0.834/0.841 | c=0.998437
[Epoch 0047] loss=17.2717 cls=0.4616 smmd=0.1365 ct=7.5091 rec=1.3152 | train/val/test=0.839/0.845/0.844 | c=0.998437
[Epoch 0048] loss=17.2914 cls=0.4604 smmd=0.1409 ct=7.4969 rec=1.3166 | train/val/test=0.833/0.833/0.842 | c=0.998437
[Epoch 0049] loss=17.2143 cls=0.4647 smmd=0.1337 ct=7.4938 rec=1.3147 | train/val/test=0.840/0.845/0.843 | c=0.998437
[Epoch 0050] loss=17.1865 cls=0.4615 smmd=0.1293 ct=7.5020 rec=1.3185 | train/val/test=0.835/0.840/0.843 | c=0.998437
[Epoch 0051] loss=17.1337 cls=0.4627 smmd=0.1250 ct=7.4969 rec=1.3164 | train/val/test=0.838/0.841/0.844 | c=0.998437
[Epoch 0052] loss=17.0866 cls=0.4628 smmd=0.1200 ct=7.4982 rec=1.3178 | train/val/test=0.837/0.842/0.844 | c=0.998437
[Epoch 0053] loss=17.0683 cls=0.4643 smmd=0.1195 ct=7.4913 rec=1.3177 | train/val/test=0.835/0.842/0.843 | c=0.998437
[Epoch 0054] loss=17.1279 cls=0.4645 smmd=0.1248 ct=7.4943 rec=1.3186 | train/val/test=0.838/0.842/0.845 | c=0.998437
[Epoch 0055] loss=17.0924 cls=0.4660 smmd=0.1213 ct=7.4933 rec=1.3192 | train/val/test=0.835/0.842/0.842 | c=0.998437
[Epoch 0056] loss=16.9879 cls=0.4669 smmd=0.1112 ct=7.4917 rec=1.3188 | train/val/test=0.839/0.845/0.847 | c=0.998437
[Epoch 0057] loss=16.9606 cls=0.4671 smmd=0.1101 ct=7.4830 rec=1.3204 | train/val/test=0.835/0.839/0.843 | c=0.998437
[Epoch 0058] loss=16.9976 cls=0.4703 smmd=0.1119 ct=7.4921 rec=1.3191 | train/val/test=0.840/0.846/0.847 | c=0.998437
[Epoch 0059] loss=16.9876 cls=0.4684 smmd=0.1122 ct=7.4853 rec=1.3218 | train/val/test=0.835/0.839/0.842 | c=0.998437
[Epoch 0060] loss=17.0362 cls=0.4721 smmd=0.1186 ct=7.4769 rec=1.3203 | train/val/test=0.840/0.845/0.847 | c=0.998437
[Epoch 0061] loss=17.0842 cls=0.4705 smmd=0.1199 ct=7.4943 rec=1.3230 | train/val/test=0.832/0.837/0.842 | c=0.998437
[Epoch 0062] loss=17.0719 cls=0.4764 smmd=0.1223 ct=7.4753 rec=1.3209 | train/val/test=0.838/0.845/0.841 | c=0.998437
[Epoch 0063] loss=17.0433 cls=0.4738 smmd=0.1187 ct=7.4785 rec=1.3251 | train/val/test=0.825/0.829/0.839 | c=0.998437
[Epoch 0064] loss=17.0591 cls=0.4856 smmd=0.1197 ct=7.4793 rec=1.3226 | train/val/test=0.832/0.839/0.829 | c=0.998437
[Epoch 0065] loss=17.1677 cls=0.4874 smmd=0.1305 ct=7.4772 rec=1.3298 | train/val/test=0.813/0.813/0.822 | c=0.998437
[Epoch 0066] loss=17.2203 cls=0.5067 smmd=0.1344 ct=7.4796 rec=1.3282 | train/val/test=0.811/0.815/0.811 | c=0.998437
[Epoch 0067] loss=17.3053 cls=0.5147 smmd=0.1432 ct=7.4733 rec=1.3377 | train/val/test=0.801/0.804/0.809 | c=0.998437
[Epoch 0068] loss=17.4357 cls=0.5317 smmd=0.1540 ct=7.4815 rec=1.3332 | train/val/test=0.812/0.821/0.814 | c=0.998437
[Epoch 0069] loss=17.3520 cls=0.5090 smmd=0.1489 ct=7.4700 rec=1.3361 | train/val/test=0.816/0.816/0.830 | c=0.998437
[Epoch 0070] loss=17.2336 cls=0.4994 smmd=0.1392 ct=7.4649 rec=1.3240 | train/val/test=0.835/0.842/0.838 | c=0.998437
[Epoch 0071] loss=17.1162 cls=0.4707 smmd=0.1311 ct=7.4543 rec=1.3222 | train/val/test=0.835/0.837/0.842 | c=0.998437
[Epoch 0072] loss=16.9578 cls=0.4704 smmd=0.1164 ct=7.4496 rec=1.3193 | train/val/test=0.834/0.839/0.842 | c=0.998437
[Epoch 0073] loss=16.9173 cls=0.4719 smmd=0.1114 ct=7.4531 rec=1.3225 | train/val/test=0.839/0.843/0.844 | c=0.998437
[Epoch 0074] loss=16.9771 cls=0.4755 smmd=0.1176 ct=7.4504 rec=1.3260 | train/val/test=0.830/0.836/0.840 | c=0.998437
[Epoch 0075] loss=17.0074 cls=0.4913 smmd=0.1192 ct=7.4526 rec=1.3297 | train/val/test=0.836/0.842/0.841 | c=0.998437
[Epoch 0076] loss=17.0149 cls=0.4884 smmd=0.1196 ct=7.4542 rec=1.3336 | train/val/test=0.822/0.823/0.833 | c=0.998437
[Epoch 0077] loss=17.1000 cls=0.5097 smmd=0.1260 ct=7.4583 rec=1.3368 | train/val/test=0.829/0.837/0.828 | c=0.998437
[Epoch 0078] loss=17.1936 cls=0.5040 smmd=0.1368 ct=7.4518 rec=1.3392 | train/val/test=0.812/0.813/0.819 | c=0.998437
[Epoch 0079] loss=17.2228 cls=0.5231 smmd=0.1367 ct=7.4627 rec=1.3388 | train/val/test=0.813/0.819/0.814 | c=0.998437
[Epoch 0080] loss=17.2809 cls=0.5170 smmd=0.1455 ct=7.4485 rec=1.3417 | train/val/test=0.809/0.809/0.818 | c=0.998437
[Epoch 0081] loss=17.2465 cls=0.5206 smmd=0.1396 ct=7.4614 rec=1.3340 | train/val/test=0.823/0.829/0.818 | c=0.998437
[Epoch 0082] loss=17.1224 cls=0.5004 smmd=0.1326 ct=7.4399 rec=1.3334 | train/val/test=0.824/0.824/0.833 | c=0.998437
[Epoch 0083] loss=16.9797 cls=0.4846 smmd=0.1202 ct=7.4372 rec=1.3215 | train/val/test=0.837/0.843/0.837 | c=0.998437
[Epoch 0084] loss=16.8816 cls=0.4714 smmd=0.1107 ct=7.4391 rec=1.3217 | train/val/test=0.838/0.841/0.843 | c=0.998437
[Epoch 0085] loss=16.8485 cls=0.4736 smmd=0.1102 ct=7.4246 rec=1.3217 | train/val/test=0.833/0.838/0.842 | c=0.998437
[Epoch 0086] loss=16.8433 cls=0.4810 smmd=0.1049 ct=7.4451 rec=1.3267 | train/val/test=0.836/0.842/0.837 | c=0.998437
[Epoch 0087] loss=16.8893 cls=0.4876 smmd=0.1114 ct=7.4329 rec=1.3317 | train/val/test=0.827/0.829/0.832 | c=0.998437
[Epoch 0088] loss=16.9475 cls=0.5025 smmd=0.1137 ct=7.4458 rec=1.3358 | train/val/test=0.834/0.840/0.834 | c=0.998437
[Epoch 0089] loss=17.0480 cls=0.4990 smmd=0.1247 ct=7.4412 rec=1.3388 | train/val/test=0.817/0.816/0.826 | c=0.998437
[Epoch 0090] loss=17.1589 cls=0.5214 smmd=0.1329 ct=7.4495 rec=1.3402 | train/val/test=0.818/0.826/0.815 | c=0.998437
[Epoch 0091] loss=17.2263 cls=0.5152 smmd=0.1402 ct=7.4474 rec=1.3431 | train/val/test=0.798/0.801/0.805 | c=0.998437
[Epoch 0092] loss=17.2930 cls=0.5413 smmd=0.1444 ct=7.4535 rec=1.3420 | train/val/test=0.800/0.804/0.800 | c=0.998437
[Epoch 0093] loss=17.3041 cls=0.5279 smmd=0.1474 ct=7.4474 rec=1.3420 | train/val/test=0.805/0.807/0.813 | c=0.998437
[Epoch 0094] loss=17.2158 cls=0.5189 smmd=0.1406 ct=7.4430 rec=1.3297 | train/val/test=0.829/0.837/0.828 | c=0.998437
[Epoch 0095] loss=16.8759 cls=0.4808 smmd=0.1118 ct=7.4280 rec=1.3232 | train/val/test=0.831/0.836/0.839 | c=0.998437
[Epoch 0096] loss=16.7084 cls=0.4677 smmd=0.0965 ct=7.4263 rec=1.3147 | train/val/test=0.829/0.831/0.837 | c=0.998437
[Epoch 0097] loss=16.7995 cls=0.4737 smmd=0.1056 ct=7.4237 rec=1.3190 | train/val/test=0.833/0.841/0.830 | c=0.998437
[Epoch 0098] loss=16.8748 cls=0.4861 smmd=0.1104 ct=7.4317 rec=1.3278 | train/val/test=0.813/0.812/0.821 | c=0.998437
[Epoch 0099] loss=16.9841 cls=0.5177 smmd=0.1165 ct=7.4456 rec=1.3376 | train/val/test=0.821/0.829/0.820 | c=0.998437
=== Best @ epoch 45: val=0.8463, test=0.8410 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Photo.GRACE.GAT.hyp_True.True.20250912-232537.pth-False-5-3 completed in 147.47 seconds.
==================================================
