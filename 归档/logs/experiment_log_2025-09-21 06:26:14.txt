Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-5 - 2025-09-21 06:26:14:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-5...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.8718 cls=1.7910 smmd=4.1220 ct=9.4688 rec=1.3917 | train/val/test=0.140/0.212/0.231 | c=0.998347
[Epoch 0001] loss=37.6245 cls=1.7857 smmd=3.8811 ct=9.4668 rec=1.3917 | train/val/test=0.260/0.072/0.107 | c=0.998347
[Epoch 0002] loss=36.3709 cls=1.7703 smmd=2.9599 ct=9.3046 rec=1.3917 | train/val/test=0.560/0.292/0.328 | c=0.998347
[Epoch 0003] loss=35.3932 cls=1.7424 smmd=2.3739 ct=9.1161 rec=1.3916 | train/val/test=0.440/0.320/0.376 | c=0.998347
[Epoch 0004] loss=35.1006 cls=1.7001 smmd=2.1519 ct=9.0924 rec=1.3914 | train/val/test=0.680/0.570/0.586 | c=0.998347
[Epoch 0005] loss=34.6641 cls=1.6459 smmd=1.8749 ct=9.0291 rec=1.3908 | train/val/test=0.760/0.592/0.619 | c=0.998347
[Epoch 0006] loss=34.4740 cls=1.5866 smmd=1.7468 ct=9.0180 rec=1.3898 | train/val/test=0.720/0.584/0.627 | c=0.998347
[Epoch 0007] loss=34.1921 cls=1.5257 smmd=1.5237 ct=9.0103 rec=1.3885 | train/val/test=0.720/0.604/0.626 | c=0.998347
[Epoch 0008] loss=35.3508 cls=1.4661 smmd=1.3480 ct=9.6996 rec=1.3871 | train/val/test=0.740/0.616/0.653 | c=0.998347
[Epoch 0009] loss=35.1366 cls=1.4143 smmd=1.4080 ct=9.5834 rec=1.3855 | train/val/test=0.740/0.616/0.653 | c=0.998347
[Epoch 0010] loss=35.0935 cls=1.3745 smmd=1.6135 ct=9.4750 rec=1.3843 | train/val/test=0.740/0.624/0.669 | c=0.998347
[Epoch 0011] loss=34.9722 cls=1.3333 smmd=1.5982 ct=9.4362 rec=1.3835 | train/val/test=0.780/0.638/0.656 | c=0.998347
[Epoch 0012] loss=34.7728 cls=1.2837 smmd=1.3555 ct=9.4730 rec=1.3830 | train/val/test=0.780/0.642/0.652 | c=0.998347
[Epoch 0013] loss=34.6942 cls=1.2407 smmd=1.1072 ct=9.5701 rec=1.3826 | train/val/test=0.760/0.656/0.665 | c=0.998347
[Epoch 0014] loss=34.4913 cls=1.2006 smmd=0.8367 ct=9.6161 rec=1.3822 | train/val/test=0.820/0.642/0.632 | c=0.998347
[Epoch 0015] loss=34.4354 cls=1.1481 smmd=0.8784 ct=9.5834 rec=1.3816 | train/val/test=0.820/0.638/0.631 | c=0.998347
[Epoch 0016] loss=34.3646 cls=1.0966 smmd=0.9749 ct=9.5189 rec=1.3804 | train/val/test=0.840/0.666/0.641 | c=0.998347
[Epoch 0017] loss=34.1898 cls=1.0430 smmd=0.9210 ct=9.4819 rec=1.3784 | train/val/test=0.860/0.660/0.639 | c=0.998347
[Epoch 0018] loss=34.1437 cls=0.9781 smmd=0.8767 ct=9.5104 rec=1.3757 | train/val/test=0.900/0.658/0.630 | c=0.998347
[Epoch 0019] loss=34.0431 cls=0.9245 smmd=0.7746 ct=9.5415 rec=1.3723 | train/val/test=0.860/0.666/0.640 | c=0.998347
[Epoch 0020] loss=33.8637 cls=0.8599 smmd=0.6055 ct=9.5750 rec=1.3678 | train/val/test=0.920/0.662/0.637 | c=0.998347
[Epoch 0021] loss=33.8016 cls=0.8056 smmd=0.6079 ct=9.5816 rec=1.3628 | train/val/test=0.940/0.668/0.641 | c=0.998347
[Epoch 0022] loss=33.6599 cls=0.7555 smmd=0.5878 ct=9.5637 rec=1.3567 | train/val/test=0.940/0.674/0.645 | c=0.998347
[Epoch 0023] loss=33.5565 cls=0.7084 smmd=0.6015 ct=9.5498 rec=1.3501 | train/val/test=0.940/0.670/0.654 | c=0.998347
[Epoch 0024] loss=33.4793 cls=0.6702 smmd=0.6006 ct=9.5535 rec=1.3437 | train/val/test=0.940/0.680/0.649 | c=0.998347
[Epoch 0025] loss=33.3479 cls=0.6307 smmd=0.5267 ct=9.5717 rec=1.3362 | train/val/test=0.940/0.676/0.658 | c=0.998347
[Epoch 0026] loss=33.2308 cls=0.5987 smmd=0.4748 ct=9.5818 rec=1.3293 | train/val/test=0.960/0.676/0.666 | c=0.998347
[Epoch 0027] loss=33.1494 cls=0.5688 smmd=0.4643 ct=9.5868 rec=1.3227 | train/val/test=0.940/0.676/0.669 | c=0.998347
[Epoch 0028] loss=33.0412 cls=0.5405 smmd=0.4352 ct=9.5878 rec=1.3160 | train/val/test=0.960/0.682/0.676 | c=0.998347
[Epoch 0029] loss=32.9675 cls=0.5187 smmd=0.4618 ct=9.5732 rec=1.3100 | train/val/test=0.960/0.692/0.680 | c=0.998347
[Epoch 0030] loss=32.8726 cls=0.4880 smmd=0.4558 ct=9.5702 rec=1.3032 | train/val/test=0.960/0.692/0.681 | c=0.998347
[Epoch 0031] loss=32.7775 cls=0.4659 smmd=0.4119 ct=9.5811 rec=1.2970 | train/val/test=0.960/0.690/0.683 | c=0.998347
[Epoch 0032] loss=32.6993 cls=0.4418 smmd=0.3885 ct=9.5930 rec=1.2904 | train/val/test=0.960/0.698/0.690 | c=0.998347
[Epoch 0033] loss=32.5938 cls=0.4206 smmd=0.3648 ct=9.5900 rec=1.2839 | train/val/test=0.960/0.694/0.704 | c=0.998347
[Epoch 0034] loss=32.5069 cls=0.3996 smmd=0.3748 ct=9.5830 rec=1.2766 | train/val/test=0.940/0.692/0.707 | c=0.998347
[Epoch 0035] loss=32.4313 cls=0.3791 smmd=0.3858 ct=9.5806 rec=1.2695 | train/val/test=0.960/0.696/0.713 | c=0.998347
[Epoch 0036] loss=32.3546 cls=0.3619 smmd=0.3817 ct=9.5815 rec=1.2629 | train/val/test=0.940/0.696/0.710 | c=0.998347
[Epoch 0037] loss=32.2820 cls=0.3423 smmd=0.3707 ct=9.5891 rec=1.2562 | train/val/test=0.940/0.702/0.717 | c=0.998347
[Epoch 0038] loss=32.2115 cls=0.3325 smmd=0.3573 ct=9.5911 rec=1.2506 | train/val/test=0.940/0.694/0.711 | c=0.998347
[Epoch 0039] loss=32.1563 cls=0.3146 smmd=0.3623 ct=9.5956 rec=1.2445 | train/val/test=0.960/0.708/0.715 | c=0.998347
[Epoch 0040] loss=32.0822 cls=0.3104 smmd=0.3568 ct=9.5823 rec=1.2406 | train/val/test=0.940/0.688/0.700 | c=0.998347
[Epoch 0041] loss=32.0601 cls=0.2904 smmd=0.3757 ct=9.5938 rec=1.2352 | train/val/test=0.980/0.716/0.712 | c=0.998347
[Epoch 0042] loss=32.0384 cls=0.3001 smmd=0.3760 ct=9.5883 rec=1.2336 | train/val/test=0.940/0.684/0.686 | c=0.998347
[Epoch 0043] loss=32.0542 cls=0.2728 smmd=0.3798 ct=9.6215 rec=1.2295 | train/val/test=0.980/0.718/0.698 | c=0.998347
[Epoch 0044] loss=32.0588 cls=0.3006 smmd=0.4179 ct=9.5975 rec=1.2296 | train/val/test=0.940/0.686/0.690 | c=0.998347
[Epoch 0045] loss=31.9663 cls=0.2507 smmd=0.4082 ct=9.6163 rec=1.2200 | train/val/test=0.980/0.718/0.711 | c=0.998347
[Epoch 0046] loss=31.8031 cls=0.2410 smmd=0.3609 ct=9.5944 rec=1.2133 | train/val/test=0.980/0.716/0.713 | c=0.998347
[Epoch 0047] loss=31.7732 cls=0.2374 smmd=0.3576 ct=9.5946 rec=1.2108 | train/val/test=0.940/0.692/0.696 | c=0.998347
[Epoch 0048] loss=31.8178 cls=0.2196 smmd=0.3766 ct=9.6149 rec=1.2102 | train/val/test=0.960/0.720/0.710 | c=0.998347
[Epoch 0049] loss=31.7643 cls=0.2323 smmd=0.3613 ct=9.5960 rec=1.2095 | train/val/test=0.980/0.700/0.706 | c=0.998347
[Epoch 0050] loss=31.6874 cls=0.2108 smmd=0.3295 ct=9.6013 rec=1.2050 | train/val/test=0.980/0.704/0.708 | c=0.998347
[Epoch 0051] loss=31.6613 cls=0.2021 smmd=0.3229 ct=9.5980 rec=1.2041 | train/val/test=0.980/0.706/0.700 | c=0.998347
[Epoch 0052] loss=31.6881 cls=0.2200 smmd=0.3317 ct=9.5934 rec=1.2060 | train/val/test=0.980/0.692/0.689 | c=0.998347
[Epoch 0053] loss=31.7419 cls=0.1932 smmd=0.3450 ct=9.6154 rec=1.2070 | train/val/test=0.960/0.716/0.712 | c=0.998347
[Epoch 0054] loss=31.7955 cls=0.2354 smmd=0.3888 ct=9.5980 rec=1.2093 | train/val/test=0.980/0.686/0.688 | c=0.998347
[Epoch 0055] loss=31.7637 cls=0.1843 smmd=0.3806 ct=9.6290 rec=1.2033 | train/val/test=0.980/0.710/0.704 | c=0.998347
[Epoch 0056] loss=31.5925 cls=0.1891 smmd=0.3559 ct=9.5982 rec=1.1946 | train/val/test=0.980/0.704/0.700 | c=0.998347
[Epoch 0057] loss=31.5496 cls=0.1880 smmd=0.3500 ct=9.6023 rec=1.1901 | train/val/test=0.980/0.686/0.693 | c=0.998347
[Epoch 0058] loss=31.6455 cls=0.1576 smmd=0.3904 ct=9.6213 rec=1.1934 | train/val/test=0.960/0.700/0.698 | c=0.998347
[Epoch 0059] loss=31.5637 cls=0.1878 smmd=0.3633 ct=9.6019 rec=1.1903 | train/val/test=0.980/0.696/0.707 | c=0.998347
[Epoch 0060] loss=31.4696 cls=0.1601 smmd=0.3308 ct=9.5939 rec=1.1871 | train/val/test=0.980/0.688/0.691 | c=0.998347
[Epoch 0061] loss=31.5713 cls=0.1605 smmd=0.3395 ct=9.6188 rec=1.1914 | train/val/test=0.960/0.706/0.704 | c=0.998347
[Epoch 0062] loss=31.7146 cls=0.2030 smmd=0.3971 ct=9.6015 rec=1.2013 | train/val/test=0.980/0.674/0.689 | c=0.998347
[Epoch 0063] loss=31.7721 cls=0.1813 smmd=0.4142 ct=9.6380 rec=1.1991 | train/val/test=0.960/0.692/0.704 | c=0.998347
[Epoch 0064] loss=31.7005 cls=0.1867 smmd=0.4315 ct=9.6138 rec=1.1948 | train/val/test=0.960/0.698/0.696 | c=0.998347
[Epoch 0065] loss=31.7428 cls=0.2268 smmd=0.4561 ct=9.6314 rec=1.1910 | train/val/test=1.000/0.676/0.687 | c=0.998347
[Epoch 0066] loss=31.6749 cls=0.1381 smmd=0.4683 ct=9.6324 rec=1.1873 | train/val/test=0.980/0.688/0.696 | c=0.998347
[Epoch 0067] loss=31.3644 cls=0.1300 smmd=0.3761 ct=9.6012 rec=1.1721 | train/val/test=0.960/0.704/0.700 | c=0.998347
[Epoch 0068] loss=31.6106 cls=0.1902 smmd=0.4753 ct=9.6139 rec=1.1812 | train/val/test=0.980/0.686/0.701 | c=0.998347
[Epoch 0069] loss=31.4425 cls=0.1271 smmd=0.4226 ct=9.6028 rec=1.1751 | train/val/test=0.980/0.676/0.694 | c=0.998347
[Epoch 0070] loss=31.4350 cls=0.1288 smmd=0.3687 ct=9.6097 rec=1.1782 | train/val/test=0.960/0.702/0.698 | c=0.998347
[Epoch 0071] loss=31.5784 cls=0.1883 smmd=0.3994 ct=9.6058 rec=1.1873 | train/val/test=0.980/0.688/0.698 | c=0.998347
[Epoch 0072] loss=31.3902 cls=0.1342 smmd=0.3304 ct=9.5913 rec=1.1810 | train/val/test=0.980/0.674/0.696 | c=0.998347
[Epoch 0073] loss=31.4510 cls=0.1338 smmd=0.3221 ct=9.6047 rec=1.1853 | train/val/test=0.960/0.696/0.699 | c=0.998347
[Epoch 0074] loss=31.6470 cls=0.2069 smmd=0.3886 ct=9.6177 rec=1.1920 | train/val/test=1.000/0.680/0.696 | c=0.998347
[Epoch 0075] loss=31.5838 cls=0.1538 smmd=0.3981 ct=9.6114 rec=1.1886 | train/val/test=0.980/0.682/0.693 | c=0.998347
[Epoch 0076] loss=31.3918 cls=0.1357 smmd=0.3353 ct=9.6121 rec=1.1765 | train/val/test=0.960/0.698/0.696 | c=0.998347
[Epoch 0077] loss=31.4076 cls=0.1550 smmd=0.3802 ct=9.5982 rec=1.1754 | train/val/test=0.960/0.672/0.694 | c=0.998347
[Epoch 0078] loss=31.3339 cls=0.1222 smmd=0.3510 ct=9.6007 rec=1.1720 | train/val/test=0.980/0.676/0.697 | c=0.998347
[Epoch 0079] loss=31.3314 cls=0.1257 smmd=0.3320 ct=9.6070 rec=1.1722 | train/val/test=0.960/0.694/0.701 | c=0.998347
[Epoch 0080] loss=31.4254 cls=0.1523 smmd=0.3670 ct=9.5964 rec=1.1789 | train/val/test=0.980/0.672/0.698 | c=0.998347
[Epoch 0081] loss=31.3641 cls=0.1243 smmd=0.3213 ct=9.6068 rec=1.1767 | train/val/test=0.980/0.678/0.700 | c=0.998347
[Epoch 0082] loss=31.2821 cls=0.1239 smmd=0.2784 ct=9.5917 rec=1.1758 | train/val/test=0.980/0.686/0.695 | c=0.998347
[Epoch 0083] loss=31.3471 cls=0.1515 smmd=0.2802 ct=9.5979 rec=1.1795 | train/val/test=0.980/0.668/0.694 | c=0.998347
[Epoch 0084] loss=31.4320 cls=0.1291 smmd=0.3077 ct=9.6103 rec=1.1839 | train/val/test=0.960/0.688/0.697 | c=0.998347
[Epoch 0085] loss=31.3810 cls=0.1573 smmd=0.3128 ct=9.5911 rec=1.1807 | train/val/test=0.980/0.674/0.696 | c=0.998347
[Epoch 0086] loss=31.2885 cls=0.1333 smmd=0.2800 ct=9.6062 rec=1.1729 | train/val/test=0.980/0.680/0.700 | c=0.998347
[Epoch 0087] loss=31.2707 cls=0.1280 smmd=0.3072 ct=9.5927 rec=1.1714 | train/val/test=0.960/0.690/0.696 | c=0.998347
[Epoch 0088] loss=31.2964 cls=0.1486 smmd=0.3145 ct=9.5977 rec=1.1712 | train/val/test=0.980/0.674/0.695 | c=0.998347
[Epoch 0089] loss=31.2534 cls=0.1242 smmd=0.2823 ct=9.6016 rec=1.1706 | train/val/test=0.980/0.682/0.696 | c=0.998347
[Epoch 0090] loss=31.2294 cls=0.1227 smmd=0.2777 ct=9.5881 rec=1.1714 | train/val/test=0.980/0.684/0.695 | c=0.998347
[Epoch 0091] loss=31.2750 cls=0.1374 smmd=0.2790 ct=9.5889 rec=1.1750 | train/val/test=0.980/0.672/0.695 | c=0.998347
[Epoch 0092] loss=31.3157 cls=0.1241 smmd=0.2622 ct=9.6099 rec=1.1772 | train/val/test=0.980/0.688/0.695 | c=0.998347
[Epoch 0093] loss=31.3732 cls=0.1432 smmd=0.3209 ct=9.5881 rec=1.1804 | train/val/test=0.980/0.670/0.685 | c=0.998347
[Epoch 0094] loss=31.4824 cls=0.1512 smmd=0.3226 ct=9.6372 rec=1.1810 | train/val/test=0.940/0.684/0.704 | c=0.998347
[Epoch 0095] loss=31.6431 cls=0.1859 smmd=0.4495 ct=9.6130 rec=1.1875 | train/val/test=0.960/0.684/0.692 | c=0.998347
[Epoch 0096] loss=31.7148 cls=0.2222 smmd=0.4829 ct=9.6468 rec=1.1827 | train/val/test=0.960/0.662/0.689 | c=0.998347
[Epoch 0097] loss=31.3681 cls=0.1150 smmd=0.3906 ct=9.6245 rec=1.1671 | train/val/test=0.960/0.676/0.695 | c=0.998347
[Epoch 0098] loss=31.2920 cls=0.1218 smmd=0.4058 ct=9.6006 rec=1.1624 | train/val/test=0.980/0.692/0.699 | c=0.998347
[Epoch 0099] loss=31.4741 cls=0.1657 smmd=0.4720 ct=9.6172 rec=1.1685 | train/val/test=0.980/0.678/0.696 | c=0.998347
[Epoch 0100] loss=31.2192 cls=0.1058 smmd=0.3459 ct=9.6021 rec=1.1616 | train/val/test=0.980/0.664/0.689 | c=0.998347
[Epoch 0101] loss=31.4142 cls=0.1245 smmd=0.3823 ct=9.6131 rec=1.1743 | train/val/test=0.960/0.692/0.696 | c=0.998347
[Epoch 0102] loss=31.5749 cls=0.1792 smmd=0.4206 ct=9.6233 rec=1.1818 | train/val/test=0.980/0.684/0.699 | c=0.998347
[Epoch 0103] loss=31.3350 cls=0.1308 smmd=0.3356 ct=9.5919 rec=1.1750 | train/val/test=1.000/0.662/0.687 | c=0.998347
[Epoch 0104] loss=31.4791 cls=0.1120 smmd=0.3574 ct=9.6334 rec=1.1799 | train/val/test=0.980/0.696/0.696 | c=0.998347
[Epoch 0105] loss=31.4447 cls=0.1563 smmd=0.4049 ct=9.5978 rec=1.1766 | train/val/test=0.980/0.682/0.696 | c=0.998347
[Epoch 0106] loss=31.2207 cls=0.1138 smmd=0.3292 ct=9.5926 rec=1.1649 | train/val/test=0.980/0.664/0.688 | c=0.998347
[Epoch 0107] loss=31.3139 cls=0.1076 smmd=0.3357 ct=9.6263 rec=1.1672 | train/val/test=0.980/0.696/0.695 | c=0.998347
[Epoch 0108] loss=31.2628 cls=0.1369 smmd=0.3470 ct=9.5988 rec=1.1650 | train/val/test=0.980/0.684/0.697 | c=0.998347
[Epoch 0109] loss=31.2445 cls=0.1238 smmd=0.3549 ct=9.5862 rec=1.1655 | train/val/test=0.980/0.662/0.685 | c=0.998347
[Epoch 0110] loss=31.3361 cls=0.1166 smmd=0.3193 ct=9.6250 rec=1.1708 | train/val/test=0.960/0.692/0.694 | c=0.998347
[Epoch 0111] loss=31.2398 cls=0.1353 smmd=0.2816 ct=9.5925 rec=1.1706 | train/val/test=0.980/0.690/0.698 | c=0.998347
[Epoch 0112] loss=31.2443 cls=0.1241 smmd=0.3074 ct=9.5837 rec=1.1707 | train/val/test=0.980/0.670/0.690 | c=0.998347
[Epoch 0113] loss=31.3069 cls=0.1179 smmd=0.2848 ct=9.6185 rec=1.1726 | train/val/test=0.980/0.690/0.697 | c=0.998347
[Epoch 0114] loss=31.2650 cls=0.1357 smmd=0.3005 ct=9.5898 rec=1.1717 | train/val/test=0.980/0.678/0.695 | c=0.998347
[Epoch 0115] loss=31.3007 cls=0.1162 smmd=0.3483 ct=9.5971 rec=1.1700 | train/val/test=0.980/0.672/0.691 | c=0.998347
[Epoch 0116] loss=31.2490 cls=0.1274 smmd=0.2959 ct=9.6088 rec=1.1672 | train/val/test=0.980/0.684/0.694 | c=0.998347
[Epoch 0117] loss=31.1825 cls=0.1302 smmd=0.2832 ct=9.5941 rec=1.1646 | train/val/test=0.980/0.678/0.692 | c=0.998347
[Epoch 0118] loss=31.2583 cls=0.1147 smmd=0.3420 ct=9.5905 rec=1.1678 | train/val/test=0.980/0.682/0.694 | c=0.998347
[Epoch 0119] loss=31.2256 cls=0.1296 smmd=0.2805 ct=9.6084 rec=1.1664 | train/val/test=0.980/0.682/0.695 | c=0.998347
[Epoch 0120] loss=31.1538 cls=0.1214 smmd=0.2562 ct=9.5869 rec=1.1663 | train/val/test=0.980/0.680/0.697 | c=0.998347
[Epoch 0121] loss=31.2469 cls=0.1165 smmd=0.3040 ct=9.5886 rec=1.1708 | train/val/test=0.980/0.684/0.695 | c=0.998347
[Epoch 0122] loss=31.2874 cls=0.1356 smmd=0.2756 ct=9.6075 rec=1.1729 | train/val/test=0.980/0.682/0.695 | c=0.998347
[Epoch 0123] loss=31.2079 cls=0.1136 smmd=0.2699 ct=9.5910 rec=1.1699 | train/val/test=0.980/0.684/0.697 | c=0.998347
[Epoch 0124] loss=31.2221 cls=0.1248 smmd=0.2989 ct=9.5834 rec=1.1694 | train/val/test=0.980/0.676/0.688 | c=0.998347
[Epoch 0125] loss=31.3340 cls=0.1360 smmd=0.2915 ct=9.6314 rec=1.1712 | train/val/test=1.000/0.678/0.694 | c=0.998347
[Epoch 0126] loss=31.3736 cls=0.1427 smmd=0.3676 ct=9.5968 rec=1.1741 | train/val/test=0.980/0.686/0.697 | c=0.998347
[Epoch 0127] loss=31.4242 cls=0.1657 smmd=0.3816 ct=9.6194 rec=1.1721 | train/val/test=0.980/0.670/0.688 | c=0.998347
[Epoch 0128] loss=31.2822 cls=0.1177 smmd=0.3376 ct=9.6131 rec=1.1660 | train/val/test=0.980/0.684/0.695 | c=0.998347
[Epoch 0129] loss=31.1136 cls=0.1068 smmd=0.2842 ct=9.5908 rec=1.1594 | train/val/test=0.980/0.692/0.698 | c=0.998347
[Epoch 0130] loss=31.2153 cls=0.1219 smmd=0.3193 ct=9.5961 rec=1.1643 | train/val/test=0.980/0.664/0.685 | c=0.998347
[Epoch 0131] loss=31.3169 cls=0.1185 smmd=0.3286 ct=9.6056 rec=1.1718 | train/val/test=0.980/0.684/0.690 | c=0.998347
[Epoch 0132] loss=31.3234 cls=0.1410 smmd=0.2934 ct=9.6180 rec=1.1724 | train/val/test=0.980/0.684/0.692 | c=0.998347
[Epoch 0133] loss=31.4465 cls=0.1382 smmd=0.3900 ct=9.5936 rec=1.1800 | train/val/test=0.980/0.660/0.679 | c=0.998347
[Epoch 0134] loss=31.5974 cls=0.1382 smmd=0.3904 ct=9.6640 rec=1.1810 | train/val/test=0.940/0.684/0.691 | c=0.998347
[Epoch 0135] loss=31.3424 cls=0.1376 smmd=0.3906 ct=9.5998 rec=1.1683 | train/val/test=0.980/0.686/0.696 | c=0.998347
[Epoch 0136] loss=31.2495 cls=0.1041 smmd=0.4004 ct=9.5941 rec=1.1609 | train/val/test=0.980/0.676/0.686 | c=0.998347
[Epoch 0137] loss=31.3252 cls=0.1093 smmd=0.3848 ct=9.6341 rec=1.1618 | train/val/test=0.980/0.676/0.692 | c=0.998347
[Epoch 0138] loss=31.2191 cls=0.1096 smmd=0.3397 ct=9.6217 rec=1.1581 | train/val/test=0.980/0.692/0.693 | c=0.998347
[Epoch 0139] loss=31.2875 cls=0.1175 smmd=0.4098 ct=9.5911 rec=1.1637 | train/val/test=0.980/0.684/0.696 | c=0.998347
[Epoch 0140] loss=31.1856 cls=0.1086 smmd=0.3063 ct=9.5970 rec=1.1631 | train/val/test=0.980/0.680/0.692 | c=0.998347
[Epoch 0141] loss=31.2650 cls=0.1191 smmd=0.2886 ct=9.6164 rec=1.1684 | train/val/test=0.980/0.688/0.695 | c=0.998347
[Epoch 0142] loss=31.2654 cls=0.1266 smmd=0.3087 ct=9.5808 rec=1.1732 | train/val/test=0.980/0.672/0.690 | c=0.998347
[Epoch 0143] loss=31.3996 cls=0.1298 smmd=0.3056 ct=9.6179 rec=1.1793 | train/val/test=0.940/0.672/0.684 | c=0.998347
[Epoch 0144] loss=31.8446 cls=0.2127 smmd=0.4766 ct=9.6347 rec=1.1992 | train/val/test=0.940/0.648/0.672 | c=0.998347
[Epoch 0145] loss=32.0381 cls=0.1979 smmd=0.6267 ct=9.6907 rec=1.1931 | train/val/test=0.980/0.686/0.691 | c=0.998347
[Epoch 0146] loss=31.2750 cls=0.0954 smmd=0.4513 ct=9.6035 rec=1.1569 | train/val/test=0.940/0.694/0.693 | c=0.998347
[Epoch 0147] loss=31.6329 cls=0.1870 smmd=0.6174 ct=9.6319 rec=1.1658 | train/val/test=0.960/0.690/0.690 | c=0.998347
[Epoch 0148] loss=31.3413 cls=0.1256 smmd=0.4854 ct=9.6263 rec=1.1541 | train/val/test=0.980/0.678/0.692 | c=0.998347
[Epoch 0149] loss=31.4015 cls=0.0835 smmd=0.5451 ct=9.6336 rec=1.1547 | train/val/test=0.980/0.676/0.690 | c=0.998347
[Epoch 0150] loss=31.4310 cls=0.0883 smmd=0.5295 ct=9.6284 rec=1.1601 | train/val/test=0.960/0.688/0.690 | c=0.998347
[Epoch 0151] loss=31.2875 cls=0.1120 smmd=0.4352 ct=9.5987 rec=1.1599 | train/val/test=0.960/0.684/0.690 | c=0.998347
[Epoch 0152] loss=31.3735 cls=0.1259 smmd=0.3945 ct=9.6056 rec=1.1705 | train/val/test=0.980/0.670/0.684 | c=0.998347
[Epoch 0153] loss=31.6915 cls=0.1343 smmd=0.5010 ct=9.6379 rec=1.1847 | train/val/test=0.980/0.692/0.694 | c=0.998347
[Epoch 0154] loss=31.4146 cls=0.1328 smmd=0.3794 ct=9.5872 rec=1.1794 | train/val/test=0.980/0.678/0.689 | c=0.998347
[Epoch 0155] loss=31.4009 cls=0.1314 smmd=0.3686 ct=9.6285 rec=1.1710 | train/val/test=0.980/0.676/0.686 | c=0.998347
[Epoch 0156] loss=31.2803 cls=0.1088 smmd=0.3487 ct=9.6061 rec=1.1665 | train/val/test=0.980/0.694/0.693 | c=0.998347
[Epoch 0157] loss=31.3597 cls=0.1256 smmd=0.4619 ct=9.5943 rec=1.1646 | train/val/test=0.940/0.676/0.694 | c=0.998347
[Epoch 0158] loss=31.2696 cls=0.1360 smmd=0.3783 ct=9.6201 rec=1.1583 | train/val/test=0.980/0.668/0.686 | c=0.998347
[Epoch 0159] loss=31.2716 cls=0.1041 smmd=0.3764 ct=9.6259 rec=1.1591 | train/val/test=0.980/0.688/0.692 | c=0.998347
[Epoch 0160] loss=31.2532 cls=0.1034 smmd=0.4190 ct=9.5919 rec=1.1598 | train/val/test=0.980/0.688/0.694 | c=0.998347
[Epoch 0161] loss=31.1933 cls=0.1111 smmd=0.3435 ct=9.5874 rec=1.1620 | train/val/test=0.980/0.668/0.689 | c=0.998347
[Epoch 0162] loss=31.2901 cls=0.1099 smmd=0.3256 ct=9.6247 rec=1.1660 | train/val/test=0.980/0.680/0.693 | c=0.998347
[Epoch 0163] loss=31.1934 cls=0.1119 smmd=0.2877 ct=9.5887 rec=1.1672 | train/val/test=0.980/0.688/0.694 | c=0.998347
[Epoch 0164] loss=31.3601 cls=0.1238 smmd=0.3496 ct=9.5828 rec=1.1783 | train/val/test=0.980/0.662/0.685 | c=0.998347
[Epoch 0165] loss=31.5652 cls=0.1495 smmd=0.3561 ct=9.6563 rec=1.1822 | train/val/test=0.980/0.684/0.694 | c=0.998347
[Epoch 0166] loss=31.3907 cls=0.1366 smmd=0.3917 ct=9.5964 rec=1.1738 | train/val/test=0.980/0.688/0.689 | c=0.998347
[Epoch 0167] loss=31.4145 cls=0.1410 smmd=0.4324 ct=9.6100 rec=1.1692 | train/val/test=0.980/0.662/0.685 | c=0.998347
[Epoch 0168] loss=31.3084 cls=0.1049 smmd=0.3773 ct=9.6304 rec=1.1618 | train/val/test=0.980/0.682/0.692 | c=0.998347
[Epoch 0169] loss=31.2465 cls=0.1260 smmd=0.3856 ct=9.6156 rec=1.1567 | train/val/test=0.960/0.696/0.694 | c=0.998347
[Epoch 0170] loss=31.2559 cls=0.1164 smmd=0.4302 ct=9.5938 rec=1.1580 | train/val/test=0.980/0.680/0.690 | c=0.998347
[Epoch 0171] loss=31.2083 cls=0.0893 smmd=0.3799 ct=9.5947 rec=1.1594 | train/val/test=0.980/0.676/0.693 | c=0.998347
[Epoch 0172] loss=31.2377 cls=0.1112 smmd=0.3312 ct=9.6170 rec=1.1617 | train/val/test=0.980/0.684/0.688 | c=0.998347
[Epoch 0173] loss=31.2038 cls=0.1182 smmd=0.2878 ct=9.5930 rec=1.1671 | train/val/test=1.000/0.678/0.691 | c=0.998347
[Epoch 0174] loss=31.3698 cls=0.1075 smmd=0.3697 ct=9.5909 rec=1.1765 | train/val/test=0.980/0.676/0.694 | c=0.998347
[Epoch 0175] loss=31.2860 cls=0.1379 smmd=0.2822 ct=9.6044 rec=1.1726 | train/val/test=0.960/0.672/0.685 | c=0.998347
[Epoch 0176] loss=31.2373 cls=0.1216 smmd=0.2773 ct=9.5919 rec=1.1715 | train/val/test=0.980/0.686/0.690 | c=0.998347
[Epoch 0177] loss=31.3628 cls=0.1355 smmd=0.3612 ct=9.6069 rec=1.1720 | train/val/test=0.980/0.666/0.687 | c=0.998347
[Epoch 0178] loss=31.2460 cls=0.1261 smmd=0.3229 ct=9.6008 rec=1.1658 | train/val/test=0.960/0.680/0.690 | c=0.998347
[Epoch 0179] loss=31.2443 cls=0.1321 smmd=0.3410 ct=9.6108 rec=1.1616 | train/val/test=0.980/0.674/0.690 | c=0.998347
[Epoch 0180] loss=31.1893 cls=0.0971 smmd=0.3552 ct=9.5930 rec=1.1600 | train/val/test=0.980/0.676/0.693 | c=0.998347
[Epoch 0181] loss=31.1064 cls=0.1001 smmd=0.3008 ct=9.5886 rec=1.1578 | train/val/test=0.980/0.678/0.691 | c=0.998347
[Epoch 0182] loss=31.2224 cls=0.1266 smmd=0.3044 ct=9.6090 rec=1.1637 | train/val/test=0.980/0.670/0.686 | c=0.998347
[Epoch 0183] loss=31.2004 cls=0.1020 smmd=0.2943 ct=9.5908 rec=1.1673 | train/val/test=0.980/0.686/0.691 | c=0.998347
[Epoch 0184] loss=31.2532 cls=0.1366 smmd=0.3001 ct=9.5905 rec=1.1704 | train/val/test=0.980/0.666/0.685 | c=0.998347
[Epoch 0185] loss=31.3236 cls=0.1269 smmd=0.2879 ct=9.6080 rec=1.1756 | train/val/test=0.980/0.672/0.688 | c=0.998347
[Epoch 0186] loss=31.3858 cls=0.1469 smmd=0.3136 ct=9.6187 rec=1.1761 | train/val/test=1.000/0.678/0.694 | c=0.998347
[Epoch 0187] loss=31.5015 cls=0.1495 smmd=0.4316 ct=9.5985 rec=1.1798 | train/val/test=0.980/0.670/0.683 | c=0.998347
[Epoch 0188] loss=31.4154 cls=0.1359 smmd=0.3717 ct=9.6436 rec=1.1688 | train/val/test=0.980/0.660/0.684 | c=0.998347
[Epoch 0189] loss=31.2141 cls=0.1028 smmd=0.3432 ct=9.6083 rec=1.1603 | train/val/test=0.980/0.688/0.693 | c=0.998347
[Epoch 0190] loss=31.2660 cls=0.1081 smmd=0.4371 ct=9.5931 rec=1.1589 | train/val/test=0.960/0.682/0.691 | c=0.998347
[Epoch 0191] loss=31.1825 cls=0.1144 smmd=0.3430 ct=9.6076 rec=1.1567 | train/val/test=0.980/0.664/0.686 | c=0.998347
[Epoch 0192] loss=31.2781 cls=0.0988 smmd=0.3655 ct=9.6213 rec=1.1621 | train/val/test=0.980/0.684/0.692 | c=0.998347
[Epoch 0193] loss=31.1324 cls=0.1079 smmd=0.3071 ct=9.5857 rec=1.1600 | train/val/test=0.980/0.682/0.694 | c=0.998347
[Epoch 0194] loss=31.2456 cls=0.1192 smmd=0.3239 ct=9.5866 rec=1.1689 | train/val/test=0.980/0.662/0.687 | c=0.998347
[Epoch 0195] loss=31.3194 cls=0.1199 smmd=0.2822 ct=9.6173 rec=1.1743 | train/val/test=0.980/0.688/0.691 | c=0.998347
[Epoch 0196] loss=31.3129 cls=0.1399 smmd=0.3169 ct=9.5871 rec=1.1752 | train/val/test=0.980/0.666/0.684 | c=0.998347
[Epoch 0197] loss=31.4322 cls=0.1193 smmd=0.3531 ct=9.6195 rec=1.1780 | train/val/test=0.960/0.670/0.694 | c=0.998347
[Epoch 0198] loss=31.3592 cls=0.1578 smmd=0.3785 ct=9.6044 rec=1.1693 | train/val/test=0.980/0.682/0.692 | c=0.998347
[Epoch 0199] loss=31.2210 cls=0.1355 smmd=0.3277 ct=9.6097 rec=1.1606 | train/val/test=0.980/0.662/0.688 | c=0.998347
=== Best @ epoch 48: val=0.7200, test=0.7100 ===

==================================================
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-5 - 2025-09-21 06:26:14:
Running experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-5...
Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=50, val=500, test=1000 (mode=few, shot=10)
[Epoch 0000] loss=37.8718 cls=1.7910 smmd=4.1220 ct=9.4688 rec=1.3917 | train/val/test=0.140/0.212/0.231 | c=0.998347
[Epoch 0001] loss=37.6245 cls=1.7857 smmd=3.8811 ct=9.4668 rec=1.3917 | train/val/test=0.260/0.072/0.107 | c=0.998347
[Epoch 0002] loss=36.3709 cls=1.7703 smmd=2.9599 ct=9.3046 rec=1.3917 | train/val/test=0.560/0.292/0.328 | c=0.998347
[Epoch 0003] loss=35.3932 cls=1.7424 smmd=2.3739 ct=9.1161 rec=1.3916 | train/val/test=0.440/0.320/0.376 | c=0.998347
[Epoch 0004] loss=35.1006 cls=1.7001 smmd=2.1519 ct=9.0924 rec=1.3914 | train/val/test=0.680/0.570/0.586 | c=0.998347
[Epoch 0005] loss=34.6641 cls=1.6459 smmd=1.8749 ct=9.0291 rec=1.3908 | train/val/test=0.760/0.592/0.619 | c=0.998347
[Epoch 0006] loss=34.4740 cls=1.5866 smmd=1.7468 ct=9.0180 rec=1.3898 | train/val/test=0.720/0.584/0.627 | c=0.998347
[Epoch 0007] loss=34.1921 cls=1.5257 smmd=1.5237 ct=9.0103 rec=1.3885 | train/val/test=0.720/0.604/0.626 | c=0.998347
[Epoch 0008] loss=35.3508 cls=1.4661 smmd=1.3480 ct=9.6996 rec=1.3871 | train/val/test=0.740/0.616/0.653 | c=0.998347
[Epoch 0009] loss=35.1366 cls=1.4143 smmd=1.4080 ct=9.5834 rec=1.3855 | train/val/test=0.740/0.616/0.653 | c=0.998347
[Epoch 0010] loss=35.0935 cls=1.3745 smmd=1.6135 ct=9.4750 rec=1.3843 | train/val/test=0.740/0.624/0.669 | c=0.998347
[Epoch 0011] loss=34.9722 cls=1.3333 smmd=1.5982 ct=9.4362 rec=1.3835 | train/val/test=0.780/0.638/0.656 | c=0.998347
[Epoch 0012] loss=34.7728 cls=1.2837 smmd=1.3555 ct=9.4730 rec=1.3830 | train/val/test=0.780/0.642/0.652 | c=0.998347
[Epoch 0013] loss=34.6942 cls=1.2407 smmd=1.1072 ct=9.5701 rec=1.3826 | train/val/test=0.760/0.656/0.665 | c=0.998347
[Epoch 0014] loss=34.4913 cls=1.2006 smmd=0.8367 ct=9.6161 rec=1.3822 | train/val/test=0.820/0.642/0.632 | c=0.998347
[Epoch 0015] loss=34.4354 cls=1.1481 smmd=0.8784 ct=9.5834 rec=1.3816 | train/val/test=0.820/0.638/0.631 | c=0.998347
[Epoch 0016] loss=34.3646 cls=1.0966 smmd=0.9749 ct=9.5189 rec=1.3804 | train/val/test=0.840/0.666/0.641 | c=0.998347
[Epoch 0017] loss=34.1898 cls=1.0430 smmd=0.9210 ct=9.4819 rec=1.3784 | train/val/test=0.860/0.660/0.639 | c=0.998347
[Epoch 0018] loss=34.1437 cls=0.9781 smmd=0.8767 ct=9.5104 rec=1.3757 | train/val/test=0.900/0.658/0.630 | c=0.998347
[Epoch 0019] loss=34.0431 cls=0.9245 smmd=0.7746 ct=9.5415 rec=1.3723 | train/val/test=0.860/0.666/0.640 | c=0.998347
[Epoch 0020] loss=33.8637 cls=0.8599 smmd=0.6055 ct=9.5750 rec=1.3678 | train/val/test=0.920/0.662/0.637 | c=0.998347
[Epoch 0021] loss=33.8016 cls=0.8056 smmd=0.6079 ct=9.5816 rec=1.3628 | train/val/test=0.940/0.668/0.641 | c=0.998347
[Epoch 0022] loss=33.6599 cls=0.7555 smmd=0.5878 ct=9.5637 rec=1.3567 | train/val/test=0.940/0.674/0.645 | c=0.998347
[Epoch 0023] loss=33.5565 cls=0.7084 smmd=0.6015 ct=9.5498 rec=1.3501 | train/val/test=0.940/0.670/0.654 | c=0.998347
[Epoch 0024] loss=33.4793 cls=0.6702 smmd=0.6006 ct=9.5535 rec=1.3437 | train/val/test=0.940/0.680/0.649 | c=0.998347
[Epoch 0025] loss=33.3479 cls=0.6307 smmd=0.5267 ct=9.5717 rec=1.3362 | train/val/test=0.940/0.676/0.658 | c=0.998347
[Epoch 0026] loss=33.2308 cls=0.5987 smmd=0.4748 ct=9.5818 rec=1.3293 | train/val/test=0.960/0.676/0.666 | c=0.998347
[Epoch 0027] loss=33.1494 cls=0.5688 smmd=0.4643 ct=9.5868 rec=1.3227 | train/val/test=0.940/0.676/0.669 | c=0.998347
[Epoch 0028] loss=33.0412 cls=0.5405 smmd=0.4352 ct=9.5878 rec=1.3160 | train/val/test=0.960/0.682/0.676 | c=0.998347
[Epoch 0029] loss=32.9675 cls=0.5187 smmd=0.4618 ct=9.5732 rec=1.3100 | train/val/test=0.960/0.692/0.680 | c=0.998347
[Epoch 0030] loss=32.8726 cls=0.4880 smmd=0.4558 ct=9.5702 rec=1.3032 | train/val/test=0.960/0.692/0.681 | c=0.998347
[Epoch 0031] loss=32.7775 cls=0.4659 smmd=0.4119 ct=9.5811 rec=1.2970 | train/val/test=0.960/0.690/0.683 | c=0.998347
[Epoch 0032] loss=32.6993 cls=0.4418 smmd=0.3885 ct=9.5930 rec=1.2904 | train/val/test=0.960/0.698/0.690 | c=0.998347
[Epoch 0033] loss=32.5938 cls=0.4206 smmd=0.3648 ct=9.5900 rec=1.2839 | train/val/test=0.960/0.694/0.704 | c=0.998347
[Epoch 0034] loss=32.5069 cls=0.3996 smmd=0.3748 ct=9.5830 rec=1.2766 | train/val/test=0.940/0.692/0.707 | c=0.998347
[Epoch 0035] loss=32.4313 cls=0.3791 smmd=0.3858 ct=9.5806 rec=1.2695 | train/val/test=0.960/0.696/0.713 | c=0.998347
[Epoch 0036] loss=32.3546 cls=0.3619 smmd=0.3817 ct=9.5815 rec=1.2629 | train/val/test=0.940/0.696/0.710 | c=0.998347
[Epoch 0037] loss=32.2820 cls=0.3423 smmd=0.3707 ct=9.5891 rec=1.2562 | train/val/test=0.940/0.702/0.717 | c=0.998347
[Epoch 0038] loss=32.2115 cls=0.3325 smmd=0.3573 ct=9.5911 rec=1.2506 | train/val/test=0.940/0.694/0.711 | c=0.998347
[Epoch 0039] loss=32.1563 cls=0.3146 smmd=0.3623 ct=9.5956 rec=1.2445 | train/val/test=0.960/0.708/0.715 | c=0.998347
[Epoch 0040] loss=32.0822 cls=0.3104 smmd=0.3568 ct=9.5823 rec=1.2406 | train/val/test=0.940/0.688/0.700 | c=0.998347
[Epoch 0041] loss=32.0601 cls=0.2904 smmd=0.3757 ct=9.5938 rec=1.2352 | train/val/test=0.980/0.716/0.712 | c=0.998347
[Epoch 0042] loss=32.0384 cls=0.3001 smmd=0.3760 ct=9.5883 rec=1.2336 | train/val/test=0.940/0.684/0.686 | c=0.998347
[Epoch 0043] loss=32.0542 cls=0.2728 smmd=0.3798 ct=9.6215 rec=1.2295 | train/val/test=0.980/0.718/0.698 | c=0.998347
[Epoch 0044] loss=32.0588 cls=0.3006 smmd=0.4179 ct=9.5975 rec=1.2296 | train/val/test=0.940/0.686/0.690 | c=0.998347
[Epoch 0045] loss=31.9663 cls=0.2507 smmd=0.4082 ct=9.6163 rec=1.2200 | train/val/test=0.980/0.718/0.711 | c=0.998347
[Epoch 0046] loss=31.8031 cls=0.2410 smmd=0.3609 ct=9.5944 rec=1.2133 | train/val/test=0.980/0.716/0.713 | c=0.998347
[Epoch 0047] loss=31.7732 cls=0.2374 smmd=0.3576 ct=9.5946 rec=1.2108 | train/val/test=0.940/0.692/0.696 | c=0.998347
[Epoch 0048] loss=31.8178 cls=0.2196 smmd=0.3766 ct=9.6149 rec=1.2102 | train/val/test=0.960/0.720/0.710 | c=0.998347
[Epoch 0049] loss=31.7643 cls=0.2323 smmd=0.3613 ct=9.5960 rec=1.2095 | train/val/test=0.980/0.700/0.706 | c=0.998347
[Epoch 0050] loss=31.6874 cls=0.2108 smmd=0.3295 ct=9.6013 rec=1.2050 | train/val/test=0.980/0.704/0.708 | c=0.998347
[Epoch 0051] loss=31.6613 cls=0.2021 smmd=0.3229 ct=9.5980 rec=1.2041 | train/val/test=0.980/0.706/0.700 | c=0.998347
[Epoch 0052] loss=31.6881 cls=0.2200 smmd=0.3317 ct=9.5934 rec=1.2060 | train/val/test=0.980/0.692/0.689 | c=0.998347
[Epoch 0053] loss=31.7419 cls=0.1932 smmd=0.3450 ct=9.6154 rec=1.2070 | train/val/test=0.960/0.716/0.712 | c=0.998347
[Epoch 0054] loss=31.7955 cls=0.2354 smmd=0.3888 ct=9.5980 rec=1.2093 | train/val/test=0.980/0.686/0.688 | c=0.998347
[Epoch 0055] loss=31.7637 cls=0.1843 smmd=0.3806 ct=9.6290 rec=1.2033 | train/val/test=0.980/0.710/0.704 | c=0.998347
[Epoch 0056] loss=31.5925 cls=0.1891 smmd=0.3559 ct=9.5982 rec=1.1946 | train/val/test=0.980/0.704/0.700 | c=0.998347
[Epoch 0057] loss=31.5496 cls=0.1880 smmd=0.3500 ct=9.6023 rec=1.1901 | train/val/test=0.980/0.686/0.693 | c=0.998347
[Epoch 0058] loss=31.6455 cls=0.1576 smmd=0.3904 ct=9.6213 rec=1.1934 | train/val/test=0.960/0.700/0.698 | c=0.998347
[Epoch 0059] loss=31.5637 cls=0.1878 smmd=0.3633 ct=9.6019 rec=1.1903 | train/val/test=0.980/0.696/0.707 | c=0.998347
[Epoch 0060] loss=31.4696 cls=0.1601 smmd=0.3308 ct=9.5939 rec=1.1871 | train/val/test=0.980/0.688/0.691 | c=0.998347
[Epoch 0061] loss=31.5713 cls=0.1605 smmd=0.3395 ct=9.6188 rec=1.1914 | train/val/test=0.960/0.706/0.704 | c=0.998347
[Epoch 0062] loss=31.7146 cls=0.2030 smmd=0.3971 ct=9.6015 rec=1.2013 | train/val/test=0.980/0.674/0.689 | c=0.998347
[Epoch 0063] loss=31.7721 cls=0.1813 smmd=0.4142 ct=9.6380 rec=1.1991 | train/val/test=0.960/0.692/0.704 | c=0.998347
[Epoch 0064] loss=31.7005 cls=0.1867 smmd=0.4315 ct=9.6138 rec=1.1948 | train/val/test=0.960/0.698/0.696 | c=0.998347
[Epoch 0065] loss=31.7428 cls=0.2268 smmd=0.4561 ct=9.6314 rec=1.1910 | train/val/test=1.000/0.676/0.687 | c=0.998347
[Epoch 0066] loss=31.6749 cls=0.1381 smmd=0.4683 ct=9.6324 rec=1.1873 | train/val/test=0.980/0.688/0.696 | c=0.998347
[Epoch 0067] loss=31.3644 cls=0.1300 smmd=0.3761 ct=9.6012 rec=1.1721 | train/val/test=0.960/0.704/0.700 | c=0.998347
[Epoch 0068] loss=31.6106 cls=0.1902 smmd=0.4753 ct=9.6139 rec=1.1812 | train/val/test=0.980/0.686/0.701 | c=0.998347
[Epoch 0069] loss=31.4425 cls=0.1271 smmd=0.4226 ct=9.6028 rec=1.1751 | train/val/test=0.980/0.676/0.694 | c=0.998347
[Epoch 0070] loss=31.4350 cls=0.1288 smmd=0.3687 ct=9.6097 rec=1.1782 | train/val/test=0.960/0.702/0.698 | c=0.998347
[Epoch 0071] loss=31.5784 cls=0.1883 smmd=0.3994 ct=9.6058 rec=1.1873 | train/val/test=0.980/0.688/0.698 | c=0.998347
[Epoch 0072] loss=31.3902 cls=0.1342 smmd=0.3304 ct=9.5913 rec=1.1810 | train/val/test=0.980/0.674/0.696 | c=0.998347
[Epoch 0073] loss=31.4510 cls=0.1338 smmd=0.3221 ct=9.6047 rec=1.1853 | train/val/test=0.960/0.696/0.699 | c=0.998347
[Epoch 0074] loss=31.6470 cls=0.2069 smmd=0.3886 ct=9.6177 rec=1.1920 | train/val/test=1.000/0.680/0.696 | c=0.998347
[Epoch 0075] loss=31.5838 cls=0.1538 smmd=0.3981 ct=9.6114 rec=1.1886 | train/val/test=0.980/0.682/0.693 | c=0.998347
[Epoch 0076] loss=31.3918 cls=0.1357 smmd=0.3353 ct=9.6121 rec=1.1765 | train/val/test=0.960/0.698/0.696 | c=0.998347
[Epoch 0077] loss=31.4076 cls=0.1550 smmd=0.3802 ct=9.5982 rec=1.1754 | train/val/test=0.960/0.672/0.694 | c=0.998347
[Epoch 0078] loss=31.3339 cls=0.1222 smmd=0.3510 ct=9.6007 rec=1.1720 | train/val/test=0.980/0.676/0.697 | c=0.998347
[Epoch 0079] loss=31.3314 cls=0.1257 smmd=0.3320 ct=9.6070 rec=1.1722 | train/val/test=0.960/0.694/0.701 | c=0.998347
[Epoch 0080] loss=31.4254 cls=0.1523 smmd=0.3670 ct=9.5964 rec=1.1789 | train/val/test=0.980/0.672/0.698 | c=0.998347
[Epoch 0081] loss=31.3641 cls=0.1243 smmd=0.3213 ct=9.6068 rec=1.1767 | train/val/test=0.980/0.678/0.700 | c=0.998347
[Epoch 0082] loss=31.2821 cls=0.1239 smmd=0.2784 ct=9.5917 rec=1.1758 | train/val/test=0.980/0.686/0.695 | c=0.998347
[Epoch 0083] loss=31.3471 cls=0.1515 smmd=0.2802 ct=9.5979 rec=1.1795 | train/val/test=0.980/0.668/0.694 | c=0.998347
[Epoch 0084] loss=31.4320 cls=0.1291 smmd=0.3077 ct=9.6103 rec=1.1839 | train/val/test=0.960/0.688/0.697 | c=0.998347
[Epoch 0085] loss=31.3810 cls=0.1573 smmd=0.3128 ct=9.5911 rec=1.1807 | train/val/test=0.980/0.674/0.696 | c=0.998347
[Epoch 0086] loss=31.2885 cls=0.1333 smmd=0.2800 ct=9.6062 rec=1.1729 | train/val/test=0.980/0.680/0.700 | c=0.998347
[Epoch 0087] loss=31.2707 cls=0.1280 smmd=0.3072 ct=9.5927 rec=1.1714 | train/val/test=0.960/0.690/0.696 | c=0.998347
[Epoch 0088] loss=31.2964 cls=0.1486 smmd=0.3145 ct=9.5977 rec=1.1712 | train/val/test=0.980/0.674/0.695 | c=0.998347
[Epoch 0089] loss=31.2534 cls=0.1242 smmd=0.2823 ct=9.6016 rec=1.1706 | train/val/test=0.980/0.682/0.696 | c=0.998347
[Epoch 0090] loss=31.2294 cls=0.1227 smmd=0.2777 ct=9.5881 rec=1.1714 | train/val/test=0.980/0.684/0.695 | c=0.998347
[Epoch 0091] loss=31.2750 cls=0.1374 smmd=0.2790 ct=9.5889 rec=1.1750 | train/val/test=0.980/0.672/0.695 | c=0.998347
[Epoch 0092] loss=31.3157 cls=0.1241 smmd=0.2622 ct=9.6099 rec=1.1772 | train/val/test=0.980/0.688/0.695 | c=0.998347
[Epoch 0093] loss=31.3732 cls=0.1432 smmd=0.3209 ct=9.5881 rec=1.1804 | train/val/test=0.980/0.670/0.685 | c=0.998347
[Epoch 0094] loss=31.4824 cls=0.1512 smmd=0.3226 ct=9.6372 rec=1.1810 | train/val/test=0.940/0.684/0.704 | c=0.998347
[Epoch 0095] loss=31.6431 cls=0.1859 smmd=0.4495 ct=9.6130 rec=1.1875 | train/val/test=0.960/0.684/0.692 | c=0.998347
[Epoch 0096] loss=31.7148 cls=0.2222 smmd=0.4829 ct=9.6468 rec=1.1827 | train/val/test=0.960/0.662/0.689 | c=0.998347
[Epoch 0097] loss=31.3681 cls=0.1150 smmd=0.3906 ct=9.6245 rec=1.1671 | train/val/test=0.960/0.676/0.695 | c=0.998347
[Epoch 0098] loss=31.2920 cls=0.1218 smmd=0.4058 ct=9.6006 rec=1.1624 | train/val/test=0.980/0.692/0.699 | c=0.998347
[Epoch 0099] loss=31.4741 cls=0.1657 smmd=0.4720 ct=9.6172 rec=1.1685 | train/val/test=0.980/0.678/0.696 | c=0.998347
[Epoch 0100] loss=31.2192 cls=0.1058 smmd=0.3459 ct=9.6021 rec=1.1616 | train/val/test=0.980/0.664/0.689 | c=0.998347
[Epoch 0101] loss=31.4142 cls=0.1245 smmd=0.3823 ct=9.6131 rec=1.1743 | train/val/test=0.960/0.692/0.696 | c=0.998347
[Epoch 0102] loss=31.5749 cls=0.1792 smmd=0.4206 ct=9.6233 rec=1.1818 | train/val/test=0.980/0.684/0.699 | c=0.998347
[Epoch 0103] loss=31.3350 cls=0.1308 smmd=0.3356 ct=9.5919 rec=1.1750 | train/val/test=1.000/0.662/0.687 | c=0.998347
[Epoch 0104] loss=31.4791 cls=0.1120 smmd=0.3574 ct=9.6334 rec=1.1799 | train/val/test=0.980/0.696/0.696 | c=0.998347
[Epoch 0105] loss=31.4447 cls=0.1563 smmd=0.4049 ct=9.5978 rec=1.1766 | train/val/test=0.980/0.682/0.696 | c=0.998347
[Epoch 0106] loss=31.2207 cls=0.1138 smmd=0.3292 ct=9.5926 rec=1.1649 | train/val/test=0.980/0.664/0.688 | c=0.998347
[Epoch 0107] loss=31.3139 cls=0.1076 smmd=0.3357 ct=9.6263 rec=1.1672 | train/val/test=0.980/0.696/0.695 | c=0.998347
[Epoch 0108] loss=31.2628 cls=0.1369 smmd=0.3470 ct=9.5988 rec=1.1650 | train/val/test=0.980/0.684/0.697 | c=0.998347
[Epoch 0109] loss=31.2445 cls=0.1238 smmd=0.3549 ct=9.5862 rec=1.1655 | train/val/test=0.980/0.662/0.685 | c=0.998347
[Epoch 0110] loss=31.3361 cls=0.1166 smmd=0.3193 ct=9.6250 rec=1.1708 | train/val/test=0.960/0.692/0.694 | c=0.998347
[Epoch 0111] loss=31.2398 cls=0.1353 smmd=0.2816 ct=9.5925 rec=1.1706 | train/val/test=0.980/0.690/0.698 | c=0.998347
[Epoch 0112] loss=31.2443 cls=0.1241 smmd=0.3074 ct=9.5837 rec=1.1707 | train/val/test=0.980/0.670/0.690 | c=0.998347
[Epoch 0113] loss=31.3069 cls=0.1179 smmd=0.2848 ct=9.6185 rec=1.1726 | train/val/test=0.980/0.690/0.697 | c=0.998347
[Epoch 0114] loss=31.2650 cls=0.1357 smmd=0.3005 ct=9.5898 rec=1.1717 | train/val/test=0.980/0.678/0.695 | c=0.998347
[Epoch 0115] loss=31.3007 cls=0.1162 smmd=0.3483 ct=9.5971 rec=1.1700 | train/val/test=0.980/0.672/0.691 | c=0.998347
[Epoch 0116] loss=31.2490 cls=0.1274 smmd=0.2959 ct=9.6088 rec=1.1672 | train/val/test=0.980/0.684/0.694 | c=0.998347
[Epoch 0117] loss=31.1825 cls=0.1302 smmd=0.2832 ct=9.5941 rec=1.1646 | train/val/test=0.980/0.678/0.692 | c=0.998347
[Epoch 0118] loss=31.2583 cls=0.1147 smmd=0.3420 ct=9.5905 rec=1.1678 | train/val/test=0.980/0.682/0.694 | c=0.998347
[Epoch 0119] loss=31.2256 cls=0.1296 smmd=0.2805 ct=9.6084 rec=1.1664 | train/val/test=0.980/0.682/0.695 | c=0.998347
[Epoch 0120] loss=31.1538 cls=0.1214 smmd=0.2562 ct=9.5869 rec=1.1663 | train/val/test=0.980/0.680/0.697 | c=0.998347
[Epoch 0121] loss=31.2469 cls=0.1165 smmd=0.3040 ct=9.5886 rec=1.1708 | train/val/test=0.980/0.684/0.695 | c=0.998347
[Epoch 0122] loss=31.2874 cls=0.1356 smmd=0.2756 ct=9.6075 rec=1.1729 | train/val/test=0.980/0.682/0.695 | c=0.998347
[Epoch 0123] loss=31.2079 cls=0.1136 smmd=0.2699 ct=9.5910 rec=1.1699 | train/val/test=0.980/0.684/0.697 | c=0.998347
[Epoch 0124] loss=31.2221 cls=0.1248 smmd=0.2989 ct=9.5834 rec=1.1694 | train/val/test=0.980/0.676/0.688 | c=0.998347
[Epoch 0125] loss=31.3340 cls=0.1360 smmd=0.2915 ct=9.6314 rec=1.1712 | train/val/test=1.000/0.678/0.694 | c=0.998347
[Epoch 0126] loss=31.3736 cls=0.1427 smmd=0.3676 ct=9.5968 rec=1.1741 | train/val/test=0.980/0.686/0.697 | c=0.998347
[Epoch 0127] loss=31.4242 cls=0.1657 smmd=0.3816 ct=9.6194 rec=1.1721 | train/val/test=0.980/0.670/0.688 | c=0.998347
[Epoch 0128] loss=31.2822 cls=0.1177 smmd=0.3376 ct=9.6131 rec=1.1660 | train/val/test=0.980/0.684/0.695 | c=0.998347
[Epoch 0129] loss=31.1136 cls=0.1068 smmd=0.2842 ct=9.5908 rec=1.1594 | train/val/test=0.980/0.692/0.698 | c=0.998347
[Epoch 0130] loss=31.2153 cls=0.1219 smmd=0.3193 ct=9.5961 rec=1.1643 | train/val/test=0.980/0.664/0.685 | c=0.998347
[Epoch 0131] loss=31.3169 cls=0.1185 smmd=0.3286 ct=9.6056 rec=1.1718 | train/val/test=0.980/0.684/0.690 | c=0.998347
[Epoch 0132] loss=31.3234 cls=0.1410 smmd=0.2934 ct=9.6180 rec=1.1724 | train/val/test=0.980/0.684/0.692 | c=0.998347
[Epoch 0133] loss=31.4465 cls=0.1382 smmd=0.3900 ct=9.5936 rec=1.1800 | train/val/test=0.980/0.660/0.679 | c=0.998347
[Epoch 0134] loss=31.5974 cls=0.1382 smmd=0.3904 ct=9.6640 rec=1.1810 | train/val/test=0.940/0.684/0.691 | c=0.998347
[Epoch 0135] loss=31.3424 cls=0.1376 smmd=0.3906 ct=9.5998 rec=1.1683 | train/val/test=0.980/0.686/0.696 | c=0.998347
[Epoch 0136] loss=31.2495 cls=0.1041 smmd=0.4004 ct=9.5941 rec=1.1609 | train/val/test=0.980/0.676/0.686 | c=0.998347
[Epoch 0137] loss=31.3252 cls=0.1093 smmd=0.3848 ct=9.6341 rec=1.1618 | train/val/test=0.980/0.676/0.692 | c=0.998347
[Epoch 0138] loss=31.2191 cls=0.1096 smmd=0.3397 ct=9.6217 rec=1.1581 | train/val/test=0.980/0.692/0.693 | c=0.998347
[Epoch 0139] loss=31.2875 cls=0.1175 smmd=0.4098 ct=9.5911 rec=1.1637 | train/val/test=0.980/0.684/0.696 | c=0.998347
[Epoch 0140] loss=31.1856 cls=0.1086 smmd=0.3063 ct=9.5970 rec=1.1631 | train/val/test=0.980/0.680/0.692 | c=0.998347
[Epoch 0141] loss=31.2650 cls=0.1191 smmd=0.2886 ct=9.6164 rec=1.1684 | train/val/test=0.980/0.688/0.695 | c=0.998347
[Epoch 0142] loss=31.2654 cls=0.1266 smmd=0.3087 ct=9.5808 rec=1.1732 | train/val/test=0.980/0.672/0.690 | c=0.998347
[Epoch 0143] loss=31.3996 cls=0.1298 smmd=0.3056 ct=9.6179 rec=1.1793 | train/val/test=0.940/0.672/0.684 | c=0.998347
[Epoch 0144] loss=31.8446 cls=0.2127 smmd=0.4766 ct=9.6347 rec=1.1992 | train/val/test=0.940/0.648/0.672 | c=0.998347
[Epoch 0145] loss=32.0381 cls=0.1979 smmd=0.6267 ct=9.6907 rec=1.1931 | train/val/test=0.980/0.686/0.691 | c=0.998347
[Epoch 0146] loss=31.2750 cls=0.0954 smmd=0.4513 ct=9.6035 rec=1.1569 | train/val/test=0.940/0.694/0.693 | c=0.998347
[Epoch 0147] loss=31.6329 cls=0.1870 smmd=0.6174 ct=9.6319 rec=1.1658 | train/val/test=0.960/0.690/0.690 | c=0.998347
[Epoch 0148] loss=31.3413 cls=0.1256 smmd=0.4854 ct=9.6263 rec=1.1541 | train/val/test=0.980/0.678/0.692 | c=0.998347
[Epoch 0149] loss=31.4015 cls=0.0835 smmd=0.5451 ct=9.6336 rec=1.1547 | train/val/test=0.980/0.676/0.690 | c=0.998347
[Epoch 0150] loss=31.4310 cls=0.0883 smmd=0.5295 ct=9.6284 rec=1.1601 | train/val/test=0.960/0.688/0.690 | c=0.998347
[Epoch 0151] loss=31.2875 cls=0.1120 smmd=0.4352 ct=9.5987 rec=1.1599 | train/val/test=0.960/0.684/0.690 | c=0.998347
[Epoch 0152] loss=31.3735 cls=0.1259 smmd=0.3945 ct=9.6056 rec=1.1705 | train/val/test=0.980/0.670/0.684 | c=0.998347
[Epoch 0153] loss=31.6915 cls=0.1343 smmd=0.5010 ct=9.6379 rec=1.1847 | train/val/test=0.980/0.692/0.694 | c=0.998347
[Epoch 0154] loss=31.4146 cls=0.1328 smmd=0.3794 ct=9.5872 rec=1.1794 | train/val/test=0.980/0.678/0.689 | c=0.998347
[Epoch 0155] loss=31.4009 cls=0.1314 smmd=0.3686 ct=9.6285 rec=1.1710 | train/val/test=0.980/0.676/0.686 | c=0.998347
[Epoch 0156] loss=31.2803 cls=0.1088 smmd=0.3487 ct=9.6061 rec=1.1665 | train/val/test=0.980/0.694/0.693 | c=0.998347
[Epoch 0157] loss=31.3597 cls=0.1256 smmd=0.4619 ct=9.5943 rec=1.1646 | train/val/test=0.940/0.676/0.694 | c=0.998347
[Epoch 0158] loss=31.2696 cls=0.1360 smmd=0.3783 ct=9.6201 rec=1.1583 | train/val/test=0.980/0.668/0.686 | c=0.998347
[Epoch 0159] loss=31.2716 cls=0.1041 smmd=0.3764 ct=9.6259 rec=1.1591 | train/val/test=0.980/0.688/0.692 | c=0.998347
[Epoch 0160] loss=31.2532 cls=0.1034 smmd=0.4190 ct=9.5919 rec=1.1598 | train/val/test=0.980/0.688/0.694 | c=0.998347
[Epoch 0161] loss=31.1933 cls=0.1111 smmd=0.3435 ct=9.5874 rec=1.1620 | train/val/test=0.980/0.668/0.689 | c=0.998347
[Epoch 0162] loss=31.2901 cls=0.1099 smmd=0.3256 ct=9.6247 rec=1.1660 | train/val/test=0.980/0.680/0.693 | c=0.998347
[Epoch 0163] loss=31.1934 cls=0.1119 smmd=0.2877 ct=9.5887 rec=1.1672 | train/val/test=0.980/0.688/0.694 | c=0.998347
[Epoch 0164] loss=31.3601 cls=0.1238 smmd=0.3496 ct=9.5828 rec=1.1783 | train/val/test=0.980/0.662/0.685 | c=0.998347
[Epoch 0165] loss=31.5652 cls=0.1495 smmd=0.3561 ct=9.6563 rec=1.1822 | train/val/test=0.980/0.684/0.694 | c=0.998347
[Epoch 0166] loss=31.3907 cls=0.1366 smmd=0.3917 ct=9.5964 rec=1.1738 | train/val/test=0.980/0.688/0.689 | c=0.998347
[Epoch 0167] loss=31.4145 cls=0.1410 smmd=0.4324 ct=9.6100 rec=1.1692 | train/val/test=0.980/0.662/0.685 | c=0.998347
[Epoch 0168] loss=31.3084 cls=0.1049 smmd=0.3773 ct=9.6304 rec=1.1618 | train/val/test=0.980/0.682/0.692 | c=0.998347
[Epoch 0169] loss=31.2465 cls=0.1260 smmd=0.3856 ct=9.6156 rec=1.1567 | train/val/test=0.960/0.696/0.694 | c=0.998347
[Epoch 0170] loss=31.2559 cls=0.1164 smmd=0.4302 ct=9.5938 rec=1.1580 | train/val/test=0.980/0.680/0.690 | c=0.998347
[Epoch 0171] loss=31.2083 cls=0.0893 smmd=0.3799 ct=9.5947 rec=1.1594 | train/val/test=0.980/0.676/0.693 | c=0.998347
[Epoch 0172] loss=31.2377 cls=0.1112 smmd=0.3312 ct=9.6170 rec=1.1617 | train/val/test=0.980/0.684/0.688 | c=0.998347
[Epoch 0173] loss=31.2038 cls=0.1182 smmd=0.2878 ct=9.5930 rec=1.1671 | train/val/test=1.000/0.678/0.691 | c=0.998347
[Epoch 0174] loss=31.3698 cls=0.1075 smmd=0.3697 ct=9.5909 rec=1.1765 | train/val/test=0.980/0.676/0.694 | c=0.998347
[Epoch 0175] loss=31.2860 cls=0.1379 smmd=0.2822 ct=9.6044 rec=1.1726 | train/val/test=0.960/0.672/0.685 | c=0.998347
[Epoch 0176] loss=31.2373 cls=0.1216 smmd=0.2773 ct=9.5919 rec=1.1715 | train/val/test=0.980/0.686/0.690 | c=0.998347
[Epoch 0177] loss=31.3628 cls=0.1355 smmd=0.3612 ct=9.6069 rec=1.1720 | train/val/test=0.980/0.666/0.687 | c=0.998347
[Epoch 0178] loss=31.2460 cls=0.1261 smmd=0.3229 ct=9.6008 rec=1.1658 | train/val/test=0.960/0.680/0.690 | c=0.998347
[Epoch 0179] loss=31.2443 cls=0.1321 smmd=0.3410 ct=9.6108 rec=1.1616 | train/val/test=0.980/0.674/0.690 | c=0.998347
[Epoch 0180] loss=31.1893 cls=0.0971 smmd=0.3552 ct=9.5930 rec=1.1600 | train/val/test=0.980/0.676/0.693 | c=0.998347
[Epoch 0181] loss=31.1064 cls=0.1001 smmd=0.3008 ct=9.5886 rec=1.1578 | train/val/test=0.980/0.678/0.691 | c=0.998347
[Epoch 0182] loss=31.2224 cls=0.1266 smmd=0.3044 ct=9.6090 rec=1.1637 | train/val/test=0.980/0.670/0.686 | c=0.998347
[Epoch 0183] loss=31.2004 cls=0.1020 smmd=0.2943 ct=9.5908 rec=1.1673 | train/val/test=0.980/0.686/0.691 | c=0.998347
[Epoch 0184] loss=31.2532 cls=0.1366 smmd=0.3001 ct=9.5905 rec=1.1704 | train/val/test=0.980/0.666/0.685 | c=0.998347
[Epoch 0185] loss=31.3236 cls=0.1269 smmd=0.2879 ct=9.6080 rec=1.1756 | train/val/test=0.980/0.672/0.688 | c=0.998347
[Epoch 0186] loss=31.3858 cls=0.1469 smmd=0.3136 ct=9.6187 rec=1.1761 | train/val/test=1.000/0.678/0.694 | c=0.998347
[Epoch 0187] loss=31.5015 cls=0.1495 smmd=0.4316 ct=9.5985 rec=1.1798 | train/val/test=0.980/0.670/0.683 | c=0.998347
[Epoch 0188] loss=31.4154 cls=0.1359 smmd=0.3717 ct=9.6436 rec=1.1688 | train/val/test=0.980/0.660/0.684 | c=0.998347
[Epoch 0189] loss=31.2141 cls=0.1028 smmd=0.3432 ct=9.6083 rec=1.1603 | train/val/test=0.980/0.688/0.693 | c=0.998347
[Epoch 0190] loss=31.2660 cls=0.1081 smmd=0.4371 ct=9.5931 rec=1.1589 | train/val/test=0.960/0.682/0.691 | c=0.998347
[Epoch 0191] loss=31.1825 cls=0.1144 smmd=0.3430 ct=9.6076 rec=1.1567 | train/val/test=0.980/0.664/0.686 | c=0.998347
[Epoch 0192] loss=31.2781 cls=0.0988 smmd=0.3655 ct=9.6213 rec=1.1621 | train/val/test=0.980/0.684/0.692 | c=0.998347
[Epoch 0193] loss=31.1324 cls=0.1079 smmd=0.3071 ct=9.5857 rec=1.1600 | train/val/test=0.980/0.682/0.694 | c=0.998347
[Epoch 0194] loss=31.2456 cls=0.1192 smmd=0.3239 ct=9.5866 rec=1.1689 | train/val/test=0.980/0.662/0.687 | c=0.998347
[Epoch 0195] loss=31.3194 cls=0.1199 smmd=0.2822 ct=9.6173 rec=1.1743 | train/val/test=0.980/0.688/0.691 | c=0.998347
[Epoch 0196] loss=31.3129 cls=0.1399 smmd=0.3169 ct=9.5871 rec=1.1752 | train/val/test=0.980/0.666/0.684 | c=0.998347
[Epoch 0197] loss=31.4322 cls=0.1193 smmd=0.3531 ct=9.6195 rec=1.1780 | train/val/test=0.960/0.670/0.694 | c=0.998347
[Epoch 0198] loss=31.3592 cls=0.1578 smmd=0.3785 ct=9.6044 rec=1.1693 | train/val/test=0.980/0.682/0.692 | c=0.998347
[Epoch 0199] loss=31.2210 cls=0.1355 smmd=0.3277 ct=9.6097 rec=1.1606 | train/val/test=0.980/0.662/0.688 | c=0.998347
=== Best @ epoch 48: val=0.7200, test=0.7100 ===

Experiment CiteSeer-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-True-10-5 completed in 47.46 seconds.
==================================================
