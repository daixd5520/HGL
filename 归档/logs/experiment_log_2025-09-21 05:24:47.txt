Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-5 - 2025-09-21 05:24:47:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-5...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.5046 cls=1.1027 smmd=5.6735 ct=7.2559 rec=1.4136 | train/val/test=0.446/0.450/0.451 | c=0.998347
[Epoch 0001] loss=53.1240 cls=1.0647 smmd=3.7497 ct=7.1934 rec=1.4152 | train/val/test=0.440/0.448/0.462 | c=0.998347
[Epoch 0002] loss=38.2845 cls=1.0865 smmd=2.2734 ct=7.1503 rec=1.4135 | train/val/test=0.398/0.405/0.422 | c=0.998347
[Epoch 0003] loss=40.8912 cls=1.0485 smmd=2.5428 ct=7.1160 rec=1.4139 | train/val/test=0.575/0.587/0.572 | c=0.998347
[Epoch 0004] loss=40.2148 cls=1.0093 smmd=2.4884 ct=7.0591 rec=1.4149 | train/val/test=0.583/0.591/0.581 | c=0.998347
[Epoch 0005] loss=35.6263 cls=0.9658 smmd=2.0477 ct=6.9796 rec=1.4144 | train/val/test=0.570/0.578/0.565 | c=0.998347
[Epoch 0006] loss=30.9197 cls=0.9212 smmd=1.5910 ct=6.9213 rec=1.4121 | train/val/test=0.561/0.572/0.558 | c=0.998347
[Epoch 0007] loss=33.8046 cls=0.8731 smmd=1.8840 ct=6.9127 rec=1.4046 | train/val/test=0.636/0.645/0.627 | c=0.998347
[Epoch 0008] loss=34.4053 cls=0.8183 smmd=1.9478 ct=6.9109 rec=1.3921 | train/val/test=0.698/0.699/0.688 | c=0.998347
[Epoch 0009] loss=27.9409 cls=0.7695 smmd=1.3092 ct=6.8877 rec=1.3775 | train/val/test=0.705/0.704/0.694 | c=0.998347
[Epoch 0010] loss=27.3955 cls=0.7369 smmd=1.2584 ct=6.8796 rec=1.3676 | train/val/test=0.699/0.705/0.690 | c=0.998347
[Epoch 0011] loss=29.2052 cls=0.7140 smmd=1.4411 ct=6.8784 rec=1.3609 | train/val/test=0.716/0.723/0.709 | c=0.998347
[Epoch 0012] loss=25.6261 cls=0.6870 smmd=1.0874 ct=6.8668 rec=1.3495 | train/val/test=0.730/0.740/0.725 | c=0.998347
[Epoch 0013] loss=25.7780 cls=0.6693 smmd=1.1025 ct=6.8738 rec=1.3406 | train/val/test=0.734/0.742/0.731 | c=0.998347
[Epoch 0014] loss=24.6269 cls=0.6551 smmd=0.9867 ct=6.8823 rec=1.3353 | train/val/test=0.739/0.739/0.734 | c=0.998347
[Epoch 0015] loss=24.0590 cls=0.6394 smmd=0.9326 ct=6.8723 rec=1.3376 | train/val/test=0.773/0.781/0.772 | c=0.998347
[Epoch 0016] loss=23.8062 cls=0.6098 smmd=0.9066 ct=6.8821 rec=1.3418 | train/val/test=0.791/0.797/0.781 | c=0.998347
[Epoch 0017] loss=22.1925 cls=0.5884 smmd=0.7500 ct=6.8652 rec=1.3363 | train/val/test=0.760/0.762/0.754 | c=0.998347
[Epoch 0018] loss=22.3002 cls=0.6057 smmd=0.7569 ct=6.8822 rec=1.3276 | train/val/test=0.781/0.783/0.774 | c=0.998347
[Epoch 0019] loss=21.4483 cls=0.5772 smmd=0.6740 ct=6.8788 rec=1.3252 | train/val/test=0.810/0.818/0.809 | c=0.998347
[Epoch 0020] loss=21.0272 cls=0.5391 smmd=0.6355 ct=6.8685 rec=1.3317 | train/val/test=0.806/0.814/0.805 | c=0.998347
[Epoch 0021] loss=20.7025 cls=0.5266 smmd=0.6037 ct=6.8690 rec=1.3293 | train/val/test=0.809/0.815/0.810 | c=0.998347
[Epoch 0022] loss=20.1112 cls=0.5137 smmd=0.5466 ct=6.8633 rec=1.3231 | train/val/test=0.817/0.823/0.819 | c=0.998347
[Epoch 0023] loss=19.6775 cls=0.5039 smmd=0.5035 ct=6.8652 rec=1.3200 | train/val/test=0.819/0.820/0.817 | c=0.998347
[Epoch 0024] loss=19.5252 cls=0.4996 smmd=0.4880 ct=6.8685 rec=1.3168 | train/val/test=0.821/0.824/0.824 | c=0.998347
[Epoch 0025] loss=19.1636 cls=0.4830 smmd=0.4538 ct=6.8626 rec=1.3181 | train/val/test=0.823/0.832/0.829 | c=0.998347
[Epoch 0026] loss=18.7381 cls=0.4762 smmd=0.4115 ct=6.8626 rec=1.3193 | train/val/test=0.828/0.835/0.828 | c=0.998347
[Epoch 0027] loss=20.1703 cls=0.4706 smmd=0.4125 ct=7.5764 rec=1.3150 | train/val/test=0.824/0.825/0.823 | c=0.998347
[Epoch 0028] loss=19.7227 cls=0.4792 smmd=0.3790 ct=7.5189 rec=1.3103 | train/val/test=0.828/0.832/0.830 | c=0.998347
[Epoch 0029] loss=19.5253 cls=0.4624 smmd=0.3528 ct=7.5557 rec=1.3100 | train/val/test=0.831/0.837/0.831 | c=0.998347
[Epoch 0030] loss=19.4603 cls=0.4545 smmd=0.3439 ct=7.5691 rec=1.3123 | train/val/test=0.830/0.835/0.832 | c=0.998347
[Epoch 0031] loss=19.1939 cls=0.4546 smmd=0.3233 ct=7.5394 rec=1.3090 | train/val/test=0.830/0.833/0.830 | c=0.998347
[Epoch 0032] loss=18.8896 cls=0.4596 smmd=0.2892 ct=7.5569 rec=1.3082 | train/val/test=0.831/0.836/0.832 | c=0.998347
[Epoch 0033] loss=18.9725 cls=0.4512 smmd=0.3005 ct=7.5442 rec=1.3078 | train/val/test=0.832/0.836/0.830 | c=0.998347
[Epoch 0034] loss=18.5318 cls=0.4493 smmd=0.2580 ct=7.5368 rec=1.3079 | train/val/test=0.835/0.838/0.835 | c=0.998347
[Epoch 0035] loss=18.4740 cls=0.4473 smmd=0.2471 ct=7.5619 rec=1.3103 | train/val/test=0.832/0.838/0.831 | c=0.998347
[Epoch 0036] loss=18.4450 cls=0.4506 smmd=0.2499 ct=7.5337 rec=1.3067 | train/val/test=0.832/0.837/0.831 | c=0.998347
[Epoch 0037] loss=18.1681 cls=0.4526 smmd=0.2221 ct=7.5340 rec=1.3063 | train/val/test=0.834/0.839/0.833 | c=0.998347
[Epoch 0038] loss=18.1980 cls=0.4487 smmd=0.2224 ct=7.5474 rec=1.3101 | train/val/test=0.834/0.839/0.836 | c=0.998347
[Epoch 0039] loss=18.0453 cls=0.4508 smmd=0.2082 ct=7.5409 rec=1.3118 | train/val/test=0.837/0.839/0.835 | c=0.998347
[Epoch 0040] loss=17.9435 cls=0.4544 smmd=0.1993 ct=7.5340 rec=1.3101 | train/val/test=0.835/0.837/0.832 | c=0.998347
[Epoch 0041] loss=17.9274 cls=0.4552 smmd=0.1973 ct=7.5359 rec=1.3109 | train/val/test=0.833/0.836/0.833 | c=0.998347
[Epoch 0042] loss=17.7628 cls=0.4561 smmd=0.1798 ct=7.5401 rec=1.3129 | train/val/test=0.835/0.839/0.836 | c=0.998347
[Epoch 0043] loss=17.7459 cls=0.4561 smmd=0.1794 ct=7.5333 rec=1.3138 | train/val/test=0.837/0.841/0.835 | c=0.998347
[Epoch 0044] loss=17.6455 cls=0.4576 smmd=0.1702 ct=7.5293 rec=1.3130 | train/val/test=0.834/0.835/0.832 | c=0.998347
[Epoch 0045] loss=17.5860 cls=0.4592 smmd=0.1649 ct=7.5253 rec=1.3128 | train/val/test=0.837/0.839/0.835 | c=0.998347
[Epoch 0046] loss=17.4955 cls=0.4574 smmd=0.1536 ct=7.5368 rec=1.3141 | train/val/test=0.834/0.837/0.832 | c=0.998347
[Epoch 0047] loss=17.4173 cls=0.4591 smmd=0.1484 ct=7.5235 rec=1.3136 | train/val/test=0.839/0.842/0.836 | c=0.998347
[Epoch 0048] loss=17.3955 cls=0.4589 smmd=0.1480 ct=7.5145 rec=1.3142 | train/val/test=0.838/0.840/0.833 | c=0.998347
[Epoch 0049] loss=17.2763 cls=0.4600 smmd=0.1335 ct=7.5271 rec=1.3139 | train/val/test=0.836/0.840/0.833 | c=0.998347
[Epoch 0050] loss=17.3308 cls=0.4607 smmd=0.1393 ct=7.5247 rec=1.3151 | train/val/test=0.838/0.841/0.835 | c=0.998347
[Epoch 0051] loss=17.2646 cls=0.4629 smmd=0.1343 ct=7.5159 rec=1.3159 | train/val/test=0.838/0.840/0.834 | c=0.998347
[Epoch 0052] loss=17.2797 cls=0.4653 smmd=0.1343 ct=7.5227 rec=1.3168 | train/val/test=0.839/0.844/0.837 | c=0.998347
[Epoch 0053] loss=17.2995 cls=0.4664 smmd=0.1365 ct=7.5211 rec=1.3188 | train/val/test=0.833/0.833/0.832 | c=0.998347
[Epoch 0054] loss=17.3389 cls=0.4710 smmd=0.1398 ct=7.5232 rec=1.3184 | train/val/test=0.841/0.848/0.837 | c=0.998347
[Epoch 0055] loss=17.3100 cls=0.4710 smmd=0.1366 ct=7.5240 rec=1.3208 | train/val/test=0.832/0.833/0.831 | c=0.998347
[Epoch 0056] loss=17.2491 cls=0.4713 smmd=0.1325 ct=7.5145 rec=1.3178 | train/val/test=0.841/0.847/0.837 | c=0.998347
[Epoch 0057] loss=17.1825 cls=0.4670 smmd=0.1246 ct=7.5219 rec=1.3191 | train/val/test=0.833/0.834/0.831 | c=0.998347
[Epoch 0058] loss=17.1474 cls=0.4688 smmd=0.1247 ct=7.5040 rec=1.3156 | train/val/test=0.841/0.845/0.836 | c=0.998347
[Epoch 0059] loss=17.1705 cls=0.4645 smmd=0.1229 ct=7.5249 rec=1.3180 | train/val/test=0.834/0.834/0.832 | c=0.998347
[Epoch 0060] loss=17.1424 cls=0.4667 smmd=0.1261 ct=7.4955 rec=1.3146 | train/val/test=0.839/0.845/0.836 | c=0.998347
[Epoch 0061] loss=17.0630 cls=0.4618 smmd=0.1138 ct=7.5178 rec=1.3167 | train/val/test=0.834/0.837/0.833 | c=0.998347
[Epoch 0062] loss=16.9969 cls=0.4654 smmd=0.1097 ct=7.5046 rec=1.3158 | train/val/test=0.839/0.844/0.836 | c=0.998347
[Epoch 0063] loss=17.0717 cls=0.4647 smmd=0.1172 ct=7.5043 rec=1.3177 | train/val/test=0.835/0.839/0.835 | c=0.998347
[Epoch 0064] loss=17.1049 cls=0.4673 smmd=0.1183 ct=7.5147 rec=1.3180 | train/val/test=0.837/0.844/0.836 | c=0.998347
[Epoch 0065] loss=17.1037 cls=0.4674 smmd=0.1190 ct=7.5098 rec=1.3196 | train/val/test=0.835/0.839/0.835 | c=0.998347
[Epoch 0066] loss=17.2054 cls=0.4690 smmd=0.1302 ct=7.5043 rec=1.3198 | train/val/test=0.838/0.844/0.838 | c=0.998347
[Epoch 0067] loss=17.2398 cls=0.4675 smmd=0.1318 ct=7.5139 rec=1.3200 | train/val/test=0.835/0.839/0.834 | c=0.998347
[Epoch 0068] loss=17.2451 cls=0.4668 smmd=0.1348 ct=7.5023 rec=1.3187 | train/val/test=0.839/0.843/0.837 | c=0.998347
[Epoch 0069] loss=17.0848 cls=0.4625 smmd=0.1193 ct=7.5006 rec=1.3184 | train/val/test=0.836/0.838/0.833 | c=0.998347
[Epoch 0070] loss=17.0307 cls=0.4621 smmd=0.1149 ct=7.4963 rec=1.3161 | train/val/test=0.839/0.846/0.837 | c=0.998347
[Epoch 0071] loss=17.0213 cls=0.4595 smmd=0.1143 ct=7.4951 rec=1.3169 | train/val/test=0.836/0.836/0.833 | c=0.998347
[Epoch 0072] loss=17.0153 cls=0.4617 smmd=0.1154 ct=7.4865 rec=1.3159 | train/val/test=0.841/0.848/0.837 | c=0.998347
[Epoch 0073] loss=16.9655 cls=0.4612 smmd=0.1079 ct=7.4979 rec=1.3193 | train/val/test=0.834/0.833/0.830 | c=0.998347
[Epoch 0074] loss=16.9648 cls=0.4664 smmd=0.1103 ct=7.4850 rec=1.3180 | train/val/test=0.842/0.849/0.838 | c=0.998347
[Epoch 0075] loss=16.9994 cls=0.4663 smmd=0.1104 ct=7.5004 rec=1.3230 | train/val/test=0.829/0.828/0.827 | c=0.998347
[Epoch 0076] loss=17.0847 cls=0.4753 smmd=0.1229 ct=7.4788 rec=1.3217 | train/val/test=0.842/0.846/0.839 | c=0.998347
[Epoch 0077] loss=17.1611 cls=0.4752 smmd=0.1239 ct=7.5103 rec=1.3279 | train/val/test=0.820/0.819/0.810 | c=0.998347
[Epoch 0078] loss=17.2631 cls=0.4930 smmd=0.1408 ct=7.4729 rec=1.3266 | train/val/test=0.832/0.833/0.827 | c=0.998347
[Epoch 0079] loss=17.3729 cls=0.4932 smmd=0.1422 ct=7.5184 rec=1.3351 | train/val/test=0.802/0.804/0.793 | c=0.998347
[Epoch 0080] loss=17.4801 cls=0.5229 smmd=0.1634 ct=7.4593 rec=1.3313 | train/val/test=0.815/0.811/0.811 | c=0.998347
[Epoch 0081] loss=17.4862 cls=0.5102 smmd=0.1508 ct=7.5266 rec=1.3403 | train/val/test=0.808/0.806/0.797 | c=0.998347
[Epoch 0082] loss=17.4051 cls=0.5141 smmd=0.1590 ct=7.4473 rec=1.3266 | train/val/test=0.837/0.840/0.832 | c=0.998347
[Epoch 0083] loss=17.2021 cls=0.4701 smmd=0.1336 ct=7.4846 rec=1.3241 | train/val/test=0.834/0.833/0.831 | c=0.998347
[Epoch 0084] loss=17.0561 cls=0.4630 smmd=0.1254 ct=7.4559 rec=1.3169 | train/val/test=0.837/0.839/0.833 | c=0.998347
[Epoch 0085] loss=16.9751 cls=0.4621 smmd=0.1191 ct=7.4469 rec=1.3181 | train/val/test=0.840/0.844/0.838 | c=0.998347
[Epoch 0086] loss=16.9909 cls=0.4641 smmd=0.1164 ct=7.4666 rec=1.3232 | train/val/test=0.831/0.830/0.827 | c=0.998347
[Epoch 0087] loss=17.0490 cls=0.4821 smmd=0.1246 ct=7.4491 rec=1.3271 | train/val/test=0.842/0.847/0.840 | c=0.998347
[Epoch 0088] loss=16.9998 cls=0.4786 smmd=0.1161 ct=7.4670 rec=1.3311 | train/val/test=0.828/0.829/0.824 | c=0.998347
[Epoch 0089] loss=17.0694 cls=0.4939 smmd=0.1257 ct=7.4491 rec=1.3348 | train/val/test=0.842/0.845/0.839 | c=0.998347
[Epoch 0090] loss=17.1454 cls=0.4860 smmd=0.1303 ct=7.4661 rec=1.3346 | train/val/test=0.829/0.829/0.825 | c=0.998347
[Epoch 0091] loss=17.2104 cls=0.4920 smmd=0.1408 ct=7.4446 rec=1.3350 | train/val/test=0.843/0.845/0.838 | c=0.998347
[Epoch 0092] loss=17.1726 cls=0.4821 smmd=0.1350 ct=7.4577 rec=1.3323 | train/val/test=0.831/0.829/0.824 | c=0.998347
[Epoch 0093] loss=17.1338 cls=0.4826 smmd=0.1359 ct=7.4342 rec=1.3294 | train/val/test=0.841/0.844/0.837 | c=0.998347
[Epoch 0094] loss=17.0620 cls=0.4751 smmd=0.1253 ct=7.4536 rec=1.3279 | train/val/test=0.833/0.833/0.827 | c=0.998347
[Epoch 0095] loss=16.9289 cls=0.4739 smmd=0.1185 ct=7.4226 rec=1.3234 | train/val/test=0.839/0.844/0.837 | c=0.998347
[Epoch 0096] loss=16.9057 cls=0.4687 smmd=0.1109 ct=7.4498 rec=1.3251 | train/val/test=0.837/0.837/0.833 | c=0.998347
[Epoch 0097] loss=16.9056 cls=0.4718 smmd=0.1162 ct=7.4231 rec=1.3227 | train/val/test=0.841/0.848/0.837 | c=0.998347
[Epoch 0098] loss=16.8663 cls=0.4712 smmd=0.1081 ct=7.4431 rec=1.3270 | train/val/test=0.838/0.840/0.833 | c=0.998347
[Epoch 0099] loss=16.9154 cls=0.4781 smmd=0.1145 ct=7.4339 rec=1.3273 | train/val/test=0.839/0.844/0.841 | c=0.998347
=== Best @ epoch 74: val=0.8494, test=0.8385 ===

==================================================
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-5 - 2025-09-21 05:24:47:
Running experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-5...
Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-5 output:
Parsed from filename: Pretrained backbone is Hyperbolic.
Pretrain dataset overridden by checkpoint: PubMed -> Computers
Split sizes | train=11830, val=3943, test=3944 (mode=public, shot=N/A)
[Epoch 0000] loss=72.5046 cls=1.1027 smmd=5.6735 ct=7.2559 rec=1.4136 | train/val/test=0.446/0.450/0.451 | c=0.998347
[Epoch 0001] loss=53.1240 cls=1.0647 smmd=3.7497 ct=7.1934 rec=1.4152 | train/val/test=0.440/0.448/0.462 | c=0.998347
[Epoch 0002] loss=38.2845 cls=1.0865 smmd=2.2734 ct=7.1503 rec=1.4135 | train/val/test=0.398/0.405/0.422 | c=0.998347
[Epoch 0003] loss=40.8912 cls=1.0485 smmd=2.5428 ct=7.1160 rec=1.4139 | train/val/test=0.575/0.587/0.572 | c=0.998347
[Epoch 0004] loss=40.2148 cls=1.0093 smmd=2.4884 ct=7.0591 rec=1.4149 | train/val/test=0.583/0.591/0.581 | c=0.998347
[Epoch 0005] loss=35.6263 cls=0.9658 smmd=2.0477 ct=6.9796 rec=1.4144 | train/val/test=0.570/0.578/0.565 | c=0.998347
[Epoch 0006] loss=30.9197 cls=0.9212 smmd=1.5910 ct=6.9213 rec=1.4121 | train/val/test=0.561/0.572/0.558 | c=0.998347
[Epoch 0007] loss=33.8046 cls=0.8731 smmd=1.8840 ct=6.9127 rec=1.4046 | train/val/test=0.636/0.645/0.627 | c=0.998347
[Epoch 0008] loss=34.4053 cls=0.8183 smmd=1.9478 ct=6.9109 rec=1.3921 | train/val/test=0.698/0.699/0.688 | c=0.998347
[Epoch 0009] loss=27.9409 cls=0.7695 smmd=1.3092 ct=6.8877 rec=1.3775 | train/val/test=0.705/0.704/0.694 | c=0.998347
[Epoch 0010] loss=27.3955 cls=0.7369 smmd=1.2584 ct=6.8796 rec=1.3676 | train/val/test=0.699/0.705/0.690 | c=0.998347
[Epoch 0011] loss=29.2052 cls=0.7140 smmd=1.4411 ct=6.8784 rec=1.3609 | train/val/test=0.716/0.723/0.709 | c=0.998347
[Epoch 0012] loss=25.6261 cls=0.6870 smmd=1.0874 ct=6.8668 rec=1.3495 | train/val/test=0.730/0.740/0.725 | c=0.998347
[Epoch 0013] loss=25.7780 cls=0.6693 smmd=1.1025 ct=6.8738 rec=1.3406 | train/val/test=0.734/0.742/0.731 | c=0.998347
[Epoch 0014] loss=24.6269 cls=0.6551 smmd=0.9867 ct=6.8823 rec=1.3353 | train/val/test=0.739/0.739/0.734 | c=0.998347
[Epoch 0015] loss=24.0590 cls=0.6394 smmd=0.9326 ct=6.8723 rec=1.3376 | train/val/test=0.773/0.781/0.772 | c=0.998347
[Epoch 0016] loss=23.8062 cls=0.6098 smmd=0.9066 ct=6.8821 rec=1.3418 | train/val/test=0.791/0.797/0.781 | c=0.998347
[Epoch 0017] loss=22.1925 cls=0.5884 smmd=0.7500 ct=6.8652 rec=1.3363 | train/val/test=0.760/0.762/0.754 | c=0.998347
[Epoch 0018] loss=22.3002 cls=0.6057 smmd=0.7569 ct=6.8822 rec=1.3276 | train/val/test=0.781/0.783/0.774 | c=0.998347
[Epoch 0019] loss=21.4483 cls=0.5772 smmd=0.6740 ct=6.8788 rec=1.3252 | train/val/test=0.810/0.818/0.809 | c=0.998347
[Epoch 0020] loss=21.0272 cls=0.5391 smmd=0.6355 ct=6.8685 rec=1.3317 | train/val/test=0.806/0.814/0.805 | c=0.998347
[Epoch 0021] loss=20.7025 cls=0.5266 smmd=0.6037 ct=6.8690 rec=1.3293 | train/val/test=0.809/0.815/0.810 | c=0.998347
[Epoch 0022] loss=20.1112 cls=0.5137 smmd=0.5466 ct=6.8633 rec=1.3231 | train/val/test=0.817/0.823/0.819 | c=0.998347
[Epoch 0023] loss=19.6775 cls=0.5039 smmd=0.5035 ct=6.8652 rec=1.3200 | train/val/test=0.819/0.820/0.817 | c=0.998347
[Epoch 0024] loss=19.5252 cls=0.4996 smmd=0.4880 ct=6.8685 rec=1.3168 | train/val/test=0.821/0.824/0.824 | c=0.998347
[Epoch 0025] loss=19.1636 cls=0.4830 smmd=0.4538 ct=6.8626 rec=1.3181 | train/val/test=0.823/0.832/0.829 | c=0.998347
[Epoch 0026] loss=18.7381 cls=0.4762 smmd=0.4115 ct=6.8626 rec=1.3193 | train/val/test=0.828/0.835/0.828 | c=0.998347
[Epoch 0027] loss=20.1703 cls=0.4706 smmd=0.4125 ct=7.5764 rec=1.3150 | train/val/test=0.824/0.825/0.823 | c=0.998347
[Epoch 0028] loss=19.7227 cls=0.4792 smmd=0.3790 ct=7.5189 rec=1.3103 | train/val/test=0.828/0.832/0.830 | c=0.998347
[Epoch 0029] loss=19.5253 cls=0.4624 smmd=0.3528 ct=7.5557 rec=1.3100 | train/val/test=0.831/0.837/0.831 | c=0.998347
[Epoch 0030] loss=19.4603 cls=0.4545 smmd=0.3439 ct=7.5691 rec=1.3123 | train/val/test=0.830/0.835/0.832 | c=0.998347
[Epoch 0031] loss=19.1939 cls=0.4546 smmd=0.3233 ct=7.5394 rec=1.3090 | train/val/test=0.830/0.833/0.830 | c=0.998347
[Epoch 0032] loss=18.8896 cls=0.4596 smmd=0.2892 ct=7.5569 rec=1.3082 | train/val/test=0.831/0.836/0.832 | c=0.998347
[Epoch 0033] loss=18.9725 cls=0.4512 smmd=0.3005 ct=7.5442 rec=1.3078 | train/val/test=0.832/0.836/0.830 | c=0.998347
[Epoch 0034] loss=18.5318 cls=0.4493 smmd=0.2580 ct=7.5368 rec=1.3079 | train/val/test=0.835/0.838/0.835 | c=0.998347
[Epoch 0035] loss=18.4740 cls=0.4473 smmd=0.2471 ct=7.5619 rec=1.3103 | train/val/test=0.832/0.838/0.831 | c=0.998347
[Epoch 0036] loss=18.4450 cls=0.4506 smmd=0.2499 ct=7.5337 rec=1.3067 | train/val/test=0.832/0.837/0.831 | c=0.998347
[Epoch 0037] loss=18.1681 cls=0.4526 smmd=0.2221 ct=7.5340 rec=1.3063 | train/val/test=0.834/0.839/0.833 | c=0.998347
[Epoch 0038] loss=18.1980 cls=0.4487 smmd=0.2224 ct=7.5474 rec=1.3101 | train/val/test=0.834/0.839/0.836 | c=0.998347
[Epoch 0039] loss=18.0453 cls=0.4508 smmd=0.2082 ct=7.5409 rec=1.3118 | train/val/test=0.837/0.839/0.835 | c=0.998347
[Epoch 0040] loss=17.9435 cls=0.4544 smmd=0.1993 ct=7.5340 rec=1.3101 | train/val/test=0.835/0.837/0.832 | c=0.998347
[Epoch 0041] loss=17.9274 cls=0.4552 smmd=0.1973 ct=7.5359 rec=1.3109 | train/val/test=0.833/0.836/0.833 | c=0.998347
[Epoch 0042] loss=17.7628 cls=0.4561 smmd=0.1798 ct=7.5401 rec=1.3129 | train/val/test=0.835/0.839/0.836 | c=0.998347
[Epoch 0043] loss=17.7459 cls=0.4561 smmd=0.1794 ct=7.5333 rec=1.3138 | train/val/test=0.837/0.841/0.835 | c=0.998347
[Epoch 0044] loss=17.6455 cls=0.4576 smmd=0.1702 ct=7.5293 rec=1.3130 | train/val/test=0.834/0.835/0.832 | c=0.998347
[Epoch 0045] loss=17.5860 cls=0.4592 smmd=0.1649 ct=7.5253 rec=1.3128 | train/val/test=0.837/0.839/0.835 | c=0.998347
[Epoch 0046] loss=17.4955 cls=0.4574 smmd=0.1536 ct=7.5368 rec=1.3141 | train/val/test=0.834/0.837/0.832 | c=0.998347
[Epoch 0047] loss=17.4173 cls=0.4591 smmd=0.1484 ct=7.5235 rec=1.3136 | train/val/test=0.839/0.842/0.836 | c=0.998347
[Epoch 0048] loss=17.3955 cls=0.4589 smmd=0.1480 ct=7.5145 rec=1.3142 | train/val/test=0.838/0.840/0.833 | c=0.998347
[Epoch 0049] loss=17.2763 cls=0.4600 smmd=0.1335 ct=7.5271 rec=1.3139 | train/val/test=0.836/0.840/0.833 | c=0.998347
[Epoch 0050] loss=17.3308 cls=0.4607 smmd=0.1393 ct=7.5247 rec=1.3151 | train/val/test=0.838/0.841/0.835 | c=0.998347
[Epoch 0051] loss=17.2646 cls=0.4629 smmd=0.1343 ct=7.5159 rec=1.3159 | train/val/test=0.838/0.840/0.834 | c=0.998347
[Epoch 0052] loss=17.2797 cls=0.4653 smmd=0.1343 ct=7.5227 rec=1.3168 | train/val/test=0.839/0.844/0.837 | c=0.998347
[Epoch 0053] loss=17.2995 cls=0.4664 smmd=0.1365 ct=7.5211 rec=1.3188 | train/val/test=0.833/0.833/0.832 | c=0.998347
[Epoch 0054] loss=17.3389 cls=0.4710 smmd=0.1398 ct=7.5232 rec=1.3184 | train/val/test=0.841/0.848/0.837 | c=0.998347
[Epoch 0055] loss=17.3100 cls=0.4710 smmd=0.1366 ct=7.5240 rec=1.3208 | train/val/test=0.832/0.833/0.831 | c=0.998347
[Epoch 0056] loss=17.2491 cls=0.4713 smmd=0.1325 ct=7.5145 rec=1.3178 | train/val/test=0.841/0.847/0.837 | c=0.998347
[Epoch 0057] loss=17.1825 cls=0.4670 smmd=0.1246 ct=7.5219 rec=1.3191 | train/val/test=0.833/0.834/0.831 | c=0.998347
[Epoch 0058] loss=17.1474 cls=0.4688 smmd=0.1247 ct=7.5040 rec=1.3156 | train/val/test=0.841/0.845/0.836 | c=0.998347
[Epoch 0059] loss=17.1705 cls=0.4645 smmd=0.1229 ct=7.5249 rec=1.3180 | train/val/test=0.834/0.834/0.832 | c=0.998347
[Epoch 0060] loss=17.1424 cls=0.4667 smmd=0.1261 ct=7.4955 rec=1.3146 | train/val/test=0.839/0.845/0.836 | c=0.998347
[Epoch 0061] loss=17.0630 cls=0.4618 smmd=0.1138 ct=7.5178 rec=1.3167 | train/val/test=0.834/0.837/0.833 | c=0.998347
[Epoch 0062] loss=16.9969 cls=0.4654 smmd=0.1097 ct=7.5046 rec=1.3158 | train/val/test=0.839/0.844/0.836 | c=0.998347
[Epoch 0063] loss=17.0717 cls=0.4647 smmd=0.1172 ct=7.5043 rec=1.3177 | train/val/test=0.835/0.839/0.835 | c=0.998347
[Epoch 0064] loss=17.1049 cls=0.4673 smmd=0.1183 ct=7.5147 rec=1.3180 | train/val/test=0.837/0.844/0.836 | c=0.998347
[Epoch 0065] loss=17.1037 cls=0.4674 smmd=0.1190 ct=7.5098 rec=1.3196 | train/val/test=0.835/0.839/0.835 | c=0.998347
[Epoch 0066] loss=17.2054 cls=0.4690 smmd=0.1302 ct=7.5043 rec=1.3198 | train/val/test=0.838/0.844/0.838 | c=0.998347
[Epoch 0067] loss=17.2398 cls=0.4675 smmd=0.1318 ct=7.5139 rec=1.3200 | train/val/test=0.835/0.839/0.834 | c=0.998347
[Epoch 0068] loss=17.2451 cls=0.4668 smmd=0.1348 ct=7.5023 rec=1.3187 | train/val/test=0.839/0.843/0.837 | c=0.998347
[Epoch 0069] loss=17.0848 cls=0.4625 smmd=0.1193 ct=7.5006 rec=1.3184 | train/val/test=0.836/0.838/0.833 | c=0.998347
[Epoch 0070] loss=17.0307 cls=0.4621 smmd=0.1149 ct=7.4963 rec=1.3161 | train/val/test=0.839/0.846/0.837 | c=0.998347
[Epoch 0071] loss=17.0213 cls=0.4595 smmd=0.1143 ct=7.4951 rec=1.3169 | train/val/test=0.836/0.836/0.833 | c=0.998347
[Epoch 0072] loss=17.0153 cls=0.4617 smmd=0.1154 ct=7.4865 rec=1.3159 | train/val/test=0.841/0.848/0.837 | c=0.998347
[Epoch 0073] loss=16.9655 cls=0.4612 smmd=0.1079 ct=7.4979 rec=1.3193 | train/val/test=0.834/0.833/0.830 | c=0.998347
[Epoch 0074] loss=16.9648 cls=0.4664 smmd=0.1103 ct=7.4850 rec=1.3180 | train/val/test=0.842/0.849/0.838 | c=0.998347
[Epoch 0075] loss=16.9994 cls=0.4663 smmd=0.1104 ct=7.5004 rec=1.3230 | train/val/test=0.829/0.828/0.827 | c=0.998347
[Epoch 0076] loss=17.0847 cls=0.4753 smmd=0.1229 ct=7.4788 rec=1.3217 | train/val/test=0.842/0.846/0.839 | c=0.998347
[Epoch 0077] loss=17.1611 cls=0.4752 smmd=0.1239 ct=7.5103 rec=1.3279 | train/val/test=0.820/0.819/0.810 | c=0.998347
[Epoch 0078] loss=17.2631 cls=0.4930 smmd=0.1408 ct=7.4729 rec=1.3266 | train/val/test=0.832/0.833/0.827 | c=0.998347
[Epoch 0079] loss=17.3729 cls=0.4932 smmd=0.1422 ct=7.5184 rec=1.3351 | train/val/test=0.802/0.804/0.793 | c=0.998347
[Epoch 0080] loss=17.4801 cls=0.5229 smmd=0.1634 ct=7.4593 rec=1.3313 | train/val/test=0.815/0.811/0.811 | c=0.998347
[Epoch 0081] loss=17.4862 cls=0.5102 smmd=0.1508 ct=7.5266 rec=1.3403 | train/val/test=0.808/0.806/0.797 | c=0.998347
[Epoch 0082] loss=17.4051 cls=0.5141 smmd=0.1590 ct=7.4473 rec=1.3266 | train/val/test=0.837/0.840/0.832 | c=0.998347
[Epoch 0083] loss=17.2021 cls=0.4701 smmd=0.1336 ct=7.4846 rec=1.3241 | train/val/test=0.834/0.833/0.831 | c=0.998347
[Epoch 0084] loss=17.0561 cls=0.4630 smmd=0.1254 ct=7.4559 rec=1.3169 | train/val/test=0.837/0.839/0.833 | c=0.998347
[Epoch 0085] loss=16.9751 cls=0.4621 smmd=0.1191 ct=7.4469 rec=1.3181 | train/val/test=0.840/0.844/0.838 | c=0.998347
[Epoch 0086] loss=16.9909 cls=0.4641 smmd=0.1164 ct=7.4666 rec=1.3232 | train/val/test=0.831/0.830/0.827 | c=0.998347
[Epoch 0087] loss=17.0490 cls=0.4821 smmd=0.1246 ct=7.4491 rec=1.3271 | train/val/test=0.842/0.847/0.840 | c=0.998347
[Epoch 0088] loss=16.9998 cls=0.4786 smmd=0.1161 ct=7.4670 rec=1.3311 | train/val/test=0.828/0.829/0.824 | c=0.998347
[Epoch 0089] loss=17.0694 cls=0.4939 smmd=0.1257 ct=7.4491 rec=1.3348 | train/val/test=0.842/0.845/0.839 | c=0.998347
[Epoch 0090] loss=17.1454 cls=0.4860 smmd=0.1303 ct=7.4661 rec=1.3346 | train/val/test=0.829/0.829/0.825 | c=0.998347
[Epoch 0091] loss=17.2104 cls=0.4920 smmd=0.1408 ct=7.4446 rec=1.3350 | train/val/test=0.843/0.845/0.838 | c=0.998347
[Epoch 0092] loss=17.1726 cls=0.4821 smmd=0.1350 ct=7.4577 rec=1.3323 | train/val/test=0.831/0.829/0.824 | c=0.998347
[Epoch 0093] loss=17.1338 cls=0.4826 smmd=0.1359 ct=7.4342 rec=1.3294 | train/val/test=0.841/0.844/0.837 | c=0.998347
[Epoch 0094] loss=17.0620 cls=0.4751 smmd=0.1253 ct=7.4536 rec=1.3279 | train/val/test=0.833/0.833/0.827 | c=0.998347
[Epoch 0095] loss=16.9289 cls=0.4739 smmd=0.1185 ct=7.4226 rec=1.3234 | train/val/test=0.839/0.844/0.837 | c=0.998347
[Epoch 0096] loss=16.9057 cls=0.4687 smmd=0.1109 ct=7.4498 rec=1.3251 | train/val/test=0.837/0.837/0.833 | c=0.998347
[Epoch 0097] loss=16.9056 cls=0.4718 smmd=0.1162 ct=7.4231 rec=1.3227 | train/val/test=0.841/0.848/0.837 | c=0.998347
[Epoch 0098] loss=16.8663 cls=0.4712 smmd=0.1081 ct=7.4431 rec=1.3270 | train/val/test=0.838/0.840/0.833 | c=0.998347
[Epoch 0099] loss=16.9154 cls=0.4781 smmd=0.1145 ct=7.4339 rec=1.3273 | train/val/test=0.839/0.844/0.841 | c=0.998347
=== Best @ epoch 74: val=0.8494, test=0.8385 ===

Experiment PubMed-/mnt/data1/Graph/HypGraphLoRA/pre_trained_gnn/Computers.GRACE.GAT.hyp_True.True.20250912-232538.pth-False-5-5 completed in 175.34 seconds.
==================================================
